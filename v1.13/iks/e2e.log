I0618 11:34:31.287091      17 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-953583206
I0618 11:34:31.287416      17 e2e.go:224] Starting e2e run "097fb1c0-91bd-11e9-bce2-ae54e022189f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1560857670 - Will randomize all specs
Will run 201 of 1946 specs

Jun 18 11:34:31.433: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 11:34:31.436: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jun 18 11:34:31.514: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 18 11:34:31.605: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 18 11:34:31.605: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Jun 18 11:34:31.605: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jun 18 11:34:31.629: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jun 18 11:34:31.629: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Jun 18 11:34:31.629: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Jun 18 11:34:31.629: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Jun 18 11:34:31.629: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Jun 18 11:34:31.629: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Jun 18 11:34:31.629: INFO: e2e test version: v1.13.0
Jun 18 11:34:31.634: INFO: kube-apiserver version: v1.13.7+IKS
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:34:31.635: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename sched-pred
Jun 18 11:34:32.035: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jun 18 11:34:32.092: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-6gssw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 18 11:34:32.235: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 18 11:34:32.264: INFO: Waiting for terminating namespaces to be deleted...
Jun 18 11:34:32.279: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.143 before test
Jun 18 11:34:32.331: INFO: calico-node-fw2l9 from kube-system started at 2019-06-17 21:36:37 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.332: INFO: 	Container calico-node ready: true, restart count 0
Jun 18 11:34:32.332: INFO: coredns-autoscaler-5c7646547d-dshx6 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.332: INFO: 	Container autoscaler ready: true, restart count 0
Jun 18 11:34:32.332: INFO: ibm-master-proxy-static-10.72.74.143 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 11:34:32.332: INFO: ibm-keepalived-watcher-5z7h2 from kube-system started at 2019-06-17 21:36:37 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.332: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 11:34:32.332: INFO: kubernetes-dashboard-6cf8b975c-prz8l from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.333: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 18 11:34:32.333: INFO: coredns-5545c6ddc4-dxkvs from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.333: INFO: 	Container coredns ready: true, restart count 0
Jun 18 11:34:32.333: INFO: calico-kube-controllers-54d47c87f-kwkh9 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.333: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jun 18 11:34:32.333: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-zt85r from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 11:34:32.333: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 11:34:32.333: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 18 11:34:32.333: INFO: vpn-7f677b8cb5-29tf9 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.333: INFO: 	Container vpn ready: true, restart count 0
Jun 18 11:34:32.333: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-06-18 11:33:43 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.334: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jun 18 11:34:32.334: INFO: ibm-kube-fluentd-7spm2 from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.334: INFO: 	Container fluentd ready: true, restart count 0
Jun 18 11:34:32.334: INFO: ibm-file-plugin-bf4cc7987-jwdjh from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.334: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jun 18 11:34:32.334: INFO: ibm-storage-watcher-64989c44d-tp68k from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.334: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jun 18 11:34:32.334: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-18 11:33:50 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.334: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 18 11:34:32.334: INFO: sonobuoy-e2e-job-4f826760f7504668 from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 11:34:32.334: INFO: 	Container e2e ready: true, restart count 0
Jun 18 11:34:32.334: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 11:34:32.334: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.144 before test
Jun 18 11:34:32.448: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-ct76c from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 11:34:32.448: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 11:34:32.448: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 18 11:34:32.448: INFO: ibm-master-proxy-static-10.72.74.144 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 11:34:32.448: INFO: calico-node-rptvs from kube-system started at 2019-06-17 21:36:43 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.448: INFO: 	Container calico-node ready: true, restart count 0
Jun 18 11:34:32.448: INFO: coredns-5545c6ddc4-4s87g from kube-system started at 2019-06-17 21:37:04 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.448: INFO: 	Container coredns ready: true, restart count 0
Jun 18 11:34:32.448: INFO: ibm-keepalived-watcher-drbmt from kube-system started at 2019-06-17 21:36:43 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.448: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 11:34:32.448: INFO: ibm-cloud-provider-ip-158-176-120-130-699ff5cfd-z4hhb from ibm-system started at 2019-06-17 21:40:39 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.448: INFO: 	Container ibm-cloud-provider-ip-158-176-120-130 ready: true, restart count 0
Jun 18 11:34:32.448: INFO: public-cr49a3e8d7011b436d9b4596ba0f279008-alb1-778b7ff477-tpktg from kube-system started at 2019-06-17 21:41:04 +0000 UTC (4 container statuses recorded)
Jun 18 11:34:32.448: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jun 18 11:34:32.448: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jun 18 11:34:32.448: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jun 18 11:34:32.448: INFO: 	Container nginx-ingress ready: true, restart count 0
Jun 18 11:34:32.448: INFO: ibm-kube-fluentd-g5hgb from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.448: INFO: 	Container fluentd ready: true, restart count 0
Jun 18 11:34:32.448: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.149 before test
Jun 18 11:34:32.638: INFO: ibm-cloud-provider-ip-158-176-120-130-699ff5cfd-td8hg from ibm-system started at 2019-06-17 21:40:39 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.638: INFO: 	Container ibm-cloud-provider-ip-158-176-120-130 ready: true, restart count 0
Jun 18 11:34:32.638: INFO: public-cr49a3e8d7011b436d9b4596ba0f279008-alb1-778b7ff477-sxttq from kube-system started at 2019-06-17 21:41:04 +0000 UTC (4 container statuses recorded)
Jun 18 11:34:32.638: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jun 18 11:34:32.638: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jun 18 11:34:32.638: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jun 18 11:34:32.638: INFO: 	Container nginx-ingress ready: true, restart count 0
Jun 18 11:34:32.638: INFO: ibm-kube-fluentd-c6kth from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.638: INFO: 	Container fluentd ready: true, restart count 0
Jun 18 11:34:32.638: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-btfpp from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 11:34:32.638: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 11:34:32.638: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 18 11:34:32.638: INFO: ibm-master-proxy-static-10.72.74.149 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 11:34:32.638: INFO: metrics-server-6ccf788d5b-6gwxm from kube-system started at 2019-06-17 21:37:11 +0000 UTC (2 container statuses recorded)
Jun 18 11:34:32.638: INFO: 	Container metrics-server ready: true, restart count 0
Jun 18 11:34:32.638: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jun 18 11:34:32.638: INFO: ibm-keepalived-watcher-6846v from kube-system started at 2019-06-17 21:36:50 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.638: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 11:34:32.638: INFO: calico-node-4pqtj from kube-system started at 2019-06-17 21:36:50 +0000 UTC (1 container statuses recorded)
Jun 18 11:34:32.639: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0d356e86-91bd-11e9-bce2-ae54e022189f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-0d356e86-91bd-11e9-bce2-ae54e022189f off the node 10.72.74.149
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0d356e86-91bd-11e9-bce2-ae54e022189f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:34:38.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-6gssw" for this suite.
Jun 18 11:34:59.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:34:59.600: INFO: namespace: e2e-tests-sched-pred-6gssw, resource: bindings, ignored listing per whitelist
Jun 18 11:34:59.774: INFO: namespace e2e-tests-sched-pred-6gssw deletion completed in 20.78903945s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:28.139 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:34:59.774: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5wsxk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 18 11:35:00.253: INFO: Waiting up to 5m0s for pod "pod-1b2cd48c-91bd-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-5wsxk" to be "success or failure"
Jun 18 11:35:00.268: INFO: Pod "pod-1b2cd48c-91bd-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.299289ms
Jun 18 11:35:02.289: INFO: Pod "pod-1b2cd48c-91bd-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035284058s
Jun 18 11:35:04.303: INFO: Pod "pod-1b2cd48c-91bd-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049995698s
STEP: Saw pod success
Jun 18 11:35:04.303: INFO: Pod "pod-1b2cd48c-91bd-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:35:04.401: INFO: Trying to get logs from node 10.72.74.149 pod pod-1b2cd48c-91bd-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 11:35:04.480: INFO: Waiting for pod pod-1b2cd48c-91bd-11e9-bce2-ae54e022189f to disappear
Jun 18 11:35:04.494: INFO: Pod pod-1b2cd48c-91bd-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:35:04.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5wsxk" for this suite.
Jun 18 11:35:12.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:35:12.751: INFO: namespace: e2e-tests-emptydir-5wsxk, resource: bindings, ignored listing per whitelist
Jun 18 11:35:13.046: INFO: namespace e2e-tests-emptydir-5wsxk deletion completed in 8.528593681s

• [SLOW TEST:13.272 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:35:13.049: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-lzfb8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jun 18 11:35:19.701: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-231d6bba-91bd-11e9-bce2-ae54e022189f", GenerateName:"", Namespace:"e2e-tests-pods-lzfb8", SelfLink:"/api/v1/namespaces/e2e-tests-pods-lzfb8/pods/pod-submit-remove-231d6bba-91bd-11e9-bce2-ae54e022189f", UID:"23232966-91bd-11e9-bf44-fa6f350b29f0", ResourceVersion:"88488", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63696454513, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"548800715"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-7l7c2", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001382ac0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7l7c2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000fde338), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.72.74.143", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0001e2fc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000fde380)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000fde3a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000fde3a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000fde3ac)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696454513, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696454518, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696454518, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696454513, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.72.74.143", PodIP:"172.30.58.140", StartTime:(*v1.Time)(0xc001f7d700), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001f7d720), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"containerd://f00e194769cead829e4e05962add82a982710bf6ef5b60bb89c3902c42d7cfcb"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jun 18 11:35:24.787: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:35:24.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lzfb8" for this suite.
Jun 18 11:35:30.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:35:31.263: INFO: namespace: e2e-tests-pods-lzfb8, resource: bindings, ignored listing per whitelist
Jun 18 11:35:31.422: INFO: namespace e2e-tests-pods-lzfb8 deletion completed in 6.60600513s

• [SLOW TEST:18.373 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:35:31.422: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-75d9j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 18 11:35:31.897: INFO: Waiting up to 5m0s for pod "downward-api-2e09838e-91bd-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-75d9j" to be "success or failure"
Jun 18 11:35:31.912: INFO: Pod "downward-api-2e09838e-91bd-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.631039ms
Jun 18 11:35:33.929: INFO: Pod "downward-api-2e09838e-91bd-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031273594s
Jun 18 11:35:35.951: INFO: Pod "downward-api-2e09838e-91bd-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053079691s
STEP: Saw pod success
Jun 18 11:35:35.951: INFO: Pod "downward-api-2e09838e-91bd-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:35:35.966: INFO: Trying to get logs from node 10.72.74.149 pod downward-api-2e09838e-91bd-11e9-bce2-ae54e022189f container dapi-container: <nil>
STEP: delete the pod
Jun 18 11:35:36.059: INFO: Waiting for pod downward-api-2e09838e-91bd-11e9-bce2-ae54e022189f to disappear
Jun 18 11:35:36.073: INFO: Pod downward-api-2e09838e-91bd-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:35:36.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-75d9j" for this suite.
Jun 18 11:35:42.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:35:42.257: INFO: namespace: e2e-tests-downward-api-75d9j, resource: bindings, ignored listing per whitelist
Jun 18 11:35:42.801: INFO: namespace e2e-tests-downward-api-75d9j deletion completed in 6.701250959s

• [SLOW TEST:11.378 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:35:42.801: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-sv2dm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-vf74
STEP: Creating a pod to test atomic-volume-subpath
Jun 18 11:35:43.332: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vf74" in namespace "e2e-tests-subpath-sv2dm" to be "success or failure"
Jun 18 11:35:43.345: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Pending", Reason="", readiness=false. Elapsed: 13.061065ms
Jun 18 11:35:45.360: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028183825s
Jun 18 11:35:47.399: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 4.066802388s
Jun 18 11:35:49.414: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 6.08196526s
Jun 18 11:35:51.445: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 8.113189468s
Jun 18 11:35:53.517: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 10.185651286s
Jun 18 11:35:55.532: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 12.200305368s
Jun 18 11:35:57.548: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 14.215898756s
Jun 18 11:35:59.563: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 16.231264019s
Jun 18 11:36:01.596: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 18.263674965s
Jun 18 11:36:03.612: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 20.280467994s
Jun 18 11:36:05.627: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Running", Reason="", readiness=false. Elapsed: 22.295303171s
Jun 18 11:36:07.642: INFO: Pod "pod-subpath-test-configmap-vf74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.310376023s
STEP: Saw pod success
Jun 18 11:36:07.642: INFO: Pod "pod-subpath-test-configmap-vf74" satisfied condition "success or failure"
Jun 18 11:36:07.657: INFO: Trying to get logs from node 10.72.74.149 pod pod-subpath-test-configmap-vf74 container test-container-subpath-configmap-vf74: <nil>
STEP: delete the pod
Jun 18 11:36:07.760: INFO: Waiting for pod pod-subpath-test-configmap-vf74 to disappear
Jun 18 11:36:07.774: INFO: Pod pod-subpath-test-configmap-vf74 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vf74
Jun 18 11:36:07.775: INFO: Deleting pod "pod-subpath-test-configmap-vf74" in namespace "e2e-tests-subpath-sv2dm"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:36:07.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-sv2dm" for this suite.
Jun 18 11:36:15.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:36:16.056: INFO: namespace: e2e-tests-subpath-sv2dm, resource: bindings, ignored listing per whitelist
Jun 18 11:36:16.396: INFO: namespace e2e-tests-subpath-sv2dm deletion completed in 8.584928496s

• [SLOW TEST:33.596 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:36:16.397: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-v5rcx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0618 11:36:26.974053      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 18 11:36:26.974: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:36:26.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-v5rcx" for this suite.
Jun 18 11:36:35.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:36:35.554: INFO: namespace: e2e-tests-gc-v5rcx, resource: bindings, ignored listing per whitelist
Jun 18 11:36:35.554: INFO: namespace e2e-tests-gc-v5rcx deletion completed in 8.565757905s

• [SLOW TEST:19.157 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:36:35.554: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-mg5bt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mg5bt
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mg5bt
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mg5bt
Jun 18 11:36:36.044: INFO: Found 0 stateful pods, waiting for 1
Jun 18 11:36:46.090: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jun 18 11:36:46.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-mg5bt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 11:36:46.541: INFO: stderr: ""
Jun 18 11:36:46.541: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 11:36:46.541: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 11:36:46.557: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 18 11:36:56.596: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 18 11:36:56.597: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 11:36:56.658: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:36:56.658: INFO: ss-0  10.72.74.149  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:36:56.658: INFO: ss-1                Pending         []
Jun 18 11:36:56.658: INFO: 
Jun 18 11:36:56.658: INFO: StatefulSet ss has not reached scale 3, at 2
Jun 18 11:36:57.674: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98416794s
Jun 18 11:36:58.690: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.968292944s
Jun 18 11:36:59.705: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.952603706s
Jun 18 11:37:00.721: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936666834s
Jun 18 11:37:01.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.921247951s
Jun 18 11:37:02.755: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.903874215s
Jun 18 11:37:03.774: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.886692689s
Jun 18 11:37:04.790: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.868200041s
Jun 18 11:37:05.807: INFO: Verifying statefulset ss doesn't scale past 3 for another 851.961558ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mg5bt
Jun 18 11:37:06.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-mg5bt ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 11:37:07.511: INFO: stderr: ""
Jun 18 11:37:07.511: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 11:37:07.511: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 11:37:07.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-mg5bt ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 11:37:09.021: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jun 18 11:37:09.021: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 11:37:09.021: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 11:37:09.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-mg5bt ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 11:37:09.494: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jun 18 11:37:09.494: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 11:37:09.494: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 11:37:09.510: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 11:37:09.510: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 11:37:09.510: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jun 18 11:37:09.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-mg5bt ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 11:37:09.928: INFO: stderr: ""
Jun 18 11:37:09.928: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 11:37:09.928: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 11:37:09.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-mg5bt ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 11:37:10.310: INFO: stderr: ""
Jun 18 11:37:10.310: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 11:37:10.310: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 11:37:10.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-mg5bt ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 11:37:10.719: INFO: stderr: ""
Jun 18 11:37:10.719: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 11:37:10.719: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 11:37:10.719: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 11:37:10.734: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jun 18 11:37:20.784: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 18 11:37:20.784: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 18 11:37:20.784: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 18 11:37:20.831: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:20.831: INFO: ss-0  10.72.74.149  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:37:20.831: INFO: ss-1  10.72.74.143  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:20.831: INFO: ss-2  10.72.74.144  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:20.831: INFO: 
Jun 18 11:37:20.831: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 18 11:37:21.885: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:21.885: INFO: ss-0  10.72.74.149  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:37:21.885: INFO: ss-1  10.72.74.143  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:21.885: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:21.885: INFO: 
Jun 18 11:37:21.885: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 18 11:37:22.901: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:22.901: INFO: ss-0  10.72.74.149  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:37:22.901: INFO: ss-1  10.72.74.143  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:22.901: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:22.901: INFO: 
Jun 18 11:37:22.901: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 18 11:37:23.916: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:23.916: INFO: ss-0  10.72.74.149  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:37:23.916: INFO: ss-1  10.72.74.143  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:23.916: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:23.916: INFO: 
Jun 18 11:37:23.916: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 18 11:37:24.933: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:24.933: INFO: ss-0  10.72.74.149  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:37:24.933: INFO: ss-1  10.72.74.143  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:24.933: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:24.933: INFO: 
Jun 18 11:37:24.933: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 18 11:37:25.949: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:25.949: INFO: ss-0  10.72.74.149  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:37:25.949: INFO: ss-1  10.72.74.143  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:25.949: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:25.949: INFO: 
Jun 18 11:37:25.949: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 18 11:37:26.964: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:26.964: INFO: ss-0  10.72.74.149  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:37:26.964: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:26.964: INFO: 
Jun 18 11:37:26.964: INFO: StatefulSet ss has not reached scale 0, at 2
Jun 18 11:37:27.979: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:27.979: INFO: ss-0  10.72.74.149  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:36 +0000 UTC  }]
Jun 18 11:37:27.979: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:27.979: INFO: 
Jun 18 11:37:27.979: INFO: StatefulSet ss has not reached scale 0, at 2
Jun 18 11:37:29.458: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:29.458: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:29.458: INFO: 
Jun 18 11:37:29.458: INFO: StatefulSet ss has not reached scale 0, at 1
Jun 18 11:37:30.499: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jun 18 11:37:30.499: INFO: ss-2  10.72.74.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:37:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:36:56 +0000 UTC  }]
Jun 18 11:37:30.499: INFO: 
Jun 18 11:37:30.499: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mg5bt
Jun 18 11:37:31.533: INFO: Scaling statefulset ss to 0
Jun 18 11:37:31.575: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 18 11:37:31.589: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mg5bt
Jun 18 11:37:31.603: INFO: Scaling statefulset ss to 0
Jun 18 11:37:31.647: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 11:37:31.661: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:37:31.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mg5bt" for this suite.
Jun 18 11:37:39.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:37:41.238: INFO: namespace: e2e-tests-statefulset-mg5bt, resource: bindings, ignored listing per whitelist
Jun 18 11:37:41.383: INFO: namespace e2e-tests-statefulset-mg5bt deletion completed in 9.643137461s

• [SLOW TEST:65.829 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:37:41.386: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-h9sfn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:37:48.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-h9sfn" for this suite.
Jun 18 11:37:56.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:37:56.298: INFO: namespace: e2e-tests-emptydir-wrapper-h9sfn, resource: bindings, ignored listing per whitelist
Jun 18 11:37:56.782: INFO: namespace e2e-tests-emptydir-wrapper-h9sfn deletion completed in 8.617274941s

• [SLOW TEST:15.397 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:37:56.784: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-w9hsb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-wxjh
STEP: Creating a pod to test atomic-volume-subpath
Jun 18 11:37:57.290: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wxjh" in namespace "e2e-tests-subpath-w9hsb" to be "success or failure"
Jun 18 11:37:57.307: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Pending", Reason="", readiness=false. Elapsed: 16.891579ms
Jun 18 11:37:59.322: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031406857s
Jun 18 11:38:01.337: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046894145s
Jun 18 11:38:03.373: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Pending", Reason="", readiness=false. Elapsed: 6.082617315s
Jun 18 11:38:05.391: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 8.100470668s
Jun 18 11:38:07.406: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 10.115247887s
Jun 18 11:38:09.421: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 12.130341346s
Jun 18 11:38:11.435: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 14.144695589s
Jun 18 11:38:13.471: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 16.180015785s
Jun 18 11:38:15.485: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 18.194863623s
Jun 18 11:38:17.853: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 20.562042445s
Jun 18 11:38:19.885: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 22.593965861s
Jun 18 11:38:21.904: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 24.613684127s
Jun 18 11:38:23.985: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Running", Reason="", readiness=false. Elapsed: 26.694293432s
Jun 18 11:38:26.004: INFO: Pod "pod-subpath-test-secret-wxjh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.712971408s
STEP: Saw pod success
Jun 18 11:38:26.004: INFO: Pod "pod-subpath-test-secret-wxjh" satisfied condition "success or failure"
Jun 18 11:38:26.018: INFO: Trying to get logs from node 10.72.74.143 pod pod-subpath-test-secret-wxjh container test-container-subpath-secret-wxjh: <nil>
STEP: delete the pod
Jun 18 11:38:26.097: INFO: Waiting for pod pod-subpath-test-secret-wxjh to disappear
Jun 18 11:38:26.119: INFO: Pod pod-subpath-test-secret-wxjh no longer exists
STEP: Deleting pod pod-subpath-test-secret-wxjh
Jun 18 11:38:26.119: INFO: Deleting pod "pod-subpath-test-secret-wxjh" in namespace "e2e-tests-subpath-w9hsb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:38:26.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-w9hsb" for this suite.
Jun 18 11:38:32.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:38:32.570: INFO: namespace: e2e-tests-subpath-w9hsb, resource: bindings, ignored listing per whitelist
Jun 18 11:38:32.681: INFO: namespace e2e-tests-subpath-w9hsb deletion completed in 6.526698349s

• [SLOW TEST:35.898 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:38:32.681: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-frc4s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 18 11:38:33.280: INFO: Number of nodes with available pods: 0
Jun 18 11:38:33.280: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:34.399: INFO: Number of nodes with available pods: 0
Jun 18 11:38:34.399: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:35.323: INFO: Number of nodes with available pods: 0
Jun 18 11:38:35.323: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:36.315: INFO: Number of nodes with available pods: 1
Jun 18 11:38:36.315: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:37.314: INFO: Number of nodes with available pods: 3
Jun 18 11:38:37.314: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jun 18 11:38:37.392: INFO: Number of nodes with available pods: 2
Jun 18 11:38:37.392: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:38.504: INFO: Number of nodes with available pods: 2
Jun 18 11:38:38.504: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:39.501: INFO: Number of nodes with available pods: 2
Jun 18 11:38:39.501: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:40.427: INFO: Number of nodes with available pods: 2
Jun 18 11:38:40.427: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:41.499: INFO: Number of nodes with available pods: 2
Jun 18 11:38:41.499: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:42.428: INFO: Number of nodes with available pods: 2
Jun 18 11:38:42.428: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:43.427: INFO: Number of nodes with available pods: 2
Jun 18 11:38:43.427: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:44.443: INFO: Number of nodes with available pods: 2
Jun 18 11:38:44.443: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:45.427: INFO: Number of nodes with available pods: 2
Jun 18 11:38:45.427: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:46.424: INFO: Number of nodes with available pods: 2
Jun 18 11:38:46.424: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:47.426: INFO: Number of nodes with available pods: 2
Jun 18 11:38:47.426: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:48.499: INFO: Number of nodes with available pods: 2
Jun 18 11:38:48.499: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:49.500: INFO: Number of nodes with available pods: 2
Jun 18 11:38:49.500: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:50.425: INFO: Number of nodes with available pods: 2
Jun 18 11:38:50.426: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:51.499: INFO: Number of nodes with available pods: 2
Jun 18 11:38:51.499: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:52.425: INFO: Number of nodes with available pods: 2
Jun 18 11:38:52.425: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:53.427: INFO: Number of nodes with available pods: 2
Jun 18 11:38:53.427: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:54.484: INFO: Number of nodes with available pods: 2
Jun 18 11:38:54.484: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:56.210: INFO: Number of nodes with available pods: 2
Jun 18 11:38:56.210: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:56.425: INFO: Number of nodes with available pods: 2
Jun 18 11:38:56.425: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:57.671: INFO: Number of nodes with available pods: 2
Jun 18 11:38:57.672: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:58.499: INFO: Number of nodes with available pods: 2
Jun 18 11:38:58.499: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:38:59.426: INFO: Number of nodes with available pods: 2
Jun 18 11:38:59.426: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:00.500: INFO: Number of nodes with available pods: 2
Jun 18 11:39:00.500: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:01.426: INFO: Number of nodes with available pods: 2
Jun 18 11:39:01.426: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:02.426: INFO: Number of nodes with available pods: 2
Jun 18 11:39:02.426: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:03.426: INFO: Number of nodes with available pods: 2
Jun 18 11:39:03.426: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:04.426: INFO: Number of nodes with available pods: 2
Jun 18 11:39:04.426: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:05.445: INFO: Number of nodes with available pods: 2
Jun 18 11:39:05.445: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:06.499: INFO: Number of nodes with available pods: 2
Jun 18 11:39:06.500: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:07.427: INFO: Number of nodes with available pods: 2
Jun 18 11:39:07.427: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:08.427: INFO: Number of nodes with available pods: 2
Jun 18 11:39:08.427: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:09.484: INFO: Number of nodes with available pods: 2
Jun 18 11:39:09.484: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:10.427: INFO: Number of nodes with available pods: 2
Jun 18 11:39:10.427: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:11.426: INFO: Number of nodes with available pods: 2
Jun 18 11:39:11.426: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:12.427: INFO: Number of nodes with available pods: 2
Jun 18 11:39:12.427: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:39:13.426: INFO: Number of nodes with available pods: 3
Jun 18 11:39:13.426: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-frc4s, will wait for the garbage collector to delete the pods
Jun 18 11:39:13.529: INFO: Deleting DaemonSet.extensions daemon-set took: 28.035819ms
Jun 18 11:39:13.729: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.410306ms
Jun 18 11:39:56.063: INFO: Number of nodes with available pods: 0
Jun 18 11:39:56.063: INFO: Number of running nodes: 0, number of available pods: 0
Jun 18 11:39:56.081: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-frc4s/daemonsets","resourceVersion":"89552"},"items":null}

Jun 18 11:39:56.095: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-frc4s/pods","resourceVersion":"89552"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:39:56.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-frc4s" for this suite.
Jun 18 11:40:04.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:40:04.635: INFO: namespace: e2e-tests-daemonsets-frc4s, resource: bindings, ignored listing per whitelist
Jun 18 11:40:04.747: INFO: namespace e2e-tests-daemonsets-frc4s deletion completed in 8.576766657s

• [SLOW TEST:92.066 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:40:04.748: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-9cb5v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-9cb5v
Jun 18 11:40:11.302: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-9cb5v
STEP: checking the pod's current state and verifying that restartCount is present
Jun 18 11:40:11.319: INFO: Initial restart count of pod liveness-http is 0
Jun 18 11:40:27.501: INFO: Restart count of pod e2e-tests-container-probe-9cb5v/liveness-http is now 1 (16.182143884s elapsed)
Jun 18 11:40:46.535: INFO: Restart count of pod e2e-tests-container-probe-9cb5v/liveness-http is now 2 (35.215712929s elapsed)
Jun 18 11:41:07.242: INFO: Restart count of pod e2e-tests-container-probe-9cb5v/liveness-http is now 3 (55.92263753s elapsed)
Jun 18 11:41:27.427: INFO: Restart count of pod e2e-tests-container-probe-9cb5v/liveness-http is now 4 (1m16.10776734s elapsed)
Jun 18 11:42:32.185: INFO: Restart count of pod e2e-tests-container-probe-9cb5v/liveness-http is now 5 (2m20.86648334s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:42:32.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9cb5v" for this suite.
Jun 18 11:42:38.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:42:38.487: INFO: namespace: e2e-tests-container-probe-9cb5v, resource: bindings, ignored listing per whitelist
Jun 18 11:42:38.844: INFO: namespace e2e-tests-container-probe-9cb5v deletion completed in 6.585980418s

• [SLOW TEST:154.096 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:42:38.844: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-bbl59
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-2ccc87bb-91be-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 11:42:39.333: INFO: Waiting up to 5m0s for pod "pod-configmaps-2cce9b75-91be-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-bbl59" to be "success or failure"
Jun 18 11:42:39.384: INFO: Pod "pod-configmaps-2cce9b75-91be-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 51.1557ms
Jun 18 11:42:41.416: INFO: Pod "pod-configmaps-2cce9b75-91be-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.08279105s
Jun 18 11:42:43.431: INFO: Pod "pod-configmaps-2cce9b75-91be-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.098095355s
STEP: Saw pod success
Jun 18 11:42:43.431: INFO: Pod "pod-configmaps-2cce9b75-91be-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:42:43.445: INFO: Trying to get logs from node 10.72.74.149 pod pod-configmaps-2cce9b75-91be-11e9-bce2-ae54e022189f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 11:42:43.526: INFO: Waiting for pod pod-configmaps-2cce9b75-91be-11e9-bce2-ae54e022189f to disappear
Jun 18 11:42:43.542: INFO: Pod pod-configmaps-2cce9b75-91be-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:42:43.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bbl59" for this suite.
Jun 18 11:42:49.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:42:49.872: INFO: namespace: e2e-tests-configmap-bbl59, resource: bindings, ignored listing per whitelist
Jun 18 11:42:50.136: INFO: namespace e2e-tests-configmap-bbl59 deletion completed in 6.575749634s

• [SLOW TEST:11.292 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:42:50.137: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-49ldv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 11:42:54.799: INFO: Waiting up to 5m0s for pod "client-envvars-3606d9a3-91be-11e9-bce2-ae54e022189f" in namespace "e2e-tests-pods-49ldv" to be "success or failure"
Jun 18 11:42:54.814: INFO: Pod "client-envvars-3606d9a3-91be-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.003756ms
Jun 18 11:42:56.829: INFO: Pod "client-envvars-3606d9a3-91be-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029770766s
Jun 18 11:42:58.843: INFO: Pod "client-envvars-3606d9a3-91be-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044526834s
STEP: Saw pod success
Jun 18 11:42:58.844: INFO: Pod "client-envvars-3606d9a3-91be-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:42:58.858: INFO: Trying to get logs from node 10.72.74.144 pod client-envvars-3606d9a3-91be-11e9-bce2-ae54e022189f container env3cont: <nil>
STEP: delete the pod
Jun 18 11:42:58.937: INFO: Waiting for pod client-envvars-3606d9a3-91be-11e9-bce2-ae54e022189f to disappear
Jun 18 11:42:58.954: INFO: Pod client-envvars-3606d9a3-91be-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:42:58.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-49ldv" for this suite.
Jun 18 11:43:41.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:43:41.259: INFO: namespace: e2e-tests-pods-49ldv, resource: bindings, ignored listing per whitelist
Jun 18 11:43:41.540: INFO: namespace e2e-tests-pods-49ldv deletion completed in 42.55032617s

• [SLOW TEST:51.403 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:43:41.540: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qdpzb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 11:43:42.340: INFO: Waiting up to 5m0s for pod "downwardapi-volume-525cdba9-91be-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-qdpzb" to be "success or failure"
Jun 18 11:43:42.358: INFO: Pod "downwardapi-volume-525cdba9-91be-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.119208ms
Jun 18 11:43:44.373: INFO: Pod "downwardapi-volume-525cdba9-91be-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033622535s
STEP: Saw pod success
Jun 18 11:43:44.373: INFO: Pod "downwardapi-volume-525cdba9-91be-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:43:44.387: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-525cdba9-91be-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 11:43:44.557: INFO: Waiting for pod downwardapi-volume-525cdba9-91be-11e9-bce2-ae54e022189f to disappear
Jun 18 11:43:44.572: INFO: Pod downwardapi-volume-525cdba9-91be-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:43:44.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qdpzb" for this suite.
Jun 18 11:43:50.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:43:51.055: INFO: namespace: e2e-tests-downward-api-qdpzb, resource: bindings, ignored listing per whitelist
Jun 18 11:43:51.246: INFO: namespace e2e-tests-downward-api-qdpzb deletion completed in 6.654917712s

• [SLOW TEST:9.706 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:43:51.246: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-sd8qh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 11:43:51.754: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jun 18 11:43:51.797: INFO: Number of nodes with available pods: 0
Jun 18 11:43:51.797: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:43:52.830: INFO: Number of nodes with available pods: 0
Jun 18 11:43:52.830: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 11:43:53.830: INFO: Number of nodes with available pods: 2
Jun 18 11:43:53.830: INFO: Node 10.72.74.149 is running more than one daemon pod
Jun 18 11:43:54.830: INFO: Number of nodes with available pods: 3
Jun 18 11:43:54.830: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jun 18 11:43:54.943: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:54.943: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:54.943: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:55.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:55.984: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:55.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:56.974: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:56.974: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:56.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:58.034: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:58.034: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:58.034: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:58.974: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:58.974: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:58.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:59.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:59.985: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:43:59.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:00.993: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:00.993: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:00.993: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:02.285: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:02.285: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:02.285: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:02.974: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:02.974: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:02.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:03.985: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:03.985: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:03.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:04.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:04.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:04.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:05.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:05.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:05.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:06.975: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:06.975: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:06.975: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:07.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:07.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:07.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:08.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:08.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:08.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:09.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:09.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:09.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:10.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:10.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:10.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:11.989: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:11.989: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:11.989: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:12.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:12.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:12.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:13.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:13.973: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:13.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:14.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:14.984: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:14.984: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:15.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:15.985: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:15.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:16.975: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:16.975: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:16.975: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:17.985: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:17.985: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:17.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:18.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:18.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:18.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:19.985: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:19.985: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:19.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:20.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:20.973: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:20.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:21.979: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:21.979: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:21.979: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:22.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:22.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:22.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:23.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:23.973: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:23.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:24.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:24.973: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:24.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:25.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:25.973: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:25.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:26.971: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:26.971: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:26.971: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:26.971: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:27.974: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:27.974: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:27.974: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:27.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:28.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:28.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:28.972: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:28.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:29.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:29.985: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:29.985: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:29.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:30.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:30.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:30.972: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:30.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:31.985: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:31.985: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:31.985: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:31.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:32.993: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:32.993: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:32.994: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:32.994: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:33.979: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:33.979: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:33.979: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:33.979: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:34.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:34.972: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:34.972: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:34.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:35.985: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:35.985: INFO: Wrong image for pod: daemon-set-dv9hc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:35.985: INFO: Pod daemon-set-dv9hc is not available
Jun 18 11:44:35.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:36.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:36.973: INFO: Pod daemon-set-nq2fm is not available
Jun 18 11:44:36.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:37.975: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:37.976: INFO: Pod daemon-set-nq2fm is not available
Jun 18 11:44:37.976: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:38.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:38.984: INFO: Pod daemon-set-nq2fm is not available
Jun 18 11:44:38.984: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:39.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:39.985: INFO: Pod daemon-set-nq2fm is not available
Jun 18 11:44:39.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:40.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:40.984: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:41.971: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:41.971: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:42.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:42.984: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:43.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:43.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:44.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:44.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:45.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:45.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:46.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:46.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:47.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:47.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:48.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:48.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:49.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:49.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:50.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:50.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:51.974: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:51.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:52.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:52.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:53.997: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:53.997: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:54.971: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:54.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:55.977: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:55.977: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:56.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:56.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:57.976: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:57.976: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:58.985: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:58.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:59.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:44:59.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:00.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:00.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:01.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:01.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:02.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:02.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:03.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:03.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:04.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:04.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:06.881: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:06.881: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:06.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:06.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:09.759: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:09.759: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:09.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:09.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:10.984: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:10.984: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:11.977: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:11.977: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:11.977: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:12.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:12.972: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:12.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:14.154: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:14.154: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:14.154: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:14.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:14.973: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:14.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:15.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:15.972: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:15.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:16.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:16.973: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:16.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:17.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:17.972: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:17.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:18.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:18.973: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:18.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:19.973: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:19.973: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:19.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:20.972: INFO: Wrong image for pod: daemon-set-c9vbb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:20.972: INFO: Pod daemon-set-c9vbb is not available
Jun 18 11:45:20.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:21.975: INFO: Pod daemon-set-t752l is not available
Jun 18 11:45:21.975: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:22.972: INFO: Pod daemon-set-t752l is not available
Jun 18 11:45:22.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:23.973: INFO: Pod daemon-set-t752l is not available
Jun 18 11:45:23.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:25.002: INFO: Pod daemon-set-t752l is not available
Jun 18 11:45:25.002: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:25.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:26.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:27.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:28.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:29.976: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:30.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:31.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:32.999: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:33.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:34.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:35.989: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:36.976: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:37.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:38.985: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:39.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:40.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:41.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:42.984: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:43.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:44.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:46.183: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:46.977: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:47.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:48.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:49.975: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:50.971: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:51.974: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:52.971: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:53.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:54.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:55.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:56.990: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:57.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:57.972: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:45:58.984: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:58.984: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:45:59.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:45:59.972: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:00.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:46:00.973: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:01.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:46:01.973: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:02.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:46:02.973: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:03.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:46:03.973: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:04.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:46:04.973: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:05.973: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:46:05.973: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:06.972: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:46:06.972: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:07.992: INFO: Wrong image for pod: daemon-set-zpfp6. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun 18 11:46:07.992: INFO: Pod daemon-set-zpfp6 is not available
Jun 18 11:46:08.984: INFO: Pod daemon-set-969gc is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jun 18 11:46:09.041: INFO: Number of nodes with available pods: 2
Jun 18 11:46:09.041: INFO: Node 10.72.74.149 is running more than one daemon pod
Jun 18 11:46:10.078: INFO: Number of nodes with available pods: 2
Jun 18 11:46:10.078: INFO: Node 10.72.74.149 is running more than one daemon pod
Jun 18 11:46:11.078: INFO: Number of nodes with available pods: 2
Jun 18 11:46:11.078: INFO: Node 10.72.74.149 is running more than one daemon pod
Jun 18 11:46:12.081: INFO: Number of nodes with available pods: 2
Jun 18 11:46:12.082: INFO: Node 10.72.74.149 is running more than one daemon pod
Jun 18 11:46:13.077: INFO: Number of nodes with available pods: 3
Jun 18 11:46:13.077: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-sd8qh, will wait for the garbage collector to delete the pods
Jun 18 11:46:13.237: INFO: Deleting DaemonSet.extensions daemon-set took: 27.514298ms
Jun 18 11:46:13.337: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.212922ms
Jun 18 11:46:26.077: INFO: Number of nodes with available pods: 0
Jun 18 11:46:26.077: INFO: Number of running nodes: 0, number of available pods: 0
Jun 18 11:46:26.090: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-sd8qh/daemonsets","resourceVersion":"90606"},"items":null}

Jun 18 11:46:26.104: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-sd8qh/pods","resourceVersion":"90606"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:46:26.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-sd8qh" for this suite.
Jun 18 11:46:34.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:46:34.532: INFO: namespace: e2e-tests-daemonsets-sd8qh, resource: bindings, ignored listing per whitelist
Jun 18 11:46:34.709: INFO: namespace e2e-tests-daemonsets-sd8qh deletion completed in 8.528311597s

• [SLOW TEST:163.463 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:46:34.712: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f5gds
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b9623103-91be-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 11:46:35.196: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b96447a1-91be-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-f5gds" to be "success or failure"
Jun 18 11:46:35.234: INFO: Pod "pod-projected-configmaps-b96447a1-91be-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 37.796569ms
Jun 18 11:46:37.284: INFO: Pod "pod-projected-configmaps-b96447a1-91be-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.088452602s
Jun 18 11:46:39.299: INFO: Pod "pod-projected-configmaps-b96447a1-91be-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.103025099s
STEP: Saw pod success
Jun 18 11:46:39.299: INFO: Pod "pod-projected-configmaps-b96447a1-91be-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:46:39.315: INFO: Trying to get logs from node 10.72.74.143 pod pod-projected-configmaps-b96447a1-91be-11e9-bce2-ae54e022189f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 11:46:39.424: INFO: Waiting for pod pod-projected-configmaps-b96447a1-91be-11e9-bce2-ae54e022189f to disappear
Jun 18 11:46:39.438: INFO: Pod pod-projected-configmaps-b96447a1-91be-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:46:39.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f5gds" for this suite.
Jun 18 11:46:45.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:46:46.157: INFO: namespace: e2e-tests-projected-f5gds, resource: bindings, ignored listing per whitelist
Jun 18 11:46:46.363: INFO: namespace e2e-tests-projected-f5gds deletion completed in 6.900672091s

• [SLOW TEST:11.652 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:46:46.363: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-cxzg9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-cxzg9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 18 11:46:46.891: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 18 11:47:13.214: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.114.10:8080/dial?request=hostName&protocol=udp&host=172.30.39.16&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-cxzg9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 11:47:13.214: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 11:47:13.501: INFO: Waiting for endpoints: map[]
Jun 18 11:47:13.517: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.114.10:8080/dial?request=hostName&protocol=udp&host=172.30.58.150&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-cxzg9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 11:47:13.517: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 11:47:13.734: INFO: Waiting for endpoints: map[]
Jun 18 11:47:13.748: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.114.10:8080/dial?request=hostName&protocol=udp&host=172.30.114.9&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-cxzg9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 11:47:13.748: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 11:47:13.984: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:47:13.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-cxzg9" for this suite.
Jun 18 11:47:38.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:47:38.372: INFO: namespace: e2e-tests-pod-network-test-cxzg9, resource: bindings, ignored listing per whitelist
Jun 18 11:47:38.549: INFO: namespace e2e-tests-pod-network-test-cxzg9 deletion completed in 24.542866067s

• [SLOW TEST:52.186 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:47:38.549: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pw2p9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-df70f185-91be-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 11:47:39.044: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-df7325e7-91be-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-pw2p9" to be "success or failure"
Jun 18 11:47:39.058: INFO: Pod "pod-projected-secrets-df7325e7-91be-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.543801ms
Jun 18 11:47:41.074: INFO: Pod "pod-projected-secrets-df7325e7-91be-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030086259s
STEP: Saw pod success
Jun 18 11:47:41.074: INFO: Pod "pod-projected-secrets-df7325e7-91be-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:47:41.089: INFO: Trying to get logs from node 10.72.74.143 pod pod-projected-secrets-df7325e7-91be-11e9-bce2-ae54e022189f container secret-volume-test: <nil>
STEP: delete the pod
Jun 18 11:47:41.160: INFO: Waiting for pod pod-projected-secrets-df7325e7-91be-11e9-bce2-ae54e022189f to disappear
Jun 18 11:47:41.175: INFO: Pod pod-projected-secrets-df7325e7-91be-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:47:41.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pw2p9" for this suite.
Jun 18 11:47:49.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:47:49.399: INFO: namespace: e2e-tests-projected-pw2p9, resource: bindings, ignored listing per whitelist
Jun 18 11:47:49.757: INFO: namespace e2e-tests-projected-pw2p9 deletion completed in 8.557412971s

• [SLOW TEST:11.208 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:47:49.757: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-cddjl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-942rq
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-856jq
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:47:57.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-cddjl" for this suite.
Jun 18 11:48:04.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:48:04.677: INFO: namespace: e2e-tests-namespaces-cddjl, resource: bindings, ignored listing per whitelist
Jun 18 11:48:04.715: INFO: namespace e2e-tests-namespaces-cddjl deletion completed in 6.772836112s
STEP: Destroying namespace "e2e-tests-nsdeletetest-942rq" for this suite.
Jun 18 11:48:04.731: INFO: Namespace e2e-tests-nsdeletetest-942rq was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-856jq" for this suite.
Jun 18 11:48:10.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:48:11.007: INFO: namespace: e2e-tests-nsdeletetest-856jq, resource: bindings, ignored listing per whitelist
Jun 18 11:48:11.597: INFO: namespace e2e-tests-nsdeletetest-856jq deletion completed in 6.866103474s

• [SLOW TEST:21.840 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:48:11.597: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-fnr4d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 11:48:12.118: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jun 18 11:48:17.153: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 18 11:48:17.153: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 18 11:48:17.232: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-fnr4d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fnr4d/deployments/test-cleanup-deployment,UID:f63253cd-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91136,Generation:1,CreationTimestamp:2019-06-18 11:48:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jun 18 11:48:17.246: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jun 18 11:48:17.246: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jun 18 11:48:17.246: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-fnr4d,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fnr4d/replicasets/test-cleanup-controller,UID:f329e69f-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91137,Generation:1,CreationTimestamp:2019-06-18 11:48:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment f63253cd-91be-11e9-bf44-fa6f350b29f0 0xc0017351f7 0xc0017351f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun 18 11:48:17.263: INFO: Pod "test-cleanup-controller-pslsj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-pslsj,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-fnr4d,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnr4d/pods/test-cleanup-controller-pslsj,UID:f32fda23-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91132,Generation:0,CreationTimestamp:2019-06-18 11:48:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller f329e69f-91be-11e9-bf44-fa6f350b29f0 0xc0021a4587 0xc0021a4588}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-kmqbr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kmqbr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kmqbr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021a4600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021a4620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:48:12 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:48:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:48:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 11:48:12 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:172.30.114.11,StartTime:2019-06-18 11:48:12 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 11:48:13 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://6fda0b030ff10f427b12682f8bf2ca5a738d8c9e4a6d8482ca92c59f4486b470}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:48:17.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fnr4d" for this suite.
Jun 18 11:48:23.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:48:23.561: INFO: namespace: e2e-tests-deployment-fnr4d, resource: bindings, ignored listing per whitelist
Jun 18 11:48:24.055: INFO: namespace e2e-tests-deployment-fnr4d deletion completed in 6.769347211s

• [SLOW TEST:12.458 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:48:24.055: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-qbwmb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jun 18 11:48:24.545: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-a,UID:fa94e668-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91209,Generation:0,CreationTimestamp:2019-06-18 11:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 18 11:48:24.545: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-a,UID:fa94e668-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91209,Generation:0,CreationTimestamp:2019-06-18 11:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jun 18 11:48:34.590: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-a,UID:fa94e668-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91226,Generation:0,CreationTimestamp:2019-06-18 11:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 18 11:48:34.591: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-a,UID:fa94e668-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91226,Generation:0,CreationTimestamp:2019-06-18 11:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jun 18 11:48:44.700: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-a,UID:fa94e668-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91244,Generation:0,CreationTimestamp:2019-06-18 11:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 18 11:48:44.700: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-a,UID:fa94e668-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91244,Generation:0,CreationTimestamp:2019-06-18 11:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jun 18 11:48:54.743: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-a,UID:fa94e668-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91261,Generation:0,CreationTimestamp:2019-06-18 11:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 18 11:48:54.743: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-a,UID:fa94e668-91be-11e9-bf44-fa6f350b29f0,ResourceVersion:91261,Generation:0,CreationTimestamp:2019-06-18 11:48:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jun 18 11:49:05.117: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-b,UID:12c23309-91bf-11e9-bf44-fa6f350b29f0,ResourceVersion:91279,Generation:0,CreationTimestamp:2019-06-18 11:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 18 11:49:05.117: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-b,UID:12c23309-91bf-11e9-bf44-fa6f350b29f0,ResourceVersion:91279,Generation:0,CreationTimestamp:2019-06-18 11:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jun 18 11:49:15.351: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-b,UID:12c23309-91bf-11e9-bf44-fa6f350b29f0,ResourceVersion:91297,Generation:0,CreationTimestamp:2019-06-18 11:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 18 11:49:15.351: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qbwmb,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbwmb/configmaps/e2e-watch-test-configmap-b,UID:12c23309-91bf-11e9-bf44-fa6f350b29f0,ResourceVersion:91297,Generation:0,CreationTimestamp:2019-06-18 11:49:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:49:25.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qbwmb" for this suite.
Jun 18 11:49:31.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:49:32.722: INFO: namespace: e2e-tests-watch-qbwmb, resource: bindings, ignored listing per whitelist
Jun 18 11:49:33.099: INFO: namespace e2e-tests-watch-qbwmb deletion completed in 7.711628267s

• [SLOW TEST:69.044 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:49:33.099: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mdjpd
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-23bca456-91bf-11e9-bce2-ae54e022189f
STEP: Creating configMap with name cm-test-opt-upd-23bca4aa-91bf-11e9-bce2-ae54e022189f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-23bca456-91bf-11e9-bce2-ae54e022189f
STEP: Updating configmap cm-test-opt-upd-23bca4aa-91bf-11e9-bce2-ae54e022189f
STEP: Creating configMap with name cm-test-opt-create-23bca4d7-91bf-11e9-bce2-ae54e022189f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:51:02.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mdjpd" for this suite.
Jun 18 11:51:26.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:51:26.666: INFO: namespace: e2e-tests-projected-mdjpd, resource: bindings, ignored listing per whitelist
Jun 18 11:51:26.838: INFO: namespace e2e-tests-projected-mdjpd deletion completed in 24.561696136s

• [SLOW TEST:113.739 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:51:26.839: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-j4br4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 18 11:51:27.516: INFO: Waiting up to 5m0s for pod "pod-67a1763c-91bf-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-j4br4" to be "success or failure"
Jun 18 11:51:27.531: INFO: Pod "pod-67a1763c-91bf-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.883419ms
Jun 18 11:51:29.547: INFO: Pod "pod-67a1763c-91bf-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0308532s
Jun 18 11:51:31.562: INFO: Pod "pod-67a1763c-91bf-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045722555s
Jun 18 11:51:33.595: INFO: Pod "pod-67a1763c-91bf-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.079131073s
STEP: Saw pod success
Jun 18 11:51:33.595: INFO: Pod "pod-67a1763c-91bf-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:51:33.610: INFO: Trying to get logs from node 10.72.74.144 pod pod-67a1763c-91bf-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 11:51:33.688: INFO: Waiting for pod pod-67a1763c-91bf-11e9-bce2-ae54e022189f to disappear
Jun 18 11:51:33.701: INFO: Pod pod-67a1763c-91bf-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:51:33.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j4br4" for this suite.
Jun 18 11:51:39.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:51:40.112: INFO: namespace: e2e-tests-emptydir-j4br4, resource: bindings, ignored listing per whitelist
Jun 18 11:51:40.318: INFO: namespace e2e-tests-emptydir-j4br4 deletion completed in 6.595004758s

• [SLOW TEST:13.480 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:51:40.320: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mtbs9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 11:51:40.795: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f8b7834-91bf-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-mtbs9" to be "success or failure"
Jun 18 11:51:40.810: INFO: Pod "downwardapi-volume-6f8b7834-91bf-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.505605ms
Jun 18 11:51:42.825: INFO: Pod "downwardapi-volume-6f8b7834-91bf-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.029532817s
Jun 18 11:51:44.857: INFO: Pod "downwardapi-volume-6f8b7834-91bf-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061563737s
STEP: Saw pod success
Jun 18 11:51:44.857: INFO: Pod "downwardapi-volume-6f8b7834-91bf-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:51:44.871: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-6f8b7834-91bf-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 11:51:44.951: INFO: Waiting for pod downwardapi-volume-6f8b7834-91bf-11e9-bce2-ae54e022189f to disappear
Jun 18 11:51:44.965: INFO: Pod downwardapi-volume-6f8b7834-91bf-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:51:44.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mtbs9" for this suite.
Jun 18 11:51:53.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:51:53.295: INFO: namespace: e2e-tests-projected-mtbs9, resource: bindings, ignored listing per whitelist
Jun 18 11:51:53.833: INFO: namespace e2e-tests-projected-mtbs9 deletion completed in 8.85033182s

• [SLOW TEST:13.513 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:51:53.834: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-z65vx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jun 18 11:51:54.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-z65vx'
Jun 18 11:51:54.860: INFO: stderr: ""
Jun 18 11:51:54.861: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 18 11:51:55.892: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 11:51:55.892: INFO: Found 0 / 1
Jun 18 11:51:56.875: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 11:51:56.875: INFO: Found 1 / 1
Jun 18 11:51:56.875: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jun 18 11:51:56.890: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 11:51:56.890: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 18 11:51:56.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 patch pod redis-master-zd72d --namespace=e2e-tests-kubectl-z65vx -p {"metadata":{"annotations":{"x":"y"}}}'
Jun 18 11:51:57.037: INFO: stderr: ""
Jun 18 11:51:57.037: INFO: stdout: "pod/redis-master-zd72d patched\n"
STEP: checking annotations
Jun 18 11:51:57.052: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 11:51:57.052: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:51:57.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z65vx" for this suite.
Jun 18 11:52:21.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:52:21.527: INFO: namespace: e2e-tests-kubectl-z65vx, resource: bindings, ignored listing per whitelist
Jun 18 11:52:21.704: INFO: namespace e2e-tests-kubectl-z65vx deletion completed in 24.633980974s

• [SLOW TEST:27.870 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:52:21.706: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-x68nm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-x68nm
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-x68nm to expose endpoints map[]
Jun 18 11:52:22.198: INFO: Get endpoints failed (11.828849ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jun 18 11:52:23.210: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-x68nm exposes endpoints map[] (1.024407469s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-x68nm
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-x68nm to expose endpoints map[pod1:[80]]
Jun 18 11:52:26.384: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-x68nm exposes endpoints map[pod1:[80]] (3.140390415s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-x68nm
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-x68nm to expose endpoints map[pod1:[80] pod2:[80]]
Jun 18 11:52:29.605: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-x68nm exposes endpoints map[pod1:[80] pod2:[80]] (3.200879832s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-x68nm
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-x68nm to expose endpoints map[pod2:[80]]
Jun 18 11:52:29.699: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-x68nm exposes endpoints map[pod2:[80]] (69.673439ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-x68nm
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-x68nm to expose endpoints map[]
Jun 18 11:52:29.734: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-x68nm exposes endpoints map[] (12.499935ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:52:29.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-x68nm" for this suite.
Jun 18 11:52:37.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:52:38.007: INFO: namespace: e2e-tests-services-x68nm, resource: bindings, ignored listing per whitelist
Jun 18 11:52:39.542: INFO: namespace e2e-tests-services-x68nm deletion completed in 9.724294154s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:17.837 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:52:39.546: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jcczq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 11:52:40.118: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92e74509-91bf-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-jcczq" to be "success or failure"
Jun 18 11:52:40.135: INFO: Pod "downwardapi-volume-92e74509-91bf-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.545017ms
Jun 18 11:52:42.150: INFO: Pod "downwardapi-volume-92e74509-91bf-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.031397567s
Jun 18 11:52:44.165: INFO: Pod "downwardapi-volume-92e74509-91bf-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046114687s
STEP: Saw pod success
Jun 18 11:52:44.165: INFO: Pod "downwardapi-volume-92e74509-91bf-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:52:44.179: INFO: Trying to get logs from node 10.72.74.143 pod downwardapi-volume-92e74509-91bf-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 11:52:44.261: INFO: Waiting for pod downwardapi-volume-92e74509-91bf-11e9-bce2-ae54e022189f to disappear
Jun 18 11:52:44.278: INFO: Pod downwardapi-volume-92e74509-91bf-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:52:44.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jcczq" for this suite.
Jun 18 11:52:50.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:52:50.465: INFO: namespace: e2e-tests-downward-api-jcczq, resource: bindings, ignored listing per whitelist
Jun 18 11:52:51.009: INFO: namespace e2e-tests-downward-api-jcczq deletion completed in 6.711858518s

• [SLOW TEST:11.464 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:52:51.010: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wxs7n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jun 18 11:52:51.483: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-953583206 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:52:51.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wxs7n" for this suite.
Jun 18 11:52:57.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:52:58.132: INFO: namespace: e2e-tests-kubectl-wxs7n, resource: bindings, ignored listing per whitelist
Jun 18 11:52:58.147: INFO: namespace e2e-tests-kubectl-wxs7n deletion completed in 6.524445614s

• [SLOW TEST:7.137 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:52:58.147: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nm5fq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun 18 11:53:01.238: INFO: Successfully updated pod "annotationupdate9deb3049-91bf-11e9-bce2-ae54e022189f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:53:05.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nm5fq" for this suite.
Jun 18 11:53:29.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:53:30.031: INFO: namespace: e2e-tests-downward-api-nm5fq, resource: bindings, ignored listing per whitelist
Jun 18 11:53:30.541: INFO: namespace e2e-tests-downward-api-nm5fq deletion completed in 25.176288634s

• [SLOW TEST:32.395 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:53:30.545: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-lhwk9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-b14d1127-91bf-11e9-bce2-ae54e022189f
Jun 18 11:53:31.119: INFO: Pod name my-hostname-basic-b14d1127-91bf-11e9-bce2-ae54e022189f: Found 0 pods out of 1
Jun 18 11:53:36.159: INFO: Pod name my-hostname-basic-b14d1127-91bf-11e9-bce2-ae54e022189f: Found 1 pods out of 1
Jun 18 11:53:36.159: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b14d1127-91bf-11e9-bce2-ae54e022189f" are running
Jun 18 11:53:36.173: INFO: Pod "my-hostname-basic-b14d1127-91bf-11e9-bce2-ae54e022189f-lnnf9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-18 11:53:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-18 11:53:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-18 11:53:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-18 11:53:31 +0000 UTC Reason: Message:}])
Jun 18 11:53:36.173: INFO: Trying to dial the pod
Jun 18 11:53:41.816: INFO: Controller my-hostname-basic-b14d1127-91bf-11e9-bce2-ae54e022189f: Got expected result from replica 1 [my-hostname-basic-b14d1127-91bf-11e9-bce2-ae54e022189f-lnnf9]: "my-hostname-basic-b14d1127-91bf-11e9-bce2-ae54e022189f-lnnf9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:53:41.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-lhwk9" for this suite.
Jun 18 11:53:47.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:53:47.935: INFO: namespace: e2e-tests-replication-controller-lhwk9, resource: bindings, ignored listing per whitelist
Jun 18 11:53:48.392: INFO: namespace e2e-tests-replication-controller-lhwk9 deletion completed in 6.556722122s

• [SLOW TEST:17.847 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:53:48.393: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dvrgz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 18 11:53:48.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-dvrgz'
Jun 18 11:53:49.014: INFO: stderr: ""
Jun 18 11:53:49.014: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jun 18 11:53:49.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-dvrgz'
Jun 18 11:53:56.172: INFO: stderr: ""
Jun 18 11:53:56.172: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:53:56.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dvrgz" for this suite.
Jun 18 11:54:02.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:54:02.360: INFO: namespace: e2e-tests-kubectl-dvrgz, resource: bindings, ignored listing per whitelist
Jun 18 11:54:02.760: INFO: namespace e2e-tests-kubectl-dvrgz deletion completed in 6.567816546s

• [SLOW TEST:14.367 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:54:02.761: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-56kfg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-56kfg
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-56kfg
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-56kfg
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-56kfg
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-56kfg
Jun 18 11:54:07.921: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-56kfg, name: ss-0, uid: c5b85413-91bf-11e9-bf44-fa6f350b29f0, status phase: Failed. Waiting for statefulset controller to delete.
Jun 18 11:54:07.986: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-56kfg, name: ss-0, uid: c5b85413-91bf-11e9-bf44-fa6f350b29f0, status phase: Failed. Waiting for statefulset controller to delete.
Jun 18 11:54:07.986: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-56kfg
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-56kfg
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-56kfg and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 18 11:54:18.182: INFO: Deleting all statefulset in ns e2e-tests-statefulset-56kfg
Jun 18 11:54:18.196: INFO: Scaling statefulset ss to 0
Jun 18 11:54:28.277: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 11:54:28.299: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:54:28.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-56kfg" for this suite.
Jun 18 11:54:35.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:54:35.540: INFO: namespace: e2e-tests-statefulset-56kfg, resource: bindings, ignored listing per whitelist
Jun 18 11:54:39.082: INFO: namespace e2e-tests-statefulset-56kfg deletion completed in 10.707235979s

• [SLOW TEST:36.321 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:54:39.082: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-5dtpj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-5dtpj/configmap-test-da2157e7-91bf-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 11:54:39.630: INFO: Waiting up to 5m0s for pod "pod-configmaps-da236834-91bf-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-5dtpj" to be "success or failure"
Jun 18 11:54:39.644: INFO: Pod "pod-configmaps-da236834-91bf-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.554748ms
Jun 18 11:54:41.659: INFO: Pod "pod-configmaps-da236834-91bf-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.029232063s
Jun 18 11:54:43.673: INFO: Pod "pod-configmaps-da236834-91bf-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043155517s
STEP: Saw pod success
Jun 18 11:54:43.673: INFO: Pod "pod-configmaps-da236834-91bf-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:54:43.687: INFO: Trying to get logs from node 10.72.74.144 pod pod-configmaps-da236834-91bf-11e9-bce2-ae54e022189f container env-test: <nil>
STEP: delete the pod
Jun 18 11:54:43.785: INFO: Waiting for pod pod-configmaps-da236834-91bf-11e9-bce2-ae54e022189f to disappear
Jun 18 11:54:43.801: INFO: Pod pod-configmaps-da236834-91bf-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:54:43.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5dtpj" for this suite.
Jun 18 11:54:51.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:54:52.012: INFO: namespace: e2e-tests-configmap-5dtpj, resource: bindings, ignored listing per whitelist
Jun 18 11:54:52.416: INFO: namespace e2e-tests-configmap-5dtpj deletion completed in 8.595551754s

• [SLOW TEST:13.334 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:54:52.416: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-4hbw6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 11:54:52.860: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:54:55.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4hbw6" for this suite.
Jun 18 11:55:43.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:55:43.696: INFO: namespace: e2e-tests-pods-4hbw6, resource: bindings, ignored listing per whitelist
Jun 18 11:55:43.752: INFO: namespace e2e-tests-pods-4hbw6 deletion completed in 48.558932495s

• [SLOW TEST:51.336 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:55:43.754: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wh69j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 18 11:55:44.238: INFO: Waiting up to 5m0s for pod "downward-api-00a5f64f-91c0-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-wh69j" to be "success or failure"
Jun 18 11:55:44.256: INFO: Pod "downward-api-00a5f64f-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.595203ms
Jun 18 11:55:46.270: INFO: Pod "downward-api-00a5f64f-91c0-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032024221s
STEP: Saw pod success
Jun 18 11:55:46.270: INFO: Pod "downward-api-00a5f64f-91c0-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:55:46.285: INFO: Trying to get logs from node 10.72.74.143 pod downward-api-00a5f64f-91c0-11e9-bce2-ae54e022189f container dapi-container: <nil>
STEP: delete the pod
Jun 18 11:55:46.366: INFO: Waiting for pod downward-api-00a5f64f-91c0-11e9-bce2-ae54e022189f to disappear
Jun 18 11:55:46.380: INFO: Pod downward-api-00a5f64f-91c0-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:55:46.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wh69j" for this suite.
Jun 18 11:55:52.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:55:52.700: INFO: namespace: e2e-tests-downward-api-wh69j, resource: bindings, ignored listing per whitelist
Jun 18 11:55:52.950: INFO: namespace e2e-tests-downward-api-wh69j deletion completed in 6.550708025s

• [SLOW TEST:9.196 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:55:52.950: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-267tt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-267tt
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-267tt
STEP: Deleting pre-stop pod
Jun 18 11:56:08.648: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:56:08.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-267tt" for this suite.
Jun 18 11:56:48.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:56:48.854: INFO: namespace: e2e-tests-prestop-267tt, resource: bindings, ignored listing per whitelist
Jun 18 11:56:49.279: INFO: namespace e2e-tests-prestop-267tt deletion completed in 40.569554785s

• [SLOW TEST:56.329 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:56:49.279: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-749wd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 11:56:49.774: INFO: Waiting up to 5m0s for pod "downwardapi-volume-27b56a70-91c0-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-749wd" to be "success or failure"
Jun 18 11:56:49.789: INFO: Pod "downwardapi-volume-27b56a70-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.796116ms
Jun 18 11:56:51.804: INFO: Pod "downwardapi-volume-27b56a70-91c0-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.030092186s
Jun 18 11:56:53.819: INFO: Pod "downwardapi-volume-27b56a70-91c0-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045234691s
STEP: Saw pod success
Jun 18 11:56:53.819: INFO: Pod "downwardapi-volume-27b56a70-91c0-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:56:53.834: INFO: Trying to get logs from node 10.72.74.143 pod downwardapi-volume-27b56a70-91c0-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 11:56:53.984: INFO: Waiting for pod downwardapi-volume-27b56a70-91c0-11e9-bce2-ae54e022189f to disappear
Jun 18 11:56:54.003: INFO: Pod downwardapi-volume-27b56a70-91c0-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:56:54.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-749wd" for this suite.
Jun 18 11:57:00.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:57:00.142: INFO: namespace: e2e-tests-downward-api-749wd, resource: bindings, ignored listing per whitelist
Jun 18 11:57:00.624: INFO: namespace e2e-tests-downward-api-749wd deletion completed in 6.599051909s

• [SLOW TEST:11.345 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:57:00.625: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qc5bj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 11:57:01.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 version'
Jun 18 11:57:01.196: INFO: stderr: ""
Jun 18 11:57:01.196: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.7+IKS\", GitCommit:\"675df39b011fd4f4f54aa131d903bab685cde6b8\", GitTreeState:\"clean\", BuildDate:\"2019-06-10T19:51:36Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:57:01.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qc5bj" for this suite.
Jun 18 11:57:07.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:57:08.233: INFO: namespace: e2e-tests-kubectl-qc5bj, resource: bindings, ignored listing per whitelist
Jun 18 11:57:08.545: INFO: namespace e2e-tests-kubectl-qc5bj deletion completed in 7.330865465s

• [SLOW TEST:7.920 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:57:08.545: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-spkd5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-332b67b1-91c0-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 11:57:09.013: INFO: Waiting up to 5m0s for pod "pod-configmaps-332d94b4-91c0-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-spkd5" to be "success or failure"
Jun 18 11:57:09.028: INFO: Pod "pod-configmaps-332d94b4-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.796586ms
Jun 18 11:57:11.043: INFO: Pod "pod-configmaps-332d94b4-91c0-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.030098892s
Jun 18 11:57:13.058: INFO: Pod "pod-configmaps-332d94b4-91c0-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044933817s
STEP: Saw pod success
Jun 18 11:57:13.058: INFO: Pod "pod-configmaps-332d94b4-91c0-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:57:13.073: INFO: Trying to get logs from node 10.72.74.144 pod pod-configmaps-332d94b4-91c0-11e9-bce2-ae54e022189f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 11:57:13.157: INFO: Waiting for pod pod-configmaps-332d94b4-91c0-11e9-bce2-ae54e022189f to disappear
Jun 18 11:57:13.171: INFO: Pod pod-configmaps-332d94b4-91c0-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:57:13.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-spkd5" for this suite.
Jun 18 11:57:19.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:57:19.310: INFO: namespace: e2e-tests-configmap-spkd5, resource: bindings, ignored listing per whitelist
Jun 18 11:57:20.513: INFO: namespace e2e-tests-configmap-spkd5 deletion completed in 7.322777767s

• [SLOW TEST:11.968 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:57:20.514: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-rn6tl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun 18 11:57:20.967: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:57:24.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rn6tl" for this suite.
Jun 18 11:57:30.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:57:30.698: INFO: namespace: e2e-tests-init-container-rn6tl, resource: bindings, ignored listing per whitelist
Jun 18 11:57:30.947: INFO: namespace e2e-tests-init-container-rn6tl deletion completed in 6.557255362s

• [SLOW TEST:10.434 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:57:30.949: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p6vrf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 11:57:31.519: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40977b36-91c0-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-p6vrf" to be "success or failure"
Jun 18 11:57:31.533: INFO: Pod "downwardapi-volume-40977b36-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.764601ms
Jun 18 11:57:33.549: INFO: Pod "downwardapi-volume-40977b36-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030349171s
Jun 18 11:57:35.565: INFO: Pod "downwardapi-volume-40977b36-91c0-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046008441s
STEP: Saw pod success
Jun 18 11:57:35.565: INFO: Pod "downwardapi-volume-40977b36-91c0-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:57:35.580: INFO: Trying to get logs from node 10.72.74.144 pod downwardapi-volume-40977b36-91c0-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 11:57:35.659: INFO: Waiting for pod downwardapi-volume-40977b36-91c0-11e9-bce2-ae54e022189f to disappear
Jun 18 11:57:35.672: INFO: Pod downwardapi-volume-40977b36-91c0-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:57:35.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p6vrf" for this suite.
Jun 18 11:57:41.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:57:42.109: INFO: namespace: e2e-tests-projected-p6vrf, resource: bindings, ignored listing per whitelist
Jun 18 11:57:42.257: INFO: namespace e2e-tests-projected-p6vrf deletion completed in 6.543140343s

• [SLOW TEST:11.309 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:57:42.258: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-k4jfb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-4745231b-91c0-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 11:57:42.736: INFO: Waiting up to 5m0s for pod "pod-secrets-474735d8-91c0-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-k4jfb" to be "success or failure"
Jun 18 11:57:42.751: INFO: Pod "pod-secrets-474735d8-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.998026ms
Jun 18 11:57:44.798: INFO: Pod "pod-secrets-474735d8-91c0-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.061461631s
STEP: Saw pod success
Jun 18 11:57:44.798: INFO: Pod "pod-secrets-474735d8-91c0-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 11:57:44.812: INFO: Trying to get logs from node 10.72.74.144 pod pod-secrets-474735d8-91c0-11e9-bce2-ae54e022189f container secret-volume-test: <nil>
STEP: delete the pod
Jun 18 11:57:44.885: INFO: Waiting for pod pod-secrets-474735d8-91c0-11e9-bce2-ae54e022189f to disappear
Jun 18 11:57:44.900: INFO: Pod pod-secrets-474735d8-91c0-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:57:44.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-k4jfb" for this suite.
Jun 18 11:57:50.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:57:51.152: INFO: namespace: e2e-tests-secrets-k4jfb, resource: bindings, ignored listing per whitelist
Jun 18 11:57:51.498: INFO: namespace e2e-tests-secrets-k4jfb deletion completed in 6.578493169s

• [SLOW TEST:9.240 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:57:51.499: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-7zv6h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0618 11:58:33.200421      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 18 11:58:33.200: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:58:33.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7zv6h" for this suite.
Jun 18 11:58:41.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:58:41.645: INFO: namespace: e2e-tests-gc-7zv6h, resource: bindings, ignored listing per whitelist
Jun 18 11:58:41.822: INFO: namespace e2e-tests-gc-7zv6h deletion completed in 8.607733478s

• [SLOW TEST:50.323 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:58:41.822: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-ckrfx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 18 11:58:47.158: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 18 11:58:47.174: INFO: Pod pod-with-poststart-http-hook still exists
Jun 18 11:58:49.174: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 18 11:58:49.190: INFO: Pod pod-with-poststart-http-hook still exists
Jun 18 11:58:51.175: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 18 11:58:51.189: INFO: Pod pod-with-poststart-http-hook still exists
Jun 18 11:58:53.174: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 18 11:58:53.190: INFO: Pod pod-with-poststart-http-hook still exists
Jun 18 11:58:55.174: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 18 11:58:55.207: INFO: Pod pod-with-poststart-http-hook still exists
Jun 18 11:58:57.174: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 18 11:58:57.190: INFO: Pod pod-with-poststart-http-hook still exists
Jun 18 11:58:59.174: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 18 11:58:59.199: INFO: Pod pod-with-poststart-http-hook still exists
Jun 18 11:59:01.174: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 18 11:59:01.196: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:59:01.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ckrfx" for this suite.
Jun 18 11:59:25.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 11:59:25.472: INFO: namespace: e2e-tests-container-lifecycle-hook-ckrfx, resource: bindings, ignored listing per whitelist
Jun 18 11:59:25.871: INFO: namespace e2e-tests-container-lifecycle-hook-ckrfx deletion completed in 24.586517682s

• [SLOW TEST:44.049 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 11:59:25.872: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-4sdnf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 18 11:59:30.521: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 18 11:59:30.535: INFO: Pod pod-with-prestop-http-hook still exists
Jun 18 11:59:32.535: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 18 11:59:32.550: INFO: Pod pod-with-prestop-http-hook still exists
Jun 18 11:59:34.535: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 18 11:59:34.552: INFO: Pod pod-with-prestop-http-hook still exists
Jun 18 11:59:36.535: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 18 11:59:36.550: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 11:59:36.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4sdnf" for this suite.
Jun 18 12:00:00.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:00:00.845: INFO: namespace: e2e-tests-container-lifecycle-hook-4sdnf, resource: bindings, ignored listing per whitelist
Jun 18 12:00:01.251: INFO: namespace e2e-tests-container-lifecycle-hook-4sdnf deletion completed in 24.566359761s

• [SLOW TEST:35.379 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:00:01.252: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ps68s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 18 12:00:01.821: INFO: Waiting up to 5m0s for pod "downward-api-9a2e11b9-91c0-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-ps68s" to be "success or failure"
Jun 18 12:00:01.835: INFO: Pod "downward-api-9a2e11b9-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.4461ms
Jun 18 12:00:03.850: INFO: Pod "downward-api-9a2e11b9-91c0-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.029147638s
Jun 18 12:00:05.865: INFO: Pod "downward-api-9a2e11b9-91c0-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044732589s
STEP: Saw pod success
Jun 18 12:00:05.865: INFO: Pod "downward-api-9a2e11b9-91c0-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:00:05.880: INFO: Trying to get logs from node 10.72.74.149 pod downward-api-9a2e11b9-91c0-11e9-bce2-ae54e022189f container dapi-container: <nil>
STEP: delete the pod
Jun 18 12:00:05.954: INFO: Waiting for pod downward-api-9a2e11b9-91c0-11e9-bce2-ae54e022189f to disappear
Jun 18 12:00:05.968: INFO: Pod downward-api-9a2e11b9-91c0-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:00:05.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ps68s" for this suite.
Jun 18 12:00:12.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:00:12.247: INFO: namespace: e2e-tests-downward-api-ps68s, resource: bindings, ignored listing per whitelist
Jun 18 12:00:12.596: INFO: namespace e2e-tests-downward-api-ps68s deletion completed in 6.60657604s

• [SLOW TEST:11.344 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:00:12.596: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pnjr4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-a0e1ca97-91c0-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 12:00:13.094: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a0e3c2ae-91c0-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-pnjr4" to be "success or failure"
Jun 18 12:00:13.113: INFO: Pod "pod-projected-secrets-a0e3c2ae-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.57701ms
Jun 18 12:00:15.129: INFO: Pod "pod-projected-secrets-a0e3c2ae-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035149747s
Jun 18 12:00:17.144: INFO: Pod "pod-projected-secrets-a0e3c2ae-91c0-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050113616s
STEP: Saw pod success
Jun 18 12:00:17.144: INFO: Pod "pod-projected-secrets-a0e3c2ae-91c0-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:00:17.160: INFO: Trying to get logs from node 10.72.74.149 pod pod-projected-secrets-a0e3c2ae-91c0-11e9-bce2-ae54e022189f container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 18 12:00:17.238: INFO: Waiting for pod pod-projected-secrets-a0e3c2ae-91c0-11e9-bce2-ae54e022189f to disappear
Jun 18 12:00:17.299: INFO: Pod pod-projected-secrets-a0e3c2ae-91c0-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:00:17.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pnjr4" for this suite.
Jun 18 12:00:25.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:00:25.912: INFO: namespace: e2e-tests-projected-pnjr4, resource: bindings, ignored listing per whitelist
Jun 18 12:00:25.951: INFO: namespace e2e-tests-projected-pnjr4 deletion completed in 8.632905815s

• [SLOW TEST:13.355 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:00:25.952: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-bsxl6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0618 12:00:57.049622      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 18 12:00:57.049: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:00:57.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bsxl6" for this suite.
Jun 18 12:01:03.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:01:03.313: INFO: namespace: e2e-tests-gc-bsxl6, resource: bindings, ignored listing per whitelist
Jun 18 12:01:03.765: INFO: namespace e2e-tests-gc-bsxl6 deletion completed in 6.680265217s

• [SLOW TEST:37.814 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:01:03.769: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4cfh7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jun 18 12:01:04.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 --namespace=e2e-tests-kubectl-4cfh7 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jun 18 12:01:06.622: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jun 18 12:01:06.622: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:01:08.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4cfh7" for this suite.
Jun 18 12:01:16.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:01:16.992: INFO: namespace: e2e-tests-kubectl-4cfh7, resource: bindings, ignored listing per whitelist
Jun 18 12:01:17.535: INFO: namespace e2e-tests-kubectl-4cfh7 deletion completed in 8.831526822s

• [SLOW TEST:13.766 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:01:17.536: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4n88m
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-c7985325-91c0-11e9-bce2-ae54e022189f
STEP: Creating configMap with name cm-test-opt-upd-c798537e-91c0-11e9-bce2-ae54e022189f
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c7985325-91c0-11e9-bce2-ae54e022189f
STEP: Updating configmap cm-test-opt-upd-c798537e-91c0-11e9-bce2-ae54e022189f
STEP: Creating configMap with name cm-test-opt-create-c79853a7-91c0-11e9-bce2-ae54e022189f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:02:31.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4n88m" for this suite.
Jun 18 12:02:48.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:02:48.813: INFO: namespace: e2e-tests-configmap-4n88m, resource: bindings, ignored listing per whitelist
Jun 18 12:02:48.955: INFO: namespace e2e-tests-configmap-4n88m deletion completed in 16.981179102s

• [SLOW TEST:91.418 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:02:48.955: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-v642t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:02:49.648: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe361889-91c0-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-v642t" to be "success or failure"
Jun 18 12:02:49.662: INFO: Pod "downwardapi-volume-fe361889-91c0-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.230622ms
Jun 18 12:02:51.677: INFO: Pod "downwardapi-volume-fe361889-91c0-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028814137s
STEP: Saw pod success
Jun 18 12:02:51.677: INFO: Pod "downwardapi-volume-fe361889-91c0-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:02:51.698: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-fe361889-91c0-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:02:51.770: INFO: Waiting for pod downwardapi-volume-fe361889-91c0-11e9-bce2-ae54e022189f to disappear
Jun 18 12:02:51.784: INFO: Pod downwardapi-volume-fe361889-91c0-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:02:51.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v642t" for this suite.
Jun 18 12:02:57.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:02:57.976: INFO: namespace: e2e-tests-projected-v642t, resource: bindings, ignored listing per whitelist
Jun 18 12:02:58.343: INFO: namespace e2e-tests-projected-v642t deletion completed in 6.536820803s

• [SLOW TEST:9.388 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:02:58.345: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8cd82
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 18 12:02:58.802: INFO: Waiting up to 5m0s for pod "pod-03aaac9b-91c1-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-8cd82" to be "success or failure"
Jun 18 12:02:58.816: INFO: Pod "pod-03aaac9b-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.060147ms
Jun 18 12:03:00.833: INFO: Pod "pod-03aaac9b-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030584723s
Jun 18 12:03:02.848: INFO: Pod "pod-03aaac9b-91c1-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045749513s
STEP: Saw pod success
Jun 18 12:03:02.848: INFO: Pod "pod-03aaac9b-91c1-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:03:02.885: INFO: Trying to get logs from node 10.72.74.149 pod pod-03aaac9b-91c1-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:03:02.957: INFO: Waiting for pod pod-03aaac9b-91c1-11e9-bce2-ae54e022189f to disappear
Jun 18 12:03:02.972: INFO: Pod pod-03aaac9b-91c1-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:03:02.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8cd82" for this suite.
Jun 18 12:03:09.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:03:09.436: INFO: namespace: e2e-tests-emptydir-8cd82, resource: bindings, ignored listing per whitelist
Jun 18 12:03:09.623: INFO: namespace e2e-tests-emptydir-8cd82 deletion completed in 6.631004789s

• [SLOW TEST:11.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:03:09.623: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-s9vcd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s9vcd A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-s9vcd;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s9vcd A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-s9vcd;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s9vcd.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-s9vcd.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s9vcd.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s9vcd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-s9vcd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s9vcd.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-s9vcd.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-s9vcd.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 233.65.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.65.233_udp@PTR;check="$$(dig +tcp +noall +answer +search 233.65.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.65.233_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s9vcd A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-s9vcd;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s9vcd A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s9vcd.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s9vcd.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s9vcd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-s9vcd.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s9vcd.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-s9vcd.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-s9vcd.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 233.65.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.65.233_udp@PTR;check="$$(dig +tcp +noall +answer +search 233.65.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.65.233_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 18 12:03:24.492: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:24.910: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:24.935: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:24.959: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s9vcd from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:24.986: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:25.014: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:25.037: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:25.062: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:25.086: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:25.231: INFO: Lookups using e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s9vcd jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc]

Jun 18 12:03:30.273: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.605: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.634: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.658: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s9vcd from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.682: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.705: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.730: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.753: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.777: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:30.919: INFO: Lookups using e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s9vcd jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc]

Jun 18 12:03:35.255: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.630: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.653: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.676: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s9vcd from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.705: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.731: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.757: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.780: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.805: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:35.951: INFO: Lookups using e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s9vcd jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc]

Jun 18 12:03:40.255: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.658: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.682: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.706: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s9vcd from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.729: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.784: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.807: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.831: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.855: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc from pod e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f: the server could not find the requested resource (get pods dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f)
Jun 18 12:03:40.997: INFO: Lookups using e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s9vcd jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd jessie_udp@dns-test-service.e2e-tests-dns-s9vcd.svc jessie_tcp@dns-test-service.e2e-tests-dns-s9vcd.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s9vcd.svc]

Jun 18 12:03:46.000: INFO: DNS probes using e2e-tests-dns-s9vcd/dns-test-0a7516a2-91c1-11e9-bce2-ae54e022189f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:03:46.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-s9vcd" for this suite.
Jun 18 12:03:52.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:03:52.347: INFO: namespace: e2e-tests-dns-s9vcd, resource: bindings, ignored listing per whitelist
Jun 18 12:03:52.722: INFO: namespace e2e-tests-dns-s9vcd deletion completed in 6.549431869s

• [SLOW TEST:43.100 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:03:52.723: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-bq2tp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0618 12:03:54.326628      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 18 12:03:54.326: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:03:54.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bq2tp" for this suite.
Jun 18 12:04:02.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:04:02.530: INFO: namespace: e2e-tests-gc-bq2tp, resource: bindings, ignored listing per whitelist
Jun 18 12:04:02.920: INFO: namespace e2e-tests-gc-bq2tp deletion completed in 8.578276335s

• [SLOW TEST:10.197 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:04:02.922: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-6jpjk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun 18 12:04:03.379: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:04:07.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6jpjk" for this suite.
Jun 18 12:04:15.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:04:15.572: INFO: namespace: e2e-tests-init-container-6jpjk, resource: bindings, ignored listing per whitelist
Jun 18 12:04:16.007: INFO: namespace e2e-tests-init-container-6jpjk deletion completed in 8.554142094s

• [SLOW TEST:13.086 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:04:16.008: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lp5tr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jun 18 12:04:16.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 cluster-info'
Jun 18 12:04:16.695: INFO: stderr: ""
Jun 18 12:04:16.695: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:04:16.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lp5tr" for this suite.
Jun 18 12:04:22.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:04:23.311: INFO: namespace: e2e-tests-kubectl-lp5tr, resource: bindings, ignored listing per whitelist
Jun 18 12:04:23.461: INFO: namespace e2e-tests-kubectl-lp5tr deletion completed in 6.746004561s

• [SLOW TEST:7.453 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:04:23.462: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-dlss8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-366c56eb-91c1-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 12:04:23.966: INFO: Waiting up to 5m0s for pod "pod-secrets-366e480a-91c1-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-dlss8" to be "success or failure"
Jun 18 12:04:23.980: INFO: Pod "pod-secrets-366e480a-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.804563ms
Jun 18 12:04:25.997: INFO: Pod "pod-secrets-366e480a-91c1-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03017606s
STEP: Saw pod success
Jun 18 12:04:25.997: INFO: Pod "pod-secrets-366e480a-91c1-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:04:26.012: INFO: Trying to get logs from node 10.72.74.149 pod pod-secrets-366e480a-91c1-11e9-bce2-ae54e022189f container secret-volume-test: <nil>
STEP: delete the pod
Jun 18 12:04:26.999: INFO: Waiting for pod pod-secrets-366e480a-91c1-11e9-bce2-ae54e022189f to disappear
Jun 18 12:04:27.012: INFO: Pod pod-secrets-366e480a-91c1-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:04:27.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dlss8" for this suite.
Jun 18 12:04:33.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:04:33.330: INFO: namespace: e2e-tests-secrets-dlss8, resource: bindings, ignored listing per whitelist
Jun 18 12:04:33.612: INFO: namespace e2e-tests-secrets-dlss8 deletion completed in 6.581174165s

• [SLOW TEST:10.151 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:04:33.613: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z2ppl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3c78d8f5-91c1-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:04:34.116: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3c7ad519-91c1-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-z2ppl" to be "success or failure"
Jun 18 12:04:34.131: INFO: Pod "pod-projected-configmaps-3c7ad519-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.571957ms
Jun 18 12:04:36.146: INFO: Pod "pod-projected-configmaps-3c7ad519-91c1-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029527828s
STEP: Saw pod success
Jun 18 12:04:36.146: INFO: Pod "pod-projected-configmaps-3c7ad519-91c1-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:04:36.161: INFO: Trying to get logs from node 10.72.74.149 pod pod-projected-configmaps-3c7ad519-91c1-11e9-bce2-ae54e022189f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:04:36.285: INFO: Waiting for pod pod-projected-configmaps-3c7ad519-91c1-11e9-bce2-ae54e022189f to disappear
Jun 18 12:04:36.300: INFO: Pod pod-projected-configmaps-3c7ad519-91c1-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:04:36.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z2ppl" for this suite.
Jun 18 12:04:42.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:04:42.520: INFO: namespace: e2e-tests-projected-z2ppl, resource: bindings, ignored listing per whitelist
Jun 18 12:04:42.903: INFO: namespace e2e-tests-projected-z2ppl deletion completed in 6.584518054s

• [SLOW TEST:9.290 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:04:42.904: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-6pnq4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 12:04:43.334: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:04:47.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6pnq4" for this suite.
Jun 18 12:05:37.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:05:38.198: INFO: namespace: e2e-tests-pods-6pnq4, resource: bindings, ignored listing per whitelist
Jun 18 12:05:38.326: INFO: namespace e2e-tests-pods-6pnq4 deletion completed in 50.799791403s

• [SLOW TEST:55.422 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:05:38.326: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nz5t2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:05:38.886: INFO: Waiting up to 5m0s for pod "downwardapi-volume-631627be-91c1-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-nz5t2" to be "success or failure"
Jun 18 12:05:38.900: INFO: Pod "downwardapi-volume-631627be-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.556114ms
Jun 18 12:05:40.916: INFO: Pod "downwardapi-volume-631627be-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029304337s
Jun 18 12:05:42.947: INFO: Pod "downwardapi-volume-631627be-91c1-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060313385s
STEP: Saw pod success
Jun 18 12:05:42.947: INFO: Pod "downwardapi-volume-631627be-91c1-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:05:42.961: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-631627be-91c1-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:05:43.084: INFO: Waiting for pod downwardapi-volume-631627be-91c1-11e9-bce2-ae54e022189f to disappear
Jun 18 12:05:43.099: INFO: Pod downwardapi-volume-631627be-91c1-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:05:43.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nz5t2" for this suite.
Jun 18 12:05:49.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:05:49.603: INFO: namespace: e2e-tests-downward-api-nz5t2, resource: bindings, ignored listing per whitelist
Jun 18 12:05:49.696: INFO: namespace e2e-tests-downward-api-nz5t2 deletion completed in 6.576959561s

• [SLOW TEST:11.369 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:05:49.696: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kwmfl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-69d72420-91c1-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:05:50.236: INFO: Waiting up to 5m0s for pod "pod-configmaps-69d94c21-91c1-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-kwmfl" to be "success or failure"
Jun 18 12:05:50.253: INFO: Pod "pod-configmaps-69d94c21-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.549947ms
Jun 18 12:05:52.268: INFO: Pod "pod-configmaps-69d94c21-91c1-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.032237237s
Jun 18 12:05:54.309: INFO: Pod "pod-configmaps-69d94c21-91c1-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073315985s
STEP: Saw pod success
Jun 18 12:05:54.309: INFO: Pod "pod-configmaps-69d94c21-91c1-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:05:54.323: INFO: Trying to get logs from node 10.72.74.149 pod pod-configmaps-69d94c21-91c1-11e9-bce2-ae54e022189f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:05:54.392: INFO: Waiting for pod pod-configmaps-69d94c21-91c1-11e9-bce2-ae54e022189f to disappear
Jun 18 12:05:54.484: INFO: Pod pod-configmaps-69d94c21-91c1-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:05:54.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kwmfl" for this suite.
Jun 18 12:06:00.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:06:00.706: INFO: namespace: e2e-tests-configmap-kwmfl, resource: bindings, ignored listing per whitelist
Jun 18 12:06:01.051: INFO: namespace e2e-tests-configmap-kwmfl deletion completed in 6.547863095s

• [SLOW TEST:11.356 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:06:01.052: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2xrmr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 18 12:06:01.685: INFO: Waiting up to 5m0s for pod "pod-709e0ec0-91c1-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-2xrmr" to be "success or failure"
Jun 18 12:06:01.699: INFO: Pod "pod-709e0ec0-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.514272ms
Jun 18 12:06:03.715: INFO: Pod "pod-709e0ec0-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030440953s
Jun 18 12:06:06.351: INFO: Pod "pod-709e0ec0-91c1-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.666792389s
STEP: Saw pod success
Jun 18 12:06:06.352: INFO: Pod "pod-709e0ec0-91c1-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:06:06.369: INFO: Trying to get logs from node 10.72.74.143 pod pod-709e0ec0-91c1-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:06:06.441: INFO: Waiting for pod pod-709e0ec0-91c1-11e9-bce2-ae54e022189f to disappear
Jun 18 12:06:06.456: INFO: Pod pod-709e0ec0-91c1-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:06:06.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2xrmr" for this suite.
Jun 18 12:06:12.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:06:12.691: INFO: namespace: e2e-tests-emptydir-2xrmr, resource: bindings, ignored listing per whitelist
Jun 18 12:06:13.030: INFO: namespace e2e-tests-emptydir-2xrmr deletion completed in 6.554259993s

• [SLOW TEST:11.977 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:06:13.031: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mhr68
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jun 18 12:06:13.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:13.814: INFO: stderr: ""
Jun 18 12:06:13.814: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 18 12:06:13.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:13.958: INFO: stderr: ""
Jun 18 12:06:13.958: INFO: stdout: "update-demo-nautilus-429rs update-demo-nautilus-ld8l8 "
Jun 18 12:06:13.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-429rs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:14.096: INFO: stderr: ""
Jun 18 12:06:14.096: INFO: stdout: ""
Jun 18 12:06:14.096: INFO: update-demo-nautilus-429rs is created but not running
Jun 18 12:06:19.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:19.258: INFO: stderr: ""
Jun 18 12:06:19.258: INFO: stdout: "update-demo-nautilus-429rs update-demo-nautilus-ld8l8 "
Jun 18 12:06:19.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-429rs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:19.388: INFO: stderr: ""
Jun 18 12:06:19.388: INFO: stdout: "true"
Jun 18 12:06:19.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-429rs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:19.535: INFO: stderr: ""
Jun 18 12:06:19.535: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:06:19.535: INFO: validating pod update-demo-nautilus-429rs
Jun 18 12:06:19.568: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:06:19.568: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:06:19.568: INFO: update-demo-nautilus-429rs is verified up and running
Jun 18 12:06:19.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-ld8l8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:19.698: INFO: stderr: ""
Jun 18 12:06:19.698: INFO: stdout: "true"
Jun 18 12:06:19.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-ld8l8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:20.638: INFO: stderr: ""
Jun 18 12:06:20.638: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:06:20.638: INFO: validating pod update-demo-nautilus-ld8l8
Jun 18 12:06:20.671: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:06:20.671: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:06:20.671: INFO: update-demo-nautilus-ld8l8 is verified up and running
STEP: using delete to clean up resources
Jun 18 12:06:20.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:20.812: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 12:06:20.812: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 18 12:06:20.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-mhr68'
Jun 18 12:06:20.988: INFO: stderr: "No resources found.\n"
Jun 18 12:06:20.988: INFO: stdout: ""
Jun 18 12:06:20.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -l name=update-demo --namespace=e2e-tests-kubectl-mhr68 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 18 12:06:21.124: INFO: stderr: ""
Jun 18 12:06:21.124: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:06:21.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mhr68" for this suite.
Jun 18 12:06:45.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:06:46.774: INFO: namespace: e2e-tests-kubectl-mhr68, resource: bindings, ignored listing per whitelist
Jun 18 12:06:46.801: INFO: namespace e2e-tests-kubectl-mhr68 deletion completed in 25.655984162s

• [SLOW TEST:33.770 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:06:46.801: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-bx8lz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 18 12:06:51.500: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:06:51.515: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:06:53.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:06:53.549: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:06:55.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:06:55.532: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:06:57.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:06:57.530: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:06:59.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:06:59.530: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:01.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:01.531: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:03.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:03.530: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:05.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:05.553: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:07.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:07.530: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:09.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:09.532: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:11.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:11.531: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:13.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:13.533: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:15.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:15.531: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:17.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:17.552: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 18 12:07:19.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 18 12:07:19.530: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:07:19.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bx8lz" for this suite.
Jun 18 12:07:43.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:07:43.706: INFO: namespace: e2e-tests-container-lifecycle-hook-bx8lz, resource: bindings, ignored listing per whitelist
Jun 18 12:07:44.158: INFO: namespace e2e-tests-container-lifecycle-hook-bx8lz deletion completed in 24.55459548s

• [SLOW TEST:57.357 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:07:44.159: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-sgtlc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 18 12:07:44.823: INFO: Number of nodes with available pods: 0
Jun 18 12:07:44.823: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:07:45.860: INFO: Number of nodes with available pods: 0
Jun 18 12:07:45.860: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:07:46.885: INFO: Number of nodes with available pods: 1
Jun 18 12:07:46.885: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:07:47.858: INFO: Number of nodes with available pods: 3
Jun 18 12:07:47.859: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jun 18 12:07:47.930: INFO: Number of nodes with available pods: 2
Jun 18 12:07:47.930: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:07:48.979: INFO: Number of nodes with available pods: 2
Jun 18 12:07:48.979: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:07:50.373: INFO: Number of nodes with available pods: 3
Jun 18 12:07:50.373: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-sgtlc, will wait for the garbage collector to delete the pods
Jun 18 12:07:50.492: INFO: Deleting DaemonSet.extensions daemon-set took: 29.404003ms
Jun 18 12:07:50.593: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.354605ms
Jun 18 12:08:31.185: INFO: Number of nodes with available pods: 0
Jun 18 12:08:31.185: INFO: Number of running nodes: 0, number of available pods: 0
Jun 18 12:08:31.198: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-sgtlc/daemonsets","resourceVersion":"95589"},"items":null}

Jun 18 12:08:31.212: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-sgtlc/pods","resourceVersion":"95589"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:08:31.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-sgtlc" for this suite.
Jun 18 12:08:39.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:08:39.416: INFO: namespace: e2e-tests-daemonsets-sgtlc, resource: bindings, ignored listing per whitelist
Jun 18 12:08:39.834: INFO: namespace e2e-tests-daemonsets-sgtlc deletion completed in 8.545417349s

• [SLOW TEST:55.675 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:08:39.834: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-dpjsn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jun 18 12:08:40.355: INFO: Waiting up to 5m0s for pod "var-expansion-cf4036c1-91c1-11e9-bce2-ae54e022189f" in namespace "e2e-tests-var-expansion-dpjsn" to be "success or failure"
Jun 18 12:08:40.370: INFO: Pod "var-expansion-cf4036c1-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.561912ms
Jun 18 12:08:42.403: INFO: Pod "var-expansion-cf4036c1-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047077524s
Jun 18 12:08:44.418: INFO: Pod "var-expansion-cf4036c1-91c1-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062284293s
STEP: Saw pod success
Jun 18 12:08:44.418: INFO: Pod "var-expansion-cf4036c1-91c1-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:08:44.432: INFO: Trying to get logs from node 10.72.74.149 pod var-expansion-cf4036c1-91c1-11e9-bce2-ae54e022189f container dapi-container: <nil>
STEP: delete the pod
Jun 18 12:08:44.502: INFO: Waiting for pod var-expansion-cf4036c1-91c1-11e9-bce2-ae54e022189f to disappear
Jun 18 12:08:44.516: INFO: Pod var-expansion-cf4036c1-91c1-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:08:44.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-dpjsn" for this suite.
Jun 18 12:08:50.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:08:50.972: INFO: namespace: e2e-tests-var-expansion-dpjsn, resource: bindings, ignored listing per whitelist
Jun 18 12:08:51.335: INFO: namespace e2e-tests-var-expansion-dpjsn deletion completed in 6.800770061s

• [SLOW TEST:11.501 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:08:51.335: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8r9nx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d6150c58-91c1-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:08:51.831: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d6170c2f-91c1-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-8r9nx" to be "success or failure"
Jun 18 12:08:51.846: INFO: Pod "pod-projected-configmaps-d6170c2f-91c1-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.785808ms
Jun 18 12:08:53.880: INFO: Pod "pod-projected-configmaps-d6170c2f-91c1-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04882872s
STEP: Saw pod success
Jun 18 12:08:53.880: INFO: Pod "pod-projected-configmaps-d6170c2f-91c1-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:08:53.894: INFO: Trying to get logs from node 10.72.74.143 pod pod-projected-configmaps-d6170c2f-91c1-11e9-bce2-ae54e022189f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:08:53.969: INFO: Waiting for pod pod-projected-configmaps-d6170c2f-91c1-11e9-bce2-ae54e022189f to disappear
Jun 18 12:08:53.983: INFO: Pod pod-projected-configmaps-d6170c2f-91c1-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:08:53.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8r9nx" for this suite.
Jun 18 12:09:00.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:09:00.387: INFO: namespace: e2e-tests-projected-8r9nx, resource: bindings, ignored listing per whitelist
Jun 18 12:09:00.572: INFO: namespace e2e-tests-projected-8r9nx deletion completed in 6.567598408s

• [SLOW TEST:9.236 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:09:00.573: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-b2kqz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-b2kqz
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jun 18 12:09:01.136: INFO: Found 0 stateful pods, waiting for 3
Jun 18 12:09:11.216: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:09:11.216: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:09:11.216: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:09:11.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-b2kqz ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 12:09:11.718: INFO: stderr: ""
Jun 18 12:09:11.718: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 12:09:11.718: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jun 18 12:09:21.900: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jun 18 12:09:31.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-b2kqz ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 12:09:32.379: INFO: stderr: ""
Jun 18 12:09:32.379: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 12:09:32.379: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 12:09:43.759: INFO: Waiting for StatefulSet e2e-tests-statefulset-b2kqz/ss2 to complete update
Jun 18 12:09:43.759: INFO: Waiting for Pod e2e-tests-statefulset-b2kqz/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 18 12:09:43.759: INFO: Waiting for Pod e2e-tests-statefulset-b2kqz/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 18 12:09:53.807: INFO: Waiting for StatefulSet e2e-tests-statefulset-b2kqz/ss2 to complete update
STEP: Rolling back to a previous revision
Jun 18 12:10:03.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-b2kqz ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 12:10:04.208: INFO: stderr: ""
Jun 18 12:10:04.208: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 12:10:04.208: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 12:10:14.356: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jun 18 12:10:24.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-b2kqz ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 12:10:24.884: INFO: stderr: ""
Jun 18 12:10:24.884: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 12:10:24.884: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 12:10:35.084: INFO: Waiting for StatefulSet e2e-tests-statefulset-b2kqz/ss2 to complete update
Jun 18 12:10:35.084: INFO: Waiting for Pod e2e-tests-statefulset-b2kqz/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 18 12:10:35.084: INFO: Waiting for Pod e2e-tests-statefulset-b2kqz/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 18 12:10:35.084: INFO: Waiting for Pod e2e-tests-statefulset-b2kqz/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 18 12:10:45.134: INFO: Waiting for StatefulSet e2e-tests-statefulset-b2kqz/ss2 to complete update
Jun 18 12:10:45.134: INFO: Waiting for Pod e2e-tests-statefulset-b2kqz/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 18 12:10:45.134: INFO: Waiting for Pod e2e-tests-statefulset-b2kqz/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jun 18 12:10:55.115: INFO: Waiting for StatefulSet e2e-tests-statefulset-b2kqz/ss2 to complete update
Jun 18 12:10:55.116: INFO: Waiting for Pod e2e-tests-statefulset-b2kqz/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 18 12:11:05.133: INFO: Deleting all statefulset in ns e2e-tests-statefulset-b2kqz
Jun 18 12:11:05.147: INFO: Scaling statefulset ss2 to 0
Jun 18 12:11:35.227: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 12:11:35.242: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:11:35.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-b2kqz" for this suite.
Jun 18 12:11:43.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:11:43.626: INFO: namespace: e2e-tests-statefulset-b2kqz, resource: bindings, ignored listing per whitelist
Jun 18 12:11:43.900: INFO: namespace e2e-tests-statefulset-b2kqz deletion completed in 8.571896658s

• [SLOW TEST:163.327 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:11:43.903: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-trhgx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:11:52.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-trhgx" for this suite.
Jun 18 12:12:18.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:12:18.320: INFO: namespace: e2e-tests-replication-controller-trhgx, resource: bindings, ignored listing per whitelist
Jun 18 12:12:18.762: INFO: namespace e2e-tests-replication-controller-trhgx deletion completed in 26.618058139s

• [SLOW TEST:34.860 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:12:18.763: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-2s59d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-2s59d
I0618 12:12:19.218107      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-2s59d, replica count: 1
I0618 12:12:20.268511      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0618 12:12:21.268804      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 18 12:12:21.400: INFO: Created: latency-svc-zvd9c
Jun 18 12:12:21.423: INFO: Got endpoints: latency-svc-zvd9c [54.631568ms]
Jun 18 12:12:21.517: INFO: Created: latency-svc-x2tf4
Jun 18 12:12:21.526: INFO: Got endpoints: latency-svc-x2tf4 [102.180344ms]
Jun 18 12:12:21.536: INFO: Created: latency-svc-x7dmn
Jun 18 12:12:21.545: INFO: Got endpoints: latency-svc-x7dmn [120.248753ms]
Jun 18 12:12:21.551: INFO: Created: latency-svc-n6frb
Jun 18 12:12:21.560: INFO: Got endpoints: latency-svc-n6frb [135.813347ms]
Jun 18 12:12:21.569: INFO: Created: latency-svc-8bzd5
Jun 18 12:12:21.578: INFO: Got endpoints: latency-svc-8bzd5 [153.228533ms]
Jun 18 12:12:21.587: INFO: Created: latency-svc-k5z5s
Jun 18 12:12:21.596: INFO: Got endpoints: latency-svc-k5z5s [170.926692ms]
Jun 18 12:12:21.608: INFO: Created: latency-svc-42z2z
Jun 18 12:12:21.621: INFO: Got endpoints: latency-svc-42z2z [196.4617ms]
Jun 18 12:12:21.628: INFO: Created: latency-svc-2pn4s
Jun 18 12:12:21.637: INFO: Got endpoints: latency-svc-2pn4s [211.843627ms]
Jun 18 12:12:21.644: INFO: Created: latency-svc-w2jmx
Jun 18 12:12:21.653: INFO: Got endpoints: latency-svc-w2jmx [228.146356ms]
Jun 18 12:12:21.663: INFO: Created: latency-svc-jq9d8
Jun 18 12:12:21.673: INFO: Got endpoints: latency-svc-jq9d8 [248.48844ms]
Jun 18 12:12:21.683: INFO: Created: latency-svc-n2x47
Jun 18 12:12:21.692: INFO: Got endpoints: latency-svc-n2x47 [267.272925ms]
Jun 18 12:12:21.701: INFO: Created: latency-svc-fsv9r
Jun 18 12:12:21.710: INFO: Got endpoints: latency-svc-fsv9r [284.725913ms]
Jun 18 12:12:21.718: INFO: Created: latency-svc-psc9p
Jun 18 12:12:21.728: INFO: Got endpoints: latency-svc-psc9p [302.997155ms]
Jun 18 12:12:21.803: INFO: Created: latency-svc-qtpxr
Jun 18 12:12:21.815: INFO: Got endpoints: latency-svc-qtpxr [389.670609ms]
Jun 18 12:12:21.823: INFO: Created: latency-svc-kv2wg
Jun 18 12:12:21.831: INFO: Got endpoints: latency-svc-kv2wg [405.426607ms]
Jun 18 12:12:21.845: INFO: Created: latency-svc-l95fd
Jun 18 12:12:21.854: INFO: Got endpoints: latency-svc-l95fd [428.527881ms]
Jun 18 12:12:21.861: INFO: Created: latency-svc-h68sr
Jun 18 12:12:21.868: INFO: Got endpoints: latency-svc-h68sr [341.839025ms]
Jun 18 12:12:21.879: INFO: Created: latency-svc-l585t
Jun 18 12:12:21.890: INFO: Got endpoints: latency-svc-l585t [344.938025ms]
Jun 18 12:12:21.984: INFO: Created: latency-svc-snst8
Jun 18 12:12:21.993: INFO: Got endpoints: latency-svc-snst8 [432.485424ms]
Jun 18 12:12:22.000: INFO: Created: latency-svc-c4qk7
Jun 18 12:12:22.012: INFO: Got endpoints: latency-svc-c4qk7 [434.290341ms]
Jun 18 12:12:22.026: INFO: Created: latency-svc-jll8z
Jun 18 12:12:22.036: INFO: Got endpoints: latency-svc-jll8z [440.261183ms]
Jun 18 12:12:22.047: INFO: Created: latency-svc-6t5bl
Jun 18 12:12:22.056: INFO: Got endpoints: latency-svc-6t5bl [434.702512ms]
Jun 18 12:12:22.067: INFO: Created: latency-svc-zwjsb
Jun 18 12:12:22.075: INFO: Got endpoints: latency-svc-zwjsb [438.540147ms]
Jun 18 12:12:22.083: INFO: Created: latency-svc-56wsq
Jun 18 12:12:22.092: INFO: Got endpoints: latency-svc-56wsq [439.011195ms]
Jun 18 12:12:22.101: INFO: Created: latency-svc-5j8l6
Jun 18 12:12:22.111: INFO: Got endpoints: latency-svc-5j8l6 [437.191241ms]
Jun 18 12:12:22.125: INFO: Created: latency-svc-rd5p8
Jun 18 12:12:22.135: INFO: Got endpoints: latency-svc-rd5p8 [442.107251ms]
Jun 18 12:12:22.143: INFO: Created: latency-svc-xm7ht
Jun 18 12:12:22.152: INFO: Got endpoints: latency-svc-xm7ht [441.875561ms]
Jun 18 12:12:22.164: INFO: Created: latency-svc-w865v
Jun 18 12:12:22.172: INFO: Got endpoints: latency-svc-w865v [443.521062ms]
Jun 18 12:12:22.179: INFO: Created: latency-svc-l9fll
Jun 18 12:12:22.188: INFO: Got endpoints: latency-svc-l9fll [373.35196ms]
Jun 18 12:12:22.196: INFO: Created: latency-svc-nzmf2
Jun 18 12:12:22.206: INFO: Got endpoints: latency-svc-nzmf2 [375.398314ms]
Jun 18 12:12:22.218: INFO: Created: latency-svc-wc595
Jun 18 12:12:22.229: INFO: Got endpoints: latency-svc-wc595 [374.987012ms]
Jun 18 12:12:22.239: INFO: Created: latency-svc-d5j62
Jun 18 12:12:22.251: INFO: Got endpoints: latency-svc-d5j62 [383.391309ms]
Jun 18 12:12:22.263: INFO: Created: latency-svc-249pf
Jun 18 12:12:22.273: INFO: Got endpoints: latency-svc-249pf [382.877396ms]
Jun 18 12:12:22.279: INFO: Created: latency-svc-v9jvn
Jun 18 12:12:22.290: INFO: Got endpoints: latency-svc-v9jvn [297.268496ms]
Jun 18 12:12:22.294: INFO: Created: latency-svc-9wfd5
Jun 18 12:12:22.303: INFO: Got endpoints: latency-svc-9wfd5 [290.935501ms]
Jun 18 12:12:22.311: INFO: Created: latency-svc-2r2nw
Jun 18 12:12:22.320: INFO: Got endpoints: latency-svc-2r2nw [284.238801ms]
Jun 18 12:12:22.333: INFO: Created: latency-svc-m5m92
Jun 18 12:12:22.342: INFO: Got endpoints: latency-svc-m5m92 [286.358506ms]
Jun 18 12:12:22.352: INFO: Created: latency-svc-bk8j8
Jun 18 12:12:22.363: INFO: Got endpoints: latency-svc-bk8j8 [287.497253ms]
Jun 18 12:12:22.371: INFO: Created: latency-svc-t42z5
Jun 18 12:12:22.380: INFO: Got endpoints: latency-svc-t42z5 [287.198588ms]
Jun 18 12:12:22.390: INFO: Created: latency-svc-hjm4j
Jun 18 12:12:22.397: INFO: Got endpoints: latency-svc-hjm4j [286.57377ms]
Jun 18 12:12:22.405: INFO: Created: latency-svc-9tpk5
Jun 18 12:12:22.416: INFO: Got endpoints: latency-svc-9tpk5 [281.112973ms]
Jun 18 12:12:22.425: INFO: Created: latency-svc-ldrdk
Jun 18 12:12:22.434: INFO: Got endpoints: latency-svc-ldrdk [281.590495ms]
Jun 18 12:12:22.442: INFO: Created: latency-svc-69rvn
Jun 18 12:12:22.453: INFO: Got endpoints: latency-svc-69rvn [280.518968ms]
Jun 18 12:12:22.461: INFO: Created: latency-svc-mkd7g
Jun 18 12:12:22.472: INFO: Got endpoints: latency-svc-mkd7g [283.805804ms]
Jun 18 12:12:22.479: INFO: Created: latency-svc-7hdjv
Jun 18 12:12:22.488: INFO: Got endpoints: latency-svc-7hdjv [281.886503ms]
Jun 18 12:12:22.501: INFO: Created: latency-svc-nx7n9
Jun 18 12:12:22.514: INFO: Got endpoints: latency-svc-nx7n9 [285.012838ms]
Jun 18 12:12:22.544: INFO: Created: latency-svc-h6wrd
Jun 18 12:12:22.556: INFO: Got endpoints: latency-svc-h6wrd [304.58996ms]
Jun 18 12:12:22.631: INFO: Created: latency-svc-ng6v4
Jun 18 12:12:22.642: INFO: Got endpoints: latency-svc-ng6v4 [369.624646ms]
Jun 18 12:12:22.656: INFO: Created: latency-svc-g74lw
Jun 18 12:12:22.664: INFO: Got endpoints: latency-svc-g74lw [373.289216ms]
Jun 18 12:12:22.673: INFO: Created: latency-svc-7xs6f
Jun 18 12:12:22.682: INFO: Got endpoints: latency-svc-7xs6f [378.573447ms]
Jun 18 12:12:22.692: INFO: Created: latency-svc-6hqhj
Jun 18 12:12:22.704: INFO: Got endpoints: latency-svc-6hqhj [383.253552ms]
Jun 18 12:12:22.719: INFO: Created: latency-svc-8fkjf
Jun 18 12:12:22.728: INFO: Created: latency-svc-fsv8x
Jun 18 12:12:22.729: INFO: Got endpoints: latency-svc-8fkjf [386.851459ms]
Jun 18 12:12:22.739: INFO: Got endpoints: latency-svc-fsv8x [375.200433ms]
Jun 18 12:12:22.747: INFO: Created: latency-svc-r5swg
Jun 18 12:12:22.760: INFO: Got endpoints: latency-svc-r5swg [380.438672ms]
Jun 18 12:12:22.766: INFO: Created: latency-svc-vmddc
Jun 18 12:12:22.777: INFO: Got endpoints: latency-svc-vmddc [379.656037ms]
Jun 18 12:12:22.785: INFO: Created: latency-svc-25pq4
Jun 18 12:12:22.794: INFO: Got endpoints: latency-svc-25pq4 [377.626535ms]
Jun 18 12:12:22.803: INFO: Created: latency-svc-xn2sh
Jun 18 12:12:22.819: INFO: Created: latency-svc-94qgl
Jun 18 12:12:22.828: INFO: Got endpoints: latency-svc-xn2sh [394.031427ms]
Jun 18 12:12:22.840: INFO: Created: latency-svc-qlxq5
Jun 18 12:12:22.864: INFO: Created: latency-svc-t8dtq
Jun 18 12:12:22.876: INFO: Got endpoints: latency-svc-94qgl [423.582557ms]
Jun 18 12:12:22.884: INFO: Created: latency-svc-djsgj
Jun 18 12:12:22.898: INFO: Created: latency-svc-bj7vx
Jun 18 12:12:22.920: INFO: Created: latency-svc-lvnfs
Jun 18 12:12:22.926: INFO: Got endpoints: latency-svc-qlxq5 [453.549171ms]
Jun 18 12:12:22.934: INFO: Created: latency-svc-lwpp9
Jun 18 12:12:22.951: INFO: Created: latency-svc-pnh9s
Jun 18 12:12:22.967: INFO: Created: latency-svc-hzlbw
Jun 18 12:12:22.975: INFO: Got endpoints: latency-svc-t8dtq [486.431252ms]
Jun 18 12:12:22.983: INFO: Created: latency-svc-f6fhp
Jun 18 12:12:23.001: INFO: Created: latency-svc-6c7lc
Jun 18 12:12:23.020: INFO: Created: latency-svc-ctpkh
Jun 18 12:12:23.025: INFO: Got endpoints: latency-svc-djsgj [510.893392ms]
Jun 18 12:12:23.036: INFO: Created: latency-svc-jlrp2
Jun 18 12:12:23.050: INFO: Created: latency-svc-d7hnr
Jun 18 12:12:23.068: INFO: Created: latency-svc-tz8bs
Jun 18 12:12:23.077: INFO: Got endpoints: latency-svc-bj7vx [520.951558ms]
Jun 18 12:12:23.085: INFO: Created: latency-svc-tq9zk
Jun 18 12:12:23.101: INFO: Created: latency-svc-rp9jc
Jun 18 12:12:23.119: INFO: Created: latency-svc-jspjt
Jun 18 12:12:23.126: INFO: Got endpoints: latency-svc-lvnfs [483.589495ms]
Jun 18 12:12:23.135: INFO: Created: latency-svc-x9xkh
Jun 18 12:12:23.155: INFO: Created: latency-svc-lvxfx
Jun 18 12:12:23.171: INFO: Created: latency-svc-vxjbx
Jun 18 12:12:23.176: INFO: Got endpoints: latency-svc-lwpp9 [512.443396ms]
Jun 18 12:12:23.216: INFO: Created: latency-svc-fvj7k
Jun 18 12:12:23.226: INFO: Got endpoints: latency-svc-pnh9s [544.048989ms]
Jun 18 12:12:23.264: INFO: Created: latency-svc-qzbkk
Jun 18 12:12:23.276: INFO: Got endpoints: latency-svc-hzlbw [571.793858ms]
Jun 18 12:12:23.306: INFO: Created: latency-svc-nm8ks
Jun 18 12:12:23.326: INFO: Got endpoints: latency-svc-f6fhp [596.991912ms]
Jun 18 12:12:23.356: INFO: Created: latency-svc-tzjf9
Jun 18 12:12:23.376: INFO: Got endpoints: latency-svc-6c7lc [637.256025ms]
Jun 18 12:12:23.406: INFO: Created: latency-svc-dtl62
Jun 18 12:12:23.426: INFO: Got endpoints: latency-svc-ctpkh [665.823313ms]
Jun 18 12:12:23.456: INFO: Created: latency-svc-4hlg4
Jun 18 12:12:23.476: INFO: Got endpoints: latency-svc-jlrp2 [699.051929ms]
Jun 18 12:12:23.507: INFO: Created: latency-svc-4bp8s
Jun 18 12:12:23.525: INFO: Got endpoints: latency-svc-d7hnr [731.611388ms]
Jun 18 12:12:23.558: INFO: Created: latency-svc-lv5tp
Jun 18 12:12:23.576: INFO: Got endpoints: latency-svc-tz8bs [748.586102ms]
Jun 18 12:12:23.608: INFO: Created: latency-svc-8vksv
Jun 18 12:12:23.625: INFO: Got endpoints: latency-svc-tq9zk [748.793237ms]
Jun 18 12:12:23.657: INFO: Created: latency-svc-vd4bh
Jun 18 12:12:23.676: INFO: Got endpoints: latency-svc-rp9jc [750.322886ms]
Jun 18 12:12:23.714: INFO: Created: latency-svc-gsfv7
Jun 18 12:12:23.725: INFO: Got endpoints: latency-svc-jspjt [749.91922ms]
Jun 18 12:12:23.757: INFO: Created: latency-svc-xx82k
Jun 18 12:12:23.778: INFO: Got endpoints: latency-svc-x9xkh [752.656617ms]
Jun 18 12:12:23.816: INFO: Created: latency-svc-fmx5t
Jun 18 12:12:23.826: INFO: Got endpoints: latency-svc-lvxfx [748.626796ms]
Jun 18 12:12:23.860: INFO: Created: latency-svc-44952
Jun 18 12:12:23.875: INFO: Got endpoints: latency-svc-vxjbx [749.226253ms]
Jun 18 12:12:23.908: INFO: Created: latency-svc-g7vw6
Jun 18 12:12:23.927: INFO: Got endpoints: latency-svc-fvj7k [750.384058ms]
Jun 18 12:12:23.959: INFO: Created: latency-svc-6p58p
Jun 18 12:12:23.975: INFO: Got endpoints: latency-svc-qzbkk [749.287416ms]
Jun 18 12:12:24.007: INFO: Created: latency-svc-n9k9d
Jun 18 12:12:24.025: INFO: Got endpoints: latency-svc-nm8ks [749.741971ms]
Jun 18 12:12:24.057: INFO: Created: latency-svc-7b2dh
Jun 18 12:12:24.076: INFO: Got endpoints: latency-svc-tzjf9 [750.22507ms]
Jun 18 12:12:24.107: INFO: Created: latency-svc-69l2t
Jun 18 12:12:24.125: INFO: Got endpoints: latency-svc-dtl62 [747.721798ms]
Jun 18 12:12:24.157: INFO: Created: latency-svc-s45ck
Jun 18 12:12:24.176: INFO: Got endpoints: latency-svc-4hlg4 [750.161137ms]
Jun 18 12:12:24.208: INFO: Created: latency-svc-vtnpl
Jun 18 12:12:24.226: INFO: Got endpoints: latency-svc-4bp8s [750.360782ms]
Jun 18 12:12:24.265: INFO: Created: latency-svc-447lx
Jun 18 12:12:24.277: INFO: Got endpoints: latency-svc-lv5tp [751.553736ms]
Jun 18 12:12:24.323: INFO: Created: latency-svc-9ct7t
Jun 18 12:12:24.326: INFO: Got endpoints: latency-svc-8vksv [749.710213ms]
Jun 18 12:12:24.359: INFO: Created: latency-svc-lll4x
Jun 18 12:12:24.378: INFO: Got endpoints: latency-svc-vd4bh [752.696787ms]
Jun 18 12:12:24.408: INFO: Created: latency-svc-4vfs7
Jun 18 12:12:24.433: INFO: Got endpoints: latency-svc-gsfv7 [756.498871ms]
Jun 18 12:12:24.464: INFO: Created: latency-svc-9dh5g
Jun 18 12:12:24.475: INFO: Got endpoints: latency-svc-xx82k [749.566906ms]
Jun 18 12:12:24.504: INFO: Created: latency-svc-mn4dp
Jun 18 12:12:24.526: INFO: Got endpoints: latency-svc-fmx5t [748.091555ms]
Jun 18 12:12:24.558: INFO: Created: latency-svc-xkpt4
Jun 18 12:12:24.576: INFO: Got endpoints: latency-svc-44952 [749.71911ms]
Jun 18 12:12:24.605: INFO: Created: latency-svc-4ftnc
Jun 18 12:12:24.625: INFO: Got endpoints: latency-svc-g7vw6 [749.775561ms]
Jun 18 12:12:24.656: INFO: Created: latency-svc-zncqc
Jun 18 12:12:24.676: INFO: Got endpoints: latency-svc-6p58p [748.836015ms]
Jun 18 12:12:24.706: INFO: Created: latency-svc-qt6gx
Jun 18 12:12:24.725: INFO: Got endpoints: latency-svc-n9k9d [750.077609ms]
Jun 18 12:12:24.763: INFO: Created: latency-svc-nqqzn
Jun 18 12:12:24.775: INFO: Got endpoints: latency-svc-7b2dh [749.862677ms]
Jun 18 12:12:24.805: INFO: Created: latency-svc-sm794
Jun 18 12:12:24.826: INFO: Got endpoints: latency-svc-69l2t [749.959385ms]
Jun 18 12:12:24.857: INFO: Created: latency-svc-k7d7c
Jun 18 12:12:24.875: INFO: Got endpoints: latency-svc-s45ck [750.330996ms]
Jun 18 12:12:24.907: INFO: Created: latency-svc-9cd4j
Jun 18 12:12:24.925: INFO: Got endpoints: latency-svc-vtnpl [749.295845ms]
Jun 18 12:12:24.955: INFO: Created: latency-svc-q69vb
Jun 18 12:12:24.980: INFO: Got endpoints: latency-svc-447lx [754.117246ms]
Jun 18 12:12:25.014: INFO: Created: latency-svc-wcqpc
Jun 18 12:12:25.026: INFO: Got endpoints: latency-svc-9ct7t [749.103554ms]
Jun 18 12:12:25.057: INFO: Created: latency-svc-h8bsm
Jun 18 12:12:25.075: INFO: Got endpoints: latency-svc-lll4x [748.176977ms]
Jun 18 12:12:25.107: INFO: Created: latency-svc-fvmcd
Jun 18 12:12:25.125: INFO: Got endpoints: latency-svc-4vfs7 [747.535821ms]
Jun 18 12:12:25.156: INFO: Created: latency-svc-t6scc
Jun 18 12:12:25.176: INFO: Got endpoints: latency-svc-9dh5g [743.039834ms]
Jun 18 12:12:25.214: INFO: Created: latency-svc-cthd5
Jun 18 12:12:25.229: INFO: Got endpoints: latency-svc-mn4dp [754.331939ms]
Jun 18 12:12:25.261: INFO: Created: latency-svc-lcdcg
Jun 18 12:12:25.275: INFO: Got endpoints: latency-svc-xkpt4 [749.346325ms]
Jun 18 12:12:25.308: INFO: Created: latency-svc-rjdh4
Jun 18 12:12:25.326: INFO: Got endpoints: latency-svc-4ftnc [750.561246ms]
Jun 18 12:12:25.375: INFO: Got endpoints: latency-svc-zncqc [749.717394ms]
Jun 18 12:12:25.377: INFO: Created: latency-svc-rqg4l
Jun 18 12:12:25.404: INFO: Created: latency-svc-pdjkv
Jun 18 12:12:25.426: INFO: Got endpoints: latency-svc-qt6gx [750.411356ms]
Jun 18 12:12:25.460: INFO: Created: latency-svc-vhrvj
Jun 18 12:12:25.476: INFO: Got endpoints: latency-svc-nqqzn [750.576879ms]
Jun 18 12:12:25.506: INFO: Created: latency-svc-9ln45
Jun 18 12:12:25.528: INFO: Got endpoints: latency-svc-sm794 [752.321294ms]
Jun 18 12:12:25.578: INFO: Got endpoints: latency-svc-k7d7c [751.608325ms]
Jun 18 12:12:25.627: INFO: Got endpoints: latency-svc-9cd4j [751.247572ms]
Jun 18 12:12:25.679: INFO: Got endpoints: latency-svc-q69vb [752.914833ms]
Jun 18 12:12:25.729: INFO: Got endpoints: latency-svc-wcqpc [748.15402ms]
Jun 18 12:12:25.760: INFO: Created: latency-svc-s8nww
Jun 18 12:12:25.776: INFO: Got endpoints: latency-svc-h8bsm [749.707081ms]
Jun 18 12:12:25.776: INFO: Created: latency-svc-ngpb9
Jun 18 12:12:25.795: INFO: Created: latency-svc-zlw8c
Jun 18 12:12:25.812: INFO: Created: latency-svc-kn8k8
Jun 18 12:12:25.826: INFO: Got endpoints: latency-svc-fvmcd [750.92495ms]
Jun 18 12:12:25.829: INFO: Created: latency-svc-pzfcd
Jun 18 12:12:25.847: INFO: Created: latency-svc-cbj4p
Jun 18 12:12:25.865: INFO: Created: latency-svc-nvcvx
Jun 18 12:12:25.876: INFO: Got endpoints: latency-svc-t6scc [751.020321ms]
Jun 18 12:12:25.910: INFO: Created: latency-svc-cqp55
Jun 18 12:12:25.926: INFO: Got endpoints: latency-svc-cthd5 [749.909019ms]
Jun 18 12:12:25.957: INFO: Created: latency-svc-mj4vk
Jun 18 12:12:25.977: INFO: Got endpoints: latency-svc-lcdcg [747.610365ms]
Jun 18 12:12:26.010: INFO: Created: latency-svc-4zfrf
Jun 18 12:12:26.030: INFO: Got endpoints: latency-svc-rjdh4 [754.429987ms]
Jun 18 12:12:26.064: INFO: Created: latency-svc-z5mnz
Jun 18 12:12:26.079: INFO: Got endpoints: latency-svc-rqg4l [752.219013ms]
Jun 18 12:12:26.116: INFO: Created: latency-svc-zxvfz
Jun 18 12:12:26.127: INFO: Got endpoints: latency-svc-pdjkv [752.406732ms]
Jun 18 12:12:26.158: INFO: Created: latency-svc-plcrx
Jun 18 12:12:26.176: INFO: Got endpoints: latency-svc-vhrvj [749.63327ms]
Jun 18 12:12:26.207: INFO: Created: latency-svc-z2ddm
Jun 18 12:12:26.226: INFO: Got endpoints: latency-svc-9ln45 [750.117632ms]
Jun 18 12:12:26.257: INFO: Created: latency-svc-8cckf
Jun 18 12:12:26.276: INFO: Got endpoints: latency-svc-s8nww [748.858357ms]
Jun 18 12:12:26.310: INFO: Created: latency-svc-qtp6n
Jun 18 12:12:26.327: INFO: Got endpoints: latency-svc-ngpb9 [748.614553ms]
Jun 18 12:12:26.361: INFO: Created: latency-svc-82v2d
Jun 18 12:12:26.379: INFO: Got endpoints: latency-svc-zlw8c [751.878489ms]
Jun 18 12:12:26.416: INFO: Created: latency-svc-pvctk
Jun 18 12:12:26.427: INFO: Got endpoints: latency-svc-kn8k8 [748.838258ms]
Jun 18 12:12:26.458: INFO: Created: latency-svc-vnmh9
Jun 18 12:12:26.477: INFO: Got endpoints: latency-svc-pzfcd [747.869033ms]
Jun 18 12:12:26.511: INFO: Created: latency-svc-z5d8r
Jun 18 12:12:26.525: INFO: Got endpoints: latency-svc-cbj4p [749.547835ms]
Jun 18 12:12:26.561: INFO: Created: latency-svc-2fjzk
Jun 18 12:12:26.576: INFO: Got endpoints: latency-svc-nvcvx [749.31538ms]
Jun 18 12:12:26.606: INFO: Created: latency-svc-xn4l2
Jun 18 12:12:26.630: INFO: Got endpoints: latency-svc-cqp55 [753.646306ms]
Jun 18 12:12:26.660: INFO: Created: latency-svc-bv86n
Jun 18 12:12:26.677: INFO: Got endpoints: latency-svc-mj4vk [750.908599ms]
Jun 18 12:12:26.707: INFO: Created: latency-svc-xgfsj
Jun 18 12:12:26.726: INFO: Got endpoints: latency-svc-4zfrf [749.120544ms]
Jun 18 12:12:26.757: INFO: Created: latency-svc-qs66c
Jun 18 12:12:26.776: INFO: Got endpoints: latency-svc-z5mnz [746.378785ms]
Jun 18 12:12:26.810: INFO: Created: latency-svc-xtjvn
Jun 18 12:12:26.825: INFO: Got endpoints: latency-svc-zxvfz [746.329454ms]
Jun 18 12:12:26.858: INFO: Created: latency-svc-49lm2
Jun 18 12:12:26.876: INFO: Got endpoints: latency-svc-plcrx [749.145907ms]
Jun 18 12:12:26.909: INFO: Created: latency-svc-hsmzx
Jun 18 12:12:26.926: INFO: Got endpoints: latency-svc-z2ddm [750.184676ms]
Jun 18 12:12:26.969: INFO: Created: latency-svc-j9gc2
Jun 18 12:12:26.975: INFO: Got endpoints: latency-svc-8cckf [748.941277ms]
Jun 18 12:12:27.025: INFO: Got endpoints: latency-svc-qtp6n [748.95904ms]
Jun 18 12:12:27.077: INFO: Got endpoints: latency-svc-82v2d [750.49935ms]
Jun 18 12:12:27.126: INFO: Got endpoints: latency-svc-pvctk [747.116792ms]
Jun 18 12:12:27.176: INFO: Got endpoints: latency-svc-vnmh9 [748.448081ms]
Jun 18 12:12:27.228: INFO: Got endpoints: latency-svc-z5d8r [751.711252ms]
Jun 18 12:12:27.277: INFO: Got endpoints: latency-svc-2fjzk [750.846441ms]
Jun 18 12:12:27.326: INFO: Got endpoints: latency-svc-xn4l2 [750.578321ms]
Jun 18 12:12:27.376: INFO: Got endpoints: latency-svc-bv86n [746.172119ms]
Jun 18 12:12:27.425: INFO: Got endpoints: latency-svc-xgfsj [748.666435ms]
Jun 18 12:12:27.476: INFO: Got endpoints: latency-svc-qs66c [749.814621ms]
Jun 18 12:12:27.526: INFO: Got endpoints: latency-svc-xtjvn [750.083959ms]
Jun 18 12:12:27.575: INFO: Got endpoints: latency-svc-49lm2 [750.233063ms]
Jun 18 12:12:27.627: INFO: Got endpoints: latency-svc-hsmzx [750.745316ms]
Jun 18 12:12:27.675: INFO: Got endpoints: latency-svc-j9gc2 [748.488411ms]
Jun 18 12:12:28.131: INFO: Created: latency-svc-8tcs9
Jun 18 12:12:28.136: INFO: Created: latency-svc-bcbft
Jun 18 12:12:28.136: INFO: Created: latency-svc-hmdqr
Jun 18 12:12:28.138: INFO: Created: latency-svc-t8vpp
Jun 18 12:12:28.139: INFO: Created: latency-svc-zv4hn
Jun 18 12:12:28.141: INFO: Created: latency-svc-zjm4w
Jun 18 12:12:28.141: INFO: Created: latency-svc-dvwdp
Jun 18 12:12:28.142: INFO: Got endpoints: latency-svc-8tcs9 [1.166667247s]
Jun 18 12:12:28.145: INFO: Created: latency-svc-zpd95
Jun 18 12:12:28.146: INFO: Created: latency-svc-nczdw
Jun 18 12:12:28.148: INFO: Created: latency-svc-hpm7d
Jun 18 12:12:28.150: INFO: Created: latency-svc-5r6bp
Jun 18 12:12:28.155: INFO: Got endpoints: latency-svc-bcbft [1.129471701s]
Jun 18 12:12:28.156: INFO: Created: latency-svc-vzkt7
Jun 18 12:12:28.157: INFO: Created: latency-svc-22gxv
Jun 18 12:12:28.157: INFO: Created: latency-svc-84qhf
Jun 18 12:12:28.158: INFO: Got endpoints: latency-svc-hmdqr [1.08090827s]
Jun 18 12:12:28.160: INFO: Created: latency-svc-t64k2
Jun 18 12:12:28.160: INFO: Got endpoints: latency-svc-zv4hn [1.034064557s]
Jun 18 12:12:28.161: INFO: Got endpoints: latency-svc-t8vpp [985.272271ms]
Jun 18 12:12:28.162: INFO: Got endpoints: latency-svc-dvwdp [933.908882ms]
Jun 18 12:12:28.169: INFO: Got endpoints: latency-svc-zjm4w [892.781499ms]
Jun 18 12:12:28.171: INFO: Got endpoints: latency-svc-zpd95 [844.081324ms]
Jun 18 12:12:28.176: INFO: Got endpoints: latency-svc-hpm7d [750.602847ms]
Jun 18 12:12:28.176: INFO: Got endpoints: latency-svc-nczdw [799.958753ms]
Jun 18 12:12:28.186: INFO: Created: latency-svc-52wt6
Jun 18 12:12:28.200: INFO: Created: latency-svc-d7bvm
Jun 18 12:12:28.228: INFO: Got endpoints: latency-svc-84qhf [752.135028ms]
Jun 18 12:12:28.229: INFO: Created: latency-svc-2jl2k
Jun 18 12:12:28.250: INFO: Created: latency-svc-cqghj
Jun 18 12:12:28.270: INFO: Created: latency-svc-ncrdb
Jun 18 12:12:28.279: INFO: Got endpoints: latency-svc-5r6bp [752.667581ms]
Jun 18 12:12:28.295: INFO: Created: latency-svc-4fwzs
Jun 18 12:12:28.322: INFO: Created: latency-svc-b95cq
Jun 18 12:12:28.330: INFO: Got endpoints: latency-svc-t64k2 [754.285679ms]
Jun 18 12:12:28.344: INFO: Created: latency-svc-j99nc
Jun 18 12:12:28.360: INFO: Created: latency-svc-wkr9v
Jun 18 12:12:28.377: INFO: Got endpoints: latency-svc-22gxv [749.941382ms]
Jun 18 12:12:28.382: INFO: Created: latency-svc-swcx9
Jun 18 12:12:28.398: INFO: Created: latency-svc-l2fwd
Jun 18 12:12:28.418: INFO: Created: latency-svc-vz84w
Jun 18 12:12:28.428: INFO: Got endpoints: latency-svc-vzkt7 [753.486004ms]
Jun 18 12:12:28.434: INFO: Created: latency-svc-89vp4
Jun 18 12:12:28.450: INFO: Created: latency-svc-rw98k
Jun 18 12:12:28.471: INFO: Created: latency-svc-42wt7
Jun 18 12:12:28.475: INFO: Got endpoints: latency-svc-52wt6 [333.13616ms]
Jun 18 12:12:28.508: INFO: Created: latency-svc-7qbr9
Jun 18 12:12:28.527: INFO: Got endpoints: latency-svc-d7bvm [371.468125ms]
Jun 18 12:12:28.561: INFO: Created: latency-svc-kd2nn
Jun 18 12:12:28.577: INFO: Got endpoints: latency-svc-2jl2k [418.916476ms]
Jun 18 12:12:28.609: INFO: Created: latency-svc-vtc8k
Jun 18 12:12:28.627: INFO: Got endpoints: latency-svc-cqghj [466.690955ms]
Jun 18 12:12:28.662: INFO: Created: latency-svc-spmmj
Jun 18 12:12:28.675: INFO: Got endpoints: latency-svc-ncrdb [514.045884ms]
Jun 18 12:12:28.708: INFO: Created: latency-svc-j2zv7
Jun 18 12:12:28.725: INFO: Got endpoints: latency-svc-4fwzs [562.686061ms]
Jun 18 12:12:28.759: INFO: Created: latency-svc-8plwf
Jun 18 12:12:28.777: INFO: Got endpoints: latency-svc-b95cq [607.072685ms]
Jun 18 12:12:28.808: INFO: Created: latency-svc-k4wvc
Jun 18 12:12:28.828: INFO: Got endpoints: latency-svc-j99nc [657.540814ms]
Jun 18 12:12:28.860: INFO: Created: latency-svc-8mlkj
Jun 18 12:12:28.876: INFO: Got endpoints: latency-svc-wkr9v [700.298727ms]
Jun 18 12:12:28.915: INFO: Created: latency-svc-gctpm
Jun 18 12:12:28.926: INFO: Got endpoints: latency-svc-swcx9 [749.146795ms]
Jun 18 12:12:28.959: INFO: Created: latency-svc-cr8jc
Jun 18 12:12:28.977: INFO: Got endpoints: latency-svc-l2fwd [748.729938ms]
Jun 18 12:12:29.009: INFO: Created: latency-svc-jpbx9
Jun 18 12:12:29.027: INFO: Got endpoints: latency-svc-vz84w [747.296959ms]
Jun 18 12:12:29.057: INFO: Created: latency-svc-7qq42
Jun 18 12:12:29.076: INFO: Got endpoints: latency-svc-89vp4 [746.108379ms]
Jun 18 12:12:29.108: INFO: Created: latency-svc-jq49v
Jun 18 12:12:29.125: INFO: Got endpoints: latency-svc-rw98k [747.66056ms]
Jun 18 12:12:29.156: INFO: Created: latency-svc-qvm9t
Jun 18 12:12:29.184: INFO: Got endpoints: latency-svc-42wt7 [755.843493ms]
Jun 18 12:12:29.216: INFO: Created: latency-svc-7xc8f
Jun 18 12:12:29.225: INFO: Got endpoints: latency-svc-7qbr9 [750.027218ms]
Jun 18 12:12:29.255: INFO: Created: latency-svc-zpzhv
Jun 18 12:12:29.276: INFO: Got endpoints: latency-svc-kd2nn [748.916509ms]
Jun 18 12:12:29.312: INFO: Created: latency-svc-zzf7m
Jun 18 12:12:29.330: INFO: Got endpoints: latency-svc-vtc8k [752.874824ms]
Jun 18 12:12:29.380: INFO: Got endpoints: latency-svc-spmmj [753.179238ms]
Jun 18 12:12:29.429: INFO: Got endpoints: latency-svc-j2zv7 [753.564559ms]
Jun 18 12:12:29.476: INFO: Got endpoints: latency-svc-8plwf [750.420558ms]
Jun 18 12:12:29.528: INFO: Got endpoints: latency-svc-k4wvc [751.389777ms]
Jun 18 12:12:29.576: INFO: Got endpoints: latency-svc-8mlkj [747.821518ms]
Jun 18 12:12:29.626: INFO: Got endpoints: latency-svc-gctpm [749.194014ms]
Jun 18 12:12:29.677: INFO: Got endpoints: latency-svc-cr8jc [751.327994ms]
Jun 18 12:12:29.726: INFO: Got endpoints: latency-svc-jpbx9 [749.138402ms]
Jun 18 12:12:29.789: INFO: Got endpoints: latency-svc-7qq42 [762.672184ms]
Jun 18 12:12:29.825: INFO: Got endpoints: latency-svc-jq49v [749.469013ms]
Jun 18 12:12:29.877: INFO: Got endpoints: latency-svc-qvm9t [751.535542ms]
Jun 18 12:12:29.926: INFO: Got endpoints: latency-svc-7xc8f [741.586066ms]
Jun 18 12:12:29.975: INFO: Got endpoints: latency-svc-zpzhv [750.127033ms]
Jun 18 12:12:30.026: INFO: Got endpoints: latency-svc-zzf7m [749.972907ms]
Jun 18 12:12:30.026: INFO: Latencies: [102.180344ms 120.248753ms 135.813347ms 153.228533ms 170.926692ms 196.4617ms 211.843627ms 228.146356ms 248.48844ms 267.272925ms 280.518968ms 281.112973ms 281.590495ms 281.886503ms 283.805804ms 284.238801ms 284.725913ms 285.012838ms 286.358506ms 286.57377ms 287.198588ms 287.497253ms 290.935501ms 297.268496ms 302.997155ms 304.58996ms 333.13616ms 341.839025ms 344.938025ms 369.624646ms 371.468125ms 373.289216ms 373.35196ms 374.987012ms 375.200433ms 375.398314ms 377.626535ms 378.573447ms 379.656037ms 380.438672ms 382.877396ms 383.253552ms 383.391309ms 386.851459ms 389.670609ms 394.031427ms 405.426607ms 418.916476ms 423.582557ms 428.527881ms 432.485424ms 434.290341ms 434.702512ms 437.191241ms 438.540147ms 439.011195ms 440.261183ms 441.875561ms 442.107251ms 443.521062ms 453.549171ms 466.690955ms 483.589495ms 486.431252ms 510.893392ms 512.443396ms 514.045884ms 520.951558ms 544.048989ms 562.686061ms 571.793858ms 596.991912ms 607.072685ms 637.256025ms 657.540814ms 665.823313ms 699.051929ms 700.298727ms 731.611388ms 741.586066ms 743.039834ms 746.108379ms 746.172119ms 746.329454ms 746.378785ms 747.116792ms 747.296959ms 747.535821ms 747.610365ms 747.66056ms 747.721798ms 747.821518ms 747.869033ms 748.091555ms 748.15402ms 748.176977ms 748.448081ms 748.488411ms 748.586102ms 748.614553ms 748.626796ms 748.666435ms 748.729938ms 748.793237ms 748.836015ms 748.838258ms 748.858357ms 748.916509ms 748.941277ms 748.95904ms 749.103554ms 749.120544ms 749.138402ms 749.145907ms 749.146795ms 749.194014ms 749.226253ms 749.287416ms 749.295845ms 749.31538ms 749.346325ms 749.469013ms 749.547835ms 749.566906ms 749.63327ms 749.707081ms 749.710213ms 749.717394ms 749.71911ms 749.741971ms 749.775561ms 749.814621ms 749.862677ms 749.909019ms 749.91922ms 749.941382ms 749.959385ms 749.972907ms 750.027218ms 750.077609ms 750.083959ms 750.117632ms 750.127033ms 750.161137ms 750.184676ms 750.22507ms 750.233063ms 750.322886ms 750.330996ms 750.360782ms 750.384058ms 750.411356ms 750.420558ms 750.49935ms 750.561246ms 750.576879ms 750.578321ms 750.602847ms 750.745316ms 750.846441ms 750.908599ms 750.92495ms 751.020321ms 751.247572ms 751.327994ms 751.389777ms 751.535542ms 751.553736ms 751.608325ms 751.711252ms 751.878489ms 752.135028ms 752.219013ms 752.321294ms 752.406732ms 752.656617ms 752.667581ms 752.696787ms 752.874824ms 752.914833ms 753.179238ms 753.486004ms 753.564559ms 753.646306ms 754.117246ms 754.285679ms 754.331939ms 754.429987ms 755.843493ms 756.498871ms 762.672184ms 799.958753ms 844.081324ms 892.781499ms 933.908882ms 985.272271ms 1.034064557s 1.08090827s 1.129471701s 1.166667247s]
Jun 18 12:12:30.026: INFO: 50 %ile: 748.626796ms
Jun 18 12:12:30.026: INFO: 90 %ile: 753.179238ms
Jun 18 12:12:30.026: INFO: 99 %ile: 1.129471701s
Jun 18 12:12:30.026: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:12:30.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-2s59d" for this suite.
Jun 18 12:12:56.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:12:56.460: INFO: namespace: e2e-tests-svc-latency-2s59d, resource: bindings, ignored listing per whitelist
Jun 18 12:12:56.661: INFO: namespace e2e-tests-svc-latency-2s59d deletion completed in 26.620577396s

• [SLOW TEST:37.899 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:12:56.664: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-kr6vw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:12:57.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kr6vw" for this suite.
Jun 18 12:13:03.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:13:04.945: INFO: namespace: e2e-tests-services-kr6vw, resource: bindings, ignored listing per whitelist
Jun 18 12:13:05.083: INFO: namespace e2e-tests-services-kr6vw deletion completed in 7.919125189s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:8.420 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:13:05.085: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-k27sq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-plvhh in namespace e2e-tests-proxy-k27sq
I0618 12:13:05.603606      17 runners.go:184] Created replication controller with name: proxy-service-plvhh, namespace: e2e-tests-proxy-k27sq, replica count: 1
I0618 12:13:06.654052      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0618 12:13:07.654344      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0618 12:13:08.654567      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0618 12:13:09.654805      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0618 12:13:10.655108      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:11.655471      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:12.655742      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:13.656041      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:14.656289      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:15.656602      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:16.656832      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:17.657047      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:18.657259      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0618 12:13:19.657453      17 runners.go:184] proxy-service-plvhh Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 18 12:13:19.698: INFO: setup took 14.143300995s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jun 18 12:13:19.736: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 38.133871ms)
Jun 18 12:13:19.736: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 38.041808ms)
Jun 18 12:13:19.740: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 41.211644ms)
Jun 18 12:13:19.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 43.804906ms)
Jun 18 12:13:19.743: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 45.131747ms)
Jun 18 12:13:19.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 45.694581ms)
Jun 18 12:13:19.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 46.01147ms)
Jun 18 12:13:19.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 45.848152ms)
Jun 18 12:13:19.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 55.214828ms)
Jun 18 12:13:19.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 55.346138ms)
Jun 18 12:13:19.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 55.552533ms)
Jun 18 12:13:19.763: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 64.742483ms)
Jun 18 12:13:19.763: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 64.6533ms)
Jun 18 12:13:19.763: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 64.959256ms)
Jun 18 12:13:19.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 71.152468ms)
Jun 18 12:13:19.774: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 75.781121ms)
Jun 18 12:13:19.798: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 23.667649ms)
Jun 18 12:13:19.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 32.082723ms)
Jun 18 12:13:19.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 32.018733ms)
Jun 18 12:13:19.806: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 32.209556ms)
Jun 18 12:13:19.807: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 32.954703ms)
Jun 18 12:13:19.807: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 32.957866ms)
Jun 18 12:13:19.808: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 33.227523ms)
Jun 18 12:13:19.808: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 33.378344ms)
Jun 18 12:13:19.808: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 33.450829ms)
Jun 18 12:13:19.808: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 33.074263ms)
Jun 18 12:13:19.808: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 33.416635ms)
Jun 18 12:13:19.808: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 33.310981ms)
Jun 18 12:13:19.808: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 33.343036ms)
Jun 18 12:13:19.815: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 40.740933ms)
Jun 18 12:13:19.815: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 40.44133ms)
Jun 18 12:13:19.815: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 41.212313ms)
Jun 18 12:13:19.846: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 30.170205ms)
Jun 18 12:13:19.849: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 33.02287ms)
Jun 18 12:13:19.850: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 33.769375ms)
Jun 18 12:13:19.850: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 33.976711ms)
Jun 18 12:13:19.850: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 33.568386ms)
Jun 18 12:13:19.850: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 33.527725ms)
Jun 18 12:13:19.850: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 33.74956ms)
Jun 18 12:13:19.854: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 37.337733ms)
Jun 18 12:13:19.854: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 37.543737ms)
Jun 18 12:13:19.855: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 39.017373ms)
Jun 18 12:13:19.856: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 39.566045ms)
Jun 18 12:13:19.856: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 40.191424ms)
Jun 18 12:13:19.859: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 43.758006ms)
Jun 18 12:13:19.859: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 43.226861ms)
Jun 18 12:13:19.859: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 43.843478ms)
Jun 18 12:13:19.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 49.610537ms)
Jun 18 12:13:19.889: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 23.571888ms)
Jun 18 12:13:19.904: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 38.111617ms)
Jun 18 12:13:19.906: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 39.67156ms)
Jun 18 12:13:19.906: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 39.915212ms)
Jun 18 12:13:19.906: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 39.873576ms)
Jun 18 12:13:19.906: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 40.285833ms)
Jun 18 12:13:19.906: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 40.001555ms)
Jun 18 12:13:19.906: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 40.099178ms)
Jun 18 12:13:19.906: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 39.970822ms)
Jun 18 12:13:19.907: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 40.770123ms)
Jun 18 12:13:19.908: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 41.525469ms)
Jun 18 12:13:19.908: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 41.46987ms)
Jun 18 12:13:19.907: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 41.027855ms)
Jun 18 12:13:19.908: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 41.453323ms)
Jun 18 12:13:19.914: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 47.455351ms)
Jun 18 12:13:19.914: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 47.693131ms)
Jun 18 12:13:19.936: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 21.988066ms)
Jun 18 12:13:19.940: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 25.02834ms)
Jun 18 12:13:19.941: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 26.065165ms)
Jun 18 12:13:19.941: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 26.310419ms)
Jun 18 12:13:19.941: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 26.407526ms)
Jun 18 12:13:19.941: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 26.688009ms)
Jun 18 12:13:19.941: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 26.214389ms)
Jun 18 12:13:19.941: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 26.076123ms)
Jun 18 12:13:19.941: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 26.944584ms)
Jun 18 12:13:19.941: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 27.033551ms)
Jun 18 12:13:19.949: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 34.831953ms)
Jun 18 12:13:19.949: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 34.714829ms)
Jun 18 12:13:19.949: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 34.304838ms)
Jun 18 12:13:19.949: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 35.0562ms)
Jun 18 12:13:19.951: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 35.591329ms)
Jun 18 12:13:19.951: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 35.915556ms)
Jun 18 12:13:19.973: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 21.624904ms)
Jun 18 12:13:19.978: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 26.008518ms)
Jun 18 12:13:19.978: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 25.946088ms)
Jun 18 12:13:19.978: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 26.592518ms)
Jun 18 12:13:19.979: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 27.162148ms)
Jun 18 12:13:19.979: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 27.07865ms)
Jun 18 12:13:19.979: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 27.230696ms)
Jun 18 12:13:19.979: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 27.002716ms)
Jun 18 12:13:19.979: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 27.34701ms)
Jun 18 12:13:19.979: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 27.84892ms)
Jun 18 12:13:19.984: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 33.023749ms)
Jun 18 12:13:19.985: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 33.79163ms)
Jun 18 12:13:19.986: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 33.737651ms)
Jun 18 12:13:19.986: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 35.233902ms)
Jun 18 12:13:19.987: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 35.134659ms)
Jun 18 12:13:19.987: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 35.121094ms)
Jun 18 12:13:20.010: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 22.574263ms)
Jun 18 12:13:20.015: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 27.049801ms)
Jun 18 12:13:20.015: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 27.618342ms)
Jun 18 12:13:20.015: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 27.508019ms)
Jun 18 12:13:20.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 28.486939ms)
Jun 18 12:13:20.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 28.424261ms)
Jun 18 12:13:20.016: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 28.694589ms)
Jun 18 12:13:20.020: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 32.20575ms)
Jun 18 12:13:20.020: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 32.43904ms)
Jun 18 12:13:20.021: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 33.503394ms)
Jun 18 12:13:20.023: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 35.460778ms)
Jun 18 12:13:20.027: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 39.262282ms)
Jun 18 12:13:20.027: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 39.516695ms)
Jun 18 12:13:20.027: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 39.59412ms)
Jun 18 12:13:20.027: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 39.562092ms)
Jun 18 12:13:20.028: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 40.184097ms)
Jun 18 12:13:20.049: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 21.676738ms)
Jun 18 12:13:20.055: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 27.453144ms)
Jun 18 12:13:20.056: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 27.848113ms)
Jun 18 12:13:20.056: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 28.30097ms)
Jun 18 12:13:20.057: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 28.445427ms)
Jun 18 12:13:20.060: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 31.635979ms)
Jun 18 12:13:20.060: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 31.995526ms)
Jun 18 12:13:20.060: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 31.952535ms)
Jun 18 12:13:20.061: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 32.470346ms)
Jun 18 12:13:20.061: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 33.266371ms)
Jun 18 12:13:20.062: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 33.859509ms)
Jun 18 12:13:20.065: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 37.115759ms)
Jun 18 12:13:20.065: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 37.023786ms)
Jun 18 12:13:20.069: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 40.795737ms)
Jun 18 12:13:20.070: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 41.614719ms)
Jun 18 12:13:20.070: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 41.572806ms)
Jun 18 12:13:20.095: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 24.529464ms)
Jun 18 12:13:20.095: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 24.714609ms)
Jun 18 12:13:20.100: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 29.944446ms)
Jun 18 12:13:20.101: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 30.769628ms)
Jun 18 12:13:20.101: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 31.114037ms)
Jun 18 12:13:20.102: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 31.327819ms)
Jun 18 12:13:20.102: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 31.568171ms)
Jun 18 12:13:20.101: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 31.156357ms)
Jun 18 12:13:20.102: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 31.311439ms)
Jun 18 12:13:20.102: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 31.531541ms)
Jun 18 12:13:20.108: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 37.551192ms)
Jun 18 12:13:20.108: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 37.607697ms)
Jun 18 12:13:20.108: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 37.742341ms)
Jun 18 12:13:20.109: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 39.077756ms)
Jun 18 12:13:20.109: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 38.572801ms)
Jun 18 12:13:20.109: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 38.638003ms)
Jun 18 12:13:20.131: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 21.739206ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 30.42784ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 30.105164ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 30.654638ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 30.4744ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 30.625627ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 30.669242ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 30.986162ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 30.88988ms)
Jun 18 12:13:20.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 31.086847ms)
Jun 18 12:13:20.142: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 32.472777ms)
Jun 18 12:13:20.146: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 36.448791ms)
Jun 18 12:13:20.149: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 39.582218ms)
Jun 18 12:13:20.149: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 39.631588ms)
Jun 18 12:13:20.151: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 40.750264ms)
Jun 18 12:13:20.151: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 41.100821ms)
Jun 18 12:13:20.173: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 22.158266ms)
Jun 18 12:13:20.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 27.343465ms)
Jun 18 12:13:20.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 27.052462ms)
Jun 18 12:13:20.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 27.546867ms)
Jun 18 12:13:20.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 28.294968ms)
Jun 18 12:13:20.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 28.086074ms)
Jun 18 12:13:20.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 27.368686ms)
Jun 18 12:13:20.180: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 28.145352ms)
Jun 18 12:13:20.180: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 28.741803ms)
Jun 18 12:13:20.180: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 28.165329ms)
Jun 18 12:13:20.185: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 33.213084ms)
Jun 18 12:13:20.186: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 34.029952ms)
Jun 18 12:13:20.188: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 36.881495ms)
Jun 18 12:13:20.188: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 36.44749ms)
Jun 18 12:13:20.188: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 36.757536ms)
Jun 18 12:13:20.188: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 37.155118ms)
Jun 18 12:13:20.212: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 23.297261ms)
Jun 18 12:13:20.218: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 29.542514ms)
Jun 18 12:13:20.218: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 28.935692ms)
Jun 18 12:13:20.218: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 29.409807ms)
Jun 18 12:13:20.219: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 29.851168ms)
Jun 18 12:13:20.220: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 31.927931ms)
Jun 18 12:13:20.221: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 31.584019ms)
Jun 18 12:13:20.221: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 31.669409ms)
Jun 18 12:13:20.221: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 31.670225ms)
Jun 18 12:13:20.221: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 31.506456ms)
Jun 18 12:13:20.226: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 36.690877ms)
Jun 18 12:13:20.228: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 38.718959ms)
Jun 18 12:13:20.228: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 38.926926ms)
Jun 18 12:13:20.228: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 38.99743ms)
Jun 18 12:13:20.229: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 39.863622ms)
Jun 18 12:13:20.229: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 40.008708ms)
Jun 18 12:13:20.252: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 22.925966ms)
Jun 18 12:13:20.257: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 27.599796ms)
Jun 18 12:13:20.257: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 27.939696ms)
Jun 18 12:13:20.257: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 27.886882ms)
Jun 18 12:13:20.257: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 27.914274ms)
Jun 18 12:13:20.257: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 27.507663ms)
Jun 18 12:13:20.257: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 27.625587ms)
Jun 18 12:13:20.260: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 30.638617ms)
Jun 18 12:13:20.260: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 30.26639ms)
Jun 18 12:13:20.260: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 30.750685ms)
Jun 18 12:13:20.261: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 31.686612ms)
Jun 18 12:13:20.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 32.207745ms)
Jun 18 12:13:20.265: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 35.587927ms)
Jun 18 12:13:20.266: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 36.454139ms)
Jun 18 12:13:20.268: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 38.690079ms)
Jun 18 12:13:20.268: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 38.468245ms)
Jun 18 12:13:20.293: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 25.192529ms)
Jun 18 12:13:20.299: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 30.784573ms)
Jun 18 12:13:20.299: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 30.723191ms)
Jun 18 12:13:20.299: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 30.929452ms)
Jun 18 12:13:20.300: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 31.428869ms)
Jun 18 12:13:20.300: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 31.552367ms)
Jun 18 12:13:20.300: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 31.810499ms)
Jun 18 12:13:20.300: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 32.052559ms)
Jun 18 12:13:20.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 32.116715ms)
Jun 18 12:13:20.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 32.122561ms)
Jun 18 12:13:20.303: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 34.628628ms)
Jun 18 12:13:20.309: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 40.841521ms)
Jun 18 12:13:20.309: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 40.821724ms)
Jun 18 12:13:20.309: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 40.826119ms)
Jun 18 12:13:20.309: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 40.753631ms)
Jun 18 12:13:20.309: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 40.733834ms)
Jun 18 12:13:20.332: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 22.498011ms)
Jun 18 12:13:20.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 28.101415ms)
Jun 18 12:13:20.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 28.614012ms)
Jun 18 12:13:20.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 28.426655ms)
Jun 18 12:13:20.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 28.412959ms)
Jun 18 12:13:20.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 28.705428ms)
Jun 18 12:13:20.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 28.356453ms)
Jun 18 12:13:20.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 28.189722ms)
Jun 18 12:13:20.338: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 28.704998ms)
Jun 18 12:13:20.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 29.388457ms)
Jun 18 12:13:20.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 32.669163ms)
Jun 18 12:13:20.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 32.435976ms)
Jun 18 12:13:20.346: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 36.272055ms)
Jun 18 12:13:20.346: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 36.387264ms)
Jun 18 12:13:20.346: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 36.838456ms)
Jun 18 12:13:20.347: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 36.980956ms)
Jun 18 12:13:20.370: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 23.23336ms)
Jun 18 12:13:20.374: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 27.363991ms)
Jun 18 12:13:20.375: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 27.679816ms)
Jun 18 12:13:20.375: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 28.519419ms)
Jun 18 12:13:20.375: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 28.023014ms)
Jun 18 12:13:20.376: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 28.648068ms)
Jun 18 12:13:20.376: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 28.702143ms)
Jun 18 12:13:20.376: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 28.514788ms)
Jun 18 12:13:20.376: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 29.052281ms)
Jun 18 12:13:20.376: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 28.696351ms)
Jun 18 12:13:20.380: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 32.601871ms)
Jun 18 12:13:20.380: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 32.780423ms)
Jun 18 12:13:20.383: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 36.435346ms)
Jun 18 12:13:20.383: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 36.628077ms)
Jun 18 12:13:20.387: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 39.807976ms)
Jun 18 12:13:20.389: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 42.015195ms)
Jun 18 12:13:20.412: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 23.133377ms)
Jun 18 12:13:20.412: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 23.250537ms)
Jun 18 12:13:20.412: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 23.315133ms)
Jun 18 12:13:20.416: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 27.413436ms)
Jun 18 12:13:20.417: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 27.535693ms)
Jun 18 12:13:20.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 29.474422ms)
Jun 18 12:13:20.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 29.539273ms)
Jun 18 12:13:20.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 29.632002ms)
Jun 18 12:13:20.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 29.622066ms)
Jun 18 12:13:20.419: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 29.647757ms)
Jun 18 12:13:20.423: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 33.723363ms)
Jun 18 12:13:20.423: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 34.001887ms)
Jun 18 12:13:20.423: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 34.11599ms)
Jun 18 12:13:20.427: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 38.090641ms)
Jun 18 12:13:20.427: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 38.059287ms)
Jun 18 12:13:20.427: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 38.188623ms)
Jun 18 12:13:20.451: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 23.246743ms)
Jun 18 12:13:20.460: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 32.314103ms)
Jun 18 12:13:20.460: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 32.589235ms)
Jun 18 12:13:20.460: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 32.797073ms)
Jun 18 12:13:20.461: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 33.823737ms)
Jun 18 12:13:20.461: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 33.821412ms)
Jun 18 12:13:20.461: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 33.851718ms)
Jun 18 12:13:20.461: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 33.878923ms)
Jun 18 12:13:20.462: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 34.722482ms)
Jun 18 12:13:20.462: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 34.547201ms)
Jun 18 12:13:20.462: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 34.621518ms)
Jun 18 12:13:20.462: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 34.443411ms)
Jun 18 12:13:20.469: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 41.854886ms)
Jun 18 12:13:20.471: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 43.027429ms)
Jun 18 12:13:20.471: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 43.032636ms)
Jun 18 12:13:20.471: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 43.433899ms)
Jun 18 12:13:20.494: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 23.071959ms)
Jun 18 12:13:20.494: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 23.210993ms)
Jun 18 12:13:20.501: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 29.70921ms)
Jun 18 12:13:20.503: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 31.263727ms)
Jun 18 12:13:20.503: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 31.947565ms)
Jun 18 12:13:20.503: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 31.914234ms)
Jun 18 12:13:20.503: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 31.875973ms)
Jun 18 12:13:20.503: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 32.039835ms)
Jun 18 12:13:20.503: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 32.023177ms)
Jun 18 12:13:20.503: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 31.951737ms)
Jun 18 12:13:20.506: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 34.433353ms)
Jun 18 12:13:20.511: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 39.798228ms)
Jun 18 12:13:20.512: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 40.053248ms)
Jun 18 12:13:20.512: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 40.212806ms)
Jun 18 12:13:20.512: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 40.267602ms)
Jun 18 12:13:20.512: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 40.199152ms)
Jun 18 12:13:20.541: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:1080/proxy/... (200; 29.175598ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:462/proxy/: tls qux (200; 35.640517ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:1080/proxy/rewri... (200; 35.544196ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:160/proxy/: foo (200; 35.324103ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:460/proxy/: tls baz (200; 35.29255ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46/proxy/rewriteme"... (200; 35.660841ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/proxy-service-plvhh-h9x46:162/proxy/: bar (200; 35.819902ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:160/proxy/: foo (200; 35.419019ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-k27sq/pods/https:proxy-service-plvhh-h9x46:443/proxy/... (200; 35.42118ms)
Jun 18 12:13:20.548: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/pods/http:proxy-service-plvhh-h9x46:162/proxy/: bar (200; 35.742651ms)
Jun 18 12:13:20.549: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname1/proxy/: tls baz (200; 37.104118ms)
Jun 18 12:13:20.549: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/https:proxy-service-plvhh:tlsportname2/proxy/: tls qux (200; 37.334621ms)
Jun 18 12:13:20.556: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname2/proxy/: bar (200; 44.370957ms)
Jun 18 12:13:20.557: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/http:proxy-service-plvhh:portname1/proxy/: foo (200; 44.181544ms)
Jun 18 12:13:20.557: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname1/proxy/: foo (200; 44.492986ms)
Jun 18 12:13:20.557: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-k27sq/services/proxy-service-plvhh:portname2/proxy/: bar (200; 44.634707ms)
STEP: deleting ReplicationController proxy-service-plvhh in namespace e2e-tests-proxy-k27sq, will wait for the garbage collector to delete the pods
Jun 18 12:13:20.647: INFO: Deleting ReplicationController proxy-service-plvhh took: 27.105797ms
Jun 18 12:13:20.748: INFO: Terminating ReplicationController proxy-service-plvhh pods took: 100.281114ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:13:26.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-k27sq" for this suite.
Jun 18 12:13:34.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:13:34.362: INFO: namespace: e2e-tests-proxy-k27sq, resource: bindings, ignored listing per whitelist
Jun 18 12:13:34.682: INFO: namespace e2e-tests-proxy-k27sq deletion completed in 8.614023692s

• [SLOW TEST:29.597 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:13:34.683: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2gfx4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:13:35.210: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ef69536-91c2-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-2gfx4" to be "success or failure"
Jun 18 12:13:35.225: INFO: Pod "downwardapi-volume-7ef69536-91c2-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.145091ms
Jun 18 12:13:37.241: INFO: Pod "downwardapi-volume-7ef69536-91c2-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030458474s
STEP: Saw pod success
Jun 18 12:13:37.241: INFO: Pod "downwardapi-volume-7ef69536-91c2-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:13:37.255: INFO: Trying to get logs from node 10.72.74.144 pod downwardapi-volume-7ef69536-91c2-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:13:37.346: INFO: Waiting for pod downwardapi-volume-7ef69536-91c2-11e9-bce2-ae54e022189f to disappear
Jun 18 12:13:37.361: INFO: Pod downwardapi-volume-7ef69536-91c2-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:13:37.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2gfx4" for this suite.
Jun 18 12:13:43.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:13:44.605: INFO: namespace: e2e-tests-projected-2gfx4, resource: bindings, ignored listing per whitelist
Jun 18 12:13:44.942: INFO: namespace e2e-tests-projected-2gfx4 deletion completed in 7.561471216s

• [SLOW TEST:10.259 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:13:44.942: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xxmfj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:13:45.511: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8522dd8b-91c2-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-xxmfj" to be "success or failure"
Jun 18 12:13:45.528: INFO: Pod "downwardapi-volume-8522dd8b-91c2-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.788664ms
Jun 18 12:13:47.543: INFO: Pod "downwardapi-volume-8522dd8b-91c2-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031190614s
Jun 18 12:13:49.560: INFO: Pod "downwardapi-volume-8522dd8b-91c2-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048455776s
STEP: Saw pod success
Jun 18 12:13:49.560: INFO: Pod "downwardapi-volume-8522dd8b-91c2-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:13:49.574: INFO: Trying to get logs from node 10.72.74.143 pod downwardapi-volume-8522dd8b-91c2-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:13:49.665: INFO: Waiting for pod downwardapi-volume-8522dd8b-91c2-11e9-bce2-ae54e022189f to disappear
Jun 18 12:13:49.679: INFO: Pod downwardapi-volume-8522dd8b-91c2-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:13:49.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xxmfj" for this suite.
Jun 18 12:13:55.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:13:57.341: INFO: namespace: e2e-tests-projected-xxmfj, resource: bindings, ignored listing per whitelist
Jun 18 12:13:57.423: INFO: namespace e2e-tests-projected-xxmfj deletion completed in 7.72432526s

• [SLOW TEST:12.481 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:13:57.423: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8tqhz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 18 12:13:57.906: INFO: Waiting up to 5m0s for pod "pod-8c86065a-91c2-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-8tqhz" to be "success or failure"
Jun 18 12:13:57.919: INFO: Pod "pod-8c86065a-91c2-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.546728ms
Jun 18 12:13:59.935: INFO: Pod "pod-8c86065a-91c2-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029018846s
Jun 18 12:14:01.968: INFO: Pod "pod-8c86065a-91c2-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062227719s
STEP: Saw pod success
Jun 18 12:14:01.968: INFO: Pod "pod-8c86065a-91c2-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:14:01.985: INFO: Trying to get logs from node 10.72.74.143 pod pod-8c86065a-91c2-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:14:02.058: INFO: Waiting for pod pod-8c86065a-91c2-11e9-bce2-ae54e022189f to disappear
Jun 18 12:14:02.072: INFO: Pod pod-8c86065a-91c2-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:14:02.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8tqhz" for this suite.
Jun 18 12:14:10.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:14:10.326: INFO: namespace: e2e-tests-emptydir-8tqhz, resource: bindings, ignored listing per whitelist
Jun 18 12:14:10.657: INFO: namespace e2e-tests-emptydir-8tqhz deletion completed in 8.560759941s

• [SLOW TEST:13.234 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:14:10.660: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xv9w4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 18 12:14:11.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xv9w4'
Jun 18 12:14:11.275: INFO: stderr: ""
Jun 18 12:14:11.275: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jun 18 12:14:16.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xv9w4 -o json'
Jun 18 12:14:16.453: INFO: stderr: ""
Jun 18 12:14:16.453: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-06-18T12:14:11Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-xv9w4\",\n        \"resourceVersion\": \"98337\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-xv9w4/pods/e2e-test-nginx-pod\",\n        \"uid\": \"947f4be7-91c2-11e9-bf44-fa6f350b29f0\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-q2jrc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.72.74.144\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-q2jrc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-q2jrc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-18T12:14:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-18T12:14:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-18T12:14:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-18T12:14:11Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://b332dd0683b1ed72440faea31ebea2f8fe19a233b3272929f92d4b672d56473d\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-06-18T12:14:12Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.72.74.144\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.114.33\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-06-18T12:14:11Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jun 18 12:14:16.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 replace -f - --namespace=e2e-tests-kubectl-xv9w4'
Jun 18 12:14:17.049: INFO: stderr: ""
Jun 18 12:14:17.049: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jun 18 12:14:17.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-xv9w4'
Jun 18 12:14:19.076: INFO: stderr: ""
Jun 18 12:14:19.076: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:14:19.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xv9w4" for this suite.
Jun 18 12:14:25.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:14:25.608: INFO: namespace: e2e-tests-kubectl-xv9w4, resource: bindings, ignored listing per whitelist
Jun 18 12:14:25.647: INFO: namespace e2e-tests-kubectl-xv9w4 deletion completed in 6.5493873s

• [SLOW TEST:14.988 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:14:25.648: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6zvks
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 18 12:14:26.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6zvks'
Jun 18 12:14:26.342: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 18 12:14:26.342: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jun 18 12:14:28.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-6zvks'
Jun 18 12:14:28.545: INFO: stderr: ""
Jun 18 12:14:28.546: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:14:28.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6zvks" for this suite.
Jun 18 12:14:36.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:14:36.726: INFO: namespace: e2e-tests-kubectl-6zvks, resource: bindings, ignored listing per whitelist
Jun 18 12:14:37.166: INFO: namespace e2e-tests-kubectl-6zvks deletion completed in 8.560805443s

• [SLOW TEST:11.518 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:14:37.166: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fx2mp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jun 18 12:14:37.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-fx2mp'
Jun 18 12:14:37.903: INFO: stderr: ""
Jun 18 12:14:37.903: INFO: stdout: "pod/pause created\n"
Jun 18 12:14:37.903: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jun 18 12:14:37.903: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-fx2mp" to be "running and ready"
Jun 18 12:14:37.918: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 14.593961ms
Jun 18 12:14:39.950: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046181934s
Jun 18 12:14:41.964: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.060668848s
Jun 18 12:14:41.964: INFO: Pod "pause" satisfied condition "running and ready"
Jun 18 12:14:41.964: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jun 18 12:14:41.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-fx2mp'
Jun 18 12:14:42.204: INFO: stderr: ""
Jun 18 12:14:42.204: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jun 18 12:14:42.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pod pause -L testing-label --namespace=e2e-tests-kubectl-fx2mp'
Jun 18 12:14:42.339: INFO: stderr: ""
Jun 18 12:14:42.339: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jun 18 12:14:42.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 label pods pause testing-label- --namespace=e2e-tests-kubectl-fx2mp'
Jun 18 12:14:42.495: INFO: stderr: ""
Jun 18 12:14:42.495: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jun 18 12:14:42.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pod pause -L testing-label --namespace=e2e-tests-kubectl-fx2mp'
Jun 18 12:14:42.624: INFO: stderr: ""
Jun 18 12:14:42.624: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jun 18 12:14:42.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fx2mp'
Jun 18 12:14:42.811: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 12:14:42.811: INFO: stdout: "pod \"pause\" force deleted\n"
Jun 18 12:14:42.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-fx2mp'
Jun 18 12:14:42.960: INFO: stderr: "No resources found.\n"
Jun 18 12:14:42.960: INFO: stdout: ""
Jun 18 12:14:42.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -l name=pause --namespace=e2e-tests-kubectl-fx2mp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 18 12:14:43.112: INFO: stderr: ""
Jun 18 12:14:43.112: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:14:43.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fx2mp" for this suite.
Jun 18 12:14:51.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:14:51.347: INFO: namespace: e2e-tests-kubectl-fx2mp, resource: bindings, ignored listing per whitelist
Jun 18 12:14:51.838: INFO: namespace e2e-tests-kubectl-fx2mp deletion completed in 8.707340522s

• [SLOW TEST:14.672 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:14:51.839: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kx8vz
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-ad023d3d-91c2-11e9-bce2-ae54e022189f
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ad023d3d-91c2-11e9-bce2-ae54e022189f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:14:56.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kx8vz" for this suite.
Jun 18 12:15:20.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:15:20.869: INFO: namespace: e2e-tests-configmap-kx8vz, resource: bindings, ignored listing per whitelist
Jun 18 12:15:21.238: INFO: namespace e2e-tests-configmap-kx8vz deletion completed in 24.552791258s

• [SLOW TEST:29.399 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:15:21.238: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-bz2kw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jun 18 12:15:23.761: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-be790474-91c2-11e9-bce2-ae54e022189f,GenerateName:,Namespace:e2e-tests-events-bz2kw,SelfLink:/api/v1/namespaces/e2e-tests-events-bz2kw/pods/send-events-be790474-91c2-11e9-bce2-ae54e022189f,UID:be7bb817-91c2-11e9-bf44-fa6f350b29f0,ResourceVersion:98634,Generation:0,CreationTimestamp:2019-06-18 12:15:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 679583437,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zlxb5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zlxb5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-zlxb5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0002f4f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0002f59f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:15:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:15:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:15:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:15:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:172.30.39.49,StartTime:2019-06-18 12:15:21 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-06-18 12:15:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://1a091482f806d7420678be509ce49e38fabecc3b22f6117e46a5b544be78e3cc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jun 18 12:15:26.023: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jun 18 12:15:28.036: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:15:28.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-bz2kw" for this suite.
Jun 18 12:16:10.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:16:11.309: INFO: namespace: e2e-tests-events-bz2kw, resource: bindings, ignored listing per whitelist
Jun 18 12:16:11.620: INFO: namespace e2e-tests-events-bz2kw deletion completed in 43.539530001s

• [SLOW TEST:50.382 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:16:11.621: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4pwmq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-dc811107-91c2-11e9-bce2-ae54e022189f
STEP: Creating secret with name secret-projected-all-test-volume-dc8110de-91c2-11e9-bce2-ae54e022189f
STEP: Creating a pod to test Check all projections for projected volume plugin
Jun 18 12:16:12.119: INFO: Waiting up to 5m0s for pod "projected-volume-dc811086-91c2-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-4pwmq" to be "success or failure"
Jun 18 12:16:12.133: INFO: Pod "projected-volume-dc811086-91c2-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.896431ms
Jun 18 12:16:14.147: INFO: Pod "projected-volume-dc811086-91c2-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028153616s
Jun 18 12:16:16.163: INFO: Pod "projected-volume-dc811086-91c2-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043891054s
STEP: Saw pod success
Jun 18 12:16:16.163: INFO: Pod "projected-volume-dc811086-91c2-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:16:16.181: INFO: Trying to get logs from node 10.72.74.143 pod projected-volume-dc811086-91c2-11e9-bce2-ae54e022189f container projected-all-volume-test: <nil>
STEP: delete the pod
Jun 18 12:16:16.253: INFO: Waiting for pod projected-volume-dc811086-91c2-11e9-bce2-ae54e022189f to disappear
Jun 18 12:16:16.268: INFO: Pod projected-volume-dc811086-91c2-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:16:16.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4pwmq" for this suite.
Jun 18 12:16:22.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:16:22.902: INFO: namespace: e2e-tests-projected-4pwmq, resource: bindings, ignored listing per whitelist
Jun 18 12:16:23.035: INFO: namespace e2e-tests-projected-4pwmq deletion completed in 6.744241471s

• [SLOW TEST:11.415 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:16:23.036: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ltw4d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jun 18 12:16:23.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:16:23.789: INFO: stderr: ""
Jun 18 12:16:23.789: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 18 12:16:23.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:16:23.932: INFO: stderr: ""
Jun 18 12:16:23.932: INFO: stdout: "update-demo-nautilus-7lslx update-demo-nautilus-fmm4k "
Jun 18 12:16:23.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-7lslx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:16:24.146: INFO: stderr: ""
Jun 18 12:16:24.146: INFO: stdout: ""
Jun 18 12:16:24.146: INFO: update-demo-nautilus-7lslx is created but not running
Jun 18 12:16:29.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:16:29.978: INFO: stderr: ""
Jun 18 12:16:29.978: INFO: stdout: "update-demo-nautilus-7lslx update-demo-nautilus-fmm4k "
Jun 18 12:16:29.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-7lslx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:16:30.124: INFO: stderr: ""
Jun 18 12:16:30.124: INFO: stdout: "true"
Jun 18 12:16:30.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-7lslx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:16:37.520: INFO: stderr: ""
Jun 18 12:16:37.520: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:16:37.520: INFO: validating pod update-demo-nautilus-7lslx
Jun 18 12:16:37.574: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:16:37.574: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:16:37.574: INFO: update-demo-nautilus-7lslx is verified up and running
Jun 18 12:16:37.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-fmm4k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:16:37.787: INFO: stderr: ""
Jun 18 12:16:37.787: INFO: stdout: "true"
Jun 18 12:16:37.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-fmm4k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:16:37.946: INFO: stderr: ""
Jun 18 12:16:37.946: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:16:37.946: INFO: validating pod update-demo-nautilus-fmm4k
Jun 18 12:16:37.986: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:16:37.986: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:16:37.986: INFO: update-demo-nautilus-fmm4k is verified up and running
STEP: rolling-update to new replication controller
Jun 18 12:16:37.988: INFO: scanned /root for discovery docs: <nil>
Jun 18 12:16:37.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:17:05.676: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun 18 12:17:05.676: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 18 12:17:05.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:17:05.890: INFO: stderr: ""
Jun 18 12:17:05.890: INFO: stdout: "update-demo-kitten-mx6df update-demo-kitten-vgzp6 "
Jun 18 12:17:05.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-kitten-mx6df -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:17:06.256: INFO: stderr: ""
Jun 18 12:17:06.257: INFO: stdout: "true"
Jun 18 12:17:06.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-kitten-mx6df -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:17:06.400: INFO: stderr: ""
Jun 18 12:17:06.400: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun 18 12:17:06.400: INFO: validating pod update-demo-kitten-mx6df
Jun 18 12:17:06.433: INFO: got data: {
  "image": "kitten.jpg"
}

Jun 18 12:17:06.433: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun 18 12:17:06.433: INFO: update-demo-kitten-mx6df is verified up and running
Jun 18 12:17:06.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-kitten-vgzp6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:17:06.566: INFO: stderr: ""
Jun 18 12:17:06.566: INFO: stdout: "true"
Jun 18 12:17:06.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-kitten-vgzp6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ltw4d'
Jun 18 12:17:06.711: INFO: stderr: ""
Jun 18 12:17:06.711: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun 18 12:17:06.711: INFO: validating pod update-demo-kitten-vgzp6
Jun 18 12:17:06.745: INFO: got data: {
  "image": "kitten.jpg"
}

Jun 18 12:17:06.745: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun 18 12:17:06.745: INFO: update-demo-kitten-vgzp6 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:17:06.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ltw4d" for this suite.
Jun 18 12:17:32.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:17:33.180: INFO: namespace: e2e-tests-kubectl-ltw4d, resource: bindings, ignored listing per whitelist
Jun 18 12:17:33.751: INFO: namespace e2e-tests-kubectl-ltw4d deletion completed in 26.98677573s

• [SLOW TEST:70.715 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:17:33.752: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-t5xbb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-t5xbb
Jun 18 12:17:36.295: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-t5xbb
STEP: checking the pod's current state and verifying that restartCount is present
Jun 18 12:17:36.309: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:21:37.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-t5xbb" for this suite.
Jun 18 12:21:43.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:21:43.571: INFO: namespace: e2e-tests-container-probe-t5xbb, resource: bindings, ignored listing per whitelist
Jun 18 12:21:43.822: INFO: namespace e2e-tests-container-probe-t5xbb deletion completed in 6.534344079s

• [SLOW TEST:250.070 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:21:43.824: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-hsv6v
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a2a15f79-91c3-11e9-bce2-ae54e022189f
STEP: Creating secret with name s-test-opt-upd-a2a15fd9-91c3-11e9-bce2-ae54e022189f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a2a15f79-91c3-11e9-bce2-ae54e022189f
STEP: Updating secret s-test-opt-upd-a2a15fd9-91c3-11e9-bce2-ae54e022189f
STEP: Creating secret with name s-test-opt-create-a2a16005-91c3-11e9-bce2-ae54e022189f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:23:13.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-hsv6v" for this suite.
Jun 18 12:23:39.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:23:40.357: INFO: namespace: e2e-tests-secrets-hsv6v, resource: bindings, ignored listing per whitelist
Jun 18 12:23:40.430: INFO: namespace e2e-tests-secrets-hsv6v deletion completed in 26.561063679s

• [SLOW TEST:116.606 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:23:40.430: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-sxqbn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-sxqbn
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 18 12:23:40.883: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 18 12:23:59.201: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.39.53:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sxqbn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 12:23:59.201: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 12:23:59.449: INFO: Found all expected endpoints: [netserver-0]
Jun 18 12:23:59.464: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.58.183:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sxqbn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 12:23:59.464: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 12:23:59.786: INFO: Found all expected endpoints: [netserver-1]
Jun 18 12:23:59.800: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.114.35:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-sxqbn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 12:23:59.800: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 12:24:00.049: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:24:00.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-sxqbn" for this suite.
Jun 18 12:24:24.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:24:24.549: INFO: namespace: e2e-tests-pod-network-test-sxqbn, resource: bindings, ignored listing per whitelist
Jun 18 12:24:24.613: INFO: namespace e2e-tests-pod-network-test-sxqbn deletion completed in 24.544492874s

• [SLOW TEST:44.183 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:24:24.614: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-hpfc8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 18 12:24:25.047: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 18 12:24:25.076: INFO: Waiting for terminating namespaces to be deleted...
Jun 18 12:24:25.089: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.143 before test
Jun 18 12:24:25.140: INFO: sonobuoy-e2e-job-4f826760f7504668 from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 12:24:25.140: INFO: 	Container e2e ready: true, restart count 0
Jun 18 12:24:25.140: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 12:24:25.140: INFO: ibm-kube-fluentd-7spm2 from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.140: INFO: 	Container fluentd ready: true, restart count 0
Jun 18 12:24:25.140: INFO: ibm-file-plugin-bf4cc7987-jwdjh from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.140: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jun 18 12:24:25.141: INFO: ibm-storage-watcher-64989c44d-tp68k from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jun 18 12:24:25.141: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-18 11:33:50 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 18 12:24:25.141: INFO: calico-node-fw2l9 from kube-system started at 2019-06-17 21:36:37 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container calico-node ready: true, restart count 0
Jun 18 12:24:25.141: INFO: coredns-autoscaler-5c7646547d-dshx6 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container autoscaler ready: true, restart count 0
Jun 18 12:24:25.141: INFO: calico-kube-controllers-54d47c87f-kwkh9 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jun 18 12:24:25.141: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-zt85r from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 12:24:25.141: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 18 12:24:25.141: INFO: ibm-master-proxy-static-10.72.74.143 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 12:24:25.141: INFO: ibm-keepalived-watcher-5z7h2 from kube-system started at 2019-06-17 21:36:37 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 12:24:25.141: INFO: kubernetes-dashboard-6cf8b975c-prz8l from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 18 12:24:25.141: INFO: coredns-5545c6ddc4-dxkvs from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container coredns ready: true, restart count 0
Jun 18 12:24:25.141: INFO: vpn-7f677b8cb5-29tf9 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container vpn ready: true, restart count 0
Jun 18 12:24:25.141: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-06-18 11:33:43 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.141: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jun 18 12:24:25.141: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.144 before test
Jun 18 12:24:25.195: INFO: ibm-cloud-provider-ip-158-176-120-130-699ff5cfd-z4hhb from ibm-system started at 2019-06-17 21:40:39 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.195: INFO: 	Container ibm-cloud-provider-ip-158-176-120-130 ready: true, restart count 0
Jun 18 12:24:25.195: INFO: public-cr49a3e8d7011b436d9b4596ba0f279008-alb1-778b7ff477-tpktg from kube-system started at 2019-06-17 21:41:04 +0000 UTC (4 container statuses recorded)
Jun 18 12:24:25.195: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jun 18 12:24:25.195: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jun 18 12:24:25.195: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jun 18 12:24:25.195: INFO: 	Container nginx-ingress ready: true, restart count 0
Jun 18 12:24:25.195: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-ct76c from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 12:24:25.195: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 12:24:25.195: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 18 12:24:25.195: INFO: ibm-master-proxy-static-10.72.74.144 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 12:24:25.195: INFO: calico-node-rptvs from kube-system started at 2019-06-17 21:36:43 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.195: INFO: 	Container calico-node ready: true, restart count 0
Jun 18 12:24:25.195: INFO: ibm-keepalived-watcher-drbmt from kube-system started at 2019-06-17 21:36:43 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.195: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 12:24:25.195: INFO: coredns-5545c6ddc4-4s87g from kube-system started at 2019-06-17 21:37:04 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.195: INFO: 	Container coredns ready: true, restart count 0
Jun 18 12:24:25.195: INFO: ibm-kube-fluentd-g5hgb from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.195: INFO: 	Container fluentd ready: true, restart count 0
Jun 18 12:24:25.195: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.149 before test
Jun 18 12:24:25.254: INFO: ibm-master-proxy-static-10.72.74.149 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 12:24:25.255: INFO: calico-node-4pqtj from kube-system started at 2019-06-17 21:36:50 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.255: INFO: 	Container calico-node ready: true, restart count 0
Jun 18 12:24:25.255: INFO: ibm-cloud-provider-ip-158-176-120-130-699ff5cfd-td8hg from ibm-system started at 2019-06-17 21:40:39 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.255: INFO: 	Container ibm-cloud-provider-ip-158-176-120-130 ready: true, restart count 0
Jun 18 12:24:25.255: INFO: public-cr49a3e8d7011b436d9b4596ba0f279008-alb1-778b7ff477-sxttq from kube-system started at 2019-06-17 21:41:04 +0000 UTC (4 container statuses recorded)
Jun 18 12:24:25.255: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jun 18 12:24:25.255: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jun 18 12:24:25.255: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jun 18 12:24:25.255: INFO: 	Container nginx-ingress ready: true, restart count 0
Jun 18 12:24:25.255: INFO: ibm-kube-fluentd-c6kth from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.255: INFO: 	Container fluentd ready: true, restart count 0
Jun 18 12:24:25.255: INFO: metrics-server-6ccf788d5b-6gwxm from kube-system started at 2019-06-17 21:37:11 +0000 UTC (2 container statuses recorded)
Jun 18 12:24:25.255: INFO: 	Container metrics-server ready: true, restart count 0
Jun 18 12:24:25.255: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jun 18 12:24:25.255: INFO: ibm-keepalived-watcher-6846v from kube-system started at 2019-06-17 21:36:50 +0000 UTC (1 container statuses recorded)
Jun 18 12:24:25.255: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 12:24:25.255: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-btfpp from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 12:24:25.255: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 12:24:25.255: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.72.74.143
STEP: verifying the node has the label node 10.72.74.144
STEP: verifying the node has the label node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod sonobuoy-e2e-job-4f826760f7504668 requesting resource cpu=0m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-btfpp requesting resource cpu=0m on Node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-ct76c requesting resource cpu=0m on Node 10.72.74.144
Jun 18 12:24:25.420: INFO: Pod sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-zt85r requesting resource cpu=0m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod ibm-cloud-provider-ip-158-176-120-130-699ff5cfd-td8hg requesting resource cpu=5m on Node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod ibm-cloud-provider-ip-158-176-120-130-699ff5cfd-z4hhb requesting resource cpu=5m on Node 10.72.74.144
Jun 18 12:24:25.420: INFO: Pod calico-kube-controllers-54d47c87f-kwkh9 requesting resource cpu=10m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod calico-node-4pqtj requesting resource cpu=250m on Node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod calico-node-fw2l9 requesting resource cpu=250m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod calico-node-rptvs requesting resource cpu=250m on Node 10.72.74.144
Jun 18 12:24:25.420: INFO: Pod coredns-5545c6ddc4-4s87g requesting resource cpu=100m on Node 10.72.74.144
Jun 18 12:24:25.420: INFO: Pod coredns-5545c6ddc4-dxkvs requesting resource cpu=100m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod coredns-autoscaler-5c7646547d-dshx6 requesting resource cpu=20m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod ibm-file-plugin-bf4cc7987-jwdjh requesting resource cpu=50m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod ibm-keepalived-watcher-5z7h2 requesting resource cpu=5m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod ibm-keepalived-watcher-6846v requesting resource cpu=5m on Node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod ibm-keepalived-watcher-drbmt requesting resource cpu=5m on Node 10.72.74.144
Jun 18 12:24:25.420: INFO: Pod ibm-kube-fluentd-7spm2 requesting resource cpu=25m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod ibm-kube-fluentd-c6kth requesting resource cpu=25m on Node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod ibm-kube-fluentd-g5hgb requesting resource cpu=25m on Node 10.72.74.144
Jun 18 12:24:25.420: INFO: Pod ibm-master-proxy-static-10.72.74.143 requesting resource cpu=25m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod ibm-master-proxy-static-10.72.74.144 requesting resource cpu=25m on Node 10.72.74.144
Jun 18 12:24:25.420: INFO: Pod ibm-master-proxy-static-10.72.74.149 requesting resource cpu=25m on Node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod ibm-storage-watcher-64989c44d-tp68k requesting resource cpu=50m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod kubernetes-dashboard-6cf8b975c-prz8l requesting resource cpu=50m on Node 10.72.74.143
Jun 18 12:24:25.420: INFO: Pod metrics-server-6ccf788d5b-6gwxm requesting resource cpu=53m on Node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod public-cr49a3e8d7011b436d9b4596ba0f279008-alb1-778b7ff477-sxttq requesting resource cpu=0m on Node 10.72.74.149
Jun 18 12:24:25.420: INFO: Pod public-cr49a3e8d7011b436d9b4596ba0f279008-alb1-778b7ff477-tpktg requesting resource cpu=0m on Node 10.72.74.144
Jun 18 12:24:25.420: INFO: Pod vpn-7f677b8cb5-29tf9 requesting resource cpu=5m on Node 10.72.74.143
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0291545e-91c4-11e9-bce2-ae54e022189f.15a94a81651122ee], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-hpfc8/filler-pod-0291545e-91c4-11e9-bce2-ae54e022189f to 10.72.74.144]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0291545e-91c4-11e9-bce2-ae54e022189f.15a94a81a5523b26], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0291545e-91c4-11e9-bce2-ae54e022189f.15a94a81a8776faa], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0291545e-91c4-11e9-bce2-ae54e022189f.15a94a81b7c08230], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-02961fdc-91c4-11e9-bce2-ae54e022189f.15a94a8166a0776e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-hpfc8/filler-pod-02961fdc-91c4-11e9-bce2-ae54e022189f to 10.72.74.149]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-02961fdc-91c4-11e9-bce2-ae54e022189f.15a94a81a97c7ff9], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-02961fdc-91c4-11e9-bce2-ae54e022189f.15a94a81acfd0f37], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-02961fdc-91c4-11e9-bce2-ae54e022189f.15a94a81bb7491ed], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0298b9a6-91c4-11e9-bce2-ae54e022189f.15a94a816792590a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-hpfc8/filler-pod-0298b9a6-91c4-11e9-bce2-ae54e022189f to 10.72.74.143]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0298b9a6-91c4-11e9-bce2-ae54e022189f.15a94a81a8ca7762], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0298b9a6-91c4-11e9-bce2-ae54e022189f.15a94a81ace91807], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0298b9a6-91c4-11e9-bce2-ae54e022189f.15a94a81ba433cde], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a94a81e3dcfc48], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.72.74.143
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.72.74.144
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.72.74.149
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:24:28.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-hpfc8" for this suite.
Jun 18 12:24:36.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:24:37.076: INFO: namespace: e2e-tests-sched-pred-hpfc8, resource: bindings, ignored listing per whitelist
Jun 18 12:24:37.422: INFO: namespace e2e-tests-sched-pred-hpfc8 deletion completed in 8.659467646s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.808 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:24:37.423: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-j2k4q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j2k4q
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 18 12:24:37.895: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 18 12:25:04.267: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.58.185 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j2k4q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 12:25:04.267: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 12:25:05.541: INFO: Found all expected endpoints: [netserver-0]
Jun 18 12:25:05.555: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.114.38 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j2k4q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 12:25:05.555: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 12:25:06.802: INFO: Found all expected endpoints: [netserver-1]
Jun 18 12:25:06.818: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.39.55 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-j2k4q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 12:25:06.818: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 12:25:08.069: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:25:08.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j2k4q" for this suite.
Jun 18 12:25:32.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:25:32.547: INFO: namespace: e2e-tests-pod-network-test-j2k4q, resource: bindings, ignored listing per whitelist
Jun 18 12:25:32.679: INFO: namespace e2e-tests-pod-network-test-j2k4q deletion completed in 24.5896822s

• [SLOW TEST:55.256 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:25:32.679: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rcb72
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 18 12:25:33.172: INFO: Waiting up to 5m0s for pod "pod-2aef12ce-91c4-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-rcb72" to be "success or failure"
Jun 18 12:25:33.190: INFO: Pod "pod-2aef12ce-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.73837ms
Jun 18 12:25:35.210: INFO: Pod "pod-2aef12ce-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037301392s
Jun 18 12:25:37.227: INFO: Pod "pod-2aef12ce-91c4-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054498212s
STEP: Saw pod success
Jun 18 12:25:37.227: INFO: Pod "pod-2aef12ce-91c4-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:25:37.301: INFO: Trying to get logs from node 10.72.74.149 pod pod-2aef12ce-91c4-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:25:37.377: INFO: Waiting for pod pod-2aef12ce-91c4-11e9-bce2-ae54e022189f to disappear
Jun 18 12:25:37.391: INFO: Pod pod-2aef12ce-91c4-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:25:37.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rcb72" for this suite.
Jun 18 12:25:43.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:25:43.638: INFO: namespace: e2e-tests-emptydir-rcb72, resource: bindings, ignored listing per whitelist
Jun 18 12:25:44.058: INFO: namespace e2e-tests-emptydir-rcb72 deletion completed in 6.643437675s

• [SLOW TEST:11.380 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:25:44.058: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-4kl8k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:25:44.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4kl8k" for this suite.
Jun 18 12:26:08.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:26:08.886: INFO: namespace: e2e-tests-pods-4kl8k, resource: bindings, ignored listing per whitelist
Jun 18 12:26:09.319: INFO: namespace e2e-tests-pods-4kl8k deletion completed in 24.746909285s

• [SLOW TEST:25.260 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:26:09.319: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-r9btl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jun 18 12:26:09.937: INFO: Waiting up to 5m0s for pod "client-containers-40d94c72-91c4-11e9-bce2-ae54e022189f" in namespace "e2e-tests-containers-r9btl" to be "success or failure"
Jun 18 12:26:09.984: INFO: Pod "client-containers-40d94c72-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 47.075252ms
Jun 18 12:26:12.000: INFO: Pod "client-containers-40d94c72-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063179342s
Jun 18 12:26:14.035: INFO: Pod "client-containers-40d94c72-91c4-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.097338025s
STEP: Saw pod success
Jun 18 12:26:14.036: INFO: Pod "client-containers-40d94c72-91c4-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:26:14.052: INFO: Trying to get logs from node 10.72.74.144 pod client-containers-40d94c72-91c4-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:26:14.126: INFO: Waiting for pod client-containers-40d94c72-91c4-11e9-bce2-ae54e022189f to disappear
Jun 18 12:26:14.143: INFO: Pod client-containers-40d94c72-91c4-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:26:14.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-r9btl" for this suite.
Jun 18 12:26:20.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:26:20.293: INFO: namespace: e2e-tests-containers-r9btl, resource: bindings, ignored listing per whitelist
Jun 18 12:26:20.747: INFO: namespace e2e-tests-containers-r9btl deletion completed in 6.585084949s

• [SLOW TEST:11.428 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:26:20.748: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-jzshx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 12:26:21.290: INFO: Creating deployment "nginx-deployment"
Jun 18 12:26:21.305: INFO: Waiting for observed generation 1
Jun 18 12:26:23.332: INFO: Waiting for all required pods to come up
Jun 18 12:26:23.358: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jun 18 12:26:25.485: INFO: Waiting for deployment "nginx-deployment" to complete
Jun 18 12:26:25.512: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jun 18 12:26:25.537: INFO: Updating deployment nginx-deployment
Jun 18 12:26:25.537: INFO: Waiting for observed generation 2
Jun 18 12:26:27.564: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jun 18 12:26:27.577: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jun 18 12:26:27.590: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jun 18 12:26:27.636: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jun 18 12:26:27.636: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jun 18 12:26:27.648: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jun 18 12:26:27.675: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jun 18 12:26:27.675: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jun 18 12:26:27.717: INFO: Updating deployment nginx-deployment
Jun 18 12:26:27.717: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jun 18 12:26:27.742: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jun 18 12:26:29.770: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 18 12:26:29.797: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-jzshx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jzshx/deployments/nginx-deployment,UID:47a2e90c-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100836,Generation:3,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-06-18 12:26:27 +0000 UTC 2019-06-18 12:26:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-06-18 12:26:27 +0000 UTC 2019-06-18 12:26:21 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jun 18 12:26:29.813: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-jzshx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jzshx/replicasets/nginx-deployment-65bbdb5f8,UID:4a2a98be-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100819,Generation:3,CreationTimestamp:2019-06-18 12:26:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 47a2e90c-91c4-11e9-bf44-fa6f350b29f0 0xc001ed3ef7 0xc001ed3ef8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 18 12:26:29.813: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jun 18 12:26:29.813: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-jzshx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jzshx/replicasets/nginx-deployment-555b55d965,UID:47a72cb1-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100833,Generation:3,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 47a2e90c-91c4-11e9-bf44-fa6f350b29f0 0xc001ed3e37 0xc001ed3e38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jun 18 12:26:29.842: INFO: Pod "nginx-deployment-555b55d965-5bj56" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5bj56,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-5bj56,UID:47b0f76a-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100642,Generation:0,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc002278c27 0xc002278c28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002279d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002279d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:172.30.39.57,StartTime:2019-06-18 12:26:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 12:26:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://01b4097e1fbf7970ccee4f476cc9c6c91971f93c1c422b8b1179ddedb4f1b915}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.842: INFO: Pod "nginx-deployment-555b55d965-6b9lc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6b9lc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-6b9lc,UID:4b7a70f5-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100797,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012da037 0xc0012da038}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012da0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012da0d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.843: INFO: Pod "nginx-deployment-555b55d965-6fd5f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6fd5f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-6fd5f,UID:47ae7d83-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100631,Generation:0,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012da187 0xc0012da188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012da200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012da220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:172.30.58.188,StartTime:2019-06-18 12:26:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 12:26:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://33fa3eb4726d71d8e3075e986f7e8eb1483205a2a6b99fcdffdff6267ced9209}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.843: INFO: Pod "nginx-deployment-555b55d965-74q7h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-74q7h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-74q7h,UID:4b7fcdec-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100889,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012da2e7 0xc0012da2e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012da360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012da380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.843: INFO: Pod "nginx-deployment-555b55d965-7tgt2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7tgt2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-7tgt2,UID:4b8043bf-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100870,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012da437 0xc0012da438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012da4b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012da4d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.843: INFO: Pod "nginx-deployment-555b55d965-848zb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-848zb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-848zb,UID:4b800bce-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100834,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012da587 0xc0012da588}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012da600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012da620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.843: INFO: Pod "nginx-deployment-555b55d965-8wkq4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8wkq4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-8wkq4,UID:4b7a727e-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100822,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012da6d7 0xc0012da6d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012da760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012da780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.843: INFO: Pod "nginx-deployment-555b55d965-cppb2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cppb2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-cppb2,UID:4b789bd1-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100780,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012da837 0xc0012da838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012da8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012da8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.843: INFO: Pod "nginx-deployment-555b55d965-hkjgv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hkjgv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-hkjgv,UID:47b340de-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100648,Generation:0,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012da987 0xc0012da988}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012daa00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012daa20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:172.30.39.58,StartTime:2019-06-18 12:26:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 12:26:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://4adad8f0224e913cf784f81655b4d207efa8c1a6de6b3b813110cd9a411dfcb4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.844: INFO: Pod "nginx-deployment-555b55d965-hxlbp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hxlbp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-hxlbp,UID:4b7d35cd-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100854,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012daae7 0xc0012daae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012dab60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012dab80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.844: INFO: Pod "nginx-deployment-555b55d965-jr74f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jr74f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-jr74f,UID:4b807ddf-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100808,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012dac37 0xc0012dac38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012dacb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012dacd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.844: INFO: Pod "nginx-deployment-555b55d965-kvlp7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kvlp7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-kvlp7,UID:4b7d339b-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100827,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012dad40 0xc0012dad41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012dadb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012dadd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.844: INFO: Pod "nginx-deployment-555b55d965-lc57v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lc57v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-lc57v,UID:47b3246f-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100643,Generation:0,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012dae87 0xc0012dae88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012daf00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012daf20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:172.30.114.40,StartTime:2019-06-18 12:26:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 12:26:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://395d7e2b2a551c4ecaa72c76fa93bfa940f8a39c3906a344795569ab9d9a7d56}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.844: INFO: Pod "nginx-deployment-555b55d965-nq2gt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nq2gt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-nq2gt,UID:4b7cecb9-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100830,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012dafe7 0xc0012dafe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012db070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012db090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.844: INFO: Pod "nginx-deployment-555b55d965-p9wr9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p9wr9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-p9wr9,UID:47b0db8a-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100633,Generation:0,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012db147 0xc0012db148}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012db1c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012db1e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:172.30.58.189,StartTime:2019-06-18 12:26:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 12:26:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://717f7979042dac3f0c280a3b344980260a99d3cb4f53c82d3906b2b6f560294e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.844: INFO: Pod "nginx-deployment-555b55d965-qltqg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qltqg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-qltqg,UID:47b0c684-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100640,Generation:0,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012db2a7 0xc0012db2a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012db320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012db340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:172.30.114.41,StartTime:2019-06-18 12:26:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 12:26:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://cb7d9f910d3de18a607384e08c982d116fcb849811477017dd117f0c827014e6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.845: INFO: Pod "nginx-deployment-555b55d965-slxr9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-slxr9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-slxr9,UID:47acc168-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100653,Generation:0,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012db407 0xc0012db408}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012db480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012db4a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:172.30.39.60,StartTime:2019-06-18 12:26:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 12:26:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f60b6e26dfc4f0de54d7dddec6ca3a97d49002f3c94cb679d66508eb2284a01c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.845: INFO: Pod "nginx-deployment-555b55d965-w6mz4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-w6mz4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-w6mz4,UID:47aeb70d-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100647,Generation:0,CreationTimestamp:2019-06-18 12:26:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012db567 0xc0012db568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012db5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012db600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:21 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:172.30.114.42,StartTime:2019-06-18 12:26:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-18 12:26:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f94cab596649fefe951931b63560d02c5cd5c8ed32af9ab0fc63ce3724260b9b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.845: INFO: Pod "nginx-deployment-555b55d965-xwfpx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xwfpx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-xwfpx,UID:4b7fdb9c-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100899,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012db6c7 0xc0012db6c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012db740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012db760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.845: INFO: Pod "nginx-deployment-555b55d965-zhw7h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zhw7h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-555b55d965-zhw7h,UID:4b7d05fd-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100821,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 47a72cb1-91c4-11e9-bf44-fa6f350b29f0 0xc0012db817 0xc0012db818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012db8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012db8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.845: INFO: Pod "nginx-deployment-65bbdb5f8-457mh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-457mh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-457mh,UID:4a2e83f7-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100690,Generation:0,CreationTimestamp:2019-06-18 12:26:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc0012db977 0xc0012db978}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012db9f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012dba20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:,StartTime:2019-06-18 12:26:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.845: INFO: Pod "nginx-deployment-65bbdb5f8-5vl8m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5vl8m,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-5vl8m,UID:4a2e95c8-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100691,Generation:0,CreationTimestamp:2019-06-18 12:26:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc0012dbaf0 0xc0012dbaf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012dbb70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012dbb90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:,StartTime:2019-06-18 12:26:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.845: INFO: Pod "nginx-deployment-65bbdb5f8-95khm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-95khm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-95khm,UID:4a384751-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100714,Generation:0,CreationTimestamp:2019-06-18 12:26:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc0012dbc50 0xc0012dbc51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012dbcd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012dbcf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 12:26:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.846: INFO: Pod "nginx-deployment-65bbdb5f8-98hkp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-98hkp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-98hkp,UID:4a2c6631-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100687,Generation:0,CreationTimestamp:2019-06-18 12:26:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc0012dbde0 0xc0012dbde1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012dbe70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012dbe90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 12:26:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.846: INFO: Pod "nginx-deployment-65bbdb5f8-bh87k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bh87k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-bh87k,UID:4b821eb4-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100812,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc0012dbf60 0xc0012dbf61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012dbfe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195e060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.846: INFO: Pod "nginx-deployment-65bbdb5f8-br7m9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-br7m9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-br7m9,UID:4b7f9287-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100828,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc00195e0d0 0xc00195e0d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195e1c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195e1e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.846: INFO: Pod "nginx-deployment-65bbdb5f8-cj62g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cj62g,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-cj62g,UID:4b7fcfa6-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100864,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc00195e310 0xc00195e311}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195e390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195e5a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.846: INFO: Pod "nginx-deployment-65bbdb5f8-fwb76" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fwb76,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-fwb76,UID:4b7a2ca5-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100802,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc00195e660 0xc00195e661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195e6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195e7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.847: INFO: Pod "nginx-deployment-65bbdb5f8-h6rnn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h6rnn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-h6rnn,UID:4b7c8636-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100807,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc00195e8a0 0xc00195e8a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195e9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195e9f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.143,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.847: INFO: Pod "nginx-deployment-65bbdb5f8-scd8r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-scd8r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-scd8r,UID:4b7fa7b3-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100887,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc00195eb00 0xc00195eb01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195f010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195f030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.847: INFO: Pod "nginx-deployment-65bbdb5f8-shgr2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-shgr2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-shgr2,UID:4b7fb6fc-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100837,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc00195f410 0xc00195f411}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195f490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195f4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.847: INFO: Pod "nginx-deployment-65bbdb5f8-ssccf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ssccf,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-ssccf,UID:4b7d003e-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100818,Generation:0,CreationTimestamp:2019-06-18 12:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc00195f570 0xc00195f571}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195f620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195f670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:27 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:,StartTime:2019-06-18 12:26:27 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun 18 12:26:29.847: INFO: Pod "nginx-deployment-65bbdb5f8-vx4tp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vx4tp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-jzshx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jzshx/pods/nginx-deployment-65bbdb5f8-vx4tp,UID:4a3a0012-91c4-11e9-bf44-fa6f350b29f0,ResourceVersion:100715,Generation:0,CreationTimestamp:2019-06-18 12:26:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 4a2a98be-91c4-11e9-bf44-fa6f350b29f0 0xc00195f760 0xc00195f761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g4nvn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g4nvn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-g4nvn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00195f810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00195f830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:26:25 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:,StartTime:2019-06-18 12:26:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:26:29.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jzshx" for this suite.
Jun 18 12:26:39.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:26:40.513: INFO: namespace: e2e-tests-deployment-jzshx, resource: bindings, ignored listing per whitelist
Jun 18 12:26:40.667: INFO: namespace e2e-tests-deployment-jzshx deletion completed in 10.804576771s

• [SLOW TEST:19.919 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:26:40.667: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2j42f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 18 12:26:41.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-2j42f'
Jun 18 12:26:41.511: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 18 12:26:41.511: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jun 18 12:26:41.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-2j42f'
Jun 18 12:26:41.694: INFO: stderr: ""
Jun 18 12:26:41.694: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:26:41.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2j42f" for this suite.
Jun 18 12:26:47.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:26:47.937: INFO: namespace: e2e-tests-kubectl-2j42f, resource: bindings, ignored listing per whitelist
Jun 18 12:26:48.271: INFO: namespace e2e-tests-kubectl-2j42f deletion completed in 6.54620729s

• [SLOW TEST:7.603 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:26:48.271: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-ph5vs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jun 18 12:26:48.817: INFO: Waiting up to 5m0s for pod "var-expansion-5805e26d-91c4-11e9-bce2-ae54e022189f" in namespace "e2e-tests-var-expansion-ph5vs" to be "success or failure"
Jun 18 12:26:48.832: INFO: Pod "var-expansion-5805e26d-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.513307ms
Jun 18 12:26:50.848: INFO: Pod "var-expansion-5805e26d-91c4-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.030574539s
Jun 18 12:26:52.863: INFO: Pod "var-expansion-5805e26d-91c4-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046089782s
STEP: Saw pod success
Jun 18 12:26:52.863: INFO: Pod "var-expansion-5805e26d-91c4-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:26:52.878: INFO: Trying to get logs from node 10.72.74.149 pod var-expansion-5805e26d-91c4-11e9-bce2-ae54e022189f container dapi-container: <nil>
STEP: delete the pod
Jun 18 12:26:53.052: INFO: Waiting for pod var-expansion-5805e26d-91c4-11e9-bce2-ae54e022189f to disappear
Jun 18 12:26:53.066: INFO: Pod var-expansion-5805e26d-91c4-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:26:53.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ph5vs" for this suite.
Jun 18 12:27:01.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:27:01.580: INFO: namespace: e2e-tests-var-expansion-ph5vs, resource: bindings, ignored listing per whitelist
Jun 18 12:27:02.998: INFO: namespace e2e-tests-var-expansion-ph5vs deletion completed in 9.91084251s

• [SLOW TEST:14.726 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:27:02.999: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kllld
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-60c5420a-91c4-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:27:03.512: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-60c80a9c-91c4-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-kllld" to be "success or failure"
Jun 18 12:27:03.527: INFO: Pod "pod-projected-configmaps-60c80a9c-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.995975ms
Jun 18 12:27:05.542: INFO: Pod "pod-projected-configmaps-60c80a9c-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030521065s
Jun 18 12:27:07.557: INFO: Pod "pod-projected-configmaps-60c80a9c-91c4-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045081629s
STEP: Saw pod success
Jun 18 12:27:07.557: INFO: Pod "pod-projected-configmaps-60c80a9c-91c4-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:27:07.598: INFO: Trying to get logs from node 10.72.74.144 pod pod-projected-configmaps-60c80a9c-91c4-11e9-bce2-ae54e022189f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:27:07.673: INFO: Waiting for pod pod-projected-configmaps-60c80a9c-91c4-11e9-bce2-ae54e022189f to disappear
Jun 18 12:27:07.687: INFO: Pod pod-projected-configmaps-60c80a9c-91c4-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:27:07.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kllld" for this suite.
Jun 18 12:27:17.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:27:17.876: INFO: namespace: e2e-tests-projected-kllld, resource: bindings, ignored listing per whitelist
Jun 18 12:27:18.263: INFO: namespace e2e-tests-projected-kllld deletion completed in 10.556521334s

• [SLOW TEST:15.265 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:27:18.263: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rk98z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:27:18.948: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69fbb760-91c4-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-rk98z" to be "success or failure"
Jun 18 12:27:18.962: INFO: Pod "downwardapi-volume-69fbb760-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.043282ms
Jun 18 12:27:20.993: INFO: Pod "downwardapi-volume-69fbb760-91c4-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044799922s
STEP: Saw pod success
Jun 18 12:27:20.993: INFO: Pod "downwardapi-volume-69fbb760-91c4-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:27:21.008: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-69fbb760-91c4-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:27:21.088: INFO: Waiting for pod downwardapi-volume-69fbb760-91c4-11e9-bce2-ae54e022189f to disappear
Jun 18 12:27:21.103: INFO: Pod downwardapi-volume-69fbb760-91c4-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:27:21.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rk98z" for this suite.
Jun 18 12:27:27.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:27:27.727: INFO: namespace: e2e-tests-projected-rk98z, resource: bindings, ignored listing per whitelist
Jun 18 12:27:28.111: INFO: namespace e2e-tests-projected-rk98z deletion completed in 6.983552879s

• [SLOW TEST:9.847 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:27:28.111: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7p77j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 18 12:27:28.584: INFO: Waiting up to 5m0s for pod "pod-6fb97d1e-91c4-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-7p77j" to be "success or failure"
Jun 18 12:27:28.598: INFO: Pod "pod-6fb97d1e-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.637576ms
Jun 18 12:27:30.613: INFO: Pod "pod-6fb97d1e-91c4-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028116402s
STEP: Saw pod success
Jun 18 12:27:30.613: INFO: Pod "pod-6fb97d1e-91c4-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:27:30.627: INFO: Trying to get logs from node 10.72.74.143 pod pod-6fb97d1e-91c4-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:27:30.697: INFO: Waiting for pod pod-6fb97d1e-91c4-11e9-bce2-ae54e022189f to disappear
Jun 18 12:27:30.711: INFO: Pod pod-6fb97d1e-91c4-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:27:30.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7p77j" for this suite.
Jun 18 12:27:36.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:27:37.309: INFO: namespace: e2e-tests-emptydir-7p77j, resource: bindings, ignored listing per whitelist
Jun 18 12:27:37.351: INFO: namespace e2e-tests-emptydir-7p77j deletion completed in 6.619169407s

• [SLOW TEST:9.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:27:37.351: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-scznw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0618 12:27:44.031213      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 18 12:27:44.031: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:27:44.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-scznw" for this suite.
Jun 18 12:27:52.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:27:52.758: INFO: namespace: e2e-tests-gc-scznw, resource: bindings, ignored listing per whitelist
Jun 18 12:27:52.908: INFO: namespace e2e-tests-gc-scznw deletion completed in 8.863667938s

• [SLOW TEST:15.557 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:27:52.909: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-txwmz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:27:53.433: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e89930a-91c4-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-txwmz" to be "success or failure"
Jun 18 12:27:53.447: INFO: Pod "downwardapi-volume-7e89930a-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.684233ms
Jun 18 12:27:55.461: INFO: Pod "downwardapi-volume-7e89930a-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028142414s
Jun 18 12:27:57.478: INFO: Pod "downwardapi-volume-7e89930a-91c4-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044655422s
STEP: Saw pod success
Jun 18 12:27:57.478: INFO: Pod "downwardapi-volume-7e89930a-91c4-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:27:57.496: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-7e89930a-91c4-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:27:57.632: INFO: Waiting for pod downwardapi-volume-7e89930a-91c4-11e9-bce2-ae54e022189f to disappear
Jun 18 12:27:57.646: INFO: Pod downwardapi-volume-7e89930a-91c4-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:27:57.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-txwmz" for this suite.
Jun 18 12:28:03.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:28:04.183: INFO: namespace: e2e-tests-downward-api-txwmz, resource: bindings, ignored listing per whitelist
Jun 18 12:28:04.247: INFO: namespace e2e-tests-downward-api-txwmz deletion completed in 6.576714077s

• [SLOW TEST:11.339 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:28:04.247: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ntsxs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun 18 12:28:09.400: INFO: Successfully updated pod "labelsupdate85455b79-91c4-11e9-bce2-ae54e022189f"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:28:12.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ntsxs" for this suite.
Jun 18 12:28:36.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:28:36.973: INFO: namespace: e2e-tests-downward-api-ntsxs, resource: bindings, ignored listing per whitelist
Jun 18 12:28:37.428: INFO: namespace e2e-tests-downward-api-ntsxs deletion completed in 25.123957633s

• [SLOW TEST:33.181 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:28:37.429: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-ldj62
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jun 18 12:28:40.019: INFO: Pod pod-hostip-991353cc-91c4-11e9-bce2-ae54e022189f has hostIP: 10.72.74.143
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:28:40.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ldj62" for this suite.
Jun 18 12:29:04.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:29:04.415: INFO: namespace: e2e-tests-pods-ldj62, resource: bindings, ignored listing per whitelist
Jun 18 12:29:04.563: INFO: namespace e2e-tests-pods-ldj62 deletion completed in 24.518894698s

• [SLOW TEST:27.134 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:29:04.563: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-fglh2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a942ba31-91c4-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:29:05.124: INFO: Waiting up to 5m0s for pod "pod-configmaps-a944c093-91c4-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-fglh2" to be "success or failure"
Jun 18 12:29:05.138: INFO: Pod "pod-configmaps-a944c093-91c4-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.2729ms
Jun 18 12:29:07.152: INFO: Pod "pod-configmaps-a944c093-91c4-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027837558s
STEP: Saw pod success
Jun 18 12:29:07.152: INFO: Pod "pod-configmaps-a944c093-91c4-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:29:07.202: INFO: Trying to get logs from node 10.72.74.144 pod pod-configmaps-a944c093-91c4-11e9-bce2-ae54e022189f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:29:07.277: INFO: Waiting for pod pod-configmaps-a944c093-91c4-11e9-bce2-ae54e022189f to disappear
Jun 18 12:29:07.291: INFO: Pod pod-configmaps-a944c093-91c4-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:29:07.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fglh2" for this suite.
Jun 18 12:29:13.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:29:13.770: INFO: namespace: e2e-tests-configmap-fglh2, resource: bindings, ignored listing per whitelist
Jun 18 12:29:13.849: INFO: namespace e2e-tests-configmap-fglh2 deletion completed in 6.531625795s

• [SLOW TEST:9.285 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:29:13.849: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-xq29x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jun 18 12:29:15.021: INFO: Pod name wrapped-volume-race-af273b75-91c4-11e9-bce2-ae54e022189f: Found 0 pods out of 5
Jun 18 12:29:20.046: INFO: Pod name wrapped-volume-race-af273b75-91c4-11e9-bce2-ae54e022189f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-af273b75-91c4-11e9-bce2-ae54e022189f in namespace e2e-tests-emptydir-wrapper-xq29x, will wait for the garbage collector to delete the pods
Jun 18 12:32:04.349: INFO: Deleting ReplicationController wrapped-volume-race-af273b75-91c4-11e9-bce2-ae54e022189f took: 34.141243ms
Jun 18 12:32:04.451: INFO: Terminating ReplicationController wrapped-volume-race-af273b75-91c4-11e9-bce2-ae54e022189f pods took: 101.687484ms
STEP: Creating RC which spawns configmap-volume pods
Jun 18 12:32:47.114: INFO: Pod name wrapped-volume-race-2d160b3e-91c5-11e9-bce2-ae54e022189f: Found 0 pods out of 5
Jun 18 12:32:52.185: INFO: Pod name wrapped-volume-race-2d160b3e-91c5-11e9-bce2-ae54e022189f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2d160b3e-91c5-11e9-bce2-ae54e022189f in namespace e2e-tests-emptydir-wrapper-xq29x, will wait for the garbage collector to delete the pods
Jun 18 12:34:46.524: INFO: Deleting ReplicationController wrapped-volume-race-2d160b3e-91c5-11e9-bce2-ae54e022189f took: 30.768477ms
Jun 18 12:34:46.624: INFO: Terminating ReplicationController wrapped-volume-race-2d160b3e-91c5-11e9-bce2-ae54e022189f pods took: 100.197721ms
STEP: Creating RC which spawns configmap-volume pods
Jun 18 12:35:26.305: INFO: Pod name wrapped-volume-race-8c700672-91c5-11e9-bce2-ae54e022189f: Found 0 pods out of 5
Jun 18 12:35:31.334: INFO: Pod name wrapped-volume-race-8c700672-91c5-11e9-bce2-ae54e022189f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8c700672-91c5-11e9-bce2-ae54e022189f in namespace e2e-tests-emptydir-wrapper-xq29x, will wait for the garbage collector to delete the pods
Jun 18 12:37:25.522: INFO: Deleting ReplicationController wrapped-volume-race-8c700672-91c5-11e9-bce2-ae54e022189f took: 26.697911ms
Jun 18 12:37:25.622: INFO: Terminating ReplicationController wrapped-volume-race-8c700672-91c5-11e9-bce2-ae54e022189f pods took: 100.41775ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:38:07.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-xq29x" for this suite.
Jun 18 12:38:15.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:38:16.071: INFO: namespace: e2e-tests-emptydir-wrapper-xq29x, resource: bindings, ignored listing per whitelist
Jun 18 12:38:16.410: INFO: namespace e2e-tests-emptydir-wrapper-xq29x deletion completed in 8.540661816s

• [SLOW TEST:542.562 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:38:16.411: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-2gx7x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:38:21.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-2gx7x" for this suite.
Jun 18 12:38:27.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:38:27.417: INFO: namespace: e2e-tests-kubelet-test-2gx7x, resource: bindings, ignored listing per whitelist
Jun 18 12:38:27.662: INFO: namespace e2e-tests-kubelet-test-2gx7x deletion completed in 6.577470622s

• [SLOW TEST:11.251 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:38:27.663: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-npbjq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f8d79ddb-91c5-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:38:29.255: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f8e6bdf6-91c5-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-npbjq" to be "success or failure"
Jun 18 12:38:29.273: INFO: Pod "pod-projected-configmaps-f8e6bdf6-91c5-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.208458ms
Jun 18 12:38:31.290: INFO: Pod "pod-projected-configmaps-f8e6bdf6-91c5-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.03468284s
Jun 18 12:38:33.305: INFO: Pod "pod-projected-configmaps-f8e6bdf6-91c5-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049725339s
STEP: Saw pod success
Jun 18 12:38:33.305: INFO: Pod "pod-projected-configmaps-f8e6bdf6-91c5-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:38:33.319: INFO: Trying to get logs from node 10.72.74.143 pod pod-projected-configmaps-f8e6bdf6-91c5-11e9-bce2-ae54e022189f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:38:33.469: INFO: Waiting for pod pod-projected-configmaps-f8e6bdf6-91c5-11e9-bce2-ae54e022189f to disappear
Jun 18 12:38:33.484: INFO: Pod pod-projected-configmaps-f8e6bdf6-91c5-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:38:33.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-npbjq" for this suite.
Jun 18 12:38:39.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:38:39.822: INFO: namespace: e2e-tests-projected-npbjq, resource: bindings, ignored listing per whitelist
Jun 18 12:38:40.048: INFO: namespace e2e-tests-projected-npbjq deletion completed in 6.543984896s

• [SLOW TEST:12.386 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:38:40.049: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-tjrrz
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jun 18 12:38:40.910: INFO: Waiting up to 5m0s for pod "pod-0076d37c-91c6-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-tjrrz" to be "success or failure"
Jun 18 12:38:40.924: INFO: Pod "pod-0076d37c-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.043013ms
Jun 18 12:38:42.939: INFO: Pod "pod-0076d37c-91c6-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028843248s
STEP: Saw pod success
Jun 18 12:38:42.939: INFO: Pod "pod-0076d37c-91c6-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:38:42.953: INFO: Trying to get logs from node 10.72.74.143 pod pod-0076d37c-91c6-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:38:43.027: INFO: Waiting for pod pod-0076d37c-91c6-11e9-bce2-ae54e022189f to disappear
Jun 18 12:38:43.042: INFO: Pod pod-0076d37c-91c6-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:38:43.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tjrrz" for this suite.
Jun 18 12:38:49.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:38:49.486: INFO: namespace: e2e-tests-emptydir-tjrrz, resource: bindings, ignored listing per whitelist
Jun 18 12:38:49.606: INFO: namespace e2e-tests-emptydir-tjrrz deletion completed in 6.545564852s

• [SLOW TEST:9.558 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:38:49.608: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g7bx9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jun 18 12:38:50.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:50.568: INFO: stderr: ""
Jun 18 12:38:50.568: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 18 12:38:50.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:50.697: INFO: stderr: ""
Jun 18 12:38:50.697: INFO: stdout: "update-demo-nautilus-dcbrd update-demo-nautilus-hqm4n "
Jun 18 12:38:50.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-dcbrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:50.829: INFO: stderr: ""
Jun 18 12:38:50.829: INFO: stdout: ""
Jun 18 12:38:50.829: INFO: update-demo-nautilus-dcbrd is created but not running
Jun 18 12:38:55.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:55.990: INFO: stderr: ""
Jun 18 12:38:55.990: INFO: stdout: "update-demo-nautilus-dcbrd update-demo-nautilus-hqm4n "
Jun 18 12:38:55.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-dcbrd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:56.128: INFO: stderr: ""
Jun 18 12:38:56.128: INFO: stdout: "true"
Jun 18 12:38:56.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-dcbrd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:56.260: INFO: stderr: ""
Jun 18 12:38:56.260: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:38:56.261: INFO: validating pod update-demo-nautilus-dcbrd
Jun 18 12:38:56.295: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:38:56.295: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:38:56.295: INFO: update-demo-nautilus-dcbrd is verified up and running
Jun 18 12:38:56.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-hqm4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:56.426: INFO: stderr: ""
Jun 18 12:38:56.426: INFO: stdout: "true"
Jun 18 12:38:56.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-hqm4n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:56.548: INFO: stderr: ""
Jun 18 12:38:56.548: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:38:56.548: INFO: validating pod update-demo-nautilus-hqm4n
Jun 18 12:38:56.581: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:38:56.581: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:38:56.581: INFO: update-demo-nautilus-hqm4n is verified up and running
STEP: scaling down the replication controller
Jun 18 12:38:56.583: INFO: scanned /root for discovery docs: <nil>
Jun 18 12:38:56.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:57.810: INFO: stderr: ""
Jun 18 12:38:57.810: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 18 12:38:57.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:38:57.945: INFO: stderr: ""
Jun 18 12:38:57.945: INFO: stdout: "update-demo-nautilus-dcbrd update-demo-nautilus-hqm4n "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 18 12:39:02.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:03.122: INFO: stderr: ""
Jun 18 12:39:03.122: INFO: stdout: "update-demo-nautilus-dcbrd update-demo-nautilus-hqm4n "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 18 12:39:08.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:08.353: INFO: stderr: ""
Jun 18 12:39:08.353: INFO: stdout: "update-demo-nautilus-hqm4n "
Jun 18 12:39:08.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-hqm4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:08.493: INFO: stderr: ""
Jun 18 12:39:08.493: INFO: stdout: "true"
Jun 18 12:39:08.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-hqm4n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:08.641: INFO: stderr: ""
Jun 18 12:39:08.641: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:39:08.641: INFO: validating pod update-demo-nautilus-hqm4n
Jun 18 12:39:08.666: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:39:08.666: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:39:08.666: INFO: update-demo-nautilus-hqm4n is verified up and running
STEP: scaling up the replication controller
Jun 18 12:39:08.668: INFO: scanned /root for discovery docs: <nil>
Jun 18 12:39:08.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:09.890: INFO: stderr: ""
Jun 18 12:39:09.890: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 18 12:39:09.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:10.036: INFO: stderr: ""
Jun 18 12:39:10.036: INFO: stdout: "update-demo-nautilus-hqm4n update-demo-nautilus-plnh7 "
Jun 18 12:39:10.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-hqm4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:10.174: INFO: stderr: ""
Jun 18 12:39:10.174: INFO: stdout: "true"
Jun 18 12:39:10.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-hqm4n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:10.387: INFO: stderr: ""
Jun 18 12:39:10.387: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:39:10.387: INFO: validating pod update-demo-nautilus-hqm4n
Jun 18 12:39:10.411: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:39:10.411: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:39:10.411: INFO: update-demo-nautilus-hqm4n is verified up and running
Jun 18 12:39:10.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-plnh7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:10.535: INFO: stderr: ""
Jun 18 12:39:10.535: INFO: stdout: "true"
Jun 18 12:39:10.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods update-demo-nautilus-plnh7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:10.672: INFO: stderr: ""
Jun 18 12:39:10.672: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 18 12:39:10.672: INFO: validating pod update-demo-nautilus-plnh7
Jun 18 12:39:10.707: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 18 12:39:10.707: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 18 12:39:10.707: INFO: update-demo-nautilus-plnh7 is verified up and running
STEP: using delete to clean up resources
Jun 18 12:39:10.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:10.886: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 12:39:10.886: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 18 12:39:10.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-g7bx9'
Jun 18 12:39:11.026: INFO: stderr: "No resources found.\n"
Jun 18 12:39:11.026: INFO: stdout: ""
Jun 18 12:39:11.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -l name=update-demo --namespace=e2e-tests-kubectl-g7bx9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 18 12:39:11.167: INFO: stderr: ""
Jun 18 12:39:11.167: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:39:11.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g7bx9" for this suite.
Jun 18 12:39:19.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:39:19.785: INFO: namespace: e2e-tests-kubectl-g7bx9, resource: bindings, ignored listing per whitelist
Jun 18 12:39:20.227: INFO: namespace e2e-tests-kubectl-g7bx9 deletion completed in 9.036202232s

• [SLOW TEST:30.619 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:39:20.227: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-s4h9k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:39:22.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-s4h9k" for this suite.
Jun 18 12:40:04.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:40:05.115: INFO: namespace: e2e-tests-kubelet-test-s4h9k, resource: bindings, ignored listing per whitelist
Jun 18 12:40:05.484: INFO: namespace e2e-tests-kubelet-test-s4h9k deletion completed in 42.653141106s

• [SLOW TEST:45.257 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:40:05.485: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5vhth
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 18 12:40:06.040: INFO: Waiting up to 5m0s for pod "downward-api-33349705-91c6-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-5vhth" to be "success or failure"
Jun 18 12:40:06.053: INFO: Pod "downward-api-33349705-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.020096ms
Jun 18 12:40:08.491: INFO: Pod "downward-api-33349705-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.45096525s
Jun 18 12:40:10.506: INFO: Pod "downward-api-33349705-91c6-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.466661348s
STEP: Saw pod success
Jun 18 12:40:10.506: INFO: Pod "downward-api-33349705-91c6-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:40:10.522: INFO: Trying to get logs from node 10.72.74.149 pod downward-api-33349705-91c6-11e9-bce2-ae54e022189f container dapi-container: <nil>
STEP: delete the pod
Jun 18 12:40:10.626: INFO: Waiting for pod downward-api-33349705-91c6-11e9-bce2-ae54e022189f to disappear
Jun 18 12:40:10.641: INFO: Pod downward-api-33349705-91c6-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:40:10.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5vhth" for this suite.
Jun 18 12:40:16.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:40:17.177: INFO: namespace: e2e-tests-downward-api-5vhth, resource: bindings, ignored listing per whitelist
Jun 18 12:40:17.278: INFO: namespace e2e-tests-downward-api-5vhth deletion completed in 6.619107117s

• [SLOW TEST:11.793 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:40:17.279: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bqgx7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jun 18 12:40:17.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-bqgx7'
Jun 18 12:40:18.049: INFO: stderr: ""
Jun 18 12:40:18.049: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jun 18 12:40:19.065: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 12:40:19.065: INFO: Found 0 / 1
Jun 18 12:40:20.063: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 12:40:20.063: INFO: Found 0 / 1
Jun 18 12:40:21.065: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 12:40:21.065: INFO: Found 1 / 1
Jun 18 12:40:21.065: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 18 12:40:21.081: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 12:40:21.081: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jun 18 12:40:21.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 logs redis-master-bhdmv redis-master --namespace=e2e-tests-kubectl-bqgx7'
Jun 18 12:40:21.351: INFO: stderr: ""
Jun 18 12:40:21.351: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Jun 12:40:19.478 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Jun 12:40:19.478 # Server started, Redis version 3.2.12\n1:M 18 Jun 12:40:19.478 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Jun 12:40:19.478 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jun 18 12:40:21.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 log redis-master-bhdmv redis-master --namespace=e2e-tests-kubectl-bqgx7 --tail=1'
Jun 18 12:40:21.523: INFO: stderr: ""
Jun 18 12:40:21.523: INFO: stdout: "1:M 18 Jun 12:40:19.478 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jun 18 12:40:21.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 log redis-master-bhdmv redis-master --namespace=e2e-tests-kubectl-bqgx7 --limit-bytes=1'
Jun 18 12:40:21.783: INFO: stderr: ""
Jun 18 12:40:21.783: INFO: stdout: " "
STEP: exposing timestamps
Jun 18 12:40:21.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 log redis-master-bhdmv redis-master --namespace=e2e-tests-kubectl-bqgx7 --tail=1 --timestamps'
Jun 18 12:40:21.928: INFO: stderr: ""
Jun 18 12:40:21.928: INFO: stdout: "2019-06-18T12:40:19.479252347Z 1:M 18 Jun 12:40:19.478 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jun 18 12:40:24.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 log redis-master-bhdmv redis-master --namespace=e2e-tests-kubectl-bqgx7 --since=1s'
Jun 18 12:40:24.876: INFO: stderr: ""
Jun 18 12:40:24.876: INFO: stdout: ""
Jun 18 12:40:24.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 log redis-master-bhdmv redis-master --namespace=e2e-tests-kubectl-bqgx7 --since=24h'
Jun 18 12:40:25.033: INFO: stderr: ""
Jun 18 12:40:25.033: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Jun 12:40:19.478 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Jun 12:40:19.478 # Server started, Redis version 3.2.12\n1:M 18 Jun 12:40:19.478 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Jun 12:40:19.478 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jun 18 12:40:25.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bqgx7'
Jun 18 12:40:25.174: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 12:40:25.174: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jun 18 12:40:25.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-bqgx7'
Jun 18 12:40:25.324: INFO: stderr: "No resources found.\n"
Jun 18 12:40:25.324: INFO: stdout: ""
Jun 18 12:40:25.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -l name=nginx --namespace=e2e-tests-kubectl-bqgx7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 18 12:40:25.469: INFO: stderr: ""
Jun 18 12:40:25.469: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:40:25.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bqgx7" for this suite.
Jun 18 12:40:33.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:40:33.932: INFO: namespace: e2e-tests-kubectl-bqgx7, resource: bindings, ignored listing per whitelist
Jun 18 12:40:34.402: INFO: namespace e2e-tests-kubectl-bqgx7 deletion completed in 8.913366606s

• [SLOW TEST:17.124 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:40:34.403: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-fwvsr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jun 18 12:40:38.757: INFO: created pod pod-service-account-defaultsa
Jun 18 12:40:38.757: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jun 18 12:40:38.775: INFO: created pod pod-service-account-mountsa
Jun 18 12:40:38.775: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jun 18 12:40:38.807: INFO: created pod pod-service-account-nomountsa
Jun 18 12:40:38.807: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jun 18 12:40:38.828: INFO: created pod pod-service-account-defaultsa-mountspec
Jun 18 12:40:38.828: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jun 18 12:40:38.844: INFO: created pod pod-service-account-mountsa-mountspec
Jun 18 12:40:38.844: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jun 18 12:40:38.863: INFO: created pod pod-service-account-nomountsa-mountspec
Jun 18 12:40:38.863: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jun 18 12:40:38.880: INFO: created pod pod-service-account-defaultsa-nomountspec
Jun 18 12:40:38.880: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jun 18 12:40:38.898: INFO: created pod pod-service-account-mountsa-nomountspec
Jun 18 12:40:38.898: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jun 18 12:40:38.920: INFO: created pod pod-service-account-nomountsa-nomountspec
Jun 18 12:40:38.920: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:40:38.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-fwvsr" for this suite.
Jun 18 12:40:47.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:40:47.235: INFO: namespace: e2e-tests-svcaccounts-fwvsr, resource: bindings, ignored listing per whitelist
Jun 18 12:40:47.562: INFO: namespace e2e-tests-svcaccounts-fwvsr deletion completed in 8.60923952s

• [SLOW TEST:13.160 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:40:47.563: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-r8s22
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jun 18 12:40:49.276: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-r8s22,SelfLink:/api/v1/namespaces/e2e-tests-watch-r8s22/configmaps/e2e-watch-test-watch-closed,UID:4c444736-91c6-11e9-bf44-fa6f350b29f0,ResourceVersion:104495,Generation:0,CreationTimestamp:2019-06-18 12:40:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 18 12:40:49.276: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-r8s22,SelfLink:/api/v1/namespaces/e2e-tests-watch-r8s22/configmaps/e2e-watch-test-watch-closed,UID:4c444736-91c6-11e9-bf44-fa6f350b29f0,ResourceVersion:104496,Generation:0,CreationTimestamp:2019-06-18 12:40:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jun 18 12:40:49.334: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-r8s22,SelfLink:/api/v1/namespaces/e2e-tests-watch-r8s22/configmaps/e2e-watch-test-watch-closed,UID:4c444736-91c6-11e9-bf44-fa6f350b29f0,ResourceVersion:104497,Generation:0,CreationTimestamp:2019-06-18 12:40:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 18 12:40:49.334: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-r8s22,SelfLink:/api/v1/namespaces/e2e-tests-watch-r8s22/configmaps/e2e-watch-test-watch-closed,UID:4c444736-91c6-11e9-bf44-fa6f350b29f0,ResourceVersion:104498,Generation:0,CreationTimestamp:2019-06-18 12:40:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:40:49.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-r8s22" for this suite.
Jun 18 12:40:57.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:40:59.019: INFO: namespace: e2e-tests-watch-r8s22, resource: bindings, ignored listing per whitelist
Jun 18 12:40:59.200: INFO: namespace e2e-tests-watch-r8s22 deletion completed in 9.843509494s

• [SLOW TEST:11.637 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:40:59.201: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fhhjx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jun 18 12:41:00.632: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-953583206 proxy --unix-socket=/tmp/kubectl-proxy-unix640593037/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:41:00.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fhhjx" for this suite.
Jun 18 12:41:06.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:41:06.833: INFO: namespace: e2e-tests-kubectl-fhhjx, resource: bindings, ignored listing per whitelist
Jun 18 12:41:07.290: INFO: namespace e2e-tests-kubectl-fhhjx deletion completed in 6.563286468s

• [SLOW TEST:8.090 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:41:07.291: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qbxc5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:41:07.873: INFO: Waiting up to 5m0s for pod "downwardapi-volume-580f401e-91c6-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-qbxc5" to be "success or failure"
Jun 18 12:41:07.888: INFO: Pod "downwardapi-volume-580f401e-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.887166ms
Jun 18 12:41:09.904: INFO: Pod "downwardapi-volume-580f401e-91c6-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030609487s
STEP: Saw pod success
Jun 18 12:41:09.904: INFO: Pod "downwardapi-volume-580f401e-91c6-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:41:09.919: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-580f401e-91c6-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:41:10.006: INFO: Waiting for pod downwardapi-volume-580f401e-91c6-11e9-bce2-ae54e022189f to disappear
Jun 18 12:41:10.020: INFO: Pod downwardapi-volume-580f401e-91c6-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:41:10.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qbxc5" for this suite.
Jun 18 12:41:18.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:41:18.605: INFO: namespace: e2e-tests-downward-api-qbxc5, resource: bindings, ignored listing per whitelist
Jun 18 12:41:18.746: INFO: namespace e2e-tests-downward-api-qbxc5 deletion completed in 8.703851603s

• [SLOW TEST:11.455 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:41:18.746: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-fqzhc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-f57z
STEP: Creating a pod to test atomic-volume-subpath
Jun 18 12:41:19.350: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-f57z" in namespace "e2e-tests-subpath-fqzhc" to be "success or failure"
Jun 18 12:41:19.366: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Pending", Reason="", readiness=false. Elapsed: 15.492815ms
Jun 18 12:41:21.384: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033799726s
Jun 18 12:41:23.399: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 4.048860302s
Jun 18 12:41:26.117: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 6.767355268s
Jun 18 12:41:28.160: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 8.809669844s
Jun 18 12:41:30.174: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 10.824325251s
Jun 18 12:41:32.189: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 12.83875514s
Jun 18 12:41:34.203: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 14.853447433s
Jun 18 12:41:36.218: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 16.867841855s
Jun 18 12:41:38.253: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 18.903163908s
Jun 18 12:41:40.268: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Running", Reason="", readiness=false. Elapsed: 20.918148648s
Jun 18 12:41:42.286: INFO: Pod "pod-subpath-test-projected-f57z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.935935489s
STEP: Saw pod success
Jun 18 12:41:42.286: INFO: Pod "pod-subpath-test-projected-f57z" satisfied condition "success or failure"
Jun 18 12:41:42.300: INFO: Trying to get logs from node 10.72.74.143 pod pod-subpath-test-projected-f57z container test-container-subpath-projected-f57z: <nil>
STEP: delete the pod
Jun 18 12:41:42.383: INFO: Waiting for pod pod-subpath-test-projected-f57z to disappear
Jun 18 12:41:42.397: INFO: Pod pod-subpath-test-projected-f57z no longer exists
STEP: Deleting pod pod-subpath-test-projected-f57z
Jun 18 12:41:42.397: INFO: Deleting pod "pod-subpath-test-projected-f57z" in namespace "e2e-tests-subpath-fqzhc"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:41:42.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fqzhc" for this suite.
Jun 18 12:41:48.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:41:48.962: INFO: namespace: e2e-tests-subpath-fqzhc, resource: bindings, ignored listing per whitelist
Jun 18 12:41:49.043: INFO: namespace e2e-tests-subpath-fqzhc deletion completed in 6.613984316s

• [SLOW TEST:30.297 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:41:49.044: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-j2bcl
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 12:41:49.525: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:41:50.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-j2bcl" for this suite.
Jun 18 12:41:56.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:41:56.985: INFO: namespace: e2e-tests-custom-resource-definition-j2bcl, resource: bindings, ignored listing per whitelist
Jun 18 12:41:57.396: INFO: namespace e2e-tests-custom-resource-definition-j2bcl deletion completed in 6.610856577s

• [SLOW TEST:8.352 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:41:57.396: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-tbkw4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-tbkw4/secret-test-75dbfaec-91c6-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 12:41:57.879: INFO: Waiting up to 5m0s for pod "pod-configmaps-75ddee40-91c6-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-tbkw4" to be "success or failure"
Jun 18 12:41:57.892: INFO: Pod "pod-configmaps-75ddee40-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.249916ms
Jun 18 12:41:59.925: INFO: Pod "pod-configmaps-75ddee40-91c6-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046462878s
STEP: Saw pod success
Jun 18 12:41:59.925: INFO: Pod "pod-configmaps-75ddee40-91c6-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:41:59.941: INFO: Trying to get logs from node 10.72.74.144 pod pod-configmaps-75ddee40-91c6-11e9-bce2-ae54e022189f container env-test: <nil>
STEP: delete the pod
Jun 18 12:42:00.017: INFO: Waiting for pod pod-configmaps-75ddee40-91c6-11e9-bce2-ae54e022189f to disappear
Jun 18 12:42:00.037: INFO: Pod pod-configmaps-75ddee40-91c6-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:42:00.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tbkw4" for this suite.
Jun 18 12:42:08.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:42:08.365: INFO: namespace: e2e-tests-secrets-tbkw4, resource: bindings, ignored listing per whitelist
Jun 18 12:42:08.636: INFO: namespace e2e-tests-secrets-tbkw4 deletion completed in 8.579104705s

• [SLOW TEST:11.240 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:42:08.637: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-bt9dv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:43:09.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bt9dv" for this suite.
Jun 18 12:43:33.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:43:33.572: INFO: namespace: e2e-tests-container-probe-bt9dv, resource: bindings, ignored listing per whitelist
Jun 18 12:43:33.799: INFO: namespace e2e-tests-container-probe-bt9dv deletion completed in 24.599593906s

• [SLOW TEST:85.162 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:43:33.799: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-gsxkf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-n698v
STEP: Creating secret with name secret-test-af5aec88-91c6-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 12:43:34.572: INFO: Waiting up to 5m0s for pod "pod-secrets-af800d8f-91c6-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-gsxkf" to be "success or failure"
Jun 18 12:43:34.591: INFO: Pod "pod-secrets-af800d8f-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.94049ms
Jun 18 12:43:36.606: INFO: Pod "pod-secrets-af800d8f-91c6-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033861853s
STEP: Saw pod success
Jun 18 12:43:36.606: INFO: Pod "pod-secrets-af800d8f-91c6-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:43:36.624: INFO: Trying to get logs from node 10.72.74.143 pod pod-secrets-af800d8f-91c6-11e9-bce2-ae54e022189f container secret-volume-test: <nil>
STEP: delete the pod
Jun 18 12:43:36.709: INFO: Waiting for pod pod-secrets-af800d8f-91c6-11e9-bce2-ae54e022189f to disappear
Jun 18 12:43:36.724: INFO: Pod pod-secrets-af800d8f-91c6-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:43:36.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gsxkf" for this suite.
Jun 18 12:43:42.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:43:43.071: INFO: namespace: e2e-tests-secrets-gsxkf, resource: bindings, ignored listing per whitelist
Jun 18 12:43:43.391: INFO: namespace e2e-tests-secrets-gsxkf deletion completed in 6.643578016s
STEP: Destroying namespace "e2e-tests-secret-namespace-n698v" for this suite.
Jun 18 12:43:51.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:43:52.118: INFO: namespace: e2e-tests-secret-namespace-n698v, resource: bindings, ignored listing per whitelist
Jun 18 12:43:52.173: INFO: namespace e2e-tests-secret-namespace-n698v deletion completed in 8.782295194s

• [SLOW TEST:18.375 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:43:52.174: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s499m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun 18 12:43:57.284: INFO: Successfully updated pod "annotationupdateba45f552-91c6-11e9-bce2-ae54e022189f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:43:59.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s499m" for this suite.
Jun 18 12:44:23.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:44:23.668: INFO: namespace: e2e-tests-projected-s499m, resource: bindings, ignored listing per whitelist
Jun 18 12:44:23.980: INFO: namespace e2e-tests-projected-s499m deletion completed in 24.607799233s

• [SLOW TEST:31.806 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:44:23.980: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9p99t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cd3aee55-91c6-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:44:24.472: INFO: Waiting up to 5m0s for pod "pod-configmaps-cd3cf9b9-91c6-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-9p99t" to be "success or failure"
Jun 18 12:44:24.486: INFO: Pod "pod-configmaps-cd3cf9b9-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.683547ms
Jun 18 12:44:26.501: INFO: Pod "pod-configmaps-cd3cf9b9-91c6-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029483086s
STEP: Saw pod success
Jun 18 12:44:26.501: INFO: Pod "pod-configmaps-cd3cf9b9-91c6-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:44:26.598: INFO: Trying to get logs from node 10.72.74.149 pod pod-configmaps-cd3cf9b9-91c6-11e9-bce2-ae54e022189f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:44:26.677: INFO: Waiting for pod pod-configmaps-cd3cf9b9-91c6-11e9-bce2-ae54e022189f to disappear
Jun 18 12:44:26.693: INFO: Pod pod-configmaps-cd3cf9b9-91c6-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:44:26.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9p99t" for this suite.
Jun 18 12:44:32.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:44:33.231: INFO: namespace: e2e-tests-configmap-9p99t, resource: bindings, ignored listing per whitelist
Jun 18 12:44:33.386: INFO: namespace e2e-tests-configmap-9p99t deletion completed in 6.673476284s

• [SLOW TEST:9.406 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:44:33.388: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-85xj7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jun 18 12:44:33.924: INFO: Waiting up to 5m0s for pod "var-expansion-d2df5c2b-91c6-11e9-bce2-ae54e022189f" in namespace "e2e-tests-var-expansion-85xj7" to be "success or failure"
Jun 18 12:44:33.938: INFO: Pod "var-expansion-d2df5c2b-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.179002ms
Jun 18 12:44:35.954: INFO: Pod "var-expansion-d2df5c2b-91c6-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030236549s
STEP: Saw pod success
Jun 18 12:44:35.954: INFO: Pod "var-expansion-d2df5c2b-91c6-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:44:35.968: INFO: Trying to get logs from node 10.72.74.143 pod var-expansion-d2df5c2b-91c6-11e9-bce2-ae54e022189f container dapi-container: <nil>
STEP: delete the pod
Jun 18 12:44:36.084: INFO: Waiting for pod var-expansion-d2df5c2b-91c6-11e9-bce2-ae54e022189f to disappear
Jun 18 12:44:36.098: INFO: Pod var-expansion-d2df5c2b-91c6-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:44:36.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-85xj7" for this suite.
Jun 18 12:44:42.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:44:42.422: INFO: namespace: e2e-tests-var-expansion-85xj7, resource: bindings, ignored listing per whitelist
Jun 18 12:44:42.663: INFO: namespace e2e-tests-var-expansion-85xj7 deletion completed in 6.540842073s

• [SLOW TEST:9.276 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:44:42.664: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sw4z8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d86097d7-91c6-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 12:44:43.167: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d862b6b5-91c6-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-sw4z8" to be "success or failure"
Jun 18 12:44:43.181: INFO: Pod "pod-projected-secrets-d862b6b5-91c6-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.719758ms
Jun 18 12:44:45.198: INFO: Pod "pod-projected-secrets-d862b6b5-91c6-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031119413s
STEP: Saw pod success
Jun 18 12:44:45.199: INFO: Pod "pod-projected-secrets-d862b6b5-91c6-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:44:45.212: INFO: Trying to get logs from node 10.72.74.144 pod pod-projected-secrets-d862b6b5-91c6-11e9-bce2-ae54e022189f container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 18 12:44:45.285: INFO: Waiting for pod pod-projected-secrets-d862b6b5-91c6-11e9-bce2-ae54e022189f to disappear
Jun 18 12:44:45.299: INFO: Pod pod-projected-secrets-d862b6b5-91c6-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:44:45.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sw4z8" for this suite.
Jun 18 12:44:51.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:44:51.710: INFO: namespace: e2e-tests-projected-sw4z8, resource: bindings, ignored listing per whitelist
Jun 18 12:44:51.976: INFO: namespace e2e-tests-projected-sw4z8 deletion completed in 6.654290333s

• [SLOW TEST:9.312 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:44:51.980: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-p76x4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 18 12:44:52.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-p76x4'
Jun 18 12:44:52.568: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 18 12:44:52.568: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jun 18 12:44:56.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-p76x4'
Jun 18 12:44:56.798: INFO: stderr: ""
Jun 18 12:44:56.798: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:44:56.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p76x4" for this suite.
Jun 18 12:45:20.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:45:21.243: INFO: namespace: e2e-tests-kubectl-p76x4, resource: bindings, ignored listing per whitelist
Jun 18 12:45:21.447: INFO: namespace e2e-tests-kubectl-p76x4 deletion completed in 24.627880076s

• [SLOW TEST:29.467 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:45:21.447: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-lp2qj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:45:23.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-lp2qj" for this suite.
Jun 18 12:46:16.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:46:16.369: INFO: namespace: e2e-tests-kubelet-test-lp2qj, resource: bindings, ignored listing per whitelist
Jun 18 12:46:16.665: INFO: namespace e2e-tests-kubelet-test-lp2qj deletion completed in 52.653466484s

• [SLOW TEST:55.218 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:46:16.666: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-nrsx2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 18 12:46:17.162: INFO: Waiting up to 5m0s for pod "pod-10697156-91c7-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-nrsx2" to be "success or failure"
Jun 18 12:46:17.176: INFO: Pod "pod-10697156-91c7-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.076494ms
Jun 18 12:46:19.190: INFO: Pod "pod-10697156-91c7-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028208675s
Jun 18 12:46:21.205: INFO: Pod "pod-10697156-91c7-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043087296s
STEP: Saw pod success
Jun 18 12:46:21.205: INFO: Pod "pod-10697156-91c7-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:46:21.220: INFO: Trying to get logs from node 10.72.74.144 pod pod-10697156-91c7-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:46:21.300: INFO: Waiting for pod pod-10697156-91c7-11e9-bce2-ae54e022189f to disappear
Jun 18 12:46:21.314: INFO: Pod pod-10697156-91c7-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:46:21.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nrsx2" for this suite.
Jun 18 12:46:27.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:46:28.146: INFO: namespace: e2e-tests-emptydir-nrsx2, resource: bindings, ignored listing per whitelist
Jun 18 12:46:28.456: INFO: namespace e2e-tests-emptydir-nrsx2 deletion completed in 7.120905195s

• [SLOW TEST:11.790 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:46:28.456: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-pvzpw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 12:46:30.293: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jun 18 12:46:35.310: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 18 12:46:35.310: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jun 18 12:46:37.341: INFO: Creating deployment "test-rollover-deployment"
Jun 18 12:46:37.374: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jun 18 12:46:39.407: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jun 18 12:46:39.434: INFO: Ensure that both replica sets have 1 created replica
Jun 18 12:46:39.461: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jun 18 12:46:39.491: INFO: Updating deployment test-rollover-deployment
Jun 18 12:46:39.491: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jun 18 12:46:41.522: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jun 18 12:46:41.600: INFO: Make sure deployment "test-rollover-deployment" is complete
Jun 18 12:46:41.628: INFO: all replica sets need to contain the pod-template-hash label
Jun 18 12:46:41.628: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458801, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 18 12:46:44.311: INFO: all replica sets need to contain the pod-template-hash label
Jun 18 12:46:44.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458801, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 18 12:46:45.655: INFO: all replica sets need to contain the pod-template-hash label
Jun 18 12:46:45.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458801, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 18 12:46:47.698: INFO: all replica sets need to contain the pod-template-hash label
Jun 18 12:46:47.699: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458801, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 18 12:46:49.656: INFO: all replica sets need to contain the pod-template-hash label
Jun 18 12:46:49.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458801, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696458797, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 18 12:46:51.658: INFO: 
Jun 18 12:46:51.658: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 18 12:46:51.704: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-pvzpw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pvzpw/deployments/test-rollover-deployment,UID:1c75ac7e-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:105749,Generation:2,CreationTimestamp:2019-06-18 12:46:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-18 12:46:37 +0000 UTC 2019-06-18 12:46:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-18 12:46:51 +0000 UTC 2019-06-18 12:46:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun 18 12:46:51.719: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-pvzpw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pvzpw/replicasets/test-rollover-deployment-6b7f9d6597,UID:1dbce917-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:105740,Generation:2,CreationTimestamp:2019-06-18 12:46:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1c75ac7e-91c7-11e9-bf44-fa6f350b29f0 0xc002249367 0xc002249368}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun 18 12:46:51.719: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jun 18 12:46:51.719: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-pvzpw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pvzpw/replicasets/test-rollover-controller,UID:183d8251-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:105748,Generation:2,CreationTimestamp:2019-06-18 12:46:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1c75ac7e-91c7-11e9-bf44-fa6f350b29f0 0xc0022491d7 0xc0022491d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 18 12:46:51.719: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-pvzpw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-pvzpw/replicasets/test-rollover-deployment-6586df867b,UID:1c7e8a0e-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:105706,Generation:2,CreationTimestamp:2019-06-18 12:46:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 1c75ac7e-91c7-11e9-bf44-fa6f350b29f0 0xc002249297 0xc002249298}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 18 12:46:51.734: INFO: Pod "test-rollover-deployment-6b7f9d6597-8gsnj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-8gsnj,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-pvzpw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-pvzpw/pods/test-rollover-deployment-6b7f9d6597-8gsnj,UID:1dc5b87c-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:105721,Generation:0,CreationTimestamp:2019-06-18 12:46:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 1dbce917-91c7-11e9-bf44-fa6f350b29f0 0xc0021543f7 0xc0021543f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rkgg7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rkgg7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rkgg7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002154600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002154620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:46:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:46:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:46:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 12:46:39 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:172.30.114.9,StartTime:2019-06-18 12:46:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-18 12:46:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://ee6d4938b0a456a3060d09834073d7f7189870a173aa6dccd61082f995a7c7b8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:46:51.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-pvzpw" for this suite.
Jun 18 12:46:59.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:47:00.332: INFO: namespace: e2e-tests-deployment-pvzpw, resource: bindings, ignored listing per whitelist
Jun 18 12:47:00.490: INFO: namespace e2e-tests-deployment-pvzpw deletion completed in 8.736759518s

• [SLOW TEST:32.034 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:47:00.490: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-x7flg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-7jfd
STEP: Creating a pod to test atomic-volume-subpath
Jun 18 12:47:00.990: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-7jfd" in namespace "e2e-tests-subpath-x7flg" to be "success or failure"
Jun 18 12:47:01.006: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Pending", Reason="", readiness=false. Elapsed: 15.79041ms
Jun 18 12:47:03.021: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03112706s
Jun 18 12:47:05.036: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 4.046073067s
Jun 18 12:47:07.055: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 6.064696983s
Jun 18 12:47:09.089: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 8.098673934s
Jun 18 12:47:11.105: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 10.114520585s
Jun 18 12:47:13.120: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 12.129517708s
Jun 18 12:47:15.135: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 14.144368402s
Jun 18 12:47:17.150: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 16.159650311s
Jun 18 12:47:19.182: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 18.191589585s
Jun 18 12:47:21.198: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 20.207295315s
Jun 18 12:47:23.216: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Running", Reason="", readiness=false. Elapsed: 22.225507535s
Jun 18 12:47:25.231: INFO: Pod "pod-subpath-test-downwardapi-7jfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.240625439s
STEP: Saw pod success
Jun 18 12:47:25.231: INFO: Pod "pod-subpath-test-downwardapi-7jfd" satisfied condition "success or failure"
Jun 18 12:47:25.247: INFO: Trying to get logs from node 10.72.74.149 pod pod-subpath-test-downwardapi-7jfd container test-container-subpath-downwardapi-7jfd: <nil>
STEP: delete the pod
Jun 18 12:47:25.321: INFO: Waiting for pod pod-subpath-test-downwardapi-7jfd to disappear
Jun 18 12:47:25.335: INFO: Pod pod-subpath-test-downwardapi-7jfd no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-7jfd
Jun 18 12:47:25.335: INFO: Deleting pod "pod-subpath-test-downwardapi-7jfd" in namespace "e2e-tests-subpath-x7flg"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:47:25.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-x7flg" for this suite.
Jun 18 12:47:33.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:47:33.575: INFO: namespace: e2e-tests-subpath-x7flg, resource: bindings, ignored listing per whitelist
Jun 18 12:47:33.912: INFO: namespace e2e-tests-subpath-x7flg deletion completed in 8.544396817s

• [SLOW TEST:33.422 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:47:33.912: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-nqbn2
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-3e76f649-91c7-11e9-bce2-ae54e022189f
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:47:38.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nqbn2" for this suite.
Jun 18 12:48:02.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:48:02.699: INFO: namespace: e2e-tests-configmap-nqbn2, resource: bindings, ignored listing per whitelist
Jun 18 12:48:03.153: INFO: namespace e2e-tests-configmap-nqbn2 deletion completed in 24.579861794s

• [SLOW TEST:29.240 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:48:03.153: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-zzv98
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jun 18 12:48:03.724: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zzv98,SelfLink:/api/v1/namespaces/e2e-tests-watch-zzv98/configmaps/e2e-watch-test-label-changed,UID:4fe188fe-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:106055,Generation:0,CreationTimestamp:2019-06-18 12:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 18 12:48:03.724: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zzv98,SelfLink:/api/v1/namespaces/e2e-tests-watch-zzv98/configmaps/e2e-watch-test-label-changed,UID:4fe188fe-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:106056,Generation:0,CreationTimestamp:2019-06-18 12:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 18 12:48:03.724: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zzv98,SelfLink:/api/v1/namespaces/e2e-tests-watch-zzv98/configmaps/e2e-watch-test-label-changed,UID:4fe188fe-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:106057,Generation:0,CreationTimestamp:2019-06-18 12:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jun 18 12:48:13.842: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zzv98,SelfLink:/api/v1/namespaces/e2e-tests-watch-zzv98/configmaps/e2e-watch-test-label-changed,UID:4fe188fe-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:106075,Generation:0,CreationTimestamp:2019-06-18 12:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 18 12:48:13.842: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zzv98,SelfLink:/api/v1/namespaces/e2e-tests-watch-zzv98/configmaps/e2e-watch-test-label-changed,UID:4fe188fe-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:106076,Generation:0,CreationTimestamp:2019-06-18 12:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jun 18 12:48:13.842: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-zzv98,SelfLink:/api/v1/namespaces/e2e-tests-watch-zzv98/configmaps/e2e-watch-test-label-changed,UID:4fe188fe-91c7-11e9-bf44-fa6f350b29f0,ResourceVersion:106077,Generation:0,CreationTimestamp:2019-06-18 12:48:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:48:13.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zzv98" for this suite.
Jun 18 12:48:21.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:48:22.388: INFO: namespace: e2e-tests-watch-zzv98, resource: bindings, ignored listing per whitelist
Jun 18 12:48:22.546: INFO: namespace e2e-tests-watch-zzv98 deletion completed in 8.682920468s

• [SLOW TEST:19.393 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:48:22.551: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2rl55
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:48:23.110: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b7b84af-91c7-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-2rl55" to be "success or failure"
Jun 18 12:48:23.125: INFO: Pod "downwardapi-volume-5b7b84af-91c7-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.28053ms
Jun 18 12:48:25.157: INFO: Pod "downwardapi-volume-5b7b84af-91c7-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046146533s
Jun 18 12:48:27.171: INFO: Pod "downwardapi-volume-5b7b84af-91c7-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0607141s
STEP: Saw pod success
Jun 18 12:48:27.171: INFO: Pod "downwardapi-volume-5b7b84af-91c7-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:48:27.186: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-5b7b84af-91c7-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:48:27.327: INFO: Waiting for pod downwardapi-volume-5b7b84af-91c7-11e9-bce2-ae54e022189f to disappear
Jun 18 12:48:27.341: INFO: Pod downwardapi-volume-5b7b84af-91c7-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:48:27.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2rl55" for this suite.
Jun 18 12:48:33.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:48:33.903: INFO: namespace: e2e-tests-downward-api-2rl55, resource: bindings, ignored listing per whitelist
Jun 18 12:48:33.943: INFO: namespace e2e-tests-downward-api-2rl55 deletion completed in 6.577511248s

• [SLOW TEST:11.393 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:48:33.944: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-z2gvj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-z2gvj
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jun 18 12:48:34.457: INFO: Found 0 stateful pods, waiting for 3
Jun 18 12:48:44.491: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:48:44.491: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:48:44.491: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jun 18 12:48:44.580: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jun 18 12:48:54.696: INFO: Updating stateful set ss2
Jun 18 12:48:54.725: INFO: Waiting for Pod e2e-tests-statefulset-z2gvj/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jun 18 12:49:04.870: INFO: Found 2 stateful pods, waiting for 3
Jun 18 12:49:14.903: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:49:14.903: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:49:14.903: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jun 18 12:49:16.257: INFO: Updating stateful set ss2
Jun 18 12:49:16.304: INFO: Waiting for Pod e2e-tests-statefulset-z2gvj/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 18 12:49:26.391: INFO: Updating stateful set ss2
Jun 18 12:49:26.426: INFO: Waiting for StatefulSet e2e-tests-statefulset-z2gvj/ss2 to complete update
Jun 18 12:49:26.426: INFO: Waiting for Pod e2e-tests-statefulset-z2gvj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun 18 12:49:36.478: INFO: Waiting for StatefulSet e2e-tests-statefulset-z2gvj/ss2 to complete update
Jun 18 12:49:36.479: INFO: Waiting for Pod e2e-tests-statefulset-z2gvj/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 18 12:49:46.460: INFO: Deleting all statefulset in ns e2e-tests-statefulset-z2gvj
Jun 18 12:49:46.491: INFO: Scaling statefulset ss2 to 0
Jun 18 12:50:06.559: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 12:50:06.573: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:50:07.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-z2gvj" for this suite.
Jun 18 12:50:15.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:50:15.712: INFO: namespace: e2e-tests-statefulset-z2gvj, resource: bindings, ignored listing per whitelist
Jun 18 12:50:16.011: INFO: namespace e2e-tests-statefulset-z2gvj deletion completed in 8.611406983s

• [SLOW TEST:102.067 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:50:16.013: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hj4qw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jun 18 12:50:16.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 api-versions'
Jun 18 12:50:16.598: INFO: stderr: ""
Jun 18 12:50:16.598: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:50:16.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hj4qw" for this suite.
Jun 18 12:50:22.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:50:22.799: INFO: namespace: e2e-tests-kubectl-hj4qw, resource: bindings, ignored listing per whitelist
Jun 18 12:50:23.242: INFO: namespace e2e-tests-kubectl-hj4qw deletion completed in 6.628130348s

• [SLOW TEST:7.230 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:50:23.243: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-w8bdc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jun 18 12:50:24.254: INFO: Waiting up to 5m0s for pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-hf4nf" in namespace "e2e-tests-svcaccounts-w8bdc" to be "success or failure"
Jun 18 12:50:24.268: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-hf4nf": Phase="Pending", Reason="", readiness=false. Elapsed: 13.342654ms
Jun 18 12:50:26.283: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-hf4nf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028326579s
Jun 18 12:50:28.304: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-hf4nf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050114865s
STEP: Saw pod success
Jun 18 12:50:28.304: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-hf4nf" satisfied condition "success or failure"
Jun 18 12:50:28.319: INFO: Trying to get logs from node 10.72.74.144 pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-hf4nf container token-test: <nil>
STEP: delete the pod
Jun 18 12:50:28.464: INFO: Waiting for pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-hf4nf to disappear
Jun 18 12:50:28.480: INFO: Pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-hf4nf no longer exists
STEP: Creating a pod to test consume service account root CA
Jun 18 12:50:28.498: INFO: Waiting up to 5m0s for pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-lxlps" in namespace "e2e-tests-svcaccounts-w8bdc" to be "success or failure"
Jun 18 12:50:28.512: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-lxlps": Phase="Pending", Reason="", readiness=false. Elapsed: 14.127458ms
Jun 18 12:50:30.546: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-lxlps": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047955845s
Jun 18 12:50:32.562: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-lxlps": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064304511s
STEP: Saw pod success
Jun 18 12:50:32.562: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-lxlps" satisfied condition "success or failure"
Jun 18 12:50:32.577: INFO: Trying to get logs from node 10.72.74.144 pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-lxlps container root-ca-test: <nil>
STEP: delete the pod
Jun 18 12:50:32.650: INFO: Waiting for pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-lxlps to disappear
Jun 18 12:50:32.664: INFO: Pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-lxlps no longer exists
STEP: Creating a pod to test consume service account namespace
Jun 18 12:50:32.681: INFO: Waiting up to 5m0s for pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-7n5hk" in namespace "e2e-tests-svcaccounts-w8bdc" to be "success or failure"
Jun 18 12:50:32.697: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-7n5hk": Phase="Pending", Reason="", readiness=false. Elapsed: 16.105875ms
Jun 18 12:50:34.873: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-7n5hk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.191852932s
Jun 18 12:50:37.005: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-7n5hk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.32418989s
STEP: Saw pod success
Jun 18 12:50:37.005: INFO: Pod "pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-7n5hk" satisfied condition "success or failure"
Jun 18 12:50:37.020: INFO: Trying to get logs from node 10.72.74.144 pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-7n5hk container namespace-test: <nil>
STEP: delete the pod
Jun 18 12:50:37.102: INFO: Waiting for pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-7n5hk to disappear
Jun 18 12:50:37.115: INFO: Pod pod-service-account-a3b08a3b-91c7-11e9-bce2-ae54e022189f-7n5hk no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:50:37.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-w8bdc" for this suite.
Jun 18 12:50:45.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:50:45.726: INFO: namespace: e2e-tests-svcaccounts-w8bdc, resource: bindings, ignored listing per whitelist
Jun 18 12:50:45.751: INFO: namespace e2e-tests-svcaccounts-w8bdc deletion completed in 8.612077285s

• [SLOW TEST:22.509 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:50:45.752: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-jtl5n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jun 18 12:50:46.588: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:50:47.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-jtl5n" for this suite.
Jun 18 12:50:53.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:50:54.227: INFO: namespace: e2e-tests-replication-controller-jtl5n, resource: bindings, ignored listing per whitelist
Jun 18 12:50:54.355: INFO: namespace e2e-tests-replication-controller-jtl5n deletion completed in 6.592482624s

• [SLOW TEST:8.603 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:50:54.355: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2nc6n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b5f65992-91c7-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 12:50:54.921: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b5f857a9-91c7-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-2nc6n" to be "success or failure"
Jun 18 12:50:54.935: INFO: Pod "pod-projected-secrets-b5f857a9-91c7-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.614617ms
Jun 18 12:50:56.950: INFO: Pod "pod-projected-secrets-b5f857a9-91c7-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028433459s
STEP: Saw pod success
Jun 18 12:50:56.950: INFO: Pod "pod-projected-secrets-b5f857a9-91c7-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:50:56.964: INFO: Trying to get logs from node 10.72.74.143 pod pod-projected-secrets-b5f857a9-91c7-11e9-bce2-ae54e022189f container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 18 12:50:57.044: INFO: Waiting for pod pod-projected-secrets-b5f857a9-91c7-11e9-bce2-ae54e022189f to disappear
Jun 18 12:50:57.057: INFO: Pod pod-projected-secrets-b5f857a9-91c7-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:50:57.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2nc6n" for this suite.
Jun 18 12:51:03.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:51:04.220: INFO: namespace: e2e-tests-projected-2nc6n, resource: bindings, ignored listing per whitelist
Jun 18 12:51:04.620: INFO: namespace e2e-tests-projected-2nc6n deletion completed in 7.542171892s

• [SLOW TEST:10.265 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:51:04.622: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-5x46v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 12:51:33.199: INFO: Container started at 2019-06-18 12:51:08 +0000 UTC, pod became ready at 2019-06-18 12:51:31 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:51:33.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5x46v" for this suite.
Jun 18 12:51:57.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:51:57.326: INFO: namespace: e2e-tests-container-probe-5x46v, resource: bindings, ignored listing per whitelist
Jun 18 12:51:57.773: INFO: namespace e2e-tests-container-probe-5x46v deletion completed in 24.555655445s

• [SLOW TEST:53.151 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:51:57.774: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kw7q9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-dbb68e4c-91c7-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:51:58.257: INFO: Waiting up to 5m0s for pod "pod-configmaps-dbb893a8-91c7-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-kw7q9" to be "success or failure"
Jun 18 12:51:58.272: INFO: Pod "pod-configmaps-dbb893a8-91c7-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.468636ms
Jun 18 12:52:00.304: INFO: Pod "pod-configmaps-dbb893a8-91c7-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047001025s
Jun 18 12:52:02.320: INFO: Pod "pod-configmaps-dbb893a8-91c7-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062795379s
STEP: Saw pod success
Jun 18 12:52:02.320: INFO: Pod "pod-configmaps-dbb893a8-91c7-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:52:02.384: INFO: Trying to get logs from node 10.72.74.144 pod pod-configmaps-dbb893a8-91c7-11e9-bce2-ae54e022189f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:52:02.464: INFO: Waiting for pod pod-configmaps-dbb893a8-91c7-11e9-bce2-ae54e022189f to disappear
Jun 18 12:52:02.479: INFO: Pod pod-configmaps-dbb893a8-91c7-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:52:02.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kw7q9" for this suite.
Jun 18 12:52:08.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:52:08.772: INFO: namespace: e2e-tests-configmap-kw7q9, resource: bindings, ignored listing per whitelist
Jun 18 12:52:09.060: INFO: namespace e2e-tests-configmap-kw7q9 deletion completed in 6.560492233s

• [SLOW TEST:11.286 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:52:09.061: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-hcsms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 12:52:09.610: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jun 18 12:52:09.640: INFO: Number of nodes with available pods: 0
Jun 18 12:52:09.640: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jun 18 12:52:09.702: INFO: Number of nodes with available pods: 0
Jun 18 12:52:09.702: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:10.737: INFO: Number of nodes with available pods: 0
Jun 18 12:52:10.737: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:11.717: INFO: Number of nodes with available pods: 1
Jun 18 12:52:11.717: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jun 18 12:52:11.782: INFO: Number of nodes with available pods: 1
Jun 18 12:52:11.782: INFO: Number of running nodes: 0, number of available pods: 1
Jun 18 12:52:12.797: INFO: Number of nodes with available pods: 0
Jun 18 12:52:12.797: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jun 18 12:52:12.899: INFO: Number of nodes with available pods: 0
Jun 18 12:52:12.899: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:13.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:13.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:14.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:14.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:15.915: INFO: Number of nodes with available pods: 0
Jun 18 12:52:15.915: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:16.913: INFO: Number of nodes with available pods: 0
Jun 18 12:52:16.913: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:17.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:17.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:18.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:18.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:19.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:19.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:20.932: INFO: Number of nodes with available pods: 0
Jun 18 12:52:20.932: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:21.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:21.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:22.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:22.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:23.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:23.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:24.915: INFO: Number of nodes with available pods: 0
Jun 18 12:52:24.915: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:25.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:25.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:26.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:26.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:27.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:27.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:28.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:28.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:29.915: INFO: Number of nodes with available pods: 0
Jun 18 12:52:29.915: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:30.915: INFO: Number of nodes with available pods: 0
Jun 18 12:52:30.915: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:31.943: INFO: Number of nodes with available pods: 0
Jun 18 12:52:31.943: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:32.916: INFO: Number of nodes with available pods: 0
Jun 18 12:52:32.916: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:33.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:33.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:34.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:34.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:35.916: INFO: Number of nodes with available pods: 0
Jun 18 12:52:35.916: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:36.913: INFO: Number of nodes with available pods: 0
Jun 18 12:52:36.913: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:37.916: INFO: Number of nodes with available pods: 0
Jun 18 12:52:37.916: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:38.985: INFO: Number of nodes with available pods: 0
Jun 18 12:52:38.985: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:39.915: INFO: Number of nodes with available pods: 0
Jun 18 12:52:39.915: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:40.918: INFO: Number of nodes with available pods: 0
Jun 18 12:52:40.918: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:41.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:41.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:42.939: INFO: Number of nodes with available pods: 0
Jun 18 12:52:42.939: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:43.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:43.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:44.915: INFO: Number of nodes with available pods: 0
Jun 18 12:52:44.915: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:45.913: INFO: Number of nodes with available pods: 0
Jun 18 12:52:45.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:46.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:46.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:47.918: INFO: Number of nodes with available pods: 0
Jun 18 12:52:47.918: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:48.920: INFO: Number of nodes with available pods: 0
Jun 18 12:52:48.920: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:49.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:49.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:50.915: INFO: Number of nodes with available pods: 0
Jun 18 12:52:50.915: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:51.984: INFO: Number of nodes with available pods: 0
Jun 18 12:52:51.984: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:52.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:52.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:53.931: INFO: Number of nodes with available pods: 0
Jun 18 12:52:53.931: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:54.915: INFO: Number of nodes with available pods: 0
Jun 18 12:52:54.915: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:55.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:55.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:56.914: INFO: Number of nodes with available pods: 0
Jun 18 12:52:56.914: INFO: Node 10.72.74.143 is running more than one daemon pod
Jun 18 12:52:57.914: INFO: Number of nodes with available pods: 1
Jun 18 12:52:57.914: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hcsms, will wait for the garbage collector to delete the pods
Jun 18 12:52:58.033: INFO: Deleting DaemonSet.extensions daemon-set took: 30.048381ms
Jun 18 12:52:58.133: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.300231ms
Jun 18 12:53:32.871: INFO: Number of nodes with available pods: 0
Jun 18 12:53:32.871: INFO: Number of running nodes: 0, number of available pods: 0
Jun 18 12:53:32.884: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hcsms/daemonsets","resourceVersion":"107338"},"items":null}

Jun 18 12:53:32.897: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hcsms/pods","resourceVersion":"107338"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:53:32.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hcsms" for this suite.
Jun 18 12:53:41.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:53:41.497: INFO: namespace: e2e-tests-daemonsets-hcsms, resource: bindings, ignored listing per whitelist
Jun 18 12:53:41.517: INFO: namespace e2e-tests-daemonsets-hcsms deletion completed in 8.518706838s

• [SLOW TEST:92.456 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:53:41.517: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jgr8h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:53:41.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-198e1312-91c8-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-jgr8h" to be "success or failure"
Jun 18 12:53:42.012: INFO: Pod "downwardapi-volume-198e1312-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.283073ms
Jun 18 12:53:44.048: INFO: Pod "downwardapi-volume-198e1312-91c8-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050539154s
STEP: Saw pod success
Jun 18 12:53:44.048: INFO: Pod "downwardapi-volume-198e1312-91c8-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:53:44.063: INFO: Trying to get logs from node 10.72.74.143 pod downwardapi-volume-198e1312-91c8-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:53:44.138: INFO: Waiting for pod downwardapi-volume-198e1312-91c8-11e9-bce2-ae54e022189f to disappear
Jun 18 12:53:44.154: INFO: Pod downwardapi-volume-198e1312-91c8-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:53:44.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jgr8h" for this suite.
Jun 18 12:53:50.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:53:50.625: INFO: namespace: e2e-tests-downward-api-jgr8h, resource: bindings, ignored listing per whitelist
Jun 18 12:53:50.741: INFO: namespace e2e-tests-downward-api-jgr8h deletion completed in 6.565716731s

• [SLOW TEST:9.224 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:53:50.741: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-g9244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-g9244
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-g9244
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-g9244
Jun 18 12:53:51.242: INFO: Found 0 stateful pods, waiting for 1
Jun 18 12:54:01.276: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jun 18 12:54:01.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-g9244 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 12:54:01.904: INFO: stderr: ""
Jun 18 12:54:01.904: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 12:54:01.904: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 12:54:01.919: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 18 12:54:11.954: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 18 12:54:11.954: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 12:54:12.018: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999784s
Jun 18 12:54:13.033: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.981923918s
Jun 18 12:54:14.049: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.966832038s
Jun 18 12:54:15.066: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.951240246s
Jun 18 12:54:16.082: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.933718424s
Jun 18 12:54:17.099: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.917517053s
Jun 18 12:54:18.115: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.901253561s
Jun 18 12:54:19.131: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.884882785s
Jun 18 12:54:20.147: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.868517024s
Jun 18 12:54:21.162: INFO: Verifying statefulset ss doesn't scale past 1 for another 853.20856ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-g9244
Jun 18 12:54:22.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-g9244 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 12:54:22.642: INFO: stderr: ""
Jun 18 12:54:22.642: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 12:54:22.642: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 12:54:22.657: INFO: Found 1 stateful pods, waiting for 3
Jun 18 12:54:32.690: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:54:32.690: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 18 12:54:32.690: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jun 18 12:54:32.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-g9244 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 12:54:33.192: INFO: stderr: ""
Jun 18 12:54:33.192: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 12:54:33.192: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 12:54:33.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-g9244 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 12:54:33.585: INFO: stderr: ""
Jun 18 12:54:33.585: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 12:54:33.585: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 12:54:33.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-g9244 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun 18 12:54:34.164: INFO: stderr: ""
Jun 18 12:54:34.164: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun 18 12:54:34.164: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun 18 12:54:34.164: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 12:54:34.178: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jun 18 12:54:44.284: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 18 12:54:44.284: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 18 12:54:44.284: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 18 12:54:44.336: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999997996s
Jun 18 12:54:45.351: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985299335s
Jun 18 12:54:46.384: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.970252935s
Jun 18 12:54:47.400: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.936546805s
Jun 18 12:54:48.415: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.921256515s
Jun 18 12:54:49.432: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.905479045s
Jun 18 12:54:50.485: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.888539774s
Jun 18 12:54:51.500: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.836201977s
Jun 18 12:54:52.520: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.820536858s
Jun 18 12:54:53.537: INFO: Verifying statefulset ss doesn't scale past 3 for another 801.032582ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-g9244
Jun 18 12:54:54.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-g9244 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 12:54:55.011: INFO: stderr: ""
Jun 18 12:54:55.011: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 12:54:55.011: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 12:54:55.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-g9244 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 12:54:55.467: INFO: stderr: ""
Jun 18 12:54:55.467: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 12:54:55.467: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 12:54:55.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 exec --namespace=e2e-tests-statefulset-g9244 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun 18 12:54:55.840: INFO: stderr: ""
Jun 18 12:54:55.840: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun 18 12:54:55.840: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun 18 12:54:55.840: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun 18 12:55:25.925: INFO: Deleting all statefulset in ns e2e-tests-statefulset-g9244
Jun 18 12:55:25.940: INFO: Scaling statefulset ss to 0
Jun 18 12:55:26.015: INFO: Waiting for statefulset status.replicas updated to 0
Jun 18 12:55:26.029: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:55:26.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-g9244" for this suite.
Jun 18 12:55:34.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:55:34.344: INFO: namespace: e2e-tests-statefulset-g9244, resource: bindings, ignored listing per whitelist
Jun 18 12:55:34.646: INFO: namespace e2e-tests-statefulset-g9244 deletion completed in 8.534911717s

• [SLOW TEST:103.904 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:55:34.646: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bkq2d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 18 12:55:35.124: INFO: Waiting up to 5m0s for pod "pod-5cfbe5c1-91c8-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-bkq2d" to be "success or failure"
Jun 18 12:55:35.139: INFO: Pod "pod-5cfbe5c1-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.932131ms
Jun 18 12:55:37.178: INFO: Pod "pod-5cfbe5c1-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053398612s
Jun 18 12:55:39.192: INFO: Pod "pod-5cfbe5c1-91c8-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067994446s
STEP: Saw pod success
Jun 18 12:55:39.192: INFO: Pod "pod-5cfbe5c1-91c8-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:55:39.207: INFO: Trying to get logs from node 10.72.74.144 pod pod-5cfbe5c1-91c8-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:55:39.281: INFO: Waiting for pod pod-5cfbe5c1-91c8-11e9-bce2-ae54e022189f to disappear
Jun 18 12:55:39.296: INFO: Pod pod-5cfbe5c1-91c8-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:55:39.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bkq2d" for this suite.
Jun 18 12:55:45.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:55:45.468: INFO: namespace: e2e-tests-emptydir-bkq2d, resource: bindings, ignored listing per whitelist
Jun 18 12:55:45.901: INFO: namespace e2e-tests-emptydir-bkq2d deletion completed in 6.585077841s

• [SLOW TEST:11.255 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:55:45.902: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mq6hg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 12:55:46.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 version --client'
Jun 18 12:55:46.477: INFO: stderr: ""
Jun 18 12:55:46.477: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jun 18 12:55:46.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-mq6hg'
Jun 18 12:55:47.032: INFO: stderr: ""
Jun 18 12:55:47.032: INFO: stdout: "replicationcontroller/redis-master created\n"
Jun 18 12:55:47.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-mq6hg'
Jun 18 12:55:47.431: INFO: stderr: ""
Jun 18 12:55:47.431: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 18 12:55:48.445: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 12:55:48.445: INFO: Found 0 / 1
Jun 18 12:55:49.447: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 12:55:49.447: INFO: Found 1 / 1
Jun 18 12:55:49.447: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 18 12:55:49.462: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 12:55:49.462: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 18 12:55:49.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 describe pod redis-master-wsfsn --namespace=e2e-tests-kubectl-mq6hg'
Jun 18 12:55:49.629: INFO: stderr: ""
Jun 18 12:55:49.629: INFO: stdout: "Name:               redis-master-wsfsn\nNamespace:          e2e-tests-kubectl-mq6hg\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.72.74.149/10.72.74.149\nStart Time:         Tue, 18 Jun 2019 12:55:47 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.39.35\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://00b8b539895762d3ca4d60eaed4ee5741b5b7d92cb5df37d7c9aa1abe3b25b44\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 18 Jun 2019 12:55:48 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-b8gws (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-b8gws:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-b8gws\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  2s    default-scheduler      Successfully assigned e2e-tests-kubectl-mq6hg/redis-master-wsfsn to 10.72.74.149\n  Normal  Pulled     1s    kubelet, 10.72.74.149  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 10.72.74.149  Created container\n  Normal  Started    1s    kubelet, 10.72.74.149  Started container\n"
Jun 18 12:55:49.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 describe rc redis-master --namespace=e2e-tests-kubectl-mq6hg'
Jun 18 12:55:50.559: INFO: stderr: ""
Jun 18 12:55:50.559: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-mq6hg\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-wsfsn\n"
Jun 18 12:55:50.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 describe service redis-master --namespace=e2e-tests-kubectl-mq6hg'
Jun 18 12:55:50.737: INFO: stderr: ""
Jun 18 12:55:50.737: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-mq6hg\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.40.125\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.39.35:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jun 18 12:55:50.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 describe node 10.72.74.143'
Jun 18 12:55:50.949: INFO: stderr: ""
Jun 18 12:55:50.949: INFO: stdout: "Name:               10.72.74.143\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-gb\n                    failure-domain.beta.kubernetes.io/zone=lon06\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=49a3e8d7011b436d9b4596ba0f279008-7e5ee57\n                    ibm-cloud.kubernetes.io/worker-version=1.13.7_1526\n                    kubernetes.io/hostname=10.72.74.143\n                    privateVLAN=2643595\n                    publicVLAN=2643593\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 17 Jun 2019 21:36:37 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 18 Jun 2019 12:55:47 +0000   Mon, 17 Jun 2019 21:36:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 18 Jun 2019 12:55:47 +0000   Mon, 17 Jun 2019 21:36:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 18 Jun 2019 12:55:47 +0000   Mon, 17 Jun 2019 21:36:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 18 Jun 2019 12:55:47 +0000   Mon, 17 Jun 2019 21:36:47 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.72.74.143\n  ExternalIP:  158.176.111.60\n  Hostname:    10.72.74.143\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419916Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627468Ki\n pods:               110\nSystem Info:\n Machine ID:                 c061a5f0b4cb45e69da8d3f656c657bf\n System UUID:                C5FEE2E3-75D6-CCA2-2125-F4191D25A4A8\n Boot ID:                    5da3ff2c-7d82-4839-b06f-1b7fc37e00de\n Kernel Version:             4.15.0-51-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.6\n Kubelet Version:            v1.13.7+IKS\n Kube-Proxy Version:         v1.13.7+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///49a3e8d7011b436d9b4596ba0f279008/kube-lon06-cr49a3e8d7011b436d9b4596ba0f279008-w2\nNon-terminated Pods:         (15 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    test-k8s-e2e-pvg-master-verification                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  heptio-sonobuoy            sonobuoy-e2e-job-4f826760f7504668                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-zt85r    0 (0%)        0 (0%)      0 (0%)           0 (0%)         81m\n  kube-system                calico-kube-controllers-54d47c87f-kwkh9                    10m (0%)      0 (0%)      25Mi (0%)        0 (0%)         15h\n  kube-system                calico-node-fw2l9                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         15h\n  kube-system                coredns-5545c6ddc4-dxkvs                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     15h\n  kube-system                coredns-autoscaler-5c7646547d-dshx6                        20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         15h\n  kube-system                ibm-file-plugin-bf4cc7987-jwdjh                            50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         15h\n  kube-system                ibm-keepalived-watcher-5z7h2                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         15h\n  kube-system                ibm-kube-fluentd-7spm2                                     25m (0%)      300m (7%)   150Mi (1%)       1600M (11%)    15h\n  kube-system                ibm-master-proxy-static-10.72.74.143                       25m (0%)      300m (7%)   32M (0%)         512M (3%)      15h\n  kube-system                ibm-storage-watcher-64989c44d-tp68k                        50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         15h\n  kube-system                kubernetes-dashboard-6cf8b975c-prz8l                       50m (1%)      0 (0%)      100Mi (0%)       0 (0%)         15h\n  kube-system                vpn-7f677b8cb5-29tf9                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         15h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                590m (15%)     1 (25%)\n  memory             696850Ki (5%)  2472100Ki (18%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Jun 18 12:55:50.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 describe namespace e2e-tests-kubectl-mq6hg'
Jun 18 12:55:51.112: INFO: stderr: ""
Jun 18 12:55:51.112: INFO: stdout: "Name:         e2e-tests-kubectl-mq6hg\nLabels:       e2e-framework=kubectl\n              e2e-run=097fb1c0-91bd-11e9-bce2-ae54e022189f\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:55:51.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mq6hg" for this suite.
Jun 18 12:56:15.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:56:16.107: INFO: namespace: e2e-tests-kubectl-mq6hg, resource: bindings, ignored listing per whitelist
Jun 18 12:56:17.409: INFO: namespace e2e-tests-kubectl-mq6hg deletion completed in 26.278558433s

• [SLOW TEST:31.507 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:56:17.410: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bjjw8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-7678e739-91c8-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 12:56:17.903: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-767b272d-91c8-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-bjjw8" to be "success or failure"
Jun 18 12:56:17.918: INFO: Pod "pod-projected-configmaps-767b272d-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.430282ms
Jun 18 12:56:19.932: INFO: Pod "pod-projected-configmaps-767b272d-91c8-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.029126472s
Jun 18 12:56:21.970: INFO: Pod "pod-projected-configmaps-767b272d-91c8-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066872994s
STEP: Saw pod success
Jun 18 12:56:21.970: INFO: Pod "pod-projected-configmaps-767b272d-91c8-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:56:21.987: INFO: Trying to get logs from node 10.72.74.143 pod pod-projected-configmaps-767b272d-91c8-11e9-bce2-ae54e022189f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 12:56:22.085: INFO: Waiting for pod pod-projected-configmaps-767b272d-91c8-11e9-bce2-ae54e022189f to disappear
Jun 18 12:56:22.101: INFO: Pod pod-projected-configmaps-767b272d-91c8-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:56:22.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bjjw8" for this suite.
Jun 18 12:56:30.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:56:30.561: INFO: namespace: e2e-tests-projected-bjjw8, resource: bindings, ignored listing per whitelist
Jun 18 12:56:30.696: INFO: namespace e2e-tests-projected-bjjw8 deletion completed in 8.576851145s

• [SLOW TEST:13.287 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:56:30.696: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-9shpd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jun 18 12:56:31.980: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-9shpd,SelfLink:/api/v1/namespaces/e2e-tests-watch-9shpd/configmaps/e2e-watch-test-resource-version,UID:7ed18a8b-91c8-11e9-bf44-fa6f350b29f0,ResourceVersion:108045,Generation:0,CreationTimestamp:2019-06-18 12:56:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 18 12:56:31.980: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-9shpd,SelfLink:/api/v1/namespaces/e2e-tests-watch-9shpd/configmaps/e2e-watch-test-resource-version,UID:7ed18a8b-91c8-11e9-bf44-fa6f350b29f0,ResourceVersion:108046,Generation:0,CreationTimestamp:2019-06-18 12:56:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:56:31.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9shpd" for this suite.
Jun 18 12:56:38.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:56:38.521: INFO: namespace: e2e-tests-watch-9shpd, resource: bindings, ignored listing per whitelist
Jun 18 12:56:38.609: INFO: namespace e2e-tests-watch-9shpd deletion completed in 6.610391087s

• [SLOW TEST:7.913 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:56:38.610: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bqzcl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 18 12:56:39.070: INFO: Waiting up to 5m0s for pod "pod-83192200-91c8-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-bqzcl" to be "success or failure"
Jun 18 12:56:39.086: INFO: Pod "pod-83192200-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.768357ms
Jun 18 12:56:41.102: INFO: Pod "pod-83192200-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031752491s
Jun 18 12:56:43.136: INFO: Pod "pod-83192200-91c8-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066057037s
STEP: Saw pod success
Jun 18 12:56:43.136: INFO: Pod "pod-83192200-91c8-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:56:43.151: INFO: Trying to get logs from node 10.72.74.144 pod pod-83192200-91c8-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:56:43.234: INFO: Waiting for pod pod-83192200-91c8-11e9-bce2-ae54e022189f to disappear
Jun 18 12:56:43.248: INFO: Pod pod-83192200-91c8-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:56:43.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bqzcl" for this suite.
Jun 18 12:56:49.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:56:49.821: INFO: namespace: e2e-tests-emptydir-bqzcl, resource: bindings, ignored listing per whitelist
Jun 18 12:56:49.847: INFO: namespace e2e-tests-emptydir-bqzcl deletion completed in 6.577390308s

• [SLOW TEST:11.238 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:56:49.849: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lzpbx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:56:50.346: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89d14c3d-91c8-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-lzpbx" to be "success or failure"
Jun 18 12:56:50.359: INFO: Pod "downwardapi-volume-89d14c3d-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.142983ms
Jun 18 12:56:53.132: INFO: Pod "downwardapi-volume-89d14c3d-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.785909937s
Jun 18 12:56:55.171: INFO: Pod "downwardapi-volume-89d14c3d-91c8-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.824849366s
STEP: Saw pod success
Jun 18 12:56:55.171: INFO: Pod "downwardapi-volume-89d14c3d-91c8-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:56:55.186: INFO: Trying to get logs from node 10.72.74.144 pod downwardapi-volume-89d14c3d-91c8-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:56:55.263: INFO: Waiting for pod downwardapi-volume-89d14c3d-91c8-11e9-bce2-ae54e022189f to disappear
Jun 18 12:56:55.277: INFO: Pod downwardapi-volume-89d14c3d-91c8-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:56:55.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lzpbx" for this suite.
Jun 18 12:57:01.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:57:01.577: INFO: namespace: e2e-tests-projected-lzpbx, resource: bindings, ignored listing per whitelist
Jun 18 12:57:01.854: INFO: namespace e2e-tests-projected-lzpbx deletion completed in 6.554293096s

• [SLOW TEST:12.006 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:57:01.855: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-bx2jn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 12:57:02.377: INFO: (0) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 33.177175ms)
Jun 18 12:57:02.402: INFO: (1) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.508304ms)
Jun 18 12:57:02.429: INFO: (2) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 27.040243ms)
Jun 18 12:57:02.452: INFO: (3) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.949911ms)
Jun 18 12:57:02.478: INFO: (4) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 26.223666ms)
Jun 18 12:57:02.504: INFO: (5) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.706047ms)
Jun 18 12:57:02.528: INFO: (6) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.679913ms)
Jun 18 12:57:02.565: INFO: (7) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 37.650527ms)
Jun 18 12:57:02.591: INFO: (8) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.469427ms)
Jun 18 12:57:02.614: INFO: (9) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.591009ms)
Jun 18 12:57:02.639: INFO: (10) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.651596ms)
Jun 18 12:57:02.663: INFO: (11) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.074917ms)
Jun 18 12:57:02.687: INFO: (12) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.039587ms)
Jun 18 12:57:02.710: INFO: (13) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.268668ms)
Jun 18 12:57:02.735: INFO: (14) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.207539ms)
Jun 18 12:57:02.762: INFO: (15) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 27.000127ms)
Jun 18 12:57:02.791: INFO: (16) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 29.025175ms)
Jun 18 12:57:02.818: INFO: (17) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 26.642446ms)
Jun 18 12:57:02.842: INFO: (18) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.586352ms)
Jun 18 12:57:02.869: INFO: (19) /api/v1/nodes/10.72.74.143:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 27.202881ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:57:02.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-bx2jn" for this suite.
Jun 18 12:57:09.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:57:09.147: INFO: namespace: e2e-tests-proxy-bx2jn, resource: bindings, ignored listing per whitelist
Jun 18 12:57:09.530: INFO: namespace e2e-tests-proxy-bx2jn deletion completed in 6.545331401s

• [SLOW TEST:7.676 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:57:09.530: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5kkxc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 18 12:57:10.063: INFO: Waiting up to 5m0s for pod "pod-95920aa7-91c8-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-5kkxc" to be "success or failure"
Jun 18 12:57:10.078: INFO: Pod "pod-95920aa7-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.586793ms
Jun 18 12:57:12.093: INFO: Pod "pod-95920aa7-91c8-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.03023011s
Jun 18 12:57:14.108: INFO: Pod "pod-95920aa7-91c8-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045221686s
STEP: Saw pod success
Jun 18 12:57:14.108: INFO: Pod "pod-95920aa7-91c8-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:57:14.122: INFO: Trying to get logs from node 10.72.74.143 pod pod-95920aa7-91c8-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 12:57:14.196: INFO: Waiting for pod pod-95920aa7-91c8-11e9-bce2-ae54e022189f to disappear
Jun 18 12:57:14.212: INFO: Pod pod-95920aa7-91c8-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:57:14.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5kkxc" for this suite.
Jun 18 12:57:20.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:57:20.836: INFO: namespace: e2e-tests-emptydir-5kkxc, resource: bindings, ignored listing per whitelist
Jun 18 12:57:20.851: INFO: namespace e2e-tests-emptydir-5kkxc deletion completed in 6.617532075s

• [SLOW TEST:11.320 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:57:20.852: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xbh2k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:57:21.340: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c4a6454-91c8-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-xbh2k" to be "success or failure"
Jun 18 12:57:21.354: INFO: Pod "downwardapi-volume-9c4a6454-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.306969ms
Jun 18 12:57:23.372: INFO: Pod "downwardapi-volume-9c4a6454-91c8-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032063502s
STEP: Saw pod success
Jun 18 12:57:23.372: INFO: Pod "downwardapi-volume-9c4a6454-91c8-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:57:23.386: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-9c4a6454-91c8-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:57:23.462: INFO: Waiting for pod downwardapi-volume-9c4a6454-91c8-11e9-bce2-ae54e022189f to disappear
Jun 18 12:57:23.476: INFO: Pod downwardapi-volume-9c4a6454-91c8-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:57:23.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xbh2k" for this suite.
Jun 18 12:57:29.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:57:29.982: INFO: namespace: e2e-tests-projected-xbh2k, resource: bindings, ignored listing per whitelist
Jun 18 12:57:30.085: INFO: namespace e2e-tests-projected-xbh2k deletion completed in 6.58691693s

• [SLOW TEST:9.233 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:57:30.086: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-wwz6v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun 18 12:57:30.519: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 18 12:57:30.553: INFO: Waiting for terminating namespaces to be deleted...
Jun 18 12:57:30.566: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.143 before test
Jun 18 12:57:30.630: INFO: calico-node-fw2l9 from kube-system started at 2019-06-17 21:36:37 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.630: INFO: 	Container calico-node ready: true, restart count 0
Jun 18 12:57:30.630: INFO: coredns-autoscaler-5c7646547d-dshx6 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.630: INFO: 	Container autoscaler ready: true, restart count 0
Jun 18 12:57:30.630: INFO: ibm-master-proxy-static-10.72.74.143 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 12:57:30.630: INFO: ibm-keepalived-watcher-5z7h2 from kube-system started at 2019-06-17 21:36:37 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.630: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 12:57:30.630: INFO: kubernetes-dashboard-6cf8b975c-prz8l from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 18 12:57:30.631: INFO: coredns-5545c6ddc4-dxkvs from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container coredns ready: true, restart count 0
Jun 18 12:57:30.631: INFO: calico-kube-controllers-54d47c87f-kwkh9 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jun 18 12:57:30.631: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-zt85r from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 18 12:57:30.631: INFO: 	Container systemd-logs ready: true, restart count 1
Jun 18 12:57:30.631: INFO: vpn-7f677b8cb5-29tf9 from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container vpn ready: true, restart count 0
Jun 18 12:57:30.631: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-06-18 11:33:43 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jun 18 12:57:30.631: INFO: ibm-kube-fluentd-7spm2 from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container fluentd ready: true, restart count 0
Jun 18 12:57:30.631: INFO: ibm-file-plugin-bf4cc7987-jwdjh from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jun 18 12:57:30.631: INFO: ibm-storage-watcher-64989c44d-tp68k from kube-system started at 2019-06-17 21:36:47 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jun 18 12:57:30.631: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-18 11:33:50 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 18 12:57:30.631: INFO: sonobuoy-e2e-job-4f826760f7504668 from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 12:57:30.631: INFO: 	Container e2e ready: true, restart count 0
Jun 18 12:57:30.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 18 12:57:30.631: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.144 before test
Jun 18 12:57:30.697: INFO: coredns-5545c6ddc4-4s87g from kube-system started at 2019-06-17 21:37:04 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.697: INFO: 	Container coredns ready: true, restart count 0
Jun 18 12:57:30.697: INFO: ibm-kube-fluentd-g5hgb from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.697: INFO: 	Container fluentd ready: true, restart count 0
Jun 18 12:57:30.697: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-ct76c from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 12:57:30.697: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 18 12:57:30.697: INFO: 	Container systemd-logs ready: true, restart count 1
Jun 18 12:57:30.697: INFO: ibm-cloud-provider-ip-158-176-120-130-699ff5cfd-z4hhb from ibm-system started at 2019-06-17 21:40:39 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.697: INFO: 	Container ibm-cloud-provider-ip-158-176-120-130 ready: true, restart count 0
Jun 18 12:57:30.697: INFO: public-cr49a3e8d7011b436d9b4596ba0f279008-alb1-778b7ff477-tpktg from kube-system started at 2019-06-17 21:41:04 +0000 UTC (4 container statuses recorded)
Jun 18 12:57:30.697: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jun 18 12:57:30.697: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jun 18 12:57:30.697: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jun 18 12:57:30.697: INFO: 	Container nginx-ingress ready: true, restart count 0
Jun 18 12:57:30.697: INFO: ibm-master-proxy-static-10.72.74.144 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 12:57:30.697: INFO: calico-node-rptvs from kube-system started at 2019-06-17 21:36:43 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.697: INFO: 	Container calico-node ready: true, restart count 0
Jun 18 12:57:30.697: INFO: ibm-keepalived-watcher-drbmt from kube-system started at 2019-06-17 21:36:43 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.697: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 12:57:30.697: INFO: 
Logging pods the kubelet thinks is on node 10.72.74.149 before test
Jun 18 12:57:30.748: INFO: sonobuoy-systemd-logs-daemon-set-562f76bc52c447d0-btfpp from heptio-sonobuoy started at 2019-06-18 11:33:59 +0000 UTC (2 container statuses recorded)
Jun 18 12:57:30.748: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 18 12:57:30.748: INFO: 	Container systemd-logs ready: true, restart count 1
Jun 18 12:57:30.748: INFO: ibm-cloud-provider-ip-158-176-120-130-699ff5cfd-td8hg from ibm-system started at 2019-06-17 21:40:39 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.748: INFO: 	Container ibm-cloud-provider-ip-158-176-120-130 ready: true, restart count 0
Jun 18 12:57:30.748: INFO: public-cr49a3e8d7011b436d9b4596ba0f279008-alb1-778b7ff477-sxttq from kube-system started at 2019-06-17 21:41:04 +0000 UTC (4 container statuses recorded)
Jun 18 12:57:30.748: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jun 18 12:57:30.748: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jun 18 12:57:30.748: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jun 18 12:57:30.748: INFO: 	Container nginx-ingress ready: true, restart count 0
Jun 18 12:57:30.748: INFO: ibm-master-proxy-static-10.72.74.149 from kube-system started at <nil> (0 container statuses recorded)
Jun 18 12:57:30.748: INFO: calico-node-4pqtj from kube-system started at 2019-06-17 21:36:50 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.748: INFO: 	Container calico-node ready: true, restart count 0
Jun 18 12:57:30.748: INFO: metrics-server-6ccf788d5b-6gwxm from kube-system started at 2019-06-17 21:37:11 +0000 UTC (2 container statuses recorded)
Jun 18 12:57:30.748: INFO: 	Container metrics-server ready: true, restart count 0
Jun 18 12:57:30.748: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jun 18 12:57:30.748: INFO: ibm-keepalived-watcher-6846v from kube-system started at 2019-06-17 21:36:50 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.748: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jun 18 12:57:30.748: INFO: ibm-kube-fluentd-c6kth from kube-system started at 2019-06-17 21:43:21 +0000 UTC (1 container statuses recorded)
Jun 18 12:57:30.748: INFO: 	Container fluentd ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a94c4fa5f64d11], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:57:31.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wwz6v" for this suite.
Jun 18 12:57:37.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:57:38.034: INFO: namespace: e2e-tests-sched-pred-wwz6v, resource: bindings, ignored listing per whitelist
Jun 18 12:57:38.471: INFO: namespace e2e-tests-sched-pred-wwz6v deletion completed in 6.608375963s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:8.385 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:57:38.473: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f6dmh
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a6cf857d-91c8-11e9-bce2-ae54e022189f
STEP: Creating secret with name s-test-opt-upd-a6cf85e4-91c8-11e9-bce2-ae54e022189f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a6cf857d-91c8-11e9-bce2-ae54e022189f
STEP: Updating secret s-test-opt-upd-a6cf85e4-91c8-11e9-bce2-ae54e022189f
STEP: Creating secret with name s-test-opt-create-a6cf860c-91c8-11e9-bce2-ae54e022189f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:58:46.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f6dmh" for this suite.
Jun 18 12:59:10.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:59:11.394: INFO: namespace: e2e-tests-projected-f6dmh, resource: bindings, ignored listing per whitelist
Jun 18 12:59:11.407: INFO: namespace e2e-tests-projected-f6dmh deletion completed in 24.556094283s

• [SLOW TEST:92.935 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:59:11.409: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-swjlb
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-de3294c8-91c8-11e9-bce2-ae54e022189f
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-de3294c8-91c8-11e9-bce2-ae54e022189f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:59:16.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-swjlb" for this suite.
Jun 18 12:59:40.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:59:42.453: INFO: namespace: e2e-tests-projected-swjlb, resource: bindings, ignored listing per whitelist
Jun 18 12:59:42.567: INFO: namespace e2e-tests-projected-swjlb deletion completed in 26.448164028s

• [SLOW TEST:31.158 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:59:42.568: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-gq7kx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 12:59:43.052: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f0c24ed9-91c8-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-gq7kx" to be "success or failure"
Jun 18 12:59:43.069: INFO: Pod "downwardapi-volume-f0c24ed9-91c8-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.200487ms
Jun 18 12:59:45.085: INFO: Pod "downwardapi-volume-f0c24ed9-91c8-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.033140579s
Jun 18 12:59:47.100: INFO: Pod "downwardapi-volume-f0c24ed9-91c8-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048400701s
STEP: Saw pod success
Jun 18 12:59:47.101: INFO: Pod "downwardapi-volume-f0c24ed9-91c8-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 12:59:47.115: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-f0c24ed9-91c8-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 12:59:47.226: INFO: Waiting for pod downwardapi-volume-f0c24ed9-91c8-11e9-bce2-ae54e022189f to disappear
Jun 18 12:59:47.241: INFO: Pod downwardapi-volume-f0c24ed9-91c8-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 12:59:47.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gq7kx" for this suite.
Jun 18 12:59:55.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 12:59:55.475: INFO: namespace: e2e-tests-downward-api-gq7kx, resource: bindings, ignored listing per whitelist
Jun 18 12:59:55.907: INFO: namespace e2e-tests-downward-api-gq7kx deletion completed in 8.645403275s

• [SLOW TEST:13.339 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 12:59:55.907: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-djsdz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:00:19.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-djsdz" for this suite.
Jun 18 13:00:27.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:00:28.449: INFO: namespace: e2e-tests-container-runtime-djsdz, resource: bindings, ignored listing per whitelist
Jun 18 13:00:28.495: INFO: namespace e2e-tests-container-runtime-djsdz deletion completed in 8.92023168s

• [SLOW TEST:32.589 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:00:28.496: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-9h78m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jun 18 13:00:29.094: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-9h78m" to be "success or failure"
Jun 18 13:00:29.110: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 16.35673ms
Jun 18 13:00:31.124: INFO: Pod "pod-host-path-test": Phase="Running", Reason="", readiness=false. Elapsed: 2.030461035s
Jun 18 13:00:33.139: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045781301s
STEP: Saw pod success
Jun 18 13:00:33.140: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jun 18 13:00:33.154: INFO: Trying to get logs from node 10.72.74.149 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jun 18 13:00:33.228: INFO: Waiting for pod pod-host-path-test to disappear
Jun 18 13:00:33.241: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:00:33.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-9h78m" for this suite.
Jun 18 13:00:39.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:00:39.582: INFO: namespace: e2e-tests-hostpath-9h78m, resource: bindings, ignored listing per whitelist
Jun 18 13:00:39.986: INFO: namespace e2e-tests-hostpath-9h78m deletion completed in 6.72087531s

• [SLOW TEST:11.490 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:00:39.987: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-4wcjm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:00:42.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-4wcjm" for this suite.
Jun 18 13:01:25.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:01:25.529: INFO: namespace: e2e-tests-kubelet-test-4wcjm, resource: bindings, ignored listing per whitelist
Jun 18 13:01:25.555: INFO: namespace e2e-tests-kubelet-test-4wcjm deletion completed in 42.668901033s

• [SLOW TEST:45.568 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:01:25.555: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-27dld
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-ljkcq
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Jun 18 13:01:35.058: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-cr5fv
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:01:52.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-27dld" for this suite.
Jun 18 13:02:00.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:02:01.314: INFO: namespace: e2e-tests-namespaces-27dld, resource: bindings, ignored listing per whitelist
Jun 18 13:02:01.458: INFO: namespace e2e-tests-namespaces-27dld deletion completed in 8.720019452s
STEP: Destroying namespace "e2e-tests-nsdeletetest-ljkcq" for this suite.
Jun 18 13:02:01.471: INFO: Namespace e2e-tests-nsdeletetest-ljkcq was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-cr5fv" for this suite.
Jun 18 13:02:07.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:02:07.607: INFO: namespace: e2e-tests-nsdeletetest-cr5fv, resource: bindings, ignored listing per whitelist
Jun 18 13:02:08.142: INFO: namespace e2e-tests-nsdeletetest-cr5fv deletion completed in 6.670408983s

• [SLOW TEST:42.587 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:02:08.142: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-qrb9x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:02:08.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qrb9x" for this suite.
Jun 18 13:02:14.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:02:15.238: INFO: namespace: e2e-tests-kubelet-test-qrb9x, resource: bindings, ignored listing per whitelist
Jun 18 13:02:15.267: INFO: namespace e2e-tests-kubelet-test-qrb9x deletion completed in 6.573741496s

• [SLOW TEST:7.124 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:02:15.267: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-f9kg8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jun 18 13:02:15.790: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jun 18 13:02:15.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:16.123: INFO: stderr: ""
Jun 18 13:02:16.123: INFO: stdout: "service/redis-slave created\n"
Jun 18 13:02:16.123: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jun 18 13:02:16.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:16.488: INFO: stderr: ""
Jun 18 13:02:16.488: INFO: stdout: "service/redis-master created\n"
Jun 18 13:02:16.489: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jun 18 13:02:16.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:16.742: INFO: stderr: ""
Jun 18 13:02:16.742: INFO: stdout: "service/frontend created\n"
Jun 18 13:02:16.742: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jun 18 13:02:16.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:16.962: INFO: stderr: ""
Jun 18 13:02:16.962: INFO: stdout: "deployment.extensions/frontend created\n"
Jun 18 13:02:16.963: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jun 18 13:02:16.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:17.245: INFO: stderr: ""
Jun 18 13:02:17.245: INFO: stdout: "deployment.extensions/redis-master created\n"
Jun 18 13:02:17.246: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jun 18 13:02:17.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:17.635: INFO: stderr: ""
Jun 18 13:02:17.635: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jun 18 13:02:17.635: INFO: Waiting for all frontend pods to be Running.
Jun 18 13:02:37.686: INFO: Waiting for frontend to serve content.
Jun 18 13:02:42.755: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jun 18 13:02:47.821: INFO: Trying to add a new entry to the guestbook.
Jun 18 13:02:47.867: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jun 18 13:02:47.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:48.213: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 13:02:48.213: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jun 18 13:02:48.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:48.464: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 13:02:48.464: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 18 13:02:48.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:48.638: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 13:02:48.638: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 18 13:02:48.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:48.785: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 13:02:48.785: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 18 13:02:48.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:48.964: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 13:02:48.964: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 18 13:02:48.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f9kg8'
Jun 18 13:02:49.115: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 18 13:02:49.115: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:02:49.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f9kg8" for this suite.
Jun 18 13:03:31.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:03:31.648: INFO: namespace: e2e-tests-kubectl-f9kg8, resource: bindings, ignored listing per whitelist
Jun 18 13:03:31.673: INFO: namespace e2e-tests-kubectl-f9kg8 deletion completed in 42.53981067s

• [SLOW TEST:76.406 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:03:31.674: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-z4c8g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0618 13:03:42.416296      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 18 13:03:42.416: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:03:42.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-z4c8g" for this suite.
Jun 18 13:03:50.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:03:50.841: INFO: namespace: e2e-tests-gc-z4c8g, resource: bindings, ignored listing per whitelist
Jun 18 13:03:50.943: INFO: namespace e2e-tests-gc-z4c8g deletion completed in 8.51323857s

• [SLOW TEST:19.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:03:50.944: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cffwb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 18 13:03:51.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-cffwb'
Jun 18 13:03:52.283: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 18 13:03:52.283: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Jun 18 13:03:52.392: INFO: scanned /root for discovery docs: <nil>
Jun 18 13:03:52.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-cffwb'
Jun 18 13:04:08.438: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun 18 13:04:08.438: INFO: stdout: "Created e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6\nScaling up e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jun 18 13:04:08.438: INFO: stdout: "Created e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6\nScaling up e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jun 18 13:04:08.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-cffwb'
Jun 18 13:04:08.577: INFO: stderr: ""
Jun 18 13:04:08.577: INFO: stdout: "e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6-t5plg "
Jun 18 13:04:08.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6-t5plg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cffwb'
Jun 18 13:04:08.753: INFO: stderr: ""
Jun 18 13:04:08.753: INFO: stdout: "true"
Jun 18 13:04:08.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 get pods e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6-t5plg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cffwb'
Jun 18 13:04:08.902: INFO: stderr: ""
Jun 18 13:04:08.902: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jun 18 13:04:08.902: INFO: e2e-test-nginx-rc-5c3b0d70e485ce34b8d17399023285b6-t5plg is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jun 18 13:04:08.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-cffwb'
Jun 18 13:04:09.161: INFO: stderr: ""
Jun 18 13:04:09.161: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:04:09.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cffwb" for this suite.
Jun 18 13:04:33.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:04:33.739: INFO: namespace: e2e-tests-kubectl-cffwb, resource: bindings, ignored listing per whitelist
Jun 18 13:04:33.765: INFO: namespace e2e-tests-kubectl-cffwb deletion completed in 24.581208099s

• [SLOW TEST:42.822 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:04:33.765: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-68kjh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 13:04:34.220: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jun 18 13:04:34.249: INFO: Pod name sample-pod: Found 0 pods out of 1
Jun 18 13:04:39.265: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 18 13:04:39.265: INFO: Creating deployment "test-rolling-update-deployment"
Jun 18 13:04:39.280: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jun 18 13:04:39.306: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jun 18 13:04:41.336: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jun 18 13:04:41.349: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 18 13:04:41.393: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-68kjh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-68kjh/deployments/test-rolling-update-deployment,UID:a156030f-91c9-11e9-bf44-fa6f350b29f0,ResourceVersion:110169,Generation:1,CreationTimestamp:2019-06-18 13:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-18 13:04:39 +0000 UTC 2019-06-18 13:04:39 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-18 13:04:40 +0000 UTC 2019-06-18 13:04:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun 18 13:04:41.407: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-68kjh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-68kjh/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:a15d2d5d-91c9-11e9-bf44-fa6f350b29f0,ResourceVersion:110159,Generation:1,CreationTimestamp:2019-06-18 13:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a156030f-91c9-11e9-bf44-fa6f350b29f0 0xc001734c37 0xc001734c38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun 18 13:04:41.407: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jun 18 13:04:41.407: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-68kjh,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-68kjh/replicasets/test-rolling-update-controller,UID:9e544ba8-91c9-11e9-bf44-fa6f350b29f0,ResourceVersion:110168,Generation:2,CreationTimestamp:2019-06-18 13:04:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a156030f-91c9-11e9-bf44-fa6f350b29f0 0xc001734b77 0xc001734b78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 18 13:04:41.422: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-z4jxp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-z4jxp,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-68kjh,SelfLink:/api/v1/namespaces/e2e-tests-deployment-68kjh/pods/test-rolling-update-deployment-68b55d7bc6-z4jxp,UID:a15f0a1e-91c9-11e9-bf44-fa6f350b29f0,ResourceVersion:110158,Generation:0,CreationTimestamp:2019-06-18 13:04:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 a15d2d5d-91c9-11e9-bf44-fa6f350b29f0 0xc001735c47 0xc001735c48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5mnfv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5mnfv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5mnfv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001735db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001735dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 13:04:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 13:04:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 13:04:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 13:04:39 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.144,PodIP:172.30.114.36,StartTime:2019-06-18 13:04:39 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-18 13:04:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://c227d3ae976f62825517120a33ec351cee4b39631c1fa2504294f9aeb188920d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:04:41.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-68kjh" for this suite.
Jun 18 13:04:49.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:04:49.927: INFO: namespace: e2e-tests-deployment-68kjh, resource: bindings, ignored listing per whitelist
Jun 18 13:04:49.979: INFO: namespace e2e-tests-deployment-68kjh deletion completed in 8.538474209s

• [SLOW TEST:16.214 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:04:49.979: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-pqfxq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-pqfxq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqfxq to expose endpoints map[]
Jun 18 13:04:50.525: INFO: Get endpoints failed (12.078189ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jun 18 13:04:51.539: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqfxq exposes endpoints map[] (1.025369365s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-pqfxq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqfxq to expose endpoints map[pod1:[100]]
Jun 18 13:04:53.663: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqfxq exposes endpoints map[pod1:[100]] (2.098026929s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-pqfxq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqfxq to expose endpoints map[pod1:[100] pod2:[101]]
Jun 18 13:04:56.927: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqfxq exposes endpoints map[pod1:[100] pod2:[101]] (3.247748534s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-pqfxq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqfxq to expose endpoints map[pod2:[101]]
Jun 18 13:04:56.976: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqfxq exposes endpoints map[pod2:[101]] (27.081541ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-pqfxq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-pqfxq to expose endpoints map[]
Jun 18 13:04:57.012: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-pqfxq exposes endpoints map[] (11.872768ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:04:57.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-pqfxq" for this suite.
Jun 18 13:05:21.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:05:21.253: INFO: namespace: e2e-tests-services-pqfxq, resource: bindings, ignored listing per whitelist
Jun 18 13:05:21.642: INFO: namespace e2e-tests-services-pqfxq deletion completed in 24.543851995s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:31.662 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:05:21.642: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-bgkpg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-bgkpg
Jun 18 13:05:24.172: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-bgkpg
STEP: checking the pod's current state and verifying that restartCount is present
Jun 18 13:05:24.188: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:09:25.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bgkpg" for this suite.
Jun 18 13:09:31.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:09:32.066: INFO: namespace: e2e-tests-container-probe-bgkpg, resource: bindings, ignored listing per whitelist
Jun 18 13:09:32.448: INFO: namespace e2e-tests-container-probe-bgkpg deletion completed in 6.645606921s

• [SLOW TEST:250.807 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:09:32.449: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-tq6sf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 13:09:32.967: INFO: (0) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 27.500355ms)
Jun 18 13:09:32.990: INFO: (1) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.256562ms)
Jun 18 13:09:33.013: INFO: (2) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.185403ms)
Jun 18 13:09:33.037: INFO: (3) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.592954ms)
Jun 18 13:09:33.061: INFO: (4) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.974457ms)
Jun 18 13:09:33.086: INFO: (5) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.9444ms)
Jun 18 13:09:33.112: INFO: (6) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 26.041693ms)
Jun 18 13:09:33.135: INFO: (7) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.018023ms)
Jun 18 13:09:33.160: INFO: (8) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.110916ms)
Jun 18 13:09:33.184: INFO: (9) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.586285ms)
Jun 18 13:09:33.207: INFO: (10) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.439621ms)
Jun 18 13:09:33.237: INFO: (11) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 29.70776ms)
Jun 18 13:09:33.261: INFO: (12) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.199605ms)
Jun 18 13:09:33.290: INFO: (13) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 28.195825ms)
Jun 18 13:09:33.322: INFO: (14) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 32.463036ms)
Jun 18 13:09:33.346: INFO: (15) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.02537ms)
Jun 18 13:09:33.371: INFO: (16) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.243789ms)
Jun 18 13:09:33.394: INFO: (17) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.867736ms)
Jun 18 13:09:33.418: INFO: (18) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.715209ms)
Jun 18 13:09:33.442: INFO: (19) /api/v1/nodes/10.72.74.143/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.143406ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:09:33.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-tq6sf" for this suite.
Jun 18 13:09:39.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:09:39.993: INFO: namespace: e2e-tests-proxy-tq6sf, resource: bindings, ignored listing per whitelist
Jun 18 13:09:40.073: INFO: namespace e2e-tests-proxy-tq6sf deletion completed in 6.615924529s

• [SLOW TEST:7.624 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:09:40.073: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-99vqr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun 18 13:09:44.460: INFO: Successfully updated pod "labelsupdate5502ad75-91ca-11e9-bce2-ae54e022189f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:09:48.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-99vqr" for this suite.
Jun 18 13:10:12.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:10:13.070: INFO: namespace: e2e-tests-projected-99vqr, resource: bindings, ignored listing per whitelist
Jun 18 13:10:13.244: INFO: namespace e2e-tests-projected-99vqr deletion completed in 24.660263931s

• [SLOW TEST:33.171 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:10:13.245: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-2lnks
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 13:10:13.687: INFO: Creating ReplicaSet my-hostname-basic-68a98c8a-91ca-11e9-bce2-ae54e022189f
Jun 18 13:10:13.716: INFO: Pod name my-hostname-basic-68a98c8a-91ca-11e9-bce2-ae54e022189f: Found 0 pods out of 1
Jun 18 13:10:18.751: INFO: Pod name my-hostname-basic-68a98c8a-91ca-11e9-bce2-ae54e022189f: Found 1 pods out of 1
Jun 18 13:10:18.751: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-68a98c8a-91ca-11e9-bce2-ae54e022189f" is running
Jun 18 13:10:18.766: INFO: Pod "my-hostname-basic-68a98c8a-91ca-11e9-bce2-ae54e022189f-w45gp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-18 13:10:13 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-18 13:10:16 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-18 13:10:16 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-18 13:10:13 +0000 UTC Reason: Message:}])
Jun 18 13:10:18.766: INFO: Trying to dial the pod
Jun 18 13:10:23.832: INFO: Controller my-hostname-basic-68a98c8a-91ca-11e9-bce2-ae54e022189f: Got expected result from replica 1 [my-hostname-basic-68a98c8a-91ca-11e9-bce2-ae54e022189f-w45gp]: "my-hostname-basic-68a98c8a-91ca-11e9-bce2-ae54e022189f-w45gp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:10:23.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-2lnks" for this suite.
Jun 18 13:10:29.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:10:30.406: INFO: namespace: e2e-tests-replicaset-2lnks, resource: bindings, ignored listing per whitelist
Jun 18 13:10:30.476: INFO: namespace e2e-tests-replicaset-2lnks deletion completed in 6.62366172s

• [SLOW TEST:17.231 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:10:30.477: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-7cg66
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jun 18 13:10:30.988: INFO: Waiting up to 5m0s for pod "client-containers-72f16aff-91ca-11e9-bce2-ae54e022189f" in namespace "e2e-tests-containers-7cg66" to be "success or failure"
Jun 18 13:10:31.004: INFO: Pod "client-containers-72f16aff-91ca-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.010377ms
Jun 18 13:10:33.018: INFO: Pod "client-containers-72f16aff-91ca-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.030713314s
Jun 18 13:10:35.033: INFO: Pod "client-containers-72f16aff-91ca-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045601134s
STEP: Saw pod success
Jun 18 13:10:35.033: INFO: Pod "client-containers-72f16aff-91ca-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:10:35.052: INFO: Trying to get logs from node 10.72.74.144 pod client-containers-72f16aff-91ca-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 13:10:35.143: INFO: Waiting for pod client-containers-72f16aff-91ca-11e9-bce2-ae54e022189f to disappear
Jun 18 13:10:35.161: INFO: Pod client-containers-72f16aff-91ca-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:10:35.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7cg66" for this suite.
Jun 18 13:10:41.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:10:41.379: INFO: namespace: e2e-tests-containers-7cg66, resource: bindings, ignored listing per whitelist
Jun 18 13:10:41.747: INFO: namespace e2e-tests-containers-7cg66 deletion completed in 6.566269952s

• [SLOW TEST:11.271 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:10:41.750: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wsgvr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-79a9faa7-91ca-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 13:10:42.252: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-79ac196e-91ca-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-wsgvr" to be "success or failure"
Jun 18 13:10:42.268: INFO: Pod "pod-projected-secrets-79ac196e-91ca-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.365547ms
Jun 18 13:10:44.291: INFO: Pod "pod-projected-secrets-79ac196e-91ca-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038934287s
STEP: Saw pod success
Jun 18 13:10:44.291: INFO: Pod "pod-projected-secrets-79ac196e-91ca-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:10:44.306: INFO: Trying to get logs from node 10.72.74.149 pod pod-projected-secrets-79ac196e-91ca-11e9-bce2-ae54e022189f container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 18 13:10:44.382: INFO: Waiting for pod pod-projected-secrets-79ac196e-91ca-11e9-bce2-ae54e022189f to disappear
Jun 18 13:10:44.397: INFO: Pod pod-projected-secrets-79ac196e-91ca-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:10:44.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wsgvr" for this suite.
Jun 18 13:10:50.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:10:50.792: INFO: namespace: e2e-tests-projected-wsgvr, resource: bindings, ignored listing per whitelist
Jun 18 13:10:50.956: INFO: namespace e2e-tests-projected-wsgvr deletion completed in 6.535961565s

• [SLOW TEST:9.205 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:10:50.956: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vcb6m
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jun 18 13:10:51.483: INFO: Waiting up to 5m0s for pod "pod-7f2cccfa-91ca-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-vcb6m" to be "success or failure"
Jun 18 13:10:51.499: INFO: Pod "pod-7f2cccfa-91ca-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.133297ms
Jun 18 13:10:53.514: INFO: Pod "pod-7f2cccfa-91ca-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031192454s
STEP: Saw pod success
Jun 18 13:10:53.514: INFO: Pod "pod-7f2cccfa-91ca-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:10:53.528: INFO: Trying to get logs from node 10.72.74.143 pod pod-7f2cccfa-91ca-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 13:10:53.604: INFO: Waiting for pod pod-7f2cccfa-91ca-11e9-bce2-ae54e022189f to disappear
Jun 18 13:10:53.619: INFO: Pod pod-7f2cccfa-91ca-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:10:53.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vcb6m" for this suite.
Jun 18 13:11:01.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:11:02.002: INFO: namespace: e2e-tests-emptydir-vcb6m, resource: bindings, ignored listing per whitelist
Jun 18 13:11:02.238: INFO: namespace e2e-tests-emptydir-vcb6m deletion completed in 8.597695433s

• [SLOW TEST:11.282 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:11:02.242: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-64mbg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-85e11667-91ca-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 13:11:02.747: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-85e33269-91ca-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-64mbg" to be "success or failure"
Jun 18 13:11:02.763: INFO: Pod "pod-projected-secrets-85e33269-91ca-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.224363ms
Jun 18 13:11:04.778: INFO: Pod "pod-projected-secrets-85e33269-91ca-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030963038s
STEP: Saw pod success
Jun 18 13:11:04.778: INFO: Pod "pod-projected-secrets-85e33269-91ca-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:11:04.792: INFO: Trying to get logs from node 10.72.74.144 pod pod-projected-secrets-85e33269-91ca-11e9-bce2-ae54e022189f container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 18 13:11:04.955: INFO: Waiting for pod pod-projected-secrets-85e33269-91ca-11e9-bce2-ae54e022189f to disappear
Jun 18 13:11:04.971: INFO: Pod pod-projected-secrets-85e33269-91ca-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:11:04.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-64mbg" for this suite.
Jun 18 13:11:11.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:11:11.130: INFO: namespace: e2e-tests-projected-64mbg, resource: bindings, ignored listing per whitelist
Jun 18 13:11:11.557: INFO: namespace e2e-tests-projected-64mbg deletion completed in 6.567768169s

• [SLOW TEST:9.316 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:11:11.558: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7qm9r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jun 18 13:11:12.041: INFO: namespace e2e-tests-kubectl-7qm9r
Jun 18 13:11:12.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 create -f - --namespace=e2e-tests-kubectl-7qm9r'
Jun 18 13:11:12.443: INFO: stderr: ""
Jun 18 13:11:12.443: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 18 13:11:13.460: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 13:11:13.460: INFO: Found 0 / 1
Jun 18 13:11:14.460: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 13:11:14.460: INFO: Found 0 / 1
Jun 18 13:11:15.460: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 13:11:15.460: INFO: Found 1 / 1
Jun 18 13:11:15.460: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 18 13:11:15.475: INFO: Selector matched 1 pods for map[app:redis]
Jun 18 13:11:15.475: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 18 13:11:15.475: INFO: wait on redis-master startup in e2e-tests-kubectl-7qm9r 
Jun 18 13:11:15.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 logs redis-master-8kdbk redis-master --namespace=e2e-tests-kubectl-7qm9r'
Jun 18 13:11:15.707: INFO: stderr: ""
Jun 18 13:11:15.707: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 18 Jun 13:11:13.718 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 18 Jun 13:11:13.718 # Server started, Redis version 3.2.12\n1:M 18 Jun 13:11:13.718 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 18 Jun 13:11:13.718 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jun 18 13:11:15.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-7qm9r'
Jun 18 13:11:15.985: INFO: stderr: ""
Jun 18 13:11:15.985: INFO: stdout: "service/rm2 exposed\n"
Jun 18 13:11:15.999: INFO: Service rm2 in namespace e2e-tests-kubectl-7qm9r found.
STEP: exposing service
Jun 18 13:11:18.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-7qm9r'
Jun 18 13:11:18.272: INFO: stderr: ""
Jun 18 13:11:18.272: INFO: stdout: "service/rm3 exposed\n"
Jun 18 13:11:18.288: INFO: Service rm3 in namespace e2e-tests-kubectl-7qm9r found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:11:20.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7qm9r" for this suite.
Jun 18 13:11:44.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:11:44.758: INFO: namespace: e2e-tests-kubectl-7qm9r, resource: bindings, ignored listing per whitelist
Jun 18 13:11:44.914: INFO: namespace e2e-tests-kubectl-7qm9r deletion completed in 24.580441115s

• [SLOW TEST:33.357 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:11:44.916: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4drcz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-4drcz
Jun 18 13:11:47.432: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-4drcz
STEP: checking the pod's current state and verifying that restartCount is present
Jun 18 13:11:47.447: INFO: Initial restart count of pod liveness-exec is 0
Jun 18 13:12:41.968: INFO: Restart count of pod e2e-tests-container-probe-4drcz/liveness-exec is now 1 (54.521413371s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:12:42.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4drcz" for this suite.
Jun 18 13:12:48.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:12:48.356: INFO: namespace: e2e-tests-container-probe-4drcz, resource: bindings, ignored listing per whitelist
Jun 18 13:12:49.154: INFO: namespace e2e-tests-container-probe-4drcz deletion completed in 7.126708611s

• [SLOW TEST:64.238 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:12:49.155: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-w9x8w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jun 18 13:12:54.942: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:12:54.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-w9x8w" for this suite.
Jun 18 13:13:19.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:13:20.342: INFO: namespace: e2e-tests-replicaset-w9x8w, resource: bindings, ignored listing per whitelist
Jun 18 13:13:20.455: INFO: namespace e2e-tests-replicaset-w9x8w deletion completed in 25.438237253s

• [SLOW TEST:31.300 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:13:20.455: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-hjl5x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-xgb7
STEP: Creating a pod to test atomic-volume-subpath
Jun 18 13:13:21.044: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xgb7" in namespace "e2e-tests-subpath-hjl5x" to be "success or failure"
Jun 18 13:13:21.062: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Pending", Reason="", readiness=false. Elapsed: 17.856378ms
Jun 18 13:13:23.103: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.059169233s
Jun 18 13:13:25.118: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 4.074205887s
Jun 18 13:13:27.133: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 6.089090054s
Jun 18 13:13:29.149: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 8.104405156s
Jun 18 13:13:31.181: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 10.136699649s
Jun 18 13:13:33.196: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 12.151280534s
Jun 18 13:13:35.210: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 14.166165172s
Jun 18 13:13:37.226: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 16.182072685s
Jun 18 13:13:39.334: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 18.289816801s
Jun 18 13:13:41.368: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 20.323974771s
Jun 18 13:13:43.384: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Running", Reason="", readiness=false. Elapsed: 22.339604032s
Jun 18 13:13:45.399: INFO: Pod "pod-subpath-test-configmap-xgb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.3543421s
STEP: Saw pod success
Jun 18 13:13:45.399: INFO: Pod "pod-subpath-test-configmap-xgb7" satisfied condition "success or failure"
Jun 18 13:13:45.413: INFO: Trying to get logs from node 10.72.74.143 pod pod-subpath-test-configmap-xgb7 container test-container-subpath-configmap-xgb7: <nil>
STEP: delete the pod
Jun 18 13:13:45.984: INFO: Waiting for pod pod-subpath-test-configmap-xgb7 to disappear
Jun 18 13:13:46.000: INFO: Pod pod-subpath-test-configmap-xgb7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xgb7
Jun 18 13:13:46.000: INFO: Deleting pod "pod-subpath-test-configmap-xgb7" in namespace "e2e-tests-subpath-hjl5x"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:13:46.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hjl5x" for this suite.
Jun 18 13:13:52.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:13:52.680: INFO: namespace: e2e-tests-subpath-hjl5x, resource: bindings, ignored listing per whitelist
Jun 18 13:13:52.829: INFO: namespace e2e-tests-subpath-hjl5x deletion completed in 6.795241037s

• [SLOW TEST:32.374 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:13:52.831: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-g9jtw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-eb9784f6-91ca-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 13:13:53.391: INFO: Waiting up to 5m0s for pod "pod-secrets-eb99a2e2-91ca-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-g9jtw" to be "success or failure"
Jun 18 13:13:53.404: INFO: Pod "pod-secrets-eb99a2e2-91ca-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.287486ms
Jun 18 13:13:55.420: INFO: Pod "pod-secrets-eb99a2e2-91ca-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.028949109s
Jun 18 13:13:57.435: INFO: Pod "pod-secrets-eb99a2e2-91ca-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044299778s
STEP: Saw pod success
Jun 18 13:13:57.435: INFO: Pod "pod-secrets-eb99a2e2-91ca-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:13:57.449: INFO: Trying to get logs from node 10.72.74.144 pod pod-secrets-eb99a2e2-91ca-11e9-bce2-ae54e022189f container secret-volume-test: <nil>
STEP: delete the pod
Jun 18 13:13:57.584: INFO: Waiting for pod pod-secrets-eb99a2e2-91ca-11e9-bce2-ae54e022189f to disappear
Jun 18 13:13:57.598: INFO: Pod pod-secrets-eb99a2e2-91ca-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:13:57.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g9jtw" for this suite.
Jun 18 13:14:03.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:14:04.185: INFO: namespace: e2e-tests-secrets-g9jtw, resource: bindings, ignored listing per whitelist
Jun 18 13:14:04.526: INFO: namespace e2e-tests-secrets-g9jtw deletion completed in 6.90896854s

• [SLOW TEST:11.695 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:14:04.528: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rsfbj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f28ab4ea-91ca-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 13:14:05.052: INFO: Waiting up to 5m0s for pod "pod-secrets-f28cd59f-91ca-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-rsfbj" to be "success or failure"
Jun 18 13:14:05.066: INFO: Pod "pod-secrets-f28cd59f-91ca-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.653521ms
Jun 18 13:14:07.081: INFO: Pod "pod-secrets-f28cd59f-91ca-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.028771815s
Jun 18 13:14:09.096: INFO: Pod "pod-secrets-f28cd59f-91ca-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043620661s
STEP: Saw pod success
Jun 18 13:14:09.096: INFO: Pod "pod-secrets-f28cd59f-91ca-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:14:09.111: INFO: Trying to get logs from node 10.72.74.149 pod pod-secrets-f28cd59f-91ca-11e9-bce2-ae54e022189f container secret-volume-test: <nil>
STEP: delete the pod
Jun 18 13:14:09.223: INFO: Waiting for pod pod-secrets-f28cd59f-91ca-11e9-bce2-ae54e022189f to disappear
Jun 18 13:14:09.237: INFO: Pod pod-secrets-f28cd59f-91ca-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:14:09.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rsfbj" for this suite.
Jun 18 13:14:15.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:14:15.906: INFO: namespace: e2e-tests-secrets-rsfbj, resource: bindings, ignored listing per whitelist
Jun 18 13:14:15.959: INFO: namespace e2e-tests-secrets-rsfbj deletion completed in 6.700216563s

• [SLOW TEST:11.432 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:14:15.961: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-wr2nx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-wr2nx
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 18 13:14:16.491: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 18 13:14:38.985: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.114.51:8080/dial?request=hostName&protocol=http&host=172.30.114.45&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-wr2nx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:14:38.985: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:14:39.232: INFO: Waiting for endpoints: map[]
Jun 18 13:14:39.246: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.114.51:8080/dial?request=hostName&protocol=http&host=172.30.39.53&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-wr2nx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:14:39.246: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:14:39.486: INFO: Waiting for endpoints: map[]
Jun 18 13:14:39.501: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.114.51:8080/dial?request=hostName&protocol=http&host=172.30.58.191&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-wr2nx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:14:39.501: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:14:39.730: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:14:39.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-wr2nx" for this suite.
Jun 18 13:15:03.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:15:04.073: INFO: namespace: e2e-tests-pod-network-test-wr2nx, resource: bindings, ignored listing per whitelist
Jun 18 13:15:04.498: INFO: namespace e2e-tests-pod-network-test-wr2nx deletion completed in 24.749006702s

• [SLOW TEST:48.537 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:15:04.499: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-j625h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-j625h.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-j625h.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-j625h.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-j625h.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-j625h.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-j625h.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 18 13:15:09.606: INFO: DNS probes using e2e-tests-dns-j625h/dns-test-1644f1a4-91cb-11e9-bce2-ae54e022189f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:15:09.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-j625h" for this suite.
Jun 18 13:15:15.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:15:16.116: INFO: namespace: e2e-tests-dns-j625h, resource: bindings, ignored listing per whitelist
Jun 18 13:15:16.205: INFO: namespace e2e-tests-dns-j625h deletion completed in 6.533811732s

• [SLOW TEST:11.706 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:15:16.205: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-7vtph
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 18 13:15:16.679: INFO: Waiting up to 5m0s for pod "pod-1d3e76e0-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-emptydir-7vtph" to be "success or failure"
Jun 18 13:15:16.693: INFO: Pod "pod-1d3e76e0-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.254873ms
Jun 18 13:15:18.709: INFO: Pod "pod-1d3e76e0-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030537471s
Jun 18 13:15:20.725: INFO: Pod "pod-1d3e76e0-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04609604s
STEP: Saw pod success
Jun 18 13:15:20.725: INFO: Pod "pod-1d3e76e0-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:15:20.742: INFO: Trying to get logs from node 10.72.74.143 pod pod-1d3e76e0-91cb-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 13:15:20.819: INFO: Waiting for pod pod-1d3e76e0-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:15:20.834: INFO: Pod pod-1d3e76e0-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:15:20.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7vtph" for this suite.
Jun 18 13:15:28.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:15:29.196: INFO: namespace: e2e-tests-emptydir-7vtph, resource: bindings, ignored listing per whitelist
Jun 18 13:15:29.414: INFO: namespace e2e-tests-emptydir-7vtph deletion completed in 8.561247385s

• [SLOW TEST:13.209 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:15:29.415: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-phbft
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun 18 13:15:29.903: INFO: Waiting up to 5m0s for pod "downward-api-252000a3-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-downward-api-phbft" to be "success or failure"
Jun 18 13:15:29.917: INFO: Pod "downward-api-252000a3-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.926631ms
Jun 18 13:15:31.932: INFO: Pod "downward-api-252000a3-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028378987s
Jun 18 13:15:33.967: INFO: Pod "downward-api-252000a3-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063922355s
STEP: Saw pod success
Jun 18 13:15:33.967: INFO: Pod "downward-api-252000a3-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:15:33.983: INFO: Trying to get logs from node 10.72.74.149 pod downward-api-252000a3-91cb-11e9-bce2-ae54e022189f container dapi-container: <nil>
STEP: delete the pod
Jun 18 13:15:34.062: INFO: Waiting for pod downward-api-252000a3-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:15:34.077: INFO: Pod downward-api-252000a3-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:15:34.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-phbft" for this suite.
Jun 18 13:15:40.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:15:40.246: INFO: namespace: e2e-tests-downward-api-phbft, resource: bindings, ignored listing per whitelist
Jun 18 13:15:40.701: INFO: namespace e2e-tests-downward-api-phbft deletion completed in 6.595767325s

• [SLOW TEST:11.286 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:15:40.703: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-knphn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2bddb6a0-91cb-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 13:15:41.225: INFO: Waiting up to 5m0s for pod "pod-secrets-2bdfd18e-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-knphn" to be "success or failure"
Jun 18 13:15:41.240: INFO: Pod "pod-secrets-2bdfd18e-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.883454ms
Jun 18 13:15:43.255: INFO: Pod "pod-secrets-2bdfd18e-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029102313s
STEP: Saw pod success
Jun 18 13:15:43.255: INFO: Pod "pod-secrets-2bdfd18e-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:15:43.284: INFO: Trying to get logs from node 10.72.74.149 pod pod-secrets-2bdfd18e-91cb-11e9-bce2-ae54e022189f container secret-env-test: <nil>
STEP: delete the pod
Jun 18 13:15:43.367: INFO: Waiting for pod pod-secrets-2bdfd18e-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:15:43.380: INFO: Pod pod-secrets-2bdfd18e-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:15:43.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-knphn" for this suite.
Jun 18 13:15:49.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:15:49.771: INFO: namespace: e2e-tests-secrets-knphn, resource: bindings, ignored listing per whitelist
Jun 18 13:15:51.233: INFO: namespace e2e-tests-secrets-knphn deletion completed in 7.832938476s

• [SLOW TEST:10.530 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:15:51.233: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-mlchq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 13:15:51.920: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"323fa8cc-91cb-11e9-bf44-fa6f350b29f0", Controller:(*bool)(0xc002371b16), BlockOwnerDeletion:(*bool)(0xc002371b17)}}
Jun 18 13:15:51.937: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3239f005-91cb-11e9-bf44-fa6f350b29f0", Controller:(*bool)(0xc002548532), BlockOwnerDeletion:(*bool)(0xc002548533)}}
Jun 18 13:15:51.953: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"323cd931-91cb-11e9-bf44-fa6f350b29f0", Controller:(*bool)(0xc002371daa), BlockOwnerDeletion:(*bool)(0xc002371dab)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:15:57.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mlchq" for this suite.
Jun 18 13:16:05.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:16:05.168: INFO: namespace: e2e-tests-gc-mlchq, resource: bindings, ignored listing per whitelist
Jun 18 13:16:05.632: INFO: namespace e2e-tests-gc-mlchq deletion completed in 8.599046468s

• [SLOW TEST:14.399 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:16:05.632: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-zf7f5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 18 13:16:10.408: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:10.422: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:12.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:12.501: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:14.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:14.438: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:16.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:16.439: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:18.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:18.454: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:20.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:20.437: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:22.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:22.438: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:24.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:24.438: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:26.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:26.438: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:28.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:28.438: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 18 13:16:30.423: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 18 13:16:30.454: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:16:30.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zf7f5" for this suite.
Jun 18 13:16:54.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:16:55.130: INFO: namespace: e2e-tests-container-lifecycle-hook-zf7f5, resource: bindings, ignored listing per whitelist
Jun 18 13:16:55.182: INFO: namespace e2e-tests-container-lifecycle-hook-zf7f5 deletion completed in 24.707416018s

• [SLOW TEST:49.550 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:16:55.183: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-dg268
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun 18 13:16:55.667: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:17:01.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dg268" for this suite.
Jun 18 13:17:27.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:17:27.652: INFO: namespace: e2e-tests-init-container-dg268, resource: bindings, ignored listing per whitelist
Jun 18 13:17:27.806: INFO: namespace e2e-tests-init-container-dg268 deletion completed in 26.601647431s

• [SLOW TEST:32.624 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:17:27.807: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-z42lz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 18 13:17:30.984: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6bbd242d-91cb-11e9-bce2-ae54e022189f"
Jun 18 13:17:30.984: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6bbd242d-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-pods-z42lz" to be "terminated due to deadline exceeded"
Jun 18 13:17:31.001: INFO: Pod "pod-update-activedeadlineseconds-6bbd242d-91cb-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 16.786835ms
Jun 18 13:17:33.091: INFO: Pod "pod-update-activedeadlineseconds-6bbd242d-91cb-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.106513917s
Jun 18 13:17:35.106: INFO: Pod "pod-update-activedeadlineseconds-6bbd242d-91cb-11e9-bce2-ae54e022189f": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.121750271s
Jun 18 13:17:35.106: INFO: Pod "pod-update-activedeadlineseconds-6bbd242d-91cb-11e9-bce2-ae54e022189f" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:17:35.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-z42lz" for this suite.
Jun 18 13:17:41.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:17:41.215: INFO: namespace: e2e-tests-pods-z42lz, resource: bindings, ignored listing per whitelist
Jun 18 13:17:41.668: INFO: namespace e2e-tests-pods-z42lz deletion completed in 6.542006554s

• [SLOW TEST:13.862 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:17:41.668: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rr7wj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-73f8089a-91cb-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 13:17:42.195: INFO: Waiting up to 5m0s for pod "pod-secrets-73fa6ecf-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-rr7wj" to be "success or failure"
Jun 18 13:17:42.211: INFO: Pod "pod-secrets-73fa6ecf-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.911754ms
Jun 18 13:17:44.226: INFO: Pod "pod-secrets-73fa6ecf-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031425931s
Jun 18 13:17:46.240: INFO: Pod "pod-secrets-73fa6ecf-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045620983s
STEP: Saw pod success
Jun 18 13:17:46.240: INFO: Pod "pod-secrets-73fa6ecf-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:17:46.258: INFO: Trying to get logs from node 10.72.74.144 pod pod-secrets-73fa6ecf-91cb-11e9-bce2-ae54e022189f container secret-volume-test: <nil>
STEP: delete the pod
Jun 18 13:17:46.423: INFO: Waiting for pod pod-secrets-73fa6ecf-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:17:46.437: INFO: Pod pod-secrets-73fa6ecf-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:17:46.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rr7wj" for this suite.
Jun 18 13:17:52.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:17:53.550: INFO: namespace: e2e-tests-secrets-rr7wj, resource: bindings, ignored listing per whitelist
Jun 18 13:17:53.909: INFO: namespace e2e-tests-secrets-rr7wj deletion completed in 7.449275272s

• [SLOW TEST:12.241 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:17:53.910: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-5khw2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 18 13:17:58.999: INFO: Successfully updated pod "pod-update-7b4271ce-91cb-11e9-bce2-ae54e022189f"
STEP: verifying the updated pod is in kubernetes
Jun 18 13:17:59.099: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:17:59.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5khw2" for this suite.
Jun 18 13:18:23.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:18:24.320: INFO: namespace: e2e-tests-pods-5khw2, resource: bindings, ignored listing per whitelist
Jun 18 13:18:24.820: INFO: namespace e2e-tests-pods-5khw2 deletion completed in 25.699431957s

• [SLOW TEST:30.911 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:18:24.821: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-dk2dd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8dabeea2-91cb-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 13:18:25.314: INFO: Waiting up to 5m0s for pod "pod-configmaps-8dade6db-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-dk2dd" to be "success or failure"
Jun 18 13:18:25.335: INFO: Pod "pod-configmaps-8dade6db-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.263003ms
Jun 18 13:18:27.350: INFO: Pod "pod-configmaps-8dade6db-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035770714s
STEP: Saw pod success
Jun 18 13:18:27.350: INFO: Pod "pod-configmaps-8dade6db-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:18:27.365: INFO: Trying to get logs from node 10.72.74.143 pod pod-configmaps-8dade6db-91cb-11e9-bce2-ae54e022189f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 13:18:27.447: INFO: Waiting for pod pod-configmaps-8dade6db-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:18:27.462: INFO: Pod pod-configmaps-8dade6db-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:18:27.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dk2dd" for this suite.
Jun 18 13:18:33.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:18:33.739: INFO: namespace: e2e-tests-configmap-dk2dd, resource: bindings, ignored listing per whitelist
Jun 18 13:18:34.040: INFO: namespace e2e-tests-configmap-dk2dd deletion completed in 6.556857498s

• [SLOW TEST:9.219 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:18:34.041: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-cxpw5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun 18 13:18:35.599: INFO: PodSpec: initContainers in spec.initContainers
Jun 18 13:19:19.552: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-93d333f4-91cb-11e9-bce2-ae54e022189f", GenerateName:"", Namespace:"e2e-tests-init-container-cxpw5", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-cxpw5/pods/pod-init-93d333f4-91cb-11e9-bce2-ae54e022189f", UID:"93d5c14c-91cb-11e9-bf44-fa6f350b29f0", ResourceVersion:"112969", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63696460715, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"599161851"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-sh6rs", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001908d80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-sh6rs", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-sh6rs", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-sh6rs", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0006aa698), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.72.74.144", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0026e7ec0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0006aa730)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0006aa750)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0006aa758), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0006aa75c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696460716, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696460716, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696460716, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696460716, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.72.74.144", PodIP:"172.30.114.48", StartTime:(*v1.Time)(0xc001a75520), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00157dd50)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00157ddc0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://505dd430c8eade065b775afed7cb772dad0b44d7ec300df02845ccd576088ed8"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001a75560), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001a75540), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:19:19.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cxpw5" for this suite.
Jun 18 13:19:43.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:19:44.003: INFO: namespace: e2e-tests-init-container-cxpw5, resource: bindings, ignored listing per whitelist
Jun 18 13:19:44.301: INFO: namespace e2e-tests-init-container-cxpw5 deletion completed in 24.703338115s

• [SLOW TEST:70.260 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:19:44.302: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-vpq7l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vpq7l
Jun 18 13:19:46.812: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vpq7l
STEP: checking the pod's current state and verifying that restartCount is present
Jun 18 13:19:46.827: INFO: Initial restart count of pod liveness-http is 0
Jun 18 13:20:08.044: INFO: Restart count of pod e2e-tests-container-probe-vpq7l/liveness-http is now 1 (21.216726207s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:20:08.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vpq7l" for this suite.
Jun 18 13:20:14.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:20:14.422: INFO: namespace: e2e-tests-container-probe-vpq7l, resource: bindings, ignored listing per whitelist
Jun 18 13:20:14.741: INFO: namespace e2e-tests-container-probe-vpq7l deletion completed in 6.632215565s

• [SLOW TEST:30.439 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:20:14.741: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-269kc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-cf2f7a3a-91cb-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 13:20:15.231: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cf31b0fa-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-269kc" to be "success or failure"
Jun 18 13:20:15.245: INFO: Pod "pod-projected-configmaps-cf31b0fa-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.039366ms
Jun 18 13:20:17.260: INFO: Pod "pod-projected-configmaps-cf31b0fa-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029047569s
Jun 18 13:20:19.275: INFO: Pod "pod-projected-configmaps-cf31b0fa-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04394336s
STEP: Saw pod success
Jun 18 13:20:19.275: INFO: Pod "pod-projected-configmaps-cf31b0fa-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:20:19.290: INFO: Trying to get logs from node 10.72.74.143 pod pod-projected-configmaps-cf31b0fa-91cb-11e9-bce2-ae54e022189f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 18 13:20:19.365: INFO: Waiting for pod pod-projected-configmaps-cf31b0fa-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:20:19.383: INFO: Pod pod-projected-configmaps-cf31b0fa-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:20:19.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-269kc" for this suite.
Jun 18 13:20:25.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:20:25.990: INFO: namespace: e2e-tests-projected-269kc, resource: bindings, ignored listing per whitelist
Jun 18 13:20:26.130: INFO: namespace e2e-tests-projected-269kc deletion completed in 6.724724058s

• [SLOW TEST:11.389 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:20:26.131: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-2lrqs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 13:20:26.578: INFO: Creating deployment "test-recreate-deployment"
Jun 18 13:20:26.597: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jun 18 13:20:26.624: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jun 18 13:20:28.655: INFO: Waiting deployment "test-recreate-deployment" to complete
Jun 18 13:20:28.669: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696460826, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696460826, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63696460826, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63696460826, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 18 13:20:30.683: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jun 18 13:20:30.714: INFO: Updating deployment test-recreate-deployment
Jun 18 13:20:30.714: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun 18 13:20:30.883: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-2lrqs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2lrqs/deployments/test-recreate-deployment,UID:d5fa9605-91cb-11e9-bf44-fa6f350b29f0,ResourceVersion:113234,Generation:2,CreationTimestamp:2019-06-18 13:20:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-06-18 13:20:30 +0000 UTC 2019-06-18 13:20:30 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-06-18 13:20:30 +0000 UTC 2019-06-18 13:20:26 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jun 18 13:20:30.900: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-2lrqs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2lrqs/replicasets/test-recreate-deployment-697fbf54bf,UID:d87c3336-91cb-11e9-bf44-fa6f350b29f0,ResourceVersion:113232,Generation:1,CreationTimestamp:2019-06-18 13:20:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d5fa9605-91cb-11e9-bf44-fa6f350b29f0 0xc00241f7a7 0xc00241f7a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 18 13:20:30.900: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jun 18 13:20:30.900: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-2lrqs,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2lrqs/replicasets/test-recreate-deployment-5dfdcc846d,UID:d5ff7d37-91cb-11e9-bf44-fa6f350b29f0,ResourceVersion:113222,Generation:2,CreationTimestamp:2019-06-18 13:20:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment d5fa9605-91cb-11e9-bf44-fa6f350b29f0 0xc00241f6e7 0xc00241f6e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun 18 13:20:30.916: INFO: Pod "test-recreate-deployment-697fbf54bf-q8zx6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-q8zx6,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-2lrqs,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2lrqs/pods/test-recreate-deployment-697fbf54bf-q8zx6,UID:d87dd047-91cb-11e9-bf44-fa6f350b29f0,ResourceVersion:113233,Generation:0,CreationTimestamp:2019-06-18 13:20:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf d87c3336-91cb-11e9-bf44-fa6f350b29f0 0xc0023b03e7 0xc0023b03e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lhx4s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lhx4s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lhx4s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.72.74.149,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023b0bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023b0bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 13:20:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 13:20:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-18 13:20:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-18 13:20:30 +0000 UTC  }],Message:,Reason:,HostIP:10.72.74.149,PodIP:,StartTime:2019-06-18 13:20:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:20:30.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2lrqs" for this suite.
Jun 18 13:20:38.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:20:39.134: INFO: namespace: e2e-tests-deployment-2lrqs, resource: bindings, ignored listing per whitelist
Jun 18 13:20:39.570: INFO: namespace e2e-tests-deployment-2lrqs deletion completed in 8.62998369s

• [SLOW TEST:13.439 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:20:39.571: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9gsfn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-9gsfn/configmap-test-ddfe3170-91cb-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume configMaps
Jun 18 13:20:40.077: INFO: Waiting up to 5m0s for pod "pod-configmaps-de00a116-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-configmap-9gsfn" to be "success or failure"
Jun 18 13:20:40.093: INFO: Pod "pod-configmaps-de00a116-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.195891ms
Jun 18 13:20:42.116: INFO: Pod "pod-configmaps-de00a116-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03960635s
STEP: Saw pod success
Jun 18 13:20:42.117: INFO: Pod "pod-configmaps-de00a116-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:20:42.132: INFO: Trying to get logs from node 10.72.74.143 pod pod-configmaps-de00a116-91cb-11e9-bce2-ae54e022189f container env-test: <nil>
STEP: delete the pod
Jun 18 13:20:42.220: INFO: Waiting for pod pod-configmaps-de00a116-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:20:42.237: INFO: Pod pod-configmaps-de00a116-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:20:42.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9gsfn" for this suite.
Jun 18 13:20:48.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:20:48.591: INFO: namespace: e2e-tests-configmap-9gsfn, resource: bindings, ignored listing per whitelist
Jun 18 13:20:48.842: INFO: namespace e2e-tests-configmap-9gsfn deletion completed in 6.58538389s

• [SLOW TEST:9.272 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:20:48.843: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5fwtb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e3808fac-91cb-11e9-bce2-ae54e022189f
STEP: Creating a pod to test consume secrets
Jun 18 13:20:49.312: INFO: Waiting up to 5m0s for pod "pod-secrets-e38285da-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-secrets-5fwtb" to be "success or failure"
Jun 18 13:20:49.326: INFO: Pod "pod-secrets-e38285da-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.972286ms
Jun 18 13:20:51.342: INFO: Pod "pod-secrets-e38285da-91cb-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.029674669s
Jun 18 13:20:53.357: INFO: Pod "pod-secrets-e38285da-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044894481s
STEP: Saw pod success
Jun 18 13:20:53.358: INFO: Pod "pod-secrets-e38285da-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:20:53.372: INFO: Trying to get logs from node 10.72.74.144 pod pod-secrets-e38285da-91cb-11e9-bce2-ae54e022189f container secret-volume-test: <nil>
STEP: delete the pod
Jun 18 13:20:53.484: INFO: Waiting for pod pod-secrets-e38285da-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:20:53.499: INFO: Pod pod-secrets-e38285da-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:20:53.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5fwtb" for this suite.
Jun 18 13:21:01.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:21:03.070: INFO: namespace: e2e-tests-secrets-5fwtb, resource: bindings, ignored listing per whitelist
Jun 18 13:21:03.606: INFO: namespace e2e-tests-secrets-5fwtb deletion completed in 10.078978876s

• [SLOW TEST:14.763 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:21:03.607: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-fqbcd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jun 18 13:21:04.101: INFO: Waiting up to 5m0s for pod "client-containers-ec5301db-91cb-11e9-bce2-ae54e022189f" in namespace "e2e-tests-containers-fqbcd" to be "success or failure"
Jun 18 13:21:04.116: INFO: Pod "client-containers-ec5301db-91cb-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.685696ms
Jun 18 13:21:06.131: INFO: Pod "client-containers-ec5301db-91cb-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02947169s
STEP: Saw pod success
Jun 18 13:21:06.131: INFO: Pod "client-containers-ec5301db-91cb-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:21:06.146: INFO: Trying to get logs from node 10.72.74.144 pod client-containers-ec5301db-91cb-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 13:21:06.222: INFO: Waiting for pod client-containers-ec5301db-91cb-11e9-bce2-ae54e022189f to disappear
Jun 18 13:21:06.236: INFO: Pod client-containers-ec5301db-91cb-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:21:06.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fqbcd" for this suite.
Jun 18 13:21:14.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:21:14.530: INFO: namespace: e2e-tests-containers-fqbcd, resource: bindings, ignored listing per whitelist
Jun 18 13:21:14.961: INFO: namespace e2e-tests-containers-fqbcd deletion completed in 8.696143974s

• [SLOW TEST:11.355 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:21:14.962: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-hmxxb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun 18 13:21:15.591: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jun 18 13:21:15.615: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hmxxb/daemonsets","resourceVersion":"113465"},"items":null}

Jun 18 13:21:15.629: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hmxxb/pods","resourceVersion":"113465"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:21:15.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hmxxb" for this suite.
Jun 18 13:21:21.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:21:22.128: INFO: namespace: e2e-tests-daemonsets-hmxxb, resource: bindings, ignored listing per whitelist
Jun 18 13:21:22.293: INFO: namespace e2e-tests-daemonsets-hmxxb deletion completed in 6.587947695s

S [SKIPPING] [7.331 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jun 18 13:21:15.591: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:21:22.295: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-rgcft
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jun 18 13:21:28.919: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:28.919: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:29.159: INFO: Exec stderr: ""
Jun 18 13:21:29.159: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:29.159: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:29.415: INFO: Exec stderr: ""
Jun 18 13:21:29.415: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:29.415: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:29.684: INFO: Exec stderr: ""
Jun 18 13:21:29.684: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:29.684: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:30.524: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jun 18 13:21:30.524: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:30.524: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:30.750: INFO: Exec stderr: ""
Jun 18 13:21:30.750: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:30.750: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:31.002: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jun 18 13:21:31.002: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:31.003: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:31.393: INFO: Exec stderr: ""
Jun 18 13:21:31.394: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:31.394: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:31.767: INFO: Exec stderr: ""
Jun 18 13:21:31.767: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:31.767: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:32.001: INFO: Exec stderr: ""
Jun 18 13:21:32.001: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rgcft PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 18 13:21:32.001: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
Jun 18 13:21:32.413: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:21:32.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-rgcft" for this suite.
Jun 18 13:22:24.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:22:24.899: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-rgcft, resource: bindings, ignored listing per whitelist
Jun 18 13:22:25.063: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-rgcft deletion completed in 52.609665418s

• [SLOW TEST:62.769 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:22:25.064: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f8792
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun 18 13:22:25.594: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1ce5516b-91cc-11e9-bce2-ae54e022189f" in namespace "e2e-tests-projected-f8792" to be "success or failure"
Jun 18 13:22:25.609: INFO: Pod "downwardapi-volume-1ce5516b-91cc-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.092294ms
Jun 18 13:22:27.625: INFO: Pod "downwardapi-volume-1ce5516b-91cc-11e9-bce2-ae54e022189f": Phase="Running", Reason="", readiness=true. Elapsed: 2.031110444s
Jun 18 13:22:29.659: INFO: Pod "downwardapi-volume-1ce5516b-91cc-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064607827s
STEP: Saw pod success
Jun 18 13:22:29.659: INFO: Pod "downwardapi-volume-1ce5516b-91cc-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:22:29.672: INFO: Trying to get logs from node 10.72.74.149 pod downwardapi-volume-1ce5516b-91cc-11e9-bce2-ae54e022189f container client-container: <nil>
STEP: delete the pod
Jun 18 13:22:29.784: INFO: Waiting for pod downwardapi-volume-1ce5516b-91cc-11e9-bce2-ae54e022189f to disappear
Jun 18 13:22:29.802: INFO: Pod downwardapi-volume-1ce5516b-91cc-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:22:29.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f8792" for this suite.
Jun 18 13:22:37.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:22:38.113: INFO: namespace: e2e-tests-projected-f8792, resource: bindings, ignored listing per whitelist
Jun 18 13:22:38.374: INFO: namespace e2e-tests-projected-f8792 deletion completed in 8.54847721s

• [SLOW TEST:13.311 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:22:38.375: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-rvn8n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jun 18 13:22:38.851: INFO: Waiting up to 5m0s for pod "client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f" in namespace "e2e-tests-containers-rvn8n" to be "success or failure"
Jun 18 13:22:38.873: INFO: Pod "client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.868066ms
Jun 18 13:22:40.910: INFO: Pod "client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058221964s
Jun 18 13:22:42.924: INFO: Pod "client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.073081425s
Jun 18 13:22:44.939: INFO: Pod "client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.087919552s
STEP: Saw pod success
Jun 18 13:22:44.939: INFO: Pod "client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f" satisfied condition "success or failure"
Jun 18 13:22:44.954: INFO: Trying to get logs from node 10.72.74.143 pod client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f container test-container: <nil>
STEP: delete the pod
Jun 18 13:22:45.024: INFO: Waiting for pod client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f to disappear
Jun 18 13:22:45.038: INFO: Pod client-containers-24cc6bd0-91cc-11e9-bce2-ae54e022189f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:22:45.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rvn8n" for this suite.
Jun 18 13:22:51.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:22:51.520: INFO: namespace: e2e-tests-containers-rvn8n, resource: bindings, ignored listing per whitelist
Jun 18 13:22:51.827: INFO: namespace e2e-tests-containers-rvn8n deletion completed in 6.764418146s

• [SLOW TEST:13.452 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun 18 13:22:51.827: INFO: >>> kubeConfig: /tmp/kubeconfig-953583206
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rmjwh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun 18 13:22:52.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-rmjwh'
Jun 18 13:22:52.781: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 18 13:22:52.781: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jun 18 13:22:54.823: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-rx8x7]
Jun 18 13:22:54.823: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-rx8x7" in namespace "e2e-tests-kubectl-rmjwh" to be "running and ready"
Jun 18 13:22:54.899: INFO: Pod "e2e-test-nginx-rc-rx8x7": Phase="Pending", Reason="", readiness=false. Elapsed: 75.941894ms
Jun 18 13:22:56.914: INFO: Pod "e2e-test-nginx-rc-rx8x7": Phase="Running", Reason="", readiness=true. Elapsed: 2.091159932s
Jun 18 13:22:56.914: INFO: Pod "e2e-test-nginx-rc-rx8x7" satisfied condition "running and ready"
Jun 18 13:22:56.914: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-rx8x7]
Jun 18 13:22:56.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rmjwh'
Jun 18 13:22:57.119: INFO: stderr: ""
Jun 18 13:22:57.119: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jun 18 13:22:57.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-953583206 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-rmjwh'
Jun 18 13:22:57.288: INFO: stderr: ""
Jun 18 13:22:57.288: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun 18 13:22:57.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rmjwh" for this suite.
Jun 18 13:23:03.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 18 13:23:03.448: INFO: namespace: e2e-tests-kubectl-rmjwh, resource: bindings, ignored listing per whitelist
Jun 18 13:23:03.868: INFO: namespace e2e-tests-kubectl-rmjwh deletion completed in 6.561414796s

• [SLOW TEST:12.042 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSJun 18 13:23:03.869: INFO: Running AfterSuite actions on all nodes
Jun 18 13:23:03.869: INFO: Running AfterSuite actions on node 1
Jun 18 13:23:03.869: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6512.437 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h48m33.384556665s
Test Suite Passed
