I0814 21:12:00.725785      17 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-371106957
I0814 21:12:00.725942      17 e2e.go:224] Starting e2e run "27c39ba6-bed8-11e9-9404-ee44c4277148" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1565817119 - Will randomize all specs
Will run 201 of 1946 specs

Aug 14 21:12:00.933: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 21:12:00.937: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 14 21:12:01.055: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 14 21:12:01.184: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 14 21:12:01.184: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Aug 14 21:12:01.184: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 14 21:12:01.207: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug 14 21:12:01.207: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Aug 14 21:12:01.207: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Aug 14 21:12:01.207: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Aug 14 21:12:01.207: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Aug 14 21:12:01.207: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Aug 14 21:12:01.207: INFO: e2e test version: v1.13.0
Aug 14 21:12:01.213: INFO: kube-apiserver version: v1.13.9+IKS
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:12:01.213: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
Aug 14 21:12:01.598: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug 14 21:12:01.648: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-wrjjp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-28c8350d-bed8-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 21:12:01.839: INFO: Waiting up to 5m0s for pod "pod-secrets-28caa309-bed8-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-wrjjp" to be "success or failure"
Aug 14 21:12:01.856: INFO: Pod "pod-secrets-28caa309-bed8-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 17.334083ms
Aug 14 21:12:03.871: INFO: Pod "pod-secrets-28caa309-bed8-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032274641s
Aug 14 21:12:05.888: INFO: Pod "pod-secrets-28caa309-bed8-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049133253s
STEP: Saw pod success
Aug 14 21:12:05.888: INFO: Pod "pod-secrets-28caa309-bed8-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:12:05.902: INFO: Trying to get logs from node 10.73.228.2 pod pod-secrets-28caa309-bed8-11e9-9404-ee44c4277148 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 21:12:05.990: INFO: Waiting for pod pod-secrets-28caa309-bed8-11e9-9404-ee44c4277148 to disappear
Aug 14 21:12:06.007: INFO: Pod pod-secrets-28caa309-bed8-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:12:06.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wrjjp" for this suite.
Aug 14 21:12:14.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:12:14.245: INFO: namespace: e2e-tests-secrets-wrjjp, resource: bindings, ignored listing per whitelist
Aug 14 21:12:14.716: INFO: namespace e2e-tests-secrets-wrjjp deletion completed in 8.686962926s

• [SLOW TEST:13.503 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:12:14.716: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-fdsbl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-xw9qx
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Aug 14 21:12:27.868: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-lvcg6
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:12:45.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-fdsbl" for this suite.
Aug 14 21:12:51.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:12:52.391: INFO: namespace: e2e-tests-namespaces-fdsbl, resource: bindings, ignored listing per whitelist
Aug 14 21:12:52.818: INFO: namespace e2e-tests-namespaces-fdsbl deletion completed in 6.889209804s
STEP: Destroying namespace "e2e-tests-nsdeletetest-xw9qx" for this suite.
Aug 14 21:12:52.839: INFO: Namespace e2e-tests-nsdeletetest-xw9qx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-lvcg6" for this suite.
Aug 14 21:12:58.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:12:59.259: INFO: namespace: e2e-tests-nsdeletetest-lvcg6, resource: bindings, ignored listing per whitelist
Aug 14 21:12:59.671: INFO: namespace e2e-tests-nsdeletetest-lvcg6 deletion completed in 6.832121905s

• [SLOW TEST:44.955 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:12:59.671: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rs5qk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-rs5qk
Aug 14 21:13:04.163: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-rs5qk
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 21:13:04.177: INFO: Initial restart count of pod liveness-http is 0
Aug 14 21:13:20.373: INFO: Restart count of pod e2e-tests-container-probe-rs5qk/liveness-http is now 1 (16.196154553s elapsed)
Aug 14 21:13:40.587: INFO: Restart count of pod e2e-tests-container-probe-rs5qk/liveness-http is now 2 (36.410536476s elapsed)
Aug 14 21:14:00.781: INFO: Restart count of pod e2e-tests-container-probe-rs5qk/liveness-http is now 3 (56.604365942s elapsed)
Aug 14 21:14:20.995: INFO: Restart count of pod e2e-tests-container-probe-rs5qk/liveness-http is now 4 (1m16.818515395s elapsed)
Aug 14 21:15:22.223: INFO: Restart count of pod e2e-tests-container-probe-rs5qk/liveness-http is now 5 (2m18.045798723s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:15:22.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rs5qk" for this suite.
Aug 14 21:15:30.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:15:30.859: INFO: namespace: e2e-tests-container-probe-rs5qk, resource: bindings, ignored listing per whitelist
Aug 14 21:15:31.248: INFO: namespace e2e-tests-container-probe-rs5qk deletion completed in 8.879293536s

• [SLOW TEST:151.577 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:15:31.248: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-6fcnm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 14 21:15:31.681: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:15:36.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6fcnm" for this suite.
Aug 14 21:16:01.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:16:01.669: INFO: namespace: e2e-tests-init-container-6fcnm, resource: bindings, ignored listing per whitelist
Aug 14 21:16:01.775: INFO: namespace e2e-tests-init-container-6fcnm deletion completed in 24.806694848s

• [SLOW TEST:30.527 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:16:01.775: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-5kc8c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 21:16:02.224: INFO: Creating ReplicaSet my-hostname-basic-b8171e3e-bed8-11e9-9404-ee44c4277148
Aug 14 21:16:02.262: INFO: Pod name my-hostname-basic-b8171e3e-bed8-11e9-9404-ee44c4277148: Found 0 pods out of 1
Aug 14 21:16:07.284: INFO: Pod name my-hostname-basic-b8171e3e-bed8-11e9-9404-ee44c4277148: Found 1 pods out of 1
Aug 14 21:16:07.284: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b8171e3e-bed8-11e9-9404-ee44c4277148" is running
Aug 14 21:16:07.300: INFO: Pod "my-hostname-basic-b8171e3e-bed8-11e9-9404-ee44c4277148-n8g62" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 21:16:02 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 21:16:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 21:16:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 21:16:02 +0000 UTC Reason: Message:}])
Aug 14 21:16:07.300: INFO: Trying to dial the pod
Aug 14 21:16:12.376: INFO: Controller my-hostname-basic-b8171e3e-bed8-11e9-9404-ee44c4277148: Got expected result from replica 1 [my-hostname-basic-b8171e3e-bed8-11e9-9404-ee44c4277148-n8g62]: "my-hostname-basic-b8171e3e-bed8-11e9-9404-ee44c4277148-n8g62", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:16:12.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-5kc8c" for this suite.
Aug 14 21:16:20.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:16:20.765: INFO: namespace: e2e-tests-replicaset-5kc8c, resource: bindings, ignored listing per whitelist
Aug 14 21:16:21.132: INFO: namespace e2e-tests-replicaset-5kc8c deletion completed in 8.732617671s

• [SLOW TEST:19.357 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:16:21.132: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-j7gkv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0814 21:16:23.129600      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 21:16:23.129: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:16:23.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-j7gkv" for this suite.
Aug 14 21:16:31.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:16:32.106: INFO: namespace: e2e-tests-gc-j7gkv, resource: bindings, ignored listing per whitelist
Aug 14 21:16:32.107: INFO: namespace e2e-tests-gc-j7gkv deletion completed in 8.95783247s

• [SLOW TEST:10.974 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:16:32.107: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qsfkv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:16:32.613: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca2f644f-bed8-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-qsfkv" to be "success or failure"
Aug 14 21:16:32.636: INFO: Pod "downwardapi-volume-ca2f644f-bed8-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 23.312611ms
Aug 14 21:16:34.653: INFO: Pod "downwardapi-volume-ca2f644f-bed8-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040354076s
Aug 14 21:16:36.677: INFO: Pod "downwardapi-volume-ca2f644f-bed8-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064283683s
STEP: Saw pod success
Aug 14 21:16:36.677: INFO: Pod "downwardapi-volume-ca2f644f-bed8-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:16:36.693: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-ca2f644f-bed8-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 21:16:36.878: INFO: Waiting for pod downwardapi-volume-ca2f644f-bed8-11e9-9404-ee44c4277148 to disappear
Aug 14 21:16:36.891: INFO: Pod downwardapi-volume-ca2f644f-bed8-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:16:36.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qsfkv" for this suite.
Aug 14 21:16:43.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:16:43.291: INFO: namespace: e2e-tests-downward-api-qsfkv, resource: bindings, ignored listing per whitelist
Aug 14 21:16:43.723: INFO: namespace e2e-tests-downward-api-qsfkv deletion completed in 6.805437508s

• [SLOW TEST:11.616 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:16:43.723: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-55lsh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:16:44.301: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d126fe64-bed8-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-55lsh" to be "success or failure"
Aug 14 21:16:44.316: INFO: Pod "downwardapi-volume-d126fe64-bed8-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 15.915439ms
Aug 14 21:16:46.333: INFO: Pod "downwardapi-volume-d126fe64-bed8-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032632573s
STEP: Saw pod success
Aug 14 21:16:46.333: INFO: Pod "downwardapi-volume-d126fe64-bed8-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:16:46.391: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-d126fe64-bed8-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 21:16:46.479: INFO: Waiting for pod downwardapi-volume-d126fe64-bed8-11e9-9404-ee44c4277148 to disappear
Aug 14 21:16:46.496: INFO: Pod downwardapi-volume-d126fe64-bed8-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:16:46.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-55lsh" for this suite.
Aug 14 21:16:52.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:16:53.663: INFO: namespace: e2e-tests-downward-api-55lsh, resource: bindings, ignored listing per whitelist
Aug 14 21:16:53.738: INFO: namespace e2e-tests-downward-api-55lsh deletion completed in 7.215948986s

• [SLOW TEST:10.015 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:16:53.740: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-qh2q5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:16:58.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qh2q5" for this suite.
Aug 14 21:17:40.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:17:40.679: INFO: namespace: e2e-tests-kubelet-test-qh2q5, resource: bindings, ignored listing per whitelist
Aug 14 21:17:41.169: INFO: namespace e2e-tests-kubelet-test-qh2q5 deletion completed in 42.856313142s

• [SLOW TEST:47.429 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:17:41.170: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-g88qb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-g88qb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g88qb to expose endpoints map[]
Aug 14 21:17:41.634: INFO: Get endpoints failed (12.984022ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Aug 14 21:17:42.691: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g88qb exposes endpoints map[] (1.069901158s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-g88qb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g88qb to expose endpoints map[pod1:[100]]
Aug 14 21:17:45.833: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g88qb exposes endpoints map[pod1:[100]] (3.11087957s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-g88qb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g88qb to expose endpoints map[pod1:[100] pod2:[101]]
Aug 14 21:17:48.125: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g88qb exposes endpoints map[pod1:[100] pod2:[101]] (2.13408177s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-g88qb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g88qb to expose endpoints map[pod2:[101]]
Aug 14 21:17:48.182: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g88qb exposes endpoints map[pod2:[101]] (27.892156ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-g88qb
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-g88qb to expose endpoints map[]
Aug 14 21:17:48.223: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-g88qb exposes endpoints map[] (14.335391ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:17:48.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-g88qb" for this suite.
Aug 14 21:18:10.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:18:10.776: INFO: namespace: e2e-tests-services-g88qb, resource: bindings, ignored listing per whitelist
Aug 14 21:18:11.591: INFO: namespace e2e-tests-services-g88qb deletion completed in 23.264375132s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.421 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:18:11.591: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ljtcm
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 14 21:18:12.077: INFO: Waiting up to 5m0s for pod "pod-0578188d-bed9-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-ljtcm" to be "success or failure"
Aug 14 21:18:12.098: INFO: Pod "pod-0578188d-bed9-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 21.129217ms
Aug 14 21:18:14.114: INFO: Pod "pod-0578188d-bed9-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036799617s
Aug 14 21:18:16.191: INFO: Pod "pod-0578188d-bed9-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113686643s
STEP: Saw pod success
Aug 14 21:18:16.191: INFO: Pod "pod-0578188d-bed9-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:18:16.212: INFO: Trying to get logs from node 10.209.12.141 pod pod-0578188d-bed9-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 21:18:16.290: INFO: Waiting for pod pod-0578188d-bed9-11e9-9404-ee44c4277148 to disappear
Aug 14 21:18:16.305: INFO: Pod pod-0578188d-bed9-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:18:16.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ljtcm" for this suite.
Aug 14 21:18:24.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:18:24.989: INFO: namespace: e2e-tests-emptydir-ljtcm, resource: bindings, ignored listing per whitelist
Aug 14 21:18:24.989: INFO: namespace e2e-tests-emptydir-ljtcm deletion completed in 8.660408779s

• [SLOW TEST:13.398 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:18:24.991: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-flt99
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-flt99
Aug 14 21:18:27.502: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-flt99
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 21:18:27.519: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:22:28.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-flt99" for this suite.
Aug 14 21:22:36.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:22:36.639: INFO: namespace: e2e-tests-container-probe-flt99, resource: bindings, ignored listing per whitelist
Aug 14 21:22:36.954: INFO: namespace e2e-tests-container-probe-flt99 deletion completed in 8.726494306s

• [SLOW TEST:251.964 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:22:36.955: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-ptglt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 21:22:37.431: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 14 21:22:42.469: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 21:22:42.469: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 14 21:22:44.487: INFO: Creating deployment "test-rollover-deployment"
Aug 14 21:22:44.519: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 14 21:22:46.553: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 14 21:22:46.591: INFO: Ensure that both replica sets have 1 created replica
Aug 14 21:22:46.628: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 14 21:22:46.724: INFO: Updating deployment test-rollover-deployment
Aug 14 21:22:46.724: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 14 21:22:48.760: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 14 21:22:48.791: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 14 21:22:48.907: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 21:22:48.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414566, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 21:22:50.940: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 21:22:50.940: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414569, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 21:22:52.964: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 21:22:52.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414569, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 21:22:54.950: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 21:22:54.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414569, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 21:22:56.941: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 21:22:56.941: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414569, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 21:22:59.005: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 21:22:59.005: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414569, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701414564, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 21:23:01.007: INFO: 
Aug 14 21:23:01.008: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 14 21:23:01.053: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-ptglt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ptglt/deployments/test-rollover-deployment,UID:a7dc17b6-bed9-11e9-a2b3-62a1b681b4a5,ResourceVersion:20304,Generation:2,CreationTimestamp:2019-08-14 21:22:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-14 21:22:44 +0000 UTC 2019-08-14 21:22:44 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-14 21:22:59 +0000 UTC 2019-08-14 21:22:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 14 21:23:01.073: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-ptglt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ptglt/replicasets/test-rollover-deployment-6b7f9d6597,UID:a930e80b-bed9-11e9-a2b3-62a1b681b4a5,ResourceVersion:20295,Generation:2,CreationTimestamp:2019-08-14 21:22:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a7dc17b6-bed9-11e9-a2b3-62a1b681b4a5 0xc000c4f0a7 0xc000c4f0a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 21:23:01.073: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 14 21:23:01.073: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-ptglt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ptglt/replicasets/test-rollover-controller,UID:a3a014f7-bed9-11e9-a2b3-62a1b681b4a5,ResourceVersion:20303,Generation:2,CreationTimestamp:2019-08-14 21:22:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a7dc17b6-bed9-11e9-a2b3-62a1b681b4a5 0xc000c4ef17 0xc000c4ef18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 21:23:01.073: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-ptglt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ptglt/replicasets/test-rollover-deployment-6586df867b,UID:a7e7551b-bed9-11e9-a2b3-62a1b681b4a5,ResourceVersion:20254,Generation:2,CreationTimestamp:2019-08-14 21:22:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment a7dc17b6-bed9-11e9-a2b3-62a1b681b4a5 0xc000c4efd7 0xc000c4efd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 21:23:01.098: INFO: Pod "test-rollover-deployment-6b7f9d6597-mdqkq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-mdqkq,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-ptglt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ptglt/pods/test-rollover-deployment-6b7f9d6597-mdqkq,UID:a93ddfae-bed9-11e9-a2b3-62a1b681b4a5,ResourceVersion:20276,Generation:0,CreationTimestamp:2019-08-14 21:22:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 a930e80b-bed9-11e9-a2b3-62a1b681b4a5 0xc000c4fc97 0xc000c4fc98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-f84qx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-f84qx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-f84qx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c4fd10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c4fd30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:22:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:22:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:22:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:22:46 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:172.30.187.234,StartTime:2019-08-14 21:22:46 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-14 21:22:49 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://d8d1cbc257eafb672ee962efe2d2bddcab029883806a20b364449d1531d45ffe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:23:01.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ptglt" for this suite.
Aug 14 21:23:09.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:23:09.388: INFO: namespace: e2e-tests-deployment-ptglt, resource: bindings, ignored listing per whitelist
Aug 14 21:23:09.667: INFO: namespace e2e-tests-deployment-ptglt deletion completed in 8.546281626s

• [SLOW TEST:32.712 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:23:09.667: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-r6gfw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b72d9d20-bed9-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 21:23:10.234: INFO: Waiting up to 5m0s for pod "pod-configmaps-b72fbec0-bed9-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-r6gfw" to be "success or failure"
Aug 14 21:23:10.259: INFO: Pod "pod-configmaps-b72fbec0-bed9-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.935949ms
Aug 14 21:23:12.275: INFO: Pod "pod-configmaps-b72fbec0-bed9-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041064108s
Aug 14 21:23:14.311: INFO: Pod "pod-configmaps-b72fbec0-bed9-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07772432s
STEP: Saw pod success
Aug 14 21:23:14.312: INFO: Pod "pod-configmaps-b72fbec0-bed9-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:23:14.326: INFO: Trying to get logs from node 10.73.228.4 pod pod-configmaps-b72fbec0-bed9-11e9-9404-ee44c4277148 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 21:23:14.449: INFO: Waiting for pod pod-configmaps-b72fbec0-bed9-11e9-9404-ee44c4277148 to disappear
Aug 14 21:23:14.464: INFO: Pod pod-configmaps-b72fbec0-bed9-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:23:14.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r6gfw" for this suite.
Aug 14 21:23:22.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:23:22.888: INFO: namespace: e2e-tests-configmap-r6gfw, resource: bindings, ignored listing per whitelist
Aug 14 21:23:23.334: INFO: namespace e2e-tests-configmap-r6gfw deletion completed in 8.849317715s

• [SLOW TEST:13.667 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:23:23.335: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rlcq2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 14 21:23:23.785: INFO: Waiting up to 5m0s for pod "pod-bf431463-bed9-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-rlcq2" to be "success or failure"
Aug 14 21:23:23.804: INFO: Pod "pod-bf431463-bed9-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.80419ms
Aug 14 21:23:25.850: INFO: Pod "pod-bf431463-bed9-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065206341s
Aug 14 21:23:27.866: INFO: Pod "pod-bf431463-bed9-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.080888864s
STEP: Saw pod success
Aug 14 21:23:27.866: INFO: Pod "pod-bf431463-bed9-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:23:27.881: INFO: Trying to get logs from node 10.73.228.2 pod pod-bf431463-bed9-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 21:23:28.038: INFO: Waiting for pod pod-bf431463-bed9-11e9-9404-ee44c4277148 to disappear
Aug 14 21:23:28.056: INFO: Pod pod-bf431463-bed9-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:23:28.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rlcq2" for this suite.
Aug 14 21:23:36.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:23:36.403: INFO: namespace: e2e-tests-emptydir-rlcq2, resource: bindings, ignored listing per whitelist
Aug 14 21:23:36.728: INFO: namespace e2e-tests-emptydir-rlcq2 deletion completed in 8.650342005s

• [SLOW TEST:13.393 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:23:36.730: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dtrnl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 14 21:23:37.228: INFO: Waiting up to 5m0s for pod "pod-c746516e-bed9-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-dtrnl" to be "success or failure"
Aug 14 21:23:37.242: INFO: Pod "pod-c746516e-bed9-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 13.200707ms
Aug 14 21:23:39.257: INFO: Pod "pod-c746516e-bed9-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028273214s
STEP: Saw pod success
Aug 14 21:23:39.257: INFO: Pod "pod-c746516e-bed9-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:23:39.276: INFO: Trying to get logs from node 10.209.12.141 pod pod-c746516e-bed9-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 21:23:39.391: INFO: Waiting for pod pod-c746516e-bed9-11e9-9404-ee44c4277148 to disappear
Aug 14 21:23:39.415: INFO: Pod pod-c746516e-bed9-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:23:39.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dtrnl" for this suite.
Aug 14 21:23:47.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:23:48.258: INFO: namespace: e2e-tests-emptydir-dtrnl, resource: bindings, ignored listing per whitelist
Aug 14 21:23:48.394: INFO: namespace e2e-tests-emptydir-dtrnl deletion completed in 8.957592825s

• [SLOW TEST:11.664 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:23:48.394: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-95jst
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:23:48.849: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce34128a-bed9-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-95jst" to be "success or failure"
Aug 14 21:23:48.870: INFO: Pod "downwardapi-volume-ce34128a-bed9-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.467904ms
Aug 14 21:23:50.886: INFO: Pod "downwardapi-volume-ce34128a-bed9-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.036909102s
Aug 14 21:23:52.904: INFO: Pod "downwardapi-volume-ce34128a-bed9-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054538312s
STEP: Saw pod success
Aug 14 21:23:52.904: INFO: Pod "downwardapi-volume-ce34128a-bed9-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:23:52.919: INFO: Trying to get logs from node 10.73.228.4 pod downwardapi-volume-ce34128a-bed9-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 21:23:53.012: INFO: Waiting for pod downwardapi-volume-ce34128a-bed9-11e9-9404-ee44c4277148 to disappear
Aug 14 21:23:53.028: INFO: Pod downwardapi-volume-ce34128a-bed9-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:23:53.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-95jst" for this suite.
Aug 14 21:23:59.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:23:59.582: INFO: namespace: e2e-tests-projected-95jst, resource: bindings, ignored listing per whitelist
Aug 14 21:23:59.949: INFO: namespace e2e-tests-projected-95jst deletion completed in 6.899078s

• [SLOW TEST:11.555 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:23:59.950: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-gmcf5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 21:24:00.439: INFO: (0) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 29.594307ms)
Aug 14 21:24:00.476: INFO: (1) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 37.440166ms)
Aug 14 21:24:00.497: INFO: (2) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.988407ms)
Aug 14 21:24:00.519: INFO: (3) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.570034ms)
Aug 14 21:24:00.541: INFO: (4) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.683845ms)
Aug 14 21:24:00.563: INFO: (5) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.832733ms)
Aug 14 21:24:00.593: INFO: (6) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 29.70995ms)
Aug 14 21:24:00.618: INFO: (7) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.757287ms)
Aug 14 21:24:00.639: INFO: (8) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.381717ms)
Aug 14 21:24:00.661: INFO: (9) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.817278ms)
Aug 14 21:24:00.683: INFO: (10) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.736342ms)
Aug 14 21:24:00.705: INFO: (11) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.429156ms)
Aug 14 21:24:00.733: INFO: (12) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 28.096781ms)
Aug 14 21:24:00.757: INFO: (13) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.915475ms)
Aug 14 21:24:00.778: INFO: (14) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.266886ms)
Aug 14 21:24:00.803: INFO: (15) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.328772ms)
Aug 14 21:24:00.825: INFO: (16) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.237994ms)
Aug 14 21:24:00.848: INFO: (17) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.188769ms)
Aug 14 21:24:00.869: INFO: (18) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.90194ms)
Aug 14 21:24:00.890: INFO: (19) /api/v1/nodes/10.209.12.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.434254ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:24:00.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-gmcf5" for this suite.
Aug 14 21:24:08.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:24:08.994: INFO: namespace: e2e-tests-proxy-gmcf5, resource: bindings, ignored listing per whitelist
Aug 14 21:24:09.526: INFO: namespace e2e-tests-proxy-gmcf5 deletion completed in 8.614401287s

• [SLOW TEST:9.577 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:24:09.527: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bxnl7
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-dad0f8cd-bed9-11e9-9404-ee44c4277148
STEP: Creating secret with name s-test-opt-upd-dad0f926-bed9-11e9-9404-ee44c4277148
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dad0f8cd-bed9-11e9-9404-ee44c4277148
STEP: Updating secret s-test-opt-upd-dad0f926-bed9-11e9-9404-ee44c4277148
STEP: Creating secret with name s-test-opt-create-dad0f94d-bed9-11e9-9404-ee44c4277148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:25:24.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bxnl7" for this suite.
Aug 14 21:25:48.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:25:48.856: INFO: namespace: e2e-tests-projected-bxnl7, resource: bindings, ignored listing per whitelist
Aug 14 21:25:48.958: INFO: namespace e2e-tests-projected-bxnl7 deletion completed in 24.691994846s

• [SLOW TEST:99.432 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:25:48.960: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-wj6rx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wj6rx
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-wj6rx
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-wj6rx
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-wj6rx
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-wj6rx
Aug 14 21:25:53.528: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wj6rx, name: ss-0, uid: 18361261-beda-11e9-a2b3-62a1b681b4a5, status phase: Pending. Waiting for statefulset controller to delete.
Aug 14 21:26:01.697: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wj6rx, name: ss-0, uid: 18361261-beda-11e9-a2b3-62a1b681b4a5, status phase: Failed. Waiting for statefulset controller to delete.
Aug 14 21:26:02.244: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-wj6rx, name: ss-0, uid: 18361261-beda-11e9-a2b3-62a1b681b4a5, status phase: Failed. Waiting for statefulset controller to delete.
Aug 14 21:26:02.290: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-wj6rx
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-wj6rx
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-wj6rx and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 14 21:26:04.385: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wj6rx
Aug 14 21:26:04.403: INFO: Scaling statefulset ss to 0
Aug 14 21:26:14.519: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 21:26:14.534: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:26:14.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wj6rx" for this suite.
Aug 14 21:26:22.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:26:23.433: INFO: namespace: e2e-tests-statefulset-wj6rx, resource: bindings, ignored listing per whitelist
Aug 14 21:26:23.639: INFO: namespace e2e-tests-statefulset-wj6rx deletion completed in 8.857114266s

• [SLOW TEST:34.679 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:26:23.639: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7sp5b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:26:24.108: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2abe6a29-beda-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-7sp5b" to be "success or failure"
Aug 14 21:26:24.132: INFO: Pod "downwardapi-volume-2abe6a29-beda-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 23.652663ms
Aug 14 21:26:26.187: INFO: Pod "downwardapi-volume-2abe6a29-beda-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.079432599s
STEP: Saw pod success
Aug 14 21:26:26.188: INFO: Pod "downwardapi-volume-2abe6a29-beda-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:26:26.215: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-2abe6a29-beda-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 21:26:26.330: INFO: Waiting for pod downwardapi-volume-2abe6a29-beda-11e9-9404-ee44c4277148 to disappear
Aug 14 21:26:26.352: INFO: Pod downwardapi-volume-2abe6a29-beda-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:26:26.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7sp5b" for this suite.
Aug 14 21:26:34.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:26:34.908: INFO: namespace: e2e-tests-projected-7sp5b, resource: bindings, ignored listing per whitelist
Aug 14 21:26:35.160: INFO: namespace e2e-tests-projected-7sp5b deletion completed in 8.782301643s

• [SLOW TEST:11.521 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:26:35.160: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-npnn2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-8pb84
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-jkwq4
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:26:42.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-npnn2" for this suite.
Aug 14 21:26:48.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:26:48.440: INFO: namespace: e2e-tests-namespaces-npnn2, resource: bindings, ignored listing per whitelist
Aug 14 21:26:48.829: INFO: namespace e2e-tests-namespaces-npnn2 deletion completed in 6.637893916s
STEP: Destroying namespace "e2e-tests-nsdeletetest-8pb84" for this suite.
Aug 14 21:26:48.847: INFO: Namespace e2e-tests-nsdeletetest-8pb84 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-jkwq4" for this suite.
Aug 14 21:26:54.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:26:55.161: INFO: namespace: e2e-tests-nsdeletetest-jkwq4, resource: bindings, ignored listing per whitelist
Aug 14 21:26:55.611: INFO: namespace e2e-tests-nsdeletetest-jkwq4 deletion completed in 6.763802382s

• [SLOW TEST:20.450 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:26:55.611: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-6qsql
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-fhrh
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 21:26:56.114: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-fhrh" in namespace "e2e-tests-subpath-6qsql" to be "success or failure"
Aug 14 21:26:56.135: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Pending", Reason="", readiness=false. Elapsed: 21.059533ms
Aug 14 21:26:58.159: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045329962s
Aug 14 21:27:00.193: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 4.079742008s
Aug 14 21:27:02.209: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 6.094896579s
Aug 14 21:27:04.224: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 8.110771411s
Aug 14 21:27:06.240: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 10.126193025s
Aug 14 21:27:08.255: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 12.141388382s
Aug 14 21:27:10.298: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 14.184290032s
Aug 14 21:27:12.314: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 16.200163138s
Aug 14 21:27:14.331: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 18.217308817s
Aug 14 21:27:16.348: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 20.234613824s
Aug 14 21:27:18.366: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Running", Reason="", readiness=false. Elapsed: 22.252266077s
Aug 14 21:27:20.493: INFO: Pod "pod-subpath-test-projected-fhrh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.379293072s
STEP: Saw pod success
Aug 14 21:27:20.493: INFO: Pod "pod-subpath-test-projected-fhrh" satisfied condition "success or failure"
Aug 14 21:27:20.507: INFO: Trying to get logs from node 10.73.228.4 pod pod-subpath-test-projected-fhrh container test-container-subpath-projected-fhrh: <nil>
STEP: delete the pod
Aug 14 21:27:20.593: INFO: Waiting for pod pod-subpath-test-projected-fhrh to disappear
Aug 14 21:27:20.612: INFO: Pod pod-subpath-test-projected-fhrh no longer exists
STEP: Deleting pod pod-subpath-test-projected-fhrh
Aug 14 21:27:20.612: INFO: Deleting pod "pod-subpath-test-projected-fhrh" in namespace "e2e-tests-subpath-6qsql"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:27:20.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6qsql" for this suite.
Aug 14 21:27:28.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:27:29.308: INFO: namespace: e2e-tests-subpath-6qsql, resource: bindings, ignored listing per whitelist
Aug 14 21:27:29.568: INFO: namespace e2e-tests-subpath-6qsql deletion completed in 8.91727619s

• [SLOW TEST:33.956 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:27:29.568: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mlpgs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Aug 14 21:27:30.007: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-371106957 proxy --unix-socket=/tmp/kubectl-proxy-unix948626568/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:27:30.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mlpgs" for this suite.
Aug 14 21:27:36.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:27:36.238: INFO: namespace: e2e-tests-kubectl-mlpgs, resource: bindings, ignored listing per whitelist
Aug 14 21:27:36.667: INFO: namespace e2e-tests-kubectl-mlpgs deletion completed in 6.582130085s

• [SLOW TEST:7.099 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:27:36.668: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-fgvjd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fgvjd
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Aug 14 21:27:37.154: INFO: Found 0 stateful pods, waiting for 3
Aug 14 21:27:47.189: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:27:47.189: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:27:47.189: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 14 21:27:47.276: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 14 21:27:57.436: INFO: Updating stateful set ss2
Aug 14 21:27:57.475: INFO: Waiting for Pod e2e-tests-statefulset-fgvjd/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Aug 14 21:28:07.652: INFO: Found 1 stateful pods, waiting for 3
Aug 14 21:28:17.688: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:28:17.688: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:28:17.688: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 14 21:28:17.770: INFO: Updating stateful set ss2
Aug 14 21:28:17.806: INFO: Waiting for Pod e2e-tests-statefulset-fgvjd/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 14 21:28:27.956: INFO: Updating stateful set ss2
Aug 14 21:28:27.989: INFO: Waiting for StatefulSet e2e-tests-statefulset-fgvjd/ss2 to complete update
Aug 14 21:28:27.989: INFO: Waiting for Pod e2e-tests-statefulset-fgvjd/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 14 21:28:38.039: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fgvjd
Aug 14 21:28:38.054: INFO: Scaling statefulset ss2 to 0
Aug 14 21:29:08.154: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 21:29:08.190: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:29:08.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fgvjd" for this suite.
Aug 14 21:29:16.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:29:16.865: INFO: namespace: e2e-tests-statefulset-fgvjd, resource: bindings, ignored listing per whitelist
Aug 14 21:29:17.169: INFO: namespace e2e-tests-statefulset-fgvjd deletion completed in 8.889726664s

• [SLOW TEST:100.501 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:29:17.170: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-r5tkv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-r5tkv/configmap-test-922b9343-beda-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 21:29:17.640: INFO: Waiting up to 5m0s for pod "pod-configmaps-922da9b0-beda-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-r5tkv" to be "success or failure"
Aug 14 21:29:17.656: INFO: Pod "pod-configmaps-922da9b0-beda-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 15.834594ms
Aug 14 21:29:19.692: INFO: Pod "pod-configmaps-922da9b0-beda-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052226421s
Aug 14 21:29:21.708: INFO: Pod "pod-configmaps-922da9b0-beda-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067796668s
STEP: Saw pod success
Aug 14 21:29:21.708: INFO: Pod "pod-configmaps-922da9b0-beda-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:29:21.722: INFO: Trying to get logs from node 10.73.228.2 pod pod-configmaps-922da9b0-beda-11e9-9404-ee44c4277148 container env-test: <nil>
STEP: delete the pod
Aug 14 21:29:21.814: INFO: Waiting for pod pod-configmaps-922da9b0-beda-11e9-9404-ee44c4277148 to disappear
Aug 14 21:29:21.831: INFO: Pod pod-configmaps-922da9b0-beda-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:29:21.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r5tkv" for this suite.
Aug 14 21:29:29.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:29:30.055: INFO: namespace: e2e-tests-configmap-r5tkv, resource: bindings, ignored listing per whitelist
Aug 14 21:29:30.549: INFO: namespace e2e-tests-configmap-r5tkv deletion completed in 8.652891569s

• [SLOW TEST:13.379 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:29:30.552: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zmp7c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 21:29:30.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zmp7c'
Aug 14 21:29:31.367: INFO: stderr: ""
Aug 14 21:29:31.367: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Aug 14 21:29:31.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-zmp7c'
Aug 14 21:29:38.893: INFO: stderr: ""
Aug 14 21:29:38.893: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:29:38.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zmp7c" for this suite.
Aug 14 21:29:46.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:29:47.391: INFO: namespace: e2e-tests-kubectl-zmp7c, resource: bindings, ignored listing per whitelist
Aug 14 21:29:47.601: INFO: namespace e2e-tests-kubectl-zmp7c deletion completed in 8.682032626s

• [SLOW TEST:17.049 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:29:47.602: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-967h6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Aug 14 21:29:48.031: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-371106957 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:29:48.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-967h6" for this suite.
Aug 14 21:29:54.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:29:54.718: INFO: namespace: e2e-tests-kubectl-967h6, resource: bindings, ignored listing per whitelist
Aug 14 21:29:54.939: INFO: namespace e2e-tests-kubectl-967h6 deletion completed in 6.687847879s

• [SLOW TEST:7.338 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:29:54.940: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-rlcsl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Aug 14 21:29:59.482: INFO: Pod pod-hostip-a8ad8c98-beda-11e9-9404-ee44c4277148 has hostIP: 10.209.12.141
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:29:59.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rlcsl" for this suite.
Aug 14 21:30:23.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:30:23.950: INFO: namespace: e2e-tests-pods-rlcsl, resource: bindings, ignored listing per whitelist
Aug 14 21:30:24.200: INFO: namespace e2e-tests-pods-rlcsl deletion completed in 24.691085224s

• [SLOW TEST:29.259 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:30:24.200: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-45d25
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-ba25dad0-beda-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 21:30:24.712: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ba280d1c-beda-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-45d25" to be "success or failure"
Aug 14 21:30:24.730: INFO: Pod "pod-projected-secrets-ba280d1c-beda-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.477628ms
Aug 14 21:30:26.762: INFO: Pod "pod-projected-secrets-ba280d1c-beda-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050438491s
STEP: Saw pod success
Aug 14 21:30:26.762: INFO: Pod "pod-projected-secrets-ba280d1c-beda-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:30:26.777: INFO: Trying to get logs from node 10.73.228.4 pod pod-projected-secrets-ba280d1c-beda-11e9-9404-ee44c4277148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 21:30:26.873: INFO: Waiting for pod pod-projected-secrets-ba280d1c-beda-11e9-9404-ee44c4277148 to disappear
Aug 14 21:30:26.886: INFO: Pod pod-projected-secrets-ba280d1c-beda-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:30:26.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-45d25" for this suite.
Aug 14 21:30:34.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:30:35.354: INFO: namespace: e2e-tests-projected-45d25, resource: bindings, ignored listing per whitelist
Aug 14 21:30:35.528: INFO: namespace e2e-tests-projected-45d25 deletion completed in 8.620133765s

• [SLOW TEST:11.329 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:30:35.529: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tdlhc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Aug 14 21:30:35.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-tdlhc'
Aug 14 21:30:36.266: INFO: stderr: ""
Aug 14 21:30:36.266: INFO: stdout: "pod/pause created\n"
Aug 14 21:30:36.266: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 14 21:30:36.266: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-tdlhc" to be "running and ready"
Aug 14 21:30:36.280: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.64276ms
Aug 14 21:30:38.315: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.048174102s
Aug 14 21:30:38.315: INFO: Pod "pause" satisfied condition "running and ready"
Aug 14 21:30:38.315: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 14 21:30:38.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-tdlhc'
Aug 14 21:30:38.461: INFO: stderr: ""
Aug 14 21:30:38.461: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 14 21:30:38.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pod pause -L testing-label --namespace=e2e-tests-kubectl-tdlhc'
Aug 14 21:30:38.585: INFO: stderr: ""
Aug 14 21:30:38.585: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 14 21:30:38.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 label pods pause testing-label- --namespace=e2e-tests-kubectl-tdlhc'
Aug 14 21:30:38.747: INFO: stderr: ""
Aug 14 21:30:38.747: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 14 21:30:38.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pod pause -L testing-label --namespace=e2e-tests-kubectl-tdlhc'
Aug 14 21:30:38.860: INFO: stderr: ""
Aug 14 21:30:38.860: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Aug 14 21:30:38.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-tdlhc'
Aug 14 21:30:39.001: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 21:30:39.001: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 14 21:30:39.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-tdlhc'
Aug 14 21:30:39.150: INFO: stderr: "No resources found.\n"
Aug 14 21:30:39.150: INFO: stdout: ""
Aug 14 21:30:39.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -l name=pause --namespace=e2e-tests-kubectl-tdlhc -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 21:30:39.268: INFO: stderr: ""
Aug 14 21:30:39.268: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:30:39.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tdlhc" for this suite.
Aug 14 21:30:47.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:30:47.684: INFO: namespace: e2e-tests-kubectl-tdlhc, resource: bindings, ignored listing per whitelist
Aug 14 21:30:47.927: INFO: namespace e2e-tests-kubectl-tdlhc deletion completed in 8.630648763s

• [SLOW TEST:12.398 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:30:47.928: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-89r42
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 14 21:30:56.680: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:30:56.699: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:30:58.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:30:58.732: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:00.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:00.719: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:02.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:02.715: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:04.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:04.715: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:06.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:06.715: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:08.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:08.714: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:10.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:10.733: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:12.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:12.714: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:14.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:14.715: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:16.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:16.715: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:18.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:18.716: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:20.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:20.729: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:22.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:22.734: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:24.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:24.716: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 21:31:26.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 21:31:26.715: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:31:26.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-89r42" for this suite.
Aug 14 21:31:50.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:31:51.214: INFO: namespace: e2e-tests-container-lifecycle-hook-89r42, resource: bindings, ignored listing per whitelist
Aug 14 21:31:51.423: INFO: namespace e2e-tests-container-lifecycle-hook-89r42 deletion completed in 24.631514514s

• [SLOW TEST:63.495 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:31:51.423: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-vxtp2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 14 21:31:51.828: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:31:56.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vxtp2" for this suite.
Aug 14 21:32:04.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:32:04.537: INFO: namespace: e2e-tests-init-container-vxtp2, resource: bindings, ignored listing per whitelist
Aug 14 21:32:05.029: INFO: namespace e2e-tests-init-container-vxtp2 deletion completed in 8.728949291s

• [SLOW TEST:13.606 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:32:05.029: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-ctdvw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-4bp7
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 21:32:05.570: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4bp7" in namespace "e2e-tests-subpath-ctdvw" to be "success or failure"
Aug 14 21:32:05.592: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.812799ms
Aug 14 21:32:07.631: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06096243s
Aug 14 21:32:09.645: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 4.075093257s
Aug 14 21:32:11.660: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 6.090046795s
Aug 14 21:32:13.676: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 8.10616498s
Aug 14 21:32:15.697: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 10.126493498s
Aug 14 21:32:17.730: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 12.159766555s
Aug 14 21:32:19.745: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 14.175136881s
Aug 14 21:32:21.761: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 16.190407434s
Aug 14 21:32:23.777: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 18.206470287s
Aug 14 21:32:25.792: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 20.221903552s
Aug 14 21:32:27.824: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Running", Reason="", readiness=false. Elapsed: 22.253853253s
Aug 14 21:32:29.842: INFO: Pod "pod-subpath-test-secret-4bp7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.271308698s
STEP: Saw pod success
Aug 14 21:32:29.842: INFO: Pod "pod-subpath-test-secret-4bp7" satisfied condition "success or failure"
Aug 14 21:32:29.857: INFO: Trying to get logs from node 10.209.12.141 pod pod-subpath-test-secret-4bp7 container test-container-subpath-secret-4bp7: <nil>
STEP: delete the pod
Aug 14 21:32:29.946: INFO: Waiting for pod pod-subpath-test-secret-4bp7 to disappear
Aug 14 21:32:29.962: INFO: Pod pod-subpath-test-secret-4bp7 no longer exists
STEP: Deleting pod pod-subpath-test-secret-4bp7
Aug 14 21:32:29.962: INFO: Deleting pod "pod-subpath-test-secret-4bp7" in namespace "e2e-tests-subpath-ctdvw"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:32:29.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ctdvw" for this suite.
Aug 14 21:32:38.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:32:38.564: INFO: namespace: e2e-tests-subpath-ctdvw, resource: bindings, ignored listing per whitelist
Aug 14 21:32:38.625: INFO: namespace e2e-tests-subpath-ctdvw deletion completed in 8.620108024s

• [SLOW TEST:33.596 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:32:38.625: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-lsz7r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-mfq5
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 21:32:39.114: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-mfq5" in namespace "e2e-tests-subpath-lsz7r" to be "success or failure"
Aug 14 21:32:39.128: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.749713ms
Aug 14 21:32:41.143: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029421443s
Aug 14 21:32:43.160: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 4.046068647s
Aug 14 21:32:45.176: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 6.061832069s
Aug 14 21:32:47.191: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 8.076772001s
Aug 14 21:32:49.232: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 10.118356644s
Aug 14 21:32:51.291: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 12.176678359s
Aug 14 21:32:53.306: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 14.192330923s
Aug 14 21:32:55.324: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 16.210350787s
Aug 14 21:32:57.342: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 18.227773276s
Aug 14 21:32:59.373: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 20.259453459s
Aug 14 21:33:01.389: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Running", Reason="", readiness=false. Elapsed: 22.275009053s
Aug 14 21:33:03.415: INFO: Pod "pod-subpath-test-downwardapi-mfq5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.301587694s
STEP: Saw pod success
Aug 14 21:33:03.416: INFO: Pod "pod-subpath-test-downwardapi-mfq5" satisfied condition "success or failure"
Aug 14 21:33:03.432: INFO: Trying to get logs from node 10.73.228.4 pod pod-subpath-test-downwardapi-mfq5 container test-container-subpath-downwardapi-mfq5: <nil>
STEP: delete the pod
Aug 14 21:33:03.591: INFO: Waiting for pod pod-subpath-test-downwardapi-mfq5 to disappear
Aug 14 21:33:03.611: INFO: Pod pod-subpath-test-downwardapi-mfq5 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-mfq5
Aug 14 21:33:03.611: INFO: Deleting pod "pod-subpath-test-downwardapi-mfq5" in namespace "e2e-tests-subpath-lsz7r"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:33:03.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lsz7r" for this suite.
Aug 14 21:33:11.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:33:11.846: INFO: namespace: e2e-tests-subpath-lsz7r, resource: bindings, ignored listing per whitelist
Aug 14 21:33:12.308: INFO: namespace e2e-tests-subpath-lsz7r deletion completed in 8.654195112s

• [SLOW TEST:33.683 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:33:12.308: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-b4vbn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 14 21:33:21.021: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 21:33:21.041: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 21:33:23.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 21:33:23.061: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 21:33:25.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 21:33:25.058: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 21:33:27.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 21:33:27.056: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 21:33:29.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 21:33:29.057: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 21:33:31.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 21:33:31.091: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 21:33:33.041: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 21:33:33.066: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:33:33.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-b4vbn" for this suite.
Aug 14 21:33:57.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:33:57.845: INFO: namespace: e2e-tests-container-lifecycle-hook-b4vbn, resource: bindings, ignored listing per whitelist
Aug 14 21:33:58.022: INFO: namespace e2e-tests-container-lifecycle-hook-b4vbn deletion completed in 24.883902264s

• [SLOW TEST:45.714 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:33:58.023: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-7kfld
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-39927df5-bedb-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 21:33:58.496: INFO: Waiting up to 5m0s for pod "pod-secrets-3994c7b2-bedb-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-7kfld" to be "success or failure"
Aug 14 21:33:58.510: INFO: Pod "pod-secrets-3994c7b2-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 13.907812ms
Aug 14 21:34:00.525: INFO: Pod "pod-secrets-3994c7b2-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029032529s
Aug 14 21:34:02.591: INFO: Pod "pod-secrets-3994c7b2-bedb-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.094543548s
STEP: Saw pod success
Aug 14 21:34:02.591: INFO: Pod "pod-secrets-3994c7b2-bedb-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:34:02.606: INFO: Trying to get logs from node 10.73.228.4 pod pod-secrets-3994c7b2-bedb-11e9-9404-ee44c4277148 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 21:34:02.687: INFO: Waiting for pod pod-secrets-3994c7b2-bedb-11e9-9404-ee44c4277148 to disappear
Aug 14 21:34:02.704: INFO: Pod pod-secrets-3994c7b2-bedb-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:34:02.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7kfld" for this suite.
Aug 14 21:34:10.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:34:11.305: INFO: namespace: e2e-tests-secrets-7kfld, resource: bindings, ignored listing per whitelist
Aug 14 21:34:11.493: INFO: namespace e2e-tests-secrets-7kfld deletion completed in 8.767265404s

• [SLOW TEST:13.471 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:34:11.493: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hkgl2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hkgl2
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 21:34:12.000: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 21:34:36.491: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.126.80 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hkgl2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 21:34:36.491: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 21:34:37.833: INFO: Found all expected endpoints: [netserver-0]
Aug 14 21:34:37.849: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.187.246 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hkgl2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 21:34:37.849: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 21:34:39.399: INFO: Found all expected endpoints: [netserver-1]
Aug 14 21:34:39.430: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.171.141 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hkgl2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 21:34:39.430: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 21:34:40.770: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:34:40.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hkgl2" for this suite.
Aug 14 21:35:04.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:35:05.195: INFO: namespace: e2e-tests-pod-network-test-hkgl2, resource: bindings, ignored listing per whitelist
Aug 14 21:35:05.605: INFO: namespace e2e-tests-pod-network-test-hkgl2 deletion completed in 24.801717591s

• [SLOW TEST:54.112 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:35:05.605: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-v6src
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-61dc9a84-bedb-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 21:35:06.088: INFO: Waiting up to 5m0s for pod "pod-secrets-61dea1f7-bedb-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-v6src" to be "success or failure"
Aug 14 21:35:06.103: INFO: Pod "pod-secrets-61dea1f7-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.879177ms
Aug 14 21:35:08.123: INFO: Pod "pod-secrets-61dea1f7-bedb-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034964414s
STEP: Saw pod success
Aug 14 21:35:08.123: INFO: Pod "pod-secrets-61dea1f7-bedb-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:35:08.141: INFO: Trying to get logs from node 10.73.228.4 pod pod-secrets-61dea1f7-bedb-11e9-9404-ee44c4277148 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 21:35:08.221: INFO: Waiting for pod pod-secrets-61dea1f7-bedb-11e9-9404-ee44c4277148 to disappear
Aug 14 21:35:08.235: INFO: Pod pod-secrets-61dea1f7-bedb-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:35:08.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v6src" for this suite.
Aug 14 21:35:16.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:35:16.760: INFO: namespace: e2e-tests-secrets-v6src, resource: bindings, ignored listing per whitelist
Aug 14 21:35:17.094: INFO: namespace e2e-tests-secrets-v6src deletion completed in 8.837824506s

• [SLOW TEST:11.489 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:35:17.094: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9hvcn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-68b5743d-bedb-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 21:35:17.579: INFO: Waiting up to 5m0s for pod "pod-configmaps-68b7b82f-bedb-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-9hvcn" to be "success or failure"
Aug 14 21:35:17.599: INFO: Pod "pod-configmaps-68b7b82f-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.479882ms
Aug 14 21:35:19.617: INFO: Pod "pod-configmaps-68b7b82f-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037828563s
Aug 14 21:35:21.637: INFO: Pod "pod-configmaps-68b7b82f-bedb-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057450465s
STEP: Saw pod success
Aug 14 21:35:21.637: INFO: Pod "pod-configmaps-68b7b82f-bedb-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:35:21.665: INFO: Trying to get logs from node 10.73.228.2 pod pod-configmaps-68b7b82f-bedb-11e9-9404-ee44c4277148 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 21:35:21.790: INFO: Waiting for pod pod-configmaps-68b7b82f-bedb-11e9-9404-ee44c4277148 to disappear
Aug 14 21:35:21.804: INFO: Pod pod-configmaps-68b7b82f-bedb-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:35:21.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9hvcn" for this suite.
Aug 14 21:35:27.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:35:28.085: INFO: namespace: e2e-tests-configmap-9hvcn, resource: bindings, ignored listing per whitelist
Aug 14 21:35:28.659: INFO: namespace e2e-tests-configmap-9hvcn deletion completed in 6.829813579s

• [SLOW TEST:11.565 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:35:28.659: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s7qsn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:35:29.191: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f9750ff-bedb-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-s7qsn" to be "success or failure"
Aug 14 21:35:29.205: INFO: Pod "downwardapi-volume-6f9750ff-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 13.912463ms
Aug 14 21:35:31.221: INFO: Pod "downwardapi-volume-6f9750ff-bedb-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030082554s
STEP: Saw pod success
Aug 14 21:35:31.221: INFO: Pod "downwardapi-volume-6f9750ff-bedb-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:35:31.238: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-6f9750ff-bedb-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 21:35:31.311: INFO: Waiting for pod downwardapi-volume-6f9750ff-bedb-11e9-9404-ee44c4277148 to disappear
Aug 14 21:35:31.325: INFO: Pod downwardapi-volume-6f9750ff-bedb-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:35:31.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s7qsn" for this suite.
Aug 14 21:35:37.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:35:37.584: INFO: namespace: e2e-tests-projected-s7qsn, resource: bindings, ignored listing per whitelist
Aug 14 21:35:38.119: INFO: namespace e2e-tests-projected-s7qsn deletion completed in 6.771550522s

• [SLOW TEST:9.460 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:35:38.119: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8rng5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 14 21:35:38.627: INFO: Waiting up to 5m0s for pod "pod-75426206-bedb-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-8rng5" to be "success or failure"
Aug 14 21:35:38.658: INFO: Pod "pod-75426206-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 31.173401ms
Aug 14 21:35:40.672: INFO: Pod "pod-75426206-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045512591s
Aug 14 21:35:42.694: INFO: Pod "pod-75426206-bedb-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067009832s
STEP: Saw pod success
Aug 14 21:35:42.694: INFO: Pod "pod-75426206-bedb-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:35:42.861: INFO: Trying to get logs from node 10.73.228.4 pod pod-75426206-bedb-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 21:35:42.951: INFO: Waiting for pod pod-75426206-bedb-11e9-9404-ee44c4277148 to disappear
Aug 14 21:35:43.011: INFO: Pod pod-75426206-bedb-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:35:43.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8rng5" for this suite.
Aug 14 21:35:49.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:35:49.268: INFO: namespace: e2e-tests-emptydir-8rng5, resource: bindings, ignored listing per whitelist
Aug 14 21:35:49.734: INFO: namespace e2e-tests-emptydir-8rng5 deletion completed in 6.699859596s

• [SLOW TEST:11.615 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:35:49.734: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5g2g8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 14 21:35:50.188: INFO: Waiting up to 5m0s for pod "pod-7c2782cf-bedb-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-5g2g8" to be "success or failure"
Aug 14 21:35:50.207: INFO: Pod "pod-7c2782cf-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.302068ms
Aug 14 21:35:52.223: INFO: Pod "pod-7c2782cf-bedb-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.03555407s
Aug 14 21:35:54.238: INFO: Pod "pod-7c2782cf-bedb-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050490678s
STEP: Saw pod success
Aug 14 21:35:54.239: INFO: Pod "pod-7c2782cf-bedb-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:35:54.291: INFO: Trying to get logs from node 10.73.228.2 pod pod-7c2782cf-bedb-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 21:35:54.369: INFO: Waiting for pod pod-7c2782cf-bedb-11e9-9404-ee44c4277148 to disappear
Aug 14 21:35:54.384: INFO: Pod pod-7c2782cf-bedb-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:35:54.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5g2g8" for this suite.
Aug 14 21:36:02.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:36:03.025: INFO: namespace: e2e-tests-emptydir-5g2g8, resource: bindings, ignored listing per whitelist
Aug 14 21:36:03.082: INFO: namespace e2e-tests-emptydir-5g2g8 deletion completed in 8.676941648s

• [SLOW TEST:13.348 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:36:03.082: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bs2tm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 21:36:03.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-bs2tm'
Aug 14 21:36:03.664: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 21:36:03.664: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Aug 14 21:36:05.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-bs2tm'
Aug 14 21:36:05.904: INFO: stderr: ""
Aug 14 21:36:05.904: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:36:05.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bs2tm" for this suite.
Aug 14 21:36:29.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:36:30.354: INFO: namespace: e2e-tests-kubectl-bs2tm, resource: bindings, ignored listing per whitelist
Aug 14 21:36:30.635: INFO: namespace e2e-tests-kubectl-bs2tm deletion completed in 24.709356018s

• [SLOW TEST:27.553 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:36:30.635: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8prxd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:36:31.107: INFO: Waiting up to 5m0s for pod "downwardapi-volume-948b9af3-bedb-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-8prxd" to be "success or failure"
Aug 14 21:36:31.127: INFO: Pod "downwardapi-volume-948b9af3-bedb-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.499248ms
Aug 14 21:36:33.141: INFO: Pod "downwardapi-volume-948b9af3-bedb-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033781521s
STEP: Saw pod success
Aug 14 21:36:33.141: INFO: Pod "downwardapi-volume-948b9af3-bedb-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:36:33.156: INFO: Trying to get logs from node 10.73.228.4 pod downwardapi-volume-948b9af3-bedb-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 21:36:33.240: INFO: Waiting for pod downwardapi-volume-948b9af3-bedb-11e9-9404-ee44c4277148 to disappear
Aug 14 21:36:33.270: INFO: Pod downwardapi-volume-948b9af3-bedb-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:36:33.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8prxd" for this suite.
Aug 14 21:36:39.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:36:39.479: INFO: namespace: e2e-tests-projected-8prxd, resource: bindings, ignored listing per whitelist
Aug 14 21:36:39.913: INFO: namespace e2e-tests-projected-8prxd deletion completed in 6.621289085s

• [SLOW TEST:9.278 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:36:39.913: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-g9qxf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Aug 14 21:36:40.380: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-g9qxf" to be "success or failure"
Aug 14 21:36:40.405: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 24.781932ms
Aug 14 21:36:42.421: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041076516s
Aug 14 21:36:44.436: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056117879s
STEP: Saw pod success
Aug 14 21:36:44.436: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 14 21:36:44.452: INFO: Trying to get logs from node 10.73.228.2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 14 21:36:44.536: INFO: Waiting for pod pod-host-path-test to disappear
Aug 14 21:36:44.550: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:36:44.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-g9qxf" for this suite.
Aug 14 21:36:52.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:36:53.111: INFO: namespace: e2e-tests-hostpath-g9qxf, resource: bindings, ignored listing per whitelist
Aug 14 21:36:53.245: INFO: namespace e2e-tests-hostpath-g9qxf deletion completed in 8.666691484s

• [SLOW TEST:13.332 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:36:53.246: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-lnjdv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Aug 14 21:36:54.327: INFO: Waiting up to 5m0s for pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-2xgq5" in namespace "e2e-tests-svcaccounts-lnjdv" to be "success or failure"
Aug 14 21:36:54.358: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-2xgq5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.510426ms
Aug 14 21:36:56.373: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-2xgq5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045748106s
STEP: Saw pod success
Aug 14 21:36:56.373: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-2xgq5" satisfied condition "success or failure"
Aug 14 21:36:56.391: INFO: Trying to get logs from node 10.209.12.141 pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-2xgq5 container token-test: <nil>
STEP: delete the pod
Aug 14 21:36:56.485: INFO: Waiting for pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-2xgq5 to disappear
Aug 14 21:36:56.506: INFO: Pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-2xgq5 no longer exists
STEP: Creating a pod to test consume service account root CA
Aug 14 21:36:56.523: INFO: Waiting up to 5m0s for pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-q5rnx" in namespace "e2e-tests-svcaccounts-lnjdv" to be "success or failure"
Aug 14 21:36:56.538: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-q5rnx": Phase="Pending", Reason="", readiness=false. Elapsed: 14.256602ms
Aug 14 21:36:58.573: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-q5rnx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049643554s
Aug 14 21:37:00.591: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-q5rnx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067014199s
STEP: Saw pod success
Aug 14 21:37:00.591: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-q5rnx" satisfied condition "success or failure"
Aug 14 21:37:00.606: INFO: Trying to get logs from node 10.209.12.141 pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-q5rnx container root-ca-test: <nil>
STEP: delete the pod
Aug 14 21:37:00.699: INFO: Waiting for pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-q5rnx to disappear
Aug 14 21:37:00.714: INFO: Pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-q5rnx no longer exists
STEP: Creating a pod to test consume service account namespace
Aug 14 21:37:00.791: INFO: Waiting up to 5m0s for pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-7b2p7" in namespace "e2e-tests-svcaccounts-lnjdv" to be "success or failure"
Aug 14 21:37:00.812: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-7b2p7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.218422ms
Aug 14 21:37:02.828: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-7b2p7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036922358s
Aug 14 21:37:04.844: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-7b2p7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052770939s
STEP: Saw pod success
Aug 14 21:37:04.844: INFO: Pod "pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-7b2p7" satisfied condition "success or failure"
Aug 14 21:37:04.860: INFO: Trying to get logs from node 10.209.12.141 pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-7b2p7 container namespace-test: <nil>
STEP: delete the pod
Aug 14 21:37:04.968: INFO: Waiting for pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-7b2p7 to disappear
Aug 14 21:37:04.989: INFO: Pod pod-service-account-a253a23e-bedb-11e9-9404-ee44c4277148-7b2p7 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:37:04.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-lnjdv" for this suite.
Aug 14 21:37:13.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:37:13.733: INFO: namespace: e2e-tests-svcaccounts-lnjdv, resource: bindings, ignored listing per whitelist
Aug 14 21:37:13.774: INFO: namespace e2e-tests-svcaccounts-lnjdv deletion completed in 8.762380158s

• [SLOW TEST:20.529 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:37:13.775: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-hd2z8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 21:37:14.310: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 14 21:37:14.348: INFO: Number of nodes with available pods: 0
Aug 14 21:37:14.348: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 14 21:37:14.432: INFO: Number of nodes with available pods: 0
Aug 14 21:37:14.432: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:15.447: INFO: Number of nodes with available pods: 0
Aug 14 21:37:15.448: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:16.448: INFO: Number of nodes with available pods: 1
Aug 14 21:37:16.448: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 14 21:37:16.513: INFO: Number of nodes with available pods: 1
Aug 14 21:37:16.513: INFO: Number of running nodes: 0, number of available pods: 1
Aug 14 21:37:17.529: INFO: Number of nodes with available pods: 0
Aug 14 21:37:17.529: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 14 21:37:17.560: INFO: Number of nodes with available pods: 0
Aug 14 21:37:17.560: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:18.581: INFO: Number of nodes with available pods: 0
Aug 14 21:37:18.581: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:19.594: INFO: Number of nodes with available pods: 0
Aug 14 21:37:19.594: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:20.575: INFO: Number of nodes with available pods: 0
Aug 14 21:37:20.575: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:21.577: INFO: Number of nodes with available pods: 0
Aug 14 21:37:21.577: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:22.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:22.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:23.575: INFO: Number of nodes with available pods: 0
Aug 14 21:37:23.575: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:24.580: INFO: Number of nodes with available pods: 0
Aug 14 21:37:24.580: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:25.577: INFO: Number of nodes with available pods: 0
Aug 14 21:37:25.577: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:26.577: INFO: Number of nodes with available pods: 0
Aug 14 21:37:26.577: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:27.578: INFO: Number of nodes with available pods: 0
Aug 14 21:37:27.578: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:28.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:28.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:29.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:29.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:30.603: INFO: Number of nodes with available pods: 0
Aug 14 21:37:30.603: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:31.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:31.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:32.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:32.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:33.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:33.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:34.585: INFO: Number of nodes with available pods: 0
Aug 14 21:37:34.585: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:35.575: INFO: Number of nodes with available pods: 0
Aug 14 21:37:35.575: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:36.575: INFO: Number of nodes with available pods: 0
Aug 14 21:37:36.575: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:37.577: INFO: Number of nodes with available pods: 0
Aug 14 21:37:37.577: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:38.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:38.577: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:39.575: INFO: Number of nodes with available pods: 0
Aug 14 21:37:39.575: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:40.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:40.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:41.596: INFO: Number of nodes with available pods: 0
Aug 14 21:37:41.596: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:42.577: INFO: Number of nodes with available pods: 0
Aug 14 21:37:42.577: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:43.577: INFO: Number of nodes with available pods: 0
Aug 14 21:37:43.577: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:44.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:44.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:45.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:45.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:46.575: INFO: Number of nodes with available pods: 0
Aug 14 21:37:46.575: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:47.576: INFO: Number of nodes with available pods: 0
Aug 14 21:37:47.576: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:48.583: INFO: Number of nodes with available pods: 0
Aug 14 21:37:48.583: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:49.610: INFO: Number of nodes with available pods: 0
Aug 14 21:37:49.610: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:50.580: INFO: Number of nodes with available pods: 0
Aug 14 21:37:50.580: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:51.578: INFO: Number of nodes with available pods: 0
Aug 14 21:37:51.578: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 21:37:52.593: INFO: Number of nodes with available pods: 1
Aug 14 21:37:52.593: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hd2z8, will wait for the garbage collector to delete the pods
Aug 14 21:37:52.732: INFO: Deleting DaemonSet.extensions daemon-set took: 39.41902ms
Aug 14 21:37:52.833: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.304883ms
Aug 14 21:38:31.791: INFO: Number of nodes with available pods: 0
Aug 14 21:38:31.791: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 21:38:31.811: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hd2z8/daemonsets","resourceVersion":"23916"},"items":null}

Aug 14 21:38:31.828: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hd2z8/pods","resourceVersion":"23916"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:38:31.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hd2z8" for this suite.
Aug 14 21:38:39.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:38:40.461: INFO: namespace: e2e-tests-daemonsets-hd2z8, resource: bindings, ignored listing per whitelist
Aug 14 21:38:40.722: INFO: namespace e2e-tests-daemonsets-hd2z8 deletion completed in 8.784112666s

• [SLOW TEST:86.947 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:38:40.722: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-klbqz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:38:41.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-klbqz" for this suite.
Aug 14 21:38:47.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:38:47.927: INFO: namespace: e2e-tests-kubelet-test-klbqz, resource: bindings, ignored listing per whitelist
Aug 14 21:38:47.996: INFO: namespace e2e-tests-kubelet-test-klbqz deletion completed in 6.646688478s

• [SLOW TEST:7.274 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:38:47.997: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-7jhhx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 14 21:38:49.284: INFO: Pod name wrapped-volume-race-e6e180b0-bedb-11e9-9404-ee44c4277148: Found 0 pods out of 5
Aug 14 21:38:54.326: INFO: Pod name wrapped-volume-race-e6e180b0-bedb-11e9-9404-ee44c4277148: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e6e180b0-bedb-11e9-9404-ee44c4277148 in namespace e2e-tests-emptydir-wrapper-7jhhx, will wait for the garbage collector to delete the pods
Aug 14 21:39:18.625: INFO: Deleting ReplicationController wrapped-volume-race-e6e180b0-bedb-11e9-9404-ee44c4277148 took: 35.469629ms
Aug 14 21:39:18.725: INFO: Terminating ReplicationController wrapped-volume-race-e6e180b0-bedb-11e9-9404-ee44c4277148 pods took: 100.351229ms
STEP: Creating RC which spawns configmap-volume pods
Aug 14 21:40:02.321: INFO: Pod name wrapped-volume-race-1265ebb1-bedc-11e9-9404-ee44c4277148: Found 0 pods out of 5
Aug 14 21:40:07.346: INFO: Pod name wrapped-volume-race-1265ebb1-bedc-11e9-9404-ee44c4277148: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1265ebb1-bedc-11e9-9404-ee44c4277148 in namespace e2e-tests-emptydir-wrapper-7jhhx, will wait for the garbage collector to delete the pods
Aug 14 21:40:29.556: INFO: Deleting ReplicationController wrapped-volume-race-1265ebb1-bedc-11e9-9404-ee44c4277148 took: 37.816947ms
Aug 14 21:40:29.656: INFO: Terminating ReplicationController wrapped-volume-race-1265ebb1-bedc-11e9-9404-ee44c4277148 pods took: 100.274636ms
STEP: Creating RC which spawns configmap-volume pods
Aug 14 21:41:12.440: INFO: Pod name wrapped-volume-race-3c23b432-bedc-11e9-9404-ee44c4277148: Found 0 pods out of 5
Aug 14 21:41:17.491: INFO: Pod name wrapped-volume-race-3c23b432-bedc-11e9-9404-ee44c4277148: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3c23b432-bedc-11e9-9404-ee44c4277148 in namespace e2e-tests-emptydir-wrapper-7jhhx, will wait for the garbage collector to delete the pods
Aug 14 21:41:39.713: INFO: Deleting ReplicationController wrapped-volume-race-3c23b432-bedc-11e9-9404-ee44c4277148 took: 33.886196ms
Aug 14 21:41:39.813: INFO: Terminating ReplicationController wrapped-volume-race-3c23b432-bedc-11e9-9404-ee44c4277148 pods took: 100.245392ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:42:24.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-7jhhx" for this suite.
Aug 14 21:42:34.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:42:34.653: INFO: namespace: e2e-tests-emptydir-wrapper-7jhhx, resource: bindings, ignored listing per whitelist
Aug 14 21:42:35.103: INFO: namespace e2e-tests-emptydir-wrapper-7jhhx deletion completed in 11.011470688s

• [SLOW TEST:227.105 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:42:35.103: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sz97k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Aug 14 21:42:35.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 api-versions'
Aug 14 21:42:35.693: INFO: stderr: ""
Aug 14 21:42:35.693: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:42:35.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sz97k" for this suite.
Aug 14 21:42:41.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:42:42.258: INFO: namespace: e2e-tests-kubectl-sz97k, resource: bindings, ignored listing per whitelist
Aug 14 21:42:42.422: INFO: namespace e2e-tests-kubectl-sz97k deletion completed in 6.705937978s

• [SLOW TEST:7.319 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:42:42.422: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vfmx8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0814 21:42:49.237279      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 21:42:49.237: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:42:49.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vfmx8" for this suite.
Aug 14 21:42:59.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:43:00.108: INFO: namespace: e2e-tests-gc-vfmx8, resource: bindings, ignored listing per whitelist
Aug 14 21:43:00.137: INFO: namespace e2e-tests-gc-vfmx8 deletion completed in 10.873960423s

• [SLOW TEST:17.715 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:43:00.138: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6v99x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-7cc68a81-bedc-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 21:43:00.753: INFO: Waiting up to 5m0s for pod "pod-configmaps-7cca3a1a-bedc-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-6v99x" to be "success or failure"
Aug 14 21:43:00.771: INFO: Pod "pod-configmaps-7cca3a1a-bedc-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 17.748909ms
Aug 14 21:43:02.787: INFO: Pod "pod-configmaps-7cca3a1a-bedc-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.033530134s
Aug 14 21:43:04.802: INFO: Pod "pod-configmaps-7cca3a1a-bedc-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048833017s
STEP: Saw pod success
Aug 14 21:43:04.802: INFO: Pod "pod-configmaps-7cca3a1a-bedc-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:43:04.816: INFO: Trying to get logs from node 10.209.12.141 pod pod-configmaps-7cca3a1a-bedc-11e9-9404-ee44c4277148 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 21:43:04.971: INFO: Waiting for pod pod-configmaps-7cca3a1a-bedc-11e9-9404-ee44c4277148 to disappear
Aug 14 21:43:04.984: INFO: Pod pod-configmaps-7cca3a1a-bedc-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:43:04.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6v99x" for this suite.
Aug 14 21:43:13.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:43:13.190: INFO: namespace: e2e-tests-configmap-6v99x, resource: bindings, ignored listing per whitelist
Aug 14 21:43:13.710: INFO: namespace e2e-tests-configmap-6v99x deletion completed in 8.70256849s

• [SLOW TEST:13.572 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:43:13.710: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-j5rp9
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-84d5d937-bedc-11e9-9404-ee44c4277148
STEP: Creating secret with name s-test-opt-upd-84d5d99b-bedc-11e9-9404-ee44c4277148
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-84d5d937-bedc-11e9-9404-ee44c4277148
STEP: Updating secret s-test-opt-upd-84d5d99b-bedc-11e9-9404-ee44c4277148
STEP: Creating secret with name s-test-opt-create-84d5d9c9-bedc-11e9-9404-ee44c4277148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:44:32.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j5rp9" for this suite.
Aug 14 21:44:56.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:44:56.366: INFO: namespace: e2e-tests-secrets-j5rp9, resource: bindings, ignored listing per whitelist
Aug 14 21:44:56.880: INFO: namespace e2e-tests-secrets-j5rp9 deletion completed in 24.688939277s

• [SLOW TEST:103.170 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:44:56.881: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-m2cts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Aug 14 21:44:57.331: INFO: Waiting up to 5m0s for pod "client-containers-c246167a-bedc-11e9-9404-ee44c4277148" in namespace "e2e-tests-containers-m2cts" to be "success or failure"
Aug 14 21:44:57.410: INFO: Pod "client-containers-c246167a-bedc-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 78.726979ms
Aug 14 21:44:59.428: INFO: Pod "client-containers-c246167a-bedc-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097228833s
Aug 14 21:45:01.443: INFO: Pod "client-containers-c246167a-bedc-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.112010948s
STEP: Saw pod success
Aug 14 21:45:01.443: INFO: Pod "client-containers-c246167a-bedc-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:45:01.462: INFO: Trying to get logs from node 10.73.228.4 pod client-containers-c246167a-bedc-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 21:45:01.560: INFO: Waiting for pod client-containers-c246167a-bedc-11e9-9404-ee44c4277148 to disappear
Aug 14 21:45:01.604: INFO: Pod client-containers-c246167a-bedc-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:45:01.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-m2cts" for this suite.
Aug 14 21:45:09.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:45:09.861: INFO: namespace: e2e-tests-containers-m2cts, resource: bindings, ignored listing per whitelist
Aug 14 21:45:10.730: INFO: namespace e2e-tests-containers-m2cts deletion completed in 9.102923483s

• [SLOW TEST:13.850 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:45:10.731: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tjdmf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cad23ee1-bedc-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 21:45:11.682: INFO: Waiting up to 5m0s for pod "pod-configmaps-cad4852e-bedc-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-tjdmf" to be "success or failure"
Aug 14 21:45:11.698: INFO: Pod "pod-configmaps-cad4852e-bedc-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.261457ms
Aug 14 21:45:13.714: INFO: Pod "pod-configmaps-cad4852e-bedc-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031812995s
STEP: Saw pod success
Aug 14 21:45:13.714: INFO: Pod "pod-configmaps-cad4852e-bedc-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:45:13.729: INFO: Trying to get logs from node 10.73.228.2 pod pod-configmaps-cad4852e-bedc-11e9-9404-ee44c4277148 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 21:45:13.817: INFO: Waiting for pod pod-configmaps-cad4852e-bedc-11e9-9404-ee44c4277148 to disappear
Aug 14 21:45:13.835: INFO: Pod pod-configmaps-cad4852e-bedc-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:45:13.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tjdmf" for this suite.
Aug 14 21:45:21.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:45:22.089: INFO: namespace: e2e-tests-configmap-tjdmf, resource: bindings, ignored listing per whitelist
Aug 14 21:45:22.503: INFO: namespace e2e-tests-configmap-tjdmf deletion completed in 8.646346723s

• [SLOW TEST:11.772 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:45:22.504: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-h5lzm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 14 21:45:22.963: INFO: Waiting up to 5m0s for pod "pod-d18d6574-bedc-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-h5lzm" to be "success or failure"
Aug 14 21:45:22.984: INFO: Pod "pod-d18d6574-bedc-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.752247ms
Aug 14 21:45:25.001: INFO: Pod "pod-d18d6574-bedc-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.037607825s
Aug 14 21:45:27.017: INFO: Pod "pod-d18d6574-bedc-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053761202s
STEP: Saw pod success
Aug 14 21:45:27.017: INFO: Pod "pod-d18d6574-bedc-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:45:27.031: INFO: Trying to get logs from node 10.209.12.141 pod pod-d18d6574-bedc-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 21:45:27.282: INFO: Waiting for pod pod-d18d6574-bedc-11e9-9404-ee44c4277148 to disappear
Aug 14 21:45:27.308: INFO: Pod pod-d18d6574-bedc-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:45:27.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h5lzm" for this suite.
Aug 14 21:45:35.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:45:35.563: INFO: namespace: e2e-tests-emptydir-h5lzm, resource: bindings, ignored listing per whitelist
Aug 14 21:45:35.996: INFO: namespace e2e-tests-emptydir-h5lzm deletion completed in 8.665953821s

• [SLOW TEST:13.493 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:45:35.997: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-tn924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0814 21:45:46.612690      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 21:45:46.612: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:45:46.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tn924" for this suite.
Aug 14 21:45:54.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:45:55.143: INFO: namespace: e2e-tests-gc-tn924, resource: bindings, ignored listing per whitelist
Aug 14 21:45:55.565: INFO: namespace e2e-tests-gc-tn924 deletion completed in 8.935391163s

• [SLOW TEST:19.568 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:45:55.566: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-wfmvp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Aug 14 21:45:56.055: INFO: Waiting up to 5m0s for pod "var-expansion-e5478d60-bedc-11e9-9404-ee44c4277148" in namespace "e2e-tests-var-expansion-wfmvp" to be "success or failure"
Aug 14 21:45:56.069: INFO: Pod "var-expansion-e5478d60-bedc-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.05522ms
Aug 14 21:45:58.084: INFO: Pod "var-expansion-e5478d60-bedc-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028800445s
Aug 14 21:46:00.101: INFO: Pod "var-expansion-e5478d60-bedc-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046592477s
STEP: Saw pod success
Aug 14 21:46:00.101: INFO: Pod "var-expansion-e5478d60-bedc-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:46:00.118: INFO: Trying to get logs from node 10.209.12.141 pod var-expansion-e5478d60-bedc-11e9-9404-ee44c4277148 container dapi-container: <nil>
STEP: delete the pod
Aug 14 21:46:00.199: INFO: Waiting for pod var-expansion-e5478d60-bedc-11e9-9404-ee44c4277148 to disappear
Aug 14 21:46:00.240: INFO: Pod var-expansion-e5478d60-bedc-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:46:00.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-wfmvp" for this suite.
Aug 14 21:46:06.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:46:06.735: INFO: namespace: e2e-tests-var-expansion-wfmvp, resource: bindings, ignored listing per whitelist
Aug 14 21:46:07.264: INFO: namespace e2e-tests-var-expansion-wfmvp deletion completed in 7.000490075s

• [SLOW TEST:11.698 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:46:07.264: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-znttl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 21:46:07.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-znttl'
Aug 14 21:46:08.201: INFO: stderr: ""
Aug 14 21:46:08.201: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 14 21:46:13.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-znttl -o json'
Aug 14 21:46:13.407: INFO: stderr: ""
Aug 14 21:46:13.407: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-08-14T21:46:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-znttl\",\n        \"resourceVersion\": \"25891\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-znttl/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ec84912d-bedc-11e9-bfb6-223dd2282084\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-cf2nv\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.73.228.4\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-cf2nv\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-cf2nv\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T21:46:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T21:46:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T21:46:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T21:46:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://acfccf7c76405c6b752fd12cfefca13c76517be6ccc5f4498a8263d5100ee12f\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-14T21:46:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.73.228.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.126.87\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-14T21:46:08Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 14 21:46:13.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 replace -f - --namespace=e2e-tests-kubectl-znttl'
Aug 14 21:46:13.723: INFO: stderr: ""
Aug 14 21:46:13.723: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Aug 14 21:46:13.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-znttl'
Aug 14 21:46:16.136: INFO: stderr: ""
Aug 14 21:46:16.136: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:46:16.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-znttl" for this suite.
Aug 14 21:46:24.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:46:24.663: INFO: namespace: e2e-tests-kubectl-znttl, resource: bindings, ignored listing per whitelist
Aug 14 21:46:24.919: INFO: namespace e2e-tests-kubectl-znttl deletion completed in 8.743799323s

• [SLOW TEST:17.655 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:46:24.920: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-8n5gs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-w5kl
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 21:46:25.446: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w5kl" in namespace "e2e-tests-subpath-8n5gs" to be "success or failure"
Aug 14 21:46:25.465: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Pending", Reason="", readiness=false. Elapsed: 18.627232ms
Aug 14 21:46:27.498: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05169704s
Aug 14 21:46:29.517: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 4.071467978s
Aug 14 21:46:31.533: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 6.086850271s
Aug 14 21:46:33.548: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 8.101804531s
Aug 14 21:46:35.562: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 10.116285773s
Aug 14 21:46:37.598: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 12.152022688s
Aug 14 21:46:39.614: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 14.168157136s
Aug 14 21:46:41.633: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 16.186746417s
Aug 14 21:46:43.649: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 18.202697431s
Aug 14 21:46:45.664: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 20.218006695s
Aug 14 21:46:47.695: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Running", Reason="", readiness=false. Elapsed: 22.249377904s
Aug 14 21:46:49.730: INFO: Pod "pod-subpath-test-configmap-w5kl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.283644627s
STEP: Saw pod success
Aug 14 21:46:49.730: INFO: Pod "pod-subpath-test-configmap-w5kl" satisfied condition "success or failure"
Aug 14 21:46:49.749: INFO: Trying to get logs from node 10.209.12.141 pod pod-subpath-test-configmap-w5kl container test-container-subpath-configmap-w5kl: <nil>
STEP: delete the pod
Aug 14 21:46:49.891: INFO: Waiting for pod pod-subpath-test-configmap-w5kl to disappear
Aug 14 21:46:49.911: INFO: Pod pod-subpath-test-configmap-w5kl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w5kl
Aug 14 21:46:49.911: INFO: Deleting pod "pod-subpath-test-configmap-w5kl" in namespace "e2e-tests-subpath-8n5gs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:46:49.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8n5gs" for this suite.
Aug 14 21:46:58.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:46:58.428: INFO: namespace: e2e-tests-subpath-8n5gs, resource: bindings, ignored listing per whitelist
Aug 14 21:46:58.601: INFO: namespace e2e-tests-subpath-8n5gs deletion completed in 8.65582969s

• [SLOW TEST:33.682 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:46:58.604: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-f2qq7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Aug 14 21:47:01.249: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-0ae02274-bedd-11e9-9404-ee44c4277148", GenerateName:"", Namespace:"e2e-tests-pods-f2qq7", SelfLink:"/api/v1/namespaces/e2e-tests-pods-f2qq7/pods/pod-submit-remove-0ae02274-bedd-11e9-9404-ee44c4277148", UID:"0ae51f54-bedd-11e9-a2b3-62a1b681b4a5", ResourceVersion:"26070", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63701416019, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"102175913"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-vdclc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000b44900), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-vdclc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0012cfd38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.209.12.141", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001b01e60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012cfd80)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012cfda0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0012cfda8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0012cfdac)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416019, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416020, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416020, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416019, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.209.12.141", PodIP:"172.30.187.220", StartTime:(*v1.Time)(0xc000b844a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000b844c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"containerd://e810d73fda7a85b8cd074bd1b53b7f43a752f9772ea4d2d406bd9bb82eef50f9"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:47:11.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f2qq7" for this suite.
Aug 14 21:47:19.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:47:20.044: INFO: namespace: e2e-tests-pods-f2qq7, resource: bindings, ignored listing per whitelist
Aug 14 21:47:20.807: INFO: namespace e2e-tests-pods-f2qq7 deletion completed in 8.977076731s

• [SLOW TEST:22.203 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:47:20.808: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-f8xd6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 14 21:47:21.311: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-a,UID:181a850e-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26134,Generation:0,CreationTimestamp:2019-08-14 21:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 21:47:21.311: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-a,UID:181a850e-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26134,Generation:0,CreationTimestamp:2019-08-14 21:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 14 21:47:31.391: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-a,UID:181a850e-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26151,Generation:0,CreationTimestamp:2019-08-14 21:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 14 21:47:31.391: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-a,UID:181a850e-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26151,Generation:0,CreationTimestamp:2019-08-14 21:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 14 21:47:41.440: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-a,UID:181a850e-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26168,Generation:0,CreationTimestamp:2019-08-14 21:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 21:47:41.440: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-a,UID:181a850e-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26168,Generation:0,CreationTimestamp:2019-08-14 21:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 14 21:47:51.488: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-a,UID:181a850e-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26186,Generation:0,CreationTimestamp:2019-08-14 21:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 21:47:51.488: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-a,UID:181a850e-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26186,Generation:0,CreationTimestamp:2019-08-14 21:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 14 21:48:01.633: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-b,UID:30219bd6-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26203,Generation:0,CreationTimestamp:2019-08-14 21:48:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 21:48:01.633: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-b,UID:30219bd6-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26203,Generation:0,CreationTimestamp:2019-08-14 21:48:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 14 21:48:11.690: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-b,UID:30219bd6-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26220,Generation:0,CreationTimestamp:2019-08-14 21:48:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 21:48:11.690: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-f8xd6,SelfLink:/api/v1/namespaces/e2e-tests-watch-f8xd6/configmaps/e2e-watch-test-configmap-b,UID:30219bd6-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:26220,Generation:0,CreationTimestamp:2019-08-14 21:48:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:48:21.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-f8xd6" for this suite.
Aug 14 21:48:27.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:48:28.091: INFO: namespace: e2e-tests-watch-f8xd6, resource: bindings, ignored listing per whitelist
Aug 14 21:48:28.421: INFO: namespace e2e-tests-watch-f8xd6 deletion completed in 6.689665177s

• [SLOW TEST:67.614 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:48:28.422: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-8bvzz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-8bvzz
I0814 21:48:29.012790      17 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-8bvzz, replica count: 1
I0814 21:48:30.063374      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 21:48:31.063648      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 21:48:32.064034      17 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 14 21:48:32.202: INFO: Created: latency-svc-txf4b
Aug 14 21:48:32.230: INFO: Got endpoints: latency-svc-txf4b [65.566007ms]
Aug 14 21:48:32.291: INFO: Created: latency-svc-b75wl
Aug 14 21:48:32.291: INFO: Created: latency-svc-xrf6l
Aug 14 21:48:32.291: INFO: Got endpoints: latency-svc-xrf6l [61.611115ms]
Aug 14 21:48:32.303: INFO: Got endpoints: latency-svc-b75wl [73.277983ms]
Aug 14 21:48:32.315: INFO: Created: latency-svc-kb8xd
Aug 14 21:48:32.325: INFO: Got endpoints: latency-svc-kb8xd [94.504127ms]
Aug 14 21:48:32.343: INFO: Created: latency-svc-vdft6
Aug 14 21:48:32.344: INFO: Created: latency-svc-mzt7j
Aug 14 21:48:32.350: INFO: Created: latency-svc-f5pws
Aug 14 21:48:32.352: INFO: Got endpoints: latency-svc-vdft6 [122.382337ms]
Aug 14 21:48:32.353: INFO: Got endpoints: latency-svc-mzt7j [122.618751ms]
Aug 14 21:48:32.360: INFO: Got endpoints: latency-svc-f5pws [129.666324ms]
Aug 14 21:48:32.379: INFO: Created: latency-svc-cwl2g
Aug 14 21:48:32.381: INFO: Created: latency-svc-bp8qf
Aug 14 21:48:32.389: INFO: Got endpoints: latency-svc-cwl2g [158.851742ms]
Aug 14 21:48:32.390: INFO: Got endpoints: latency-svc-bp8qf [160.381977ms]
Aug 14 21:48:32.407: INFO: Created: latency-svc-t8mlh
Aug 14 21:48:32.415: INFO: Created: latency-svc-ndxtj
Aug 14 21:48:32.417: INFO: Got endpoints: latency-svc-t8mlh [187.053251ms]
Aug 14 21:48:32.426: INFO: Got endpoints: latency-svc-ndxtj [196.125477ms]
Aug 14 21:48:32.456: INFO: Created: latency-svc-mmztb
Aug 14 21:48:32.456: INFO: Created: latency-svc-nwtwz
Aug 14 21:48:32.463: INFO: Created: latency-svc-5df6w
Aug 14 21:48:32.465: INFO: Got endpoints: latency-svc-mmztb [234.927142ms]
Aug 14 21:48:32.466: INFO: Got endpoints: latency-svc-nwtwz [235.629034ms]
Aug 14 21:48:32.470: INFO: Got endpoints: latency-svc-5df6w [239.500513ms]
Aug 14 21:48:32.497: INFO: Created: latency-svc-rxb8f
Aug 14 21:48:32.499: INFO: Created: latency-svc-rhz7k
Aug 14 21:48:32.506: INFO: Got endpoints: latency-svc-rxb8f [275.695637ms]
Aug 14 21:48:32.508: INFO: Got endpoints: latency-svc-rhz7k [216.726419ms]
Aug 14 21:48:32.516: INFO: Created: latency-svc-84dbq
Aug 14 21:48:32.527: INFO: Got endpoints: latency-svc-84dbq [296.766802ms]
Aug 14 21:48:32.528: INFO: Created: latency-svc-4p6cc
Aug 14 21:48:32.541: INFO: Got endpoints: latency-svc-4p6cc [238.009202ms]
Aug 14 21:48:32.542: INFO: Created: latency-svc-zrfrm
Aug 14 21:48:32.552: INFO: Got endpoints: latency-svc-zrfrm [227.123226ms]
Aug 14 21:48:32.567: INFO: Created: latency-svc-l5qmm
Aug 14 21:48:32.579: INFO: Got endpoints: latency-svc-l5qmm [51.456337ms]
Aug 14 21:48:32.595: INFO: Created: latency-svc-xk6st
Aug 14 21:48:32.605: INFO: Got endpoints: latency-svc-xk6st [252.233064ms]
Aug 14 21:48:32.617: INFO: Created: latency-svc-rg5pm
Aug 14 21:48:32.623: INFO: Created: latency-svc-crr4n
Aug 14 21:48:32.624: INFO: Created: latency-svc-dx6c7
Aug 14 21:48:32.628: INFO: Got endpoints: latency-svc-crr4n [268.191353ms]
Aug 14 21:48:32.628: INFO: Got endpoints: latency-svc-rg5pm [275.482553ms]
Aug 14 21:48:32.635: INFO: Got endpoints: latency-svc-dx6c7 [245.546759ms]
Aug 14 21:48:32.641: INFO: Created: latency-svc-s7647
Aug 14 21:48:32.653: INFO: Got endpoints: latency-svc-s7647 [262.006916ms]
Aug 14 21:48:32.661: INFO: Created: latency-svc-5ms46
Aug 14 21:48:32.672: INFO: Got endpoints: latency-svc-5ms46 [254.308047ms]
Aug 14 21:48:32.673: INFO: Created: latency-svc-c5dbm
Aug 14 21:48:32.683: INFO: Got endpoints: latency-svc-c5dbm [256.521138ms]
Aug 14 21:48:32.694: INFO: Created: latency-svc-2t79x
Aug 14 21:48:32.703: INFO: Got endpoints: latency-svc-2t79x [236.539074ms]
Aug 14 21:48:32.709: INFO: Created: latency-svc-kh696
Aug 14 21:48:32.719: INFO: Got endpoints: latency-svc-kh696 [253.721632ms]
Aug 14 21:48:32.726: INFO: Created: latency-svc-lpjkp
Aug 14 21:48:32.736: INFO: Got endpoints: latency-svc-lpjkp [265.794354ms]
Aug 14 21:48:32.737: INFO: Created: latency-svc-g249n
Aug 14 21:48:32.751: INFO: Got endpoints: latency-svc-g249n [244.578ms]
Aug 14 21:48:32.758: INFO: Created: latency-svc-s4z2w
Aug 14 21:48:32.772: INFO: Got endpoints: latency-svc-s4z2w [263.730941ms]
Aug 14 21:48:32.794: INFO: Created: latency-svc-fzhkg
Aug 14 21:48:32.809: INFO: Got endpoints: latency-svc-fzhkg [268.29746ms]
Aug 14 21:48:32.818: INFO: Created: latency-svc-x7ngw
Aug 14 21:48:32.824: INFO: Created: latency-svc-bgqkx
Aug 14 21:48:32.832: INFO: Got endpoints: latency-svc-x7ngw [279.87917ms]
Aug 14 21:48:32.833: INFO: Got endpoints: latency-svc-bgqkx [254.535824ms]
Aug 14 21:48:32.841: INFO: Created: latency-svc-gc7p7
Aug 14 21:48:32.851: INFO: Got endpoints: latency-svc-gc7p7 [246.61389ms]
Aug 14 21:48:32.864: INFO: Created: latency-svc-nk6g4
Aug 14 21:48:32.872: INFO: Created: latency-svc-4b9hg
Aug 14 21:48:32.873: INFO: Got endpoints: latency-svc-nk6g4 [245.209296ms]
Aug 14 21:48:32.884: INFO: Got endpoints: latency-svc-4b9hg [256.08026ms]
Aug 14 21:48:32.892: INFO: Created: latency-svc-lbbpn
Aug 14 21:48:32.904: INFO: Got endpoints: latency-svc-lbbpn [269.594199ms]
Aug 14 21:48:32.904: INFO: Created: latency-svc-md9t9
Aug 14 21:48:32.914: INFO: Got endpoints: latency-svc-md9t9 [260.947837ms]
Aug 14 21:48:32.932: INFO: Created: latency-svc-pkhw2
Aug 14 21:48:32.938: INFO: Created: latency-svc-vwt5t
Aug 14 21:48:32.945: INFO: Got endpoints: latency-svc-pkhw2 [272.967812ms]
Aug 14 21:48:32.949: INFO: Got endpoints: latency-svc-vwt5t [266.103626ms]
Aug 14 21:48:32.958: INFO: Created: latency-svc-nw5ww
Aug 14 21:48:32.968: INFO: Got endpoints: latency-svc-nw5ww [265.208942ms]
Aug 14 21:48:32.974: INFO: Created: latency-svc-2zz2r
Aug 14 21:48:32.983: INFO: Got endpoints: latency-svc-2zz2r [264.141595ms]
Aug 14 21:48:32.989: INFO: Created: latency-svc-gxzcd
Aug 14 21:48:33.000: INFO: Got endpoints: latency-svc-gxzcd [263.965588ms]
Aug 14 21:48:33.014: INFO: Created: latency-svc-r7tnd
Aug 14 21:48:33.023: INFO: Created: latency-svc-8r6kz
Aug 14 21:48:33.044: INFO: Got endpoints: latency-svc-r7tnd [293.10647ms]
Aug 14 21:48:33.044: INFO: Created: latency-svc-mtmnq
Aug 14 21:48:33.061: INFO: Created: latency-svc-p9xd2
Aug 14 21:48:33.075: INFO: Created: latency-svc-28nln
Aug 14 21:48:33.095: INFO: Got endpoints: latency-svc-8r6kz [322.997049ms]
Aug 14 21:48:33.096: INFO: Created: latency-svc-fzs2w
Aug 14 21:48:33.113: INFO: Created: latency-svc-dg8wc
Aug 14 21:48:33.138: INFO: Created: latency-svc-7jdl9
Aug 14 21:48:33.142: INFO: Got endpoints: latency-svc-mtmnq [332.660058ms]
Aug 14 21:48:33.156: INFO: Created: latency-svc-gsqzs
Aug 14 21:48:33.160: INFO: Created: latency-svc-t7bm7
Aug 14 21:48:33.186: INFO: Created: latency-svc-fclgl
Aug 14 21:48:33.191: INFO: Created: latency-svc-46h87
Aug 14 21:48:33.192: INFO: Got endpoints: latency-svc-p9xd2 [360.116742ms]
Aug 14 21:48:33.210: INFO: Created: latency-svc-pt48d
Aug 14 21:48:33.224: INFO: Created: latency-svc-42wbk
Aug 14 21:48:33.238: INFO: Created: latency-svc-dj447
Aug 14 21:48:33.241: INFO: Got endpoints: latency-svc-28nln [407.242617ms]
Aug 14 21:48:33.257: INFO: Created: latency-svc-6p6wj
Aug 14 21:48:33.279: INFO: Created: latency-svc-tphbq
Aug 14 21:48:33.291: INFO: Got endpoints: latency-svc-fzs2w [439.446309ms]
Aug 14 21:48:33.305: INFO: Created: latency-svc-v5vmb
Aug 14 21:48:33.305: INFO: Created: latency-svc-cln9r
Aug 14 21:48:33.322: INFO: Created: latency-svc-hz65k
Aug 14 21:48:33.341: INFO: Got endpoints: latency-svc-dg8wc [467.900664ms]
Aug 14 21:48:33.345: INFO: Created: latency-svc-zdx47
Aug 14 21:48:33.499: INFO: Got endpoints: latency-svc-7jdl9 [615.243793ms]
Aug 14 21:48:33.500: INFO: Created: latency-svc-9jslm
Aug 14 21:48:33.500: INFO: Got endpoints: latency-svc-gsqzs [595.673347ms]
Aug 14 21:48:33.500: INFO: Got endpoints: latency-svc-t7bm7 [586.492146ms]
Aug 14 21:48:33.541: INFO: Created: latency-svc-blgsg
Aug 14 21:48:33.542: INFO: Got endpoints: latency-svc-fclgl [597.697424ms]
Aug 14 21:48:33.547: INFO: Created: latency-svc-zrgrh
Aug 14 21:48:33.564: INFO: Created: latency-svc-rs92x
Aug 14 21:48:33.580: INFO: Created: latency-svc-c4ktd
Aug 14 21:48:33.592: INFO: Got endpoints: latency-svc-46h87 [643.406127ms]
Aug 14 21:48:33.626: INFO: Created: latency-svc-qrcz5
Aug 14 21:48:33.641: INFO: Got endpoints: latency-svc-pt48d [673.343698ms]
Aug 14 21:48:33.683: INFO: Created: latency-svc-8w6d9
Aug 14 21:48:33.692: INFO: Got endpoints: latency-svc-42wbk [708.313274ms]
Aug 14 21:48:33.723: INFO: Created: latency-svc-pc27g
Aug 14 21:48:33.741: INFO: Got endpoints: latency-svc-dj447 [741.089949ms]
Aug 14 21:48:33.781: INFO: Created: latency-svc-lnrn5
Aug 14 21:48:33.797: INFO: Got endpoints: latency-svc-6p6wj [753.66714ms]
Aug 14 21:48:33.835: INFO: Created: latency-svc-45khv
Aug 14 21:48:33.841: INFO: Got endpoints: latency-svc-tphbq [746.064462ms]
Aug 14 21:48:33.996: INFO: Created: latency-svc-shf4f
Aug 14 21:48:33.996: INFO: Got endpoints: latency-svc-v5vmb [803.901523ms]
Aug 14 21:48:33.996: INFO: Got endpoints: latency-svc-cln9r [853.532613ms]
Aug 14 21:48:33.996: INFO: Got endpoints: latency-svc-hz65k [755.796583ms]
Aug 14 21:48:34.034: INFO: Created: latency-svc-f4qnh
Aug 14 21:48:34.044: INFO: Got endpoints: latency-svc-zdx47 [752.606677ms]
Aug 14 21:48:34.045: INFO: Created: latency-svc-w47nm
Aug 14 21:48:34.080: INFO: Created: latency-svc-ksb8t
Aug 14 21:48:34.091: INFO: Got endpoints: latency-svc-9jslm [749.227373ms]
Aug 14 21:48:34.095: INFO: Created: latency-svc-qrt4q
Aug 14 21:48:34.121: INFO: Created: latency-svc-4rx94
Aug 14 21:48:34.144: INFO: Got endpoints: latency-svc-blgsg [643.617097ms]
Aug 14 21:48:34.186: INFO: Created: latency-svc-p6dhc
Aug 14 21:48:34.196: INFO: Got endpoints: latency-svc-zrgrh [696.106199ms]
Aug 14 21:48:34.234: INFO: Created: latency-svc-lvdm7
Aug 14 21:48:34.243: INFO: Got endpoints: latency-svc-rs92x [742.753375ms]
Aug 14 21:48:34.282: INFO: Created: latency-svc-xwwt8
Aug 14 21:48:34.293: INFO: Got endpoints: latency-svc-c4ktd [750.942549ms]
Aug 14 21:48:34.329: INFO: Created: latency-svc-sqsh5
Aug 14 21:48:34.344: INFO: Got endpoints: latency-svc-qrcz5 [751.636462ms]
Aug 14 21:48:34.380: INFO: Created: latency-svc-vhf22
Aug 14 21:48:34.392: INFO: Got endpoints: latency-svc-8w6d9 [751.112712ms]
Aug 14 21:48:34.435: INFO: Created: latency-svc-zqf2p
Aug 14 21:48:34.443: INFO: Got endpoints: latency-svc-pc27g [751.675678ms]
Aug 14 21:48:34.474: INFO: Created: latency-svc-nbs9g
Aug 14 21:48:34.491: INFO: Got endpoints: latency-svc-lnrn5 [750.289578ms]
Aug 14 21:48:34.527: INFO: Created: latency-svc-8bn98
Aug 14 21:48:34.544: INFO: Got endpoints: latency-svc-45khv [746.06576ms]
Aug 14 21:48:34.573: INFO: Created: latency-svc-xlfvv
Aug 14 21:48:34.592: INFO: Got endpoints: latency-svc-shf4f [751.283106ms]
Aug 14 21:48:34.631: INFO: Created: latency-svc-l78dq
Aug 14 21:48:34.641: INFO: Got endpoints: latency-svc-f4qnh [645.445169ms]
Aug 14 21:48:34.692: INFO: Got endpoints: latency-svc-w47nm [695.687891ms]
Aug 14 21:48:34.791: INFO: Got endpoints: latency-svc-ksb8t [794.186514ms]
Aug 14 21:48:34.791: INFO: Created: latency-svc-gwl6l
Aug 14 21:48:34.796: INFO: Got endpoints: latency-svc-qrt4q [752.168689ms]
Aug 14 21:48:34.824: INFO: Created: latency-svc-5s7bz
Aug 14 21:48:34.841: INFO: Got endpoints: latency-svc-4rx94 [750.494158ms]
Aug 14 21:48:34.868: INFO: Created: latency-svc-mnpnf
Aug 14 21:48:34.868: INFO: Created: latency-svc-b4rnm
Aug 14 21:48:34.885: INFO: Created: latency-svc-p7fwg
Aug 14 21:48:34.891: INFO: Got endpoints: latency-svc-p6dhc [747.548434ms]
Aug 14 21:48:34.927: INFO: Created: latency-svc-gq695
Aug 14 21:48:34.941: INFO: Got endpoints: latency-svc-lvdm7 [745.748058ms]
Aug 14 21:48:34.985: INFO: Created: latency-svc-t4w9k
Aug 14 21:48:35.000: INFO: Got endpoints: latency-svc-xwwt8 [757.56093ms]
Aug 14 21:48:35.039: INFO: Created: latency-svc-z54qw
Aug 14 21:48:35.041: INFO: Got endpoints: latency-svc-sqsh5 [747.640244ms]
Aug 14 21:48:35.092: INFO: Got endpoints: latency-svc-vhf22 [747.617212ms]
Aug 14 21:48:35.094: INFO: Created: latency-svc-5tf9v
Aug 14 21:48:35.134: INFO: Created: latency-svc-5867h
Aug 14 21:48:35.141: INFO: Got endpoints: latency-svc-zqf2p [748.475601ms]
Aug 14 21:48:35.172: INFO: Created: latency-svc-48df9
Aug 14 21:48:35.191: INFO: Got endpoints: latency-svc-nbs9g [747.965527ms]
Aug 14 21:48:35.242: INFO: Got endpoints: latency-svc-8bn98 [751.187291ms]
Aug 14 21:48:35.248: INFO: Created: latency-svc-fx6bf
Aug 14 21:48:35.282: INFO: Created: latency-svc-gqfnt
Aug 14 21:48:35.292: INFO: Got endpoints: latency-svc-xlfvv [747.732914ms]
Aug 14 21:48:35.328: INFO: Created: latency-svc-8nlt7
Aug 14 21:48:35.342: INFO: Got endpoints: latency-svc-l78dq [749.775314ms]
Aug 14 21:48:35.386: INFO: Created: latency-svc-td5gq
Aug 14 21:48:35.392: INFO: Got endpoints: latency-svc-gwl6l [750.745639ms]
Aug 14 21:48:35.424: INFO: Created: latency-svc-2xrk7
Aug 14 21:48:35.441: INFO: Got endpoints: latency-svc-5s7bz [749.634096ms]
Aug 14 21:48:35.489: INFO: Created: latency-svc-kvg89
Aug 14 21:48:35.493: INFO: Got endpoints: latency-svc-b4rnm [702.256124ms]
Aug 14 21:48:35.529: INFO: Created: latency-svc-fw8gf
Aug 14 21:48:35.542: INFO: Got endpoints: latency-svc-mnpnf [746.494522ms]
Aug 14 21:48:35.592: INFO: Got endpoints: latency-svc-p7fwg [750.487189ms]
Aug 14 21:48:35.607: INFO: Created: latency-svc-76wl6
Aug 14 21:48:35.625: INFO: Created: latency-svc-9grv9
Aug 14 21:48:35.642: INFO: Got endpoints: latency-svc-gq695 [750.077488ms]
Aug 14 21:48:35.674: INFO: Created: latency-svc-z74s2
Aug 14 21:48:35.692: INFO: Got endpoints: latency-svc-t4w9k [750.338713ms]
Aug 14 21:48:35.725: INFO: Created: latency-svc-glk8s
Aug 14 21:48:35.745: INFO: Got endpoints: latency-svc-z54qw [744.24697ms]
Aug 14 21:48:35.789: INFO: Created: latency-svc-jpzmf
Aug 14 21:48:35.791: INFO: Got endpoints: latency-svc-5tf9v [750.095313ms]
Aug 14 21:48:35.840: INFO: Created: latency-svc-dsbnh
Aug 14 21:48:35.840: INFO: Got endpoints: latency-svc-5867h [748.528358ms]
Aug 14 21:48:35.876: INFO: Created: latency-svc-qr642
Aug 14 21:48:35.891: INFO: Got endpoints: latency-svc-48df9 [750.418493ms]
Aug 14 21:48:35.924: INFO: Created: latency-svc-7ch58
Aug 14 21:48:35.943: INFO: Got endpoints: latency-svc-fx6bf [750.990439ms]
Aug 14 21:48:35.976: INFO: Created: latency-svc-qhc87
Aug 14 21:48:35.992: INFO: Got endpoints: latency-svc-gqfnt [749.259196ms]
Aug 14 21:48:36.032: INFO: Created: latency-svc-nk2dv
Aug 14 21:48:36.041: INFO: Got endpoints: latency-svc-8nlt7 [749.439849ms]
Aug 14 21:48:36.075: INFO: Created: latency-svc-zrp2n
Aug 14 21:48:36.091: INFO: Got endpoints: latency-svc-td5gq [748.7646ms]
Aug 14 21:48:36.125: INFO: Created: latency-svc-cgktl
Aug 14 21:48:36.142: INFO: Got endpoints: latency-svc-2xrk7 [749.287683ms]
Aug 14 21:48:36.172: INFO: Created: latency-svc-tzt95
Aug 14 21:48:36.191: INFO: Got endpoints: latency-svc-kvg89 [749.708771ms]
Aug 14 21:48:36.224: INFO: Created: latency-svc-csrxk
Aug 14 21:48:36.241: INFO: Got endpoints: latency-svc-fw8gf [747.241928ms]
Aug 14 21:48:36.275: INFO: Created: latency-svc-pwjfp
Aug 14 21:48:36.295: INFO: Got endpoints: latency-svc-76wl6 [752.11192ms]
Aug 14 21:48:36.326: INFO: Created: latency-svc-hmq6k
Aug 14 21:48:36.344: INFO: Got endpoints: latency-svc-9grv9 [751.574117ms]
Aug 14 21:48:36.375: INFO: Created: latency-svc-bwvpl
Aug 14 21:48:36.392: INFO: Got endpoints: latency-svc-z74s2 [750.569849ms]
Aug 14 21:48:36.433: INFO: Created: latency-svc-9dg4v
Aug 14 21:48:36.442: INFO: Got endpoints: latency-svc-glk8s [750.523379ms]
Aug 14 21:48:36.491: INFO: Got endpoints: latency-svc-jpzmf [746.495062ms]
Aug 14 21:48:36.495: INFO: Created: latency-svc-hwsjj
Aug 14 21:48:36.531: INFO: Created: latency-svc-pmt2c
Aug 14 21:48:36.542: INFO: Got endpoints: latency-svc-dsbnh [750.404532ms]
Aug 14 21:48:36.578: INFO: Created: latency-svc-6jhwr
Aug 14 21:48:36.594: INFO: Got endpoints: latency-svc-qr642 [753.183799ms]
Aug 14 21:48:36.625: INFO: Created: latency-svc-p67h7
Aug 14 21:48:36.643: INFO: Got endpoints: latency-svc-7ch58 [751.397456ms]
Aug 14 21:48:36.673: INFO: Created: latency-svc-xjg2z
Aug 14 21:48:36.692: INFO: Got endpoints: latency-svc-qhc87 [749.049831ms]
Aug 14 21:48:36.741: INFO: Got endpoints: latency-svc-nk2dv [749.414634ms]
Aug 14 21:48:36.747: INFO: Created: latency-svc-hnr9d
Aug 14 21:48:36.774: INFO: Created: latency-svc-b42fd
Aug 14 21:48:36.794: INFO: Got endpoints: latency-svc-zrp2n [752.745637ms]
Aug 14 21:48:36.840: INFO: Created: latency-svc-bbrv2
Aug 14 21:48:36.847: INFO: Got endpoints: latency-svc-cgktl [755.547742ms]
Aug 14 21:48:36.879: INFO: Created: latency-svc-98x7k
Aug 14 21:48:36.891: INFO: Got endpoints: latency-svc-tzt95 [749.729551ms]
Aug 14 21:48:36.923: INFO: Created: latency-svc-p7gpd
Aug 14 21:48:36.942: INFO: Got endpoints: latency-svc-csrxk [750.363405ms]
Aug 14 21:48:36.973: INFO: Created: latency-svc-vhpcv
Aug 14 21:48:36.991: INFO: Got endpoints: latency-svc-pwjfp [750.58709ms]
Aug 14 21:48:37.032: INFO: Created: latency-svc-rbm9n
Aug 14 21:48:37.042: INFO: Got endpoints: latency-svc-hmq6k [747.255854ms]
Aug 14 21:48:37.075: INFO: Created: latency-svc-c7bqn
Aug 14 21:48:37.094: INFO: Got endpoints: latency-svc-bwvpl [750.752095ms]
Aug 14 21:48:37.132: INFO: Created: latency-svc-cmwsd
Aug 14 21:48:37.141: INFO: Got endpoints: latency-svc-9dg4v [748.779121ms]
Aug 14 21:48:37.175: INFO: Created: latency-svc-kvmch
Aug 14 21:48:37.192: INFO: Got endpoints: latency-svc-hwsjj [749.610654ms]
Aug 14 21:48:37.225: INFO: Created: latency-svc-ww6bs
Aug 14 21:48:37.241: INFO: Got endpoints: latency-svc-pmt2c [749.764653ms]
Aug 14 21:48:37.271: INFO: Created: latency-svc-j9zcd
Aug 14 21:48:37.292: INFO: Got endpoints: latency-svc-6jhwr [749.868603ms]
Aug 14 21:48:37.324: INFO: Created: latency-svc-jhj84
Aug 14 21:48:37.342: INFO: Got endpoints: latency-svc-p67h7 [748.121899ms]
Aug 14 21:48:37.378: INFO: Created: latency-svc-g5wrz
Aug 14 21:48:37.393: INFO: Got endpoints: latency-svc-xjg2z [749.725541ms]
Aug 14 21:48:37.440: INFO: Created: latency-svc-cvpb6
Aug 14 21:48:37.443: INFO: Got endpoints: latency-svc-hnr9d [751.415221ms]
Aug 14 21:48:37.489: INFO: Created: latency-svc-vcdkd
Aug 14 21:48:37.492: INFO: Got endpoints: latency-svc-b42fd [750.296958ms]
Aug 14 21:48:37.531: INFO: Created: latency-svc-q2mn7
Aug 14 21:48:37.542: INFO: Got endpoints: latency-svc-bbrv2 [747.59007ms]
Aug 14 21:48:37.579: INFO: Created: latency-svc-65s87
Aug 14 21:48:37.591: INFO: Got endpoints: latency-svc-98x7k [743.684993ms]
Aug 14 21:48:37.622: INFO: Created: latency-svc-4x7hc
Aug 14 21:48:37.642: INFO: Got endpoints: latency-svc-p7gpd [750.723214ms]
Aug 14 21:48:37.684: INFO: Created: latency-svc-clmcp
Aug 14 21:48:37.691: INFO: Got endpoints: latency-svc-vhpcv [749.15541ms]
Aug 14 21:48:37.733: INFO: Created: latency-svc-cwtns
Aug 14 21:48:37.742: INFO: Got endpoints: latency-svc-rbm9n [750.828596ms]
Aug 14 21:48:37.779: INFO: Created: latency-svc-s2wxz
Aug 14 21:48:37.792: INFO: Got endpoints: latency-svc-c7bqn [750.029259ms]
Aug 14 21:48:37.829: INFO: Created: latency-svc-c64fg
Aug 14 21:48:37.843: INFO: Got endpoints: latency-svc-cmwsd [748.765991ms]
Aug 14 21:48:37.876: INFO: Created: latency-svc-pf64v
Aug 14 21:48:37.891: INFO: Got endpoints: latency-svc-kvmch [749.983862ms]
Aug 14 21:48:37.925: INFO: Created: latency-svc-xc6lg
Aug 14 21:48:37.960: INFO: Got endpoints: latency-svc-ww6bs [767.407361ms]
Aug 14 21:48:37.991: INFO: Got endpoints: latency-svc-j9zcd [750.338318ms]
Aug 14 21:48:37.998: INFO: Created: latency-svc-jghzh
Aug 14 21:48:38.031: INFO: Created: latency-svc-cg4ph
Aug 14 21:48:38.043: INFO: Got endpoints: latency-svc-jhj84 [751.021277ms]
Aug 14 21:48:38.075: INFO: Created: latency-svc-lzq2x
Aug 14 21:48:38.096: INFO: Got endpoints: latency-svc-g5wrz [753.907086ms]
Aug 14 21:48:38.139: INFO: Created: latency-svc-gfkl6
Aug 14 21:48:38.146: INFO: Got endpoints: latency-svc-cvpb6 [753.134523ms]
Aug 14 21:48:38.175: INFO: Created: latency-svc-mwbnj
Aug 14 21:48:38.193: INFO: Got endpoints: latency-svc-vcdkd [749.600225ms]
Aug 14 21:48:38.224: INFO: Created: latency-svc-zgrh9
Aug 14 21:48:38.241: INFO: Got endpoints: latency-svc-q2mn7 [749.132568ms]
Aug 14 21:48:38.274: INFO: Created: latency-svc-nbhlc
Aug 14 21:48:38.292: INFO: Got endpoints: latency-svc-65s87 [750.276389ms]
Aug 14 21:48:38.329: INFO: Created: latency-svc-8szf8
Aug 14 21:48:38.342: INFO: Got endpoints: latency-svc-4x7hc [751.081329ms]
Aug 14 21:48:38.372: INFO: Created: latency-svc-hjhtz
Aug 14 21:48:38.391: INFO: Got endpoints: latency-svc-clmcp [748.737377ms]
Aug 14 21:48:38.434: INFO: Created: latency-svc-kgtg8
Aug 14 21:48:38.443: INFO: Got endpoints: latency-svc-cwtns [751.854353ms]
Aug 14 21:48:38.477: INFO: Created: latency-svc-x7gg6
Aug 14 21:48:38.491: INFO: Got endpoints: latency-svc-s2wxz [749.293256ms]
Aug 14 21:48:38.527: INFO: Created: latency-svc-t8vl5
Aug 14 21:48:38.546: INFO: Got endpoints: latency-svc-c64fg [753.806615ms]
Aug 14 21:48:38.578: INFO: Created: latency-svc-67tss
Aug 14 21:48:38.594: INFO: Got endpoints: latency-svc-pf64v [750.789846ms]
Aug 14 21:48:38.627: INFO: Created: latency-svc-v7nv7
Aug 14 21:48:38.641: INFO: Got endpoints: latency-svc-xc6lg [749.307547ms]
Aug 14 21:48:38.675: INFO: Created: latency-svc-xj2dp
Aug 14 21:48:38.693: INFO: Got endpoints: latency-svc-jghzh [733.542349ms]
Aug 14 21:48:38.730: INFO: Created: latency-svc-lhltp
Aug 14 21:48:38.741: INFO: Got endpoints: latency-svc-cg4ph [749.486687ms]
Aug 14 21:48:38.778: INFO: Created: latency-svc-zv7s7
Aug 14 21:48:38.791: INFO: Got endpoints: latency-svc-lzq2x [748.402651ms]
Aug 14 21:48:38.852: INFO: Created: latency-svc-4kb5r
Aug 14 21:48:38.853: INFO: Got endpoints: latency-svc-gfkl6 [757.260866ms]
Aug 14 21:48:38.890: INFO: Created: latency-svc-ppqm5
Aug 14 21:48:38.891: INFO: Got endpoints: latency-svc-mwbnj [745.023617ms]
Aug 14 21:48:38.930: INFO: Created: latency-svc-4vkhn
Aug 14 21:48:38.941: INFO: Got endpoints: latency-svc-zgrh9 [747.698129ms]
Aug 14 21:48:38.972: INFO: Created: latency-svc-nk4vq
Aug 14 21:48:38.994: INFO: Got endpoints: latency-svc-nbhlc [752.875074ms]
Aug 14 21:48:39.031: INFO: Created: latency-svc-lmksh
Aug 14 21:48:39.042: INFO: Got endpoints: latency-svc-8szf8 [750.420187ms]
Aug 14 21:48:39.073: INFO: Created: latency-svc-vmtgg
Aug 14 21:48:39.091: INFO: Got endpoints: latency-svc-hjhtz [748.85688ms]
Aug 14 21:48:39.124: INFO: Created: latency-svc-c27ws
Aug 14 21:48:39.142: INFO: Got endpoints: latency-svc-kgtg8 [751.597277ms]
Aug 14 21:48:39.178: INFO: Created: latency-svc-ltg4w
Aug 14 21:48:39.192: INFO: Got endpoints: latency-svc-x7gg6 [748.989783ms]
Aug 14 21:48:39.227: INFO: Created: latency-svc-mnsq2
Aug 14 21:48:39.241: INFO: Got endpoints: latency-svc-t8vl5 [749.953116ms]
Aug 14 21:48:39.281: INFO: Created: latency-svc-8r69n
Aug 14 21:48:39.295: INFO: Got endpoints: latency-svc-67tss [748.924987ms]
Aug 14 21:48:39.338: INFO: Created: latency-svc-jd57t
Aug 14 21:48:39.342: INFO: Got endpoints: latency-svc-v7nv7 [747.742533ms]
Aug 14 21:48:39.381: INFO: Created: latency-svc-l2q22
Aug 14 21:48:39.391: INFO: Got endpoints: latency-svc-xj2dp [750.647068ms]
Aug 14 21:48:39.432: INFO: Created: latency-svc-zzz9r
Aug 14 21:48:39.442: INFO: Got endpoints: latency-svc-lhltp [749.048482ms]
Aug 14 21:48:39.474: INFO: Created: latency-svc-k2gzb
Aug 14 21:48:39.491: INFO: Got endpoints: latency-svc-zv7s7 [749.836626ms]
Aug 14 21:48:39.530: INFO: Created: latency-svc-lmspq
Aug 14 21:48:39.541: INFO: Got endpoints: latency-svc-4kb5r [749.531205ms]
Aug 14 21:48:39.575: INFO: Created: latency-svc-n2rq2
Aug 14 21:48:39.591: INFO: Got endpoints: latency-svc-ppqm5 [738.382853ms]
Aug 14 21:48:39.642: INFO: Got endpoints: latency-svc-4vkhn [750.753469ms]
Aug 14 21:48:39.649: INFO: Created: latency-svc-rhmg5
Aug 14 21:48:39.677: INFO: Created: latency-svc-g5jvn
Aug 14 21:48:39.694: INFO: Got endpoints: latency-svc-nk4vq [753.07979ms]
Aug 14 21:48:39.732: INFO: Created: latency-svc-wzlv6
Aug 14 21:48:39.743: INFO: Got endpoints: latency-svc-lmksh [749.22537ms]
Aug 14 21:48:39.780: INFO: Created: latency-svc-8mx8f
Aug 14 21:48:39.791: INFO: Got endpoints: latency-svc-vmtgg [748.410634ms]
Aug 14 21:48:39.827: INFO: Created: latency-svc-96gq7
Aug 14 21:48:39.843: INFO: Got endpoints: latency-svc-c27ws [752.596418ms]
Aug 14 21:48:39.893: INFO: Created: latency-svc-5gcxt
Aug 14 21:48:39.893: INFO: Got endpoints: latency-svc-ltg4w [750.400575ms]
Aug 14 21:48:39.942: INFO: Got endpoints: latency-svc-mnsq2 [749.720428ms]
Aug 14 21:48:39.952: INFO: Created: latency-svc-nn5t5
Aug 14 21:48:39.978: INFO: Created: latency-svc-gtzrs
Aug 14 21:48:39.992: INFO: Got endpoints: latency-svc-8r69n [750.630815ms]
Aug 14 21:48:40.034: INFO: Created: latency-svc-ljldr
Aug 14 21:48:40.042: INFO: Got endpoints: latency-svc-jd57t [747.240728ms]
Aug 14 21:48:40.091: INFO: Got endpoints: latency-svc-l2q22 [749.595137ms]
Aug 14 21:48:40.092: INFO: Created: latency-svc-hzlkg
Aug 14 21:48:40.142: INFO: Got endpoints: latency-svc-zzz9r [751.002724ms]
Aug 14 21:48:40.193: INFO: Got endpoints: latency-svc-k2gzb [750.360417ms]
Aug 14 21:48:40.241: INFO: Got endpoints: latency-svc-lmspq [749.763015ms]
Aug 14 21:48:40.305: INFO: Got endpoints: latency-svc-n2rq2 [764.324478ms]
Aug 14 21:48:40.341: INFO: Got endpoints: latency-svc-rhmg5 [749.079986ms]
Aug 14 21:48:40.393: INFO: Got endpoints: latency-svc-g5jvn [751.370406ms]
Aug 14 21:48:40.441: INFO: Got endpoints: latency-svc-wzlv6 [747.529846ms]
Aug 14 21:48:40.492: INFO: Got endpoints: latency-svc-8mx8f [748.828769ms]
Aug 14 21:48:40.547: INFO: Got endpoints: latency-svc-96gq7 [755.607471ms]
Aug 14 21:48:40.594: INFO: Got endpoints: latency-svc-5gcxt [750.212162ms]
Aug 14 21:48:40.641: INFO: Got endpoints: latency-svc-nn5t5 [748.299587ms]
Aug 14 21:48:40.909: INFO: Got endpoints: latency-svc-ljldr [917.142912ms]
Aug 14 21:48:40.909: INFO: Got endpoints: latency-svc-gtzrs [967.771143ms]
Aug 14 21:48:40.991: INFO: Got endpoints: latency-svc-hzlkg [948.488243ms]
Aug 14 21:48:40.991: INFO: Latencies: [51.456337ms 61.611115ms 73.277983ms 94.504127ms 122.382337ms 122.618751ms 129.666324ms 158.851742ms 160.381977ms 187.053251ms 196.125477ms 216.726419ms 227.123226ms 234.927142ms 235.629034ms 236.539074ms 238.009202ms 239.500513ms 244.578ms 245.209296ms 245.546759ms 246.61389ms 252.233064ms 253.721632ms 254.308047ms 254.535824ms 256.08026ms 256.521138ms 260.947837ms 262.006916ms 263.730941ms 263.965588ms 264.141595ms 265.208942ms 265.794354ms 266.103626ms 268.191353ms 268.29746ms 269.594199ms 272.967812ms 275.482553ms 275.695637ms 279.87917ms 293.10647ms 296.766802ms 322.997049ms 332.660058ms 360.116742ms 407.242617ms 439.446309ms 467.900664ms 586.492146ms 595.673347ms 597.697424ms 615.243793ms 643.406127ms 643.617097ms 645.445169ms 673.343698ms 695.687891ms 696.106199ms 702.256124ms 708.313274ms 733.542349ms 738.382853ms 741.089949ms 742.753375ms 743.684993ms 744.24697ms 745.023617ms 745.748058ms 746.064462ms 746.06576ms 746.494522ms 746.495062ms 747.240728ms 747.241928ms 747.255854ms 747.529846ms 747.548434ms 747.59007ms 747.617212ms 747.640244ms 747.698129ms 747.732914ms 747.742533ms 747.965527ms 748.121899ms 748.299587ms 748.402651ms 748.410634ms 748.475601ms 748.528358ms 748.737377ms 748.7646ms 748.765991ms 748.779121ms 748.828769ms 748.85688ms 748.924987ms 748.989783ms 749.048482ms 749.049831ms 749.079986ms 749.132568ms 749.15541ms 749.22537ms 749.227373ms 749.259196ms 749.287683ms 749.293256ms 749.307547ms 749.414634ms 749.439849ms 749.486687ms 749.531205ms 749.595137ms 749.600225ms 749.610654ms 749.634096ms 749.708771ms 749.720428ms 749.725541ms 749.729551ms 749.763015ms 749.764653ms 749.775314ms 749.836626ms 749.868603ms 749.953116ms 749.983862ms 750.029259ms 750.077488ms 750.095313ms 750.212162ms 750.276389ms 750.289578ms 750.296958ms 750.338318ms 750.338713ms 750.360417ms 750.363405ms 750.400575ms 750.404532ms 750.418493ms 750.420187ms 750.487189ms 750.494158ms 750.523379ms 750.569849ms 750.58709ms 750.630815ms 750.647068ms 750.723214ms 750.745639ms 750.752095ms 750.753469ms 750.789846ms 750.828596ms 750.942549ms 750.990439ms 751.002724ms 751.021277ms 751.081329ms 751.112712ms 751.187291ms 751.283106ms 751.370406ms 751.397456ms 751.415221ms 751.574117ms 751.597277ms 751.636462ms 751.675678ms 751.854353ms 752.11192ms 752.168689ms 752.596418ms 752.606677ms 752.745637ms 752.875074ms 753.07979ms 753.134523ms 753.183799ms 753.66714ms 753.806615ms 753.907086ms 755.547742ms 755.607471ms 755.796583ms 757.260866ms 757.56093ms 764.324478ms 767.407361ms 794.186514ms 803.901523ms 853.532613ms 917.142912ms 948.488243ms 967.771143ms]
Aug 14 21:48:40.991: INFO: 50 %ile: 748.989783ms
Aug 14 21:48:40.991: INFO: 90 %ile: 752.875074ms
Aug 14 21:48:40.991: INFO: 99 %ile: 948.488243ms
Aug 14 21:48:40.991: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:48:40.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-8bvzz" for this suite.
Aug 14 21:49:05.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:49:05.240: INFO: namespace: e2e-tests-svc-latency-8bvzz, resource: bindings, ignored listing per whitelist
Aug 14 21:49:05.632: INFO: namespace e2e-tests-svc-latency-8bvzz deletion completed in 24.619657317s

• [SLOW TEST:37.211 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:49:05.633: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-s2w95
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-s2w95
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-s2w95
STEP: Deleting pre-stop pod
Aug 14 21:49:17.272: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:49:17.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-s2w95" for this suite.
Aug 14 21:49:57.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:49:57.976: INFO: namespace: e2e-tests-prestop-s2w95, resource: bindings, ignored listing per whitelist
Aug 14 21:49:57.991: INFO: namespace e2e-tests-prestop-s2w95 deletion completed in 40.663122925s

• [SLOW TEST:52.358 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:49:57.991: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wvmjh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Aug 14 21:49:58.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-wvmjh'
Aug 14 21:49:58.809: INFO: stderr: ""
Aug 14 21:49:58.809: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Aug 14 21:49:59.825: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:49:59.825: INFO: Found 0 / 1
Aug 14 21:50:00.828: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:50:00.828: INFO: Found 0 / 1
Aug 14 21:50:01.863: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:50:01.863: INFO: Found 1 / 1
Aug 14 21:50:01.863: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 21:50:01.879: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 21:50:01.879: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 14 21:50:01.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 logs redis-master-47628 redis-master --namespace=e2e-tests-kubectl-wvmjh'
Aug 14 21:50:02.036: INFO: stderr: ""
Aug 14 21:50:02.036: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 21:50:00.880 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 21:50:00.880 # Server started, Redis version 3.2.12\n1:M 14 Aug 21:50:00.880 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 21:50:00.880 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 14 21:50:02.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 log redis-master-47628 redis-master --namespace=e2e-tests-kubectl-wvmjh --tail=1'
Aug 14 21:50:02.261: INFO: stderr: ""
Aug 14 21:50:02.261: INFO: stdout: "1:M 14 Aug 21:50:00.880 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 14 21:50:02.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 log redis-master-47628 redis-master --namespace=e2e-tests-kubectl-wvmjh --limit-bytes=1'
Aug 14 21:50:02.417: INFO: stderr: ""
Aug 14 21:50:02.417: INFO: stdout: " "
STEP: exposing timestamps
Aug 14 21:50:02.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 log redis-master-47628 redis-master --namespace=e2e-tests-kubectl-wvmjh --tail=1 --timestamps'
Aug 14 21:50:02.584: INFO: stderr: ""
Aug 14 21:50:02.584: INFO: stdout: "2019-08-14T21:50:00.880906234Z 1:M 14 Aug 21:50:00.880 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 14 21:50:05.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 log redis-master-47628 redis-master --namespace=e2e-tests-kubectl-wvmjh --since=1s'
Aug 14 21:50:05.231: INFO: stderr: ""
Aug 14 21:50:05.231: INFO: stdout: ""
Aug 14 21:50:05.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 log redis-master-47628 redis-master --namespace=e2e-tests-kubectl-wvmjh --since=24h'
Aug 14 21:50:05.408: INFO: stderr: ""
Aug 14 21:50:05.409: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 21:50:00.880 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 21:50:00.880 # Server started, Redis version 3.2.12\n1:M 14 Aug 21:50:00.880 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 21:50:00.880 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Aug 14 21:50:05.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wvmjh'
Aug 14 21:50:05.707: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 21:50:05.707: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 14 21:50:05.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-wvmjh'
Aug 14 21:50:05.871: INFO: stderr: "No resources found.\n"
Aug 14 21:50:05.871: INFO: stdout: ""
Aug 14 21:50:05.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -l name=nginx --namespace=e2e-tests-kubectl-wvmjh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 21:50:06.019: INFO: stderr: ""
Aug 14 21:50:06.019: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:50:06.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wvmjh" for this suite.
Aug 14 21:50:30.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:50:30.749: INFO: namespace: e2e-tests-kubectl-wvmjh, resource: bindings, ignored listing per whitelist
Aug 14 21:50:30.839: INFO: namespace e2e-tests-kubectl-wvmjh deletion completed in 24.791645659s

• [SLOW TEST:32.848 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:50:30.840: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5sbdb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 14 21:50:31.316: INFO: Waiting up to 5m0s for pod "pod-89582332-bedd-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-5sbdb" to be "success or failure"
Aug 14 21:50:31.341: INFO: Pod "pod-89582332-bedd-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.570653ms
Aug 14 21:50:33.357: INFO: Pod "pod-89582332-bedd-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040100727s
STEP: Saw pod success
Aug 14 21:50:33.357: INFO: Pod "pod-89582332-bedd-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:50:33.373: INFO: Trying to get logs from node 10.209.12.141 pod pod-89582332-bedd-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 21:50:33.490: INFO: Waiting for pod pod-89582332-bedd-11e9-9404-ee44c4277148 to disappear
Aug 14 21:50:33.505: INFO: Pod pod-89582332-bedd-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:50:33.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5sbdb" for this suite.
Aug 14 21:50:39.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:50:39.826: INFO: namespace: e2e-tests-emptydir-5sbdb, resource: bindings, ignored listing per whitelist
Aug 14 21:50:40.353: INFO: namespace e2e-tests-emptydir-5sbdb deletion completed in 6.826530169s

• [SLOW TEST:9.513 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:50:40.353: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xrtsn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 21:50:44.929: INFO: Waiting up to 5m0s for pod "client-envvars-91780799-bedd-11e9-9404-ee44c4277148" in namespace "e2e-tests-pods-xrtsn" to be "success or failure"
Aug 14 21:50:44.952: INFO: Pod "client-envvars-91780799-bedd-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 23.136926ms
Aug 14 21:50:46.984: INFO: Pod "client-envvars-91780799-bedd-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055441228s
STEP: Saw pod success
Aug 14 21:50:46.984: INFO: Pod "client-envvars-91780799-bedd-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:50:47.005: INFO: Trying to get logs from node 10.73.228.4 pod client-envvars-91780799-bedd-11e9-9404-ee44c4277148 container env3cont: <nil>
STEP: delete the pod
Aug 14 21:50:47.085: INFO: Waiting for pod client-envvars-91780799-bedd-11e9-9404-ee44c4277148 to disappear
Aug 14 21:50:47.100: INFO: Pod client-envvars-91780799-bedd-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:50:47.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xrtsn" for this suite.
Aug 14 21:51:33.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:51:33.656: INFO: namespace: e2e-tests-pods-xrtsn, resource: bindings, ignored listing per whitelist
Aug 14 21:51:33.869: INFO: namespace e2e-tests-pods-xrtsn deletion completed in 46.745965776s

• [SLOW TEST:53.516 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:51:33.869: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xfxtr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-aeec6625-bedd-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 21:51:34.375: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aeeee4b1-bedd-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-xfxtr" to be "success or failure"
Aug 14 21:51:34.407: INFO: Pod "pod-projected-secrets-aeeee4b1-bedd-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 31.703391ms
Aug 14 21:51:36.424: INFO: Pod "pod-projected-secrets-aeeee4b1-bedd-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.048469451s
STEP: Saw pod success
Aug 14 21:51:36.424: INFO: Pod "pod-projected-secrets-aeeee4b1-bedd-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:51:36.440: INFO: Trying to get logs from node 10.73.228.2 pod pod-projected-secrets-aeeee4b1-bedd-11e9-9404-ee44c4277148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 21:51:36.526: INFO: Waiting for pod pod-projected-secrets-aeeee4b1-bedd-11e9-9404-ee44c4277148 to disappear
Aug 14 21:51:36.542: INFO: Pod pod-projected-secrets-aeeee4b1-bedd-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:51:36.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xfxtr" for this suite.
Aug 14 21:51:42.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:51:43.084: INFO: namespace: e2e-tests-projected-xfxtr, resource: bindings, ignored listing per whitelist
Aug 14 21:51:43.229: INFO: namespace e2e-tests-projected-xfxtr deletion completed in 6.615516117s

• [SLOW TEST:9.361 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:51:43.230: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-5nwkm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 21:51:43.666: INFO: Creating deployment "test-recreate-deployment"
Aug 14 21:51:43.684: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 14 21:51:43.714: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Aug 14 21:51:45.745: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 14 21:51:45.761: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416303, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416303, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416303, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701416303, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 21:51:47.776: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 14 21:51:47.891: INFO: Updating deployment test-recreate-deployment
Aug 14 21:51:47.892: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 14 21:51:48.010: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-5nwkm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5nwkm/deployments/test-recreate-deployment,UID:b47dd157-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:28294,Generation:2,CreationTimestamp:2019-08-14 21:51:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-14 21:51:47 +0000 UTC 2019-08-14 21:51:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-14 21:51:47 +0000 UTC 2019-08-14 21:51:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 14 21:51:48.024: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-5nwkm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5nwkm/replicasets/test-recreate-deployment-697fbf54bf,UID:b704521b-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:28293,Generation:1,CreationTimestamp:2019-08-14 21:51:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b47dd157-bedd-11e9-a2b3-62a1b681b4a5 0xc0021116d7 0xc0021116d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 21:51:48.024: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 14 21:51:48.024: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-5nwkm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5nwkm/replicasets/test-recreate-deployment-5dfdcc846d,UID:b482bdc3-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:28283,Generation:2,CreationTimestamp:2019-08-14 21:51:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b47dd157-bedd-11e9-a2b3-62a1b681b4a5 0xc002111617 0xc002111618}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 21:51:48.039: INFO: Pod "test-recreate-deployment-697fbf54bf-2grgk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-2grgk,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-5nwkm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5nwkm/pods/test-recreate-deployment-697fbf54bf-2grgk,UID:b7062374-bedd-11e9-a2b3-62a1b681b4a5,ResourceVersion:28295,Generation:0,CreationTimestamp:2019-08-14 21:51:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf b704521b-bedd-11e9-a2b3-62a1b681b4a5 0xc002111f47 0xc002111f48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pk5pw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pk5pw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pk5pw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002111fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002111fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:51:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:51:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:51:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 21:51:47 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:,StartTime:2019-08-14 21:51:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:51:48.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5nwkm" for this suite.
Aug 14 21:51:56.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:51:56.277: INFO: namespace: e2e-tests-deployment-5nwkm, resource: bindings, ignored listing per whitelist
Aug 14 21:51:56.825: INFO: namespace e2e-tests-deployment-5nwkm deletion completed in 8.763435663s

• [SLOW TEST:13.595 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:51:56.825: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-mvmpk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 21:51:57.303: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc99cacd-bedd-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-mvmpk" to be "success or failure"
Aug 14 21:51:57.321: INFO: Pod "downwardapi-volume-bc99cacd-bedd-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 17.748173ms
Aug 14 21:51:59.340: INFO: Pod "downwardapi-volume-bc99cacd-bedd-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036599791s
STEP: Saw pod success
Aug 14 21:51:59.340: INFO: Pod "downwardapi-volume-bc99cacd-bedd-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 21:51:59.358: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-bc99cacd-bedd-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 21:51:59.440: INFO: Waiting for pod downwardapi-volume-bc99cacd-bedd-11e9-9404-ee44c4277148 to disappear
Aug 14 21:51:59.460: INFO: Pod downwardapi-volume-bc99cacd-bedd-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:51:59.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mvmpk" for this suite.
Aug 14 21:52:07.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:52:07.654: INFO: namespace: e2e-tests-downward-api-mvmpk, resource: bindings, ignored listing per whitelist
Aug 14 21:52:08.174: INFO: namespace e2e-tests-downward-api-mvmpk deletion completed in 8.691479059s

• [SLOW TEST:11.349 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:52:08.174: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-8pxw2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8pxw2
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Aug 14 21:52:08.722: INFO: Found 0 stateful pods, waiting for 3
Aug 14 21:52:18.765: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:52:18.765: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:52:18.765: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 21:52:18.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8pxw2 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 21:52:19.394: INFO: stderr: ""
Aug 14 21:52:19.394: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 21:52:19.394: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 14 21:52:29.632: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 14 21:52:39.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8pxw2 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:52:40.301: INFO: stderr: ""
Aug 14 21:52:40.301: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 21:52:40.301: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 21:52:50.707: INFO: Waiting for StatefulSet e2e-tests-statefulset-8pxw2/ss2 to complete update
Aug 14 21:52:50.707: INFO: Waiting for Pod e2e-tests-statefulset-8pxw2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Aug 14 21:53:00.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8pxw2 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 21:53:01.254: INFO: stderr: ""
Aug 14 21:53:01.254: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 21:53:01.254: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 21:53:11.390: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 14 21:53:21.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8pxw2 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 21:53:22.096: INFO: stderr: ""
Aug 14 21:53:22.096: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 21:53:22.096: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 21:53:42.259: INFO: Waiting for StatefulSet e2e-tests-statefulset-8pxw2/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 14 21:53:52.394: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8pxw2
Aug 14 21:53:52.410: INFO: Scaling statefulset ss2 to 0
Aug 14 21:54:02.524: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 21:54:02.550: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:54:02.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8pxw2" for this suite.
Aug 14 21:54:12.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:54:13.473: INFO: namespace: e2e-tests-statefulset-8pxw2, resource: bindings, ignored listing per whitelist
Aug 14 21:54:13.473: INFO: namespace e2e-tests-statefulset-8pxw2 deletion completed in 10.794703986s

• [SLOW TEST:125.299 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:54:13.474: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2ltkb
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-0e13bd17-bede-11e9-9404-ee44c4277148
STEP: Creating configMap with name cm-test-opt-upd-0e13bd6a-bede-11e9-9404-ee44c4277148
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0e13bd17-bede-11e9-9404-ee44c4277148
STEP: Updating configmap cm-test-opt-upd-0e13bd6a-bede-11e9-9404-ee44c4277148
STEP: Creating configMap with name cm-test-opt-create-0e13bd8b-bede-11e9-9404-ee44c4277148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:55:38.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2ltkb" for this suite.
Aug 14 21:56:02.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:56:02.339: INFO: namespace: e2e-tests-configmap-2ltkb, resource: bindings, ignored listing per whitelist
Aug 14 21:56:02.887: INFO: namespace e2e-tests-configmap-2ltkb deletion completed in 24.670865875s

• [SLOW TEST:109.414 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:56:02.888: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-8zlzn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-8zlzn
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 21:56:03.400: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 21:56:25.937: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.126.98:8080/dial?request=hostName&protocol=http&host=172.30.187.228&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-8zlzn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 21:56:25.937: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 21:56:26.257: INFO: Waiting for endpoints: map[]
Aug 14 21:56:26.272: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.126.98:8080/dial?request=hostName&protocol=http&host=172.30.126.97&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-8zlzn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 21:56:26.272: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 21:56:26.594: INFO: Waiting for endpoints: map[]
Aug 14 21:56:26.613: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.126.98:8080/dial?request=hostName&protocol=http&host=172.30.171.158&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-8zlzn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 21:56:26.613: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 21:56:27.014: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:56:27.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-8zlzn" for this suite.
Aug 14 21:56:51.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:56:51.675: INFO: namespace: e2e-tests-pod-network-test-8zlzn, resource: bindings, ignored listing per whitelist
Aug 14 21:56:51.833: INFO: namespace e2e-tests-pod-network-test-8zlzn deletion completed in 24.797092012s

• [SLOW TEST:48.945 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:56:51.833: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-rcsbs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 14 21:56:58.495: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:56:58.510: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:00.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:00.528: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:02.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:02.591: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:04.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:04.545: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:06.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:06.525: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:08.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:08.527: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:10.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:10.525: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:12.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:12.529: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:14.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:14.532: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:16.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:16.546: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:18.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:18.546: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:20.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:20.526: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:22.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:22.859: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:24.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:24.525: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 21:57:26.510: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 21:57:26.528: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:57:26.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rcsbs" for this suite.
Aug 14 21:57:50.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:57:51.061: INFO: namespace: e2e-tests-container-lifecycle-hook-rcsbs, resource: bindings, ignored listing per whitelist
Aug 14 21:57:51.444: INFO: namespace e2e-tests-container-lifecycle-hook-rcsbs deletion completed in 24.693074982s

• [SLOW TEST:59.611 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:57:51.445: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-q82fr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 21:57:52.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-q82fr'
Aug 14 21:57:52.476: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 21:57:52.476: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Aug 14 21:57:52.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-q82fr'
Aug 14 21:57:52.643: INFO: stderr: ""
Aug 14 21:57:52.643: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:57:52.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q82fr" for this suite.
Aug 14 21:58:26.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:58:26.920: INFO: namespace: e2e-tests-kubectl-q82fr, resource: bindings, ignored listing per whitelist
Aug 14 21:58:27.364: INFO: namespace e2e-tests-kubectl-q82fr deletion completed in 34.698087065s

• [SLOW TEST:35.920 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:58:27.365: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-kgjbn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-kgjbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kgjbn to expose endpoints map[]
Aug 14 21:58:27.859: INFO: Get endpoints failed (13.706646ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Aug 14 21:58:28.872: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kgjbn exposes endpoints map[] (1.026655838s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-kgjbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kgjbn to expose endpoints map[pod1:[80]]
Aug 14 21:58:31.020: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kgjbn exposes endpoints map[pod1:[80]] (2.094564431s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-kgjbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kgjbn to expose endpoints map[pod1:[80] pod2:[80]]
Aug 14 21:58:33.311: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kgjbn exposes endpoints map[pod1:[80] pod2:[80]] (2.273671617s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-kgjbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kgjbn to expose endpoints map[pod2:[80]]
Aug 14 21:58:33.372: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kgjbn exposes endpoints map[pod2:[80]] (30.348026ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-kgjbn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kgjbn to expose endpoints map[]
Aug 14 21:58:33.412: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kgjbn exposes endpoints map[] (12.281046ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:58:33.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kgjbn" for this suite.
Aug 14 21:58:57.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:58:57.938: INFO: namespace: e2e-tests-services-kgjbn, resource: bindings, ignored listing per whitelist
Aug 14 21:58:58.320: INFO: namespace e2e-tests-services-kgjbn deletion completed in 24.793722494s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.956 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:58:58.322: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-8pz99
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 14 21:58:58.771: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 21:58:58.891: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 21:58:58.910: INFO: 
Logging pods the kubelet thinks is on node 10.209.12.141 before test
Aug 14 21:58:58.961: INFO: ibm-keepalived-watcher-f9cnm from kube-system started at 2019-08-14 19:54:13 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 21:58:58.961: INFO: kubernetes-dashboard-7996b848f4-d47hb from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 21:58:58.961: INFO: ibm-file-plugin-8dff78d64-jsnfs from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 14 21:58:58.961: INFO: coredns-6d59786485-9rxkc from kube-system started at 2019-08-14 20:12:54 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container coredns ready: true, restart count 0
Aug 14 21:58:58.961: INFO: ibm-master-proxy-static-10.209.12.141 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 21:58:58.961: INFO: calico-node-2v5wp from kube-system started at 2019-08-14 19:54:13 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 21:58:58.961: INFO: vpn-85755bfd8b-8jcnm from kube-system started at 2019-08-14 20:10:04 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container vpn ready: true, restart count 0
Aug 14 21:58:58.961: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-lgj9s from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 21:58:58.961: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 14 21:58:58.961: INFO: coredns-autoscaler-64f9c5b4df-hgdw6 from kube-system started at 2019-08-14 20:12:09 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container autoscaler ready: true, restart count 0
Aug 14 21:58:58.961: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-14 19:59:29 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 14 21:58:58.961: INFO: calico-kube-controllers-55fc77986d-mqkkz from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 21:58:58.961: INFO: metrics-server-6998dbf76b-9kf24 from kube-system started at 2019-08-14 19:54:48 +0000 UTC (2 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 21:58:58.961: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 14 21:58:58.961: INFO: ibm-kube-fluentd-86q5b from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 21:58:58.961: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-14 21:11:35 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 14 21:58:58.961: INFO: ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-zmddn from ibm-system started at 2019-08-14 19:55:02 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container ibm-cloud-provider-ip-169-62-248-21 ready: true, restart count 0
Aug 14 21:58:58.961: INFO: ibm-storage-watcher-7849677855-49bfj from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:58.961: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 14 21:58:58.961: INFO: 
Logging pods the kubelet thinks is on node 10.73.228.2 before test
Aug 14 21:58:59.016: INFO: calico-node-m4dp4 from kube-system started at 2019-08-14 19:55:45 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:59.016: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 21:58:59.016: INFO: coredns-6d59786485-zfbrn from kube-system started at 2019-08-14 20:12:54 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:59.016: INFO: 	Container coredns ready: true, restart count 0
Aug 14 21:58:59.016: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-st8k5 from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 21:58:59.016: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 21:58:59.016: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 14 21:58:59.016: INFO: ibm-master-proxy-static-10.73.228.2 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 21:58:59.016: INFO: public-crbla645md08dcbpval0ag-alb1-58664575d4-5958l from kube-system started at 2019-08-14 19:56:54 +0000 UTC (4 container statuses recorded)
Aug 14 21:58:59.016: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 21:58:59.016: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 21:58:59.016: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 21:58:59.016: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 21:58:59.016: INFO: ibm-keepalived-watcher-gkgbf from kube-system started at 2019-08-14 19:55:45 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:59.016: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 21:58:59.016: INFO: ibm-kube-fluentd-zwsgm from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:59.016: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 21:58:59.016: INFO: 
Logging pods the kubelet thinks is on node 10.73.228.4 before test
Aug 14 21:58:59.074: INFO: ibm-master-proxy-static-10.73.228.4 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 21:58:59.074: INFO: ibm-keepalived-watcher-g56pk from kube-system started at 2019-08-14 19:54:57 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:59.074: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 21:58:59.074: INFO: calico-node-4k6w8 from kube-system started at 2019-08-14 19:54:57 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:59.074: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 21:58:59.074: INFO: ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-mnhmd from ibm-system started at 2019-08-14 19:55:09 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:59.074: INFO: 	Container ibm-cloud-provider-ip-169-62-248-21 ready: true, restart count 0
Aug 14 21:58:59.074: INFO: public-crbla645md08dcbpval0ag-alb1-58664575d4-bsm75 from kube-system started at 2019-08-14 19:56:54 +0000 UTC (4 container statuses recorded)
Aug 14 21:58:59.074: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 21:58:59.074: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 21:58:59.074: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 21:58:59.074: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 21:58:59.074: INFO: ibm-kube-fluentd-zczvb from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 21:58:59.075: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 21:58:59.075: INFO: sonobuoy-e2e-job-0bc5e98b143e4e8a from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 21:58:59.075: INFO: 	Container e2e ready: true, restart count 0
Aug 14 21:58:59.075: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 21:58:59.075: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-rlc9b from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 21:58:59.075: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 21:58:59.075: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b947de9d-bede-11e9-9404-ee44c4277148 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b947de9d-bede-11e9-9404-ee44c4277148 off the node 10.73.228.2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b947de9d-bede-11e9-9404-ee44c4277148
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:59:03.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-8pz99" for this suite.
Aug 14 21:59:13.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 21:59:13.819: INFO: namespace: e2e-tests-sched-pred-8pz99, resource: bindings, ignored listing per whitelist
Aug 14 21:59:14.097: INFO: namespace e2e-tests-sched-pred-8pz99 deletion completed in 10.694628463s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:15.775 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 21:59:14.097: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-rr859
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 21:59:14.549: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 21:59:19.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rr859" for this suite.
Aug 14 22:00:03.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:00:03.860: INFO: namespace: e2e-tests-pods-rr859, resource: bindings, ignored listing per whitelist
Aug 14 22:00:04.060: INFO: namespace e2e-tests-pods-rr859 deletion completed in 44.993235368s

• [SLOW TEST:49.963 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:00:04.061: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-9v466
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:00:09.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-9v466" for this suite.
Aug 14 22:00:17.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:00:17.439: INFO: namespace: e2e-tests-emptydir-wrapper-9v466, resource: bindings, ignored listing per whitelist
Aug 14 22:00:17.968: INFO: namespace e2e-tests-emptydir-wrapper-9v466 deletion completed in 8.834119038s

• [SLOW TEST:13.907 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:00:17.968: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dgsm7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:00:18.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e749dbca-bede-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-dgsm7" to be "success or failure"
Aug 14 22:00:18.433: INFO: Pod "downwardapi-volume-e749dbca-bede-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.216371ms
Aug 14 22:00:20.538: INFO: Pod "downwardapi-volume-e749dbca-bede-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.119747896s
Aug 14 22:00:22.553: INFO: Pod "downwardapi-volume-e749dbca-bede-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.134629856s
STEP: Saw pod success
Aug 14 22:00:22.553: INFO: Pod "downwardapi-volume-e749dbca-bede-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:00:22.568: INFO: Trying to get logs from node 10.73.228.2 pod downwardapi-volume-e749dbca-bede-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:00:22.658: INFO: Waiting for pod downwardapi-volume-e749dbca-bede-11e9-9404-ee44c4277148 to disappear
Aug 14 22:00:22.675: INFO: Pod downwardapi-volume-e749dbca-bede-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:00:22.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dgsm7" for this suite.
Aug 14 22:00:30.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:00:31.055: INFO: namespace: e2e-tests-downward-api-dgsm7, resource: bindings, ignored listing per whitelist
Aug 14 22:00:31.616: INFO: namespace e2e-tests-downward-api-dgsm7 deletion completed in 8.917859762s

• [SLOW TEST:13.648 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:00:31.616: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-hbxp7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:00:32.043: INFO: Creating deployment "nginx-deployment"
Aug 14 22:00:32.061: INFO: Waiting for observed generation 1
Aug 14 22:00:34.092: INFO: Waiting for all required pods to come up
Aug 14 22:00:34.191: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 14 22:00:36.291: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 14 22:00:36.320: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 14 22:00:36.355: INFO: Updating deployment nginx-deployment
Aug 14 22:00:36.355: INFO: Waiting for observed generation 2
Aug 14 22:00:38.390: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 14 22:00:38.407: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 14 22:00:38.423: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 14 22:00:38.474: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 14 22:00:38.474: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 14 22:00:38.490: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 14 22:00:38.525: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 14 22:00:38.525: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 14 22:00:38.580: INFO: Updating deployment nginx-deployment
Aug 14 22:00:38.580: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 14 22:00:38.629: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 14 22:00:40.683: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 14 22:00:40.730: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hbxp7/deployments/nginx-deployment,UID:ef6d43d2-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30617,Generation:3,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:11,UnavailableReplicas:22,Conditions:[{Available False 2019-08-14 22:00:38 +0000 UTC 2019-08-14 22:00:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-14 22:00:40 +0000 UTC 2019-08-14 22:00:32 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:11,CollisionCount:nil,},}

Aug 14 22:00:40.767: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hbxp7/replicasets/nginx-deployment-65bbdb5f8,UID:f1feaec1-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30467,Generation:3,CreationTimestamp:2019-08-14 22:00:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment ef6d43d2-bede-11e9-a2b3-62a1b681b4a5 0xc000c9aff7 0xc000c9aff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 22:00:40.767: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 14 22:00:40.767: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-hbxp7/replicasets/nginx-deployment-555b55d965,UID:ef71ce37-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30614,Generation:3,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment ef6d43d2-bede-11e9-a2b3-62a1b681b4a5 0xc000c9af27 0xc000c9af28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:11,AvailableReplicas:11,Conditions:[],},}
Aug 14 22:00:40.846: INFO: Pod "nginx-deployment-555b55d965-4jtrz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4jtrz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-4jtrz,UID:ef81ef46-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30295,Generation:0,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc000c191b7 0xc000c191b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c19230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c19250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:172.30.187.237,StartTime:2019-08-14 22:00:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:34 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://c3b591cd13dfff3cb520f50d0538c1510454826524bed6d42121faab4824c85b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.846: INFO: Pod "nginx-deployment-555b55d965-5ss8f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5ss8f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-5ss8f,UID:ef7e909b-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30283,Generation:0,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc000c19317 0xc000c19318}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c193a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c193c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:172.30.126.102,StartTime:2019-08-14 22:00:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://b45d5b177d849be5f9bb4768351232cabcc5e7cfa56d3479399b57bbc476862e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.846: INFO: Pod "nginx-deployment-555b55d965-5x57s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5x57s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-5x57s,UID:ef81a9e7-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30269,Generation:0,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc000c194a0 0xc000c194a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c19520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c19540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:172.30.187.236,StartTime:2019-08-14 22:00:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://52d75e7703e4abab98ed61c474718929d5c1d7fa22d8339e16fddeec2b002243}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.847: INFO: Pod "nginx-deployment-555b55d965-6tvcl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6tvcl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-6tvcl,UID:f35848d2-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30481,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc000c19607 0xc000c19608}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c19680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c196b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.850: INFO: Pod "nginx-deployment-555b55d965-82lct" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-82lct,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-82lct,UID:ef825a11-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30272,Generation:0,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc000c197a0 0xc000c197a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c19810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c19830}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:172.30.171.166,StartTime:2019-08-14 22:00:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://453950e429d6889c9804f26d171ed9fd79e58ecf73d99d0a7a17e16ddf842f84}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.851: INFO: Pod "nginx-deployment-555b55d965-9n42g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9n42g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-9n42g,UID:ef7bb3ca-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30267,Generation:0,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc000c198f0 0xc000c198f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c199e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c19a00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:172.30.171.165,StartTime:2019-08-14 22:00:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ecb5a56f98f7d39a8a45b335897369fa55aa503b1bc5528f7250f9ee2409fee6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.852: INFO: Pod "nginx-deployment-555b55d965-f6wt4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f6wt4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-f6wt4,UID:f35b9965-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30499,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc000c19ac0 0xc000c19ac1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c19b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c19b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.853: INFO: Pod "nginx-deployment-555b55d965-fckbl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fckbl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-fckbl,UID:f3586f9a-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30488,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc000c19ed0 0xc000c19ed1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c19f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c19f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.853: INFO: Pod "nginx-deployment-555b55d965-gqd96" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gqd96,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-gqd96,UID:f358f522-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30471,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214c050 0xc00214c051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214c180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214c1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.854: INFO: Pod "nginx-deployment-555b55d965-hjwdn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hjwdn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-hjwdn,UID:f35b91d7-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30496,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214c257 0xc00214c258}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214c320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214c340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.854: INFO: Pod "nginx-deployment-555b55d965-lkr2m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lkr2m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-lkr2m,UID:f35431d6-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30613,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214c3f0 0xc00214c3f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214c460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214c480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:172.30.126.104,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:40 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://7e7fcc732b4386202fc3286f927a92b64e430ed8b5581fe0800bab5b5143ada3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.854: INFO: Pod "nginx-deployment-555b55d965-lm8nw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lm8nw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-lm8nw,UID:ef78814a-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30275,Generation:0,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214c5b0 0xc00214c5b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214c620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214c640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:172.30.187.235,StartTime:2019-08-14 22:00:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ec644430750a368e3b5892b50801ba99a130c674331d91aa7e8e1217c55d26b5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.855: INFO: Pod "nginx-deployment-555b55d965-npfws" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-npfws,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-npfws,UID:f35b402a-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30485,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214c707 0xc00214c708}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214c780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214c7a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.855: INFO: Pod "nginx-deployment-555b55d965-nxgns" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nxgns,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-nxgns,UID:ef7bbfb9-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30286,Generation:0,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214c850 0xc00214c851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214c8c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214c8e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:172.30.126.101,StartTime:2019-08-14 22:00:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f97c870cbfd23d0392ad7455f3a44fa48c809a38b00c7caf4780a71d195c98c0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.855: INFO: Pod "nginx-deployment-555b55d965-pffvt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pffvt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-pffvt,UID:f3563aab-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30470,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214c9a0 0xc00214c9a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214ca10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214ca40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.856: INFO: Pod "nginx-deployment-555b55d965-s6gfc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s6gfc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-s6gfc,UID:f35b9149-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30497,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214caf0 0xc00214caf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214cb60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214cb80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.856: INFO: Pod "nginx-deployment-555b55d965-tbqwk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tbqwk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-tbqwk,UID:f3586773-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30558,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214cc37 0xc00214cc38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214ccb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214ccd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:172.30.187.240,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:40 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://cee091c5893c4e2d1668ae4089195d14a23b4355fd20e59976e45bd75eb7e164}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.857: INFO: Pod "nginx-deployment-555b55d965-wqqjg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wqqjg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-wqqjg,UID:f35b623d-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30609,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214cd97 0xc00214cd98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214ce10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214ce30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:172.30.126.105,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:40 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://db84bc17524ebb5b3fef697729dce2ad40201327f97a60a22e74ba249b95e434}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.857: INFO: Pod "nginx-deployment-555b55d965-xp2hf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xp2hf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-xp2hf,UID:ef7e982a-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30264,Generation:0,CreationTimestamp:2019-08-14 22:00:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214cef0 0xc00214cef1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214cf60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214cf80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:32 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:172.30.171.164,StartTime:2019-08-14 22:00:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:00:33 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://049a890c2f3ed71887876f0681d0e6c535fbb4c493d6b4ae48db602192fbc2cc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.857: INFO: Pod "nginx-deployment-555b55d965-xrlsn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xrlsn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-555b55d965-xrlsn,UID:f356518d-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30473,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 ef71ce37-bede-11e9-a2b3-62a1b681b4a5 0xc00214d040 0xc00214d041}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214d0b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214d0d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.858: INFO: Pod "nginx-deployment-65bbdb5f8-cn6zk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cn6zk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-cn6zk,UID:f2030dea-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30382,Generation:0,CreationTimestamp:2019-08-14 22:00:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214d180 0xc00214d181}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214d200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214d220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:172.30.171.169,StartTime:2019-08-14 22:00:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.858: INFO: Pod "nginx-deployment-65bbdb5f8-fwnxk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fwnxk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-fwnxk,UID:f35b58e6-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30490,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214d300 0xc00214d301}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214d390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214d3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.858: INFO: Pod "nginx-deployment-65bbdb5f8-g4hm8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-g4hm8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-g4hm8,UID:f35e528c-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30498,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214d470 0xc00214d471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214d4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214d520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.858: INFO: Pod "nginx-deployment-65bbdb5f8-hstmh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hstmh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-hstmh,UID:f203097d-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30389,Generation:0,CreationTimestamp:2019-08-14 22:00:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214d5f0 0xc00214d5f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214d670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214d690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:172.30.187.239,StartTime:2019-08-14 22:00:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.859: INFO: Pod "nginx-deployment-65bbdb5f8-jgn6l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jgn6l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-jgn6l,UID:f35e4dea-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30493,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214d770 0xc00214d771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214d800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214d820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.861: INFO: Pod "nginx-deployment-65bbdb5f8-jwdkm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jwdkm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-jwdkm,UID:f3587561-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30483,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214d910 0xc00214d911}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214d9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214d9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.864: INFO: Pod "nginx-deployment-65bbdb5f8-lzrgn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lzrgn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-lzrgn,UID:f36058e0-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30502,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214da90 0xc00214da91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214db10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214db30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.864: INFO: Pod "nginx-deployment-65bbdb5f8-mq27k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mq27k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-mq27k,UID:f20fed0b-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30510,Generation:0,CreationTimestamp:2019-08-14 22:00:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214dc40 0xc00214dc41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214dcc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214dce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:172.30.171.170,StartTime:2019-08-14 22:00:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.864: INFO: Pod "nginx-deployment-65bbdb5f8-rv48l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rv48l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-rv48l,UID:f20d8acf-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30409,Generation:0,CreationTimestamp:2019-08-14 22:00:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214ddd0 0xc00214ddd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214de60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00214de80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:172.30.126.106,StartTime:2019-08-14 22:00:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.864: INFO: Pod "nginx-deployment-65bbdb5f8-t6lqh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-t6lqh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-t6lqh,UID:f35e56ba-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30501,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc00214df70 0xc00214df71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00214dff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d08010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.864: INFO: Pod "nginx-deployment-65bbdb5f8-tcgz6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-tcgz6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-tcgz6,UID:f35e5579-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30504,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc001d080f0 0xc001d080f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d08180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d08220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.864: INFO: Pod "nginx-deployment-65bbdb5f8-vtm2z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vtm2z,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-vtm2z,UID:f2006ac2-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30400,Generation:0,CreationTimestamp:2019-08-14 22:00:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc001d082e0 0xc001d082e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d08380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d083a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:36 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.4,PodIP:172.30.126.103,StartTime:2019-08-14 22:00:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:00:40.864: INFO: Pod "nginx-deployment-65bbdb5f8-z94z9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-z94z9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-hbxp7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-hbxp7/pods/nginx-deployment-65bbdb5f8-z94z9,UID:f35b8abe-bede-11e9-a2b3-62a1b681b4a5,ResourceVersion:30503,Generation:0,CreationTimestamp:2019-08-14 22:00:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 f1feaec1-bede-11e9-a2b3-62a1b681b4a5 0xc001d084d0 0xc001d084d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6k28l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6k28l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6k28l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d08560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d08580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:00:38 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:,StartTime:2019-08-14 22:00:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:00:40.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-hbxp7" for this suite.
Aug 14 22:00:52.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:00:53.861: INFO: namespace: e2e-tests-deployment-hbxp7, resource: bindings, ignored listing per whitelist
Aug 14 22:00:53.873: INFO: namespace e2e-tests-deployment-hbxp7 deletion completed in 12.986635883s

• [SLOW TEST:22.257 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:00:53.873: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dfbqp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Aug 14 22:00:54.344: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 14 22:00:54.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:00:54.577: INFO: stderr: ""
Aug 14 22:00:54.577: INFO: stdout: "service/redis-slave created\n"
Aug 14 22:00:54.578: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 14 22:00:54.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:00:54.819: INFO: stderr: ""
Aug 14 22:00:54.819: INFO: stdout: "service/redis-master created\n"
Aug 14 22:00:54.819: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 14 22:00:54.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:00:55.154: INFO: stderr: ""
Aug 14 22:00:55.154: INFO: stdout: "service/frontend created\n"
Aug 14 22:00:55.154: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 14 22:00:55.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:00:55.356: INFO: stderr: ""
Aug 14 22:00:55.356: INFO: stdout: "deployment.extensions/frontend created\n"
Aug 14 22:00:55.356: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 14 22:00:55.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:00:55.629: INFO: stderr: ""
Aug 14 22:00:55.629: INFO: stdout: "deployment.extensions/redis-master created\n"
Aug 14 22:00:55.630: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 14 22:00:55.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:00:55.943: INFO: stderr: ""
Aug 14 22:00:55.943: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Aug 14 22:00:55.943: INFO: Waiting for all frontend pods to be Running.
Aug 14 22:01:15.994: INFO: Waiting for frontend to serve content.
Aug 14 22:01:16.054: INFO: Trying to add a new entry to the guestbook.
Aug 14 22:01:16.095: INFO: Verifying that added entry can be retrieved.
Aug 14 22:01:16.140: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:01:21.181: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:01:26.241: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:01:31.285: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:01:36.349: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:01:41.397: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:01:46.458: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:01:51.504: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:01:56.570: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:02:01.624: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 14 22:02:06.694: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Aug 14 22:02:11.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:02:11.988: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:02:11.988: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:02:11.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:02:12.179: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:02:12.179: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:02:12.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:02:12.401: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:02:12.401: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:02:12.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:02:12.560: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:02:12.560: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:02:12.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:02:12.718: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:02:12.718: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 22:02:12.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dfbqp'
Aug 14 22:02:12.881: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:02:12.881: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:02:12.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dfbqp" for this suite.
Aug 14 22:02:56.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:02:57.022: INFO: namespace: e2e-tests-kubectl-dfbqp, resource: bindings, ignored listing per whitelist
Aug 14 22:02:57.517: INFO: namespace e2e-tests-kubectl-dfbqp deletion completed in 44.608486257s

• [SLOW TEST:123.644 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:02:57.517: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kphzq
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-4666cecf-bedf-11e9-9404-ee44c4277148
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-4666cecf-bedf-11e9-9404-ee44c4277148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:04:13.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kphzq" for this suite.
Aug 14 22:04:38.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:04:38.318: INFO: namespace: e2e-tests-projected-kphzq, resource: bindings, ignored listing per whitelist
Aug 14 22:04:38.629: INFO: namespace e2e-tests-projected-kphzq deletion completed in 24.637579824s

• [SLOW TEST:101.112 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:04:38.629: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-9cwtr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Aug 14 22:04:39.225: INFO: Waiting up to 5m0s for pod "client-containers-82bdc7b1-bedf-11e9-9404-ee44c4277148" in namespace "e2e-tests-containers-9cwtr" to be "success or failure"
Aug 14 22:04:39.240: INFO: Pod "client-containers-82bdc7b1-bedf-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.374771ms
Aug 14 22:04:41.255: INFO: Pod "client-containers-82bdc7b1-bedf-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030029483s
Aug 14 22:04:43.274: INFO: Pod "client-containers-82bdc7b1-bedf-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048505998s
STEP: Saw pod success
Aug 14 22:04:43.274: INFO: Pod "client-containers-82bdc7b1-bedf-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:04:43.297: INFO: Trying to get logs from node 10.209.12.141 pod client-containers-82bdc7b1-bedf-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:04:43.394: INFO: Waiting for pod client-containers-82bdc7b1-bedf-11e9-9404-ee44c4277148 to disappear
Aug 14 22:04:43.520: INFO: Pod client-containers-82bdc7b1-bedf-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:04:43.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9cwtr" for this suite.
Aug 14 22:04:51.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:04:52.170: INFO: namespace: e2e-tests-containers-9cwtr, resource: bindings, ignored listing per whitelist
Aug 14 22:04:52.199: INFO: namespace e2e-tests-containers-9cwtr deletion completed in 8.656513583s

• [SLOW TEST:13.570 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:04:52.201: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lsvh6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 22:04:52.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-lsvh6'
Aug 14 22:04:52.747: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 22:04:52.747: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 14 22:04:52.766: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Aug 14 22:04:52.791: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 14 22:04:52.809: INFO: scanned /root for discovery docs: <nil>
Aug 14 22:04:52.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-lsvh6'
Aug 14 22:05:09.011: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 14 22:05:09.011: INFO: stdout: "Created e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642\nScaling up e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 14 22:05:09.011: INFO: stdout: "Created e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642\nScaling up e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 14 22:05:09.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lsvh6'
Aug 14 22:05:09.455: INFO: stderr: ""
Aug 14 22:05:09.455: INFO: stdout: "e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642-qbj2g "
Aug 14 22:05:09.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642-qbj2g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lsvh6'
Aug 14 22:05:09.555: INFO: stderr: ""
Aug 14 22:05:09.555: INFO: stdout: "true"
Aug 14 22:05:09.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642-qbj2g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-lsvh6'
Aug 14 22:05:09.674: INFO: stderr: ""
Aug 14 22:05:09.674: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 14 22:05:09.674: INFO: e2e-test-nginx-rc-aff7509a06a7325a01246e4ec1687642-qbj2g is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Aug 14 22:05:09.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-lsvh6'
Aug 14 22:05:09.872: INFO: stderr: ""
Aug 14 22:05:09.872: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:05:09.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lsvh6" for this suite.
Aug 14 22:05:33.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:05:34.957: INFO: namespace: e2e-tests-kubectl-lsvh6, resource: bindings, ignored listing per whitelist
Aug 14 22:05:35.484: INFO: namespace e2e-tests-kubectl-lsvh6 deletion completed in 25.573518107s

• [SLOW TEST:43.283 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:05:35.484: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cwmwr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:05:35.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 version --client'
Aug 14 22:05:36.027: INFO: stderr: ""
Aug 14 22:05:36.027: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Aug 14 22:05:36.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-cwmwr'
Aug 14 22:05:36.328: INFO: stderr: ""
Aug 14 22:05:36.328: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 14 22:05:36.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-cwmwr'
Aug 14 22:05:36.584: INFO: stderr: ""
Aug 14 22:05:36.584: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 22:05:37.599: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:05:37.599: INFO: Found 0 / 1
Aug 14 22:05:38.601: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:05:38.601: INFO: Found 0 / 1
Aug 14 22:05:39.746: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:05:39.746: INFO: Found 1 / 1
Aug 14 22:05:39.746: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 22:05:39.760: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:05:39.760: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 22:05:39.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 describe pod redis-master-vbns5 --namespace=e2e-tests-kubectl-cwmwr'
Aug 14 22:05:39.922: INFO: stderr: ""
Aug 14 22:05:39.922: INFO: stdout: "Name:               redis-master-vbns5\nNamespace:          e2e-tests-kubectl-cwmwr\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.209.12.141/10.209.12.141\nStart Time:         Wed, 14 Aug 2019 22:05:36 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.187.250\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://0dc0941db1558cf3f9b8e6205c4dd8286414af445dde95c580946d6a0b5a8f71\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 14 Aug 2019 22:05:37 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-ht878 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-ht878:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-ht878\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  3s    default-scheduler       Successfully assigned e2e-tests-kubectl-cwmwr/redis-master-vbns5 to 10.209.12.141\n  Normal  Pulled     2s    kubelet, 10.209.12.141  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.209.12.141  Created container\n  Normal  Started    2s    kubelet, 10.209.12.141  Started container\n"
Aug 14 22:05:39.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 describe rc redis-master --namespace=e2e-tests-kubectl-cwmwr'
Aug 14 22:05:40.207: INFO: stderr: ""
Aug 14 22:05:40.207: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-cwmwr\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-vbns5\n"
Aug 14 22:05:40.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 describe service redis-master --namespace=e2e-tests-kubectl-cwmwr'
Aug 14 22:05:40.469: INFO: stderr: ""
Aug 14 22:05:40.469: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-cwmwr\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.176.34\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.187.250:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 14 22:05:40.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 describe node 10.209.12.141'
Aug 14 22:05:40.701: INFO: stderr: ""
Aug 14 22:05:40.701: INFO: stdout: "Name:               10.209.12.141\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-south\n                    failure-domain.beta.kubernetes.io/zone=dal13\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=bla645md08dcbpval0ag-0ebe6c1\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.13.8_1530\n                    kubernetes.io/hostname=10.209.12.141\n                    privateVLAN=2453379\n                    publicVLAN=2453375\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 14 Aug 2019 19:54:13 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 14 Aug 2019 22:05:35 +0000   Wed, 14 Aug 2019 19:54:13 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 14 Aug 2019 22:05:35 +0000   Wed, 14 Aug 2019 19:54:13 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 14 Aug 2019 22:05:35 +0000   Wed, 14 Aug 2019 19:54:13 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 14 Aug 2019 22:05:35 +0000   Wed, 14 Aug 2019 19:54:23 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.209.12.141\n  ExternalIP:  169.62.243.25\n  Hostname:    10.209.12.141\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419912Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627464Ki\n pods:               110\nSystem Info:\n Machine ID:                 8cb45e0843c044ce8eb737a074cfd943\n System UUID:                B8A49F9E-6097-E133-9C4C-5EF18F6E5E47\n Boot ID:                    bc751c20-bf3e-4ead-9a29-0d164685057b\n Kernel Version:             4.15.0-55-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.7\n Kubelet Version:            v1.13.8+IKS\n Kube-Proxy Version:         v1.13.8+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bla645md08dcbpval0ag/kube-bla645md08dcbpval0ag-kubee2epvgv-default-00000244\nNon-terminated Pods:         (17 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    test-k8s-e2e-pvg-master-verification                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         126m\n  e2e-tests-kubectl-cwmwr    redis-master-vbns5                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         54m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-bc35a38149844196-lgj9s    0 (0%)        0 (0%)      0 (0%)           0 (0%)         54m\n  ibm-system                 ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-zmddn       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         130m\n  kube-system                calico-kube-controllers-55fc77986d-mqkkz                   10m (0%)      0 (0%)      25Mi (0%)        3Gi (23%)      137m\n  kube-system                calico-node-2v5wp                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         131m\n  kube-system                coredns-6d59786485-9rxkc                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     112m\n  kube-system                coredns-autoscaler-64f9c5b4df-hgdw6                        20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         113m\n  kube-system                ibm-file-plugin-8dff78d64-jsnfs                            50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         135m\n  kube-system                ibm-keepalived-watcher-f9cnm                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         131m\n  kube-system                ibm-kube-fluentd-86q5b                                     25m (0%)      300m (7%)   150Mi (1%)       1600M (11%)    127m\n  kube-system                ibm-master-proxy-static-10.209.12.141                      25m (0%)      300m (7%)   32M (0%)         512M (3%)      131m\n  kube-system                ibm-storage-watcher-7849677855-49bfj                       50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         135m\n  kube-system                kubernetes-dashboard-7996b848f4-d47hb                      50m (1%)      0 (0%)      100Mi (0%)       0 (0%)         134m\n  kube-system                metrics-server-6998dbf76b-9kf24                            53m (1%)      148m (3%)   154Mi (1%)       404Mi (3%)     130m\n  kube-system                vpn-85755bfd8b-8jcnm                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         115m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                648m (16%)     1148m (29%)\n  memory             864786Ki (6%)  6031524Ki (44%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Aug 14 22:05:40.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 describe namespace e2e-tests-kubectl-cwmwr'
Aug 14 22:05:40.857: INFO: stderr: ""
Aug 14 22:05:40.857: INFO: stdout: "Name:         e2e-tests-kubectl-cwmwr\nLabels:       e2e-framework=kubectl\n              e2e-run=27c39ba6-bed8-11e9-9404-ee44c4277148\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:05:40.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cwmwr" for this suite.
Aug 14 22:06:04.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:05.288: INFO: namespace: e2e-tests-kubectl-cwmwr, resource: bindings, ignored listing per whitelist
Aug 14 22:06:05.662: INFO: namespace e2e-tests-kubectl-cwmwr deletion completed in 24.785058811s

• [SLOW TEST:30.178 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:06:05.662: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7874l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b68e8fac-bedf-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:06:06.175: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b690a4fe-bedf-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-7874l" to be "success or failure"
Aug 14 22:06:06.195: INFO: Pod "pod-projected-configmaps-b690a4fe-bedf-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.471039ms
Aug 14 22:06:08.210: INFO: Pod "pod-projected-configmaps-b690a4fe-bedf-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034652748s
Aug 14 22:06:10.230: INFO: Pod "pod-projected-configmaps-b690a4fe-bedf-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054606597s
STEP: Saw pod success
Aug 14 22:06:10.230: INFO: Pod "pod-projected-configmaps-b690a4fe-bedf-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:06:10.249: INFO: Trying to get logs from node 10.73.228.4 pod pod-projected-configmaps-b690a4fe-bedf-11e9-9404-ee44c4277148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:06:10.339: INFO: Waiting for pod pod-projected-configmaps-b690a4fe-bedf-11e9-9404-ee44c4277148 to disappear
Aug 14 22:06:10.370: INFO: Pod pod-projected-configmaps-b690a4fe-bedf-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:06:10.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7874l" for this suite.
Aug 14 22:06:16.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:16.673: INFO: namespace: e2e-tests-projected-7874l, resource: bindings, ignored listing per whitelist
Aug 14 22:06:17.198: INFO: namespace e2e-tests-projected-7874l deletion completed in 6.800846046s

• [SLOW TEST:11.536 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:06:17.199: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6mj2h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:06:17.725: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd7393e9-bedf-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-6mj2h" to be "success or failure"
Aug 14 22:06:17.741: INFO: Pod "downwardapi-volume-bd7393e9-bedf-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 15.314304ms
Aug 14 22:06:19.756: INFO: Pod "downwardapi-volume-bd7393e9-bedf-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030719297s
STEP: Saw pod success
Aug 14 22:06:19.756: INFO: Pod "downwardapi-volume-bd7393e9-bedf-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:06:19.771: INFO: Trying to get logs from node 10.73.228.4 pod downwardapi-volume-bd7393e9-bedf-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:06:19.858: INFO: Waiting for pod downwardapi-volume-bd7393e9-bedf-11e9-9404-ee44c4277148 to disappear
Aug 14 22:06:19.874: INFO: Pod downwardapi-volume-bd7393e9-bedf-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:06:19.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6mj2h" for this suite.
Aug 14 22:06:27.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:28.081: INFO: namespace: e2e-tests-projected-6mj2h, resource: bindings, ignored listing per whitelist
Aug 14 22:06:28.581: INFO: namespace e2e-tests-projected-6mj2h deletion completed in 8.685075726s

• [SLOW TEST:11.382 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:06:28.584: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kl4mb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 22:06:29.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-kl4mb'
Aug 14 22:06:29.231: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 22:06:29.231: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Aug 14 22:06:33.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-kl4mb'
Aug 14 22:06:33.507: INFO: stderr: ""
Aug 14 22:06:33.507: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:06:33.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kl4mb" for this suite.
Aug 14 22:06:41.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:41.818: INFO: namespace: e2e-tests-kubectl-kl4mb, resource: bindings, ignored listing per whitelist
Aug 14 22:06:42.488: INFO: namespace e2e-tests-kubectl-kl4mb deletion completed in 8.958612139s

• [SLOW TEST:13.904 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:06:42.491: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dbk74
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:06:42.944: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc7b888f-bedf-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-dbk74" to be "success or failure"
Aug 14 22:06:42.962: INFO: Pod "downwardapi-volume-cc7b888f-bedf-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.749207ms
Aug 14 22:06:44.978: INFO: Pod "downwardapi-volume-cc7b888f-bedf-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034822251s
Aug 14 22:06:47.006: INFO: Pod "downwardapi-volume-cc7b888f-bedf-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062325327s
STEP: Saw pod success
Aug 14 22:06:47.006: INFO: Pod "downwardapi-volume-cc7b888f-bedf-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:06:47.022: INFO: Trying to get logs from node 10.73.228.4 pod downwardapi-volume-cc7b888f-bedf-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:06:47.101: INFO: Waiting for pod downwardapi-volume-cc7b888f-bedf-11e9-9404-ee44c4277148 to disappear
Aug 14 22:06:47.116: INFO: Pod downwardapi-volume-cc7b888f-bedf-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:06:47.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dbk74" for this suite.
Aug 14 22:06:53.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:06:53.411: INFO: namespace: e2e-tests-downward-api-dbk74, resource: bindings, ignored listing per whitelist
Aug 14 22:06:53.848: INFO: namespace e2e-tests-downward-api-dbk74 deletion completed in 6.656361509s

• [SLOW TEST:11.357 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:06:53.848: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-9z5hg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0814 22:07:34.519542      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 22:07:34.519: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:07:34.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9z5hg" for this suite.
Aug 14 22:07:42.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:07:43.108: INFO: namespace: e2e-tests-gc-9z5hg, resource: bindings, ignored listing per whitelist
Aug 14 22:07:43.151: INFO: namespace e2e-tests-gc-9z5hg deletion completed in 8.615956232s

• [SLOW TEST:49.303 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:07:43.152: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-qfjll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 22:07:43.738: INFO: Number of nodes with available pods: 0
Aug 14 22:07:43.739: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:07:44.798: INFO: Number of nodes with available pods: 0
Aug 14 22:07:44.798: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:07:45.817: INFO: Number of nodes with available pods: 0
Aug 14 22:07:45.817: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:07:46.775: INFO: Number of nodes with available pods: 3
Aug 14 22:07:46.775: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 14 22:07:46.877: INFO: Number of nodes with available pods: 2
Aug 14 22:07:46.877: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:07:48.007: INFO: Number of nodes with available pods: 2
Aug 14 22:07:48.007: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:07:49.009: INFO: Number of nodes with available pods: 2
Aug 14 22:07:49.009: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:07:49.990: INFO: Number of nodes with available pods: 3
Aug 14 22:07:49.991: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qfjll, will wait for the garbage collector to delete the pods
Aug 14 22:07:50.128: INFO: Deleting DaemonSet.extensions daemon-set took: 39.465978ms
Aug 14 22:07:50.228: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.262104ms
Aug 14 22:08:31.864: INFO: Number of nodes with available pods: 0
Aug 14 22:08:31.864: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 22:08:31.883: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qfjll/daemonsets","resourceVersion":"32775"},"items":null}

Aug 14 22:08:31.900: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qfjll/pods","resourceVersion":"32775"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:08:31.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qfjll" for this suite.
Aug 14 22:08:40.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:08:40.128: INFO: namespace: e2e-tests-daemonsets-qfjll, resource: bindings, ignored listing per whitelist
Aug 14 22:08:40.614: INFO: namespace e2e-tests-daemonsets-qfjll deletion completed in 8.628356696s

• [SLOW TEST:57.463 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:08:40.615: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-lsbwx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Aug 14 22:08:41.077: INFO: Waiting up to 5m0s for pod "client-containers-12e55ac5-bee0-11e9-9404-ee44c4277148" in namespace "e2e-tests-containers-lsbwx" to be "success or failure"
Aug 14 22:08:41.114: INFO: Pod "client-containers-12e55ac5-bee0-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 36.627241ms
Aug 14 22:08:43.264: INFO: Pod "client-containers-12e55ac5-bee0-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.187273422s
STEP: Saw pod success
Aug 14 22:08:43.264: INFO: Pod "client-containers-12e55ac5-bee0-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:08:43.290: INFO: Trying to get logs from node 10.209.12.141 pod client-containers-12e55ac5-bee0-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:08:43.368: INFO: Waiting for pod client-containers-12e55ac5-bee0-11e9-9404-ee44c4277148 to disappear
Aug 14 22:08:43.382: INFO: Pod client-containers-12e55ac5-bee0-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:08:43.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-lsbwx" for this suite.
Aug 14 22:08:51.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:08:52.041: INFO: namespace: e2e-tests-containers-lsbwx, resource: bindings, ignored listing per whitelist
Aug 14 22:08:52.339: INFO: namespace e2e-tests-containers-lsbwx deletion completed in 8.929430258s

• [SLOW TEST:11.724 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:08:52.340: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rgtxq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:09:52.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rgtxq" for this suite.
Aug 14 22:10:16.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:10:17.541: INFO: namespace: e2e-tests-container-probe-rgtxq, resource: bindings, ignored listing per whitelist
Aug 14 22:10:17.555: INFO: namespace e2e-tests-container-probe-rgtxq deletion completed in 24.708002911s

• [SLOW TEST:85.215 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:10:17.555: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pwrqs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4cacee09-bee0-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:10:18.033: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4caf09b1-bee0-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-pwrqs" to be "success or failure"
Aug 14 22:10:18.059: INFO: Pod "pod-projected-secrets-4caf09b1-bee0-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 26.322907ms
Aug 14 22:10:20.074: INFO: Pod "pod-projected-secrets-4caf09b1-bee0-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040666459s
Aug 14 22:10:22.089: INFO: Pod "pod-projected-secrets-4caf09b1-bee0-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056452857s
STEP: Saw pod success
Aug 14 22:10:22.090: INFO: Pod "pod-projected-secrets-4caf09b1-bee0-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:10:22.105: INFO: Trying to get logs from node 10.73.228.4 pod pod-projected-secrets-4caf09b1-bee0-11e9-9404-ee44c4277148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:10:22.200: INFO: Waiting for pod pod-projected-secrets-4caf09b1-bee0-11e9-9404-ee44c4277148 to disappear
Aug 14 22:10:22.219: INFO: Pod pod-projected-secrets-4caf09b1-bee0-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:10:22.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pwrqs" for this suite.
Aug 14 22:10:28.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:10:28.640: INFO: namespace: e2e-tests-projected-pwrqs, resource: bindings, ignored listing per whitelist
Aug 14 22:10:29.120: INFO: namespace e2e-tests-projected-pwrqs deletion completed in 6.878020523s

• [SLOW TEST:11.565 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:10:29.121: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-x4tzg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:10:29.578: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 14 22:10:34.603: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 22:10:34.604: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 14 22:10:34.691: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-x4tzg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x4tzg/deployments/test-cleanup-deployment,UID:569844e9-bee0-11e9-a2b3-62a1b681b4a5,ResourceVersion:33150,Generation:1,CreationTimestamp:2019-08-14 22:10:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Aug 14 22:10:34.720: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-x4tzg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x4tzg/replicasets/test-cleanup-deployment-7dbbfcf846,UID:56a0f934-bee0-11e9-a2b3-62a1b681b4a5,ResourceVersion:33152,Generation:1,CreationTimestamp:2019-08-14 22:10:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 569844e9-bee0-11e9-a2b3-62a1b681b4a5 0xc000af4bf7 0xc000af4bf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 22:10:34.720: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug 14 22:10:34.721: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-x4tzg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x4tzg/replicasets/test-cleanup-controller,UID:53910722-bee0-11e9-a2b3-62a1b681b4a5,ResourceVersion:33151,Generation:1,CreationTimestamp:2019-08-14 22:10:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 569844e9-bee0-11e9-a2b3-62a1b681b4a5 0xc000af4ae7 0xc000af4ae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 22:10:34.735: INFO: Pod "test-cleanup-controller-6pnbv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-6pnbv,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-x4tzg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-x4tzg/pods/test-cleanup-controller-6pnbv,UID:5397b259-bee0-11e9-a2b3-62a1b681b4a5,ResourceVersion:33142,Generation:0,CreationTimestamp:2019-08-14 22:10:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 53910722-bee0-11e9-a2b3-62a1b681b4a5 0xc000af5697 0xc000af5698}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-c9nkj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-c9nkj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-c9nkj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000af5710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000af5740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:10:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:10:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:10:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:10:29 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:172.30.187.203,StartTime:2019-08-14 22:10:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 22:10:31 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://b6269270ac8b43035f95ae01bb03e61ea0c5da3201917a728b494498b0d44624}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 22:10:34.736: INFO: Pod "test-cleanup-deployment-7dbbfcf846-cnzq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-cnzq7,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-x4tzg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-x4tzg/pods/test-cleanup-deployment-7dbbfcf846-cnzq7,UID:56a473f8-bee0-11e9-a2b3-62a1b681b4a5,ResourceVersion:33156,Generation:0,CreationTimestamp:2019-08-14 22:10:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 56a0f934-bee0-11e9-a2b3-62a1b681b4a5 0xc000af58f7 0xc000af58f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-c9nkj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-c9nkj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-c9nkj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000af5980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000af59a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:10:34 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:10:34.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-x4tzg" for this suite.
Aug 14 22:10:42.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:10:43.071: INFO: namespace: e2e-tests-deployment-x4tzg, resource: bindings, ignored listing per whitelist
Aug 14 22:10:43.414: INFO: namespace e2e-tests-deployment-x4tzg deletion completed in 8.656269607s

• [SLOW TEST:14.293 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:10:43.415: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-n9jx6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Aug 14 22:10:43.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 cluster-info'
Aug 14 22:10:44.230: INFO: stderr: ""
Aug 14 22:10:44.230: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:10:44.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n9jx6" for this suite.
Aug 14 22:10:50.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:10:50.637: INFO: namespace: e2e-tests-kubectl-n9jx6, resource: bindings, ignored listing per whitelist
Aug 14 22:10:50.923: INFO: namespace e2e-tests-kubectl-n9jx6 deletion completed in 6.668174697s

• [SLOW TEST:7.508 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:10:50.925: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-nj7l7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-608d4b7d-bee0-11e9-9404-ee44c4277148
Aug 14 22:10:51.365: INFO: Pod name my-hostname-basic-608d4b7d-bee0-11e9-9404-ee44c4277148: Found 0 pods out of 1
Aug 14 22:10:56.380: INFO: Pod name my-hostname-basic-608d4b7d-bee0-11e9-9404-ee44c4277148: Found 1 pods out of 1
Aug 14 22:10:56.380: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-608d4b7d-bee0-11e9-9404-ee44c4277148" are running
Aug 14 22:10:56.395: INFO: Pod "my-hostname-basic-608d4b7d-bee0-11e9-9404-ee44c4277148-pqlwq" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:10:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:10:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:10:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 22:10:51 +0000 UTC Reason: Message:}])
Aug 14 22:10:56.395: INFO: Trying to dial the pod
Aug 14 22:11:01.486: INFO: Controller my-hostname-basic-608d4b7d-bee0-11e9-9404-ee44c4277148: Got expected result from replica 1 [my-hostname-basic-608d4b7d-bee0-11e9-9404-ee44c4277148-pqlwq]: "my-hostname-basic-608d4b7d-bee0-11e9-9404-ee44c4277148-pqlwq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:11:01.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-nj7l7" for this suite.
Aug 14 22:11:09.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:11:09.788: INFO: namespace: e2e-tests-replication-controller-nj7l7, resource: bindings, ignored listing per whitelist
Aug 14 22:11:10.257: INFO: namespace e2e-tests-replication-controller-nj7l7 deletion completed in 8.747228949s

• [SLOW TEST:19.332 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:11:10.257: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-g7cz8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:11:10.797: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Aug 14 22:11:10.916: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-g7cz8/daemonsets","resourceVersion":"33326"},"items":null}

Aug 14 22:11:10.991: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-g7cz8/pods","resourceVersion":"33326"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:11:11.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-g7cz8" for this suite.
Aug 14 22:11:17.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:11:17.732: INFO: namespace: e2e-tests-daemonsets-g7cz8, resource: bindings, ignored listing per whitelist
Aug 14 22:11:17.747: INFO: namespace e2e-tests-daemonsets-g7cz8 deletion completed in 6.666159881s

S [SKIPPING] [7.490 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Aug 14 22:11:10.797: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:11:17.748: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wkzd8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-708e4ab4-bee0-11e9-9404-ee44c4277148
STEP: Creating secret with name secret-projected-all-test-volume-708e4a91-bee0-11e9-9404-ee44c4277148
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 14 22:11:18.240: INFO: Waiting up to 5m0s for pod "projected-volume-708e4a47-bee0-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-wkzd8" to be "success or failure"
Aug 14 22:11:18.263: INFO: Pod "projected-volume-708e4a47-bee0-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 23.214558ms
Aug 14 22:11:20.278: INFO: Pod "projected-volume-708e4a47-bee0-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038092965s
Aug 14 22:11:22.295: INFO: Pod "projected-volume-708e4a47-bee0-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054651881s
STEP: Saw pod success
Aug 14 22:11:22.295: INFO: Pod "projected-volume-708e4a47-bee0-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:11:22.310: INFO: Trying to get logs from node 10.209.12.141 pod projected-volume-708e4a47-bee0-11e9-9404-ee44c4277148 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 14 22:11:22.411: INFO: Waiting for pod projected-volume-708e4a47-bee0-11e9-9404-ee44c4277148 to disappear
Aug 14 22:11:22.430: INFO: Pod projected-volume-708e4a47-bee0-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:11:22.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wkzd8" for this suite.
Aug 14 22:11:28.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:11:29.329: INFO: namespace: e2e-tests-projected-wkzd8, resource: bindings, ignored listing per whitelist
Aug 14 22:11:29.343: INFO: namespace e2e-tests-projected-wkzd8 deletion completed in 6.889967659s

• [SLOW TEST:11.596 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:11:29.344: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-68mls
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-68mls
Aug 14 22:11:33.840: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-68mls
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 22:11:33.856: INFO: Initial restart count of pod liveness-http is 0
Aug 14 22:11:54.110: INFO: Restart count of pod e2e-tests-container-probe-68mls/liveness-http is now 1 (20.253492931s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:11:54.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-68mls" for this suite.
Aug 14 22:12:02.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:12:02.459: INFO: namespace: e2e-tests-container-probe-68mls, resource: bindings, ignored listing per whitelist
Aug 14 22:12:02.980: INFO: namespace e2e-tests-container-probe-68mls deletion completed in 8.680456318s

• [SLOW TEST:33.636 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:12:02.981: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nxgls
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-vqx42
STEP: Creating secret with name secret-test-8b87b50b-bee0-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:12:03.716: INFO: Waiting up to 5m0s for pod "pod-secrets-8bad2167-bee0-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-nxgls" to be "success or failure"
Aug 14 22:12:03.733: INFO: Pod "pod-secrets-8bad2167-bee0-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 17.216336ms
Aug 14 22:12:05.750: INFO: Pod "pod-secrets-8bad2167-bee0-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03404774s
STEP: Saw pod success
Aug 14 22:12:05.750: INFO: Pod "pod-secrets-8bad2167-bee0-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:12:05.773: INFO: Trying to get logs from node 10.209.12.141 pod pod-secrets-8bad2167-bee0-11e9-9404-ee44c4277148 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:12:05.866: INFO: Waiting for pod pod-secrets-8bad2167-bee0-11e9-9404-ee44c4277148 to disappear
Aug 14 22:12:05.881: INFO: Pod pod-secrets-8bad2167-bee0-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:12:05.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nxgls" for this suite.
Aug 14 22:12:13.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:12:14.253: INFO: namespace: e2e-tests-secrets-nxgls, resource: bindings, ignored listing per whitelist
Aug 14 22:12:14.603: INFO: namespace e2e-tests-secrets-nxgls deletion completed in 8.692756664s
STEP: Destroying namespace "e2e-tests-secret-namespace-vqx42" for this suite.
Aug 14 22:12:20.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:12:21.482: INFO: namespace: e2e-tests-secret-namespace-vqx42, resource: bindings, ignored listing per whitelist
Aug 14 22:12:21.482: INFO: namespace e2e-tests-secret-namespace-vqx42 deletion completed in 6.878338778s

• [SLOW TEST:18.501 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:12:21.482: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-mm7mm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-96899eb3-bee0-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:12:21.951: INFO: Waiting up to 5m0s for pod "pod-configmaps-968bc32f-bee0-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-mm7mm" to be "success or failure"
Aug 14 22:12:21.964: INFO: Pod "pod-configmaps-968bc32f-bee0-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 13.586006ms
Aug 14 22:12:23.985: INFO: Pod "pod-configmaps-968bc32f-bee0-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034486478s
Aug 14 22:12:26.003: INFO: Pod "pod-configmaps-968bc32f-bee0-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052210499s
STEP: Saw pod success
Aug 14 22:12:26.003: INFO: Pod "pod-configmaps-968bc32f-bee0-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:12:26.017: INFO: Trying to get logs from node 10.73.228.2 pod pod-configmaps-968bc32f-bee0-11e9-9404-ee44c4277148 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:12:26.105: INFO: Waiting for pod pod-configmaps-968bc32f-bee0-11e9-9404-ee44c4277148 to disappear
Aug 14 22:12:26.123: INFO: Pod pod-configmaps-968bc32f-bee0-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:12:26.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mm7mm" for this suite.
Aug 14 22:12:32.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:12:32.890: INFO: namespace: e2e-tests-configmap-mm7mm, resource: bindings, ignored listing per whitelist
Aug 14 22:12:32.909: INFO: namespace e2e-tests-configmap-mm7mm deletion completed in 6.764154693s

• [SLOW TEST:11.428 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:12:32.910: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-8lmzw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8lmzw
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-8lmzw
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-8lmzw
Aug 14 22:12:33.505: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Aug 14 22:12:43.537: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 14 22:12:43.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8lmzw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:12:44.027: INFO: stderr: ""
Aug 14 22:12:44.028: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:12:44.028: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:12:44.043: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 14 22:12:54.083: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:12:54.083: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:12:54.162: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Aug 14 22:12:54.162: INFO: ss-0  10.73.228.4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:33 +0000 UTC  }]
Aug 14 22:12:54.163: INFO: 
Aug 14 22:12:54.163: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 14 22:12:55.179: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985300229s
Aug 14 22:12:56.197: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.968497806s
Aug 14 22:12:57.291: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.950810218s
Aug 14 22:12:58.307: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.85692999s
Aug 14 22:12:59.322: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.841185057s
Aug 14 22:13:00.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.826176995s
Aug 14 22:13:01.353: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.809929188s
Aug 14 22:13:02.370: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.794609318s
Aug 14 22:13:03.387: INFO: Verifying statefulset ss doesn't scale past 3 for another 778.143034ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-8lmzw
Aug 14 22:13:04.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8lmzw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:13:05.092: INFO: stderr: ""
Aug 14 22:13:05.092: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:13:05.092: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:13:05.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8lmzw ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:13:05.538: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug 14 22:13:05.538: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:13:05.538: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:13:05.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8lmzw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:13:06.079: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug 14 22:13:06.079: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:13:06.079: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:13:06.097: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:13:06.097: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:13:06.097: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 14 22:13:06.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8lmzw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:13:06.562: INFO: stderr: ""
Aug 14 22:13:06.562: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:13:06.562: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:13:06.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8lmzw ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:13:06.999: INFO: stderr: ""
Aug 14 22:13:06.999: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:13:06.999: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:13:07.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-8lmzw ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:13:07.497: INFO: stderr: ""
Aug 14 22:13:07.497: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:13:07.497: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:13:07.497: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:13:07.512: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 14 22:13:17.605: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:13:17.605: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:13:17.605: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:13:17.653: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:13:17.653: INFO: ss-0  10.73.228.4    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:33 +0000 UTC  }]
Aug 14 22:13:17.653: INFO: ss-1  10.209.12.141  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  }]
Aug 14 22:13:17.653: INFO: ss-2  10.73.228.2    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  }]
Aug 14 22:13:17.653: INFO: 
Aug 14 22:13:17.653: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 14 22:13:18.668: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:13:18.668: INFO: ss-0  10.73.228.4    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:33 +0000 UTC  }]
Aug 14 22:13:18.668: INFO: ss-1  10.209.12.141  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  }]
Aug 14 22:13:18.668: INFO: ss-2  10.73.228.2    Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  }]
Aug 14 22:13:18.668: INFO: 
Aug 14 22:13:18.668: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 14 22:13:19.687: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Aug 14 22:13:19.687: INFO: ss-0  10.73.228.4    Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:33 +0000 UTC  }]
Aug 14 22:13:19.687: INFO: ss-1  10.209.12.141  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:13:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:12:54 +0000 UTC  }]
Aug 14 22:13:19.687: INFO: 
Aug 14 22:13:19.687: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 14 22:13:20.703: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.952229282s
Aug 14 22:13:21.725: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.936108078s
Aug 14 22:13:22.741: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.913421654s
Aug 14 22:13:23.791: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.897528714s
Aug 14 22:13:24.806: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.848166025s
Aug 14 22:13:25.822: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.833090567s
Aug 14 22:13:26.837: INFO: Verifying statefulset ss doesn't scale past 0 for another 816.74307ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-8lmzw
Aug 14 22:13:27.870: INFO: Scaling statefulset ss to 0
Aug 14 22:13:27.956: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 14 22:13:27.973: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8lmzw
Aug 14 22:13:28.002: INFO: Scaling statefulset ss to 0
Aug 14 22:13:28.057: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:13:28.070: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:13:28.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8lmzw" for this suite.
Aug 14 22:13:36.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:13:36.974: INFO: namespace: e2e-tests-statefulset-8lmzw, resource: bindings, ignored listing per whitelist
Aug 14 22:13:37.133: INFO: namespace e2e-tests-statefulset-8lmzw deletion completed in 8.97457693s

• [SLOW TEST:64.223 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:13:37.133: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-4ct9z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4ct9z
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-4ct9z
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-4ct9z
Aug 14 22:13:37.675: INFO: Found 0 stateful pods, waiting for 1
Aug 14 22:13:47.719: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 14 22:13:47.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-4ct9z ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:13:48.242: INFO: stderr: ""
Aug 14 22:13:48.242: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:13:48.242: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:13:48.258: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 14 22:13:58.552: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:13:58.552: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:13:58.614: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998518s
Aug 14 22:13:59.631: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.984396819s
Aug 14 22:14:00.654: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.967235834s
Aug 14 22:14:01.671: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.944444825s
Aug 14 22:14:02.689: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.927922422s
Aug 14 22:14:03.708: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.909502729s
Aug 14 22:14:04.733: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.890119494s
Aug 14 22:14:05.751: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.865416381s
Aug 14 22:14:06.766: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.847818254s
Aug 14 22:14:07.783: INFO: Verifying statefulset ss doesn't scale past 1 for another 832.232897ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-4ct9z
Aug 14 22:14:08.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-4ct9z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:14:09.317: INFO: stderr: ""
Aug 14 22:14:09.317: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:14:09.317: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:14:09.335: INFO: Found 1 stateful pods, waiting for 3
Aug 14 22:14:19.370: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:14:19.370: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 22:14:19.370: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 14 22:14:19.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-4ct9z ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:14:19.841: INFO: stderr: ""
Aug 14 22:14:19.841: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:14:19.841: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:14:19.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-4ct9z ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:14:20.294: INFO: stderr: ""
Aug 14 22:14:20.294: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:14:20.294: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:14:20.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-4ct9z ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 22:14:20.749: INFO: stderr: ""
Aug 14 22:14:20.749: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 22:14:20.749: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 22:14:20.749: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:14:20.769: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 14 22:14:30.891: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:14:30.891: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:14:30.891: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 22:14:30.942: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998511s
Aug 14 22:14:31.958: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.983603776s
Aug 14 22:14:32.974: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.967602889s
Aug 14 22:14:33.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.951579106s
Aug 14 22:14:35.005: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936112101s
Aug 14 22:14:36.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.920131904s
Aug 14 22:14:37.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.904637793s
Aug 14 22:14:38.063: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.883518001s
Aug 14 22:14:39.079: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.86290378s
Aug 14 22:14:40.096: INFO: Verifying statefulset ss doesn't scale past 3 for another 846.523045ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-4ct9z
Aug 14 22:14:41.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-4ct9z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:14:41.657: INFO: stderr: ""
Aug 14 22:14:41.657: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:14:41.657: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:14:41.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-4ct9z ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:14:42.174: INFO: stderr: ""
Aug 14 22:14:42.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:14:42.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:14:42.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 exec --namespace=e2e-tests-statefulset-4ct9z ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 22:14:42.852: INFO: stderr: ""
Aug 14 22:14:42.852: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 22:14:42.852: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 22:14:42.852: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 14 22:15:12.937: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4ct9z
Aug 14 22:15:12.955: INFO: Scaling statefulset ss to 0
Aug 14 22:15:13.027: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 22:15:13.054: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:15:13.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4ct9z" for this suite.
Aug 14 22:15:21.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:21.494: INFO: namespace: e2e-tests-statefulset-4ct9z, resource: bindings, ignored listing per whitelist
Aug 14 22:15:21.802: INFO: namespace e2e-tests-statefulset-4ct9z deletion completed in 8.647499006s

• [SLOW TEST:104.669 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:15:21.802: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kvjgm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 14 22:15:22.262: INFO: Waiting up to 5m0s for pod "pod-02053ce0-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-kvjgm" to be "success or failure"
Aug 14 22:15:22.276: INFO: Pod "pod-02053ce0-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.293561ms
Aug 14 22:15:24.309: INFO: Pod "pod-02053ce0-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04759215s
STEP: Saw pod success
Aug 14 22:15:24.309: INFO: Pod "pod-02053ce0-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:15:24.324: INFO: Trying to get logs from node 10.73.228.4 pod pod-02053ce0-bee1-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:15:24.422: INFO: Waiting for pod pod-02053ce0-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:15:24.436: INFO: Pod pod-02053ce0-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:15:24.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kvjgm" for this suite.
Aug 14 22:15:32.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:32.986: INFO: namespace: e2e-tests-emptydir-kvjgm, resource: bindings, ignored listing per whitelist
Aug 14 22:15:33.241: INFO: namespace e2e-tests-emptydir-kvjgm deletion completed in 8.775914534s

• [SLOW TEST:11.438 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:15:33.241: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-q5987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-08dbca62-bee1-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:15:33.748: INFO: Waiting up to 5m0s for pod "pod-secrets-08de1383-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-q5987" to be "success or failure"
Aug 14 22:15:33.769: INFO: Pod "pod-secrets-08de1383-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 21.193019ms
Aug 14 22:15:35.902: INFO: Pod "pod-secrets-08de1383-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.154680355s
STEP: Saw pod success
Aug 14 22:15:35.902: INFO: Pod "pod-secrets-08de1383-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:15:35.918: INFO: Trying to get logs from node 10.73.228.2 pod pod-secrets-08de1383-bee1-11e9-9404-ee44c4277148 container secret-env-test: <nil>
STEP: delete the pod
Aug 14 22:15:36.006: INFO: Waiting for pod pod-secrets-08de1383-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:15:36.027: INFO: Pod pod-secrets-08de1383-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:15:36.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-q5987" for this suite.
Aug 14 22:15:44.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:44.287: INFO: namespace: e2e-tests-secrets-q5987, resource: bindings, ignored listing per whitelist
Aug 14 22:15:44.725: INFO: namespace e2e-tests-secrets-q5987 deletion completed in 8.674933499s

• [SLOW TEST:11.485 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:15:44.726: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dmgrg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 14 22:15:45.212: INFO: Waiting up to 5m0s for pod "downward-api-0fb349b9-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-dmgrg" to be "success or failure"
Aug 14 22:15:45.230: INFO: Pod "downward-api-0fb349b9-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.034452ms
Aug 14 22:15:47.263: INFO: Pod "downward-api-0fb349b9-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050223729s
STEP: Saw pod success
Aug 14 22:15:47.263: INFO: Pod "downward-api-0fb349b9-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:15:47.277: INFO: Trying to get logs from node 10.209.12.141 pod downward-api-0fb349b9-bee1-11e9-9404-ee44c4277148 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:15:47.358: INFO: Waiting for pod downward-api-0fb349b9-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:15:47.412: INFO: Pod downward-api-0fb349b9-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:15:47.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dmgrg" for this suite.
Aug 14 22:15:55.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:15:56.080: INFO: namespace: e2e-tests-downward-api-dmgrg, resource: bindings, ignored listing per whitelist
Aug 14 22:15:56.118: INFO: namespace e2e-tests-downward-api-dmgrg deletion completed in 8.685410757s

• [SLOW TEST:11.393 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:15:56.118: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-5b2fg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:15:56.542: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 14 22:15:56.576: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 14 22:16:01.618: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 22:16:01.619: INFO: Creating deployment "test-rolling-update-deployment"
Aug 14 22:16:01.637: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 14 22:16:01.680: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 14 22:16:03.709: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 14 22:16:03.804: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417761, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417761, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417761, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701417761, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 22:16:05.819: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 14 22:16:05.876: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-5b2fg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5b2fg/deployments/test-rolling-update-deployment,UID:197f444a-bee1-11e9-a2b3-62a1b681b4a5,ResourceVersion:34592,Generation:1,CreationTimestamp:2019-08-14 22:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-14 22:16:01 +0000 UTC 2019-08-14 22:16:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-14 22:16:04 +0000 UTC 2019-08-14 22:16:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 14 22:16:05.913: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-5b2fg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5b2fg/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:19876f89-bee1-11e9-a2b3-62a1b681b4a5,ResourceVersion:34583,Generation:1,CreationTimestamp:2019-08-14 22:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 197f444a-bee1-11e9-a2b3-62a1b681b4a5 0xc001a1ab47 0xc001a1ab48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 22:16:05.913: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 14 22:16:05.913: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-5b2fg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5b2fg/replicasets/test-rolling-update-controller,UID:167875dd-bee1-11e9-a2b3-62a1b681b4a5,ResourceVersion:34591,Generation:2,CreationTimestamp:2019-08-14 22:15:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 197f444a-bee1-11e9-a2b3-62a1b681b4a5 0xc001a1aa87 0xc001a1aa88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 22:16:05.934: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-wh77h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-wh77h,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-5b2fg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5b2fg/pods/test-rolling-update-deployment-68b55d7bc6-wh77h,UID:198a88cc-bee1-11e9-a2b3-62a1b681b4a5,ResourceVersion:34582,Generation:0,CreationTimestamp:2019-08-14 22:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 19876f89-bee1-11e9-a2b3-62a1b681b4a5 0xc000e2b587 0xc000e2b588}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m9gr4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m9gr4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-m9gr4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.209.12.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e2b760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e2b780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:16:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:16:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:16:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:16:01 +0000 UTC  }],Message:,Reason:,HostIP:10.209.12.141,PodIP:172.30.187.213,StartTime:2019-08-14 22:16:01 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-14 22:16:03 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://111de26b9ac460f67a92a55f3392be84be42fd4d9248a7bbe9011219da9e4b31}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:16:05.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5b2fg" for this suite.
Aug 14 22:16:14.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:16:14.269: INFO: namespace: e2e-tests-deployment-5b2fg, resource: bindings, ignored listing per whitelist
Aug 14 22:16:14.662: INFO: namespace e2e-tests-deployment-5b2fg deletion completed in 8.700998154s

• [SLOW TEST:18.544 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:16:14.665: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kdcqk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-2185572b-bee1-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:16:15.127: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-218796ae-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-kdcqk" to be "success or failure"
Aug 14 22:16:15.148: INFO: Pod "pod-projected-configmaps-218796ae-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 21.385285ms
Aug 14 22:16:17.165: INFO: Pod "pod-projected-configmaps-218796ae-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037522651s
STEP: Saw pod success
Aug 14 22:16:17.165: INFO: Pod "pod-projected-configmaps-218796ae-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:16:17.180: INFO: Trying to get logs from node 10.209.12.141 pod pod-projected-configmaps-218796ae-bee1-11e9-9404-ee44c4277148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:16:17.263: INFO: Waiting for pod pod-projected-configmaps-218796ae-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:16:17.277: INFO: Pod pod-projected-configmaps-218796ae-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:16:17.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kdcqk" for this suite.
Aug 14 22:16:25.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:16:25.775: INFO: namespace: e2e-tests-projected-kdcqk, resource: bindings, ignored listing per whitelist
Aug 14 22:16:25.962: INFO: namespace e2e-tests-projected-kdcqk deletion completed in 8.663002423s

• [SLOW TEST:11.297 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:16:25.962: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-m54x8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 14 22:16:26.522: INFO: Waiting up to 5m0s for pod "pod-28525e71-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-m54x8" to be "success or failure"
Aug 14 22:16:26.541: INFO: Pod "pod-28525e71-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.738483ms
Aug 14 22:16:28.556: INFO: Pod "pod-28525e71-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034372373s
STEP: Saw pod success
Aug 14 22:16:28.556: INFO: Pod "pod-28525e71-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:16:28.587: INFO: Trying to get logs from node 10.73.228.4 pod pod-28525e71-bee1-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:16:28.684: INFO: Waiting for pod pod-28525e71-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:16:28.698: INFO: Pod pod-28525e71-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:16:28.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m54x8" for this suite.
Aug 14 22:16:36.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:16:37.271: INFO: namespace: e2e-tests-emptydir-m54x8, resource: bindings, ignored listing per whitelist
Aug 14 22:16:37.371: INFO: namespace e2e-tests-emptydir-m54x8 deletion completed in 8.6518923s

• [SLOW TEST:11.409 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:16:37.373: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-qpn4j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 14 22:16:37.819: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 22:16:37.852: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 22:16:37.888: INFO: 
Logging pods the kubelet thinks is on node 10.209.12.141 before test
Aug 14 22:16:37.947: INFO: ibm-keepalived-watcher-f9cnm from kube-system started at 2019-08-14 19:54:13 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.947: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:16:37.948: INFO: kubernetes-dashboard-7996b848f4-d47hb from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 22:16:37.948: INFO: ibm-file-plugin-8dff78d64-jsnfs from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 14 22:16:37.948: INFO: coredns-6d59786485-9rxkc from kube-system started at 2019-08-14 20:12:54 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container coredns ready: true, restart count 0
Aug 14 22:16:37.948: INFO: ibm-master-proxy-static-10.209.12.141 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 22:16:37.948: INFO: calico-node-2v5wp from kube-system started at 2019-08-14 19:54:13 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:16:37.948: INFO: vpn-85755bfd8b-8jcnm from kube-system started at 2019-08-14 20:10:04 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container vpn ready: true, restart count 0
Aug 14 22:16:37.948: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-lgj9s from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:16:37.948: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 22:16:37.948: INFO: coredns-autoscaler-64f9c5b4df-hgdw6 from kube-system started at 2019-08-14 20:12:09 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container autoscaler ready: true, restart count 0
Aug 14 22:16:37.948: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-14 19:59:29 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 14 22:16:37.948: INFO: ibm-kube-fluentd-86q5b from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:16:37.948: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-14 21:11:35 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 14 22:16:37.948: INFO: ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-zmddn from ibm-system started at 2019-08-14 19:55:02 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container ibm-cloud-provider-ip-169-62-248-21 ready: true, restart count 0
Aug 14 22:16:37.948: INFO: ibm-storage-watcher-7849677855-49bfj from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 14 22:16:37.948: INFO: calico-kube-controllers-55fc77986d-mqkkz from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 22:16:37.948: INFO: metrics-server-6998dbf76b-9kf24 from kube-system started at 2019-08-14 19:54:48 +0000 UTC (2 container statuses recorded)
Aug 14 22:16:37.948: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 22:16:37.948: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 14 22:16:37.948: INFO: 
Logging pods the kubelet thinks is on node 10.73.228.2 before test
Aug 14 22:16:37.993: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-st8k5 from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 22:16:37.993: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:16:37.993: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 22:16:37.993: INFO: calico-node-m4dp4 from kube-system started at 2019-08-14 19:55:45 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.993: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:16:37.993: INFO: public-crbla645md08dcbpval0ag-alb1-58664575d4-5958l from kube-system started at 2019-08-14 19:56:54 +0000 UTC (4 container statuses recorded)
Aug 14 22:16:37.993: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 22:16:37.993: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 22:16:37.993: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 22:16:37.993: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 22:16:37.993: INFO: ibm-keepalived-watcher-gkgbf from kube-system started at 2019-08-14 19:55:45 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.993: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:16:37.993: INFO: ibm-kube-fluentd-zwsgm from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.993: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:16:37.993: INFO: ibm-master-proxy-static-10.73.228.2 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 22:16:37.993: INFO: coredns-6d59786485-zfbrn from kube-system started at 2019-08-14 20:12:54 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:37.993: INFO: 	Container coredns ready: true, restart count 0
Aug 14 22:16:37.993: INFO: 
Logging pods the kubelet thinks is on node 10.73.228.4 before test
Aug 14 22:16:38.036: INFO: ibm-master-proxy-static-10.73.228.4 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 22:16:38.036: INFO: ibm-keepalived-watcher-g56pk from kube-system started at 2019-08-14 19:54:57 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:38.036: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:16:38.036: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-rlc9b from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 22:16:38.036: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:16:38.036: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 22:16:38.036: INFO: calico-node-4k6w8 from kube-system started at 2019-08-14 19:54:57 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:38.036: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:16:38.036: INFO: ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-mnhmd from ibm-system started at 2019-08-14 19:55:09 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:38.036: INFO: 	Container ibm-cloud-provider-ip-169-62-248-21 ready: true, restart count 0
Aug 14 22:16:38.036: INFO: public-crbla645md08dcbpval0ag-alb1-58664575d4-bsm75 from kube-system started at 2019-08-14 19:56:54 +0000 UTC (4 container statuses recorded)
Aug 14 22:16:38.036: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 22:16:38.036: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 22:16:38.036: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 22:16:38.036: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 22:16:38.036: INFO: ibm-kube-fluentd-zczvb from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:16:38.036: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:16:38.036: INFO: sonobuoy-e2e-job-0bc5e98b143e4e8a from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 22:16:38.036: INFO: 	Container e2e ready: true, restart count 0
Aug 14 22:16:38.036: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.209.12.141
STEP: verifying the node has the label node 10.73.228.2
STEP: verifying the node has the label node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod sonobuoy-e2e-job-0bc5e98b143e4e8a requesting resource cpu=0m on Node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod sonobuoy-systemd-logs-daemon-set-bc35a38149844196-lgj9s requesting resource cpu=0m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod sonobuoy-systemd-logs-daemon-set-bc35a38149844196-rlc9b requesting resource cpu=0m on Node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod sonobuoy-systemd-logs-daemon-set-bc35a38149844196-st8k5 requesting resource cpu=0m on Node 10.73.228.2
Aug 14 22:16:38.211: INFO: Pod ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-mnhmd requesting resource cpu=5m on Node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-zmddn requesting resource cpu=5m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod calico-kube-controllers-55fc77986d-mqkkz requesting resource cpu=10m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod calico-node-2v5wp requesting resource cpu=250m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod calico-node-4k6w8 requesting resource cpu=250m on Node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod calico-node-m4dp4 requesting resource cpu=250m on Node 10.73.228.2
Aug 14 22:16:38.211: INFO: Pod coredns-6d59786485-9rxkc requesting resource cpu=100m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod coredns-6d59786485-zfbrn requesting resource cpu=100m on Node 10.73.228.2
Aug 14 22:16:38.211: INFO: Pod coredns-autoscaler-64f9c5b4df-hgdw6 requesting resource cpu=20m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod ibm-file-plugin-8dff78d64-jsnfs requesting resource cpu=50m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod ibm-keepalived-watcher-f9cnm requesting resource cpu=5m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod ibm-keepalived-watcher-g56pk requesting resource cpu=5m on Node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod ibm-keepalived-watcher-gkgbf requesting resource cpu=5m on Node 10.73.228.2
Aug 14 22:16:38.211: INFO: Pod ibm-kube-fluentd-86q5b requesting resource cpu=25m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod ibm-kube-fluentd-zczvb requesting resource cpu=25m on Node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod ibm-kube-fluentd-zwsgm requesting resource cpu=25m on Node 10.73.228.2
Aug 14 22:16:38.211: INFO: Pod ibm-master-proxy-static-10.209.12.141 requesting resource cpu=25m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod ibm-master-proxy-static-10.73.228.2 requesting resource cpu=25m on Node 10.73.228.2
Aug 14 22:16:38.211: INFO: Pod ibm-master-proxy-static-10.73.228.4 requesting resource cpu=25m on Node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod ibm-storage-watcher-7849677855-49bfj requesting resource cpu=50m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod kubernetes-dashboard-7996b848f4-d47hb requesting resource cpu=50m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod metrics-server-6998dbf76b-9kf24 requesting resource cpu=53m on Node 10.209.12.141
Aug 14 22:16:38.211: INFO: Pod public-crbla645md08dcbpval0ag-alb1-58664575d4-5958l requesting resource cpu=0m on Node 10.73.228.2
Aug 14 22:16:38.211: INFO: Pod public-crbla645md08dcbpval0ag-alb1-58664575d4-bsm75 requesting resource cpu=0m on Node 10.73.228.4
Aug 14 22:16:38.211: INFO: Pod vpn-85755bfd8b-8jcnm requesting resource cpu=5m on Node 10.209.12.141
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f4ea593-bee1-11e9-9404-ee44c4277148.15bae9e6de570bc2], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qpn4j/filler-pod-2f4ea593-bee1-11e9-9404-ee44c4277148 to 10.209.12.141]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f4ea593-bee1-11e9-9404-ee44c4277148.15bae9e7293d13ca], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f4ea593-bee1-11e9-9404-ee44c4277148.15bae9e72d46661b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f4ea593-bee1-11e9-9404-ee44c4277148.15bae9e73847e0a2], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f538ffd-bee1-11e9-9404-ee44c4277148.15bae9e6df90dc86], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qpn4j/filler-pod-2f538ffd-bee1-11e9-9404-ee44c4277148 to 10.73.228.2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f538ffd-bee1-11e9-9404-ee44c4277148.15bae9e71fc7f47d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f538ffd-bee1-11e9-9404-ee44c4277148.15bae9e723ad1c9e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f538ffd-bee1-11e9-9404-ee44c4277148.15bae9e72e80ded6], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f56539b-bee1-11e9-9404-ee44c4277148.15bae9e6e070df08], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qpn4j/filler-pod-2f56539b-bee1-11e9-9404-ee44c4277148 to 10.73.228.4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f56539b-bee1-11e9-9404-ee44c4277148.15bae9e72aa8cb22], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f56539b-bee1-11e9-9404-ee44c4277148.15bae9e72ebb920b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f56539b-bee1-11e9-9404-ee44c4277148.15bae9e739c8edf2], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bae9e768f21a63], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.209.12.141
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.73.228.2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.73.228.4
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:16:41.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qpn4j" for this suite.
Aug 14 22:16:49.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:16:50.132: INFO: namespace: e2e-tests-sched-pred-qpn4j, resource: bindings, ignored listing per whitelist
Aug 14 22:16:50.588: INFO: namespace e2e-tests-sched-pred-qpn4j deletion completed in 8.694481444s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:13.215 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:16:50.588: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-mpvp7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 14 22:16:51.059: INFO: Waiting up to 5m0s for pod "downward-api-36f2cd45-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-mpvp7" to be "success or failure"
Aug 14 22:16:51.072: INFO: Pod "downward-api-36f2cd45-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 13.078095ms
Aug 14 22:16:53.087: INFO: Pod "downward-api-36f2cd45-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028263055s
STEP: Saw pod success
Aug 14 22:16:53.087: INFO: Pod "downward-api-36f2cd45-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:16:53.113: INFO: Trying to get logs from node 10.73.228.2 pod downward-api-36f2cd45-bee1-11e9-9404-ee44c4277148 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:16:53.233: INFO: Waiting for pod downward-api-36f2cd45-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:16:53.252: INFO: Pod downward-api-36f2cd45-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:16:53.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mpvp7" for this suite.
Aug 14 22:16:59.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:16:59.435: INFO: namespace: e2e-tests-downward-api-mpvp7, resource: bindings, ignored listing per whitelist
Aug 14 22:16:59.990: INFO: namespace e2e-tests-downward-api-mpvp7 deletion completed in 6.708063935s

• [SLOW TEST:9.401 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:16:59.990: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fp6zd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3c8b9dd1-bee1-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:17:00.471: INFO: Waiting up to 5m0s for pod "pod-secrets-3c8dce11-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-fp6zd" to be "success or failure"
Aug 14 22:17:00.491: INFO: Pod "pod-secrets-3c8dce11-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.157609ms
Aug 14 22:17:02.607: INFO: Pod "pod-secrets-3c8dce11-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.135217831s
STEP: Saw pod success
Aug 14 22:17:02.607: INFO: Pod "pod-secrets-3c8dce11-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:17:02.626: INFO: Trying to get logs from node 10.209.12.141 pod pod-secrets-3c8dce11-bee1-11e9-9404-ee44c4277148 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:17:02.705: INFO: Waiting for pod pod-secrets-3c8dce11-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:17:02.721: INFO: Pod pod-secrets-3c8dce11-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:17:02.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fp6zd" for this suite.
Aug 14 22:17:10.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:17:11.489: INFO: namespace: e2e-tests-secrets-fp6zd, resource: bindings, ignored listing per whitelist
Aug 14 22:17:11.555: INFO: namespace e2e-tests-secrets-fp6zd deletion completed in 8.764430825s

• [SLOW TEST:11.565 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:17:11.556: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-xt5br
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:17:12.026: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:17:13.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-xt5br" for this suite.
Aug 14 22:17:19.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:17:19.849: INFO: namespace: e2e-tests-custom-resource-definition-xt5br, resource: bindings, ignored listing per whitelist
Aug 14 22:17:20.051: INFO: namespace e2e-tests-custom-resource-definition-xt5br deletion completed in 6.743968713s

• [SLOW TEST:8.495 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:17:20.053: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zs72j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 14 22:17:25.231: INFO: Successfully updated pod "labelsupdate488687bb-bee1-11e9-9404-ee44c4277148"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:17:27.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zs72j" for this suite.
Aug 14 22:17:51.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:17:52.022: INFO: namespace: e2e-tests-downward-api-zs72j, resource: bindings, ignored listing per whitelist
Aug 14 22:17:52.106: INFO: namespace e2e-tests-downward-api-zs72j deletion completed in 24.780586673s

• [SLOW TEST:32.054 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:17:52.107: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-xzkg9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:17:56.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-xzkg9" for this suite.
Aug 14 22:18:42.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:18:42.977: INFO: namespace: e2e-tests-kubelet-test-xzkg9, resource: bindings, ignored listing per whitelist
Aug 14 22:18:43.486: INFO: namespace e2e-tests-kubelet-test-xzkg9 deletion completed in 46.695075272s

• [SLOW TEST:51.379 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:18:43.487: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-67tb4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 14 22:18:48.618: INFO: Successfully updated pod "pod-update-activedeadlineseconds-7a3e3a99-bee1-11e9-9404-ee44c4277148"
Aug 14 22:18:48.618: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-7a3e3a99-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-pods-67tb4" to be "terminated due to deadline exceeded"
Aug 14 22:18:48.939: INFO: Pod "pod-update-activedeadlineseconds-7a3e3a99-bee1-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 320.182766ms
Aug 14 22:18:50.954: INFO: Pod "pod-update-activedeadlineseconds-7a3e3a99-bee1-11e9-9404-ee44c4277148": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.335123857s
Aug 14 22:18:50.954: INFO: Pod "pod-update-activedeadlineseconds-7a3e3a99-bee1-11e9-9404-ee44c4277148" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:18:50.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-67tb4" for this suite.
Aug 14 22:18:59.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:18:59.284: INFO: namespace: e2e-tests-pods-67tb4, resource: bindings, ignored listing per whitelist
Aug 14 22:18:59.657: INFO: namespace e2e-tests-pods-67tb4 deletion completed in 8.661996775s

• [SLOW TEST:16.171 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:18:59.660: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5bkn8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-83fc300f-bee1-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:19:00.331: INFO: Waiting up to 5m0s for pod "pod-secrets-83ff8a0e-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-5bkn8" to be "success or failure"
Aug 14 22:19:00.350: INFO: Pod "pod-secrets-83ff8a0e-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.162612ms
Aug 14 22:19:02.366: INFO: Pod "pod-secrets-83ff8a0e-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034746661s
Aug 14 22:19:04.382: INFO: Pod "pod-secrets-83ff8a0e-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051210021s
STEP: Saw pod success
Aug 14 22:19:04.382: INFO: Pod "pod-secrets-83ff8a0e-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:19:04.398: INFO: Trying to get logs from node 10.73.228.4 pod pod-secrets-83ff8a0e-bee1-11e9-9404-ee44c4277148 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:19:04.496: INFO: Waiting for pod pod-secrets-83ff8a0e-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:19:04.511: INFO: Pod pod-secrets-83ff8a0e-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:19:04.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5bkn8" for this suite.
Aug 14 22:19:10.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:19:10.742: INFO: namespace: e2e-tests-secrets-5bkn8, resource: bindings, ignored listing per whitelist
Aug 14 22:19:11.251: INFO: namespace e2e-tests-secrets-5bkn8 deletion completed in 6.715692036s

• [SLOW TEST:11.591 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:19:11.251: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-sgsf9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 14 22:19:15.884: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-8ada1cb3-bee1-11e9-9404-ee44c4277148,GenerateName:,Namespace:e2e-tests-events-sgsf9,SelfLink:/api/v1/namespaces/e2e-tests-events-sgsf9/pods/send-events-8ada1cb3-bee1-11e9-9404-ee44c4277148,UID:8adb9e06-bee1-11e9-a2b3-62a1b681b4a5,ResourceVersion:35378,Generation:0,CreationTimestamp:2019-08-14 22:19:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 798042198,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6xz5m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6xz5m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-6xz5m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.73.228.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001e2df50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001e2df70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:19:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:19:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:19:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 22:19:11 +0000 UTC  }],Message:,Reason:,HostIP:10.73.228.2,PodIP:172.30.171.131,StartTime:2019-08-14 22:19:11 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-14 22:19:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://bffb48146a82f064b1ba6de92b60f1f3a27701a6ee02eb1df5283954082bb1c2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 14 22:19:18.005: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 14 22:19:20.024: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:19:20.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-sgsf9" for this suite.
Aug 14 22:20:00.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:20:00.477: INFO: namespace: e2e-tests-events-sgsf9, resource: bindings, ignored listing per whitelist
Aug 14 22:20:00.876: INFO: namespace e2e-tests-events-sgsf9 deletion completed in 40.789952306s

• [SLOW TEST:49.625 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:20:00.877: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-qqslh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0814 22:20:11.724574      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 22:20:11.724: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:20:11.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qqslh" for this suite.
Aug 14 22:20:19.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:20:20.769: INFO: namespace: e2e-tests-gc-qqslh, resource: bindings, ignored listing per whitelist
Aug 14 22:20:20.820: INFO: namespace e2e-tests-gc-qqslh deletion completed in 9.075957071s

• [SLOW TEST:19.944 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:20:20.821: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-29h5z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:20:21.373: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b44a715b-bee1-11e9-a2b3-62a1b681b4a5", Controller:(*bool)(0xc0014bf8d2), BlockOwnerDeletion:(*bool)(0xc0014bf8d3)}}
Aug 14 22:20:21.391: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b445106e-bee1-11e9-a2b3-62a1b681b4a5", Controller:(*bool)(0xc000f43c76), BlockOwnerDeletion:(*bool)(0xc000f43c77)}}
Aug 14 22:20:21.413: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b447bfd3-bee1-11e9-a2b3-62a1b681b4a5", Controller:(*bool)(0xc00101d0be), BlockOwnerDeletion:(*bool)(0xc00101d0bf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:20:26.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-29h5z" for this suite.
Aug 14 22:20:34.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:20:34.829: INFO: namespace: e2e-tests-gc-29h5z, resource: bindings, ignored listing per whitelist
Aug 14 22:20:35.308: INFO: namespace e2e-tests-gc-29h5z deletion completed in 8.808257109s

• [SLOW TEST:14.488 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:20:35.310: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vxv2q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:20:36.126: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd19314d-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-vxv2q" to be "success or failure"
Aug 14 22:20:36.140: INFO: Pod "downwardapi-volume-bd19314d-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.329778ms
Aug 14 22:20:38.173: INFO: Pod "downwardapi-volume-bd19314d-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046921826s
STEP: Saw pod success
Aug 14 22:20:38.173: INFO: Pod "downwardapi-volume-bd19314d-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:20:38.187: INFO: Trying to get logs from node 10.73.228.4 pod downwardapi-volume-bd19314d-bee1-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:20:38.274: INFO: Waiting for pod downwardapi-volume-bd19314d-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:20:38.291: INFO: Pod downwardapi-volume-bd19314d-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:20:38.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vxv2q" for this suite.
Aug 14 22:20:46.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:20:46.697: INFO: namespace: e2e-tests-downward-api-vxv2q, resource: bindings, ignored listing per whitelist
Aug 14 22:20:47.075: INFO: namespace e2e-tests-downward-api-vxv2q deletion completed in 8.762254865s

• [SLOW TEST:11.765 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:20:47.076: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vx4vk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c3f78f57-bee1-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:20:47.664: INFO: Waiting up to 5m0s for pod "pod-configmaps-c3f9cb05-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-vx4vk" to be "success or failure"
Aug 14 22:20:47.685: INFO: Pod "pod-configmaps-c3f9cb05-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 20.727326ms
Aug 14 22:20:49.718: INFO: Pod "pod-configmaps-c3f9cb05-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053355414s
STEP: Saw pod success
Aug 14 22:20:49.718: INFO: Pod "pod-configmaps-c3f9cb05-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:20:49.736: INFO: Trying to get logs from node 10.209.12.141 pod pod-configmaps-c3f9cb05-bee1-11e9-9404-ee44c4277148 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:20:49.833: INFO: Waiting for pod pod-configmaps-c3f9cb05-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:20:49.854: INFO: Pod pod-configmaps-c3f9cb05-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:20:49.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vx4vk" for this suite.
Aug 14 22:20:55.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:20:56.696: INFO: namespace: e2e-tests-configmap-vx4vk, resource: bindings, ignored listing per whitelist
Aug 14 22:20:56.785: INFO: namespace e2e-tests-configmap-vx4vk deletion completed in 6.909915668s

• [SLOW TEST:9.710 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:20:56.787: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jmnjl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 14 22:20:57.231: INFO: Waiting up to 5m0s for pod "pod-c9ae1077-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-jmnjl" to be "success or failure"
Aug 14 22:20:57.253: INFO: Pod "pod-c9ae1077-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 21.095369ms
Aug 14 22:20:59.269: INFO: Pod "pod-c9ae1077-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037495539s
Aug 14 22:21:01.300: INFO: Pod "pod-c9ae1077-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068946181s
STEP: Saw pod success
Aug 14 22:21:01.301: INFO: Pod "pod-c9ae1077-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:21:01.316: INFO: Trying to get logs from node 10.209.12.141 pod pod-c9ae1077-bee1-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:21:01.400: INFO: Waiting for pod pod-c9ae1077-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:21:01.431: INFO: Pod pod-c9ae1077-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:21:01.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jmnjl" for this suite.
Aug 14 22:21:09.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:21:09.706: INFO: namespace: e2e-tests-emptydir-jmnjl, resource: bindings, ignored listing per whitelist
Aug 14 22:21:10.207: INFO: namespace e2e-tests-emptydir-jmnjl deletion completed in 8.754843993s

• [SLOW TEST:13.420 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:21:10.208: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jl8bz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:21:10.810: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1c559e2-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-jl8bz" to be "success or failure"
Aug 14 22:21:10.826: INFO: Pod "downwardapi-volume-d1c559e2-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 16.087142ms
Aug 14 22:21:12.863: INFO: Pod "downwardapi-volume-d1c559e2-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052621382s
Aug 14 22:21:14.880: INFO: Pod "downwardapi-volume-d1c559e2-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069221652s
STEP: Saw pod success
Aug 14 22:21:14.880: INFO: Pod "downwardapi-volume-d1c559e2-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:21:14.905: INFO: Trying to get logs from node 10.73.228.4 pod downwardapi-volume-d1c559e2-bee1-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:21:14.989: INFO: Waiting for pod downwardapi-volume-d1c559e2-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:21:15.005: INFO: Pod downwardapi-volume-d1c559e2-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:21:15.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jl8bz" for this suite.
Aug 14 22:21:21.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:21:21.363: INFO: namespace: e2e-tests-projected-jl8bz, resource: bindings, ignored listing per whitelist
Aug 14 22:21:21.722: INFO: namespace e2e-tests-projected-jl8bz deletion completed in 6.693731676s

• [SLOW TEST:11.514 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:21:21.723: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vhpn4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d89344a9-bee1-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:21:22.246: INFO: Waiting up to 5m0s for pod "pod-secrets-d8958876-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-vhpn4" to be "success or failure"
Aug 14 22:21:22.265: INFO: Pod "pod-secrets-d8958876-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.32993ms
Aug 14 22:21:24.307: INFO: Pod "pod-secrets-d8958876-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.060345729s
STEP: Saw pod success
Aug 14 22:21:24.307: INFO: Pod "pod-secrets-d8958876-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:21:24.326: INFO: Trying to get logs from node 10.73.228.2 pod pod-secrets-d8958876-bee1-11e9-9404-ee44c4277148 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:21:24.411: INFO: Waiting for pod pod-secrets-d8958876-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:21:24.432: INFO: Pod pod-secrets-d8958876-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:21:24.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vhpn4" for this suite.
Aug 14 22:21:32.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:21:33.090: INFO: namespace: e2e-tests-secrets-vhpn4, resource: bindings, ignored listing per whitelist
Aug 14 22:21:33.180: INFO: namespace e2e-tests-secrets-vhpn4 deletion completed in 8.725011099s

• [SLOW TEST:11.457 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:21:33.180: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-krhxm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug 14 22:21:33.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-krhxm'
Aug 14 22:21:34.255: INFO: stderr: ""
Aug 14 22:21:34.255: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 22:21:35.493: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:21:35.493: INFO: Found 0 / 1
Aug 14 22:21:36.271: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:21:36.272: INFO: Found 0 / 1
Aug 14 22:21:37.272: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:21:37.272: INFO: Found 1 / 1
Aug 14 22:21:37.272: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 14 22:21:37.286: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:21:37.286: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 22:21:37.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 patch pod redis-master-2tl4q --namespace=e2e-tests-kubectl-krhxm -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 14 22:21:37.454: INFO: stderr: ""
Aug 14 22:21:37.454: INFO: stdout: "pod/redis-master-2tl4q patched\n"
STEP: checking annotations
Aug 14 22:21:37.475: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:21:37.475: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:21:37.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-krhxm" for this suite.
Aug 14 22:22:01.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:22:02.187: INFO: namespace: e2e-tests-kubectl-krhxm, resource: bindings, ignored listing per whitelist
Aug 14 22:22:02.202: INFO: namespace e2e-tests-kubectl-krhxm deletion completed in 24.701732603s

• [SLOW TEST:29.022 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:22:02.204: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wmprh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 14 22:22:02.698: INFO: Waiting up to 5m0s for pod "pod-f0b326c9-bee1-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-wmprh" to be "success or failure"
Aug 14 22:22:02.791: INFO: Pod "pod-f0b326c9-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 92.323479ms
Aug 14 22:22:04.811: INFO: Pod "pod-f0b326c9-bee1-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.11239787s
Aug 14 22:22:06.826: INFO: Pod "pod-f0b326c9-bee1-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.128094234s
STEP: Saw pod success
Aug 14 22:22:06.827: INFO: Pod "pod-f0b326c9-bee1-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:22:06.843: INFO: Trying to get logs from node 10.73.228.4 pod pod-f0b326c9-bee1-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:22:06.925: INFO: Waiting for pod pod-f0b326c9-bee1-11e9-9404-ee44c4277148 to disappear
Aug 14 22:22:06.943: INFO: Pod pod-f0b326c9-bee1-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:22:06.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wmprh" for this suite.
Aug 14 22:22:15.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:22:15.139: INFO: namespace: e2e-tests-emptydir-wmprh, resource: bindings, ignored listing per whitelist
Aug 14 22:22:15.682: INFO: namespace e2e-tests-emptydir-wmprh deletion completed in 8.717979244s

• [SLOW TEST:13.479 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:22:15.684: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-6h9bg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:22:16.311: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 22:22:16.360: INFO: Number of nodes with available pods: 0
Aug 14 22:22:16.360: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:22:17.400: INFO: Number of nodes with available pods: 0
Aug 14 22:22:17.400: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:22:18.411: INFO: Number of nodes with available pods: 2
Aug 14 22:22:18.411: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:22:19.506: INFO: Number of nodes with available pods: 3
Aug 14 22:22:19.506: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 14 22:22:19.626: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:19.626: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:19.626: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:20.667: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:20.667: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:20.667: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:21.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:21.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:21.665: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:22.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:22.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:22.663: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:23.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:23.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:23.663: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:24.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:24.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:24.663: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:25.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:25.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:25.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:26.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:26.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:26.663: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:27.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:27.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:27.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:28.676: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:28.676: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:28.676: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:29.684: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:29.684: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:29.684: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:30.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:30.691: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:30.691: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:31.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:31.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:31.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:32.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:32.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:32.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:33.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:33.691: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:33.691: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:34.810: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:34.810: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:34.810: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:35.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:35.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:35.665: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:36.681: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:36.681: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:36.681: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:37.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:37.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:37.663: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:38.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:38.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:38.663: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:39.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:39.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:39.665: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:40.679: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:40.679: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:40.679: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:41.668: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:41.668: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:41.668: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:42.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:42.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:42.666: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:43.667: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:43.667: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:43.667: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:44.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:44.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:44.665: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:45.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:45.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:45.665: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:46.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:46.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:46.665: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:47.671: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:47.671: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:47.671: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:48.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:48.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:48.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:49.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:49.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:49.663: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:50.671: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:50.671: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:50.671: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:51.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:51.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:51.663: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:52.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:52.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:52.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:52.664: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:22:53.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:53.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:53.666: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:53.666: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:22:54.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:54.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:54.666: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:54.666: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:22:55.670: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:55.670: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:55.670: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:55.670: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:22:56.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:56.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:56.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:56.664: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:22:57.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:57.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:57.665: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:57.665: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:22:58.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:58.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:58.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:58.664: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:22:59.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:59.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:59.664: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:22:59.664: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:23:00.668: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:00.668: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:00.668: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:00.668: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:23:01.684: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:01.684: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:01.685: INFO: Wrong image for pod: daemon-set-pgt2c. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:01.685: INFO: Pod daemon-set-pgt2c is not available
Aug 14 22:23:02.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:02.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:02.663: INFO: Pod daemon-set-qfj2p is not available
Aug 14 22:23:03.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:03.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:03.665: INFO: Pod daemon-set-qfj2p is not available
Aug 14 22:23:04.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:04.691: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:05.667: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:05.667: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:06.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:06.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:07.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:07.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:08.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:08.664: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:09.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:09.665: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:10.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:10.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:11.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:11.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:12.682: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:12.682: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:13.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:13.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:14.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:14.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:15.690: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:15.691: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:16.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:16.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:17.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:17.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:18.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:18.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:19.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:19.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:20.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:20.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:21.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:21.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:22.702: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:22.702: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:23.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:23.691: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:24.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:24.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:25.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:25.691: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:26.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:26.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:27.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:27.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:28.676: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:28.676: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:29.714: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:29.714: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:30.667: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:30.668: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:31.668: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:31.668: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:32.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:32.663: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:33.690: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:33.690: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:34.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:34.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:35.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:35.666: INFO: Wrong image for pod: daemon-set-gjmf4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:35.666: INFO: Pod daemon-set-gjmf4 is not available
Aug 14 22:23:36.663: INFO: Pod daemon-set-4xfpk is not available
Aug 14 22:23:36.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:37.667: INFO: Pod daemon-set-4xfpk is not available
Aug 14 22:23:37.667: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:38.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:39.662: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:40.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:41.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:42.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:43.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:44.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:45.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:46.670: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:47.673: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:48.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:49.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:50.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:51.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:52.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:53.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:54.686: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:55.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:56.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:57.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:58.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:23:59.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:00.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:01.667: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:02.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:03.667: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:04.677: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:05.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:06.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:07.691: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:08.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:09.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:09.663: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:10.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:10.664: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:11.670: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:11.670: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:12.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:12.664: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:13.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:13.665: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:14.666: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:14.666: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:15.683: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:15.683: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:16.665: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:16.665: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:17.664: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:17.664: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:18.663: INFO: Wrong image for pod: daemon-set-6sdsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 14 22:24:18.664: INFO: Pod daemon-set-6sdsp is not available
Aug 14 22:24:19.667: INFO: Pod daemon-set-ljzrl is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 14 22:24:19.753: INFO: Number of nodes with available pods: 2
Aug 14 22:24:19.753: INFO: Node 10.73.228.2 is running more than one daemon pod
Aug 14 22:24:20.800: INFO: Number of nodes with available pods: 3
Aug 14 22:24:20.800: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-6h9bg, will wait for the garbage collector to delete the pods
Aug 14 22:24:21.085: INFO: Deleting DaemonSet.extensions daemon-set took: 34.084534ms
Aug 14 22:24:21.185: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.20043ms
Aug 14 22:24:31.815: INFO: Number of nodes with available pods: 0
Aug 14 22:24:31.815: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 22:24:31.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-6h9bg/daemonsets","resourceVersion":"36653"},"items":null}

Aug 14 22:24:31.844: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-6h9bg/pods","resourceVersion":"36653"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:24:31.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-6h9bg" for this suite.
Aug 14 22:24:39.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:24:40.588: INFO: namespace: e2e-tests-daemonsets-6h9bg, resource: bindings, ignored listing per whitelist
Aug 14 22:24:40.615: INFO: namespace e2e-tests-daemonsets-6h9bg deletion completed in 8.673431303s

• [SLOW TEST:144.932 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:24:40.616: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ncr7p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:24:41.098: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f1c239b-bee2-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-ncr7p" to be "success or failure"
Aug 14 22:24:41.121: INFO: Pod "downwardapi-volume-4f1c239b-bee2-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.290569ms
Aug 14 22:24:43.157: INFO: Pod "downwardapi-volume-4f1c239b-bee2-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05830578s
STEP: Saw pod success
Aug 14 22:24:43.157: INFO: Pod "downwardapi-volume-4f1c239b-bee2-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:24:43.172: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-4f1c239b-bee2-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:24:43.276: INFO: Waiting for pod downwardapi-volume-4f1c239b-bee2-11e9-9404-ee44c4277148 to disappear
Aug 14 22:24:43.296: INFO: Pod downwardapi-volume-4f1c239b-bee2-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:24:43.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ncr7p" for this suite.
Aug 14 22:24:51.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:24:51.775: INFO: namespace: e2e-tests-downward-api-ncr7p, resource: bindings, ignored listing per whitelist
Aug 14 22:24:52.225: INFO: namespace e2e-tests-downward-api-ncr7p deletion completed in 8.903746622s

• [SLOW TEST:11.609 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:24:52.225: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-hcr9p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Aug 14 22:24:53.336: INFO: created pod pod-service-account-defaultsa
Aug 14 22:24:53.336: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 14 22:24:53.361: INFO: created pod pod-service-account-mountsa
Aug 14 22:24:53.361: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 14 22:24:53.382: INFO: created pod pod-service-account-nomountsa
Aug 14 22:24:53.382: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 14 22:24:53.404: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 14 22:24:53.405: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 14 22:24:53.422: INFO: created pod pod-service-account-mountsa-mountspec
Aug 14 22:24:53.422: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 14 22:24:53.440: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 14 22:24:53.440: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 14 22:24:53.457: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 14 22:24:53.457: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 14 22:24:53.474: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 14 22:24:53.474: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 14 22:24:53.493: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 14 22:24:53.493: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:24:53.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-hcr9p" for this suite.
Aug 14 22:25:01.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:25:01.930: INFO: namespace: e2e-tests-svcaccounts-hcr9p, resource: bindings, ignored listing per whitelist
Aug 14 22:25:02.254: INFO: namespace e2e-tests-svcaccounts-hcr9p deletion completed in 8.734563727s

• [SLOW TEST:10.029 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:25:02.254: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-vfltq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 14 22:25:02.831: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-vfltq,SelfLink:/api/v1/namespaces/e2e-tests-watch-vfltq/configmaps/e2e-watch-test-watch-closed,UID:5c0f3330-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:36951,Generation:0,CreationTimestamp:2019-08-14 22:25:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 22:25:02.832: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-vfltq,SelfLink:/api/v1/namespaces/e2e-tests-watch-vfltq/configmaps/e2e-watch-test-watch-closed,UID:5c0f3330-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:36952,Generation:0,CreationTimestamp:2019-08-14 22:25:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 14 22:25:02.892: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-vfltq,SelfLink:/api/v1/namespaces/e2e-tests-watch-vfltq/configmaps/e2e-watch-test-watch-closed,UID:5c0f3330-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:36953,Generation:0,CreationTimestamp:2019-08-14 22:25:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 22:25:02.892: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-vfltq,SelfLink:/api/v1/namespaces/e2e-tests-watch-vfltq/configmaps/e2e-watch-test-watch-closed,UID:5c0f3330-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:36954,Generation:0,CreationTimestamp:2019-08-14 22:25:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:25:02.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-vfltq" for this suite.
Aug 14 22:25:08.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:25:09.128: INFO: namespace: e2e-tests-watch-vfltq, resource: bindings, ignored listing per whitelist
Aug 14 22:25:09.583: INFO: namespace e2e-tests-watch-vfltq deletion completed in 6.671234807s

• [SLOW TEST:7.329 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:25:09.583: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ljsdw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-605f3a33-bee2-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:25:10.072: INFO: Waiting up to 5m0s for pod "pod-configmaps-6061a5bc-bee2-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-ljsdw" to be "success or failure"
Aug 14 22:25:10.097: INFO: Pod "pod-configmaps-6061a5bc-bee2-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 24.933868ms
Aug 14 22:25:12.114: INFO: Pod "pod-configmaps-6061a5bc-bee2-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041745102s
Aug 14 22:25:14.130: INFO: Pod "pod-configmaps-6061a5bc-bee2-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057220465s
STEP: Saw pod success
Aug 14 22:25:14.130: INFO: Pod "pod-configmaps-6061a5bc-bee2-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:25:14.146: INFO: Trying to get logs from node 10.209.12.141 pod pod-configmaps-6061a5bc-bee2-11e9-9404-ee44c4277148 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:25:14.245: INFO: Waiting for pod pod-configmaps-6061a5bc-bee2-11e9-9404-ee44c4277148 to disappear
Aug 14 22:25:14.270: INFO: Pod pod-configmaps-6061a5bc-bee2-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:25:14.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ljsdw" for this suite.
Aug 14 22:25:20.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:25:20.842: INFO: namespace: e2e-tests-configmap-ljsdw, resource: bindings, ignored listing per whitelist
Aug 14 22:25:21.147: INFO: namespace e2e-tests-configmap-ljsdw deletion completed in 6.853794233s

• [SLOW TEST:11.564 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:25:21.147: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8hf7f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6744aed4-bee2-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:25:21.721: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6753533a-bee2-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-8hf7f" to be "success or failure"
Aug 14 22:25:21.742: INFO: Pod "pod-projected-configmaps-6753533a-bee2-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 21.825205ms
Aug 14 22:25:23.791: INFO: Pod "pod-projected-configmaps-6753533a-bee2-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.070082669s
STEP: Saw pod success
Aug 14 22:25:23.791: INFO: Pod "pod-projected-configmaps-6753533a-bee2-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:25:23.821: INFO: Trying to get logs from node 10.73.228.2 pod pod-projected-configmaps-6753533a-bee2-11e9-9404-ee44c4277148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:25:23.937: INFO: Waiting for pod pod-projected-configmaps-6753533a-bee2-11e9-9404-ee44c4277148 to disappear
Aug 14 22:25:23.953: INFO: Pod pod-projected-configmaps-6753533a-bee2-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:25:23.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8hf7f" for this suite.
Aug 14 22:25:32.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:25:32.415: INFO: namespace: e2e-tests-projected-8hf7f, resource: bindings, ignored listing per whitelist
Aug 14 22:25:32.652: INFO: namespace e2e-tests-projected-8hf7f deletion completed in 8.666185164s

• [SLOW TEST:11.505 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:25:32.653: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vgrkf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 14 22:25:35.891: INFO: Successfully updated pod "annotationupdate6e2f1886-bee2-11e9-9404-ee44c4277148"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:25:40.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vgrkf" for this suite.
Aug 14 22:26:04.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:26:04.832: INFO: namespace: e2e-tests-downward-api-vgrkf, resource: bindings, ignored listing per whitelist
Aug 14 22:26:04.885: INFO: namespace e2e-tests-downward-api-vgrkf deletion completed in 24.793150198s

• [SLOW TEST:32.232 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:26:04.885: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-gl6bc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 14 22:26:05.343: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 22:26:05.379: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 22:26:05.393: INFO: 
Logging pods the kubelet thinks is on node 10.209.12.141 before test
Aug 14 22:26:05.438: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-lgj9s from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 22:26:05.438: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:26:05.439: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 22:26:05.439: INFO: ibm-master-proxy-static-10.209.12.141 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 22:26:05.439: INFO: calico-node-2v5wp from kube-system started at 2019-08-14 19:54:13 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:26:05.439: INFO: vpn-85755bfd8b-8jcnm from kube-system started at 2019-08-14 20:10:04 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container vpn ready: true, restart count 0
Aug 14 22:26:05.439: INFO: coredns-autoscaler-64f9c5b4df-hgdw6 from kube-system started at 2019-08-14 20:12:09 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container autoscaler ready: true, restart count 0
Aug 14 22:26:05.439: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-08-14 19:59:29 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Aug 14 22:26:05.439: INFO: calico-kube-controllers-55fc77986d-mqkkz from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 22:26:05.439: INFO: metrics-server-6998dbf76b-9kf24 from kube-system started at 2019-08-14 19:54:48 +0000 UTC (2 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 22:26:05.439: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Aug 14 22:26:05.439: INFO: ibm-kube-fluentd-86q5b from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:26:05.439: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-14 21:11:35 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 14 22:26:05.439: INFO: ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-zmddn from ibm-system started at 2019-08-14 19:55:02 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container ibm-cloud-provider-ip-169-62-248-21 ready: true, restart count 0
Aug 14 22:26:05.439: INFO: ibm-storage-watcher-7849677855-49bfj from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Aug 14 22:26:05.439: INFO: coredns-6d59786485-9rxkc from kube-system started at 2019-08-14 20:12:54 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container coredns ready: true, restart count 0
Aug 14 22:26:05.439: INFO: ibm-keepalived-watcher-f9cnm from kube-system started at 2019-08-14 19:54:13 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:26:05.439: INFO: kubernetes-dashboard-7996b848f4-d47hb from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 22:26:05.439: INFO: ibm-file-plugin-8dff78d64-jsnfs from kube-system started at 2019-08-14 19:54:23 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.439: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Aug 14 22:26:05.439: INFO: 
Logging pods the kubelet thinks is on node 10.73.228.2 before test
Aug 14 22:26:05.488: INFO: ibm-master-proxy-static-10.73.228.2 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 22:26:05.488: INFO: public-crbla645md08dcbpval0ag-alb1-58664575d4-5958l from kube-system started at 2019-08-14 19:56:54 +0000 UTC (4 container statuses recorded)
Aug 14 22:26:05.488: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 22:26:05.488: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 22:26:05.488: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 22:26:05.488: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 22:26:05.488: INFO: ibm-keepalived-watcher-gkgbf from kube-system started at 2019-08-14 19:55:45 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.488: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:26:05.488: INFO: ibm-kube-fluentd-zwsgm from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.488: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:26:05.488: INFO: coredns-6d59786485-zfbrn from kube-system started at 2019-08-14 20:12:54 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.488: INFO: 	Container coredns ready: true, restart count 0
Aug 14 22:26:05.488: INFO: calico-node-m4dp4 from kube-system started at 2019-08-14 19:55:45 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.488: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:26:05.488: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-st8k5 from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 22:26:05.489: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:26:05.489: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 14 22:26:05.489: INFO: 
Logging pods the kubelet thinks is on node 10.73.228.4 before test
Aug 14 22:26:05.552: INFO: ibm-master-proxy-static-10.73.228.4 from kube-system started at <nil> (0 container statuses recorded)
Aug 14 22:26:05.552: INFO: ibm-keepalived-watcher-g56pk from kube-system started at 2019-08-14 19:54:57 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.552: INFO: 	Container keepalived-watcher ready: true, restart count 0
Aug 14 22:26:05.552: INFO: calico-node-4k6w8 from kube-system started at 2019-08-14 19:54:57 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.552: INFO: 	Container calico-node ready: true, restart count 0
Aug 14 22:26:05.552: INFO: ibm-cloud-provider-ip-169-62-248-21-796d9d4bd5-mnhmd from ibm-system started at 2019-08-14 19:55:09 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.552: INFO: 	Container ibm-cloud-provider-ip-169-62-248-21 ready: true, restart count 0
Aug 14 22:26:05.552: INFO: public-crbla645md08dcbpval0ag-alb1-58664575d4-bsm75 from kube-system started at 2019-08-14 19:56:54 +0000 UTC (4 container statuses recorded)
Aug 14 22:26:05.552: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Aug 14 22:26:05.552: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Aug 14 22:26:05.552: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Aug 14 22:26:05.552: INFO: 	Container nginx-ingress ready: true, restart count 0
Aug 14 22:26:05.552: INFO: ibm-kube-fluentd-zczvb from kube-system started at 2019-08-14 19:58:34 +0000 UTC (1 container statuses recorded)
Aug 14 22:26:05.552: INFO: 	Container fluentd ready: true, restart count 0
Aug 14 22:26:05.552: INFO: sonobuoy-e2e-job-0bc5e98b143e4e8a from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 22:26:05.552: INFO: 	Container e2e ready: true, restart count 0
Aug 14 22:26:05.552: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 14 22:26:05.552: INFO: sonobuoy-systemd-logs-daemon-set-bc35a38149844196-rlc9b from heptio-sonobuoy started at 2019-08-14 21:11:40 +0000 UTC (2 container statuses recorded)
Aug 14 22:26:05.552: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 14 22:26:05.552: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15baea6af8e7bc01], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:26:06.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gl6bc" for this suite.
Aug 14 22:26:12.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:26:13.072: INFO: namespace: e2e-tests-sched-pred-gl6bc, resource: bindings, ignored listing per whitelist
Aug 14 22:26:13.598: INFO: namespace e2e-tests-sched-pred-gl6bc deletion completed in 6.879320546s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:8.713 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:26:13.598: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lfr67
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-869044e6-bee2-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:26:14.157: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8692f586-bee2-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-lfr67" to be "success or failure"
Aug 14 22:26:14.176: INFO: Pod "pod-projected-secrets-8692f586-bee2-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.577365ms
Aug 14 22:26:16.192: INFO: Pod "pod-projected-secrets-8692f586-bee2-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035118905s
Aug 14 22:26:18.209: INFO: Pod "pod-projected-secrets-8692f586-bee2-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05152233s
STEP: Saw pod success
Aug 14 22:26:18.209: INFO: Pod "pod-projected-secrets-8692f586-bee2-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:26:18.224: INFO: Trying to get logs from node 10.209.12.141 pod pod-projected-secrets-8692f586-bee2-11e9-9404-ee44c4277148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:26:18.301: INFO: Waiting for pod pod-projected-secrets-8692f586-bee2-11e9-9404-ee44c4277148 to disappear
Aug 14 22:26:18.316: INFO: Pod pod-projected-secrets-8692f586-bee2-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:26:18.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lfr67" for this suite.
Aug 14 22:26:26.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:26:26.815: INFO: namespace: e2e-tests-projected-lfr67, resource: bindings, ignored listing per whitelist
Aug 14 22:26:27.145: INFO: namespace e2e-tests-projected-lfr67 deletion completed in 8.800987454s

• [SLOW TEST:13.546 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:26:27.145: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-bn5p7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 14 22:26:27.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bn5p7,SelfLink:/api/v1/namespaces/e2e-tests-watch-bn5p7/configmaps/e2e-watch-test-label-changed,UID:8ea44f5c-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:37275,Generation:0,CreationTimestamp:2019-08-14 22:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 22:26:27.723: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bn5p7,SelfLink:/api/v1/namespaces/e2e-tests-watch-bn5p7/configmaps/e2e-watch-test-label-changed,UID:8ea44f5c-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:37276,Generation:0,CreationTimestamp:2019-08-14 22:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 14 22:26:27.723: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bn5p7,SelfLink:/api/v1/namespaces/e2e-tests-watch-bn5p7/configmaps/e2e-watch-test-label-changed,UID:8ea44f5c-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:37277,Generation:0,CreationTimestamp:2019-08-14 22:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 14 22:26:37.934: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bn5p7,SelfLink:/api/v1/namespaces/e2e-tests-watch-bn5p7/configmaps/e2e-watch-test-label-changed,UID:8ea44f5c-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:37295,Generation:0,CreationTimestamp:2019-08-14 22:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 22:26:37.934: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bn5p7,SelfLink:/api/v1/namespaces/e2e-tests-watch-bn5p7/configmaps/e2e-watch-test-label-changed,UID:8ea44f5c-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:37296,Generation:0,CreationTimestamp:2019-08-14 22:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 14 22:26:37.934: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bn5p7,SelfLink:/api/v1/namespaces/e2e-tests-watch-bn5p7/configmaps/e2e-watch-test-label-changed,UID:8ea44f5c-bee2-11e9-a2b3-62a1b681b4a5,ResourceVersion:37297,Generation:0,CreationTimestamp:2019-08-14 22:26:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:26:37.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bn5p7" for this suite.
Aug 14 22:26:44.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:26:44.255: INFO: namespace: e2e-tests-watch-bn5p7, resource: bindings, ignored listing per whitelist
Aug 14 22:26:44.647: INFO: namespace e2e-tests-watch-bn5p7 deletion completed in 6.690003965s

• [SLOW TEST:17.502 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:26:44.647: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-j6tt8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Aug 14 22:26:45.245: INFO: Waiting up to 5m0s for pod "var-expansion-991c5e82-bee2-11e9-9404-ee44c4277148" in namespace "e2e-tests-var-expansion-j6tt8" to be "success or failure"
Aug 14 22:26:45.264: INFO: Pod "var-expansion-991c5e82-bee2-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.263471ms
Aug 14 22:26:47.280: INFO: Pod "var-expansion-991c5e82-bee2-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035022263s
Aug 14 22:26:49.319: INFO: Pod "var-expansion-991c5e82-bee2-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074510248s
STEP: Saw pod success
Aug 14 22:26:49.320: INFO: Pod "var-expansion-991c5e82-bee2-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:26:49.334: INFO: Trying to get logs from node 10.73.228.4 pod var-expansion-991c5e82-bee2-11e9-9404-ee44c4277148 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:26:49.421: INFO: Waiting for pod var-expansion-991c5e82-bee2-11e9-9404-ee44c4277148 to disappear
Aug 14 22:26:49.452: INFO: Pod var-expansion-991c5e82-bee2-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:26:49.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-j6tt8" for this suite.
Aug 14 22:26:57.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:26:57.703: INFO: namespace: e2e-tests-var-expansion-j6tt8, resource: bindings, ignored listing per whitelist
Aug 14 22:26:58.172: INFO: namespace e2e-tests-var-expansion-j6tt8 deletion completed in 8.67643912s

• [SLOW TEST:13.525 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:26:58.173: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-h86q5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 22:26:58.766: INFO: Number of nodes with available pods: 0
Aug 14 22:26:58.766: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:26:59.832: INFO: Number of nodes with available pods: 0
Aug 14 22:26:59.832: INFO: Node 10.209.12.141 is running more than one daemon pod
Aug 14 22:27:00.809: INFO: Number of nodes with available pods: 2
Aug 14 22:27:00.809: INFO: Node 10.73.228.2 is running more than one daemon pod
Aug 14 22:27:01.819: INFO: Number of nodes with available pods: 3
Aug 14 22:27:01.819: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 14 22:27:01.956: INFO: Number of nodes with available pods: 2
Aug 14 22:27:01.956: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:02.999: INFO: Number of nodes with available pods: 2
Aug 14 22:27:02.999: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:03.994: INFO: Number of nodes with available pods: 2
Aug 14 22:27:03.994: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:05.002: INFO: Number of nodes with available pods: 2
Aug 14 22:27:05.002: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:06.012: INFO: Number of nodes with available pods: 2
Aug 14 22:27:06.012: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:07.022: INFO: Number of nodes with available pods: 2
Aug 14 22:27:07.022: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:07.995: INFO: Number of nodes with available pods: 2
Aug 14 22:27:07.995: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:08.994: INFO: Number of nodes with available pods: 2
Aug 14 22:27:08.994: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:10.015: INFO: Number of nodes with available pods: 2
Aug 14 22:27:10.015: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:11.105: INFO: Number of nodes with available pods: 2
Aug 14 22:27:11.105: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:11.997: INFO: Number of nodes with available pods: 2
Aug 14 22:27:11.997: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:13.001: INFO: Number of nodes with available pods: 2
Aug 14 22:27:13.001: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:13.998: INFO: Number of nodes with available pods: 2
Aug 14 22:27:13.998: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:15.013: INFO: Number of nodes with available pods: 2
Aug 14 22:27:15.014: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:16.000: INFO: Number of nodes with available pods: 2
Aug 14 22:27:16.000: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:17.010: INFO: Number of nodes with available pods: 2
Aug 14 22:27:17.010: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:17.998: INFO: Number of nodes with available pods: 2
Aug 14 22:27:17.998: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:19.001: INFO: Number of nodes with available pods: 2
Aug 14 22:27:19.001: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:20.031: INFO: Number of nodes with available pods: 2
Aug 14 22:27:20.031: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:21.005: INFO: Number of nodes with available pods: 2
Aug 14 22:27:21.005: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:21.997: INFO: Number of nodes with available pods: 2
Aug 14 22:27:21.997: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:23.002: INFO: Number of nodes with available pods: 2
Aug 14 22:27:23.002: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:24.000: INFO: Number of nodes with available pods: 2
Aug 14 22:27:24.000: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:24.999: INFO: Number of nodes with available pods: 2
Aug 14 22:27:24.999: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:26.001: INFO: Number of nodes with available pods: 2
Aug 14 22:27:26.001: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:27.010: INFO: Number of nodes with available pods: 2
Aug 14 22:27:27.010: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:28.016: INFO: Number of nodes with available pods: 2
Aug 14 22:27:28.016: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:29.011: INFO: Number of nodes with available pods: 2
Aug 14 22:27:29.011: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:29.995: INFO: Number of nodes with available pods: 2
Aug 14 22:27:29.995: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:31.011: INFO: Number of nodes with available pods: 2
Aug 14 22:27:31.011: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:32.011: INFO: Number of nodes with available pods: 2
Aug 14 22:27:32.012: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:33.013: INFO: Number of nodes with available pods: 2
Aug 14 22:27:33.013: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:33.994: INFO: Number of nodes with available pods: 2
Aug 14 22:27:33.994: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:35.006: INFO: Number of nodes with available pods: 2
Aug 14 22:27:35.006: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:35.999: INFO: Number of nodes with available pods: 2
Aug 14 22:27:35.999: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:36.994: INFO: Number of nodes with available pods: 2
Aug 14 22:27:36.994: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:37.998: INFO: Number of nodes with available pods: 2
Aug 14 22:27:37.998: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:39.001: INFO: Number of nodes with available pods: 2
Aug 14 22:27:39.001: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:40.001: INFO: Number of nodes with available pods: 2
Aug 14 22:27:40.001: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:41.034: INFO: Number of nodes with available pods: 2
Aug 14 22:27:41.034: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:42.091: INFO: Number of nodes with available pods: 2
Aug 14 22:27:42.091: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:42.993: INFO: Number of nodes with available pods: 2
Aug 14 22:27:42.993: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:43.994: INFO: Number of nodes with available pods: 2
Aug 14 22:27:43.994: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:44.997: INFO: Number of nodes with available pods: 2
Aug 14 22:27:44.997: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:45.993: INFO: Number of nodes with available pods: 2
Aug 14 22:27:45.993: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:46.993: INFO: Number of nodes with available pods: 2
Aug 14 22:27:46.993: INFO: Node 10.73.228.4 is running more than one daemon pod
Aug 14 22:27:48.010: INFO: Number of nodes with available pods: 3
Aug 14 22:27:48.010: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-h86q5, will wait for the garbage collector to delete the pods
Aug 14 22:27:48.134: INFO: Deleting DaemonSet.extensions daemon-set took: 40.259983ms
Aug 14 22:27:48.234: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.293872ms
Aug 14 22:28:28.965: INFO: Number of nodes with available pods: 0
Aug 14 22:28:28.965: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 22:28:28.981: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-h86q5/daemonsets","resourceVersion":"37616"},"items":null}

Aug 14 22:28:28.997: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-h86q5/pods","resourceVersion":"37616"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:28:29.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-h86q5" for this suite.
Aug 14 22:28:37.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:28:37.610: INFO: namespace: e2e-tests-daemonsets-h86q5, resource: bindings, ignored listing per whitelist
Aug 14 22:28:37.820: INFO: namespace e2e-tests-daemonsets-h86q5 deletion completed in 8.734509051s

• [SLOW TEST:99.647 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:28:37.821: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-5skqd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5skqd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 22:28:38.352: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 22:29:02.771: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.187.228:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5skqd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:29:02.771: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:29:03.250: INFO: Found all expected endpoints: [netserver-0]
Aug 14 22:29:03.267: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.126.85:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5skqd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:29:03.267: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:29:03.612: INFO: Found all expected endpoints: [netserver-1]
Aug 14 22:29:03.627: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.171.146:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-5skqd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:29:03.627: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:29:03.952: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:29:03.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5skqd" for this suite.
Aug 14 22:29:30.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:29:30.334: INFO: namespace: e2e-tests-pod-network-test-5skqd, resource: bindings, ignored listing per whitelist
Aug 14 22:29:30.659: INFO: namespace e2e-tests-pod-network-test-5skqd deletion completed in 26.684141662s

• [SLOW TEST:52.838 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:29:30.660: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-tvjlp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 14 22:29:35.466: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 22:29:35.485: INFO: Pod pod-with-poststart-http-hook still exists
Aug 14 22:29:37.485: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 22:29:37.502: INFO: Pod pod-with-poststart-http-hook still exists
Aug 14 22:29:39.485: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 22:29:39.500: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:29:39.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-tvjlp" for this suite.
Aug 14 22:30:03.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:30:04.126: INFO: namespace: e2e-tests-container-lifecycle-hook-tvjlp, resource: bindings, ignored listing per whitelist
Aug 14 22:30:04.245: INFO: namespace e2e-tests-container-lifecycle-hook-tvjlp deletion completed in 24.721824645s

• [SLOW TEST:33.585 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:30:04.246: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bqtx2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Aug 14 22:30:04.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:04.959: INFO: stderr: ""
Aug 14 22:30:04.959: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:30:04.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:05.077: INFO: stderr: ""
Aug 14 22:30:05.077: INFO: stdout: "update-demo-nautilus-qhftf update-demo-nautilus-wdf25 "
Aug 14 22:30:05.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-qhftf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:05.217: INFO: stderr: ""
Aug 14 22:30:05.217: INFO: stdout: ""
Aug 14 22:30:05.217: INFO: update-demo-nautilus-qhftf is created but not running
Aug 14 22:30:10.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:10.395: INFO: stderr: ""
Aug 14 22:30:10.395: INFO: stdout: "update-demo-nautilus-qhftf update-demo-nautilus-wdf25 "
Aug 14 22:30:10.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-qhftf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:10.522: INFO: stderr: ""
Aug 14 22:30:10.522: INFO: stdout: "true"
Aug 14 22:30:10.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-qhftf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:10.638: INFO: stderr: ""
Aug 14 22:30:10.638: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:30:10.638: INFO: validating pod update-demo-nautilus-qhftf
Aug 14 22:30:10.689: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:30:10.689: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:30:10.689: INFO: update-demo-nautilus-qhftf is verified up and running
Aug 14 22:30:10.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-wdf25 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:10.893: INFO: stderr: ""
Aug 14 22:30:10.893: INFO: stdout: "true"
Aug 14 22:30:10.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-wdf25 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:11.009: INFO: stderr: ""
Aug 14 22:30:11.009: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:30:11.009: INFO: validating pod update-demo-nautilus-wdf25
Aug 14 22:30:11.040: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:30:11.040: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:30:11.040: INFO: update-demo-nautilus-wdf25 is verified up and running
STEP: rolling-update to new replication controller
Aug 14 22:30:11.041: INFO: scanned /root for discovery docs: <nil>
Aug 14 22:30:11.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:34.152: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 14 22:30:34.152: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:30:34.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:34.276: INFO: stderr: ""
Aug 14 22:30:34.277: INFO: stdout: "update-demo-kitten-khtk8 update-demo-kitten-zkt2j "
Aug 14 22:30:34.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-kitten-khtk8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:34.404: INFO: stderr: ""
Aug 14 22:30:34.404: INFO: stdout: "true"
Aug 14 22:30:34.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-kitten-khtk8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:34.551: INFO: stderr: ""
Aug 14 22:30:34.551: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 14 22:30:34.551: INFO: validating pod update-demo-kitten-khtk8
Aug 14 22:30:34.592: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 14 22:30:34.592: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 14 22:30:34.592: INFO: update-demo-kitten-khtk8 is verified up and running
Aug 14 22:30:34.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-kitten-zkt2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:34.725: INFO: stderr: ""
Aug 14 22:30:34.725: INFO: stdout: "true"
Aug 14 22:30:34.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-kitten-zkt2j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bqtx2'
Aug 14 22:30:34.835: INFO: stderr: ""
Aug 14 22:30:34.835: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 14 22:30:34.835: INFO: validating pod update-demo-kitten-zkt2j
Aug 14 22:30:34.868: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 14 22:30:34.868: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 14 22:30:34.868: INFO: update-demo-kitten-zkt2j is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:30:34.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bqtx2" for this suite.
Aug 14 22:30:58.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:30:59.227: INFO: namespace: e2e-tests-kubectl-bqtx2, resource: bindings, ignored listing per whitelist
Aug 14 22:30:59.607: INFO: namespace e2e-tests-kubectl-bqtx2 deletion completed in 24.715872086s

• [SLOW TEST:55.361 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:30:59.608: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-chj7f
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-310445ef-bee3-11e9-9404-ee44c4277148
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-310445ef-bee3-11e9-9404-ee44c4277148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:31:04.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-chj7f" for this suite.
Aug 14 22:31:28.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:31:29.021: INFO: namespace: e2e-tests-configmap-chj7f, resource: bindings, ignored listing per whitelist
Aug 14 22:31:29.194: INFO: namespace e2e-tests-configmap-chj7f deletion completed in 24.656421205s

• [SLOW TEST:29.586 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:31:29.195: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fvmwb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-42a4dd88-bee3-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:31:29.704: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-42a736c4-bee3-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-fvmwb" to be "success or failure"
Aug 14 22:31:29.791: INFO: Pod "pod-projected-secrets-42a736c4-bee3-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 86.517819ms
Aug 14 22:31:31.839: INFO: Pod "pod-projected-secrets-42a736c4-bee3-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.135366429s
STEP: Saw pod success
Aug 14 22:31:31.840: INFO: Pod "pod-projected-secrets-42a736c4-bee3-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:31:31.905: INFO: Trying to get logs from node 10.73.228.2 pod pod-projected-secrets-42a736c4-bee3-11e9-9404-ee44c4277148 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:31:32.070: INFO: Waiting for pod pod-projected-secrets-42a736c4-bee3-11e9-9404-ee44c4277148 to disappear
Aug 14 22:31:32.085: INFO: Pod pod-projected-secrets-42a736c4-bee3-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:31:32.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fvmwb" for this suite.
Aug 14 22:31:38.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:31:38.721: INFO: namespace: e2e-tests-projected-fvmwb, resource: bindings, ignored listing per whitelist
Aug 14 22:31:38.816: INFO: namespace e2e-tests-projected-fvmwb deletion completed in 6.625379395s

• [SLOW TEST:9.622 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:31:38.817: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-j2b6d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j2b6d
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 22:31:39.291: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 22:32:03.707: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.187.230:8080/dial?request=hostName&protocol=udp&host=172.30.171.152&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j2b6d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:32:03.707: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:32:04.092: INFO: Waiting for endpoints: map[]
Aug 14 22:32:04.141: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.187.230:8080/dial?request=hostName&protocol=udp&host=172.30.126.87&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j2b6d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:32:04.141: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:32:04.491: INFO: Waiting for endpoints: map[]
Aug 14 22:32:04.506: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.187.230:8080/dial?request=hostName&protocol=udp&host=172.30.187.233&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j2b6d PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:32:04.506: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:32:04.853: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:32:04.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j2b6d" for this suite.
Aug 14 22:32:28.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:32:29.200: INFO: namespace: e2e-tests-pod-network-test-j2b6d, resource: bindings, ignored listing per whitelist
Aug 14 22:32:29.576: INFO: namespace e2e-tests-pod-network-test-j2b6d deletion completed in 24.696445077s

• [SLOW TEST:50.760 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:32:29.577: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-wt484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:32:30.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wt484" for this suite.
Aug 14 22:32:54.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:32:54.724: INFO: namespace: e2e-tests-pods-wt484, resource: bindings, ignored listing per whitelist
Aug 14 22:32:54.810: INFO: namespace e2e-tests-pods-wt484 deletion completed in 24.63961564s

• [SLOW TEST:25.233 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:32:54.810: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-9nd6p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 14 22:32:55.319: INFO: Waiting up to 5m0s for pod "pod-75ab6fbb-bee3-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-9nd6p" to be "success or failure"
Aug 14 22:32:55.338: INFO: Pod "pod-75ab6fbb-bee3-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.512916ms
Aug 14 22:32:57.356: INFO: Pod "pod-75ab6fbb-bee3-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037481861s
Aug 14 22:32:59.371: INFO: Pod "pod-75ab6fbb-bee3-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052544327s
STEP: Saw pod success
Aug 14 22:32:59.371: INFO: Pod "pod-75ab6fbb-bee3-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:32:59.388: INFO: Trying to get logs from node 10.209.12.141 pod pod-75ab6fbb-bee3-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:32:59.496: INFO: Waiting for pod pod-75ab6fbb-bee3-11e9-9404-ee44c4277148 to disappear
Aug 14 22:32:59.510: INFO: Pod pod-75ab6fbb-bee3-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:32:59.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9nd6p" for this suite.
Aug 14 22:33:07.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:33:07.845: INFO: namespace: e2e-tests-emptydir-9nd6p, resource: bindings, ignored listing per whitelist
Aug 14 22:33:08.285: INFO: namespace e2e-tests-emptydir-9nd6p deletion completed in 8.753437749s

• [SLOW TEST:13.475 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:33:08.285: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kt7jj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 14 22:33:13.446: INFO: Successfully updated pod "labelsupdate7dba17d3-bee3-11e9-9404-ee44c4277148"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:33:15.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kt7jj" for this suite.
Aug 14 22:33:39.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:33:39.821: INFO: namespace: e2e-tests-projected-kt7jj, resource: bindings, ignored listing per whitelist
Aug 14 22:33:40.309: INFO: namespace e2e-tests-projected-kt7jj deletion completed in 24.694108803s

• [SLOW TEST:32.024 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:33:40.310: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-8xgpz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-8xgpz
Aug 14 22:33:43.191: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-8xgpz
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 22:33:43.206: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:37:44.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8xgpz" for this suite.
Aug 14 22:37:52.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:37:52.864: INFO: namespace: e2e-tests-container-probe-8xgpz, resource: bindings, ignored listing per whitelist
Aug 14 22:37:52.923: INFO: namespace e2e-tests-container-probe-8xgpz deletion completed in 8.631807837s

• [SLOW TEST:252.613 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:37:52.923: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fr4qt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-276479c9-bee4-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:37:53.470: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2766f4cc-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-fr4qt" to be "success or failure"
Aug 14 22:37:53.489: INFO: Pod "pod-projected-configmaps-2766f4cc-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.740594ms
Aug 14 22:37:55.505: INFO: Pod "pod-projected-configmaps-2766f4cc-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03450467s
Aug 14 22:37:57.520: INFO: Pod "pod-projected-configmaps-2766f4cc-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049700614s
STEP: Saw pod success
Aug 14 22:37:57.520: INFO: Pod "pod-projected-configmaps-2766f4cc-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:37:57.535: INFO: Trying to get logs from node 10.209.12.141 pod pod-projected-configmaps-2766f4cc-bee4-11e9-9404-ee44c4277148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:37:57.618: INFO: Waiting for pod pod-projected-configmaps-2766f4cc-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:37:57.634: INFO: Pod pod-projected-configmaps-2766f4cc-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:37:57.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fr4qt" for this suite.
Aug 14 22:38:03.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:38:04.110: INFO: namespace: e2e-tests-projected-fr4qt, resource: bindings, ignored listing per whitelist
Aug 14 22:38:04.363: INFO: namespace e2e-tests-projected-fr4qt deletion completed in 6.650858933s

• [SLOW TEST:11.441 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:38:04.365: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-8cmrp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:38:30.950: INFO: Container started at 2019-08-14 22:38:06 +0000 UTC, pod became ready at 2019-08-14 22:38:30 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:38:30.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8cmrp" for this suite.
Aug 14 22:38:55.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:38:55.343: INFO: namespace: e2e-tests-container-probe-8cmrp, resource: bindings, ignored listing per whitelist
Aug 14 22:38:55.756: INFO: namespace e2e-tests-container-probe-8cmrp deletion completed in 24.781736026s

• [SLOW TEST:51.391 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:38:55.756: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nkqh5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-nkqh5/secret-test-4cd34611-bee4-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:38:56.275: INFO: Waiting up to 5m0s for pod "pod-configmaps-4cd5df14-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-secrets-nkqh5" to be "success or failure"
Aug 14 22:38:56.294: INFO: Pod "pod-configmaps-4cd5df14-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.140882ms
Aug 14 22:38:58.309: INFO: Pod "pod-configmaps-4cd5df14-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03447414s
STEP: Saw pod success
Aug 14 22:38:58.310: INFO: Pod "pod-configmaps-4cd5df14-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:38:58.325: INFO: Trying to get logs from node 10.73.228.2 pod pod-configmaps-4cd5df14-bee4-11e9-9404-ee44c4277148 container env-test: <nil>
STEP: delete the pod
Aug 14 22:38:58.434: INFO: Waiting for pod pod-configmaps-4cd5df14-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:38:58.450: INFO: Pod pod-configmaps-4cd5df14-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:38:58.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nkqh5" for this suite.
Aug 14 22:39:06.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:39:06.956: INFO: namespace: e2e-tests-secrets-nkqh5, resource: bindings, ignored listing per whitelist
Aug 14 22:39:07.102: INFO: namespace e2e-tests-secrets-nkqh5 deletion completed in 8.627681344s

• [SLOW TEST:11.346 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:39:07.102: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-ms85p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9q7bq in namespace e2e-tests-proxy-ms85p
I0814 22:39:07.612882      17 runners.go:184] Created replication controller with name: proxy-service-9q7bq, namespace: e2e-tests-proxy-ms85p, replica count: 1
I0814 22:39:08.663294      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:39:09.663483      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:39:10.670237      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 22:39:11.670514      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:39:12.670771      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:39:13.671034      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:39:14.671315      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:39:15.671556      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:39:16.671751      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 22:39:17.671960      17 runners.go:184] proxy-service-9q7bq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 14 22:39:17.701: INFO: setup took 10.149198371s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 14 22:39:17.747: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 45.023899ms)
Aug 14 22:39:17.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 52.003888ms)
Aug 14 22:39:17.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 52.095572ms)
Aug 14 22:39:17.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 52.264797ms)
Aug 14 22:39:17.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 52.285146ms)
Aug 14 22:39:17.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 52.142321ms)
Aug 14 22:39:17.754: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 52.360935ms)
Aug 14 22:39:17.759: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 57.451656ms)
Aug 14 22:39:17.759: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 57.265226ms)
Aug 14 22:39:17.759: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 57.475601ms)
Aug 14 22:39:17.759: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 57.665811ms)
Aug 14 22:39:17.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 68.229598ms)
Aug 14 22:39:17.770: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 68.595431ms)
Aug 14 22:39:17.771: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 69.811364ms)
Aug 14 22:39:17.776: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 74.993682ms)
Aug 14 22:39:17.777: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 75.287645ms)
Aug 14 22:39:17.799: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 21.911902ms)
Aug 14 22:39:17.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 27.305665ms)
Aug 14 22:39:17.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 27.271793ms)
Aug 14 22:39:17.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 27.132383ms)
Aug 14 22:39:17.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 27.117549ms)
Aug 14 22:39:17.804: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 27.412668ms)
Aug 14 22:39:17.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 27.736289ms)
Aug 14 22:39:17.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 27.855288ms)
Aug 14 22:39:17.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 27.919031ms)
Aug 14 22:39:17.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 27.910478ms)
Aug 14 22:39:17.805: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 27.76703ms)
Aug 14 22:39:17.810: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 33.115614ms)
Aug 14 22:39:17.810: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 33.453274ms)
Aug 14 22:39:17.811: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 33.375157ms)
Aug 14 22:39:17.811: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 33.670785ms)
Aug 14 22:39:17.811: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 33.416173ms)
Aug 14 22:39:17.833: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 22.302882ms)
Aug 14 22:39:17.833: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 22.181394ms)
Aug 14 22:39:17.838: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 27.135385ms)
Aug 14 22:39:17.838: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 27.369428ms)
Aug 14 22:39:17.838: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 27.321472ms)
Aug 14 22:39:17.839: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 27.804025ms)
Aug 14 22:39:17.839: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 27.901071ms)
Aug 14 22:39:17.839: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 27.817642ms)
Aug 14 22:39:17.839: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 28.003716ms)
Aug 14 22:39:17.839: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 28.021787ms)
Aug 14 22:39:17.845: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 33.959211ms)
Aug 14 22:39:17.845: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 33.896009ms)
Aug 14 22:39:17.845: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 33.951977ms)
Aug 14 22:39:17.845: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 33.907115ms)
Aug 14 22:39:17.845: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 34.068287ms)
Aug 14 22:39:17.845: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 33.944029ms)
Aug 14 22:39:17.866: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 20.539904ms)
Aug 14 22:39:17.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 26.830551ms)
Aug 14 22:39:17.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 26.913506ms)
Aug 14 22:39:17.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 27.042476ms)
Aug 14 22:39:17.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 26.989472ms)
Aug 14 22:39:17.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 27.037623ms)
Aug 14 22:39:17.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 27.238614ms)
Aug 14 22:39:17.873: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 27.268369ms)
Aug 14 22:39:17.873: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 27.362125ms)
Aug 14 22:39:17.873: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 27.414839ms)
Aug 14 22:39:17.878: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 32.995928ms)
Aug 14 22:39:17.878: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 32.956922ms)
Aug 14 22:39:17.878: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 33.139285ms)
Aug 14 22:39:17.879: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 33.670556ms)
Aug 14 22:39:17.879: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 33.765881ms)
Aug 14 22:39:17.879: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 33.717736ms)
Aug 14 22:39:17.901: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 21.409802ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 28.265833ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 28.628472ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 28.550647ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 28.498852ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 28.476201ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 28.537203ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 28.757713ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 28.780541ms)
Aug 14 22:39:17.908: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 28.78948ms)
Aug 14 22:39:17.920: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 41.048564ms)
Aug 14 22:39:17.922: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 42.718763ms)
Aug 14 22:39:17.922: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 42.829767ms)
Aug 14 22:39:17.922: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 42.706106ms)
Aug 14 22:39:17.922: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 42.79861ms)
Aug 14 22:39:17.922: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 42.896842ms)
Aug 14 22:39:17.950: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 25.946998ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 31.291513ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 29.310824ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 29.434463ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 31.651319ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 31.536965ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 31.66247ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 29.94103ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 30.054737ms)
Aug 14 22:39:17.954: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 30.085784ms)
Aug 14 22:39:17.960: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 35.548073ms)
Aug 14 22:39:17.963: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 38.073877ms)
Aug 14 22:39:17.963: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 40.205456ms)
Aug 14 22:39:17.963: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 38.445078ms)
Aug 14 22:39:17.963: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 38.675658ms)
Aug 14 22:39:17.963: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 38.65153ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 25.117124ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 25.045146ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 25.438315ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 25.469394ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 25.265674ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 25.584171ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 25.373603ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 25.21269ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 25.305118ms)
Aug 14 22:39:17.989: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 25.392198ms)
Aug 14 22:39:18.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 68.786773ms)
Aug 14 22:39:18.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 68.768297ms)
Aug 14 22:39:18.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 68.608758ms)
Aug 14 22:39:18.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 68.874492ms)
Aug 14 22:39:18.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 68.671724ms)
Aug 14 22:39:18.032: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 68.76828ms)
Aug 14 22:39:18.060: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 27.528378ms)
Aug 14 22:39:18.066: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 33.612158ms)
Aug 14 22:39:18.066: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 33.702526ms)
Aug 14 22:39:18.066: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 33.836384ms)
Aug 14 22:39:18.067: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 33.826552ms)
Aug 14 22:39:18.066: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 33.952162ms)
Aug 14 22:39:18.067: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 33.885184ms)
Aug 14 22:39:18.067: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 33.998863ms)
Aug 14 22:39:18.067: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 33.908999ms)
Aug 14 22:39:18.067: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 33.846633ms)
Aug 14 22:39:18.072: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 39.926ms)
Aug 14 22:39:18.072: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 39.819375ms)
Aug 14 22:39:18.073: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 39.879199ms)
Aug 14 22:39:18.075: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 42.643114ms)
Aug 14 22:39:18.076: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 42.858839ms)
Aug 14 22:39:18.076: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 42.838997ms)
Aug 14 22:39:18.098: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 21.755186ms)
Aug 14 22:39:18.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 27.869225ms)
Aug 14 22:39:18.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 27.853026ms)
Aug 14 22:39:18.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 28.084705ms)
Aug 14 22:39:18.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 28.085309ms)
Aug 14 22:39:18.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 27.878287ms)
Aug 14 22:39:18.104: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 28.113074ms)
Aug 14 22:39:18.105: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 28.868565ms)
Aug 14 22:39:18.105: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 28.839079ms)
Aug 14 22:39:18.105: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 29.04931ms)
Aug 14 22:39:18.109: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 33.305909ms)
Aug 14 22:39:18.109: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 33.360151ms)
Aug 14 22:39:18.109: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 33.390485ms)
Aug 14 22:39:18.109: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 33.481059ms)
Aug 14 22:39:18.110: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 33.683528ms)
Aug 14 22:39:18.110: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 33.645696ms)
Aug 14 22:39:18.139: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 29.289634ms)
Aug 14 22:39:18.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 30.091871ms)
Aug 14 22:39:18.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 30.431846ms)
Aug 14 22:39:18.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 30.162692ms)
Aug 14 22:39:18.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 30.17843ms)
Aug 14 22:39:18.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 30.310372ms)
Aug 14 22:39:18.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 30.435016ms)
Aug 14 22:39:18.140: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 30.444581ms)
Aug 14 22:39:18.141: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 30.773793ms)
Aug 14 22:39:18.141: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 31.214196ms)
Aug 14 22:39:18.144: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 34.649375ms)
Aug 14 22:39:18.145: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 34.878856ms)
Aug 14 22:39:18.145: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 35.096771ms)
Aug 14 22:39:18.146: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 35.444597ms)
Aug 14 22:39:18.146: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 36.283488ms)
Aug 14 22:39:18.146: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 36.226113ms)
Aug 14 22:39:18.168: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 21.369179ms)
Aug 14 22:39:18.168: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 21.090227ms)
Aug 14 22:39:18.174: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 27.728502ms)
Aug 14 22:39:18.174: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 27.808798ms)
Aug 14 22:39:18.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 32.085029ms)
Aug 14 22:39:18.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 32.102321ms)
Aug 14 22:39:18.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 32.172985ms)
Aug 14 22:39:18.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 32.420444ms)
Aug 14 22:39:18.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 32.109454ms)
Aug 14 22:39:18.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 32.221901ms)
Aug 14 22:39:18.179: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 32.141623ms)
Aug 14 22:39:18.181: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 34.373613ms)
Aug 14 22:39:18.186: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 38.991615ms)
Aug 14 22:39:18.186: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 39.193008ms)
Aug 14 22:39:18.186: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 38.981531ms)
Aug 14 22:39:18.186: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 39.593482ms)
Aug 14 22:39:18.208: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 21.306834ms)
Aug 14 22:39:18.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 29.126897ms)
Aug 14 22:39:18.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 29.201405ms)
Aug 14 22:39:18.216: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 29.916918ms)
Aug 14 22:39:18.217: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 29.879884ms)
Aug 14 22:39:18.217: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 30.719082ms)
Aug 14 22:39:18.217: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 30.33064ms)
Aug 14 22:39:18.217: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 31.05158ms)
Aug 14 22:39:18.217: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 30.555454ms)
Aug 14 22:39:18.218: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 30.965109ms)
Aug 14 22:39:18.223: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 36.46379ms)
Aug 14 22:39:18.223: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 36.437802ms)
Aug 14 22:39:18.223: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 36.336296ms)
Aug 14 22:39:18.223: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 36.440494ms)
Aug 14 22:39:18.224: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 36.970367ms)
Aug 14 22:39:18.231: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 43.92668ms)
Aug 14 22:39:18.254: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 23.138594ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 30.564587ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 30.456589ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 30.556568ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 30.481573ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 30.672411ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 30.835523ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 30.769912ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 31.375879ms)
Aug 14 22:39:18.262: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 31.336785ms)
Aug 14 22:39:18.265: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 34.256962ms)
Aug 14 22:39:18.266: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 34.713937ms)
Aug 14 22:39:18.266: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 35.417203ms)
Aug 14 22:39:18.267: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 36.467276ms)
Aug 14 22:39:18.268: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 36.711674ms)
Aug 14 22:39:18.268: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 37.347876ms)
Aug 14 22:39:18.291: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 22.721773ms)
Aug 14 22:39:18.291: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 22.922898ms)
Aug 14 22:39:18.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 32.084639ms)
Aug 14 22:39:18.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 32.101003ms)
Aug 14 22:39:18.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 32.003926ms)
Aug 14 22:39:18.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 32.057165ms)
Aug 14 22:39:18.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 32.274183ms)
Aug 14 22:39:18.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 32.155147ms)
Aug 14 22:39:18.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 32.486505ms)
Aug 14 22:39:18.301: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 32.262018ms)
Aug 14 22:39:18.302: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 33.625759ms)
Aug 14 22:39:18.302: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 33.614716ms)
Aug 14 22:39:18.303: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 33.962462ms)
Aug 14 22:39:18.304: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 35.176251ms)
Aug 14 22:39:18.304: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 35.478034ms)
Aug 14 22:39:18.308: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 39.191146ms)
Aug 14 22:39:18.331: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 23.248548ms)
Aug 14 22:39:18.331: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 23.41531ms)
Aug 14 22:39:18.331: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 23.411578ms)
Aug 14 22:39:18.339: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 31.128309ms)
Aug 14 22:39:18.340: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 31.903025ms)
Aug 14 22:39:18.340: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 32.050149ms)
Aug 14 22:39:18.340: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 32.193538ms)
Aug 14 22:39:18.341: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 32.920483ms)
Aug 14 22:39:18.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 33.450953ms)
Aug 14 22:39:18.342: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 33.64418ms)
Aug 14 22:39:18.345: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 37.144873ms)
Aug 14 22:39:18.346: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 38.388973ms)
Aug 14 22:39:18.347: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 38.80885ms)
Aug 14 22:39:18.347: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 39.229201ms)
Aug 14 22:39:18.347: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 39.252801ms)
Aug 14 22:39:18.350: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 41.597785ms)
Aug 14 22:39:18.374: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 23.923072ms)
Aug 14 22:39:18.380: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 30.262666ms)
Aug 14 22:39:18.380: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 30.425021ms)
Aug 14 22:39:18.380: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 30.566565ms)
Aug 14 22:39:18.380: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 30.34855ms)
Aug 14 22:39:18.385: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 34.772575ms)
Aug 14 22:39:18.385: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 34.747458ms)
Aug 14 22:39:18.385: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 35.287613ms)
Aug 14 22:39:18.385: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 35.272783ms)
Aug 14 22:39:18.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 35.695925ms)
Aug 14 22:39:18.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 35.950184ms)
Aug 14 22:39:18.386: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 36.564881ms)
Aug 14 22:39:18.387: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 36.550422ms)
Aug 14 22:39:18.391: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 40.595445ms)
Aug 14 22:39:18.391: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 41.050938ms)
Aug 14 22:39:18.391: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 41.32099ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 30.64548ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 30.727745ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 30.93627ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 30.892006ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 30.938707ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 30.89207ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 30.815432ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 30.788062ms)
Aug 14 22:39:18.422: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 31.010642ms)
Aug 14 22:39:18.423: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 31.03785ms)
Aug 14 22:39:18.424: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 32.284518ms)
Aug 14 22:39:18.425: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 33.029243ms)
Aug 14 22:39:18.425: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 33.394651ms)
Aug 14 22:39:18.426: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 35.035139ms)
Aug 14 22:39:18.426: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 35.015948ms)
Aug 14 22:39:18.426: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 35.166472ms)
Aug 14 22:39:18.446: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 19.772313ms)
Aug 14 22:39:18.454: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 26.798445ms)
Aug 14 22:39:18.455: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 28.799795ms)
Aug 14 22:39:18.455: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 28.686315ms)
Aug 14 22:39:18.455: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 28.654802ms)
Aug 14 22:39:18.456: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 28.750161ms)
Aug 14 22:39:18.456: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 28.871387ms)
Aug 14 22:39:18.456: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 29.028837ms)
Aug 14 22:39:18.456: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 28.948822ms)
Aug 14 22:39:18.456: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 29.448885ms)
Aug 14 22:39:18.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 32.206046ms)
Aug 14 22:39:18.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 32.357669ms)
Aug 14 22:39:18.459: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 32.340596ms)
Aug 14 22:39:18.460: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 33.885685ms)
Aug 14 22:39:18.460: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 33.608686ms)
Aug 14 22:39:18.461: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 33.95846ms)
Aug 14 22:39:18.483: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 21.719107ms)
Aug 14 22:39:18.489: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 27.433093ms)
Aug 14 22:39:18.489: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 27.848342ms)
Aug 14 22:39:18.489: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 28.222146ms)
Aug 14 22:39:18.489: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 28.115813ms)
Aug 14 22:39:18.490: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 28.730501ms)
Aug 14 22:39:18.490: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 28.403111ms)
Aug 14 22:39:18.490: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 28.578363ms)
Aug 14 22:39:18.491: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 29.491547ms)
Aug 14 22:39:18.491: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 29.858092ms)
Aug 14 22:39:18.498: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 36.761899ms)
Aug 14 22:39:18.498: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 36.935355ms)
Aug 14 22:39:18.498: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 36.713062ms)
Aug 14 22:39:18.498: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 37.211545ms)
Aug 14 22:39:18.499: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 37.34555ms)
Aug 14 22:39:18.499: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 37.58024ms)
Aug 14 22:39:18.526: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 26.981287ms)
Aug 14 22:39:18.526: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:443/proxy/... (200; 27.412089ms)
Aug 14 22:39:18.526: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:1080/proxy/rewri... (200; 27.357492ms)
Aug 14 22:39:18.527: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:1080/proxy/... (200; 27.722377ms)
Aug 14 22:39:18.528: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg/proxy/rewriteme"... (200; 28.834371ms)
Aug 14 22:39:18.528: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:160/proxy/: foo (200; 29.054657ms)
Aug 14 22:39:18.528: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:460/proxy/: tls baz (200; 28.956453ms)
Aug 14 22:39:18.528: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/http:proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 29.2448ms)
Aug 14 22:39:18.528: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/proxy-service-9q7bq-5rmmg:162/proxy/: bar (200; 29.191883ms)
Aug 14 22:39:18.529: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/pods/https:proxy-service-9q7bq-5rmmg:462/proxy/: tls qux (200; 29.740513ms)
Aug 14 22:39:18.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname1/proxy/: foo (200; 33.305049ms)
Aug 14 22:39:18.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname2/proxy/: tls qux (200; 33.174299ms)
Aug 14 22:39:18.532: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/https:proxy-service-9q7bq:tlsportname1/proxy/: tls baz (200; 33.110794ms)
Aug 14 22:39:18.533: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/http:proxy-service-9q7bq:portname2/proxy/: bar (200; 34.026322ms)
Aug 14 22:39:18.533: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname1/proxy/: foo (200; 34.324132ms)
Aug 14 22:39:18.535: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ms85p/services/proxy-service-9q7bq:portname2/proxy/: bar (200; 36.341159ms)
STEP: deleting ReplicationController proxy-service-9q7bq in namespace e2e-tests-proxy-ms85p, will wait for the garbage collector to delete the pods
Aug 14 22:39:18.640: INFO: Deleting ReplicationController proxy-service-9q7bq took: 35.776551ms
Aug 14 22:39:18.741: INFO: Terminating ReplicationController proxy-service-9q7bq pods took: 100.323196ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:39:31.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-ms85p" for this suite.
Aug 14 22:39:39.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:39:40.448: INFO: namespace: e2e-tests-proxy-ms85p, resource: bindings, ignored listing per whitelist
Aug 14 22:39:40.712: INFO: namespace e2e-tests-proxy-ms85p deletion completed in 8.926049149s

• [SLOW TEST:33.609 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:39:40.712: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2sgrz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-679ee68e-bee4-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:39:41.224: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-67a133f7-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-2sgrz" to be "success or failure"
Aug 14 22:39:41.263: INFO: Pod "pod-projected-configmaps-67a133f7-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 38.211341ms
Aug 14 22:39:43.328: INFO: Pod "pod-projected-configmaps-67a133f7-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.103151151s
STEP: Saw pod success
Aug 14 22:39:43.328: INFO: Pod "pod-projected-configmaps-67a133f7-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:39:43.343: INFO: Trying to get logs from node 10.73.228.2 pod pod-projected-configmaps-67a133f7-bee4-11e9-9404-ee44c4277148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:39:43.424: INFO: Waiting for pod pod-projected-configmaps-67a133f7-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:39:43.438: INFO: Pod pod-projected-configmaps-67a133f7-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:39:43.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2sgrz" for this suite.
Aug 14 22:39:51.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:39:51.849: INFO: namespace: e2e-tests-projected-2sgrz, resource: bindings, ignored listing per whitelist
Aug 14 22:39:52.188: INFO: namespace e2e-tests-projected-2sgrz deletion completed in 8.720686451s

• [SLOW TEST:11.476 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:39:52.188: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-klbw2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6e7eaec7-bee4-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:39:52.755: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6e80e686-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-klbw2" to be "success or failure"
Aug 14 22:39:52.777: INFO: Pod "pod-projected-configmaps-6e80e686-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 21.751563ms
Aug 14 22:39:54.810: INFO: Pod "pod-projected-configmaps-6e80e686-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054685347s
Aug 14 22:39:56.840: INFO: Pod "pod-projected-configmaps-6e80e686-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.084192335s
STEP: Saw pod success
Aug 14 22:39:56.840: INFO: Pod "pod-projected-configmaps-6e80e686-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:39:56.857: INFO: Trying to get logs from node 10.73.228.4 pod pod-projected-configmaps-6e80e686-bee4-11e9-9404-ee44c4277148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:39:56.955: INFO: Waiting for pod pod-projected-configmaps-6e80e686-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:39:56.970: INFO: Pod pod-projected-configmaps-6e80e686-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:39:56.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-klbw2" for this suite.
Aug 14 22:40:05.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:40:05.627: INFO: namespace: e2e-tests-projected-klbw2, resource: bindings, ignored listing per whitelist
Aug 14 22:40:05.724: INFO: namespace e2e-tests-projected-klbw2 deletion completed in 8.731040219s

• [SLOW TEST:13.536 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:40:05.724: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qcpf4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 14 22:40:06.214: INFO: Waiting up to 5m0s for pod "pod-7684fd4e-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-qcpf4" to be "success or failure"
Aug 14 22:40:06.233: INFO: Pod "pod-7684fd4e-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.23209ms
Aug 14 22:40:08.249: INFO: Pod "pod-7684fd4e-bee4-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.035515775s
Aug 14 22:40:10.267: INFO: Pod "pod-7684fd4e-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053906851s
STEP: Saw pod success
Aug 14 22:40:10.267: INFO: Pod "pod-7684fd4e-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:40:10.286: INFO: Trying to get logs from node 10.209.12.141 pod pod-7684fd4e-bee4-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:40:10.406: INFO: Waiting for pod pod-7684fd4e-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:40:10.425: INFO: Pod pod-7684fd4e-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:40:10.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qcpf4" for this suite.
Aug 14 22:40:18.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:40:19.087: INFO: namespace: e2e-tests-emptydir-qcpf4, resource: bindings, ignored listing per whitelist
Aug 14 22:40:19.138: INFO: namespace e2e-tests-emptydir-qcpf4 deletion completed in 8.677392694s

• [SLOW TEST:13.413 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:40:19.138: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-dfw6z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0814 22:40:50.391349      17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 22:40:50.391: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:40:50.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-dfw6z" for this suite.
Aug 14 22:40:58.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:40:58.875: INFO: namespace: e2e-tests-gc-dfw6z, resource: bindings, ignored listing per whitelist
Aug 14 22:40:59.191: INFO: namespace e2e-tests-gc-dfw6z deletion completed in 8.782684066s

• [SLOW TEST:40.053 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:40:59.191: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-s27z6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 14 22:40:59.741: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-s27z6,SelfLink:/api/v1/namespaces/e2e-tests-watch-s27z6/configmaps/e2e-watch-test-resource-version,UID:966167da-bee4-11e9-a2b3-62a1b681b4a5,ResourceVersion:39883,Generation:0,CreationTimestamp:2019-08-14 22:40:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 22:40:59.741: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-s27z6,SelfLink:/api/v1/namespaces/e2e-tests-watch-s27z6/configmaps/e2e-watch-test-resource-version,UID:966167da-bee4-11e9-a2b3-62a1b681b4a5,ResourceVersion:39884,Generation:0,CreationTimestamp:2019-08-14 22:40:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:40:59.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-s27z6" for this suite.
Aug 14 22:41:05.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:41:06.754: INFO: namespace: e2e-tests-watch-s27z6, resource: bindings, ignored listing per whitelist
Aug 14 22:41:06.767: INFO: namespace e2e-tests-watch-s27z6 deletion completed in 7.006908995s

• [SLOW TEST:7.576 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:41:06.768: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-n6bpv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:41:07.229: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ae3cb6d-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-n6bpv" to be "success or failure"
Aug 14 22:41:07.251: INFO: Pod "downwardapi-volume-9ae3cb6d-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 21.267593ms
Aug 14 22:41:09.267: INFO: Pod "downwardapi-volume-9ae3cb6d-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037375644s
Aug 14 22:41:11.284: INFO: Pod "downwardapi-volume-9ae3cb6d-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054518756s
STEP: Saw pod success
Aug 14 22:41:11.284: INFO: Pod "downwardapi-volume-9ae3cb6d-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:41:11.302: INFO: Trying to get logs from node 10.73.228.2 pod downwardapi-volume-9ae3cb6d-bee4-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:41:11.441: INFO: Waiting for pod downwardapi-volume-9ae3cb6d-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:41:11.461: INFO: Pod downwardapi-volume-9ae3cb6d-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:41:11.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n6bpv" for this suite.
Aug 14 22:41:19.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:41:20.492: INFO: namespace: e2e-tests-projected-n6bpv, resource: bindings, ignored listing per whitelist
Aug 14 22:41:20.605: INFO: namespace e2e-tests-projected-n6bpv deletion completed in 9.1194309s

• [SLOW TEST:13.837 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:41:20.606: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-x9w5v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:41:26.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-x9w5v" for this suite.
Aug 14 22:41:50.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:41:50.482: INFO: namespace: e2e-tests-replication-controller-x9w5v, resource: bindings, ignored listing per whitelist
Aug 14 22:41:50.969: INFO: namespace e2e-tests-replication-controller-x9w5v deletion completed in 24.600474105s

• [SLOW TEST:30.363 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:41:50.969: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zkx6k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-zkx6k/configmap-test-b56bc762-bee4-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:41:51.751: INFO: Waiting up to 5m0s for pod "pod-configmaps-b56e160a-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-configmap-zkx6k" to be "success or failure"
Aug 14 22:41:51.781: INFO: Pod "pod-configmaps-b56e160a-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 29.292952ms
Aug 14 22:41:53.799: INFO: Pod "pod-configmaps-b56e160a-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047901815s
STEP: Saw pod success
Aug 14 22:41:53.799: INFO: Pod "pod-configmaps-b56e160a-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:41:53.891: INFO: Trying to get logs from node 10.73.228.2 pod pod-configmaps-b56e160a-bee4-11e9-9404-ee44c4277148 container env-test: <nil>
STEP: delete the pod
Aug 14 22:41:53.983: INFO: Waiting for pod pod-configmaps-b56e160a-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:41:54.004: INFO: Pod pod-configmaps-b56e160a-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:41:54.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zkx6k" for this suite.
Aug 14 22:42:02.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:42:02.802: INFO: namespace: e2e-tests-configmap-zkx6k, resource: bindings, ignored listing per whitelist
Aug 14 22:42:02.955: INFO: namespace e2e-tests-configmap-zkx6k deletion completed in 8.925171612s

• [SLOW TEST:11.986 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:42:02.955: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-sh9br
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Aug 14 22:42:03.433: INFO: Waiting up to 5m0s for pod "client-containers-bc649fc2-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-containers-sh9br" to be "success or failure"
Aug 14 22:42:03.447: INFO: Pod "client-containers-bc649fc2-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.275487ms
Aug 14 22:42:05.465: INFO: Pod "client-containers-bc649fc2-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032418006s
STEP: Saw pod success
Aug 14 22:42:05.465: INFO: Pod "client-containers-bc649fc2-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:42:05.480: INFO: Trying to get logs from node 10.73.228.2 pod client-containers-bc649fc2-bee4-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:42:05.560: INFO: Waiting for pod client-containers-bc649fc2-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:42:05.575: INFO: Pod client-containers-bc649fc2-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:42:05.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-sh9br" for this suite.
Aug 14 22:42:13.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:42:13.790: INFO: namespace: e2e-tests-containers-sh9br, resource: bindings, ignored listing per whitelist
Aug 14 22:42:14.220: INFO: namespace e2e-tests-containers-sh9br deletion completed in 8.61690134s

• [SLOW TEST:11.266 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:42:14.221: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-2wvth
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 14 22:42:14.684: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 14 22:42:19.701: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:42:19.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2wvth" for this suite.
Aug 14 22:42:27.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:42:28.194: INFO: namespace: e2e-tests-replication-controller-2wvth, resource: bindings, ignored listing per whitelist
Aug 14 22:42:28.503: INFO: namespace e2e-tests-replication-controller-2wvth deletion completed in 8.704290891s

• [SLOW TEST:14.283 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:42:28.503: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-njmr4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 14 22:42:33.683: INFO: Successfully updated pod "annotationupdatecba3dcac-bee4-11e9-9404-ee44c4277148"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:42:35.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-njmr4" for this suite.
Aug 14 22:42:59.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:43:00.076: INFO: namespace: e2e-tests-projected-njmr4, resource: bindings, ignored listing per whitelist
Aug 14 22:43:00.542: INFO: namespace e2e-tests-projected-njmr4 deletion completed in 24.769536132s

• [SLOW TEST:32.039 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:43:00.543: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dk94l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Aug 14 22:43:01.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 --namespace=e2e-tests-kubectl-dk94l run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 14 22:43:04.535: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 14 22:43:04.535: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:43:06.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dk94l" for this suite.
Aug 14 22:43:14.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:43:15.085: INFO: namespace: e2e-tests-kubectl-dk94l, resource: bindings, ignored listing per whitelist
Aug 14 22:43:15.396: INFO: namespace e2e-tests-kubectl-dk94l deletion completed in 8.785896359s

• [SLOW TEST:14.853 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:43:15.396: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-n58qg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-n58qg.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-n58qg.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-n58qg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-n58qg.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-n58qg.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-n58qg.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 22:43:26.461: INFO: DNS probes using e2e-tests-dns-n58qg/dns-test-e797fe21-bee4-11e9-9404-ee44c4277148 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:43:26.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-n58qg" for this suite.
Aug 14 22:43:34.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:43:35.025: INFO: namespace: e2e-tests-dns-n58qg, resource: bindings, ignored listing per whitelist
Aug 14 22:43:35.177: INFO: namespace e2e-tests-dns-n58qg deletion completed in 8.632710666s

• [SLOW TEST:19.781 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:43:35.178: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sxg5q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f35d13ac-bee4-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume configMaps
Aug 14 22:43:35.676: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f35f9f2d-bee4-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-sxg5q" to be "success or failure"
Aug 14 22:43:35.691: INFO: Pod "pod-projected-configmaps-f35f9f2d-bee4-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 15.675948ms
Aug 14 22:43:37.710: INFO: Pod "pod-projected-configmaps-f35f9f2d-bee4-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03446267s
STEP: Saw pod success
Aug 14 22:43:37.710: INFO: Pod "pod-projected-configmaps-f35f9f2d-bee4-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:43:37.726: INFO: Trying to get logs from node 10.209.12.141 pod pod-projected-configmaps-f35f9f2d-bee4-11e9-9404-ee44c4277148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 22:43:37.809: INFO: Waiting for pod pod-projected-configmaps-f35f9f2d-bee4-11e9-9404-ee44c4277148 to disappear
Aug 14 22:43:37.826: INFO: Pod pod-projected-configmaps-f35f9f2d-bee4-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:43:37.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sxg5q" for this suite.
Aug 14 22:43:45.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:43:46.597: INFO: namespace: e2e-tests-projected-sxg5q, resource: bindings, ignored listing per whitelist
Aug 14 22:43:46.716: INFO: namespace e2e-tests-projected-sxg5q deletion completed in 8.867442431s

• [SLOW TEST:11.539 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:43:46.718: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-994w4
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-fa49e05b-bee4-11e9-9404-ee44c4277148
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:43:51.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-994w4" for this suite.
Aug 14 22:44:15.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:44:16.081: INFO: namespace: e2e-tests-configmap-994w4, resource: bindings, ignored listing per whitelist
Aug 14 22:44:16.155: INFO: namespace e2e-tests-configmap-994w4 deletion completed in 24.664005197s

• [SLOW TEST:29.437 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:44:16.155: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-4m7vc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:44:18.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-4m7vc" for this suite.
Aug 14 22:45:01.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:45:01.110: INFO: namespace: e2e-tests-kubelet-test-4m7vc, resource: bindings, ignored listing per whitelist
Aug 14 22:45:01.641: INFO: namespace e2e-tests-kubelet-test-4m7vc deletion completed in 42.685300568s

• [SLOW TEST:45.486 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:45:01.642: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-9hdnf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 14 22:45:08.280: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:08.280: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:08.609: INFO: Exec stderr: ""
Aug 14 22:45:08.609: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:08.609: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:08.991: INFO: Exec stderr: ""
Aug 14 22:45:08.991: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:08.991: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:09.296: INFO: Exec stderr: ""
Aug 14 22:45:09.297: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:09.297: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:09.690: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 14 22:45:09.691: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:09.691: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:10.016: INFO: Exec stderr: ""
Aug 14 22:45:10.016: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:10.016: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:10.396: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 14 22:45:10.396: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:10.396: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:10.714: INFO: Exec stderr: ""
Aug 14 22:45:10.714: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:10.714: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:11.098: INFO: Exec stderr: ""
Aug 14 22:45:11.098: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:11.099: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:11.511: INFO: Exec stderr: ""
Aug 14 22:45:11.512: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9hdnf PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 22:45:11.512: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
Aug 14 22:45:12.191: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:45:12.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-9hdnf" for this suite.
Aug 14 22:45:56.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:45:56.998: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-9hdnf, resource: bindings, ignored listing per whitelist
Aug 14 22:45:57.322: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-9hdnf deletion completed in 45.03041139s

• [SLOW TEST:55.681 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:45:57.322: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-k9r6r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:45:58.028: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4837c1db-bee5-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-k9r6r" to be "success or failure"
Aug 14 22:45:58.051: INFO: Pod "downwardapi-volume-4837c1db-bee5-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 22.781126ms
Aug 14 22:46:00.073: INFO: Pod "downwardapi-volume-4837c1db-bee5-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.044691126s
Aug 14 22:46:02.091: INFO: Pod "downwardapi-volume-4837c1db-bee5-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062920337s
STEP: Saw pod success
Aug 14 22:46:02.091: INFO: Pod "downwardapi-volume-4837c1db-bee5-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:46:02.109: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-4837c1db-bee5-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:46:02.246: INFO: Waiting for pod downwardapi-volume-4837c1db-bee5-11e9-9404-ee44c4277148 to disappear
Aug 14 22:46:02.264: INFO: Pod downwardapi-volume-4837c1db-bee5-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:46:02.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k9r6r" for this suite.
Aug 14 22:46:10.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:46:10.546: INFO: namespace: e2e-tests-projected-k9r6r, resource: bindings, ignored listing per whitelist
Aug 14 22:46:11.118: INFO: namespace e2e-tests-projected-k9r6r deletion completed in 8.828613817s

• [SLOW TEST:13.796 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:46:11.118: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-7mpz8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-gdmr
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 22:46:11.707: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gdmr" in namespace "e2e-tests-subpath-7mpz8" to be "success or failure"
Aug 14 22:46:11.727: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Pending", Reason="", readiness=false. Elapsed: 19.853069ms
Aug 14 22:46:13.743: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03601293s
Aug 14 22:46:15.759: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 4.052114704s
Aug 14 22:46:17.778: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 6.071296097s
Aug 14 22:46:19.814: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 8.10664698s
Aug 14 22:46:21.833: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 10.125943466s
Aug 14 22:46:24.035: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 12.32808433s
Aug 14 22:46:26.053: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 14.346237269s
Aug 14 22:46:28.068: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 16.36125887s
Aug 14 22:46:30.106: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 18.398668576s
Aug 14 22:46:32.127: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 20.419740015s
Aug 14 22:46:34.147: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Running", Reason="", readiness=false. Elapsed: 22.439826437s
Aug 14 22:46:36.163: INFO: Pod "pod-subpath-test-configmap-gdmr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.456218822s
STEP: Saw pod success
Aug 14 22:46:36.163: INFO: Pod "pod-subpath-test-configmap-gdmr" satisfied condition "success or failure"
Aug 14 22:46:36.205: INFO: Trying to get logs from node 10.209.12.141 pod pod-subpath-test-configmap-gdmr container test-container-subpath-configmap-gdmr: <nil>
STEP: delete the pod
Aug 14 22:46:36.292: INFO: Waiting for pod pod-subpath-test-configmap-gdmr to disappear
Aug 14 22:46:36.306: INFO: Pod pod-subpath-test-configmap-gdmr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gdmr
Aug 14 22:46:36.306: INFO: Deleting pod "pod-subpath-test-configmap-gdmr" in namespace "e2e-tests-subpath-7mpz8"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:46:36.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7mpz8" for this suite.
Aug 14 22:46:44.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:46:44.770: INFO: namespace: e2e-tests-subpath-7mpz8, resource: bindings, ignored listing per whitelist
Aug 14 22:46:45.091: INFO: namespace e2e-tests-subpath-7mpz8 deletion completed in 8.741478741s

• [SLOW TEST:33.973 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:46:45.093: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k7q4v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug 14 22:46:45.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:45.916: INFO: stderr: ""
Aug 14 22:46:45.916: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:46:45.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:46.048: INFO: stderr: ""
Aug 14 22:46:46.048: INFO: stdout: "update-demo-nautilus-pk62c update-demo-nautilus-rmdrl "
Aug 14 22:46:46.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-pk62c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:46.181: INFO: stderr: ""
Aug 14 22:46:46.181: INFO: stdout: ""
Aug 14 22:46:46.181: INFO: update-demo-nautilus-pk62c is created but not running
Aug 14 22:46:51.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:51.428: INFO: stderr: ""
Aug 14 22:46:51.428: INFO: stdout: "update-demo-nautilus-pk62c update-demo-nautilus-rmdrl "
Aug 14 22:46:51.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-pk62c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:51.568: INFO: stderr: ""
Aug 14 22:46:51.568: INFO: stdout: "true"
Aug 14 22:46:51.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-pk62c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:51.696: INFO: stderr: ""
Aug 14 22:46:51.696: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:46:51.696: INFO: validating pod update-demo-nautilus-pk62c
Aug 14 22:46:51.730: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:46:51.730: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:46:51.730: INFO: update-demo-nautilus-pk62c is verified up and running
Aug 14 22:46:51.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-rmdrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:51.892: INFO: stderr: ""
Aug 14 22:46:51.892: INFO: stdout: "true"
Aug 14 22:46:51.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-rmdrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:52.023: INFO: stderr: ""
Aug 14 22:46:52.023: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:46:52.023: INFO: validating pod update-demo-nautilus-rmdrl
Aug 14 22:46:52.054: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:46:52.054: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:46:52.054: INFO: update-demo-nautilus-rmdrl is verified up and running
STEP: scaling down the replication controller
Aug 14 22:46:52.055: INFO: scanned /root for discovery docs: <nil>
Aug 14 22:46:52.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:53.287: INFO: stderr: ""
Aug 14 22:46:53.287: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:46:53.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:53.427: INFO: stderr: ""
Aug 14 22:46:53.427: INFO: stdout: "update-demo-nautilus-pk62c update-demo-nautilus-rmdrl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 14 22:46:58.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:46:58.567: INFO: stderr: ""
Aug 14 22:46:58.567: INFO: stdout: "update-demo-nautilus-pk62c update-demo-nautilus-rmdrl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 14 22:47:03.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:03.700: INFO: stderr: ""
Aug 14 22:47:03.701: INFO: stdout: "update-demo-nautilus-pk62c update-demo-nautilus-rmdrl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 14 22:47:08.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:08.903: INFO: stderr: ""
Aug 14 22:47:08.903: INFO: stdout: "update-demo-nautilus-pk62c "
Aug 14 22:47:08.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-pk62c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:09.010: INFO: stderr: ""
Aug 14 22:47:09.010: INFO: stdout: "true"
Aug 14 22:47:09.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-pk62c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:09.147: INFO: stderr: ""
Aug 14 22:47:09.147: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:47:09.147: INFO: validating pod update-demo-nautilus-pk62c
Aug 14 22:47:09.174: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:47:09.174: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:47:09.174: INFO: update-demo-nautilus-pk62c is verified up and running
STEP: scaling up the replication controller
Aug 14 22:47:09.176: INFO: scanned /root for discovery docs: <nil>
Aug 14 22:47:09.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:10.391: INFO: stderr: ""
Aug 14 22:47:10.391: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:47:10.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:10.558: INFO: stderr: ""
Aug 14 22:47:10.558: INFO: stdout: "update-demo-nautilus-klbnm update-demo-nautilus-pk62c "
Aug 14 22:47:10.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-klbnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:10.669: INFO: stderr: ""
Aug 14 22:47:10.669: INFO: stdout: ""
Aug 14 22:47:10.669: INFO: update-demo-nautilus-klbnm is created but not running
Aug 14 22:47:15.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:15.800: INFO: stderr: ""
Aug 14 22:47:15.800: INFO: stdout: "update-demo-nautilus-klbnm update-demo-nautilus-pk62c "
Aug 14 22:47:15.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-klbnm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:15.912: INFO: stderr: ""
Aug 14 22:47:15.912: INFO: stdout: "true"
Aug 14 22:47:15.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-klbnm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:16.019: INFO: stderr: ""
Aug 14 22:47:16.020: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:47:16.020: INFO: validating pod update-demo-nautilus-klbnm
Aug 14 22:47:16.053: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:47:16.053: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:47:16.053: INFO: update-demo-nautilus-klbnm is verified up and running
Aug 14 22:47:16.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-pk62c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:16.256: INFO: stderr: ""
Aug 14 22:47:16.256: INFO: stdout: "true"
Aug 14 22:47:16.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-pk62c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:16.411: INFO: stderr: ""
Aug 14 22:47:16.411: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:47:16.411: INFO: validating pod update-demo-nautilus-pk62c
Aug 14 22:47:16.432: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:47:16.432: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:47:16.432: INFO: update-demo-nautilus-pk62c is verified up and running
STEP: using delete to clean up resources
Aug 14 22:47:16.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:16.584: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:47:16.584: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 14 22:47:16.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-k7q4v'
Aug 14 22:47:16.753: INFO: stderr: "No resources found.\n"
Aug 14 22:47:16.753: INFO: stdout: ""
Aug 14 22:47:16.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -l name=update-demo --namespace=e2e-tests-kubectl-k7q4v -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 22:47:16.882: INFO: stderr: ""
Aug 14 22:47:16.882: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:47:16.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k7q4v" for this suite.
Aug 14 22:47:40.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:47:41.368: INFO: namespace: e2e-tests-kubectl-k7q4v, resource: bindings, ignored listing per whitelist
Aug 14 22:47:41.662: INFO: namespace e2e-tests-kubectl-k7q4v deletion completed in 24.754216504s

• [SLOW TEST:56.569 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:47:41.663: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-wk5gn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:47:42.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-wk5gn" for this suite.
Aug 14 22:47:50.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:47:50.707: INFO: namespace: e2e-tests-services-wk5gn, resource: bindings, ignored listing per whitelist
Aug 14 22:47:50.891: INFO: namespace e2e-tests-services-wk5gn deletion completed in 8.676137048s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:9.229 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:47:50.892: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s4tvq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-8bdb2ae9-bee5-11e9-9404-ee44c4277148
STEP: Creating a pod to test consume secrets
Aug 14 22:47:51.519: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8bde6d6b-bee5-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-s4tvq" to be "success or failure"
Aug 14 22:47:51.539: INFO: Pod "pod-projected-secrets-8bde6d6b-bee5-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.600962ms
Aug 14 22:47:53.555: INFO: Pod "pod-projected-secrets-8bde6d6b-bee5-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035751381s
Aug 14 22:47:55.591: INFO: Pod "pod-projected-secrets-8bde6d6b-bee5-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071460239s
STEP: Saw pod success
Aug 14 22:47:55.591: INFO: Pod "pod-projected-secrets-8bde6d6b-bee5-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:47:55.605: INFO: Trying to get logs from node 10.73.228.4 pod pod-projected-secrets-8bde6d6b-bee5-11e9-9404-ee44c4277148 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 22:47:55.704: INFO: Waiting for pod pod-projected-secrets-8bde6d6b-bee5-11e9-9404-ee44c4277148 to disappear
Aug 14 22:47:55.720: INFO: Pod pod-projected-secrets-8bde6d6b-bee5-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:47:55.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s4tvq" for this suite.
Aug 14 22:48:03.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:48:04.170: INFO: namespace: e2e-tests-projected-s4tvq, resource: bindings, ignored listing per whitelist
Aug 14 22:48:04.342: INFO: namespace e2e-tests-projected-s4tvq deletion completed in 8.601215761s

• [SLOW TEST:13.451 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:48:04.343: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-zb7jx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:48:08.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-zb7jx" for this suite.
Aug 14 22:48:16.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:48:17.037: INFO: namespace: e2e-tests-kubelet-test-zb7jx, resource: bindings, ignored listing per whitelist
Aug 14 22:48:17.696: INFO: namespace e2e-tests-kubelet-test-zb7jx deletion completed in 8.805792681s

• [SLOW TEST:13.353 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:48:17.696: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-bswtp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 14 22:48:18.201: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:48:21.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bswtp" for this suite.
Aug 14 22:48:29.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:48:30.221: INFO: namespace: e2e-tests-init-container-bswtp, resource: bindings, ignored listing per whitelist
Aug 14 22:48:30.637: INFO: namespace e2e-tests-init-container-bswtp deletion completed in 8.739745322s

• [SLOW TEST:12.940 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:48:30.637: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-968ln
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 14 22:48:34.072: INFO: Successfully updated pod "pod-update-a38a31b1-bee5-11e9-9404-ee44c4277148"
STEP: verifying the updated pod is in kubernetes
Aug 14 22:48:34.127: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:48:34.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-968ln" for this suite.
Aug 14 22:48:58.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:48:58.635: INFO: namespace: e2e-tests-pods-968ln, resource: bindings, ignored listing per whitelist
Aug 14 22:48:59.016: INFO: namespace e2e-tests-pods-968ln deletion completed in 24.866368275s

• [SLOW TEST:28.380 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:48:59.020: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-lqz9s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:49:25.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-lqz9s" for this suite.
Aug 14 22:49:33.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:49:33.996: INFO: namespace: e2e-tests-container-runtime-lqz9s, resource: bindings, ignored listing per whitelist
Aug 14 22:49:34.091: INFO: namespace e2e-tests-container-runtime-lqz9s deletion completed in 8.952586977s

• [SLOW TEST:35.072 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:49:34.091: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-xbjff
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Aug 14 22:49:34.732: INFO: Waiting up to 5m0s for pod "var-expansion-c9625bfe-bee5-11e9-9404-ee44c4277148" in namespace "e2e-tests-var-expansion-xbjff" to be "success or failure"
Aug 14 22:49:34.854: INFO: Pod "var-expansion-c9625bfe-bee5-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 122.483192ms
Aug 14 22:49:36.893: INFO: Pod "var-expansion-c9625bfe-bee5-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.160735088s
Aug 14 22:49:38.909: INFO: Pod "var-expansion-c9625bfe-bee5-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.177352257s
STEP: Saw pod success
Aug 14 22:49:38.909: INFO: Pod "var-expansion-c9625bfe-bee5-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:49:38.991: INFO: Trying to get logs from node 10.73.228.2 pod var-expansion-c9625bfe-bee5-11e9-9404-ee44c4277148 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:49:39.076: INFO: Waiting for pod var-expansion-c9625bfe-bee5-11e9-9404-ee44c4277148 to disappear
Aug 14 22:49:39.091: INFO: Pod var-expansion-c9625bfe-bee5-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:49:39.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-xbjff" for this suite.
Aug 14 22:49:45.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:49:45.662: INFO: namespace: e2e-tests-var-expansion-xbjff, resource: bindings, ignored listing per whitelist
Aug 14 22:49:45.841: INFO: namespace e2e-tests-var-expansion-xbjff deletion completed in 6.696343696s

• [SLOW TEST:11.750 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:49:45.841: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cdtnx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:49:46.330: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d04a3f97-bee5-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-cdtnx" to be "success or failure"
Aug 14 22:49:46.350: INFO: Pod "downwardapi-volume-d04a3f97-bee5-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.890537ms
Aug 14 22:49:48.387: INFO: Pod "downwardapi-volume-d04a3f97-bee5-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056933886s
STEP: Saw pod success
Aug 14 22:49:48.387: INFO: Pod "downwardapi-volume-d04a3f97-bee5-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:49:48.401: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-d04a3f97-bee5-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:49:48.488: INFO: Waiting for pod downwardapi-volume-d04a3f97-bee5-11e9-9404-ee44c4277148 to disappear
Aug 14 22:49:48.505: INFO: Pod downwardapi-volume-d04a3f97-bee5-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:49:48.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cdtnx" for this suite.
Aug 14 22:49:56.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:49:57.011: INFO: namespace: e2e-tests-downward-api-cdtnx, resource: bindings, ignored listing per whitelist
Aug 14 22:49:57.241: INFO: namespace e2e-tests-downward-api-cdtnx deletion completed in 8.705225884s

• [SLOW TEST:11.399 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:49:57.241: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qbp7h
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 14 22:49:57.710: INFO: Waiting up to 5m0s for pod "pod-d715a639-bee5-11e9-9404-ee44c4277148" in namespace "e2e-tests-emptydir-qbp7h" to be "success or failure"
Aug 14 22:49:57.724: INFO: Pod "pod-d715a639-bee5-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 13.840484ms
Aug 14 22:49:59.756: INFO: Pod "pod-d715a639-bee5-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045892703s
Aug 14 22:50:01.772: INFO: Pod "pod-d715a639-bee5-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062137688s
STEP: Saw pod success
Aug 14 22:50:01.772: INFO: Pod "pod-d715a639-bee5-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:50:01.807: INFO: Trying to get logs from node 10.73.228.4 pod pod-d715a639-bee5-11e9-9404-ee44c4277148 container test-container: <nil>
STEP: delete the pod
Aug 14 22:50:01.910: INFO: Waiting for pod pod-d715a639-bee5-11e9-9404-ee44c4277148 to disappear
Aug 14 22:50:01.926: INFO: Pod pod-d715a639-bee5-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:50:01.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qbp7h" for this suite.
Aug 14 22:50:08.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:50:08.732: INFO: namespace: e2e-tests-emptydir-qbp7h, resource: bindings, ignored listing per whitelist
Aug 14 22:50:08.819: INFO: namespace e2e-tests-emptydir-qbp7h deletion completed in 6.871225183s

• [SLOW TEST:11.578 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:50:08.820: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-59nxb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-59nxb A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-59nxb;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-59nxb A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-59nxb.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-59nxb.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-59nxb.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-59nxb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-59nxb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-59nxb.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-59nxb.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-59nxb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 246.169.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.169.246_udp@PTR;check="$$(dig +tcp +noall +answer +search 246.169.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.169.246_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-59nxb A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-59nxb;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-59nxb A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-59nxb;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-59nxb.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-59nxb.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-59nxb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-59nxb.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-59nxb.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-59nxb.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-59nxb.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 246.169.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.169.246_udp@PTR;check="$$(dig +tcp +noall +answer +search 246.169.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.169.246_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 22:50:13.791: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:13.815: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:13.836: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:13.912: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:13.935: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.143: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.167: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.189: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.211: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.238: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.262: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.286: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.312: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:14.490: INFO: Lookups using e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-59nxb wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-59nxb jessie_tcp@dns-test-service.e2e-tests-dns-59nxb jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc]

Aug 14 22:50:19.516: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:19.542: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:19.567: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:19.713: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:19.750: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:19.935: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:19.966: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:19.987: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:20.010: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:20.031: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:20.052: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:20.079: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:20.104: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:20.265: INFO: Lookups using e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-59nxb wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-59nxb jessie_tcp@dns-test-service.e2e-tests-dns-59nxb jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc]

Aug 14 22:50:24.529: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.549: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.573: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.641: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.674: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.860: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.886: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.910: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.931: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.957: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:24.987: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:25.009: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:25.041: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:25.179: INFO: Lookups using e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-59nxb wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-59nxb jessie_tcp@dns-test-service.e2e-tests-dns-59nxb jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc]

Aug 14 22:50:29.511: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.532: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.552: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.617: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.640: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.825: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.846: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.868: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.889: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.909: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.931: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.955: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:29.976: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:30.107: INFO: Lookups using e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-59nxb wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-59nxb jessie_tcp@dns-test-service.e2e-tests-dns-59nxb jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc]

Aug 14 22:50:34.513: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.554: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.591: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.655: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.677: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.850: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.875: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.895: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.917: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.940: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.961: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:34.982: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:35.003: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:35.214: INFO: Lookups using e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-59nxb wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-59nxb jessie_tcp@dns-test-service.e2e-tests-dns-59nxb jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc]

Aug 14 22:50:39.520: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.540: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.566: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.691: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.713: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.893: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.918: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.942: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.972: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:39.995: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:40.091: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:40.125: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:40.165: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc from pod e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148: the server could not find the requested resource (get pods dns-test-de3955ff-bee5-11e9-9404-ee44c4277148)
Aug 14 22:50:40.360: INFO: Lookups using e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-59nxb wheezy_tcp@dns-test-service.e2e-tests-dns-59nxb.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-59nxb jessie_tcp@dns-test-service.e2e-tests-dns-59nxb jessie_udp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@dns-test-service.e2e-tests-dns-59nxb.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-59nxb.svc]

Aug 14 22:50:45.142: INFO: DNS probes using e2e-tests-dns-59nxb/dns-test-de3955ff-bee5-11e9-9404-ee44c4277148 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:50:45.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-59nxb" for this suite.
Aug 14 22:50:53.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:50:53.937: INFO: namespace: e2e-tests-dns-59nxb, resource: bindings, ignored listing per whitelist
Aug 14 22:50:54.124: INFO: namespace e2e-tests-dns-59nxb deletion completed in 8.756803334s

• [SLOW TEST:45.305 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:50:54.124: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4tc55
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 14 22:50:54.588: INFO: Waiting up to 5m0s for pod "downward-api-f8fc11cc-bee5-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-4tc55" to be "success or failure"
Aug 14 22:50:54.623: INFO: Pod "downward-api-f8fc11cc-bee5-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 34.58484ms
Aug 14 22:50:56.639: INFO: Pod "downward-api-f8fc11cc-bee5-11e9-9404-ee44c4277148": Phase="Running", Reason="", readiness=true. Elapsed: 2.050060301s
Aug 14 22:50:58.654: INFO: Pod "downward-api-f8fc11cc-bee5-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065345255s
STEP: Saw pod success
Aug 14 22:50:58.654: INFO: Pod "downward-api-f8fc11cc-bee5-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:50:58.705: INFO: Trying to get logs from node 10.209.12.141 pod downward-api-f8fc11cc-bee5-11e9-9404-ee44c4277148 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:50:58.791: INFO: Waiting for pod downward-api-f8fc11cc-bee5-11e9-9404-ee44c4277148 to disappear
Aug 14 22:50:58.805: INFO: Pod downward-api-f8fc11cc-bee5-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:50:58.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4tc55" for this suite.
Aug 14 22:51:06.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:51:07.637: INFO: namespace: e2e-tests-downward-api-4tc55, resource: bindings, ignored listing per whitelist
Aug 14 22:51:07.718: INFO: namespace e2e-tests-downward-api-4tc55 deletion completed in 8.88969639s

• [SLOW TEST:13.594 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:51:07.719: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rsgfb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 14 22:51:08.238: INFO: Waiting up to 5m0s for pod "downward-api-011e0b2d-bee6-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-rsgfb" to be "success or failure"
Aug 14 22:51:08.265: INFO: Pod "downward-api-011e0b2d-bee6-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 27.490123ms
Aug 14 22:51:10.285: INFO: Pod "downward-api-011e0b2d-bee6-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047087911s
STEP: Saw pod success
Aug 14 22:51:10.285: INFO: Pod "downward-api-011e0b2d-bee6-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:51:10.309: INFO: Trying to get logs from node 10.73.228.4 pod downward-api-011e0b2d-bee6-11e9-9404-ee44c4277148 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:51:10.419: INFO: Waiting for pod downward-api-011e0b2d-bee6-11e9-9404-ee44c4277148 to disappear
Aug 14 22:51:10.444: INFO: Pod downward-api-011e0b2d-bee6-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:51:10.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rsgfb" for this suite.
Aug 14 22:51:18.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:51:19.053: INFO: namespace: e2e-tests-downward-api-rsgfb, resource: bindings, ignored listing per whitelist
Aug 14 22:51:19.330: INFO: namespace e2e-tests-downward-api-rsgfb deletion completed in 8.862856348s

• [SLOW TEST:11.611 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:51:19.330: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-g5trf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:51:19.924: INFO: (0) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 33.142387ms)
Aug 14 22:51:19.950: INFO: (1) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.655119ms)
Aug 14 22:51:19.972: INFO: (2) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.123102ms)
Aug 14 22:51:19.994: INFO: (3) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.321157ms)
Aug 14 22:51:20.016: INFO: (4) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.294147ms)
Aug 14 22:51:20.039: INFO: (5) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 23.09765ms)
Aug 14 22:51:20.063: INFO: (6) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.219346ms)
Aug 14 22:51:20.088: INFO: (7) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.40519ms)
Aug 14 22:51:20.122: INFO: (8) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 34.065726ms)
Aug 14 22:51:20.155: INFO: (9) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 32.822592ms)
Aug 14 22:51:20.184: INFO: (10) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 29.206006ms)
Aug 14 22:51:20.220: INFO: (11) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 35.503012ms)
Aug 14 22:51:20.248: INFO: (12) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 28.18768ms)
Aug 14 22:51:20.273: INFO: (13) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.856966ms)
Aug 14 22:51:20.297: INFO: (14) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.569004ms)
Aug 14 22:51:20.324: INFO: (15) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 27.056853ms)
Aug 14 22:51:20.345: INFO: (16) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.978213ms)
Aug 14 22:51:20.368: INFO: (17) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.563122ms)
Aug 14 22:51:20.390: INFO: (18) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.775121ms)
Aug 14 22:51:20.413: INFO: (19) /api/v1/nodes/10.209.12.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.495688ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:51:20.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-g5trf" for this suite.
Aug 14 22:51:26.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:51:26.741: INFO: namespace: e2e-tests-proxy-g5trf, resource: bindings, ignored listing per whitelist
Aug 14 22:51:27.178: INFO: namespace e2e-tests-proxy-g5trf deletion completed in 6.733888382s

• [SLOW TEST:7.848 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:51:27.179: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cmnxv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:51:27.636: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0caf3119-bee6-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-cmnxv" to be "success or failure"
Aug 14 22:51:27.655: INFO: Pod "downwardapi-volume-0caf3119-bee6-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 19.127411ms
Aug 14 22:51:29.673: INFO: Pod "downwardapi-volume-0caf3119-bee6-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037317007s
STEP: Saw pod success
Aug 14 22:51:29.673: INFO: Pod "downwardapi-volume-0caf3119-bee6-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:51:29.689: INFO: Trying to get logs from node 10.73.228.2 pod downwardapi-volume-0caf3119-bee6-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:51:29.770: INFO: Waiting for pod downwardapi-volume-0caf3119-bee6-11e9-9404-ee44c4277148 to disappear
Aug 14 22:51:29.786: INFO: Pod downwardapi-volume-0caf3119-bee6-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:51:29.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cmnxv" for this suite.
Aug 14 22:51:35.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:51:36.334: INFO: namespace: e2e-tests-downward-api-cmnxv, resource: bindings, ignored listing per whitelist
Aug 14 22:51:36.471: INFO: namespace e2e-tests-downward-api-cmnxv deletion completed in 6.656384276s

• [SLOW TEST:9.292 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:51:36.471: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-j2gs2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 14 22:51:44.076: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:51:44.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-j2gs2" for this suite.
Aug 14 22:52:08.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:52:08.850: INFO: namespace: e2e-tests-replicaset-j2gs2, resource: bindings, ignored listing per whitelist
Aug 14 22:52:08.936: INFO: namespace e2e-tests-replicaset-j2gs2 deletion completed in 24.70188125s

• [SLOW TEST:32.465 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:52:08.936: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-knm8x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 14 22:52:09.417: INFO: Waiting up to 5m0s for pod "downward-api-25961d93-bee6-11e9-9404-ee44c4277148" in namespace "e2e-tests-downward-api-knm8x" to be "success or failure"
Aug 14 22:52:09.436: INFO: Pod "downward-api-25961d93-bee6-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 18.32801ms
Aug 14 22:52:11.469: INFO: Pod "downward-api-25961d93-bee6-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051377396s
STEP: Saw pod success
Aug 14 22:52:11.469: INFO: Pod "downward-api-25961d93-bee6-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:52:11.487: INFO: Trying to get logs from node 10.73.228.2 pod downward-api-25961d93-bee6-11e9-9404-ee44c4277148 container dapi-container: <nil>
STEP: delete the pod
Aug 14 22:52:11.595: INFO: Waiting for pod downward-api-25961d93-bee6-11e9-9404-ee44c4277148 to disappear
Aug 14 22:52:11.611: INFO: Pod downward-api-25961d93-bee6-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:52:11.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-knm8x" for this suite.
Aug 14 22:52:19.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:52:20.275: INFO: namespace: e2e-tests-downward-api-knm8x, resource: bindings, ignored listing per whitelist
Aug 14 22:52:20.453: INFO: namespace e2e-tests-downward-api-knm8x deletion completed in 8.817574682s

• [SLOW TEST:11.517 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:52:20.454: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-gk4sc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-gk4sc
Aug 14 22:52:24.998: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-gk4sc
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 22:52:25.015: INFO: Initial restart count of pod liveness-exec is 0
Aug 14 22:53:15.556: INFO: Restart count of pod e2e-tests-container-probe-gk4sc/liveness-exec is now 1 (50.541763095s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:53:15.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gk4sc" for this suite.
Aug 14 22:53:23.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:53:23.961: INFO: namespace: e2e-tests-container-probe-gk4sc, resource: bindings, ignored listing per whitelist
Aug 14 22:53:24.448: INFO: namespace e2e-tests-container-probe-gk4sc deletion completed in 8.757581377s

• [SLOW TEST:63.995 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:53:24.449: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-cqg8r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 14 22:53:24.890: INFO: PodSpec: initContainers in spec.initContainers
Aug 14 22:54:13.680: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-529717ef-bee6-11e9-9404-ee44c4277148", GenerateName:"", Namespace:"e2e-tests-init-container-cqg8r", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-cqg8r/pods/pod-init-529717ef-bee6-11e9-9404-ee44c4277148", UID:"52989dfa-bee6-11e9-a2b3-62a1b681b4a5", ResourceVersion:"42645", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63701420004, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"890013762"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-86xvn", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001b7aa00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-86xvn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-86xvn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-86xvn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0019d0c28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.73.228.4", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001960180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0019d0cb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0019d0cd0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0019d0cd8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0019d0cdc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420004, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420004, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420004, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701420004, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.73.228.4", PodIP:"172.30.126.104", StartTime:(*v1.Time)(0xc002d021c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002d2bd0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002d2cb0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://60b2214b052f32286f53eac8c2b1bfedcb29c00e77c32fd656cb14053679e441"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002d02200), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002d021e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:54:13.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-cqg8r" for this suite.
Aug 14 22:54:37.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:54:37.924: INFO: namespace: e2e-tests-init-container-cqg8r, resource: bindings, ignored listing per whitelist
Aug 14 22:54:38.369: INFO: namespace e2e-tests-init-container-cqg8r deletion completed in 24.617543251s

• [SLOW TEST:73.920 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:54:38.371: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ccnkz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug 14 22:54:38.802: INFO: namespace e2e-tests-kubectl-ccnkz
Aug 14 22:54:38.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-ccnkz'
Aug 14 22:54:39.365: INFO: stderr: ""
Aug 14 22:54:39.365: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 22:54:40.381: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:54:40.381: INFO: Found 0 / 1
Aug 14 22:54:41.383: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:54:41.383: INFO: Found 0 / 1
Aug 14 22:54:42.381: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:54:42.381: INFO: Found 1 / 1
Aug 14 22:54:42.381: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 22:54:42.398: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 22:54:42.398: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 22:54:42.398: INFO: wait on redis-master startup in e2e-tests-kubectl-ccnkz 
Aug 14 22:54:42.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 logs redis-master-m66jd redis-master --namespace=e2e-tests-kubectl-ccnkz'
Aug 14 22:54:42.557: INFO: stderr: ""
Aug 14 22:54:42.557: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 22:54:40.986 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 22:54:40.986 # Server started, Redis version 3.2.12\n1:M 14 Aug 22:54:40.986 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 22:54:40.986 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 14 22:54:42.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-ccnkz'
Aug 14 22:54:42.708: INFO: stderr: ""
Aug 14 22:54:42.708: INFO: stdout: "service/rm2 exposed\n"
Aug 14 22:54:42.721: INFO: Service rm2 in namespace e2e-tests-kubectl-ccnkz found.
STEP: exposing service
Aug 14 22:54:44.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-ccnkz'
Aug 14 22:54:44.999: INFO: stderr: ""
Aug 14 22:54:44.999: INFO: stdout: "service/rm3 exposed\n"
Aug 14 22:54:45.015: INFO: Service rm3 in namespace e2e-tests-kubectl-ccnkz found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:54:47.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ccnkz" for this suite.
Aug 14 22:55:11.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:55:12.002: INFO: namespace: e2e-tests-kubectl-ccnkz, resource: bindings, ignored listing per whitelist
Aug 14 22:55:12.218: INFO: namespace e2e-tests-kubectl-ccnkz deletion completed in 25.133850225s

• [SLOW TEST:33.847 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:55:12.218: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fkg85
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 14 22:55:12.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92d5f0b1-bee6-11e9-9404-ee44c4277148" in namespace "e2e-tests-projected-fkg85" to be "success or failure"
Aug 14 22:55:12.719: INFO: Pod "downwardapi-volume-92d5f0b1-bee6-11e9-9404-ee44c4277148": Phase="Pending", Reason="", readiness=false. Elapsed: 14.168196ms
Aug 14 22:55:14.735: INFO: Pod "downwardapi-volume-92d5f0b1-bee6-11e9-9404-ee44c4277148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029895669s
STEP: Saw pod success
Aug 14 22:55:14.735: INFO: Pod "downwardapi-volume-92d5f0b1-bee6-11e9-9404-ee44c4277148" satisfied condition "success or failure"
Aug 14 22:55:14.749: INFO: Trying to get logs from node 10.209.12.141 pod downwardapi-volume-92d5f0b1-bee6-11e9-9404-ee44c4277148 container client-container: <nil>
STEP: delete the pod
Aug 14 22:55:14.835: INFO: Waiting for pod downwardapi-volume-92d5f0b1-bee6-11e9-9404-ee44c4277148 to disappear
Aug 14 22:55:14.850: INFO: Pod downwardapi-volume-92d5f0b1-bee6-11e9-9404-ee44c4277148 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:55:14.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fkg85" for this suite.
Aug 14 22:55:22.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:55:23.615: INFO: namespace: e2e-tests-projected-fkg85, resource: bindings, ignored listing per whitelist
Aug 14 22:55:23.762: INFO: namespace e2e-tests-projected-fkg85 deletion completed in 8.890970289s

• [SLOW TEST:11.544 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:55:23.764: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-4gbkf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:55:24.246: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:55:28.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4gbkf" for this suite.
Aug 14 22:56:18.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:56:18.749: INFO: namespace: e2e-tests-pods-4gbkf, resource: bindings, ignored listing per whitelist
Aug 14 22:56:19.114: INFO: namespace e2e-tests-pods-4gbkf deletion completed in 50.694794046s

• [SLOW TEST:55.351 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:56:19.115: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zg6v6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug 14 22:56:19.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 create -f - --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:19.795: INFO: stderr: ""
Aug 14 22:56:19.795: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 22:56:19.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:19.966: INFO: stderr: ""
Aug 14 22:56:19.966: INFO: stdout: "update-demo-nautilus-jjgg4 update-demo-nautilus-n6pfh "
Aug 14 22:56:19.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-jjgg4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:20.101: INFO: stderr: ""
Aug 14 22:56:20.101: INFO: stdout: ""
Aug 14 22:56:20.101: INFO: update-demo-nautilus-jjgg4 is created but not running
Aug 14 22:56:25.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:25.214: INFO: stderr: ""
Aug 14 22:56:25.214: INFO: stdout: "update-demo-nautilus-jjgg4 update-demo-nautilus-n6pfh "
Aug 14 22:56:25.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-jjgg4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:25.347: INFO: stderr: ""
Aug 14 22:56:25.347: INFO: stdout: "true"
Aug 14 22:56:25.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-jjgg4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:25.450: INFO: stderr: ""
Aug 14 22:56:25.450: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:56:25.450: INFO: validating pod update-demo-nautilus-jjgg4
Aug 14 22:56:25.481: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:56:25.481: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:56:25.481: INFO: update-demo-nautilus-jjgg4 is verified up and running
Aug 14 22:56:25.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-n6pfh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:25.604: INFO: stderr: ""
Aug 14 22:56:25.604: INFO: stdout: "true"
Aug 14 22:56:25.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods update-demo-nautilus-n6pfh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:25.721: INFO: stderr: ""
Aug 14 22:56:25.721: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 22:56:25.721: INFO: validating pod update-demo-nautilus-n6pfh
Aug 14 22:56:25.753: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 22:56:25.754: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 22:56:25.754: INFO: update-demo-nautilus-n6pfh is verified up and running
STEP: using delete to clean up resources
Aug 14 22:56:25.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:25.930: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 22:56:25.930: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 14 22:56:25.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-zg6v6'
Aug 14 22:56:26.100: INFO: stderr: "No resources found.\n"
Aug 14 22:56:26.100: INFO: stdout: ""
Aug 14 22:56:26.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 get pods -l name=update-demo --namespace=e2e-tests-kubectl-zg6v6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 22:56:26.236: INFO: stderr: ""
Aug 14 22:56:26.236: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:56:26.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zg6v6" for this suite.
Aug 14 22:56:50.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:56:50.783: INFO: namespace: e2e-tests-kubectl-zg6v6, resource: bindings, ignored listing per whitelist
Aug 14 22:56:50.992: INFO: namespace e2e-tests-kubectl-zg6v6 deletion completed in 24.727734706s

• [SLOW TEST:31.877 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:56:50.992: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-w96bw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 14 22:56:51.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 version'
Aug 14 22:56:51.609: INFO: stderr: ""
Aug 14 22:56:51.609: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.9+IKS\", GitCommit:\"858a7bdfc1b3c9dd7a4a035e563a13eb87587de4\", GitTreeState:\"clean\", BuildDate:\"2019-08-07T11:03:12Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:56:51.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w96bw" for this suite.
Aug 14 22:56:59.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:57:00.276: INFO: namespace: e2e-tests-kubectl-w96bw, resource: bindings, ignored listing per whitelist
Aug 14 22:57:00.616: INFO: namespace e2e-tests-kubectl-w96bw deletion completed in 8.979243352s

• [SLOW TEST:9.624 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:57:00.618: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dkw6k
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d39ab895-bee6-11e9-9404-ee44c4277148
STEP: Creating configMap with name cm-test-opt-upd-d39ab8e9-bee6-11e9-9404-ee44c4277148
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d39ab895-bee6-11e9-9404-ee44c4277148
STEP: Updating configmap cm-test-opt-upd-d39ab8e9-bee6-11e9-9404-ee44c4277148
STEP: Creating configMap with name cm-test-opt-create-d39ab90b-bee6-11e9-9404-ee44c4277148
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:57:07.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dkw6k" for this suite.
Aug 14 22:57:31.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:57:32.060: INFO: namespace: e2e-tests-projected-dkw6k, resource: bindings, ignored listing per whitelist
Aug 14 22:57:32.592: INFO: namespace e2e-tests-projected-dkw6k deletion completed in 24.700920737s

• [SLOW TEST:31.974 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 14 22:57:32.592: INFO: >>> kubeConfig: /tmp/kubeconfig-371106957
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5dc5x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 22:57:33.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-5dc5x'
Aug 14 22:57:33.333: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 22:57:33.334: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 14 22:57:33.366: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-sgz2l]
Aug 14 22:57:33.366: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-sgz2l" in namespace "e2e-tests-kubectl-5dc5x" to be "running and ready"
Aug 14 22:57:33.385: INFO: Pod "e2e-test-nginx-rc-sgz2l": Phase="Pending", Reason="", readiness=false. Elapsed: 19.538129ms
Aug 14 22:57:35.414: INFO: Pod "e2e-test-nginx-rc-sgz2l": Phase="Running", Reason="", readiness=true. Elapsed: 2.047979539s
Aug 14 22:57:35.414: INFO: Pod "e2e-test-nginx-rc-sgz2l" satisfied condition "running and ready"
Aug 14 22:57:35.414: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-sgz2l]
Aug 14 22:57:35.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5dc5x'
Aug 14 22:57:35.595: INFO: stderr: ""
Aug 14 22:57:35.595: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Aug 14 22:57:35.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-371106957 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5dc5x'
Aug 14 22:57:35.750: INFO: stderr: ""
Aug 14 22:57:35.750: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 14 22:57:35.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5dc5x" for this suite.
Aug 14 22:57:43.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 22:57:44.039: INFO: namespace: e2e-tests-kubectl-5dc5x, resource: bindings, ignored listing per whitelist
Aug 14 22:57:44.568: INFO: namespace e2e-tests-kubectl-5dc5x deletion completed in 8.791980477s

• [SLOW TEST:11.976 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSAug 14 22:57:44.568: INFO: Running AfterSuite actions on all nodes
Aug 14 22:57:44.568: INFO: Running AfterSuite actions on node 1
Aug 14 22:57:44.568: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6343.636 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h45m44.608541226s
Test Suite Passed
