I1021 19:55:05.370553      16 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-571745635
I1021 19:55:05.370658      16 e2e.go:224] Starting e2e run "acd199f2-f43c-11e9-a616-8a530cf33301" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1571687704 - Will randomize all specs
Will run 201 of 1946 specs

Oct 21 19:55:05.558: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 19:55:05.561: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct 21 19:55:05.598: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct 21 19:55:05.672: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct 21 19:55:05.672: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Oct 21 19:55:05.672: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct 21 19:55:05.689: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Oct 21 19:55:05.689: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Oct 21 19:55:05.689: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Oct 21 19:55:05.689: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Oct 21 19:55:05.689: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Oct 21 19:55:05.689: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Oct 21 19:55:05.689: INFO: e2e test version: v1.13.0
Oct 21 19:55:05.692: INFO: kube-apiserver version: v1.13.12+IKS
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 19:55:05.692: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
Oct 21 19:55:05.957: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Oct 21 19:55:05.988: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-klrqj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 19:55:06.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-klrqj'
Oct 21 19:55:06.494: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 19:55:06.494: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Oct 21 19:55:06.504: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Oct 21 19:55:06.523: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct 21 19:55:06.534: INFO: scanned /root for discovery docs: <nil>
Oct 21 19:55:06.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-klrqj'
Oct 21 19:55:22.537: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 21 19:55:22.537: INFO: stdout: "Created e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c\nScaling up e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Oct 21 19:55:22.538: INFO: stdout: "Created e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c\nScaling up e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Oct 21 19:55:22.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-klrqj'
Oct 21 19:55:22.678: INFO: stderr: ""
Oct 21 19:55:22.678: INFO: stdout: "e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c-gbxq2 "
Oct 21 19:55:22.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c-gbxq2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-klrqj'
Oct 21 19:55:22.796: INFO: stderr: ""
Oct 21 19:55:22.796: INFO: stdout: "true"
Oct 21 19:55:22.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c-gbxq2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-klrqj'
Oct 21 19:55:22.931: INFO: stderr: ""
Oct 21 19:55:22.931: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Oct 21 19:55:22.931: INFO: e2e-test-nginx-rc-a405238f0f66d5d10be2d53ef840cc7c-gbxq2 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Oct 21 19:55:22.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-klrqj'
Oct 21 19:55:23.083: INFO: stderr: ""
Oct 21 19:55:23.083: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 19:55:23.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-klrqj" for this suite.
Oct 21 19:55:47.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 19:55:47.358: INFO: namespace: e2e-tests-kubectl-klrqj, resource: bindings, ignored listing per whitelist
Oct 21 19:55:47.387: INFO: namespace e2e-tests-kubectl-klrqj deletion completed in 24.291778163s

â€¢ [SLOW TEST:41.695 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 19:55:47.388: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-p2g4t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c68702fc-f43c-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 19:55:47.788: INFO: Waiting up to 5m0s for pod "pod-secrets-c68b25be-f43c-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-p2g4t" to be "success or failure"
Oct 21 19:55:47.795: INFO: Pod "pod-secrets-c68b25be-f43c-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.203765ms
Oct 21 19:55:49.802: INFO: Pod "pod-secrets-c68b25be-f43c-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013783709s
Oct 21 19:55:51.809: INFO: Pod "pod-secrets-c68b25be-f43c-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021031763s
STEP: Saw pod success
Oct 21 19:55:51.810: INFO: Pod "pod-secrets-c68b25be-f43c-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 19:55:51.817: INFO: Trying to get logs from node 10.170.151.145 pod pod-secrets-c68b25be-f43c-11e9-a616-8a530cf33301 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 19:55:51.855: INFO: Waiting for pod pod-secrets-c68b25be-f43c-11e9-a616-8a530cf33301 to disappear
Oct 21 19:55:51.861: INFO: Pod pod-secrets-c68b25be-f43c-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 19:55:51.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p2g4t" for this suite.
Oct 21 19:55:57.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 19:55:57.939: INFO: namespace: e2e-tests-secrets-p2g4t, resource: bindings, ignored listing per whitelist
Oct 21 19:55:58.308: INFO: namespace e2e-tests-secrets-p2g4t deletion completed in 6.434588164s

â€¢ [SLOW TEST:10.920 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 19:55:58.308: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-jjl9q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-jjl9q
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-jjl9q
STEP: Deleting pre-stop pod
Oct 21 19:56:11.721: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 19:56:11.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-jjl9q" for this suite.
Oct 21 19:56:51.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 19:56:51.821: INFO: namespace: e2e-tests-prestop-jjl9q, resource: bindings, ignored listing per whitelist
Oct 21 19:56:52.041: INFO: namespace e2e-tests-prestop-jjl9q deletion completed in 40.298866983s

â€¢ [SLOW TEST:53.733 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 19:56:52.041: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-nhn6h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ed08a358-f43c-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 19:56:52.376: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed0a23c7-f43c-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-nhn6h" to be "success or failure"
Oct 21 19:56:52.384: INFO: Pod "pod-configmaps-ed0a23c7-f43c-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.765973ms
Oct 21 19:56:54.395: INFO: Pod "pod-configmaps-ed0a23c7-f43c-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018663375s
STEP: Saw pod success
Oct 21 19:56:54.395: INFO: Pod "pod-configmaps-ed0a23c7-f43c-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 19:56:54.402: INFO: Trying to get logs from node 10.170.151.145 pod pod-configmaps-ed0a23c7-f43c-11e9-a616-8a530cf33301 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 19:56:54.438: INFO: Waiting for pod pod-configmaps-ed0a23c7-f43c-11e9-a616-8a530cf33301 to disappear
Oct 21 19:56:54.445: INFO: Pod pod-configmaps-ed0a23c7-f43c-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 19:56:54.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nhn6h" for this suite.
Oct 21 19:57:00.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 19:57:00.626: INFO: namespace: e2e-tests-configmap-nhn6h, resource: bindings, ignored listing per whitelist
Oct 21 19:57:00.803: INFO: namespace e2e-tests-configmap-nhn6h deletion completed in 6.347691664s

â€¢ [SLOW TEST:8.761 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 19:57:00.805: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7ffcn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 19:57:01.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f23f5150-f43c-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-7ffcn" to be "success or failure"
Oct 21 19:57:01.120: INFO: Pod "downwardapi-volume-f23f5150-f43c-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.727371ms
Oct 21 19:57:03.129: INFO: Pod "downwardapi-volume-f23f5150-f43c-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015179842s
Oct 21 19:57:05.137: INFO: Pod "downwardapi-volume-f23f5150-f43c-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023522162s
STEP: Saw pod success
Oct 21 19:57:05.137: INFO: Pod "downwardapi-volume-f23f5150-f43c-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 19:57:05.144: INFO: Trying to get logs from node 10.170.151.145 pod downwardapi-volume-f23f5150-f43c-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 19:57:05.308: INFO: Waiting for pod downwardapi-volume-f23f5150-f43c-11e9-a616-8a530cf33301 to disappear
Oct 21 19:57:05.315: INFO: Pod downwardapi-volume-f23f5150-f43c-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 19:57:05.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7ffcn" for this suite.
Oct 21 19:57:11.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 19:57:11.615: INFO: namespace: e2e-tests-projected-7ffcn, resource: bindings, ignored listing per whitelist
Oct 21 19:57:11.623: INFO: namespace e2e-tests-projected-7ffcn deletion completed in 6.298450396s

â€¢ [SLOW TEST:10.818 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 19:57:11.623: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-s7bcm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 19:57:11.977: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 19:57:12.003: INFO: Number of nodes with available pods: 0
Oct 21 19:57:12.003: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 19:57:13.022: INFO: Number of nodes with available pods: 0
Oct 21 19:57:13.022: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 19:57:14.021: INFO: Number of nodes with available pods: 0
Oct 21 19:57:14.021: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 19:57:15.022: INFO: Number of nodes with available pods: 3
Oct 21 19:57:15.022: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct 21 19:57:15.071: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:15.071: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:15.071: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:16.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:16.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:16.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:17.103: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:17.103: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:17.103: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:18.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:18.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:18.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:19.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:19.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:19.088: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:20.093: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:20.093: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:20.093: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:21.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:21.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:21.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:22.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:22.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:22.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:23.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:23.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:23.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:24.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:24.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:24.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:25.112: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:25.112: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:25.112: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:26.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:26.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:26.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:27.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:27.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:27.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:28.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:28.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:28.088: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:29.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:29.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:29.088: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:30.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:30.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:30.088: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:31.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:31.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:31.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:32.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:32.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:32.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:33.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:33.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:33.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:34.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:34.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:34.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:35.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:35.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:35.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:36.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:36.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:36.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:37.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:37.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:37.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:38.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:38.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:38.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:39.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:39.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:39.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:40.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:40.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:40.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:41.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:41.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:41.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:42.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:42.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:42.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:43.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:43.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:43.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:44.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:44.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:44.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:45.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:45.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:45.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:46.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:46.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:46.088: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:47.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:47.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:47.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:48.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:48.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:48.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:48.089: INFO: Pod daemon-set-gw9tq is not available
Oct 21 19:57:49.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:49.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:49.088: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:49.088: INFO: Pod daemon-set-gw9tq is not available
Oct 21 19:57:50.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:50.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:50.088: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:50.088: INFO: Pod daemon-set-gw9tq is not available
Oct 21 19:57:51.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:51.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:51.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:51.089: INFO: Pod daemon-set-gw9tq is not available
Oct 21 19:57:52.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:52.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:52.088: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:52.088: INFO: Pod daemon-set-gw9tq is not available
Oct 21 19:57:53.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:53.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:53.089: INFO: Wrong image for pod: daemon-set-gw9tq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:53.089: INFO: Pod daemon-set-gw9tq is not available
Oct 21 19:57:54.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:54.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:54.089: INFO: Pod daemon-set-zkxnk is not available
Oct 21 19:57:55.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:55.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:55.089: INFO: Pod daemon-set-zkxnk is not available
Oct 21 19:57:56.090: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:56.090: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:57.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:57.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:58.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:58.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:59.090: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:57:59.090: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:00.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:00.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:01.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:01.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:02.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:02.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:03.090: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:03.090: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:04.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:04.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:05.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:05.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:06.090: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:06.090: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:07.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:07.090: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:08.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:08.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:09.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:09.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:10.090: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:10.090: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:11.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:11.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:12.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:12.088: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:13.091: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:13.092: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:14.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:14.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:15.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:15.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:16.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:16.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:17.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:17.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:18.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:18.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:19.090: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:19.090: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:20.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:20.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:21.099: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:21.099: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:22.101: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:22.101: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:23.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:23.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:24.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:24.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:25.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:25.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:26.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:26.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:27.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:27.089: INFO: Wrong image for pod: daemon-set-7svk8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:27.089: INFO: Pod daemon-set-7svk8 is not available
Oct 21 19:58:28.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:28.089: INFO: Pod daemon-set-b2rr6 is not available
Oct 21 19:58:29.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:29.089: INFO: Pod daemon-set-b2rr6 is not available
Oct 21 19:58:30.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:30.089: INFO: Pod daemon-set-b2rr6 is not available
Oct 21 19:58:31.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:32.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:33.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:34.092: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:35.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:36.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:37.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:38.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:39.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:40.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:41.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:42.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:43.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:44.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:45.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:46.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:47.090: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:48.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:49.111: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:50.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:51.093: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:52.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:53.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:54.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:55.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:56.095: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:57.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:58.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:58:59.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:00.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:01.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:02.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:02.088: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:03.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:03.089: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:04.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:04.089: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:05.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:05.089: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:06.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:06.089: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:07.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:07.089: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:08.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:08.089: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:09.088: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:09.089: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:10.089: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:10.089: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:11.090: INFO: Wrong image for pod: daemon-set-59lnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Oct 21 19:59:11.090: INFO: Pod daemon-set-59lnk is not available
Oct 21 19:59:12.089: INFO: Pod daemon-set-g2gdw is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Oct 21 19:59:12.115: INFO: Number of nodes with available pods: 2
Oct 21 19:59:12.115: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 19:59:13.132: INFO: Number of nodes with available pods: 2
Oct 21 19:59:13.132: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 19:59:14.134: INFO: Number of nodes with available pods: 2
Oct 21 19:59:14.134: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 19:59:15.133: INFO: Number of nodes with available pods: 3
Oct 21 19:59:15.133: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-s7bcm, will wait for the garbage collector to delete the pods
Oct 21 19:59:15.251: INFO: Deleting DaemonSet.extensions daemon-set took: 21.457116ms
Oct 21 19:59:15.351: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.364649ms
Oct 21 19:59:23.259: INFO: Number of nodes with available pods: 0
Oct 21 19:59:23.259: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 19:59:23.266: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-s7bcm/daemonsets","resourceVersion":"16191"},"items":null}

Oct 21 19:59:23.273: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-s7bcm/pods","resourceVersion":"16191"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 19:59:23.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-s7bcm" for this suite.
Oct 21 19:59:29.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 19:59:29.392: INFO: namespace: e2e-tests-daemonsets-s7bcm, resource: bindings, ignored listing per whitelist
Oct 21 19:59:29.625: INFO: namespace e2e-tests-daemonsets-s7bcm deletion completed in 6.314555658s

â€¢ [SLOW TEST:138.003 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 19:59:29.626: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9rbxn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Oct 21 19:59:29.928: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct 21 19:59:29.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:30.276: INFO: stderr: ""
Oct 21 19:59:30.276: INFO: stdout: "service/redis-slave created\n"
Oct 21 19:59:30.276: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct 21 19:59:30.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:30.561: INFO: stderr: ""
Oct 21 19:59:30.561: INFO: stdout: "service/redis-master created\n"
Oct 21 19:59:30.561: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct 21 19:59:30.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:30.784: INFO: stderr: ""
Oct 21 19:59:30.784: INFO: stdout: "service/frontend created\n"
Oct 21 19:59:30.784: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct 21 19:59:30.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:31.039: INFO: stderr: ""
Oct 21 19:59:31.039: INFO: stdout: "deployment.extensions/frontend created\n"
Oct 21 19:59:31.039: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct 21 19:59:31.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:31.292: INFO: stderr: ""
Oct 21 19:59:31.292: INFO: stdout: "deployment.extensions/redis-master created\n"
Oct 21 19:59:31.292: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct 21 19:59:31.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:31.526: INFO: stderr: ""
Oct 21 19:59:31.526: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Oct 21 19:59:31.526: INFO: Waiting for all frontend pods to be Running.
Oct 21 19:59:46.577: INFO: Waiting for frontend to serve content.
Oct 21 19:59:46.603: INFO: Trying to add a new entry to the guestbook.
Oct 21 19:59:46.635: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct 21 19:59:46.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:46.854: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 19:59:46.854: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 19:59:46.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:47.028: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 19:59:47.028: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 19:59:47.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:47.199: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 19:59:47.199: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 19:59:47.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:47.348: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 19:59:47.348: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 19:59:47.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:47.485: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 19:59:47.485: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct 21 19:59:47.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9rbxn'
Oct 21 19:59:47.651: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 19:59:47.651: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 19:59:47.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9rbxn" for this suite.
Oct 21 20:00:27.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:00:27.908: INFO: namespace: e2e-tests-kubectl-9rbxn, resource: bindings, ignored listing per whitelist
Oct 21 20:00:27.977: INFO: namespace e2e-tests-kubectl-9rbxn deletion completed in 40.315706996s

â€¢ [SLOW TEST:58.351 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:00:27.977: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cn97f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Oct 21 20:00:28.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:28.555: INFO: stderr: ""
Oct 21 20:00:28.555: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 20:00:28.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:28.704: INFO: stderr: ""
Oct 21 20:00:28.704: INFO: stdout: "update-demo-nautilus-2mrcl update-demo-nautilus-tdsqx "
Oct 21 20:00:28.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:28.840: INFO: stderr: ""
Oct 21 20:00:28.840: INFO: stdout: ""
Oct 21 20:00:28.840: INFO: update-demo-nautilus-2mrcl is created but not running
Oct 21 20:00:33.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:33.986: INFO: stderr: ""
Oct 21 20:00:33.986: INFO: stdout: "update-demo-nautilus-2mrcl update-demo-nautilus-tdsqx "
Oct 21 20:00:33.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:34.117: INFO: stderr: ""
Oct 21 20:00:34.117: INFO: stdout: "true"
Oct 21 20:00:34.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:34.242: INFO: stderr: ""
Oct 21 20:00:34.242: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:00:34.242: INFO: validating pod update-demo-nautilus-2mrcl
Oct 21 20:00:34.258: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:00:34.258: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:00:34.258: INFO: update-demo-nautilus-2mrcl is verified up and running
Oct 21 20:00:34.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-tdsqx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:34.379: INFO: stderr: ""
Oct 21 20:00:34.380: INFO: stdout: "true"
Oct 21 20:00:34.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-tdsqx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:34.526: INFO: stderr: ""
Oct 21 20:00:34.526: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:00:34.526: INFO: validating pod update-demo-nautilus-tdsqx
Oct 21 20:00:34.545: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:00:34.545: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:00:34.545: INFO: update-demo-nautilus-tdsqx is verified up and running
STEP: scaling down the replication controller
Oct 21 20:00:34.546: INFO: scanned /root for discovery docs: <nil>
Oct 21 20:00:34.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:35.723: INFO: stderr: ""
Oct 21 20:00:35.723: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 20:00:35.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:35.874: INFO: stderr: ""
Oct 21 20:00:35.874: INFO: stdout: "update-demo-nautilus-2mrcl update-demo-nautilus-tdsqx "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 21 20:00:40.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:41.015: INFO: stderr: ""
Oct 21 20:00:41.015: INFO: stdout: "update-demo-nautilus-2mrcl update-demo-nautilus-tdsqx "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct 21 20:00:46.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:46.135: INFO: stderr: ""
Oct 21 20:00:46.135: INFO: stdout: "update-demo-nautilus-2mrcl "
Oct 21 20:00:46.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:46.280: INFO: stderr: ""
Oct 21 20:00:46.280: INFO: stdout: "true"
Oct 21 20:00:46.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:46.424: INFO: stderr: ""
Oct 21 20:00:46.424: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:00:46.424: INFO: validating pod update-demo-nautilus-2mrcl
Oct 21 20:00:46.437: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:00:46.437: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:00:46.437: INFO: update-demo-nautilus-2mrcl is verified up and running
STEP: scaling up the replication controller
Oct 21 20:00:46.439: INFO: scanned /root for discovery docs: <nil>
Oct 21 20:00:46.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:47.613: INFO: stderr: ""
Oct 21 20:00:47.613: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 20:00:47.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:47.770: INFO: stderr: ""
Oct 21 20:00:47.770: INFO: stdout: "update-demo-nautilus-2mrcl update-demo-nautilus-5pc4j "
Oct 21 20:00:47.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:47.885: INFO: stderr: ""
Oct 21 20:00:47.885: INFO: stdout: "true"
Oct 21 20:00:47.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:48.015: INFO: stderr: ""
Oct 21 20:00:48.015: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:00:48.015: INFO: validating pod update-demo-nautilus-2mrcl
Oct 21 20:00:48.026: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:00:48.026: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:00:48.026: INFO: update-demo-nautilus-2mrcl is verified up and running
Oct 21 20:00:48.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-5pc4j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:48.155: INFO: stderr: ""
Oct 21 20:00:48.155: INFO: stdout: ""
Oct 21 20:00:48.155: INFO: update-demo-nautilus-5pc4j is created but not running
Oct 21 20:00:53.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:53.297: INFO: stderr: ""
Oct 21 20:00:53.297: INFO: stdout: "update-demo-nautilus-2mrcl update-demo-nautilus-5pc4j "
Oct 21 20:00:53.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:53.419: INFO: stderr: ""
Oct 21 20:00:53.419: INFO: stdout: "true"
Oct 21 20:00:53.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-2mrcl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:53.560: INFO: stderr: ""
Oct 21 20:00:53.560: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:00:53.560: INFO: validating pod update-demo-nautilus-2mrcl
Oct 21 20:00:53.574: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:00:53.574: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:00:53.574: INFO: update-demo-nautilus-2mrcl is verified up and running
Oct 21 20:00:53.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-5pc4j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:53.696: INFO: stderr: ""
Oct 21 20:00:53.696: INFO: stdout: "true"
Oct 21 20:00:53.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-5pc4j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:53.816: INFO: stderr: ""
Oct 21 20:00:53.816: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:00:53.816: INFO: validating pod update-demo-nautilus-5pc4j
Oct 21 20:00:53.831: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:00:53.831: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:00:53.831: INFO: update-demo-nautilus-5pc4j is verified up and running
STEP: using delete to clean up resources
Oct 21 20:00:53.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:53.983: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 20:00:53.983: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 21 20:00:53.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-cn97f'
Oct 21 20:00:54.140: INFO: stderr: "No resources found.\n"
Oct 21 20:00:54.140: INFO: stdout: ""
Oct 21 20:00:54.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -l name=update-demo --namespace=e2e-tests-kubectl-cn97f -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 20:00:54.283: INFO: stderr: ""
Oct 21 20:00:54.283: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:00:54.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cn97f" for this suite.
Oct 21 20:01:18.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:01:18.389: INFO: namespace: e2e-tests-kubectl-cn97f, resource: bindings, ignored listing per whitelist
Oct 21 20:01:18.613: INFO: namespace e2e-tests-kubectl-cn97f deletion completed in 24.318287386s

â€¢ [SLOW TEST:50.635 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:01:18.613: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-t7rfl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 21 20:01:18.928: INFO: Waiting up to 5m0s for pod "downward-api-8beafecd-f43d-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-t7rfl" to be "success or failure"
Oct 21 20:01:18.936: INFO: Pod "downward-api-8beafecd-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.19625ms
Oct 21 20:01:20.943: INFO: Pod "downward-api-8beafecd-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014515953s
Oct 21 20:01:22.951: INFO: Pod "downward-api-8beafecd-f43d-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022732875s
STEP: Saw pod success
Oct 21 20:01:22.951: INFO: Pod "downward-api-8beafecd-f43d-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:01:22.958: INFO: Trying to get logs from node 10.170.151.156 pod downward-api-8beafecd-f43d-11e9-a616-8a530cf33301 container dapi-container: <nil>
STEP: delete the pod
Oct 21 20:01:23.001: INFO: Waiting for pod downward-api-8beafecd-f43d-11e9-a616-8a530cf33301 to disappear
Oct 21 20:01:23.012: INFO: Pod downward-api-8beafecd-f43d-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:01:23.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t7rfl" for this suite.
Oct 21 20:01:29.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:01:29.239: INFO: namespace: e2e-tests-downward-api-t7rfl, resource: bindings, ignored listing per whitelist
Oct 21 20:01:29.307: INFO: namespace e2e-tests-downward-api-t7rfl deletion completed in 6.285746334s

â€¢ [SLOW TEST:10.694 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:01:29.307: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-w625b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 20:01:29.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w625b'
Oct 21 20:01:29.775: INFO: stderr: ""
Oct 21 20:01:29.775: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Oct 21 20:01:34.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w625b -o json'
Oct 21 20:01:34.988: INFO: stderr: ""
Oct 21 20:01:34.988: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-10-21T20:01:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-w625b\",\n        \"resourceVersion\": \"16858\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-w625b/pods/e2e-test-nginx-pod\",\n        \"uid\": \"926059ca-f43d-11e9-b0e3-be2fb188e37d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2vsmh\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.170.151.145\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2vsmh\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2vsmh\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T20:01:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T20:01:32Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T20:01:32Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-21T20:01:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9f9bb194c5c720df7e27e1f7804e7748b3e81ff2b65135a942305515abce7685\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-21T20:01:32Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.170.151.145\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.198.179\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-21T20:01:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct 21 20:01:34.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 replace -f - --namespace=e2e-tests-kubectl-w625b'
Oct 21 20:01:35.226: INFO: stderr: ""
Oct 21 20:01:35.226: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Oct 21 20:01:35.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-w625b'
Oct 21 20:01:41.390: INFO: stderr: ""
Oct 21 20:01:41.390: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:01:41.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w625b" for this suite.
Oct 21 20:01:47.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:01:47.659: INFO: namespace: e2e-tests-kubectl-w625b, resource: bindings, ignored listing per whitelist
Oct 21 20:01:47.743: INFO: namespace e2e-tests-kubectl-w625b deletion completed in 6.342187702s

â€¢ [SLOW TEST:18.436 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:01:47.744: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fr252
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-9d4770b2-f43d-11e9-a616-8a530cf33301
STEP: Creating secret with name secret-projected-all-test-volume-9d477088-f43d-11e9-a616-8a530cf33301
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct 21 20:01:48.073: INFO: Waiting up to 5m0s for pod "projected-volume-9d477022-f43d-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-fr252" to be "success or failure"
Oct 21 20:01:48.080: INFO: Pod "projected-volume-9d477022-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.607031ms
Oct 21 20:01:50.087: INFO: Pod "projected-volume-9d477022-f43d-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014178378s
STEP: Saw pod success
Oct 21 20:01:50.087: INFO: Pod "projected-volume-9d477022-f43d-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:01:50.094: INFO: Trying to get logs from node 10.170.151.145 pod projected-volume-9d477022-f43d-11e9-a616-8a530cf33301 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct 21 20:01:50.138: INFO: Waiting for pod projected-volume-9d477022-f43d-11e9-a616-8a530cf33301 to disappear
Oct 21 20:01:50.143: INFO: Pod projected-volume-9d477022-f43d-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:01:50.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fr252" for this suite.
Oct 21 20:01:56.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:01:56.212: INFO: namespace: e2e-tests-projected-fr252, resource: bindings, ignored listing per whitelist
Oct 21 20:01:56.505: INFO: namespace e2e-tests-projected-fr252 deletion completed in 6.349105989s

â€¢ [SLOW TEST:8.762 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:01:56.506: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-g47p8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a28a2880-f43d-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:01:56.895: INFO: Waiting up to 5m0s for pod "pod-configmaps-a28c6939-f43d-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-g47p8" to be "success or failure"
Oct 21 20:01:56.901: INFO: Pod "pod-configmaps-a28c6939-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.282913ms
Oct 21 20:01:58.908: INFO: Pod "pod-configmaps-a28c6939-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013546249s
Oct 21 20:02:00.916: INFO: Pod "pod-configmaps-a28c6939-f43d-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020979923s
STEP: Saw pod success
Oct 21 20:02:00.916: INFO: Pod "pod-configmaps-a28c6939-f43d-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:02:00.937: INFO: Trying to get logs from node 10.170.151.156 pod pod-configmaps-a28c6939-f43d-11e9-a616-8a530cf33301 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:02:00.977: INFO: Waiting for pod pod-configmaps-a28c6939-f43d-11e9-a616-8a530cf33301 to disappear
Oct 21 20:02:00.983: INFO: Pod pod-configmaps-a28c6939-f43d-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:02:00.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g47p8" for this suite.
Oct 21 20:02:07.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:02:07.059: INFO: namespace: e2e-tests-configmap-g47p8, resource: bindings, ignored listing per whitelist
Oct 21 20:02:07.325: INFO: namespace e2e-tests-configmap-g47p8 deletion completed in 6.331914029s

â€¢ [SLOW TEST:10.819 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:02:07.325: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-tkvxp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tkvxp A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tkvxp;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tkvxp A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tkvxp;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tkvxp.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tkvxp.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tkvxp.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tkvxp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-tkvxp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tkvxp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-tkvxp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tkvxp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 81.155.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.155.81_udp@PTR;check="$$(dig +tcp +noall +answer +search 81.155.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.155.81_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tkvxp A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tkvxp;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tkvxp A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tkvxp.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tkvxp.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tkvxp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-tkvxp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tkvxp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-tkvxp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tkvxp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 81.155.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.155.81_udp@PTR;check="$$(dig +tcp +noall +answer +search 81.155.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.155.81_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 20:02:19.898: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:19.908: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:19.922: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:19.932: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:19.944: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:19.955: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:19.965: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:19.975: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:20.059: INFO: Lookups using e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-tkvxp jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc]

Oct 21 20:02:25.235: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:25.246: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:25.262: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:25.272: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:25.289: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:25.300: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:25.315: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:25.326: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:25.409: INFO: Lookups using e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-tkvxp jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc]

Oct 21 20:02:30.217: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:30.228: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:30.238: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:30.249: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:30.260: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:30.270: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:30.280: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:30.290: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:30.368: INFO: Lookups using e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-tkvxp jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc]

Oct 21 20:02:35.227: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:35.237: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:35.248: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:35.260: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:35.270: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:35.281: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:35.293: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:35.304: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:35.406: INFO: Lookups using e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-tkvxp jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc]

Oct 21 20:02:40.228: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:40.238: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:40.248: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:40.258: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:40.269: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:40.280: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:40.291: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:40.301: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc from pod e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301: the server could not find the requested resource (get pods dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301)
Oct 21 20:02:40.364: INFO: Lookups using e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301 failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-tkvxp jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp jessie_udp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@dns-test-service.e2e-tests-dns-tkvxp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tkvxp.svc]

Oct 21 20:02:45.382: INFO: DNS probes using e2e-tests-dns-tkvxp/dns-test-a8fdf8a1-f43d-11e9-a616-8a530cf33301 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:02:45.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tkvxp" for this suite.
Oct 21 20:02:51.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:02:51.561: INFO: namespace: e2e-tests-dns-tkvxp, resource: bindings, ignored listing per whitelist
Oct 21 20:02:51.799: INFO: namespace e2e-tests-dns-tkvxp deletion completed in 6.316863986s

â€¢ [SLOW TEST:44.474 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:02:51.800: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-n8lf7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Oct 21 20:02:56.682: INFO: Successfully updated pod "labelsupdatec376b8bd-f43d-11e9-a616-8a530cf33301"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:02:58.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n8lf7" for this suite.
Oct 21 20:03:22.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:03:22.789: INFO: namespace: e2e-tests-downward-api-n8lf7, resource: bindings, ignored listing per whitelist
Oct 21 20:03:23.044: INFO: namespace e2e-tests-downward-api-n8lf7 deletion completed in 24.30378813s

â€¢ [SLOW TEST:31.244 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:03:23.045: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-d6hmt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d615f8a6-f43d-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:03:23.368: INFO: Waiting up to 5m0s for pod "pod-secrets-d617440d-f43d-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-d6hmt" to be "success or failure"
Oct 21 20:03:23.375: INFO: Pod "pod-secrets-d617440d-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.70002ms
Oct 21 20:03:25.383: INFO: Pod "pod-secrets-d617440d-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014197433s
Oct 21 20:03:27.390: INFO: Pod "pod-secrets-d617440d-f43d-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021537118s
STEP: Saw pod success
Oct 21 20:03:27.390: INFO: Pod "pod-secrets-d617440d-f43d-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:03:27.396: INFO: Trying to get logs from node 10.170.151.156 pod pod-secrets-d617440d-f43d-11e9-a616-8a530cf33301 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:03:27.439: INFO: Waiting for pod pod-secrets-d617440d-f43d-11e9-a616-8a530cf33301 to disappear
Oct 21 20:03:27.447: INFO: Pod pod-secrets-d617440d-f43d-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:03:27.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-d6hmt" for this suite.
Oct 21 20:03:33.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:03:33.850: INFO: namespace: e2e-tests-secrets-d6hmt, resource: bindings, ignored listing per whitelist
Oct 21 20:03:33.924: INFO: namespace e2e-tests-secrets-d6hmt deletion completed in 6.466493925s

â€¢ [SLOW TEST:10.880 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:03:33.927: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-znh4b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Oct 21 20:03:34.772: INFO: Waiting up to 5m0s for pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5xvrt" in namespace "e2e-tests-svcaccounts-znh4b" to be "success or failure"
Oct 21 20:03:34.778: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5xvrt": Phase="Pending", Reason="", readiness=false. Elapsed: 6.350047ms
Oct 21 20:03:36.786: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5xvrt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014122241s
Oct 21 20:03:38.794: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5xvrt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022038475s
STEP: Saw pod success
Oct 21 20:03:38.794: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5xvrt" satisfied condition "success or failure"
Oct 21 20:03:38.801: INFO: Trying to get logs from node 10.170.151.141 pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5xvrt container token-test: <nil>
STEP: delete the pod
Oct 21 20:03:38.874: INFO: Waiting for pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5xvrt to disappear
Oct 21 20:03:38.881: INFO: Pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5xvrt no longer exists
STEP: Creating a pod to test consume service account root CA
Oct 21 20:03:38.889: INFO: Waiting up to 5m0s for pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5zwvz" in namespace "e2e-tests-svcaccounts-znh4b" to be "success or failure"
Oct 21 20:03:38.897: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5zwvz": Phase="Pending", Reason="", readiness=false. Elapsed: 7.196827ms
Oct 21 20:03:40.904: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5zwvz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01466793s
Oct 21 20:03:42.912: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5zwvz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022418154s
STEP: Saw pod success
Oct 21 20:03:42.912: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5zwvz" satisfied condition "success or failure"
Oct 21 20:03:42.919: INFO: Trying to get logs from node 10.170.151.156 pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5zwvz container root-ca-test: <nil>
STEP: delete the pod
Oct 21 20:03:42.964: INFO: Waiting for pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5zwvz to disappear
Oct 21 20:03:42.971: INFO: Pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-5zwvz no longer exists
STEP: Creating a pod to test consume service account namespace
Oct 21 20:03:42.980: INFO: Waiting up to 5m0s for pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-z2sdz" in namespace "e2e-tests-svcaccounts-znh4b" to be "success or failure"
Oct 21 20:03:42.988: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-z2sdz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.055569ms
Oct 21 20:03:44.996: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-z2sdz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015951519s
Oct 21 20:03:47.003: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-z2sdz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023405199s
STEP: Saw pod success
Oct 21 20:03:47.003: INFO: Pod "pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-z2sdz" satisfied condition "success or failure"
Oct 21 20:03:47.010: INFO: Trying to get logs from node 10.170.151.141 pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-z2sdz container namespace-test: <nil>
STEP: delete the pod
Oct 21 20:03:47.043: INFO: Waiting for pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-z2sdz to disappear
Oct 21 20:03:47.049: INFO: Pod pod-service-account-dce338eb-f43d-11e9-a616-8a530cf33301-z2sdz no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:03:47.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-znh4b" for this suite.
Oct 21 20:03:53.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:03:53.141: INFO: namespace: e2e-tests-svcaccounts-znh4b, resource: bindings, ignored listing per whitelist
Oct 21 20:03:53.372: INFO: namespace e2e-tests-svcaccounts-znh4b deletion completed in 6.31345283s

â€¢ [SLOW TEST:19.445 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:03:53.373: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-mzlf8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:03:53.682: INFO: Creating ReplicaSet my-hostname-basic-e82b0482-f43d-11e9-a616-8a530cf33301
Oct 21 20:03:53.700: INFO: Pod name my-hostname-basic-e82b0482-f43d-11e9-a616-8a530cf33301: Found 0 pods out of 1
Oct 21 20:03:58.708: INFO: Pod name my-hostname-basic-e82b0482-f43d-11e9-a616-8a530cf33301: Found 1 pods out of 1
Oct 21 20:03:58.708: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e82b0482-f43d-11e9-a616-8a530cf33301" is running
Oct 21 20:03:58.715: INFO: Pod "my-hostname-basic-e82b0482-f43d-11e9-a616-8a530cf33301-5wkp7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 20:03:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 20:03:55 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 20:03:55 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 20:03:53 +0000 UTC Reason: Message:}])
Oct 21 20:03:58.715: INFO: Trying to dial the pod
Oct 21 20:04:03.743: INFO: Controller my-hostname-basic-e82b0482-f43d-11e9-a616-8a530cf33301: Got expected result from replica 1 [my-hostname-basic-e82b0482-f43d-11e9-a616-8a530cf33301-5wkp7]: "my-hostname-basic-e82b0482-f43d-11e9-a616-8a530cf33301-5wkp7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:04:03.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mzlf8" for this suite.
Oct 21 20:04:09.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:04:09.854: INFO: namespace: e2e-tests-replicaset-mzlf8, resource: bindings, ignored listing per whitelist
Oct 21 20:04:10.063: INFO: namespace e2e-tests-replicaset-mzlf8 deletion completed in 6.30785636s

â€¢ [SLOW TEST:16.690 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:04:10.064: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-6b95h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-f21dab3c-f43d-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:04:10.400: INFO: Waiting up to 5m0s for pod "pod-configmaps-f21fabdb-f43d-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-6b95h" to be "success or failure"
Oct 21 20:04:10.407: INFO: Pod "pod-configmaps-f21fabdb-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.900167ms
Oct 21 20:04:12.414: INFO: Pod "pod-configmaps-f21fabdb-f43d-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013923038s
STEP: Saw pod success
Oct 21 20:04:12.414: INFO: Pod "pod-configmaps-f21fabdb-f43d-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:04:12.420: INFO: Trying to get logs from node 10.170.151.141 pod pod-configmaps-f21fabdb-f43d-11e9-a616-8a530cf33301 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:04:12.459: INFO: Waiting for pod pod-configmaps-f21fabdb-f43d-11e9-a616-8a530cf33301 to disappear
Oct 21 20:04:12.465: INFO: Pod pod-configmaps-f21fabdb-f43d-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:04:12.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6b95h" for this suite.
Oct 21 20:04:18.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:04:18.737: INFO: namespace: e2e-tests-configmap-6b95h, resource: bindings, ignored listing per whitelist
Oct 21 20:04:18.797: INFO: namespace e2e-tests-configmap-6b95h deletion completed in 6.322399568s

â€¢ [SLOW TEST:8.734 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:04:18.801: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-j94k2
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct 21 20:04:19.110: INFO: Waiting up to 5m0s for pod "pod-f7509659-f43d-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-j94k2" to be "success or failure"
Oct 21 20:04:19.116: INFO: Pod "pod-f7509659-f43d-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.307609ms
Oct 21 20:04:21.123: INFO: Pod "pod-f7509659-f43d-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01370679s
STEP: Saw pod success
Oct 21 20:04:21.123: INFO: Pod "pod-f7509659-f43d-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:04:21.130: INFO: Trying to get logs from node 10.170.151.156 pod pod-f7509659-f43d-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:04:21.172: INFO: Waiting for pod pod-f7509659-f43d-11e9-a616-8a530cf33301 to disappear
Oct 21 20:04:21.181: INFO: Pod pod-f7509659-f43d-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:04:21.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j94k2" for this suite.
Oct 21 20:04:27.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:04:27.438: INFO: namespace: e2e-tests-emptydir-j94k2, resource: bindings, ignored listing per whitelist
Oct 21 20:04:27.510: INFO: namespace e2e-tests-emptydir-j94k2 deletion completed in 6.318764561s

â€¢ [SLOW TEST:8.709 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:04:27.510: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mgzxp
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-fc85c660-f43d-11e9-a616-8a530cf33301
STEP: Creating secret with name s-test-opt-upd-fc85c7e9-f43d-11e9-a616-8a530cf33301
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-fc85c660-f43d-11e9-a616-8a530cf33301
STEP: Updating secret s-test-opt-upd-fc85c7e9-f43d-11e9-a616-8a530cf33301
STEP: Creating secret with name s-test-opt-create-fc85c819-f43d-11e9-a616-8a530cf33301
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:05:54.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mgzxp" for this suite.
Oct 21 20:06:18.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:06:19.083: INFO: namespace: e2e-tests-projected-mgzxp, resource: bindings, ignored listing per whitelist
Oct 21 20:06:19.174: INFO: namespace e2e-tests-projected-mgzxp deletion completed in 24.294072079s

â€¢ [SLOW TEST:111.663 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:06:19.174: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-p6fjr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Oct 21 20:06:19.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:19.926: INFO: stderr: ""
Oct 21 20:06:19.926: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 20:06:19.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:20.059: INFO: stderr: ""
Oct 21 20:06:20.059: INFO: stdout: "update-demo-nautilus-b4lvs update-demo-nautilus-zdq67 "
Oct 21 20:06:20.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-b4lvs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:20.190: INFO: stderr: ""
Oct 21 20:06:20.190: INFO: stdout: ""
Oct 21 20:06:20.190: INFO: update-demo-nautilus-b4lvs is created but not running
Oct 21 20:06:25.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:25.329: INFO: stderr: ""
Oct 21 20:06:25.329: INFO: stdout: "update-demo-nautilus-b4lvs update-demo-nautilus-zdq67 "
Oct 21 20:06:25.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-b4lvs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:25.466: INFO: stderr: ""
Oct 21 20:06:25.466: INFO: stdout: "true"
Oct 21 20:06:25.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-b4lvs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:25.599: INFO: stderr: ""
Oct 21 20:06:25.599: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:06:25.599: INFO: validating pod update-demo-nautilus-b4lvs
Oct 21 20:06:25.613: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:06:25.613: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:06:25.613: INFO: update-demo-nautilus-b4lvs is verified up and running
Oct 21 20:06:25.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-zdq67 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:25.747: INFO: stderr: ""
Oct 21 20:06:25.747: INFO: stdout: "true"
Oct 21 20:06:25.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-zdq67 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:25.870: INFO: stderr: ""
Oct 21 20:06:25.870: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:06:25.870: INFO: validating pod update-demo-nautilus-zdq67
Oct 21 20:06:25.886: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:06:25.886: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:06:25.886: INFO: update-demo-nautilus-zdq67 is verified up and running
STEP: rolling-update to new replication controller
Oct 21 20:06:25.888: INFO: scanned /root for discovery docs: <nil>
Oct 21 20:06:25.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:48.556: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct 21 20:06:48.556: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 20:06:48.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:48.684: INFO: stderr: ""
Oct 21 20:06:48.684: INFO: stdout: "update-demo-kitten-5t27b update-demo-kitten-fm6wg "
Oct 21 20:06:48.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-kitten-5t27b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:48.812: INFO: stderr: ""
Oct 21 20:06:48.812: INFO: stdout: "true"
Oct 21 20:06:48.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-kitten-5t27b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:48.960: INFO: stderr: ""
Oct 21 20:06:48.961: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 21 20:06:48.961: INFO: validating pod update-demo-kitten-5t27b
Oct 21 20:06:48.975: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 21 20:06:48.975: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 21 20:06:48.975: INFO: update-demo-kitten-5t27b is verified up and running
Oct 21 20:06:48.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-kitten-fm6wg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:49.095: INFO: stderr: ""
Oct 21 20:06:49.095: INFO: stdout: "true"
Oct 21 20:06:49.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-kitten-fm6wg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p6fjr'
Oct 21 20:06:49.225: INFO: stderr: ""
Oct 21 20:06:49.225: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct 21 20:06:49.225: INFO: validating pod update-demo-kitten-fm6wg
Oct 21 20:06:49.242: INFO: got data: {
  "image": "kitten.jpg"
}

Oct 21 20:06:49.242: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct 21 20:06:49.242: INFO: update-demo-kitten-fm6wg is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:06:49.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p6fjr" for this suite.
Oct 21 20:07:13.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:07:13.404: INFO: namespace: e2e-tests-kubectl-p6fjr, resource: bindings, ignored listing per whitelist
Oct 21 20:07:13.545: INFO: namespace e2e-tests-kubectl-p6fjr deletion completed in 24.293582365s

â€¢ [SLOW TEST:54.371 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:07:13.545: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4dgz4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5f7c6029-f43e-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:07:13.893: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5f7e6dad-f43e-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-4dgz4" to be "success or failure"
Oct 21 20:07:13.900: INFO: Pod "pod-projected-configmaps-5f7e6dad-f43e-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.958164ms
Oct 21 20:07:15.908: INFO: Pod "pod-projected-configmaps-5f7e6dad-f43e-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014787002s
Oct 21 20:07:17.916: INFO: Pod "pod-projected-configmaps-5f7e6dad-f43e-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022594511s
STEP: Saw pod success
Oct 21 20:07:17.916: INFO: Pod "pod-projected-configmaps-5f7e6dad-f43e-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:07:17.922: INFO: Trying to get logs from node 10.170.151.156 pod pod-projected-configmaps-5f7e6dad-f43e-11e9-a616-8a530cf33301 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:07:17.965: INFO: Waiting for pod pod-projected-configmaps-5f7e6dad-f43e-11e9-a616-8a530cf33301 to disappear
Oct 21 20:07:17.971: INFO: Pod pod-projected-configmaps-5f7e6dad-f43e-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:07:17.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4dgz4" for this suite.
Oct 21 20:07:24.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:07:24.123: INFO: namespace: e2e-tests-projected-4dgz4, resource: bindings, ignored listing per whitelist
Oct 21 20:07:24.331: INFO: namespace e2e-tests-projected-4dgz4 deletion completed in 6.348838767s

â€¢ [SLOW TEST:10.785 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:07:24.331: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-xc55k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct 21 20:07:25.199: INFO: Pod name wrapped-volume-race-66390806-f43e-11e9-a616-8a530cf33301: Found 0 pods out of 5
Oct 21 20:07:30.211: INFO: Pod name wrapped-volume-race-66390806-f43e-11e9-a616-8a530cf33301: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-66390806-f43e-11e9-a616-8a530cf33301 in namespace e2e-tests-emptydir-wrapper-xc55k, will wait for the garbage collector to delete the pods
Oct 21 20:07:40.340: INFO: Deleting ReplicationController wrapped-volume-race-66390806-f43e-11e9-a616-8a530cf33301 took: 20.384891ms
Oct 21 20:07:40.442: INFO: Terminating ReplicationController wrapped-volume-race-66390806-f43e-11e9-a616-8a530cf33301 pods took: 101.075021ms
STEP: Creating RC which spawns configmap-volume pods
Oct 21 20:08:17.788: INFO: Pod name wrapped-volume-race-858f51ab-f43e-11e9-a616-8a530cf33301: Found 0 pods out of 5
Oct 21 20:08:22.800: INFO: Pod name wrapped-volume-race-858f51ab-f43e-11e9-a616-8a530cf33301: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-858f51ab-f43e-11e9-a616-8a530cf33301 in namespace e2e-tests-emptydir-wrapper-xc55k, will wait for the garbage collector to delete the pods
Oct 21 20:08:44.934: INFO: Deleting ReplicationController wrapped-volume-race-858f51ab-f43e-11e9-a616-8a530cf33301 took: 23.292884ms
Oct 21 20:08:45.034: INFO: Terminating ReplicationController wrapped-volume-race-858f51ab-f43e-11e9-a616-8a530cf33301 pods took: 100.238428ms
STEP: Creating RC which spawns configmap-volume pods
Oct 21 20:09:27.770: INFO: Pod name wrapped-volume-race-af47519c-f43e-11e9-a616-8a530cf33301: Found 0 pods out of 5
Oct 21 20:09:32.783: INFO: Pod name wrapped-volume-race-af47519c-f43e-11e9-a616-8a530cf33301: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-af47519c-f43e-11e9-a616-8a530cf33301 in namespace e2e-tests-emptydir-wrapper-xc55k, will wait for the garbage collector to delete the pods
Oct 21 20:09:56.927: INFO: Deleting ReplicationController wrapped-volume-race-af47519c-f43e-11e9-a616-8a530cf33301 took: 22.352304ms
Oct 21 20:09:57.028: INFO: Terminating ReplicationController wrapped-volume-race-af47519c-f43e-11e9-a616-8a530cf33301 pods took: 100.351551ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:10:38.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-xc55k" for this suite.
Oct 21 20:10:46.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:10:47.066: INFO: namespace: e2e-tests-emptydir-wrapper-xc55k, resource: bindings, ignored listing per whitelist
Oct 21 20:10:47.107: INFO: namespace e2e-tests-emptydir-wrapper-xc55k deletion completed in 8.324726066s

â€¢ [SLOW TEST:202.776 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:10:47.110: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kqz4h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Oct 21 20:10:49.985: INFO: Successfully updated pod "annotationupdatedec29a0e-f43e-11e9-a616-8a530cf33301"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:10:54.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kqz4h" for this suite.
Oct 21 20:11:16.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:11:16.477: INFO: namespace: e2e-tests-projected-kqz4h, resource: bindings, ignored listing per whitelist
Oct 21 20:11:16.505: INFO: namespace e2e-tests-projected-kqz4h deletion completed in 22.441201937s

â€¢ [SLOW TEST:29.396 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:11:16.506: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-8jfdx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8jfdx
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-8jfdx
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-8jfdx
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-8jfdx
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-8jfdx
Oct 21 20:11:20.880: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8jfdx, name: ss-0, uid: f0f41188-f43e-11e9-9086-ba4ceb9f210a, status phase: Pending. Waiting for statefulset controller to delete.
Oct 21 20:11:27.457: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8jfdx, name: ss-0, uid: f0f41188-f43e-11e9-9086-ba4ceb9f210a, status phase: Failed. Waiting for statefulset controller to delete.
Oct 21 20:11:27.486: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-8jfdx, name: ss-0, uid: f0f41188-f43e-11e9-9086-ba4ceb9f210a, status phase: Failed. Waiting for statefulset controller to delete.
Oct 21 20:11:27.496: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-8jfdx
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-8jfdx
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-8jfdx and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 20:11:31.539: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8jfdx
Oct 21 20:11:31.557: INFO: Scaling statefulset ss to 0
Oct 21 20:11:41.589: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 20:11:41.595: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:11:41.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8jfdx" for this suite.
Oct 21 20:11:47.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:11:47.750: INFO: namespace: e2e-tests-statefulset-8jfdx, resource: bindings, ignored listing per whitelist
Oct 21 20:11:47.971: INFO: namespace e2e-tests-statefulset-8jfdx deletion completed in 6.310841027s

â€¢ [SLOW TEST:31.465 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:11:47.971: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wnn4p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:11:48.293: INFO: Waiting up to 5m0s for pod "downwardapi-volume-030c567e-f43f-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-wnn4p" to be "success or failure"
Oct 21 20:11:48.299: INFO: Pod "downwardapi-volume-030c567e-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.871863ms
Oct 21 20:11:50.307: INFO: Pod "downwardapi-volume-030c567e-f43f-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014304945s
STEP: Saw pod success
Oct 21 20:11:50.307: INFO: Pod "downwardapi-volume-030c567e-f43f-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:11:50.314: INFO: Trying to get logs from node 10.170.151.141 pod downwardapi-volume-030c567e-f43f-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:11:50.353: INFO: Waiting for pod downwardapi-volume-030c567e-f43f-11e9-a616-8a530cf33301 to disappear
Oct 21 20:11:50.360: INFO: Pod downwardapi-volume-030c567e-f43f-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:11:50.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wnn4p" for this suite.
Oct 21 20:11:56.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:11:56.591: INFO: namespace: e2e-tests-projected-wnn4p, resource: bindings, ignored listing per whitelist
Oct 21 20:11:56.696: INFO: namespace e2e-tests-projected-wnn4p deletion completed in 6.326067015s

â€¢ [SLOW TEST:8.725 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:11:56.696: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-28swr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-bjgg9
STEP: Creating secret with name secret-test-083f9a13-f43f-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:11:57.222: INFO: Waiting up to 5m0s for pod "pod-secrets-085f21fd-f43f-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-28swr" to be "success or failure"
Oct 21 20:11:57.229: INFO: Pod "pod-secrets-085f21fd-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.607534ms
Oct 21 20:11:59.240: INFO: Pod "pod-secrets-085f21fd-f43f-11e9-a616-8a530cf33301": Phase="Running", Reason="", readiness=true. Elapsed: 2.017774567s
Oct 21 20:12:01.247: INFO: Pod "pod-secrets-085f21fd-f43f-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025049153s
STEP: Saw pod success
Oct 21 20:12:01.247: INFO: Pod "pod-secrets-085f21fd-f43f-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:12:01.254: INFO: Trying to get logs from node 10.170.151.156 pod pod-secrets-085f21fd-f43f-11e9-a616-8a530cf33301 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:12:01.290: INFO: Waiting for pod pod-secrets-085f21fd-f43f-11e9-a616-8a530cf33301 to disappear
Oct 21 20:12:01.298: INFO: Pod pod-secrets-085f21fd-f43f-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:12:01.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-28swr" for this suite.
Oct 21 20:12:07.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:12:07.477: INFO: namespace: e2e-tests-secrets-28swr, resource: bindings, ignored listing per whitelist
Oct 21 20:12:07.602: INFO: namespace e2e-tests-secrets-28swr deletion completed in 6.294281666s
STEP: Destroying namespace "e2e-tests-secret-namespace-bjgg9" for this suite.
Oct 21 20:12:13.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:12:13.661: INFO: namespace: e2e-tests-secret-namespace-bjgg9, resource: bindings, ignored listing per whitelist
Oct 21 20:12:14.173: INFO: namespace e2e-tests-secret-namespace-bjgg9 deletion completed in 6.571025818s

â€¢ [SLOW TEST:17.477 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:12:14.178: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-zg4vt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zg4vt
Oct 21 20:12:18.603: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zg4vt
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 20:12:18.610: INFO: Initial restart count of pod liveness-http is 0
Oct 21 20:12:38.690: INFO: Restart count of pod e2e-tests-container-probe-zg4vt/liveness-http is now 1 (20.080255712s elapsed)
Oct 21 20:12:58.772: INFO: Restart count of pod e2e-tests-container-probe-zg4vt/liveness-http is now 2 (40.162197437s elapsed)
Oct 21 20:13:18.847: INFO: Restart count of pod e2e-tests-container-probe-zg4vt/liveness-http is now 3 (1m0.237359768s elapsed)
Oct 21 20:13:38.920: INFO: Restart count of pod e2e-tests-container-probe-zg4vt/liveness-http is now 4 (1m20.31024859s elapsed)
Oct 21 20:14:49.189: INFO: Restart count of pod e2e-tests-container-probe-zg4vt/liveness-http is now 5 (2m30.57971051s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:14:49.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zg4vt" for this suite.
Oct 21 20:14:55.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:14:55.328: INFO: namespace: e2e-tests-container-probe-zg4vt, resource: bindings, ignored listing per whitelist
Oct 21 20:14:55.530: INFO: namespace e2e-tests-container-probe-zg4vt deletion completed in 6.307791434s

â€¢ [SLOW TEST:161.352 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:14:55.531: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-7r692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1021 20:15:05.987573      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 20:15:05.987: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:15:05.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7r692" for this suite.
Oct 21 20:15:14.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:15:14.166: INFO: namespace: e2e-tests-gc-7r692, resource: bindings, ignored listing per whitelist
Oct 21 20:15:14.325: INFO: namespace e2e-tests-gc-7r692 deletion completed in 8.32974964s

â€¢ [SLOW TEST:18.794 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:15:14.325: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-tsc5t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tsc5t
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-tsc5t
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-tsc5t
Oct 21 20:15:14.647: INFO: Found 0 stateful pods, waiting for 1
Oct 21 20:15:24.655: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct 21 20:15:24.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tsc5t ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 20:15:25.048: INFO: stderr: ""
Oct 21 20:15:25.048: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 20:15:25.048: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 20:15:25.056: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 21 20:15:35.064: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 20:15:35.064: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 20:15:35.090: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 20:15:35.090: INFO: ss-0  10.170.151.156  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  }]
Oct 21 20:15:35.090: INFO: 
Oct 21 20:15:35.090: INFO: StatefulSet ss has not reached scale 3, at 1
Oct 21 20:15:36.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993593909s
Oct 21 20:15:37.106: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985062618s
Oct 21 20:15:38.115: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.976897194s
Oct 21 20:15:39.123: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.968304876s
Oct 21 20:15:40.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.960408773s
Oct 21 20:15:41.139: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.952305484s
Oct 21 20:15:42.148: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.943700782s
Oct 21 20:15:43.157: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.935114018s
Oct 21 20:15:44.165: INFO: Verifying statefulset ss doesn't scale past 3 for another 926.597228ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-tsc5t
Oct 21 20:15:45.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tsc5t ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 20:15:45.824: INFO: stderr: ""
Oct 21 20:15:45.824: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 20:15:45.824: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 20:15:45.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tsc5t ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 20:15:46.201: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Oct 21 20:15:46.201: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 20:15:46.201: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 20:15:46.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tsc5t ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 20:15:46.538: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Oct 21 20:15:46.538: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 20:15:46.538: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 20:15:46.546: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct 21 20:15:56.553: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 20:15:56.553: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 20:15:56.553: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct 21 20:15:56.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tsc5t ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 20:15:56.972: INFO: stderr: ""
Oct 21 20:15:56.972: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 20:15:56.972: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 20:15:56.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tsc5t ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 20:15:57.364: INFO: stderr: ""
Oct 21 20:15:57.364: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 20:15:57.364: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 20:15:57.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tsc5t ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 20:15:57.715: INFO: stderr: ""
Oct 21 20:15:57.715: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 20:15:57.715: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 20:15:57.715: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 20:15:57.725: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct 21 20:16:07.741: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 20:16:07.741: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 20:16:07.741: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 20:16:07.765: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 20:16:07.765: INFO: ss-0  10.170.151.156  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  }]
Oct 21 20:16:07.765: INFO: ss-1  10.170.151.145  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:35 +0000 UTC  }]
Oct 21 20:16:07.765: INFO: ss-2  10.170.151.141  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:35 +0000 UTC  }]
Oct 21 20:16:07.765: INFO: 
Oct 21 20:16:07.765: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 20:16:08.773: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 20:16:08.773: INFO: ss-0  10.170.151.156  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  }]
Oct 21 20:16:08.773: INFO: ss-1  10.170.151.145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:35 +0000 UTC  }]
Oct 21 20:16:08.773: INFO: ss-2  10.170.151.141  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:35 +0000 UTC  }]
Oct 21 20:16:08.773: INFO: 
Oct 21 20:16:08.773: INFO: StatefulSet ss has not reached scale 0, at 3
Oct 21 20:16:09.781: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 20:16:09.781: INFO: ss-0  10.170.151.156  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  }]
Oct 21 20:16:09.781: INFO: 
Oct 21 20:16:09.781: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 21 20:16:10.789: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 20:16:10.789: INFO: ss-0  10.170.151.156  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  }]
Oct 21 20:16:10.789: INFO: 
Oct 21 20:16:10.789: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 21 20:16:11.798: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 20:16:11.798: INFO: ss-0  10.170.151.156  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  }]
Oct 21 20:16:11.798: INFO: 
Oct 21 20:16:11.798: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 21 20:16:12.807: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Oct 21 20:16:12.807: INFO: ss-0  10.170.151.156  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:15:14 +0000 UTC  }]
Oct 21 20:16:12.807: INFO: 
Oct 21 20:16:12.807: INFO: StatefulSet ss has not reached scale 0, at 1
Oct 21 20:16:13.814: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.950173906s
Oct 21 20:16:14.821: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.943128011s
Oct 21 20:16:15.829: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.935609105s
Oct 21 20:16:16.836: INFO: Verifying statefulset ss doesn't scale past 0 for another 928.373227ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-tsc5t
Oct 21 20:16:17.844: INFO: Scaling statefulset ss to 0
Oct 21 20:16:17.864: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 20:16:17.871: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tsc5t
Oct 21 20:16:17.877: INFO: Scaling statefulset ss to 0
Oct 21 20:16:17.898: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 20:16:17.904: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:16:17.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tsc5t" for this suite.
Oct 21 20:16:23.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:16:24.386: INFO: namespace: e2e-tests-statefulset-tsc5t, resource: bindings, ignored listing per whitelist
Oct 21 20:16:24.429: INFO: namespace e2e-tests-statefulset-tsc5t deletion completed in 6.486216224s

â€¢ [SLOW TEST:70.104 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:16:24.430: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cw29d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 21 20:16:24.738: INFO: Waiting up to 5m0s for pod "pod-a7d2dc8c-f43f-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-cw29d" to be "success or failure"
Oct 21 20:16:24.745: INFO: Pod "pod-a7d2dc8c-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.48235ms
Oct 21 20:16:26.752: INFO: Pod "pod-a7d2dc8c-f43f-11e9-a616-8a530cf33301": Phase="Running", Reason="", readiness=true. Elapsed: 2.013520576s
Oct 21 20:16:28.759: INFO: Pod "pod-a7d2dc8c-f43f-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020532908s
STEP: Saw pod success
Oct 21 20:16:28.759: INFO: Pod "pod-a7d2dc8c-f43f-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:16:28.769: INFO: Trying to get logs from node 10.170.151.156 pod pod-a7d2dc8c-f43f-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:16:28.817: INFO: Waiting for pod pod-a7d2dc8c-f43f-11e9-a616-8a530cf33301 to disappear
Oct 21 20:16:28.823: INFO: Pod pod-a7d2dc8c-f43f-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:16:28.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cw29d" for this suite.
Oct 21 20:16:34.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:16:35.056: INFO: namespace: e2e-tests-emptydir-cw29d, resource: bindings, ignored listing per whitelist
Oct 21 20:16:35.160: INFO: namespace e2e-tests-emptydir-cw29d deletion completed in 6.326990902s

â€¢ [SLOW TEST:10.730 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:16:35.162: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tw6fq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 20:16:35.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-tw6fq'
Oct 21 20:16:35.978: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 20:16:35.978: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Oct 21 20:16:35.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-tw6fq'
Oct 21 20:16:36.151: INFO: stderr: ""
Oct 21 20:16:36.151: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:16:36.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tw6fq" for this suite.
Oct 21 20:16:58.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:16:58.316: INFO: namespace: e2e-tests-kubectl-tw6fq, resource: bindings, ignored listing per whitelist
Oct 21 20:16:58.472: INFO: namespace e2e-tests-kubectl-tw6fq deletion completed in 22.31142984s

â€¢ [SLOW TEST:23.311 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:16:58.473: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-4hxd6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:16:58.790: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct 21 20:17:03.798: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 20:17:03.798: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 20:17:03.836: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-4hxd6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4hxd6/deployments/test-cleanup-deployment,UID:bf1ef482-f43f-11e9-8a4f-8adb5f5fcc88,ResourceVersion:20566,Generation:1,CreationTimestamp:2019-10-21 20:17:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Oct 21 20:17:03.845: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:17:03.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4hxd6" for this suite.
Oct 21 20:17:09.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:17:10.021: INFO: namespace: e2e-tests-deployment-4hxd6, resource: bindings, ignored listing per whitelist
Oct 21 20:17:10.214: INFO: namespace e2e-tests-deployment-4hxd6 deletion completed in 6.352800459s

â€¢ [SLOW TEST:11.740 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:17:10.214: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5lcn6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 21 20:17:10.542: INFO: Waiting up to 5m0s for pod "pod-c31f653e-f43f-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-5lcn6" to be "success or failure"
Oct 21 20:17:10.548: INFO: Pod "pod-c31f653e-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.191732ms
Oct 21 20:17:12.566: INFO: Pod "pod-c31f653e-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024503983s
Oct 21 20:17:14.574: INFO: Pod "pod-c31f653e-f43f-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031917388s
STEP: Saw pod success
Oct 21 20:17:14.574: INFO: Pod "pod-c31f653e-f43f-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:17:14.580: INFO: Trying to get logs from node 10.170.151.156 pod pod-c31f653e-f43f-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:17:14.616: INFO: Waiting for pod pod-c31f653e-f43f-11e9-a616-8a530cf33301 to disappear
Oct 21 20:17:14.639: INFO: Pod pod-c31f653e-f43f-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:17:14.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5lcn6" for this suite.
Oct 21 20:17:20.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:17:20.928: INFO: namespace: e2e-tests-emptydir-5lcn6, resource: bindings, ignored listing per whitelist
Oct 21 20:17:20.966: INFO: namespace e2e-tests-emptydir-5lcn6 deletion completed in 6.318048005s

â€¢ [SLOW TEST:10.753 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:17:20.967: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-tq5gr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:17:21.281: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9863455-f43f-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-tq5gr" to be "success or failure"
Oct 21 20:17:21.290: INFO: Pod "downwardapi-volume-c9863455-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 8.517505ms
Oct 21 20:17:23.298: INFO: Pod "downwardapi-volume-c9863455-f43f-11e9-a616-8a530cf33301": Phase="Running", Reason="", readiness=true. Elapsed: 2.016487305s
Oct 21 20:17:25.309: INFO: Pod "downwardapi-volume-c9863455-f43f-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027520613s
STEP: Saw pod success
Oct 21 20:17:25.309: INFO: Pod "downwardapi-volume-c9863455-f43f-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:17:25.315: INFO: Trying to get logs from node 10.170.151.145 pod downwardapi-volume-c9863455-f43f-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:17:25.358: INFO: Waiting for pod downwardapi-volume-c9863455-f43f-11e9-a616-8a530cf33301 to disappear
Oct 21 20:17:25.365: INFO: Pod downwardapi-volume-c9863455-f43f-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:17:25.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tq5gr" for this suite.
Oct 21 20:17:31.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:17:31.442: INFO: namespace: e2e-tests-downward-api-tq5gr, resource: bindings, ignored listing per whitelist
Oct 21 20:17:31.684: INFO: namespace e2e-tests-downward-api-tq5gr deletion completed in 6.310051844s

â€¢ [SLOW TEST:10.717 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:17:31.685: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wqtbh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cfeb0429-f43f-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:17:32.020: INFO: Waiting up to 5m0s for pod "pod-configmaps-cfec8168-f43f-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-wqtbh" to be "success or failure"
Oct 21 20:17:32.027: INFO: Pod "pod-configmaps-cfec8168-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.156221ms
Oct 21 20:17:34.034: INFO: Pod "pod-configmaps-cfec8168-f43f-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013637555s
STEP: Saw pod success
Oct 21 20:17:34.034: INFO: Pod "pod-configmaps-cfec8168-f43f-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:17:34.040: INFO: Trying to get logs from node 10.170.151.141 pod pod-configmaps-cfec8168-f43f-11e9-a616-8a530cf33301 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:17:34.078: INFO: Waiting for pod pod-configmaps-cfec8168-f43f-11e9-a616-8a530cf33301 to disappear
Oct 21 20:17:34.084: INFO: Pod pod-configmaps-cfec8168-f43f-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:17:34.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wqtbh" for this suite.
Oct 21 20:17:40.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:17:40.239: INFO: namespace: e2e-tests-configmap-wqtbh, resource: bindings, ignored listing per whitelist
Oct 21 20:17:40.417: INFO: namespace e2e-tests-configmap-wqtbh deletion completed in 6.324603826s

â€¢ [SLOW TEST:8.732 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:17:40.418: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-98nhf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:17:40.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d51cb46b-f43f-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-98nhf" to be "success or failure"
Oct 21 20:17:40.727: INFO: Pod "downwardapi-volume-d51cb46b-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.568638ms
Oct 21 20:17:42.735: INFO: Pod "downwardapi-volume-d51cb46b-f43f-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014306495s
STEP: Saw pod success
Oct 21 20:17:42.735: INFO: Pod "downwardapi-volume-d51cb46b-f43f-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:17:42.742: INFO: Trying to get logs from node 10.170.151.156 pod downwardapi-volume-d51cb46b-f43f-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:17:42.780: INFO: Waiting for pod downwardapi-volume-d51cb46b-f43f-11e9-a616-8a530cf33301 to disappear
Oct 21 20:17:42.786: INFO: Pod downwardapi-volume-d51cb46b-f43f-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:17:42.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-98nhf" for this suite.
Oct 21 20:17:48.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:17:48.845: INFO: namespace: e2e-tests-downward-api-98nhf, resource: bindings, ignored listing per whitelist
Oct 21 20:17:49.117: INFO: namespace e2e-tests-downward-api-98nhf deletion completed in 6.319515676s

â€¢ [SLOW TEST:8.699 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:17:49.118: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-4k684
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct 21 20:17:49.482: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4k684,SelfLink:/api/v1/namespaces/e2e-tests-watch-4k684/configmaps/e2e-watch-test-watch-closed,UID:da54315f-f43f-11e9-8a4f-8adb5f5fcc88,ResourceVersion:20882,Generation:0,CreationTimestamp:2019-10-21 20:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 20:17:49.483: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4k684,SelfLink:/api/v1/namespaces/e2e-tests-watch-4k684/configmaps/e2e-watch-test-watch-closed,UID:da54315f-f43f-11e9-8a4f-8adb5f5fcc88,ResourceVersion:20883,Generation:0,CreationTimestamp:2019-10-21 20:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct 21 20:17:49.523: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4k684,SelfLink:/api/v1/namespaces/e2e-tests-watch-4k684/configmaps/e2e-watch-test-watch-closed,UID:da54315f-f43f-11e9-8a4f-8adb5f5fcc88,ResourceVersion:20884,Generation:0,CreationTimestamp:2019-10-21 20:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 20:17:49.523: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-4k684,SelfLink:/api/v1/namespaces/e2e-tests-watch-4k684/configmaps/e2e-watch-test-watch-closed,UID:da54315f-f43f-11e9-8a4f-8adb5f5fcc88,ResourceVersion:20885,Generation:0,CreationTimestamp:2019-10-21 20:17:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:17:49.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4k684" for this suite.
Oct 21 20:17:55.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:17:55.822: INFO: namespace: e2e-tests-watch-4k684, resource: bindings, ignored listing per whitelist
Oct 21 20:17:55.859: INFO: namespace e2e-tests-watch-4k684 deletion completed in 6.326078624s

â€¢ [SLOW TEST:6.741 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:17:55.859: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-lbtp6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:17:56.209: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Oct 21 20:17:56.229: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lbtp6/daemonsets","resourceVersion":"20912"},"items":null}

Oct 21 20:17:56.235: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lbtp6/pods","resourceVersion":"20912"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:17:56.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lbtp6" for this suite.
Oct 21 20:18:02.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:18:02.396: INFO: namespace: e2e-tests-daemonsets-lbtp6, resource: bindings, ignored listing per whitelist
Oct 21 20:18:02.607: INFO: namespace e2e-tests-daemonsets-lbtp6 deletion completed in 6.317555443s

S [SKIPPING] [6.748 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Oct 21 20:17:56.209: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:18:02.608: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z4hzr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:18:02.934: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e25a4534-f43f-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-z4hzr" to be "success or failure"
Oct 21 20:18:02.941: INFO: Pod "downwardapi-volume-e25a4534-f43f-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.413053ms
Oct 21 20:18:04.948: INFO: Pod "downwardapi-volume-e25a4534-f43f-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013685087s
STEP: Saw pod success
Oct 21 20:18:04.949: INFO: Pod "downwardapi-volume-e25a4534-f43f-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:18:04.956: INFO: Trying to get logs from node 10.170.151.145 pod downwardapi-volume-e25a4534-f43f-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:18:04.991: INFO: Waiting for pod downwardapi-volume-e25a4534-f43f-11e9-a616-8a530cf33301 to disappear
Oct 21 20:18:04.997: INFO: Pod downwardapi-volume-e25a4534-f43f-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:18:04.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z4hzr" for this suite.
Oct 21 20:18:11.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:18:11.240: INFO: namespace: e2e-tests-projected-z4hzr, resource: bindings, ignored listing per whitelist
Oct 21 20:18:11.319: INFO: namespace e2e-tests-projected-z4hzr deletion completed in 6.312374822s

â€¢ [SLOW TEST:8.712 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:18:11.319: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-x2nsl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Oct 21 20:18:16.183: INFO: Successfully updated pod "labelsupdatee788a1ba-f43f-11e9-a616-8a530cf33301"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:18:18.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x2nsl" for this suite.
Oct 21 20:18:42.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:18:42.522: INFO: namespace: e2e-tests-projected-x2nsl, resource: bindings, ignored listing per whitelist
Oct 21 20:18:42.563: INFO: namespace e2e-tests-projected-x2nsl deletion completed in 24.335912236s

â€¢ [SLOW TEST:31.244 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:18:42.564: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-2znwm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 21 20:18:42.873: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 20:18:42.891: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 20:18:42.900: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.141 before test
Oct 21 20:18:42.924: INFO: ibm-file-plugin-5978669657-p76mk from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 20:18:42.924: INFO: sonobuoy from sonobuoy started at 2019-10-21 19:54:34 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 20:18:42.924: INFO: vpn-85755bfd8b-mgkzx from kube-system started at 2019-10-21 19:05:50 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container vpn ready: true, restart count 0
Oct 21 20:18:42.924: INFO: coredns-6d59786485-bqmjp from kube-system started at 2019-10-21 19:08:10 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container coredns ready: true, restart count 0
Oct 21 20:18:42.924: INFO: coredns-autoscaler-64f9c5b4df-9r7mj from kube-system started at 2019-10-21 19:07:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 20:18:42.924: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-dzdbt from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 20:18:42.924: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 20:18:42.924: INFO: ibm-cloud-provider-ip-169-45-227-188-d7c997c79-ss8xf from ibm-system started at 2019-10-21 18:42:59 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container ibm-cloud-provider-ip-169-45-227-188 ready: true, restart count 0
Oct 21 20:18:42.924: INFO: calico-node-bzvgs from kube-system started at 2019-10-21 18:42:09 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 20:18:42.924: INFO: ibm-storage-watcher-6d9866b77c-h5m5n from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.924: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 20:18:42.925: INFO: ibm-master-proxy-static-10.170.151.141 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 20:18:42.925: INFO: ibm-kube-fluentd-sk72w from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.925: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 20:18:42.925: INFO: calico-kube-controllers-94b69ddc9-g4p7g from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.925: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 20:18:42.925: INFO: kubernetes-dashboard-7996b848f4-5kt8s from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.925: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 20:18:42.925: INFO: ibm-keepalived-watcher-vxdfw from kube-system started at 2019-10-21 18:42:09 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.925: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 20:18:42.925: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.145 before test
Oct 21 20:18:42.948: INFO: ibm-keepalived-watcher-xwtxv from kube-system started at 2019-10-21 18:42:43 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.948: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 20:18:42.948: INFO: public-crbmmvhg4w0qp7koa8k1fg-alb1-6b94587c89-tkmzl from kube-system started at 2019-10-21 18:47:24 +0000 UTC (4 container statuses recorded)
Oct 21 20:18:42.948: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 20:18:42.948: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 20:18:42.948: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 20:18:42.948: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 20:18:42.948: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-gzf4s from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 20:18:42.948: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 20:18:42.948: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 20:18:42.948: INFO: ibm-master-proxy-static-10.170.151.145 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 20:18:42.948: INFO: calico-node-6pp5r from kube-system started at 2019-10-21 18:42:43 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.948: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 20:18:42.948: INFO: coredns-6d59786485-27lhz from kube-system started at 2019-10-21 19:08:10 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.948: INFO: 	Container coredns ready: true, restart count 0
Oct 21 20:18:42.948: INFO: sonobuoy-e2e-job-ed893f17f84e497d from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 20:18:42.948: INFO: 	Container e2e ready: true, restart count 0
Oct 21 20:18:42.948: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 20:18:42.948: INFO: ibm-kube-fluentd-x96pz from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.948: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 20:18:42.948: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.156 before test
Oct 21 20:18:42.970: INFO: ibm-master-proxy-static-10.170.151.156 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 20:18:42.970: INFO: metrics-server-c64cd58dc-7bp6m from kube-system started at 2019-10-21 18:42:53 +0000 UTC (2 container statuses recorded)
Oct 21 20:18:42.970: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 20:18:42.970: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 21 20:18:42.970: INFO: calico-node-mjzv8 from kube-system started at 2019-10-21 18:42:35 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.970: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 20:18:42.970: INFO: ibm-kube-fluentd-pkfzs from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.970: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 20:18:42.970: INFO: ibm-keepalived-watcher-zb6kn from kube-system started at 2019-10-21 18:42:35 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.970: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 20:18:42.970: INFO: ibm-cloud-provider-ip-169-45-227-188-d7c997c79-qtsb6 from ibm-system started at 2019-10-21 18:42:59 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.970: INFO: 	Container ibm-cloud-provider-ip-169-45-227-188 ready: true, restart count 0
Oct 21 20:18:42.970: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-44c55 from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 20:18:42.970: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 20:18:42.970: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 20:18:42.970: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 18:46:38 +0000 UTC (1 container statuses recorded)
Oct 21 20:18:42.970: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct 21 20:18:42.970: INFO: public-crbmmvhg4w0qp7koa8k1fg-alb1-6b94587c89-dxlp4 from kube-system started at 2019-10-21 18:47:24 +0000 UTC (4 container statuses recorded)
Oct 21 20:18:42.970: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 20:18:42.970: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 20:18:42.970: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 20:18:42.970: INFO: 	Container nginx-ingress ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15cfc2ee2289d83e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:18:44.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-2znwm" for this suite.
Oct 21 20:18:50.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:18:50.317: INFO: namespace: e2e-tests-sched-pred-2znwm, resource: bindings, ignored listing per whitelist
Oct 21 20:18:50.581: INFO: namespace e2e-tests-sched-pred-2znwm deletion completed in 6.548712446s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:8.017 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:18:50.581: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-flb5n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Oct 21 20:18:50.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-flb5n'
Oct 21 20:18:51.118: INFO: stderr: ""
Oct 21 20:18:51.118: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 20:18:52.126: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:18:52.126: INFO: Found 0 / 1
Oct 21 20:18:53.126: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:18:53.126: INFO: Found 0 / 1
Oct 21 20:18:54.126: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:18:54.126: INFO: Found 1 / 1
Oct 21 20:18:54.126: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct 21 20:18:54.133: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:18:54.133: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 20:18:54.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 patch pod redis-master-82tkx --namespace=e2e-tests-kubectl-flb5n -p {"metadata":{"annotations":{"x":"y"}}}'
Oct 21 20:18:54.277: INFO: stderr: ""
Oct 21 20:18:54.277: INFO: stdout: "pod/redis-master-82tkx patched\n"
STEP: checking annotations
Oct 21 20:18:54.286: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:18:54.286: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:18:54.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-flb5n" for this suite.
Oct 21 20:19:18.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:19:18.697: INFO: namespace: e2e-tests-kubectl-flb5n, resource: bindings, ignored listing per whitelist
Oct 21 20:19:18.734: INFO: namespace e2e-tests-kubectl-flb5n deletion completed in 24.43899049s

â€¢ [SLOW TEST:28.153 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:19:18.736: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wz6qs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Oct 21 20:19:19.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:19.354: INFO: stderr: ""
Oct 21 20:19:19.354: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct 21 20:19:19.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:19.481: INFO: stderr: ""
Oct 21 20:19:19.481: INFO: stdout: "update-demo-nautilus-lxqlw update-demo-nautilus-wcq9q "
Oct 21 20:19:19.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-lxqlw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:19.594: INFO: stderr: ""
Oct 21 20:19:19.594: INFO: stdout: ""
Oct 21 20:19:19.594: INFO: update-demo-nautilus-lxqlw is created but not running
Oct 21 20:19:24.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:24.716: INFO: stderr: ""
Oct 21 20:19:24.716: INFO: stdout: "update-demo-nautilus-lxqlw update-demo-nautilus-wcq9q "
Oct 21 20:19:24.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-lxqlw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:24.838: INFO: stderr: ""
Oct 21 20:19:24.838: INFO: stdout: "true"
Oct 21 20:19:24.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-lxqlw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:24.973: INFO: stderr: ""
Oct 21 20:19:24.973: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:19:24.973: INFO: validating pod update-demo-nautilus-lxqlw
Oct 21 20:19:24.987: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:19:24.987: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:19:24.987: INFO: update-demo-nautilus-lxqlw is verified up and running
Oct 21 20:19:24.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-wcq9q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:25.113: INFO: stderr: ""
Oct 21 20:19:25.113: INFO: stdout: "true"
Oct 21 20:19:25.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods update-demo-nautilus-wcq9q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:25.229: INFO: stderr: ""
Oct 21 20:19:25.229: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct 21 20:19:25.229: INFO: validating pod update-demo-nautilus-wcq9q
Oct 21 20:19:25.246: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct 21 20:19:25.246: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct 21 20:19:25.246: INFO: update-demo-nautilus-wcq9q is verified up and running
STEP: using delete to clean up resources
Oct 21 20:19:25.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:25.381: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 20:19:25.381: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct 21 20:19:25.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-wz6qs'
Oct 21 20:19:25.555: INFO: stderr: "No resources found.\n"
Oct 21 20:19:25.555: INFO: stdout: ""
Oct 21 20:19:25.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -l name=update-demo --namespace=e2e-tests-kubectl-wz6qs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 20:19:25.682: INFO: stderr: ""
Oct 21 20:19:25.682: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:19:25.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wz6qs" for this suite.
Oct 21 20:19:31.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:19:31.992: INFO: namespace: e2e-tests-kubectl-wz6qs, resource: bindings, ignored listing per whitelist
Oct 21 20:19:31.992: INFO: namespace e2e-tests-kubectl-wz6qs deletion completed in 6.299343319s

â€¢ [SLOW TEST:13.256 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:19:31.993: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-brpws
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-brpws
Oct 21 20:19:36.320: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-brpws
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 20:19:36.328: INFO: Initial restart count of pod liveness-http is 0
Oct 21 20:20:00.426: INFO: Restart count of pod e2e-tests-container-probe-brpws/liveness-http is now 1 (24.098499738s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:20:00.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-brpws" for this suite.
Oct 21 20:20:06.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:20:06.615: INFO: namespace: e2e-tests-container-probe-brpws, resource: bindings, ignored listing per whitelist
Oct 21 20:20:06.809: INFO: namespace e2e-tests-container-probe-brpws deletion completed in 6.339395721s

â€¢ [SLOW TEST:34.817 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:20:06.809: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dcs2h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2c63b4ef-f440-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:20:07.155: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2c64fa40-f440-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-dcs2h" to be "success or failure"
Oct 21 20:20:07.163: INFO: Pod "pod-projected-secrets-2c64fa40-f440-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.024156ms
Oct 21 20:20:09.170: INFO: Pod "pod-projected-secrets-2c64fa40-f440-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014410316s
STEP: Saw pod success
Oct 21 20:20:09.170: INFO: Pod "pod-projected-secrets-2c64fa40-f440-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:20:09.176: INFO: Trying to get logs from node 10.170.151.145 pod pod-projected-secrets-2c64fa40-f440-11e9-a616-8a530cf33301 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:20:09.212: INFO: Waiting for pod pod-projected-secrets-2c64fa40-f440-11e9-a616-8a530cf33301 to disappear
Oct 21 20:20:09.218: INFO: Pod pod-projected-secrets-2c64fa40-f440-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:20:09.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dcs2h" for this suite.
Oct 21 20:20:15.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:20:15.270: INFO: namespace: e2e-tests-projected-dcs2h, resource: bindings, ignored listing per whitelist
Oct 21 20:20:15.527: INFO: namespace e2e-tests-projected-dcs2h deletion completed in 6.299425023s

â€¢ [SLOW TEST:8.718 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:20:15.529: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-s975l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1021 20:20:25.894050      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 20:20:25.894: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:20:25.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-s975l" for this suite.
Oct 21 20:20:31.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:20:32.163: INFO: namespace: e2e-tests-gc-s975l, resource: bindings, ignored listing per whitelist
Oct 21 20:20:32.224: INFO: namespace e2e-tests-gc-s975l deletion completed in 6.322621273s

â€¢ [SLOW TEST:16.695 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:20:32.224: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-g4plw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1021 20:21:12.606169      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 20:21:12.606: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:21:12.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g4plw" for this suite.
Oct 21 20:21:20.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:21:20.779: INFO: namespace: e2e-tests-gc-g4plw, resource: bindings, ignored listing per whitelist
Oct 21 20:21:21.025: INFO: namespace e2e-tests-gc-g4plw deletion completed in 8.410689017s

â€¢ [SLOW TEST:48.801 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:21:21.025: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-chnmh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:21:23.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-chnmh" for this suite.
Oct 21 20:22:03.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:22:03.615: INFO: namespace: e2e-tests-kubelet-test-chnmh, resource: bindings, ignored listing per whitelist
Oct 21 20:22:03.709: INFO: namespace e2e-tests-kubelet-test-chnmh deletion completed in 40.321525218s

â€¢ [SLOW TEST:42.683 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:22:03.711: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-p4wd2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct 21 20:22:04.090: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p4wd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-p4wd2/configmaps/e2e-watch-test-label-changed,UID:7213158c-f440-11e9-8a4f-8adb5f5fcc88,ResourceVersion:22008,Generation:0,CreationTimestamp:2019-10-21 20:22:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 20:22:04.090: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p4wd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-p4wd2/configmaps/e2e-watch-test-label-changed,UID:7213158c-f440-11e9-8a4f-8adb5f5fcc88,ResourceVersion:22009,Generation:0,CreationTimestamp:2019-10-21 20:22:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 21 20:22:04.091: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p4wd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-p4wd2/configmaps/e2e-watch-test-label-changed,UID:7213158c-f440-11e9-8a4f-8adb5f5fcc88,ResourceVersion:22010,Generation:0,CreationTimestamp:2019-10-21 20:22:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct 21 20:22:14.174: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p4wd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-p4wd2/configmaps/e2e-watch-test-label-changed,UID:7213158c-f440-11e9-8a4f-8adb5f5fcc88,ResourceVersion:22028,Generation:0,CreationTimestamp:2019-10-21 20:22:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 20:22:14.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p4wd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-p4wd2/configmaps/e2e-watch-test-label-changed,UID:7213158c-f440-11e9-8a4f-8adb5f5fcc88,ResourceVersion:22029,Generation:0,CreationTimestamp:2019-10-21 20:22:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct 21 20:22:14.174: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-p4wd2,SelfLink:/api/v1/namespaces/e2e-tests-watch-p4wd2/configmaps/e2e-watch-test-label-changed,UID:7213158c-f440-11e9-8a4f-8adb5f5fcc88,ResourceVersion:22030,Generation:0,CreationTimestamp:2019-10-21 20:22:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:22:14.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-p4wd2" for this suite.
Oct 21 20:22:20.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:22:20.374: INFO: namespace: e2e-tests-watch-p4wd2, resource: bindings, ignored listing per whitelist
Oct 21 20:22:20.487: INFO: namespace e2e-tests-watch-p4wd2 deletion completed in 6.30280743s

â€¢ [SLOW TEST:16.777 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:22:20.489: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-8ss7t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct 21 20:22:20.808: INFO: Pod name pod-release: Found 0 pods out of 1
Oct 21 20:22:25.820: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:22:26.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8ss7t" for this suite.
Oct 21 20:22:32.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:22:33.017: INFO: namespace: e2e-tests-replication-controller-8ss7t, resource: bindings, ignored listing per whitelist
Oct 21 20:22:33.160: INFO: namespace e2e-tests-replication-controller-8ss7t deletion completed in 6.299570866s

â€¢ [SLOW TEST:12.672 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:22:33.161: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8kjjg
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-839d5f85-f440-11e9-a616-8a530cf33301
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:22:35.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8kjjg" for this suite.
Oct 21 20:22:59.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:22:59.773: INFO: namespace: e2e-tests-configmap-8kjjg, resource: bindings, ignored listing per whitelist
Oct 21 20:22:59.872: INFO: namespace e2e-tests-configmap-8kjjg deletion completed in 24.309704526s

â€¢ [SLOW TEST:26.711 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:22:59.873: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-64z99
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1021 20:23:30.762122      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 20:23:30.762: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:23:30.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-64z99" for this suite.
Oct 21 20:23:36.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:23:36.864: INFO: namespace: e2e-tests-gc-64z99, resource: bindings, ignored listing per whitelist
Oct 21 20:23:37.061: INFO: namespace e2e-tests-gc-64z99 deletion completed in 6.28888194s

â€¢ [SLOW TEST:37.188 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:23:37.062: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8lk9d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-8lk9d/configmap-test-a9b34a6f-f440-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:23:37.393: INFO: Waiting up to 5m0s for pod "pod-configmaps-a9b4c350-f440-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-8lk9d" to be "success or failure"
Oct 21 20:23:37.399: INFO: Pod "pod-configmaps-a9b4c350-f440-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 5.992202ms
Oct 21 20:23:39.409: INFO: Pod "pod-configmaps-a9b4c350-f440-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015377602s
STEP: Saw pod success
Oct 21 20:23:39.409: INFO: Pod "pod-configmaps-a9b4c350-f440-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:23:39.415: INFO: Trying to get logs from node 10.170.151.141 pod pod-configmaps-a9b4c350-f440-11e9-a616-8a530cf33301 container env-test: <nil>
STEP: delete the pod
Oct 21 20:23:39.450: INFO: Waiting for pod pod-configmaps-a9b4c350-f440-11e9-a616-8a530cf33301 to disappear
Oct 21 20:23:39.456: INFO: Pod pod-configmaps-a9b4c350-f440-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:23:39.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8lk9d" for this suite.
Oct 21 20:23:45.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:23:45.731: INFO: namespace: e2e-tests-configmap-8lk9d, resource: bindings, ignored listing per whitelist
Oct 21 20:23:45.774: INFO: namespace e2e-tests-configmap-8lk9d deletion completed in 6.306531808s

â€¢ [SLOW TEST:8.712 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:23:45.776: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wj7fn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Oct 21 20:23:46.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 api-versions'
Oct 21 20:23:46.214: INFO: stderr: ""
Oct 21 20:23:46.214: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:23:46.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wj7fn" for this suite.
Oct 21 20:23:52.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:23:52.640: INFO: namespace: e2e-tests-kubectl-wj7fn, resource: bindings, ignored listing per whitelist
Oct 21 20:23:52.677: INFO: namespace e2e-tests-kubectl-wj7fn deletion completed in 6.451762255s

â€¢ [SLOW TEST:6.901 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:23:52.677: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7mhh4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:23:53.084: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b30ec951-f440-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-7mhh4" to be "success or failure"
Oct 21 20:23:53.090: INFO: Pod "downwardapi-volume-b30ec951-f440-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.525227ms
Oct 21 20:23:55.098: INFO: Pod "downwardapi-volume-b30ec951-f440-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014018368s
STEP: Saw pod success
Oct 21 20:23:55.098: INFO: Pod "downwardapi-volume-b30ec951-f440-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:23:55.105: INFO: Trying to get logs from node 10.170.151.156 pod downwardapi-volume-b30ec951-f440-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:23:55.156: INFO: Waiting for pod downwardapi-volume-b30ec951-f440-11e9-a616-8a530cf33301 to disappear
Oct 21 20:23:55.162: INFO: Pod downwardapi-volume-b30ec951-f440-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:23:55.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7mhh4" for this suite.
Oct 21 20:24:01.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:24:01.450: INFO: namespace: e2e-tests-projected-7mhh4, resource: bindings, ignored listing per whitelist
Oct 21 20:24:01.534: INFO: namespace e2e-tests-projected-7mhh4 deletion completed in 6.359393113s

â€¢ [SLOW TEST:8.857 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:24:01.534: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2fdc5
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-b84a6eaa-f440-11e9-a616-8a530cf33301
STEP: Creating configMap with name cm-test-opt-upd-b84a6f0b-f440-11e9-a616-8a530cf33301
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b84a6eaa-f440-11e9-a616-8a530cf33301
STEP: Updating configmap cm-test-opt-upd-b84a6f0b-f440-11e9-a616-8a530cf33301
STEP: Creating configMap with name cm-test-opt-create-b84a6f35-f440-11e9-a616-8a530cf33301
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:24:08.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2fdc5" for this suite.
Oct 21 20:24:32.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:24:32.387: INFO: namespace: e2e-tests-projected-2fdc5, resource: bindings, ignored listing per whitelist
Oct 21 20:24:32.396: INFO: namespace e2e-tests-projected-2fdc5 deletion completed in 24.331241258s

â€¢ [SLOW TEST:30.862 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:24:32.396: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xbvh5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-caad3c5e-f440-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:24:32.719: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-caae69a1-f440-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-xbvh5" to be "success or failure"
Oct 21 20:24:32.727: INFO: Pod "pod-projected-secrets-caae69a1-f440-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.766748ms
Oct 21 20:24:34.734: INFO: Pod "pod-projected-secrets-caae69a1-f440-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015575154s
STEP: Saw pod success
Oct 21 20:24:34.735: INFO: Pod "pod-projected-secrets-caae69a1-f440-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:24:34.741: INFO: Trying to get logs from node 10.170.151.141 pod pod-projected-secrets-caae69a1-f440-11e9-a616-8a530cf33301 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:24:34.776: INFO: Waiting for pod pod-projected-secrets-caae69a1-f440-11e9-a616-8a530cf33301 to disappear
Oct 21 20:24:34.782: INFO: Pod pod-projected-secrets-caae69a1-f440-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:24:34.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xbvh5" for this suite.
Oct 21 20:24:40.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:24:40.905: INFO: namespace: e2e-tests-projected-xbvh5, resource: bindings, ignored listing per whitelist
Oct 21 20:24:41.112: INFO: namespace e2e-tests-projected-xbvh5 deletion completed in 6.319736415s

â€¢ [SLOW TEST:8.716 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:24:41.112: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j9zbc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:24:41.406: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfdc5c2f-f440-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-j9zbc" to be "success or failure"
Oct 21 20:24:41.422: INFO: Pod "downwardapi-volume-cfdc5c2f-f440-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 15.604715ms
Oct 21 20:24:43.429: INFO: Pod "downwardapi-volume-cfdc5c2f-f440-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022909868s
STEP: Saw pod success
Oct 21 20:24:43.429: INFO: Pod "downwardapi-volume-cfdc5c2f-f440-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:24:43.436: INFO: Trying to get logs from node 10.170.151.156 pod downwardapi-volume-cfdc5c2f-f440-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:24:43.473: INFO: Waiting for pod downwardapi-volume-cfdc5c2f-f440-11e9-a616-8a530cf33301 to disappear
Oct 21 20:24:43.478: INFO: Pod downwardapi-volume-cfdc5c2f-f440-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:24:43.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j9zbc" for this suite.
Oct 21 20:24:49.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:24:49.633: INFO: namespace: e2e-tests-projected-j9zbc, resource: bindings, ignored listing per whitelist
Oct 21 20:24:49.816: INFO: namespace e2e-tests-projected-j9zbc deletion completed in 6.327772544s

â€¢ [SLOW TEST:8.704 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:24:49.816: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qvzhk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 21 20:24:50.149: INFO: Waiting up to 5m0s for pod "downward-api-d5125a0e-f440-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-qvzhk" to be "success or failure"
Oct 21 20:24:50.157: INFO: Pod "downward-api-d5125a0e-f440-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.281399ms
Oct 21 20:24:52.163: INFO: Pod "downward-api-d5125a0e-f440-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013926922s
Oct 21 20:24:54.171: INFO: Pod "downward-api-d5125a0e-f440-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02147027s
STEP: Saw pod success
Oct 21 20:24:54.171: INFO: Pod "downward-api-d5125a0e-f440-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:24:54.177: INFO: Trying to get logs from node 10.170.151.156 pod downward-api-d5125a0e-f440-11e9-a616-8a530cf33301 container dapi-container: <nil>
STEP: delete the pod
Oct 21 20:24:54.211: INFO: Waiting for pod downward-api-d5125a0e-f440-11e9-a616-8a530cf33301 to disappear
Oct 21 20:24:54.217: INFO: Pod downward-api-d5125a0e-f440-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:24:54.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qvzhk" for this suite.
Oct 21 20:25:00.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:25:00.403: INFO: namespace: e2e-tests-downward-api-qvzhk, resource: bindings, ignored listing per whitelist
Oct 21 20:25:00.642: INFO: namespace e2e-tests-downward-api-qvzhk deletion completed in 6.415004406s

â€¢ [SLOW TEST:10.826 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:25:00.643: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-npmsc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 21 20:25:00.984: INFO: Waiting up to 5m0s for pod "pod-db875588-f440-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-npmsc" to be "success or failure"
Oct 21 20:25:00.991: INFO: Pod "pod-db875588-f440-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.332358ms
Oct 21 20:25:02.997: INFO: Pod "pod-db875588-f440-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013167324s
STEP: Saw pod success
Oct 21 20:25:02.998: INFO: Pod "pod-db875588-f440-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:25:03.004: INFO: Trying to get logs from node 10.170.151.141 pod pod-db875588-f440-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:25:03.039: INFO: Waiting for pod pod-db875588-f440-11e9-a616-8a530cf33301 to disappear
Oct 21 20:25:03.046: INFO: Pod pod-db875588-f440-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:25:03.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-npmsc" for this suite.
Oct 21 20:25:09.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:25:09.342: INFO: namespace: e2e-tests-emptydir-npmsc, resource: bindings, ignored listing per whitelist
Oct 21 20:25:09.398: INFO: namespace e2e-tests-emptydir-npmsc deletion completed in 6.342278961s

â€¢ [SLOW TEST:8.755 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:25:09.399: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-cb2pz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 21 20:25:09.694: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 20:25:09.722: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 20:25:09.731: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.141 before test
Oct 21 20:25:09.756: INFO: calico-node-bzvgs from kube-system started at 2019-10-21 18:42:09 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 20:25:09.756: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-dzdbt from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 20:25:09.756: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 20:25:09.756: INFO: ibm-cloud-provider-ip-169-45-227-188-d7c997c79-ss8xf from ibm-system started at 2019-10-21 18:42:59 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container ibm-cloud-provider-ip-169-45-227-188 ready: true, restart count 0
Oct 21 20:25:09.756: INFO: ibm-master-proxy-static-10.170.151.141 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 20:25:09.756: INFO: ibm-storage-watcher-6d9866b77c-h5m5n from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 20:25:09.756: INFO: ibm-keepalived-watcher-vxdfw from kube-system started at 2019-10-21 18:42:09 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 20:25:09.756: INFO: ibm-kube-fluentd-sk72w from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 20:25:09.756: INFO: calico-kube-controllers-94b69ddc9-g4p7g from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 20:25:09.756: INFO: kubernetes-dashboard-7996b848f4-5kt8s from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 20:25:09.756: INFO: coredns-autoscaler-64f9c5b4df-9r7mj from kube-system started at 2019-10-21 19:07:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 20:25:09.756: INFO: ibm-file-plugin-5978669657-p76mk from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 20:25:09.756: INFO: sonobuoy from sonobuoy started at 2019-10-21 19:54:34 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 20:25:09.756: INFO: vpn-85755bfd8b-mgkzx from kube-system started at 2019-10-21 19:05:50 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container vpn ready: true, restart count 0
Oct 21 20:25:09.756: INFO: coredns-6d59786485-bqmjp from kube-system started at 2019-10-21 19:08:10 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.756: INFO: 	Container coredns ready: true, restart count 0
Oct 21 20:25:09.756: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.145 before test
Oct 21 20:25:09.798: INFO: sonobuoy-e2e-job-ed893f17f84e497d from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 20:25:09.799: INFO: 	Container e2e ready: true, restart count 0
Oct 21 20:25:09.799: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 20:25:09.799: INFO: ibm-kube-fluentd-x96pz from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.799: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 20:25:09.799: INFO: calico-node-6pp5r from kube-system started at 2019-10-21 18:42:43 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.799: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 20:25:09.799: INFO: coredns-6d59786485-27lhz from kube-system started at 2019-10-21 19:08:10 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.800: INFO: 	Container coredns ready: true, restart count 0
Oct 21 20:25:09.800: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-gzf4s from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 20:25:09.800: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 20:25:09.800: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 20:25:09.800: INFO: ibm-master-proxy-static-10.170.151.145 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 20:25:09.800: INFO: ibm-keepalived-watcher-xwtxv from kube-system started at 2019-10-21 18:42:43 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.800: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 20:25:09.800: INFO: public-crbmmvhg4w0qp7koa8k1fg-alb1-6b94587c89-tkmzl from kube-system started at 2019-10-21 18:47:24 +0000 UTC (4 container statuses recorded)
Oct 21 20:25:09.801: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 20:25:09.801: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 20:25:09.801: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 20:25:09.801: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 20:25:09.801: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.156 before test
Oct 21 20:25:09.828: INFO: ibm-keepalived-watcher-zb6kn from kube-system started at 2019-10-21 18:42:35 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.828: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 20:25:09.828: INFO: ibm-cloud-provider-ip-169-45-227-188-d7c997c79-qtsb6 from ibm-system started at 2019-10-21 18:42:59 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.828: INFO: 	Container ibm-cloud-provider-ip-169-45-227-188 ready: true, restart count 0
Oct 21 20:25:09.828: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-44c55 from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 20:25:09.828: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 20:25:09.828: INFO: 	Container systemd-logs ready: true, restart count 0
Oct 21 20:25:09.828: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 18:46:38 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.828: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct 21 20:25:09.828: INFO: public-crbmmvhg4w0qp7koa8k1fg-alb1-6b94587c89-dxlp4 from kube-system started at 2019-10-21 18:47:24 +0000 UTC (4 container statuses recorded)
Oct 21 20:25:09.828: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 20:25:09.828: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 20:25:09.828: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 20:25:09.828: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 20:25:09.828: INFO: ibm-master-proxy-static-10.170.151.156 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 20:25:09.828: INFO: metrics-server-c64cd58dc-7bp6m from kube-system started at 2019-10-21 18:42:53 +0000 UTC (2 container statuses recorded)
Oct 21 20:25:09.828: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 20:25:09.828: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 21 20:25:09.828: INFO: calico-node-mjzv8 from kube-system started at 2019-10-21 18:42:35 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.828: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 20:25:09.828: INFO: ibm-kube-fluentd-pkfzs from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 20:25:09.828: INFO: 	Container fluentd ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.170.151.141
STEP: verifying the node has the label node 10.170.151.145
STEP: verifying the node has the label node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod ibm-cloud-provider-ip-169-45-227-188-d7c997c79-qtsb6 requesting resource cpu=5m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod ibm-cloud-provider-ip-169-45-227-188-d7c997c79-ss8xf requesting resource cpu=5m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod calico-kube-controllers-94b69ddc9-g4p7g requesting resource cpu=10m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod calico-node-6pp5r requesting resource cpu=250m on Node 10.170.151.145
Oct 21 20:25:09.917: INFO: Pod calico-node-bzvgs requesting resource cpu=250m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod calico-node-mjzv8 requesting resource cpu=250m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod coredns-6d59786485-27lhz requesting resource cpu=100m on Node 10.170.151.145
Oct 21 20:25:09.917: INFO: Pod coredns-6d59786485-bqmjp requesting resource cpu=100m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod coredns-autoscaler-64f9c5b4df-9r7mj requesting resource cpu=20m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod ibm-file-plugin-5978669657-p76mk requesting resource cpu=50m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod ibm-keepalived-watcher-vxdfw requesting resource cpu=5m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod ibm-keepalived-watcher-xwtxv requesting resource cpu=5m on Node 10.170.151.145
Oct 21 20:25:09.917: INFO: Pod ibm-keepalived-watcher-zb6kn requesting resource cpu=5m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod ibm-kube-fluentd-pkfzs requesting resource cpu=25m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod ibm-kube-fluentd-sk72w requesting resource cpu=25m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod ibm-kube-fluentd-x96pz requesting resource cpu=25m on Node 10.170.151.145
Oct 21 20:25:09.917: INFO: Pod ibm-master-proxy-static-10.170.151.141 requesting resource cpu=25m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod ibm-master-proxy-static-10.170.151.145 requesting resource cpu=25m on Node 10.170.151.145
Oct 21 20:25:09.917: INFO: Pod ibm-master-proxy-static-10.170.151.156 requesting resource cpu=25m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod ibm-storage-watcher-6d9866b77c-h5m5n requesting resource cpu=50m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod kubernetes-dashboard-7996b848f4-5kt8s requesting resource cpu=50m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod metrics-server-c64cd58dc-7bp6m requesting resource cpu=53m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod public-crbmmvhg4w0qp7koa8k1fg-alb1-6b94587c89-dxlp4 requesting resource cpu=0m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod public-crbmmvhg4w0qp7koa8k1fg-alb1-6b94587c89-tkmzl requesting resource cpu=0m on Node 10.170.151.145
Oct 21 20:25:09.917: INFO: Pod vpn-85755bfd8b-mgkzx requesting resource cpu=5m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod sonobuoy-e2e-job-ed893f17f84e497d requesting resource cpu=0m on Node 10.170.151.145
Oct 21 20:25:09.917: INFO: Pod sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-44c55 requesting resource cpu=0m on Node 10.170.151.156
Oct 21 20:25:09.917: INFO: Pod sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-dzdbt requesting resource cpu=0m on Node 10.170.151.141
Oct 21 20:25:09.917: INFO: Pod sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-gzf4s requesting resource cpu=0m on Node 10.170.151.145
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0dcfe54-f440-11e9-a616-8a530cf33301.15cfc348393bddc0], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-cb2pz/filler-pod-e0dcfe54-f440-11e9-a616-8a530cf33301 to 10.170.151.145]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0dcfe54-f440-11e9-a616-8a530cf33301.15cfc348770241f5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0dcfe54-f440-11e9-a616-8a530cf33301.15cfc3487a747743], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0dcfe54-f440-11e9-a616-8a530cf33301.15cfc34883efc4bd], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0df7d27-f440-11e9-a616-8a530cf33301.15cfc34839b6a6eb], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-cb2pz/filler-pod-e0df7d27-f440-11e9-a616-8a530cf33301 to 10.170.151.156]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0df7d27-f440-11e9-a616-8a530cf33301.15cfc34874736d38], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0df7d27-f440-11e9-a616-8a530cf33301.15cfc34878936186], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0df7d27-f440-11e9-a616-8a530cf33301.15cfc34882464ae0], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0e0c66e-f440-11e9-a616-8a530cf33301.15cfc3483a3e87ef], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-cb2pz/filler-pod-e0e0c66e-f440-11e9-a616-8a530cf33301 to 10.170.151.141]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0e0c66e-f440-11e9-a616-8a530cf33301.15cfc34874984265], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0e0c66e-f440-11e9-a616-8a530cf33301.15cfc34878b08c5c], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e0e0c66e-f440-11e9-a616-8a530cf33301.15cfc3488381ee32], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15cfc348b4002870], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.170.151.141
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.170.151.145
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.170.151.156
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:25:13.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-cb2pz" for this suite.
Oct 21 20:25:19.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:25:19.392: INFO: namespace: e2e-tests-sched-pred-cb2pz, resource: bindings, ignored listing per whitelist
Oct 21 20:25:19.424: INFO: namespace e2e-tests-sched-pred-cb2pz deletion completed in 6.332587018s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:10.026 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:25:19.424: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b86s8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Oct 21 20:25:19.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-b86s8'
Oct 21 20:25:20.004: INFO: stderr: ""
Oct 21 20:25:20.004: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Oct 21 20:25:21.013: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:25:21.013: INFO: Found 0 / 1
Oct 21 20:25:22.014: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:25:22.014: INFO: Found 1 / 1
Oct 21 20:25:22.014: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 20:25:22.021: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:25:22.021: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Oct 21 20:25:22.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 logs redis-master-sm69g redis-master --namespace=e2e-tests-kubectl-b86s8'
Oct 21 20:25:22.191: INFO: stderr: ""
Oct 21 20:25:22.191: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 20:25:21.308 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 20:25:21.308 # Server started, Redis version 3.2.12\n1:M 21 Oct 20:25:21.308 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 20:25:21.308 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Oct 21 20:25:22.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 log redis-master-sm69g redis-master --namespace=e2e-tests-kubectl-b86s8 --tail=1'
Oct 21 20:25:22.344: INFO: stderr: ""
Oct 21 20:25:22.344: INFO: stdout: "1:M 21 Oct 20:25:21.308 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Oct 21 20:25:22.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 log redis-master-sm69g redis-master --namespace=e2e-tests-kubectl-b86s8 --limit-bytes=1'
Oct 21 20:25:22.492: INFO: stderr: ""
Oct 21 20:25:22.492: INFO: stdout: " "
STEP: exposing timestamps
Oct 21 20:25:22.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 log redis-master-sm69g redis-master --namespace=e2e-tests-kubectl-b86s8 --tail=1 --timestamps'
Oct 21 20:25:22.655: INFO: stderr: ""
Oct 21 20:25:22.655: INFO: stdout: "2019-10-21T20:25:21.308914648Z 1:M 21 Oct 20:25:21.308 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Oct 21 20:25:25.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 log redis-master-sm69g redis-master --namespace=e2e-tests-kubectl-b86s8 --since=1s'
Oct 21 20:25:25.313: INFO: stderr: ""
Oct 21 20:25:25.313: INFO: stdout: ""
Oct 21 20:25:25.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 log redis-master-sm69g redis-master --namespace=e2e-tests-kubectl-b86s8 --since=24h'
Oct 21 20:25:25.470: INFO: stderr: ""
Oct 21 20:25:25.470: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 20:25:21.308 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 20:25:21.308 # Server started, Redis version 3.2.12\n1:M 21 Oct 20:25:21.308 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 20:25:21.308 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Oct 21 20:25:25.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-b86s8'
Oct 21 20:25:25.603: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 20:25:25.603: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Oct 21 20:25:25.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-b86s8'
Oct 21 20:25:25.746: INFO: stderr: "No resources found.\n"
Oct 21 20:25:25.746: INFO: stdout: ""
Oct 21 20:25:25.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -l name=nginx --namespace=e2e-tests-kubectl-b86s8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 20:25:25.883: INFO: stderr: ""
Oct 21 20:25:25.883: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:25:25.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b86s8" for this suite.
Oct 21 20:25:31.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:25:32.174: INFO: namespace: e2e-tests-kubectl-b86s8, resource: bindings, ignored listing per whitelist
Oct 21 20:25:32.254: INFO: namespace e2e-tests-kubectl-b86s8 deletion completed in 6.361095444s

â€¢ [SLOW TEST:12.830 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:25:32.256: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-fcfz6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:25:32.581: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:25:34.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fcfz6" for this suite.
Oct 21 20:26:14.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:26:15.016: INFO: namespace: e2e-tests-pods-fcfz6, resource: bindings, ignored listing per whitelist
Oct 21 20:26:15.023: INFO: namespace e2e-tests-pods-fcfz6 deletion completed in 40.326190204s

â€¢ [SLOW TEST:42.767 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:26:15.024: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-bvhhw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-07db0400-f441-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:26:15.361: INFO: Waiting up to 5m0s for pod "pod-configmaps-07dc979f-f441-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-bvhhw" to be "success or failure"
Oct 21 20:26:15.367: INFO: Pod "pod-configmaps-07dc979f-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.240263ms
Oct 21 20:26:17.395: INFO: Pod "pod-configmaps-07dc979f-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033693002s
Oct 21 20:26:19.402: INFO: Pod "pod-configmaps-07dc979f-f441-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041055375s
STEP: Saw pod success
Oct 21 20:26:19.402: INFO: Pod "pod-configmaps-07dc979f-f441-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:26:19.408: INFO: Trying to get logs from node 10.170.151.141 pod pod-configmaps-07dc979f-f441-11e9-a616-8a530cf33301 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:26:19.444: INFO: Waiting for pod pod-configmaps-07dc979f-f441-11e9-a616-8a530cf33301 to disappear
Oct 21 20:26:19.450: INFO: Pod pod-configmaps-07dc979f-f441-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:26:19.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bvhhw" for this suite.
Oct 21 20:26:25.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:26:25.773: INFO: namespace: e2e-tests-configmap-bvhhw, resource: bindings, ignored listing per whitelist
Oct 21 20:26:25.799: INFO: namespace e2e-tests-configmap-bvhhw deletion completed in 6.338923426s

â€¢ [SLOW TEST:10.776 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:26:25.800: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2868w
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Oct 21 20:26:26.152: INFO: Waiting up to 5m0s for pod "pod-0e4ae906-f441-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-2868w" to be "success or failure"
Oct 21 20:26:26.159: INFO: Pod "pod-0e4ae906-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.060366ms
Oct 21 20:26:28.167: INFO: Pod "pod-0e4ae906-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014501319s
Oct 21 20:26:30.174: INFO: Pod "pod-0e4ae906-f441-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022083128s
STEP: Saw pod success
Oct 21 20:26:30.174: INFO: Pod "pod-0e4ae906-f441-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:26:30.181: INFO: Trying to get logs from node 10.170.151.156 pod pod-0e4ae906-f441-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:26:30.273: INFO: Waiting for pod pod-0e4ae906-f441-11e9-a616-8a530cf33301 to disappear
Oct 21 20:26:30.279: INFO: Pod pod-0e4ae906-f441-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:26:30.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2868w" for this suite.
Oct 21 20:26:36.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:26:36.399: INFO: namespace: e2e-tests-emptydir-2868w, resource: bindings, ignored listing per whitelist
Oct 21 20:26:36.627: INFO: namespace e2e-tests-emptydir-2868w deletion completed in 6.33886792s

â€¢ [SLOW TEST:10.827 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:26:36.627: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-9kkll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:26:40.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-9kkll" for this suite.
Oct 21 20:26:47.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:26:47.287: INFO: namespace: e2e-tests-kubelet-test-9kkll, resource: bindings, ignored listing per whitelist
Oct 21 20:26:47.295: INFO: namespace e2e-tests-kubelet-test-9kkll deletion completed in 6.293988177s

â€¢ [SLOW TEST:10.668 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:26:47.295: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xhr62
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-1b15a970-f441-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:26:47.624: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b174067-f441-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-xhr62" to be "success or failure"
Oct 21 20:26:47.631: INFO: Pod "pod-projected-configmaps-1b174067-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.557597ms
Oct 21 20:26:49.639: INFO: Pod "pod-projected-configmaps-1b174067-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014735075s
Oct 21 20:26:51.647: INFO: Pod "pod-projected-configmaps-1b174067-f441-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02262184s
STEP: Saw pod success
Oct 21 20:26:51.647: INFO: Pod "pod-projected-configmaps-1b174067-f441-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:26:51.653: INFO: Trying to get logs from node 10.170.151.141 pod pod-projected-configmaps-1b174067-f441-11e9-a616-8a530cf33301 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:26:51.687: INFO: Waiting for pod pod-projected-configmaps-1b174067-f441-11e9-a616-8a530cf33301 to disappear
Oct 21 20:26:51.694: INFO: Pod pod-projected-configmaps-1b174067-f441-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:26:51.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xhr62" for this suite.
Oct 21 20:26:57.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:26:58.013: INFO: namespace: e2e-tests-projected-xhr62, resource: bindings, ignored listing per whitelist
Oct 21 20:26:58.021: INFO: namespace e2e-tests-projected-xhr62 deletion completed in 6.315678977s

â€¢ [SLOW TEST:10.726 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:26:58.022: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-gl4j7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-gl4j7
Oct 21 20:27:00.360: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-gl4j7
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 20:27:00.367: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:31:01.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gl4j7" for this suite.
Oct 21 20:31:07.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:31:07.661: INFO: namespace: e2e-tests-container-probe-gl4j7, resource: bindings, ignored listing per whitelist
Oct 21 20:31:07.939: INFO: namespace e2e-tests-container-probe-gl4j7 deletion completed in 6.433501977s

â€¢ [SLOW TEST:249.918 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:31:07.939: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-69z5p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Oct 21 20:31:08.263: INFO: Waiting up to 5m0s for pod "client-containers-b672006f-f441-11e9-a616-8a530cf33301" in namespace "e2e-tests-containers-69z5p" to be "success or failure"
Oct 21 20:31:08.269: INFO: Pod "client-containers-b672006f-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.065964ms
Oct 21 20:31:10.277: INFO: Pod "client-containers-b672006f-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014137888s
Oct 21 20:31:12.290: INFO: Pod "client-containers-b672006f-f441-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027047121s
STEP: Saw pod success
Oct 21 20:31:12.290: INFO: Pod "client-containers-b672006f-f441-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:31:12.298: INFO: Trying to get logs from node 10.170.151.145 pod client-containers-b672006f-f441-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:31:12.339: INFO: Waiting for pod client-containers-b672006f-f441-11e9-a616-8a530cf33301 to disappear
Oct 21 20:31:12.344: INFO: Pod client-containers-b672006f-f441-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:31:12.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-69z5p" for this suite.
Oct 21 20:31:18.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:31:18.608: INFO: namespace: e2e-tests-containers-69z5p, resource: bindings, ignored listing per whitelist
Oct 21 20:31:18.664: INFO: namespace e2e-tests-containers-69z5p deletion completed in 6.309679245s

â€¢ [SLOW TEST:10.725 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:31:18.665: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-f62t9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1021 20:31:20.071360      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 20:31:20.071: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:31:20.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-f62t9" for this suite.
Oct 21 20:31:26.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:31:26.162: INFO: namespace: e2e-tests-gc-f62t9, resource: bindings, ignored listing per whitelist
Oct 21 20:31:26.399: INFO: namespace e2e-tests-gc-f62t9 deletion completed in 6.320107654s

â€¢ [SLOW TEST:7.734 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:31:26.399: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-k68f5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-h6gx
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 20:31:26.760: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-h6gx" in namespace "e2e-tests-subpath-k68f5" to be "success or failure"
Oct 21 20:31:26.783: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Pending", Reason="", readiness=false. Elapsed: 23.038985ms
Oct 21 20:31:28.790: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030243062s
Oct 21 20:31:30.797: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 4.037338871s
Oct 21 20:31:32.804: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 6.044501189s
Oct 21 20:31:34.812: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 8.052782974s
Oct 21 20:31:36.820: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 10.06073903s
Oct 21 20:31:38.828: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 12.068651732s
Oct 21 20:31:40.836: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 14.076000747s
Oct 21 20:31:42.843: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 16.083212312s
Oct 21 20:31:44.850: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 18.090640433s
Oct 21 20:31:46.857: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 20.0977943s
Oct 21 20:31:48.865: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Running", Reason="", readiness=false. Elapsed: 22.105450184s
Oct 21 20:31:50.872: INFO: Pod "pod-subpath-test-secret-h6gx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.112853935s
STEP: Saw pod success
Oct 21 20:31:50.872: INFO: Pod "pod-subpath-test-secret-h6gx" satisfied condition "success or failure"
Oct 21 20:31:50.879: INFO: Trying to get logs from node 10.170.151.156 pod pod-subpath-test-secret-h6gx container test-container-subpath-secret-h6gx: <nil>
STEP: delete the pod
Oct 21 20:31:50.921: INFO: Waiting for pod pod-subpath-test-secret-h6gx to disappear
Oct 21 20:31:50.927: INFO: Pod pod-subpath-test-secret-h6gx no longer exists
STEP: Deleting pod pod-subpath-test-secret-h6gx
Oct 21 20:31:50.927: INFO: Deleting pod "pod-subpath-test-secret-h6gx" in namespace "e2e-tests-subpath-k68f5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:31:50.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-k68f5" for this suite.
Oct 21 20:31:56.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:31:57.103: INFO: namespace: e2e-tests-subpath-k68f5, resource: bindings, ignored listing per whitelist
Oct 21 20:31:57.278: INFO: namespace e2e-tests-subpath-k68f5 deletion completed in 6.331890587s

â€¢ [SLOW TEST:30.879 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:31:57.279: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-pw75p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:32:02.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-pw75p" for this suite.
Oct 21 20:32:26.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:32:26.726: INFO: namespace: e2e-tests-replication-controller-pw75p, resource: bindings, ignored listing per whitelist
Oct 21 20:32:26.969: INFO: namespace e2e-tests-replication-controller-pw75p deletion completed in 24.314681053s

â€¢ [SLOW TEST:29.690 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:32:26.969: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-x2vp2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Oct 21 20:32:27.305: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-x2vp2" to be "success or failure"
Oct 21 20:32:27.312: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 7.149647ms
Oct 21 20:32:29.322: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017090607s
STEP: Saw pod success
Oct 21 20:32:29.322: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct 21 20:32:29.332: INFO: Trying to get logs from node 10.170.151.141 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct 21 20:32:29.369: INFO: Waiting for pod pod-host-path-test to disappear
Oct 21 20:32:29.375: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:32:29.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-x2vp2" for this suite.
Oct 21 20:32:35.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:32:35.478: INFO: namespace: e2e-tests-hostpath-x2vp2, resource: bindings, ignored listing per whitelist
Oct 21 20:32:35.671: INFO: namespace e2e-tests-hostpath-x2vp2 deletion completed in 6.284855734s

â€¢ [SLOW TEST:8.702 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:32:35.671: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-j4z7v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-eabbb728-f441-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:32:35.996: INFO: Waiting up to 5m0s for pod "pod-secrets-eabcea6b-f441-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-j4z7v" to be "success or failure"
Oct 21 20:32:36.003: INFO: Pod "pod-secrets-eabcea6b-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.517396ms
Oct 21 20:32:38.010: INFO: Pod "pod-secrets-eabcea6b-f441-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014396036s
STEP: Saw pod success
Oct 21 20:32:38.011: INFO: Pod "pod-secrets-eabcea6b-f441-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:32:38.017: INFO: Trying to get logs from node 10.170.151.141 pod pod-secrets-eabcea6b-f441-11e9-a616-8a530cf33301 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:32:38.053: INFO: Waiting for pod pod-secrets-eabcea6b-f441-11e9-a616-8a530cf33301 to disappear
Oct 21 20:32:38.059: INFO: Pod pod-secrets-eabcea6b-f441-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:32:38.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j4z7v" for this suite.
Oct 21 20:32:44.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:32:44.274: INFO: namespace: e2e-tests-secrets-j4z7v, resource: bindings, ignored listing per whitelist
Oct 21 20:32:44.384: INFO: namespace e2e-tests-secrets-j4z7v deletion completed in 6.314632161s

â€¢ [SLOW TEST:8.713 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:32:44.384: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2b5gb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:32:44.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-efeda6c3-f441-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-2b5gb" to be "success or failure"
Oct 21 20:32:44.710: INFO: Pod "downwardapi-volume-efeda6c3-f441-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.239974ms
Oct 21 20:32:46.718: INFO: Pod "downwardapi-volume-efeda6c3-f441-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013609278s
STEP: Saw pod success
Oct 21 20:32:46.718: INFO: Pod "downwardapi-volume-efeda6c3-f441-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:32:46.727: INFO: Trying to get logs from node 10.170.151.141 pod downwardapi-volume-efeda6c3-f441-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:32:46.766: INFO: Waiting for pod downwardapi-volume-efeda6c3-f441-11e9-a616-8a530cf33301 to disappear
Oct 21 20:32:46.773: INFO: Pod downwardapi-volume-efeda6c3-f441-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:32:46.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2b5gb" for this suite.
Oct 21 20:32:52.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:32:53.117: INFO: namespace: e2e-tests-projected-2b5gb, resource: bindings, ignored listing per whitelist
Oct 21 20:32:53.117: INFO: namespace e2e-tests-projected-2b5gb deletion completed in 6.333931123s

â€¢ [SLOW TEST:8.734 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:32:53.118: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-xfpcp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:32:53.513: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct 21 20:32:53.529: INFO: Number of nodes with available pods: 0
Oct 21 20:32:53.529: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct 21 20:32:53.559: INFO: Number of nodes with available pods: 0
Oct 21 20:32:53.559: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:32:54.567: INFO: Number of nodes with available pods: 0
Oct 21 20:32:54.567: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:32:55.567: INFO: Number of nodes with available pods: 1
Oct 21 20:32:55.567: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct 21 20:32:55.600: INFO: Number of nodes with available pods: 1
Oct 21 20:32:55.600: INFO: Number of running nodes: 0, number of available pods: 1
Oct 21 20:32:56.609: INFO: Number of nodes with available pods: 0
Oct 21 20:32:56.609: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct 21 20:32:56.628: INFO: Number of nodes with available pods: 0
Oct 21 20:32:56.628: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:32:57.636: INFO: Number of nodes with available pods: 0
Oct 21 20:32:57.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:32:58.636: INFO: Number of nodes with available pods: 0
Oct 21 20:32:58.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:32:59.635: INFO: Number of nodes with available pods: 0
Oct 21 20:32:59.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:00.640: INFO: Number of nodes with available pods: 0
Oct 21 20:33:00.640: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:01.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:01.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:02.639: INFO: Number of nodes with available pods: 0
Oct 21 20:33:02.639: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:03.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:03.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:04.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:04.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:05.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:05.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:06.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:06.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:07.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:07.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:08.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:08.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:09.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:09.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:10.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:10.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:11.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:11.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:12.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:12.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:13.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:13.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:14.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:14.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:15.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:15.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:16.637: INFO: Number of nodes with available pods: 0
Oct 21 20:33:16.637: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:17.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:17.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:18.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:18.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:19.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:19.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:20.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:20.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:21.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:21.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:22.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:22.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:23.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:23.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:24.645: INFO: Number of nodes with available pods: 0
Oct 21 20:33:24.645: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:25.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:25.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:26.634: INFO: Number of nodes with available pods: 0
Oct 21 20:33:26.634: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:27.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:27.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:28.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:28.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:29.639: INFO: Number of nodes with available pods: 0
Oct 21 20:33:29.639: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:30.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:30.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:31.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:31.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:32.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:32.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:33.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:33.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:34.636: INFO: Number of nodes with available pods: 0
Oct 21 20:33:34.636: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:35.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:35.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:36.637: INFO: Number of nodes with available pods: 0
Oct 21 20:33:36.637: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:37.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:37.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:38.635: INFO: Number of nodes with available pods: 0
Oct 21 20:33:38.635: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:33:39.635: INFO: Number of nodes with available pods: 1
Oct 21 20:33:39.635: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-xfpcp, will wait for the garbage collector to delete the pods
Oct 21 20:33:39.766: INFO: Deleting DaemonSet.extensions daemon-set took: 57.841165ms
Oct 21 20:33:39.867: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.26873ms
Oct 21 20:34:13.574: INFO: Number of nodes with available pods: 0
Oct 21 20:34:13.575: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 20:34:13.581: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-xfpcp/daemonsets","resourceVersion":"24411"},"items":null}

Oct 21 20:34:13.588: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-xfpcp/pods","resourceVersion":"24411"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:34:13.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-xfpcp" for this suite.
Oct 21 20:34:19.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:34:19.791: INFO: namespace: e2e-tests-daemonsets-xfpcp, resource: bindings, ignored listing per whitelist
Oct 21 20:34:19.936: INFO: namespace e2e-tests-daemonsets-xfpcp deletion completed in 6.298391478s

â€¢ [SLOW TEST:86.818 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:34:19.936: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ws9l5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 21 20:34:20.276: INFO: Waiting up to 5m0s for pod "pod-28e4d3fa-f442-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-ws9l5" to be "success or failure"
Oct 21 20:34:20.283: INFO: Pod "pod-28e4d3fa-f442-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.646605ms
Oct 21 20:34:22.290: INFO: Pod "pod-28e4d3fa-f442-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013837838s
STEP: Saw pod success
Oct 21 20:34:22.290: INFO: Pod "pod-28e4d3fa-f442-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:34:22.297: INFO: Trying to get logs from node 10.170.151.156 pod pod-28e4d3fa-f442-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:34:22.334: INFO: Waiting for pod pod-28e4d3fa-f442-11e9-a616-8a530cf33301 to disappear
Oct 21 20:34:22.341: INFO: Pod pod-28e4d3fa-f442-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:34:22.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ws9l5" for this suite.
Oct 21 20:34:28.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:34:28.529: INFO: namespace: e2e-tests-emptydir-ws9l5, resource: bindings, ignored listing per whitelist
Oct 21 20:34:28.650: INFO: namespace e2e-tests-emptydir-ws9l5 deletion completed in 6.297983177s

â€¢ [SLOW TEST:8.714 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:34:28.650: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-c2pmk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-c2pmk.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-c2pmk.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-c2pmk.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-c2pmk.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-c2pmk.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-c2pmk.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct 21 20:34:39.181: INFO: DNS probes using e2e-tests-dns-c2pmk/dns-test-2e0fc65b-f442-11e9-a616-8a530cf33301 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:34:39.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-c2pmk" for this suite.
Oct 21 20:34:45.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:34:45.419: INFO: namespace: e2e-tests-dns-c2pmk, resource: bindings, ignored listing per whitelist
Oct 21 20:34:45.501: INFO: namespace e2e-tests-dns-c2pmk deletion completed in 6.286569549s

â€¢ [SLOW TEST:16.851 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:34:45.502: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-68sx7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-68sx7
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Oct 21 20:34:45.825: INFO: Found 0 stateful pods, waiting for 3
Oct 21 20:34:55.833: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 20:34:55.833: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 20:34:55.833: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 20:34:55.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-68sx7 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 20:34:56.219: INFO: stderr: ""
Oct 21 20:34:56.219: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 20:34:56.219: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 21 20:35:06.276: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct 21 20:35:06.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-68sx7 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 20:35:06.676: INFO: stderr: ""
Oct 21 20:35:06.676: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 20:35:06.676: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Oct 21 20:35:36.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-68sx7 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 20:35:37.129: INFO: stderr: ""
Oct 21 20:35:37.129: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 20:35:37.129: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 20:35:37.168: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct 21 20:35:47.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-68sx7 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 20:35:47.562: INFO: stderr: ""
Oct 21 20:35:47.562: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 20:35:47.562: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 20:36:07.609: INFO: Waiting for StatefulSet e2e-tests-statefulset-68sx7/ss2 to complete update
Oct 21 20:36:07.609: INFO: Waiting for Pod e2e-tests-statefulset-68sx7/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 20:36:17.625: INFO: Deleting all statefulset in ns e2e-tests-statefulset-68sx7
Oct 21 20:36:17.632: INFO: Scaling statefulset ss2 to 0
Oct 21 20:36:27.662: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 20:36:27.671: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:36:27.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-68sx7" for this suite.
Oct 21 20:36:35.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:36:36.008: INFO: namespace: e2e-tests-statefulset-68sx7, resource: bindings, ignored listing per whitelist
Oct 21 20:36:36.027: INFO: namespace e2e-tests-statefulset-68sx7 deletion completed in 8.312932599s

â€¢ [SLOW TEST:110.526 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:36:36.027: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-x6sjb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:36:36.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a08fec2-f442-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-x6sjb" to be "success or failure"
Oct 21 20:36:36.416: INFO: Pod "downwardapi-volume-7a08fec2-f442-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.606836ms
Oct 21 20:36:38.424: INFO: Pod "downwardapi-volume-7a08fec2-f442-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014398611s
STEP: Saw pod success
Oct 21 20:36:38.424: INFO: Pod "downwardapi-volume-7a08fec2-f442-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:36:38.430: INFO: Trying to get logs from node 10.170.151.141 pod downwardapi-volume-7a08fec2-f442-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:36:38.467: INFO: Waiting for pod downwardapi-volume-7a08fec2-f442-11e9-a616-8a530cf33301 to disappear
Oct 21 20:36:38.473: INFO: Pod downwardapi-volume-7a08fec2-f442-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:36:38.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x6sjb" for this suite.
Oct 21 20:36:44.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:36:44.686: INFO: namespace: e2e-tests-downward-api-x6sjb, resource: bindings, ignored listing per whitelist
Oct 21 20:36:44.789: INFO: namespace e2e-tests-downward-api-x6sjb deletion completed in 6.306076279s

â€¢ [SLOW TEST:8.762 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:36:44.789: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mzb6x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-7f367c88-f442-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:36:45.117: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7f37acf8-f442-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-mzb6x" to be "success or failure"
Oct 21 20:36:45.126: INFO: Pod "pod-projected-secrets-7f37acf8-f442-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 8.482001ms
Oct 21 20:36:47.133: INFO: Pod "pod-projected-secrets-7f37acf8-f442-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015560433s
STEP: Saw pod success
Oct 21 20:36:47.133: INFO: Pod "pod-projected-secrets-7f37acf8-f442-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:36:47.140: INFO: Trying to get logs from node 10.170.151.156 pod pod-projected-secrets-7f37acf8-f442-11e9-a616-8a530cf33301 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:36:47.177: INFO: Waiting for pod pod-projected-secrets-7f37acf8-f442-11e9-a616-8a530cf33301 to disappear
Oct 21 20:36:47.183: INFO: Pod pod-projected-secrets-7f37acf8-f442-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:36:47.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mzb6x" for this suite.
Oct 21 20:36:53.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:36:53.423: INFO: namespace: e2e-tests-projected-mzb6x, resource: bindings, ignored listing per whitelist
Oct 21 20:36:53.562: INFO: namespace e2e-tests-projected-mzb6x deletion completed in 6.369769643s

â€¢ [SLOW TEST:8.773 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:36:53.562: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-rjzgj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Oct 21 20:36:53.869: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:36:56.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rjzgj" for this suite.
Oct 21 20:37:03.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:37:03.206: INFO: namespace: e2e-tests-init-container-rjzgj, resource: bindings, ignored listing per whitelist
Oct 21 20:37:03.298: INFO: namespace e2e-tests-init-container-rjzgj deletion completed in 6.324588237s

â€¢ [SLOW TEST:9.736 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:37:03.299: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-7nf9z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:37:03.661: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:37:07.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7nf9z" for this suite.
Oct 21 20:37:47.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:37:48.205: INFO: namespace: e2e-tests-pods-7nf9z, resource: bindings, ignored listing per whitelist
Oct 21 20:37:48.212: INFO: namespace e2e-tests-pods-7nf9z deletion completed in 40.300943283s

â€¢ [SLOW TEST:44.914 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:37:48.213: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pnmmb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Oct 21 20:37:48.507: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-571745635 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:37:48.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pnmmb" for this suite.
Oct 21 20:37:54.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:37:55.061: INFO: namespace: e2e-tests-kubectl-pnmmb, resource: bindings, ignored listing per whitelist
Oct 21 20:37:55.090: INFO: namespace e2e-tests-kubectl-pnmmb deletion completed in 6.314119019s

â€¢ [SLOW TEST:6.877 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:37:55.091: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-fgpl8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Oct 21 20:37:59.449: INFO: Pod pod-hostip-a9218937-f442-11e9-a616-8a530cf33301 has hostIP: 10.170.151.156
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:37:59.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fgpl8" for this suite.
Oct 21 20:38:21.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:38:21.787: INFO: namespace: e2e-tests-pods-fgpl8, resource: bindings, ignored listing per whitelist
Oct 21 20:38:21.860: INFO: namespace e2e-tests-pods-fgpl8 deletion completed in 22.400814643s

â€¢ [SLOW TEST:26.770 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:38:21.861: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-r8bn6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:38:22.162: INFO: Creating deployment "nginx-deployment"
Oct 21 20:38:22.171: INFO: Waiting for observed generation 1
Oct 21 20:38:24.184: INFO: Waiting for all required pods to come up
Oct 21 20:38:24.194: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct 21 20:38:26.209: INFO: Waiting for deployment "nginx-deployment" to complete
Oct 21 20:38:26.224: INFO: Updating deployment "nginx-deployment" with a non-existent image
Oct 21 20:38:26.238: INFO: Updating deployment nginx-deployment
Oct 21 20:38:26.238: INFO: Waiting for observed generation 2
Oct 21 20:38:28.251: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct 21 20:38:28.260: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct 21 20:38:28.270: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 21 20:38:28.295: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct 21 20:38:28.295: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct 21 20:38:28.303: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Oct 21 20:38:28.320: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Oct 21 20:38:28.320: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Oct 21 20:38:28.335: INFO: Updating deployment nginx-deployment
Oct 21 20:38:28.335: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Oct 21 20:38:28.352: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct 21 20:38:28.360: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 20:38:28.383: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r8bn6/deployments/nginx-deployment,UID:b91453c1-f442-11e9-8a4f-8adb5f5fcc88,ResourceVersion:25807,Generation:3,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-10-21 20:38:26 +0000 UTC 2019-10-21 20:38:22 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-10-21 20:38:28 +0000 UTC 2019-10-21 20:38:28 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Oct 21 20:38:28.399: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r8bn6/replicasets/nginx-deployment-65bbdb5f8,UID:bb822c42-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25794,Generation:3,CreationTimestamp:2019-10-21 20:38:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b91453c1-f442-11e9-8a4f-8adb5f5fcc88 0xc00196c8a7 0xc00196c8a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 20:38:28.402: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Oct 21 20:38:28.402: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-r8bn6/replicasets/nginx-deployment-555b55d965,UID:b9184e05-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25792,Generation:3,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b91453c1-f442-11e9-8a4f-8adb5f5fcc88 0xc00196c7e7 0xc00196c7e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Oct 21 20:38:28.418: INFO: Pod "nginx-deployment-555b55d965-45tnd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-45tnd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-45tnd,UID:b91f9b61-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25675,Generation:0,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e4627 0xc0022e4628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e46a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e4710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.156,PodIP:172.30.96.99,StartTime:2019-10-21 20:38:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://c7b1ff28e21be47c1a035690fd1f4c809b62834abd004462c0fa6119140fdfa0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.419: INFO: Pod "nginx-deployment-555b55d965-4m98v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4m98v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-4m98v,UID:bcc90bca-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25844,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e47d7 0xc0022e47d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e4850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e48e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.419: INFO: Pod "nginx-deployment-555b55d965-6zhcv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6zhcv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-6zhcv,UID:b9211096-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25659,Generation:0,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e4950 0xc0022e4951}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e49c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e49e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.141,PodIP:172.30.204.120,StartTime:2019-10-21 20:38:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f573f21deaaf540d6818eef6d6bdab0f7058aa1165ee9fc1448ec5cf6ce90f16}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.419: INFO: Pod "nginx-deployment-555b55d965-7rbhn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7rbhn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-7rbhn,UID:bcc572a6-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25809,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e4b07 0xc0022e4b08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e4b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e4ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.420: INFO: Pod "nginx-deployment-555b55d965-8k5cx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8k5cx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-8k5cx,UID:b91ccb14-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25666,Generation:0,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e4e60 0xc0022e4e61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e4f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e4f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.145,PodIP:172.30.198.145,StartTime:2019-10-21 20:38:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ff63ce9f909dc7a2e492f711971e5164dfffe69268556bdc1b128956f7b301ef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.420: INFO: Pod "nginx-deployment-555b55d965-9fwz8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9fwz8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-9fwz8,UID:bcc857d5-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25842,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e5047 0xc0022e5048}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e52a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e52c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.420: INFO: Pod "nginx-deployment-555b55d965-9m6jd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9m6jd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-9m6jd,UID:bcc87c3c-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25840,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e5330 0xc0022e5331}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e53b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e53d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.421: INFO: Pod "nginx-deployment-555b55d965-9ppnm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9ppnm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-9ppnm,UID:b91e3605-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25642,Generation:0,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e5440 0xc0022e5441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e54b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e54d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.156,PodIP:172.30.96.95,StartTime:2019-10-21 20:38:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://3dbbeadcb7c34ec64da178e68c5237b9e8f25946f87207baf88025342208f6bc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.421: INFO: Pod "nginx-deployment-555b55d965-fmm7p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fmm7p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-fmm7p,UID:b91f8851-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25663,Generation:0,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e55d7 0xc0022e55d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e5740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e5760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.145,PodIP:172.30.198.147,StartTime:2019-10-21 20:38:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://ff4c1bf0961d5e4f4ddbe79f94312776a1181e48b482bf1f31581ea6105f4042}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.422: INFO: Pod "nginx-deployment-555b55d965-jmcn7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jmcn7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-jmcn7,UID:bcc6d91c-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25823,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e5827 0xc0022e5828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e5920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e5940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.422: INFO: Pod "nginx-deployment-555b55d965-lnz5d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lnz5d,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-lnz5d,UID:bcc85e3b-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25839,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e59b0 0xc0022e59b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e5b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e5b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.422: INFO: Pod "nginx-deployment-555b55d965-lrhtw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lrhtw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-lrhtw,UID:bcc6dcd8-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25826,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e5c00 0xc0022e5c01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e5c70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e5d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.423: INFO: Pod "nginx-deployment-555b55d965-m6slw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-m6slw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-m6slw,UID:bcc3def6-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25831,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e5d80 0xc0022e5d81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e5df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e5e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.145,PodIP:,StartTime:2019-10-21 20:38:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.423: INFO: Pod "nginx-deployment-555b55d965-m75kw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-m75kw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-m75kw,UID:b9211920-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25679,Generation:0,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc0022e5ec7 0xc0022e5ec8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022e5f40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022e5f60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.141,PodIP:172.30.204.117,StartTime:2019-10-21 20:38:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:24 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://d78f69f58f00c83861048ccc526d1cbaf7433ec8835eb59b0f8d3f99c4bace51}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.423: INFO: Pod "nginx-deployment-555b55d965-n7flx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n7flx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-n7flx,UID:b91fa221-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25656,Generation:0,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc001552027 0xc001552028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015520a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015520c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.141,PodIP:172.30.204.119,StartTime:2019-10-21 20:38:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://820749156b44edbb19afffb8d752701171cb1cf6f844eee5c80d33411e227f31}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.423: INFO: Pod "nginx-deployment-555b55d965-qp4q4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qp4q4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-qp4q4,UID:bcc6d802-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25824,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc001552187 0xc001552188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001552200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001552220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.424: INFO: Pod "nginx-deployment-555b55d965-rk2nt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rk2nt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-rk2nt,UID:bcc587f9-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25810,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc001552290 0xc001552291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001552300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001552320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.424: INFO: Pod "nginx-deployment-555b55d965-vg4rr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vg4rr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-vg4rr,UID:bcc6d4fe-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25817,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc001552390 0xc001552391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001552400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001552420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.424: INFO: Pod "nginx-deployment-555b55d965-wrdqc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wrdqc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-wrdqc,UID:b91e31de-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25653,Generation:0,CreationTimestamp:2019-10-21 20:38:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc001552490 0xc001552491}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001552600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001552620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:22 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.141,PodIP:172.30.204.115,StartTime:2019-10-21 20:38:22 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:23 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://0f8eabe9b54183419a12cf0d8806548f6bf06a52313c2a0c5bd0b6dda2cefb4a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.425: INFO: Pod "nginx-deployment-555b55d965-zx92j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zx92j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-555b55d965-zx92j,UID:bcc86518-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25841,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b9184e05-f442-11e9-9086-ba4ceb9f210a 0xc001552727 0xc001552728}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001552820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001552860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.425: INFO: Pod "nginx-deployment-65bbdb5f8-5rnzg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5rnzg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-5rnzg,UID:bb839b1e-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25780,Generation:0,CreationTimestamp:2019-10-21 20:38:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc0015528f0 0xc0015528f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001552970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015529c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.156,PodIP:172.30.96.100,StartTime:2019-10-21 20:38:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.426: INFO: Pod "nginx-deployment-65bbdb5f8-5xhg6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5xhg6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-5xhg6,UID:bcc7d734-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25838,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001552bd0 0xc001552bd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001552c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001552ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.426: INFO: Pod "nginx-deployment-65bbdb5f8-76hgc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-76hgc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-76hgc,UID:bcc99cec-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25846,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001552d60 0xc001552d61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001552de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001552e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.427: INFO: Pod "nginx-deployment-65bbdb5f8-7z9pl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7z9pl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-7z9pl,UID:bcc63695-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25816,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001552f30 0xc001552f31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001553060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001553080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.427: INFO: Pod "nginx-deployment-65bbdb5f8-cbl5r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cbl5r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-cbl5r,UID:bcc7cf19-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25835,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001553120 0xc001553121}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015531a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015531c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.427: INFO: Pod "nginx-deployment-65bbdb5f8-fjfbp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fjfbp,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-fjfbp,UID:bcc7d9cf-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25836,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001553230 0xc001553231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001553410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001553440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.427: INFO: Pod "nginx-deployment-65bbdb5f8-gc97d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gc97d,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-gc97d,UID:bcc4ee38-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25850,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc0015534b0 0xc0015534b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015535b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015535e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.145,PodIP:,StartTime:2019-10-21 20:38:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.427: INFO: Pod "nginx-deployment-65bbdb5f8-jprml" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jprml,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-jprml,UID:bb851926-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25787,Generation:0,CreationTimestamp:2019-10-21 20:38:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001553730 0xc001553731}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015537e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001553860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.145,PodIP:172.30.198.149,StartTime:2019-10-21 20:38:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.427: INFO: Pod "nginx-deployment-65bbdb5f8-pc2ds" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pc2ds,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-pc2ds,UID:bb850743-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25785,Generation:0,CreationTimestamp:2019-10-21 20:38:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc0015539e0 0xc0015539e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001553aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001553ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.141,PodIP:172.30.204.116,StartTime:2019-10-21 20:38:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.428: INFO: Pod "nginx-deployment-65bbdb5f8-ps9s6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ps9s6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-ps9s6,UID:bb8c12f9-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25781,Generation:0,CreationTimestamp:2019-10-21 20:38:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001553ba0 0xc001553ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001553c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001553c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.156,PodIP:172.30.96.103,StartTime:2019-10-21 20:38:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.428: INFO: Pod "nginx-deployment-65bbdb5f8-twdmh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-twdmh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-twdmh,UID:bb8a95a5-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25778,Generation:0,CreationTimestamp:2019-10-21 20:38:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001553e20 0xc001553e21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001553ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001553ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:26 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.156,PodIP:172.30.96.101,StartTime:2019-10-21 20:38:26 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.428: INFO: Pod "nginx-deployment-65bbdb5f8-w2lxq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-w2lxq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-w2lxq,UID:bcc62d71-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25852,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc001553fb0 0xc001553fb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e72070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e720a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.141,PodIP:,StartTime:2019-10-21 20:38:28 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Oct 21 20:38:28.428: INFO: Pod "nginx-deployment-65bbdb5f8-wh2ld" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wh2ld,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-r8bn6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-r8bn6/pods/nginx-deployment-65bbdb5f8-wh2ld,UID:bcc7c1e9-f442-11e9-9086-ba4ceb9f210a,ResourceVersion:25832,Generation:0,CreationTimestamp:2019-10-21 20:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 bb822c42-f442-11e9-9086-ba4ceb9f210a 0xc000e721e0 0xc000e721e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nwsk8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nwsk8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nwsk8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000e72390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000e723f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:28 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:38:28.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-r8bn6" for this suite.
Oct 21 20:38:36.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:38:36.631: INFO: namespace: e2e-tests-deployment-r8bn6, resource: bindings, ignored listing per whitelist
Oct 21 20:38:36.792: INFO: namespace e2e-tests-deployment-r8bn6 deletion completed in 8.353551773s

â€¢ [SLOW TEST:14.931 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:38:36.792: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-4dnzw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct 21 20:38:41.172: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-c1ff5466-f442-11e9-a616-8a530cf33301,GenerateName:,Namespace:e2e-tests-events-4dnzw,SelfLink:/api/v1/namespaces/e2e-tests-events-4dnzw/pods/send-events-c1ff5466-f442-11e9-a616-8a530cf33301,UID:c20111e6-f442-11e9-8a4f-8adb5f5fcc88,ResourceVersion:26308,Generation:0,CreationTimestamp:2019-10-21 20:38:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 126573217,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ndmm8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ndmm8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-ndmm8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.156,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0009990a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0009990c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:38:37 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.156,PodIP:172.30.96.108,StartTime:2019-10-21 20:38:37 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-10-21 20:38:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://5330d89a60ae48f6267828677a13c1c2df0e8560ff7a87b67d9432cb07d7b89a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Oct 21 20:38:43.181: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct 21 20:38:45.190: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:38:45.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-4dnzw" for this suite.
Oct 21 20:39:25.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:39:25.312: INFO: namespace: e2e-tests-events-4dnzw, resource: bindings, ignored listing per whitelist
Oct 21 20:39:25.553: INFO: namespace e2e-tests-events-4dnzw deletion completed in 40.336379641s

â€¢ [SLOW TEST:48.762 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:39:25.554: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j7txz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-df0d7606-f442-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:39:25.897: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-df0ee10e-f442-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-j7txz" to be "success or failure"
Oct 21 20:39:25.904: INFO: Pod "pod-projected-configmaps-df0ee10e-f442-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.829402ms
Oct 21 20:39:27.911: INFO: Pod "pod-projected-configmaps-df0ee10e-f442-11e9-a616-8a530cf33301": Phase="Running", Reason="", readiness=true. Elapsed: 2.014150543s
Oct 21 20:39:29.919: INFO: Pod "pod-projected-configmaps-df0ee10e-f442-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021505404s
STEP: Saw pod success
Oct 21 20:39:29.919: INFO: Pod "pod-projected-configmaps-df0ee10e-f442-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:39:29.926: INFO: Trying to get logs from node 10.170.151.141 pod pod-projected-configmaps-df0ee10e-f442-11e9-a616-8a530cf33301 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:39:29.966: INFO: Waiting for pod pod-projected-configmaps-df0ee10e-f442-11e9-a616-8a530cf33301 to disappear
Oct 21 20:39:29.972: INFO: Pod pod-projected-configmaps-df0ee10e-f442-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:39:29.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j7txz" for this suite.
Oct 21 20:39:36.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:39:36.041: INFO: namespace: e2e-tests-projected-j7txz, resource: bindings, ignored listing per whitelist
Oct 21 20:39:36.294: INFO: namespace e2e-tests-projected-j7txz deletion completed in 6.312029432s

â€¢ [SLOW TEST:10.741 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:39:36.299: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8qb9l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e57283ff-f442-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:39:36.626: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e573f931-f442-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-8qb9l" to be "success or failure"
Oct 21 20:39:36.633: INFO: Pod "pod-projected-configmaps-e573f931-f442-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.732473ms
Oct 21 20:39:38.640: INFO: Pod "pod-projected-configmaps-e573f931-f442-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014201748s
STEP: Saw pod success
Oct 21 20:39:38.640: INFO: Pod "pod-projected-configmaps-e573f931-f442-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:39:38.647: INFO: Trying to get logs from node 10.170.151.141 pod pod-projected-configmaps-e573f931-f442-11e9-a616-8a530cf33301 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:39:38.695: INFO: Waiting for pod pod-projected-configmaps-e573f931-f442-11e9-a616-8a530cf33301 to disappear
Oct 21 20:39:38.702: INFO: Pod pod-projected-configmaps-e573f931-f442-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:39:38.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8qb9l" for this suite.
Oct 21 20:39:44.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:39:44.876: INFO: namespace: e2e-tests-projected-8qb9l, resource: bindings, ignored listing per whitelist
Oct 21 20:39:45.088: INFO: namespace e2e-tests-projected-8qb9l deletion completed in 6.374270489s

â€¢ [SLOW TEST:8.789 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:39:45.088: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-4mdmd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Oct 21 20:39:45.399: INFO: PodSpec: initContainers in spec.initContainers
Oct 21 20:40:26.097: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-eab0fef1-f442-11e9-a616-8a530cf33301", GenerateName:"", Namespace:"e2e-tests-init-container-4mdmd", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-4mdmd/pods/pod-init-eab0fef1-f442-11e9-a616-8a530cf33301", UID:"eab25175-f442-11e9-8a4f-8adb5f5fcc88", ResourceVersion:"26611", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707287185, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"399847099", "name":"foo"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-92pz4", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000e92d80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-92pz4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-92pz4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-92pz4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001080ff8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.170.151.156", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000b0f140), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001081080)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0010810a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0010810a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0010810ac)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287185, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287185, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287185, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287185, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.170.151.156", PodIP:"172.30.96.113", StartTime:(*v1.Time)(0xc000865f80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008d1e30)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008d1ea0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://9d525ee8397bd5e8c7e5f2cd47c2413aaf91b91de0ff20cf522e603340d8bae0"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000865fc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000865fa0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:40:26.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4mdmd" for this suite.
Oct 21 20:40:50.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:40:50.192: INFO: namespace: e2e-tests-init-container-4mdmd, resource: bindings, ignored listing per whitelist
Oct 21 20:40:50.413: INFO: namespace e2e-tests-init-container-4mdmd deletion completed in 24.304667684s

â€¢ [SLOW TEST:65.325 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:40:50.413: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nf5jf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Oct 21 20:40:50.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 cluster-info'
Oct 21 20:40:50.986: INFO: stderr: ""
Oct 21 20:40:50.986: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:40:50.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nf5jf" for this suite.
Oct 21 20:40:57.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:40:57.101: INFO: namespace: e2e-tests-kubectl-nf5jf, resource: bindings, ignored listing per whitelist
Oct 21 20:40:57.337: INFO: namespace e2e-tests-kubectl-nf5jf deletion completed in 6.339760739s

â€¢ [SLOW TEST:6.924 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:40:57.340: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6wv9p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:40:57.686: INFO: Waiting up to 5m0s for pod "downwardapi-volume-15c4c5ab-f443-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-6wv9p" to be "success or failure"
Oct 21 20:40:57.693: INFO: Pod "downwardapi-volume-15c4c5ab-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.917507ms
Oct 21 20:40:59.701: INFO: Pod "downwardapi-volume-15c4c5ab-f443-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014396877s
STEP: Saw pod success
Oct 21 20:40:59.701: INFO: Pod "downwardapi-volume-15c4c5ab-f443-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:40:59.708: INFO: Trying to get logs from node 10.170.151.145 pod downwardapi-volume-15c4c5ab-f443-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:40:59.748: INFO: Waiting for pod downwardapi-volume-15c4c5ab-f443-11e9-a616-8a530cf33301 to disappear
Oct 21 20:40:59.755: INFO: Pod downwardapi-volume-15c4c5ab-f443-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:40:59.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6wv9p" for this suite.
Oct 21 20:41:05.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:41:06.079: INFO: namespace: e2e-tests-projected-6wv9p, resource: bindings, ignored listing per whitelist
Oct 21 20:41:06.086: INFO: namespace e2e-tests-projected-6wv9p deletion completed in 6.313627626s

â€¢ [SLOW TEST:8.746 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:41:06.086: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-dn7dg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:41:08.646: INFO: Waiting up to 5m0s for pod "client-envvars-1c4db0b7-f443-11e9-a616-8a530cf33301" in namespace "e2e-tests-pods-dn7dg" to be "success or failure"
Oct 21 20:41:08.653: INFO: Pod "client-envvars-1c4db0b7-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.003004ms
Oct 21 20:41:10.661: INFO: Pod "client-envvars-1c4db0b7-f443-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015168026s
STEP: Saw pod success
Oct 21 20:41:10.661: INFO: Pod "client-envvars-1c4db0b7-f443-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:41:10.668: INFO: Trying to get logs from node 10.170.151.156 pod client-envvars-1c4db0b7-f443-11e9-a616-8a530cf33301 container env3cont: <nil>
STEP: delete the pod
Oct 21 20:41:10.708: INFO: Waiting for pod client-envvars-1c4db0b7-f443-11e9-a616-8a530cf33301 to disappear
Oct 21 20:41:10.716: INFO: Pod client-envvars-1c4db0b7-f443-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:41:10.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dn7dg" for this suite.
Oct 21 20:42:00.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:42:00.886: INFO: namespace: e2e-tests-pods-dn7dg, resource: bindings, ignored listing per whitelist
Oct 21 20:42:01.061: INFO: namespace e2e-tests-pods-dn7dg deletion completed in 50.335000728s

â€¢ [SLOW TEST:54.975 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:42:01.062: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-phmh6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:42:01.497: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3bcd909c-f443-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-phmh6" to be "success or failure"
Oct 21 20:42:01.504: INFO: Pod "downwardapi-volume-3bcd909c-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.337949ms
Oct 21 20:42:03.512: INFO: Pod "downwardapi-volume-3bcd909c-f443-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014984118s
STEP: Saw pod success
Oct 21 20:42:03.512: INFO: Pod "downwardapi-volume-3bcd909c-f443-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:42:03.520: INFO: Trying to get logs from node 10.170.151.141 pod downwardapi-volume-3bcd909c-f443-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:42:03.560: INFO: Waiting for pod downwardapi-volume-3bcd909c-f443-11e9-a616-8a530cf33301 to disappear
Oct 21 20:42:03.567: INFO: Pod downwardapi-volume-3bcd909c-f443-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:42:03.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-phmh6" for this suite.
Oct 21 20:42:09.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:42:09.837: INFO: namespace: e2e-tests-downward-api-phmh6, resource: bindings, ignored listing per whitelist
Oct 21 20:42:09.911: INFO: namespace e2e-tests-downward-api-phmh6 deletion completed in 6.33154014s

â€¢ [SLOW TEST:8.849 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:42:09.911: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pbzbf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:42:10.212: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40ff5c7b-f443-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-pbzbf" to be "success or failure"
Oct 21 20:42:10.219: INFO: Pod "downwardapi-volume-40ff5c7b-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.427617ms
Oct 21 20:42:12.226: INFO: Pod "downwardapi-volume-40ff5c7b-f443-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014066343s
STEP: Saw pod success
Oct 21 20:42:12.226: INFO: Pod "downwardapi-volume-40ff5c7b-f443-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:42:12.233: INFO: Trying to get logs from node 10.170.151.141 pod downwardapi-volume-40ff5c7b-f443-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:42:12.271: INFO: Waiting for pod downwardapi-volume-40ff5c7b-f443-11e9-a616-8a530cf33301 to disappear
Oct 21 20:42:12.277: INFO: Pod downwardapi-volume-40ff5c7b-f443-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:42:12.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pbzbf" for this suite.
Oct 21 20:42:18.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:42:18.650: INFO: namespace: e2e-tests-downward-api-pbzbf, resource: bindings, ignored listing per whitelist
Oct 21 20:42:18.679: INFO: namespace e2e-tests-downward-api-pbzbf deletion completed in 6.392053434s

â€¢ [SLOW TEST:8.768 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:42:18.679: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-ml58x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:42:23.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-ml58x" for this suite.
Oct 21 20:43:05.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:43:05.121: INFO: namespace: e2e-tests-kubelet-test-ml58x, resource: bindings, ignored listing per whitelist
Oct 21 20:43:05.384: INFO: namespace e2e-tests-kubelet-test-ml58x deletion completed in 42.312189869s

â€¢ [SLOW TEST:46.705 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:43:05.384: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-tk2fj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:43:05.681: INFO: Creating deployment "test-recreate-deployment"
Oct 21 20:43:05.689: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct 21 20:43:05.703: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Oct 21 20:43:07.730: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct 21 20:43:07.737: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct 21 20:43:07.752: INFO: Updating deployment test-recreate-deployment
Oct 21 20:43:07.752: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 20:43:07.867: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-tk2fj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tk2fj/deployments/test-recreate-deployment,UID:6211b4e1-f443-11e9-8a4f-8adb5f5fcc88,ResourceVersion:27165,Generation:2,CreationTimestamp:2019-10-21 20:43:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-10-21 20:43:07 +0000 UTC 2019-10-21 20:43:07 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-10-21 20:43:07 +0000 UTC 2019-10-21 20:43:05 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Oct 21 20:43:07.876: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-tk2fj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tk2fj/replicasets/test-recreate-deployment-697fbf54bf,UID:63560cd0-f443-11e9-9086-ba4ceb9f210a,ResourceVersion:27162,Generation:1,CreationTimestamp:2019-10-21 20:43:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 6211b4e1-f443-11e9-8a4f-8adb5f5fcc88 0xc001eb3347 0xc001eb3348}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 20:43:07.876: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct 21 20:43:07.877: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-tk2fj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tk2fj/replicasets/test-recreate-deployment-5dfdcc846d,UID:62154261-f443-11e9-9086-ba4ceb9f210a,ResourceVersion:27152,Generation:2,CreationTimestamp:2019-10-21 20:43:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 6211b4e1-f443-11e9-8a4f-8adb5f5fcc88 0xc001eb3287 0xc001eb3288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 20:43:07.883: INFO: Pod "test-recreate-deployment-697fbf54bf-kb28k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-kb28k,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-tk2fj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tk2fj/pods/test-recreate-deployment-697fbf54bf-kb28k,UID:6357b660-f443-11e9-9086-ba4ceb9f210a,ResourceVersion:27164,Generation:0,CreationTimestamp:2019-10-21 20:43:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 63560cd0-f443-11e9-9086-ba4ceb9f210a 0xc001eb3bc7 0xc001eb3bc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8gqf8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8gqf8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8gqf8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001eb3c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001eb3c60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:43:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:43:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:43:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:43:07 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.141,PodIP:,StartTime:2019-10-21 20:43:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:43:07.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-tk2fj" for this suite.
Oct 21 20:43:13.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:43:14.241: INFO: namespace: e2e-tests-deployment-tk2fj, resource: bindings, ignored listing per whitelist
Oct 21 20:43:14.241: INFO: namespace e2e-tests-deployment-tk2fj deletion completed in 6.348098727s

â€¢ [SLOW TEST:8.857 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:43:14.243: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-8h599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:43:14.544: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct 21 20:43:19.552: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 20:43:19.552: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct 21 20:43:21.561: INFO: Creating deployment "test-rollover-deployment"
Oct 21 20:43:21.576: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct 21 20:43:23.589: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct 21 20:43:23.604: INFO: Ensure that both replica sets have 1 created replica
Oct 21 20:43:23.622: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct 21 20:43:23.639: INFO: Updating deployment test-rollover-deployment
Oct 21 20:43:23.639: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct 21 20:43:25.654: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct 21 20:43:25.693: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct 21 20:43:25.708: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 20:43:25.708: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287403, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 20:43:27.725: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 20:43:27.725: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287405, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 20:43:29.725: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 20:43:29.725: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287405, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 20:43:31.732: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 20:43:31.732: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287405, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 20:43:33.724: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 20:43:33.724: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287405, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 20:43:35.724: INFO: all replica sets need to contain the pod-template-hash label
Oct 21 20:43:35.724: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287405, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707287401, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 20:43:37.725: INFO: 
Oct 21 20:43:37.725: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 20:43:37.748: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-8h599,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8h599/deployments/test-rollover-deployment,UID:6b88ecfa-f443-11e9-8a4f-8adb5f5fcc88,ResourceVersion:27338,Generation:2,CreationTimestamp:2019-10-21 20:43:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-21 20:43:21 +0000 UTC 2019-10-21 20:43:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-21 20:43:35 +0000 UTC 2019-10-21 20:43:21 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 21 20:43:37.757: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-8h599,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8h599/replicasets/test-rollover-deployment-6b7f9d6597,UID:6cc5cb04-f443-11e9-9086-ba4ceb9f210a,ResourceVersion:27329,Generation:2,CreationTimestamp:2019-10-21 20:43:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6b88ecfa-f443-11e9-8a4f-8adb5f5fcc88 0xc0022650f7 0xc0022650f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 21 20:43:37.757: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct 21 20:43:37.757: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-8h599,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8h599/replicasets/test-rollover-controller,UID:675768aa-f443-11e9-8a4f-8adb5f5fcc88,ResourceVersion:27337,Generation:2,CreationTimestamp:2019-10-21 20:43:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6b88ecfa-f443-11e9-8a4f-8adb5f5fcc88 0xc002264f47 0xc002264f48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 20:43:37.757: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-8h599,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8h599/replicasets/test-rollover-deployment-6586df867b,UID:6b8f1d8c-f443-11e9-9086-ba4ceb9f210a,ResourceVersion:27291,Generation:2,CreationTimestamp:2019-10-21 20:43:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6b88ecfa-f443-11e9-8a4f-8adb5f5fcc88 0xc002265007 0xc002265008}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 20:43:37.764: INFO: Pod "test-rollover-deployment-6b7f9d6597-72sf2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-72sf2,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-8h599,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8h599/pods/test-rollover-deployment-6b7f9d6597-72sf2,UID:6ccd17a1-f443-11e9-9086-ba4ceb9f210a,ResourceVersion:27310,Generation:0,CreationTimestamp:2019-10-21 20:43:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 6cc5cb04-f443-11e9-9086-ba4ceb9f210a 0xc0022566d7 0xc0022566d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-w869z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-w869z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-w869z true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002256750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002256770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:43:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:43:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:43:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:43:23 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.145,PodIP:172.30.198.157,StartTime:2019-10-21 20:43:23 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-21 20:43:25 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://25861b514a134ffd3b514d13566c85cfafa1f2c0ea25d3004368ac1000d97151}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:43:37.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8h599" for this suite.
Oct 21 20:43:43.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:43:43.894: INFO: namespace: e2e-tests-deployment-8h599, resource: bindings, ignored listing per whitelist
Oct 21 20:43:44.246: INFO: namespace e2e-tests-deployment-8h599 deletion completed in 6.469591206s

â€¢ [SLOW TEST:30.004 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:43:44.248: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-ldrrm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vsvm6 in namespace e2e-tests-proxy-ldrrm
I1021 20:43:44.662752      16 runners.go:184] Created replication controller with name: proxy-service-vsvm6, namespace: e2e-tests-proxy-ldrrm, replica count: 1
I1021 20:43:45.713290      16 runners.go:184] proxy-service-vsvm6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 20:43:46.713534      16 runners.go:184] proxy-service-vsvm6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 20:43:47.713830      16 runners.go:184] proxy-service-vsvm6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1021 20:43:48.714043      16 runners.go:184] proxy-service-vsvm6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 21 20:43:48.721: INFO: setup took 4.096858379s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct 21 20:43:48.735: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.533254ms)
Oct 21 20:43:48.738: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 16.655389ms)
Oct 21 20:43:48.738: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 16.422006ms)
Oct 21 20:43:48.738: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.303231ms)
Oct 21 20:43:48.738: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 16.812329ms)
Oct 21 20:43:48.738: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 16.996262ms)
Oct 21 20:43:48.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 17.470377ms)
Oct 21 20:43:48.739: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 17.703774ms)
Oct 21 20:43:48.741: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 19.660962ms)
Oct 21 20:43:48.750: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 28.750172ms)
Oct 21 20:43:48.756: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 34.552218ms)
Oct 21 20:43:48.757: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 35.641405ms)
Oct 21 20:43:48.757: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 35.457165ms)
Oct 21 20:43:48.764: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 42.676263ms)
Oct 21 20:43:48.767: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 45.88052ms)
Oct 21 20:43:48.776: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 54.110907ms)
Oct 21 20:43:48.786: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 10.491882ms)
Oct 21 20:43:48.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 12.390516ms)
Oct 21 20:43:48.789: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 12.975673ms)
Oct 21 20:43:48.789: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.099886ms)
Oct 21 20:43:48.789: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 13.164176ms)
Oct 21 20:43:48.789: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 13.466733ms)
Oct 21 20:43:48.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 13.630485ms)
Oct 21 20:43:48.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.814471ms)
Oct 21 20:43:48.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 13.927851ms)
Oct 21 20:43:48.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 14.24835ms)
Oct 21 20:43:48.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 18.323523ms)
Oct 21 20:43:48.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 17.903828ms)
Oct 21 20:43:48.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 18.066607ms)
Oct 21 20:43:48.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 17.868296ms)
Oct 21 20:43:48.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 17.963289ms)
Oct 21 20:43:48.794: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 18.347745ms)
Oct 21 20:43:48.806: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 11.460717ms)
Oct 21 20:43:48.806: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 11.536771ms)
Oct 21 20:43:48.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 11.594145ms)
Oct 21 20:43:48.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 11.49056ms)
Oct 21 20:43:48.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 11.651461ms)
Oct 21 20:43:48.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 11.687756ms)
Oct 21 20:43:48.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 12.258296ms)
Oct 21 20:43:48.807: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 12.038177ms)
Oct 21 20:43:48.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 12.59945ms)
Oct 21 20:43:48.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 12.658127ms)
Oct 21 20:43:48.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 12.8381ms)
Oct 21 20:43:48.809: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 14.679301ms)
Oct 21 20:43:48.810: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 15.12546ms)
Oct 21 20:43:48.811: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 16.018238ms)
Oct 21 20:43:48.811: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.395978ms)
Oct 21 20:43:48.811: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 16.376912ms)
Oct 21 20:43:48.823: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 10.042016ms)
Oct 21 20:43:48.823: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 10.637703ms)
Oct 21 20:43:48.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 11.248866ms)
Oct 21 20:43:48.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.157995ms)
Oct 21 20:43:48.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 11.185841ms)
Oct 21 20:43:48.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 12.033144ms)
Oct 21 20:43:48.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 12.02856ms)
Oct 21 20:43:48.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 12.307876ms)
Oct 21 20:43:48.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 12.488413ms)
Oct 21 20:43:48.824: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 11.498838ms)
Oct 21 20:43:48.826: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 13.721403ms)
Oct 21 20:43:48.828: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.020672ms)
Oct 21 20:43:48.828: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 16.260321ms)
Oct 21 20:43:48.829: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 15.917464ms)
Oct 21 20:43:48.829: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 16.336035ms)
Oct 21 20:43:48.829: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 16.517216ms)
Oct 21 20:43:48.839: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 9.945237ms)
Oct 21 20:43:48.841: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 11.246675ms)
Oct 21 20:43:48.841: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 11.704294ms)
Oct 21 20:43:48.841: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.069538ms)
Oct 21 20:43:48.842: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 11.824105ms)
Oct 21 20:43:48.842: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 12.167389ms)
Oct 21 20:43:48.842: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 11.603399ms)
Oct 21 20:43:48.855: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 25.062314ms)
Oct 21 20:43:48.855: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 24.498224ms)
Oct 21 20:43:48.855: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 25.274927ms)
Oct 21 20:43:48.855: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 24.910749ms)
Oct 21 20:43:48.855: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 25.436594ms)
Oct 21 20:43:48.855: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 25.654251ms)
Oct 21 20:43:48.858: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 27.938732ms)
Oct 21 20:43:48.858: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 28.091954ms)
Oct 21 20:43:48.859: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 29.192068ms)
Oct 21 20:43:48.869: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 10.633605ms)
Oct 21 20:43:48.872: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.028658ms)
Oct 21 20:43:48.872: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 13.032456ms)
Oct 21 20:43:48.872: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.82838ms)
Oct 21 20:43:48.872: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.253766ms)
Oct 21 20:43:48.873: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 13.351424ms)
Oct 21 20:43:48.873: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 13.400614ms)
Oct 21 20:43:48.873: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.67938ms)
Oct 21 20:43:48.873: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 13.854472ms)
Oct 21 20:43:48.874: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 15.218975ms)
Oct 21 20:43:48.876: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.697031ms)
Oct 21 20:43:48.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 17.640086ms)
Oct 21 20:43:48.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 17.976902ms)
Oct 21 20:43:48.877: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 18.502215ms)
Oct 21 20:43:48.887: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 27.562421ms)
Oct 21 20:43:48.898: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 38.117955ms)
Oct 21 20:43:48.908: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 10.410281ms)
Oct 21 20:43:48.910: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.114954ms)
Oct 21 20:43:48.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 12.651866ms)
Oct 21 20:43:48.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 12.727571ms)
Oct 21 20:43:48.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.800886ms)
Oct 21 20:43:48.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 12.861409ms)
Oct 21 20:43:48.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 12.901113ms)
Oct 21 20:43:48.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 12.835026ms)
Oct 21 20:43:48.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.298902ms)
Oct 21 20:43:48.911: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 13.037171ms)
Oct 21 20:43:48.914: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 15.854197ms)
Oct 21 20:43:48.915: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 17.541965ms)
Oct 21 20:43:48.915: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 17.216017ms)
Oct 21 20:43:48.915: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 17.547294ms)
Oct 21 20:43:48.915: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 17.358643ms)
Oct 21 20:43:48.916: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 18.015727ms)
Oct 21 20:43:48.926: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 9.794291ms)
Oct 21 20:43:48.928: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 12.507452ms)
Oct 21 20:43:48.929: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 12.571083ms)
Oct 21 20:43:48.929: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 12.822774ms)
Oct 21 20:43:48.929: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 13.164157ms)
Oct 21 20:43:48.930: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.704545ms)
Oct 21 20:43:48.930: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.653694ms)
Oct 21 20:43:48.930: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 13.980894ms)
Oct 21 20:43:48.930: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.937192ms)
Oct 21 20:43:48.931: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 14.758928ms)
Oct 21 20:43:48.933: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 16.845634ms)
Oct 21 20:43:48.934: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 17.489233ms)
Oct 21 20:43:48.934: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 17.813695ms)
Oct 21 20:43:48.934: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 18.287052ms)
Oct 21 20:43:48.934: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 18.251807ms)
Oct 21 20:43:48.935: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 18.288051ms)
Oct 21 20:43:48.946: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 11.187782ms)
Oct 21 20:43:48.947: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 10.853399ms)
Oct 21 20:43:48.947: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.017922ms)
Oct 21 20:43:48.948: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 11.458327ms)
Oct 21 20:43:48.948: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 12.370162ms)
Oct 21 20:43:48.948: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 11.688866ms)
Oct 21 20:43:48.948: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 12.656715ms)
Oct 21 20:43:48.949: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.756329ms)
Oct 21 20:43:48.949: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.684404ms)
Oct 21 20:43:48.951: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 14.869208ms)
Oct 21 20:43:48.952: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 16.362537ms)
Oct 21 20:43:48.953: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 17.747122ms)
Oct 21 20:43:48.953: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 17.337726ms)
Oct 21 20:43:48.954: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 18.670663ms)
Oct 21 20:43:48.954: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 18.850094ms)
Oct 21 20:43:48.954: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 18.449226ms)
Oct 21 20:43:48.964: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 10.146531ms)
Oct 21 20:43:48.966: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 11.973274ms)
Oct 21 20:43:48.967: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 12.732196ms)
Oct 21 20:43:48.967: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.294903ms)
Oct 21 20:43:48.968: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 13.823151ms)
Oct 21 20:43:48.968: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.651464ms)
Oct 21 20:43:48.972: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 18.033777ms)
Oct 21 20:43:48.973: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 18.567042ms)
Oct 21 20:43:48.973: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 18.261221ms)
Oct 21 20:43:48.973: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 18.648105ms)
Oct 21 20:43:48.973: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 18.832313ms)
Oct 21 20:43:48.976: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 21.945561ms)
Oct 21 20:43:48.976: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 21.905929ms)
Oct 21 20:43:48.976: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 21.879584ms)
Oct 21 20:43:48.976: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 21.806999ms)
Oct 21 20:43:48.976: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 21.873017ms)
Oct 21 20:43:48.986: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 9.910924ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 13.001467ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.159096ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 13.078931ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 13.235335ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.227282ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 13.47651ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.357027ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.372321ms)
Oct 21 20:43:48.990: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 13.426899ms)
Oct 21 20:43:48.994: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 16.869291ms)
Oct 21 20:43:48.994: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 17.153049ms)
Oct 21 20:43:48.994: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.998628ms)
Oct 21 20:43:48.994: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 17.078163ms)
Oct 21 20:43:48.994: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 17.569609ms)
Oct 21 20:43:48.994: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 17.696232ms)
Oct 21 20:43:49.008: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 13.496579ms)
Oct 21 20:43:49.008: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 13.907626ms)
Oct 21 20:43:49.008: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.836616ms)
Oct 21 20:43:49.008: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 13.953716ms)
Oct 21 20:43:49.008: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.833737ms)
Oct 21 20:43:49.008: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 13.494421ms)
Oct 21 20:43:49.008: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.711233ms)
Oct 21 20:43:49.009: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 14.3778ms)
Oct 21 20:43:49.009: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 14.287347ms)
Oct 21 20:43:49.009: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 14.389737ms)
Oct 21 20:43:49.012: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 17.980128ms)
Oct 21 20:43:49.025: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 29.934967ms)
Oct 21 20:43:49.025: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 30.126834ms)
Oct 21 20:43:49.025: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 30.027731ms)
Oct 21 20:43:49.025: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 30.127689ms)
Oct 21 20:43:49.025: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 30.300159ms)
Oct 21 20:43:49.035: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 10.444338ms)
Oct 21 20:43:49.037: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 11.995841ms)
Oct 21 20:43:49.037: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 12.539037ms)
Oct 21 20:43:49.038: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 12.24256ms)
Oct 21 20:43:49.038: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.357309ms)
Oct 21 20:43:49.038: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 12.446303ms)
Oct 21 20:43:49.038: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.164856ms)
Oct 21 20:43:49.039: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.5308ms)
Oct 21 20:43:49.039: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 13.336534ms)
Oct 21 20:43:49.038: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 12.994835ms)
Oct 21 20:43:49.040: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 14.924278ms)
Oct 21 20:43:49.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 16.316374ms)
Oct 21 20:43:49.042: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.940981ms)
Oct 21 20:43:49.045: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 19.817026ms)
Oct 21 20:43:49.045: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 19.700038ms)
Oct 21 20:43:49.045: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 19.861804ms)
Oct 21 20:43:49.058: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 13.196356ms)
Oct 21 20:43:49.058: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.050953ms)
Oct 21 20:43:49.059: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 12.985988ms)
Oct 21 20:43:49.058: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 13.102145ms)
Oct 21 20:43:49.059: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.171492ms)
Oct 21 20:43:49.059: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.238137ms)
Oct 21 20:43:49.060: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 14.703919ms)
Oct 21 20:43:49.060: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 14.930636ms)
Oct 21 20:43:49.061: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 15.086877ms)
Oct 21 20:43:49.061: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 15.264136ms)
Oct 21 20:43:49.061: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 16.188974ms)
Oct 21 20:43:49.063: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 17.462831ms)
Oct 21 20:43:49.063: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 17.735296ms)
Oct 21 20:43:49.063: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 18.075745ms)
Oct 21 20:43:49.063: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 18.056912ms)
Oct 21 20:43:49.065: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 19.435259ms)
Oct 21 20:43:49.078: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 12.990643ms)
Oct 21 20:43:49.079: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 13.337372ms)
Oct 21 20:43:49.079: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 13.407444ms)
Oct 21 20:43:49.079: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 13.630278ms)
Oct 21 20:43:49.084: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 18.996938ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 22.678135ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 22.691086ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 22.637287ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 22.944151ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 22.906217ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 23.244219ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 23.082427ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 23.173496ms)
Oct 21 20:43:49.088: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 23.101792ms)
Oct 21 20:43:49.089: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 23.229775ms)
Oct 21 20:43:49.091: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 26.259987ms)
Oct 21 20:43:49.103: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.023213ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 13.1476ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.18387ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 13.389403ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.281637ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 13.415728ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 13.297695ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 13.401216ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 13.66157ms)
Oct 21 20:43:49.105: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.695434ms)
Oct 21 20:43:49.107: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 15.309553ms)
Oct 21 20:43:49.108: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 16.112364ms)
Oct 21 20:43:49.108: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.076783ms)
Oct 21 20:43:49.108: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 16.347534ms)
Oct 21 20:43:49.108: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 16.480229ms)
Oct 21 20:43:49.108: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 16.765939ms)
Oct 21 20:43:49.121: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 11.905028ms)
Oct 21 20:43:49.121: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 11.999554ms)
Oct 21 20:43:49.121: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.220911ms)
Oct 21 20:43:49.121: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 12.239831ms)
Oct 21 20:43:49.122: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 13.618698ms)
Oct 21 20:43:49.122: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 13.315256ms)
Oct 21 20:43:49.122: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.630904ms)
Oct 21 20:43:49.122: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 13.608952ms)
Oct 21 20:43:49.123: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 14.18224ms)
Oct 21 20:43:49.123: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 14.062762ms)
Oct 21 20:43:49.124: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 15.881574ms)
Oct 21 20:43:49.127: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 17.854258ms)
Oct 21 20:43:49.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 31.217218ms)
Oct 21 20:43:49.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 31.192809ms)
Oct 21 20:43:49.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 31.110912ms)
Oct 21 20:43:49.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 31.256609ms)
Oct 21 20:43:49.151: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 10.858223ms)
Oct 21 20:43:49.152: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 11.58701ms)
Oct 21 20:43:49.153: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 11.950548ms)
Oct 21 20:43:49.153: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.137353ms)
Oct 21 20:43:49.153: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 12.403166ms)
Oct 21 20:43:49.153: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 12.965392ms)
Oct 21 20:43:49.153: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 12.245523ms)
Oct 21 20:43:49.153: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 12.395706ms)
Oct 21 20:43:49.153: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 12.674292ms)
Oct 21 20:43:49.154: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 12.856045ms)
Oct 21 20:43:49.156: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 15.658424ms)
Oct 21 20:43:49.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 17.104947ms)
Oct 21 20:43:49.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 17.531584ms)
Oct 21 20:43:49.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 17.290224ms)
Oct 21 20:43:49.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 17.469955ms)
Oct 21 20:43:49.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 17.131608ms)
Oct 21 20:43:49.169: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 10.042414ms)
Oct 21 20:43:49.169: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 11.199243ms)
Oct 21 20:43:49.170: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 11.296754ms)
Oct 21 20:43:49.170: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 11.53106ms)
Oct 21 20:43:49.170: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 11.299776ms)
Oct 21 20:43:49.171: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 12.305888ms)
Oct 21 20:43:49.171: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 12.159651ms)
Oct 21 20:43:49.171: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 12.232463ms)
Oct 21 20:43:49.174: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.064534ms)
Oct 21 20:43:49.174: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 16.004878ms)
Oct 21 20:43:49.174: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 16.640994ms)
Oct 21 20:43:49.175: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 16.395858ms)
Oct 21 20:43:49.178: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 19.410561ms)
Oct 21 20:43:49.191: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 31.8424ms)
Oct 21 20:43:49.191: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 31.616033ms)
Oct 21 20:43:49.191: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 31.858099ms)
Oct 21 20:43:49.201: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:460/proxy/: tls baz (200; 10.476043ms)
Oct 21 20:43:49.203: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:1080/proxy/rewri... (200; 11.452199ms)
Oct 21 20:43:49.203: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg/proxy/rewriteme"... (200; 11.842347ms)
Oct 21 20:43:49.203: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 11.934348ms)
Oct 21 20:43:49.203: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:443/proxy/... (200; 11.757288ms)
Oct 21 20:43:49.203: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/https:proxy-service-vsvm6-v2hfg:462/proxy/: tls qux (200; 12.093611ms)
Oct 21 20:43:49.204: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.029183ms)
Oct 21 20:43:49.205: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:1080/proxy/... (200; 13.300545ms)
Oct 21 20:43:49.205: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/proxy-service-vsvm6-v2hfg:162/proxy/: bar (200; 13.428988ms)
Oct 21 20:43:49.205: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/pods/http:proxy-service-vsvm6-v2hfg:160/proxy/: foo (200; 13.272351ms)
Oct 21 20:43:49.206: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname2/proxy/: tls qux (200; 14.958088ms)
Oct 21 20:43:49.208: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname2/proxy/: bar (200; 16.566273ms)
Oct 21 20:43:49.208: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname1/proxy/: foo (200; 16.679918ms)
Oct 21 20:43:49.208: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/https:proxy-service-vsvm6:tlsportname1/proxy/: tls baz (200; 16.66031ms)
Oct 21 20:43:49.208: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/http:proxy-service-vsvm6:portname1/proxy/: foo (200; 16.922461ms)
Oct 21 20:43:49.208: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-ldrrm/services/proxy-service-vsvm6:portname2/proxy/: bar (200; 16.906702ms)
STEP: deleting ReplicationController proxy-service-vsvm6 in namespace e2e-tests-proxy-ldrrm, will wait for the garbage collector to delete the pods
Oct 21 20:43:49.286: INFO: Deleting ReplicationController proxy-service-vsvm6 took: 20.680725ms
Oct 21 20:43:49.387: INFO: Terminating ReplicationController proxy-service-vsvm6 pods took: 100.383915ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:43:51.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-ldrrm" for this suite.
Oct 21 20:43:57.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:43:57.764: INFO: namespace: e2e-tests-proxy-ldrrm, resource: bindings, ignored listing per whitelist
Oct 21 20:43:58.030: INFO: namespace e2e-tests-proxy-ldrrm deletion completed in 6.430431342s

â€¢ [SLOW TEST:13.782 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:43:58.030: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-s94rc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 21 20:43:58.397: INFO: Waiting up to 5m0s for pod "pod-817aa193-f443-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-s94rc" to be "success or failure"
Oct 21 20:43:58.405: INFO: Pod "pod-817aa193-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013623ms
Oct 21 20:44:00.412: INFO: Pod "pod-817aa193-f443-11e9-a616-8a530cf33301": Phase="Running", Reason="", readiness=true. Elapsed: 2.015293943s
Oct 21 20:44:02.419: INFO: Pod "pod-817aa193-f443-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022403488s
STEP: Saw pod success
Oct 21 20:44:02.419: INFO: Pod "pod-817aa193-f443-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:44:02.426: INFO: Trying to get logs from node 10.170.151.141 pod pod-817aa193-f443-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:44:02.461: INFO: Waiting for pod pod-817aa193-f443-11e9-a616-8a530cf33301 to disappear
Oct 21 20:44:02.467: INFO: Pod pod-817aa193-f443-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:44:02.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s94rc" for this suite.
Oct 21 20:44:08.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:44:08.577: INFO: namespace: e2e-tests-emptydir-s94rc, resource: bindings, ignored listing per whitelist
Oct 21 20:44:08.812: INFO: namespace e2e-tests-emptydir-s94rc deletion completed in 6.335382869s

â€¢ [SLOW TEST:10.782 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:44:08.813: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-zwj22
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:45:09.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zwj22" for this suite.
Oct 21 20:45:33.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:45:33.333: INFO: namespace: e2e-tests-container-probe-zwj22, resource: bindings, ignored listing per whitelist
Oct 21 20:45:33.584: INFO: namespace e2e-tests-container-probe-zwj22 deletion completed in 24.392483441s

â€¢ [SLOW TEST:84.772 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:45:33.585: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ndjkb
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ba6c8d58-f443-11e9-a616-8a530cf33301
STEP: Creating configMap with name cm-test-opt-upd-ba6c8db5-f443-11e9-a616-8a530cf33301
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ba6c8d58-f443-11e9-a616-8a530cf33301
STEP: Updating configmap cm-test-opt-upd-ba6c8db5-f443-11e9-a616-8a530cf33301
STEP: Creating configMap with name cm-test-opt-create-ba6c8dea-f443-11e9-a616-8a530cf33301
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:45:38.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ndjkb" for this suite.
Oct 21 20:46:02.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:46:02.415: INFO: namespace: e2e-tests-configmap-ndjkb, resource: bindings, ignored listing per whitelist
Oct 21 20:46:02.625: INFO: namespace e2e-tests-configmap-ndjkb deletion completed in 24.424022217s

â€¢ [SLOW TEST:29.039 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:46:02.625: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-869nd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:46:05.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-869nd" for this suite.
Oct 21 20:46:45.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:46:45.329: INFO: namespace: e2e-tests-kubelet-test-869nd, resource: bindings, ignored listing per whitelist
Oct 21 20:46:45.363: INFO: namespace e2e-tests-kubelet-test-869nd deletion completed in 40.346402239s

â€¢ [SLOW TEST:42.738 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:46:45.364: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rb44x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-e5347fa1-f443-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:46:45.720: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e535b813-f443-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-rb44x" to be "success or failure"
Oct 21 20:46:45.731: INFO: Pod "pod-projected-secrets-e535b813-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 10.876083ms
Oct 21 20:46:47.741: INFO: Pod "pod-projected-secrets-e535b813-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021445871s
Oct 21 20:46:49.749: INFO: Pod "pod-projected-secrets-e535b813-f443-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029436568s
STEP: Saw pod success
Oct 21 20:46:49.749: INFO: Pod "pod-projected-secrets-e535b813-f443-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:46:49.756: INFO: Trying to get logs from node 10.170.151.141 pod pod-projected-secrets-e535b813-f443-11e9-a616-8a530cf33301 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:46:49.793: INFO: Waiting for pod pod-projected-secrets-e535b813-f443-11e9-a616-8a530cf33301 to disappear
Oct 21 20:46:49.800: INFO: Pod pod-projected-secrets-e535b813-f443-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:46:49.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rb44x" for this suite.
Oct 21 20:46:55.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:46:56.015: INFO: namespace: e2e-tests-projected-rb44x, resource: bindings, ignored listing per whitelist
Oct 21 20:46:56.138: INFO: namespace e2e-tests-projected-rb44x deletion completed in 6.328378794s

â€¢ [SLOW TEST:10.774 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:46:56.140: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d2bmn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-eb9e17d2-f443-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:46:56.477: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eb9fa718-f443-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-d2bmn" to be "success or failure"
Oct 21 20:46:56.484: INFO: Pod "pod-projected-configmaps-eb9fa718-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.3446ms
Oct 21 20:46:58.491: INFO: Pod "pod-projected-configmaps-eb9fa718-f443-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013449803s
STEP: Saw pod success
Oct 21 20:46:58.491: INFO: Pod "pod-projected-configmaps-eb9fa718-f443-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:46:58.498: INFO: Trying to get logs from node 10.170.151.156 pod pod-projected-configmaps-eb9fa718-f443-11e9-a616-8a530cf33301 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 20:46:58.540: INFO: Waiting for pod pod-projected-configmaps-eb9fa718-f443-11e9-a616-8a530cf33301 to disappear
Oct 21 20:46:58.546: INFO: Pod pod-projected-configmaps-eb9fa718-f443-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:46:58.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d2bmn" for this suite.
Oct 21 20:47:04.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:47:04.805: INFO: namespace: e2e-tests-projected-d2bmn, resource: bindings, ignored listing per whitelist
Oct 21 20:47:04.850: INFO: namespace e2e-tests-projected-d2bmn deletion completed in 6.293317707s

â€¢ [SLOW TEST:8.710 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:47:04.850: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-s6gnj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:47:05.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-s6gnj" for this suite.
Oct 21 20:47:11.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:47:11.325: INFO: namespace: e2e-tests-kubelet-test-s6gnj, resource: bindings, ignored listing per whitelist
Oct 21 20:47:11.585: INFO: namespace e2e-tests-kubelet-test-s6gnj deletion completed in 6.320142824s

â€¢ [SLOW TEST:6.735 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:47:11.587: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kdkn7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:47:11.921: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f4d42075-f443-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-kdkn7" to be "success or failure"
Oct 21 20:47:11.929: INFO: Pod "downwardapi-volume-f4d42075-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 8.314174ms
Oct 21 20:47:13.937: INFO: Pod "downwardapi-volume-f4d42075-f443-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01609119s
Oct 21 20:47:15.944: INFO: Pod "downwardapi-volume-f4d42075-f443-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023551257s
STEP: Saw pod success
Oct 21 20:47:15.944: INFO: Pod "downwardapi-volume-f4d42075-f443-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:47:15.951: INFO: Trying to get logs from node 10.170.151.141 pod downwardapi-volume-f4d42075-f443-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:47:15.990: INFO: Waiting for pod downwardapi-volume-f4d42075-f443-11e9-a616-8a530cf33301 to disappear
Oct 21 20:47:15.997: INFO: Pod downwardapi-volume-f4d42075-f443-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:47:15.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kdkn7" for this suite.
Oct 21 20:47:22.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:47:22.225: INFO: namespace: e2e-tests-downward-api-kdkn7, resource: bindings, ignored listing per whitelist
Oct 21 20:47:22.316: INFO: namespace e2e-tests-downward-api-kdkn7 deletion completed in 6.309586918s

â€¢ [SLOW TEST:10.729 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:47:22.316: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-q2z9r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 20:47:22.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-q2z9r'
Oct 21 20:47:22.768: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 20:47:22.768: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Oct 21 20:47:26.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-q2z9r'
Oct 21 20:47:26.960: INFO: stderr: ""
Oct 21 20:47:26.960: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:47:26.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q2z9r" for this suite.
Oct 21 20:47:49.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:47:49.218: INFO: namespace: e2e-tests-kubectl-q2z9r, resource: bindings, ignored listing per whitelist
Oct 21 20:47:49.339: INFO: namespace e2e-tests-kubectl-q2z9r deletion completed in 22.367153381s

â€¢ [SLOW TEST:27.022 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:47:49.339: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-p84fk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0b539956-f444-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:47:49.673: INFO: Waiting up to 5m0s for pod "pod-secrets-0b54da43-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-p84fk" to be "success or failure"
Oct 21 20:47:49.680: INFO: Pod "pod-secrets-0b54da43-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.457552ms
Oct 21 20:47:51.687: INFO: Pod "pod-secrets-0b54da43-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013917191s
STEP: Saw pod success
Oct 21 20:47:51.688: INFO: Pod "pod-secrets-0b54da43-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:47:51.694: INFO: Trying to get logs from node 10.170.151.145 pod pod-secrets-0b54da43-f444-11e9-a616-8a530cf33301 container secret-env-test: <nil>
STEP: delete the pod
Oct 21 20:47:51.738: INFO: Waiting for pod pod-secrets-0b54da43-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:47:51.744: INFO: Pod pod-secrets-0b54da43-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:47:51.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p84fk" for this suite.
Oct 21 20:47:57.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:47:58.101: INFO: namespace: e2e-tests-secrets-p84fk, resource: bindings, ignored listing per whitelist
Oct 21 20:47:58.226: INFO: namespace e2e-tests-secrets-p84fk deletion completed in 6.473593031s

â€¢ [SLOW TEST:8.887 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:47:58.228: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-5wjmt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Oct 21 20:47:58.554: INFO: Waiting up to 5m0s for pod "client-containers-109d001b-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-containers-5wjmt" to be "success or failure"
Oct 21 20:47:58.561: INFO: Pod "client-containers-109d001b-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.294479ms
Oct 21 20:48:00.568: INFO: Pod "client-containers-109d001b-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013702417s
Oct 21 20:48:02.576: INFO: Pod "client-containers-109d001b-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021729717s
STEP: Saw pod success
Oct 21 20:48:02.576: INFO: Pod "client-containers-109d001b-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:48:02.583: INFO: Trying to get logs from node 10.170.151.141 pod client-containers-109d001b-f444-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:48:02.617: INFO: Waiting for pod client-containers-109d001b-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:48:02.624: INFO: Pod client-containers-109d001b-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:48:02.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5wjmt" for this suite.
Oct 21 20:48:08.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:48:08.893: INFO: namespace: e2e-tests-containers-5wjmt, resource: bindings, ignored listing per whitelist
Oct 21 20:48:08.930: INFO: namespace e2e-tests-containers-5wjmt deletion completed in 6.295557953s

â€¢ [SLOW TEST:10.703 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:48:08.931: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-7pqzd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 21 20:48:11.800: INFO: Successfully updated pod "pod-update-1700c8d5-f444-11e9-a616-8a530cf33301"
STEP: verifying the updated pod is in kubernetes
Oct 21 20:48:11.816: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:48:11.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7pqzd" for this suite.
Oct 21 20:48:33.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:48:33.885: INFO: namespace: e2e-tests-pods-7pqzd, resource: bindings, ignored listing per whitelist
Oct 21 20:48:34.141: INFO: namespace e2e-tests-pods-7pqzd deletion completed in 22.314005301s

â€¢ [SLOW TEST:25.211 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:48:34.142: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-88rf9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Oct 21 20:48:34.469: INFO: Waiting up to 5m0s for pod "var-expansion-260839e9-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-var-expansion-88rf9" to be "success or failure"
Oct 21 20:48:34.475: INFO: Pod "var-expansion-260839e9-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.421867ms
Oct 21 20:48:36.482: INFO: Pod "var-expansion-260839e9-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01294251s
STEP: Saw pod success
Oct 21 20:48:36.482: INFO: Pod "var-expansion-260839e9-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:48:36.489: INFO: Trying to get logs from node 10.170.151.145 pod var-expansion-260839e9-f444-11e9-a616-8a530cf33301 container dapi-container: <nil>
STEP: delete the pod
Oct 21 20:48:36.528: INFO: Waiting for pod var-expansion-260839e9-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:48:36.540: INFO: Pod var-expansion-260839e9-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:48:36.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-88rf9" for this suite.
Oct 21 20:48:42.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:48:42.893: INFO: namespace: e2e-tests-var-expansion-88rf9, resource: bindings, ignored listing per whitelist
Oct 21 20:48:42.916: INFO: namespace e2e-tests-var-expansion-88rf9 deletion completed in 6.349707419s

â€¢ [SLOW TEST:8.774 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:48:42.917: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-c8r54
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Oct 21 20:48:43.762: INFO: created pod pod-service-account-defaultsa
Oct 21 20:48:43.762: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct 21 20:48:43.771: INFO: created pod pod-service-account-mountsa
Oct 21 20:48:43.771: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct 21 20:48:43.780: INFO: created pod pod-service-account-nomountsa
Oct 21 20:48:43.780: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct 21 20:48:43.788: INFO: created pod pod-service-account-defaultsa-mountspec
Oct 21 20:48:43.788: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct 21 20:48:43.797: INFO: created pod pod-service-account-mountsa-mountspec
Oct 21 20:48:43.797: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct 21 20:48:43.805: INFO: created pod pod-service-account-nomountsa-mountspec
Oct 21 20:48:43.805: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct 21 20:48:43.817: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct 21 20:48:43.817: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct 21 20:48:43.825: INFO: created pod pod-service-account-mountsa-nomountspec
Oct 21 20:48:43.825: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct 21 20:48:43.834: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct 21 20:48:43.834: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:48:43.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-c8r54" for this suite.
Oct 21 20:48:49.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:48:50.116: INFO: namespace: e2e-tests-svcaccounts-c8r54, resource: bindings, ignored listing per whitelist
Oct 21 20:48:50.175: INFO: namespace e2e-tests-svcaccounts-c8r54 deletion completed in 6.329039213s

â€¢ [SLOW TEST:7.259 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:48:50.176: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-8lnlx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:48:50.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8lnlx" for this suite.
Oct 21 20:49:14.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:49:14.691: INFO: namespace: e2e-tests-pods-8lnlx, resource: bindings, ignored listing per whitelist
Oct 21 20:49:14.998: INFO: namespace e2e-tests-pods-8lnlx deletion completed in 24.486744893s

â€¢ [SLOW TEST:24.823 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:49:14.999: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-4kgfj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:49:15.336: INFO: (0) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.715344ms)
Oct 21 20:49:15.347: INFO: (1) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.205906ms)
Oct 21 20:49:15.360: INFO: (2) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.669794ms)
Oct 21 20:49:15.372: INFO: (3) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.160562ms)
Oct 21 20:49:15.383: INFO: (4) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.011721ms)
Oct 21 20:49:15.395: INFO: (5) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.716578ms)
Oct 21 20:49:15.406: INFO: (6) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.9817ms)
Oct 21 20:49:15.416: INFO: (7) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.221995ms)
Oct 21 20:49:15.427: INFO: (8) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.8126ms)
Oct 21 20:49:15.440: INFO: (9) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.595802ms)
Oct 21 20:49:15.451: INFO: (10) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.157086ms)
Oct 21 20:49:15.462: INFO: (11) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.091663ms)
Oct 21 20:49:15.474: INFO: (12) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.748366ms)
Oct 21 20:49:15.486: INFO: (13) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.665562ms)
Oct 21 20:49:15.497: INFO: (14) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.385048ms)
Oct 21 20:49:15.508: INFO: (15) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.516426ms)
Oct 21 20:49:15.518: INFO: (16) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.46566ms)
Oct 21 20:49:15.528: INFO: (17) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.34933ms)
Oct 21 20:49:15.539: INFO: (18) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.496063ms)
Oct 21 20:49:15.550: INFO: (19) /api/v1/nodes/10.170.151.141/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.071361ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:49:15.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-4kgfj" for this suite.
Oct 21 20:49:21.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:49:21.929: INFO: namespace: e2e-tests-proxy-4kgfj, resource: bindings, ignored listing per whitelist
Oct 21 20:49:21.935: INFO: namespace e2e-tests-proxy-4kgfj deletion completed in 6.375970131s

â€¢ [SLOW TEST:6.936 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:49:21.935: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6sn8f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Oct 21 20:49:22.242: INFO: Waiting up to 5m0s for pod "client-containers-4281ef77-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-containers-6sn8f" to be "success or failure"
Oct 21 20:49:22.248: INFO: Pod "client-containers-4281ef77-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.614142ms
Oct 21 20:49:24.260: INFO: Pod "client-containers-4281ef77-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017883705s
Oct 21 20:49:26.267: INFO: Pod "client-containers-4281ef77-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025278134s
STEP: Saw pod success
Oct 21 20:49:26.267: INFO: Pod "client-containers-4281ef77-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:49:26.273: INFO: Trying to get logs from node 10.170.151.156 pod client-containers-4281ef77-f444-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:49:26.309: INFO: Waiting for pod client-containers-4281ef77-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:49:26.315: INFO: Pod client-containers-4281ef77-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:49:26.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6sn8f" for this suite.
Oct 21 20:49:32.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:49:32.390: INFO: namespace: e2e-tests-containers-6sn8f, resource: bindings, ignored listing per whitelist
Oct 21 20:49:32.649: INFO: namespace e2e-tests-containers-6sn8f deletion completed in 6.324111578s

â€¢ [SLOW TEST:10.714 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:49:32.650: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-h6zfj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-h6zfj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6zfj to expose endpoints map[]
Oct 21 20:49:33.150: INFO: Get endpoints failed (6.120974ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct 21 20:49:34.157: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6zfj exposes endpoints map[] (1.013380783s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-h6zfj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6zfj to expose endpoints map[pod1:[80]]
Oct 21 20:49:37.227: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6zfj exposes endpoints map[pod1:[80]] (3.054659491s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-h6zfj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6zfj to expose endpoints map[pod1:[80] pod2:[80]]
Oct 21 20:49:39.306: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6zfj exposes endpoints map[pod1:[80] pod2:[80]] (2.069446021s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-h6zfj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6zfj to expose endpoints map[pod2:[80]]
Oct 21 20:49:40.345: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6zfj exposes endpoints map[pod2:[80]] (1.027832572s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-h6zfj
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-h6zfj to expose endpoints map[]
Oct 21 20:49:41.369: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-h6zfj exposes endpoints map[] (1.012680888s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:49:41.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-h6zfj" for this suite.
Oct 21 20:50:05.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:50:05.719: INFO: namespace: e2e-tests-services-h6zfj, resource: bindings, ignored listing per whitelist
Oct 21 20:50:05.913: INFO: namespace e2e-tests-services-h6zfj deletion completed in 24.491917956s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:33.263 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:50:05.915: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-gg7ns
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 20:50:06.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5cba7a9c-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-gg7ns" to be "success or failure"
Oct 21 20:50:06.241: INFO: Pod "downwardapi-volume-5cba7a9c-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.658338ms
Oct 21 20:50:08.249: INFO: Pod "downwardapi-volume-5cba7a9c-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014439937s
Oct 21 20:50:10.257: INFO: Pod "downwardapi-volume-5cba7a9c-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022324708s
STEP: Saw pod success
Oct 21 20:50:10.257: INFO: Pod "downwardapi-volume-5cba7a9c-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:50:10.264: INFO: Trying to get logs from node 10.170.151.156 pod downwardapi-volume-5cba7a9c-f444-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 20:50:10.303: INFO: Waiting for pod downwardapi-volume-5cba7a9c-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:50:10.309: INFO: Pod downwardapi-volume-5cba7a9c-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:50:10.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gg7ns" for this suite.
Oct 21 20:50:16.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:50:16.419: INFO: namespace: e2e-tests-downward-api-gg7ns, resource: bindings, ignored listing per whitelist
Oct 21 20:50:16.660: INFO: namespace e2e-tests-downward-api-gg7ns deletion completed in 6.340837264s

â€¢ [SLOW TEST:10.746 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:50:16.661: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bwd9d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 20:50:16.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-bwd9d'
Oct 21 20:50:17.122: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 20:50:17.122: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Oct 21 20:50:19.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-bwd9d'
Oct 21 20:50:19.285: INFO: stderr: ""
Oct 21 20:50:19.285: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:50:19.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bwd9d" for this suite.
Oct 21 20:50:41.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:50:41.724: INFO: namespace: e2e-tests-kubectl-bwd9d, resource: bindings, ignored listing per whitelist
Oct 21 20:50:41.739: INFO: namespace e2e-tests-kubectl-bwd9d deletion completed in 22.443528481s

â€¢ [SLOW TEST:25.078 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:50:41.740: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-psnmr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 20:50:42.130: INFO: Number of nodes with available pods: 0
Oct 21 20:50:42.130: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:50:43.152: INFO: Number of nodes with available pods: 0
Oct 21 20:50:43.152: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:50:44.148: INFO: Number of nodes with available pods: 1
Oct 21 20:50:44.148: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 20:50:45.148: INFO: Number of nodes with available pods: 3
Oct 21 20:50:45.149: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct 21 20:50:45.192: INFO: Number of nodes with available pods: 2
Oct 21 20:50:45.192: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 20:50:46.220: INFO: Number of nodes with available pods: 2
Oct 21 20:50:46.220: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 20:50:47.211: INFO: Number of nodes with available pods: 3
Oct 21 20:50:47.211: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-psnmr, will wait for the garbage collector to delete the pods
Oct 21 20:50:47.304: INFO: Deleting DaemonSet.extensions daemon-set took: 19.99839ms
Oct 21 20:50:47.406: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.795851ms
Oct 21 20:51:31.414: INFO: Number of nodes with available pods: 0
Oct 21 20:51:31.414: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 20:51:31.421: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-psnmr/daemonsets","resourceVersion":"29232"},"items":null}

Oct 21 20:51:31.427: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-psnmr/pods","resourceVersion":"29232"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:51:31.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-psnmr" for this suite.
Oct 21 20:51:37.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:51:37.711: INFO: namespace: e2e-tests-daemonsets-psnmr, resource: bindings, ignored listing per whitelist
Oct 21 20:51:37.786: INFO: namespace e2e-tests-daemonsets-psnmr deletion completed in 6.3199863s

â€¢ [SLOW TEST:56.046 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:51:37.787: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-962pm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-938af80b-f444-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:51:38.206: INFO: Waiting up to 5m0s for pod "pod-secrets-938c4748-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-962pm" to be "success or failure"
Oct 21 20:51:38.212: INFO: Pod "pod-secrets-938c4748-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.287064ms
Oct 21 20:51:40.220: INFO: Pod "pod-secrets-938c4748-f444-11e9-a616-8a530cf33301": Phase="Running", Reason="", readiness=true. Elapsed: 2.014211781s
Oct 21 20:51:42.228: INFO: Pod "pod-secrets-938c4748-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021924216s
STEP: Saw pod success
Oct 21 20:51:42.228: INFO: Pod "pod-secrets-938c4748-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:51:42.234: INFO: Trying to get logs from node 10.170.151.141 pod pod-secrets-938c4748-f444-11e9-a616-8a530cf33301 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:51:42.280: INFO: Waiting for pod pod-secrets-938c4748-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:51:42.286: INFO: Pod pod-secrets-938c4748-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:51:42.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-962pm" for this suite.
Oct 21 20:51:48.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:51:48.433: INFO: namespace: e2e-tests-secrets-962pm, resource: bindings, ignored listing per whitelist
Oct 21 20:51:48.651: INFO: namespace e2e-tests-secrets-962pm deletion completed in 6.353104408s

â€¢ [SLOW TEST:10.864 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:51:48.651: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-w852l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-w852l/secret-test-99f69814-f444-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:51:48.977: INFO: Waiting up to 5m0s for pod "pod-configmaps-99f7f84b-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-w852l" to be "success or failure"
Oct 21 20:51:48.983: INFO: Pod "pod-configmaps-99f7f84b-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.117918ms
Oct 21 20:51:50.991: INFO: Pod "pod-configmaps-99f7f84b-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013987462s
STEP: Saw pod success
Oct 21 20:51:50.991: INFO: Pod "pod-configmaps-99f7f84b-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:51:50.998: INFO: Trying to get logs from node 10.170.151.156 pod pod-configmaps-99f7f84b-f444-11e9-a616-8a530cf33301 container env-test: <nil>
STEP: delete the pod
Oct 21 20:51:51.041: INFO: Waiting for pod pod-configmaps-99f7f84b-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:51:51.047: INFO: Pod pod-configmaps-99f7f84b-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:51:51.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w852l" for this suite.
Oct 21 20:51:57.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:51:57.147: INFO: namespace: e2e-tests-secrets-w852l, resource: bindings, ignored listing per whitelist
Oct 21 20:51:57.357: INFO: namespace e2e-tests-secrets-w852l deletion completed in 6.300652604s

â€¢ [SLOW TEST:8.706 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:51:57.358: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-z29lb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 21 20:51:57.680: INFO: Waiting up to 5m0s for pod "downward-api-9f27a9af-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-z29lb" to be "success or failure"
Oct 21 20:51:57.687: INFO: Pod "downward-api-9f27a9af-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.243642ms
Oct 21 20:51:59.697: INFO: Pod "downward-api-9f27a9af-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016437611s
STEP: Saw pod success
Oct 21 20:51:59.697: INFO: Pod "downward-api-9f27a9af-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:51:59.705: INFO: Trying to get logs from node 10.170.151.145 pod downward-api-9f27a9af-f444-11e9-a616-8a530cf33301 container dapi-container: <nil>
STEP: delete the pod
Oct 21 20:51:59.744: INFO: Waiting for pod downward-api-9f27a9af-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:51:59.751: INFO: Pod downward-api-9f27a9af-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:51:59.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z29lb" for this suite.
Oct 21 20:52:05.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:52:06.074: INFO: namespace: e2e-tests-downward-api-z29lb, resource: bindings, ignored listing per whitelist
Oct 21 20:52:06.222: INFO: namespace e2e-tests-downward-api-z29lb deletion completed in 6.460029876s

â€¢ [SLOW TEST:8.864 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:52:06.222: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-d6vrx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Oct 21 20:52:06.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-d6vrx'
Oct 21 20:52:07.100: INFO: stderr: ""
Oct 21 20:52:07.100: INFO: stdout: "pod/pause created\n"
Oct 21 20:52:07.100: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct 21 20:52:07.100: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-d6vrx" to be "running and ready"
Oct 21 20:52:07.107: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.117253ms
Oct 21 20:52:09.114: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014335094s
Oct 21 20:52:09.114: INFO: Pod "pause" satisfied condition "running and ready"
Oct 21 20:52:09.114: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Oct 21 20:52:09.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-d6vrx'
Oct 21 20:52:09.261: INFO: stderr: ""
Oct 21 20:52:09.261: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct 21 20:52:09.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pod pause -L testing-label --namespace=e2e-tests-kubectl-d6vrx'
Oct 21 20:52:09.395: INFO: stderr: ""
Oct 21 20:52:09.395: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct 21 20:52:09.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 label pods pause testing-label- --namespace=e2e-tests-kubectl-d6vrx'
Oct 21 20:52:09.545: INFO: stderr: ""
Oct 21 20:52:09.545: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct 21 20:52:09.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pod pause -L testing-label --namespace=e2e-tests-kubectl-d6vrx'
Oct 21 20:52:09.671: INFO: stderr: ""
Oct 21 20:52:09.671: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Oct 21 20:52:09.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-d6vrx'
Oct 21 20:52:09.828: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct 21 20:52:09.828: INFO: stdout: "pod \"pause\" force deleted\n"
Oct 21 20:52:09.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-d6vrx'
Oct 21 20:52:09.967: INFO: stderr: "No resources found.\n"
Oct 21 20:52:09.967: INFO: stdout: ""
Oct 21 20:52:09.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 get pods -l name=pause --namespace=e2e-tests-kubectl-d6vrx -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct 21 20:52:10.088: INFO: stderr: ""
Oct 21 20:52:10.088: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:52:10.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d6vrx" for this suite.
Oct 21 20:52:16.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:52:16.225: INFO: namespace: e2e-tests-kubectl-d6vrx, resource: bindings, ignored listing per whitelist
Oct 21 20:52:16.419: INFO: namespace e2e-tests-kubectl-d6vrx deletion completed in 6.321989362s

â€¢ [SLOW TEST:10.198 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:52:16.420: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-q5w5d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct 21 20:52:24.791: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:24.791: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:24.988: INFO: Exec stderr: ""
Oct 21 20:52:24.988: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:24.988: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:25.207: INFO: Exec stderr: ""
Oct 21 20:52:25.207: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:25.207: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:25.425: INFO: Exec stderr: ""
Oct 21 20:52:25.425: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:25.425: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:25.652: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct 21 20:52:25.652: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:25.652: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:25.869: INFO: Exec stderr: ""
Oct 21 20:52:25.869: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:25.869: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:26.077: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct 21 20:52:26.077: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:26.077: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:26.324: INFO: Exec stderr: ""
Oct 21 20:52:26.324: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:26.324: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:26.540: INFO: Exec stderr: ""
Oct 21 20:52:26.540: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:26.540: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:26.802: INFO: Exec stderr: ""
Oct 21 20:52:26.802: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-q5w5d PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:52:26.802: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:52:27.040: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:52:27.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-q5w5d" for this suite.
Oct 21 20:53:09.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:53:09.136: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-q5w5d, resource: bindings, ignored listing per whitelist
Oct 21 20:53:09.360: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-q5w5d deletion completed in 42.309115305s

â€¢ [SLOW TEST:52.940 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:53:09.362: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-9wh5z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-9wh5z/configmap-test-ca1399ba-f444-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 20:53:09.708: INFO: Waiting up to 5m0s for pod "pod-configmaps-ca168696-f444-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-9wh5z" to be "success or failure"
Oct 21 20:53:09.718: INFO: Pod "pod-configmaps-ca168696-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 10.339226ms
Oct 21 20:53:11.726: INFO: Pod "pod-configmaps-ca168696-f444-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018189525s
Oct 21 20:53:13.734: INFO: Pod "pod-configmaps-ca168696-f444-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026225708s
STEP: Saw pod success
Oct 21 20:53:13.734: INFO: Pod "pod-configmaps-ca168696-f444-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:53:13.740: INFO: Trying to get logs from node 10.170.151.145 pod pod-configmaps-ca168696-f444-11e9-a616-8a530cf33301 container env-test: <nil>
STEP: delete the pod
Oct 21 20:53:13.798: INFO: Waiting for pod pod-configmaps-ca168696-f444-11e9-a616-8a530cf33301 to disappear
Oct 21 20:53:13.806: INFO: Pod pod-configmaps-ca168696-f444-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:53:13.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9wh5z" for this suite.
Oct 21 20:53:19.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:53:19.977: INFO: namespace: e2e-tests-configmap-9wh5z, resource: bindings, ignored listing per whitelist
Oct 21 20:53:20.125: INFO: namespace e2e-tests-configmap-9wh5z deletion completed in 6.308453175s

â€¢ [SLOW TEST:10.764 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:53:20.128: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-hmrjl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-4hlr
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 20:53:20.484: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-4hlr" in namespace "e2e-tests-subpath-hmrjl" to be "success or failure"
Oct 21 20:53:20.490: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Pending", Reason="", readiness=false. Elapsed: 5.960445ms
Oct 21 20:53:22.503: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018523927s
Oct 21 20:53:24.510: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 4.025923459s
Oct 21 20:53:26.518: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 6.033528139s
Oct 21 20:53:28.525: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 8.041139217s
Oct 21 20:53:30.533: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 10.049091415s
Oct 21 20:53:32.541: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 12.056500217s
Oct 21 20:53:34.548: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 14.063849737s
Oct 21 20:53:36.555: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 16.071098165s
Oct 21 20:53:38.564: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 18.079492388s
Oct 21 20:53:40.570: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 20.086179811s
Oct 21 20:53:42.578: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Running", Reason="", readiness=false. Elapsed: 22.09366655s
Oct 21 20:53:44.586: INFO: Pod "pod-subpath-test-downwardapi-4hlr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.101824861s
STEP: Saw pod success
Oct 21 20:53:44.586: INFO: Pod "pod-subpath-test-downwardapi-4hlr" satisfied condition "success or failure"
Oct 21 20:53:44.592: INFO: Trying to get logs from node 10.170.151.156 pod pod-subpath-test-downwardapi-4hlr container test-container-subpath-downwardapi-4hlr: <nil>
STEP: delete the pod
Oct 21 20:53:44.635: INFO: Waiting for pod pod-subpath-test-downwardapi-4hlr to disappear
Oct 21 20:53:44.641: INFO: Pod pod-subpath-test-downwardapi-4hlr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-4hlr
Oct 21 20:53:44.641: INFO: Deleting pod "pod-subpath-test-downwardapi-4hlr" in namespace "e2e-tests-subpath-hmrjl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:53:44.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hmrjl" for this suite.
Oct 21 20:53:50.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:53:50.914: INFO: namespace: e2e-tests-subpath-hmrjl, resource: bindings, ignored listing per whitelist
Oct 21 20:53:50.982: INFO: namespace e2e-tests-subpath-hmrjl deletion completed in 6.325718587s

â€¢ [SLOW TEST:30.854 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:53:50.985: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-vtrk8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct 21 20:53:54.351: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:53:55.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-vtrk8" for this suite.
Oct 21 20:54:19.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:54:19.566: INFO: namespace: e2e-tests-replicaset-vtrk8, resource: bindings, ignored listing per whitelist
Oct 21 20:54:20.063: INFO: namespace e2e-tests-replicaset-vtrk8 deletion completed in 24.673450913s

â€¢ [SLOW TEST:29.078 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:54:20.063: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-skqtn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:54:20.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 version --client'
Oct 21 20:54:20.471: INFO: stderr: ""
Oct 21 20:54:20.471: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Oct 21 20:54:20.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-skqtn'
Oct 21 20:54:20.740: INFO: stderr: ""
Oct 21 20:54:20.740: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct 21 20:54:20.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-skqtn'
Oct 21 20:54:21.011: INFO: stderr: ""
Oct 21 20:54:21.011: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 20:54:22.022: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:54:22.022: INFO: Found 0 / 1
Oct 21 20:54:23.019: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:54:23.019: INFO: Found 1 / 1
Oct 21 20:54:23.019: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 20:54:23.026: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:54:23.026: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 20:54:23.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 describe pod redis-master-h6d5z --namespace=e2e-tests-kubectl-skqtn'
Oct 21 20:54:23.197: INFO: stderr: ""
Oct 21 20:54:23.197: INFO: stdout: "Name:               redis-master-h6d5z\nNamespace:          e2e-tests-kubectl-skqtn\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.170.151.156/10.170.151.156\nStart Time:         Mon, 21 Oct 2019 20:54:20 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.96.126\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://0ebf9eed3b0032829508394b2c5c9b1c4fc56783e60f271fea875ddc478d8c2e\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 21 Oct 2019 20:54:22 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-z74q2 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-z74q2:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-z74q2\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  3s    default-scheduler        Successfully assigned e2e-tests-kubectl-skqtn/redis-master-h6d5z to 10.170.151.156\n  Normal  Pulled     2s    kubelet, 10.170.151.156  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.170.151.156  Created container\n  Normal  Started    1s    kubelet, 10.170.151.156  Started container\n"
Oct 21 20:54:23.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 describe rc redis-master --namespace=e2e-tests-kubectl-skqtn'
Oct 21 20:54:23.355: INFO: stderr: ""
Oct 21 20:54:23.355: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-skqtn\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-h6d5z\n"
Oct 21 20:54:23.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 describe service redis-master --namespace=e2e-tests-kubectl-skqtn'
Oct 21 20:54:23.510: INFO: stderr: ""
Oct 21 20:54:23.510: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-skqtn\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.197.207\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.96.126:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct 21 20:54:23.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 describe node 10.170.151.141'
Oct 21 20:54:23.708: INFO: stderr: ""
Oct 21 20:54:23.708: INFO: stdout: "Name:               10.170.151.141\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc04\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=bmmvhg4w0qp7koa8k1fg-28a77f2\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.13.11_1538\n                    kubernetes.io/hostname=10.170.151.141\n                    privateVLAN=2361459\n                    publicVLAN=2361457\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 21 Oct 2019 18:42:08 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 21 Oct 2019 20:54:17 +0000   Mon, 21 Oct 2019 18:42:08 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 21 Oct 2019 20:54:17 +0000   Mon, 21 Oct 2019 18:42:08 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 21 Oct 2019 20:54:17 +0000   Mon, 21 Oct 2019 18:42:08 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 21 Oct 2019 20:54:17 +0000   Mon, 21 Oct 2019 18:42:18 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.170.151.141\n  ExternalIP:  169.47.168.219\n  Hostname:    10.170.151.141\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419960Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627512Ki\n pods:               110\nSystem Info:\n Machine ID:                 d54c753ffe6a4e908ecce0a4bbf60792\n System UUID:                9AD5AF0B-33CA-77C4-20CF-5AE38DADE5CF\n Boot ID:                    d9b469a3-20a3-42c8-b93a-c0ee500b7d33\n Kernel Version:             4.15.0-65-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.10\n Kubelet Version:            v1.13.11+IKS\n Kube-Proxy Version:         v1.13.11+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bmmvhg4w0qp7koa8k1fg/kube-bmmvhg4w0qp7koa8k1fg-kubee2epvgq-default-0000014f\nNon-terminated Pods:         (14 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                 ibm-cloud-provider-ip-169-45-227-188-d7c997c79-ss8xf       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         131m\n  kube-system                calico-kube-controllers-94b69ddc9-g4p7g                    10m (0%)      0 (0%)      25Mi (0%)        3Gi (23%)      136m\n  kube-system                calico-node-bzvgs                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         132m\n  kube-system                coredns-6d59786485-bqmjp                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     106m\n  kube-system                coredns-autoscaler-64f9c5b4df-9r7mj                        20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         107m\n  kube-system                ibm-file-plugin-5978669657-p76mk                           50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         135m\n  kube-system                ibm-keepalived-watcher-vxdfw                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         132m\n  kube-system                ibm-kube-fluentd-sk72w                                     25m (0%)      300m (7%)   150Mi (1%)       1600M (11%)    128m\n  kube-system                ibm-master-proxy-static-10.170.151.141                     25m (0%)      300m (7%)   32M (0%)         512M (3%)      132m\n  kube-system                ibm-storage-watcher-6d9866b77c-h5m5n                       50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         135m\n  kube-system                kubernetes-dashboard-7996b848f4-5kt8s                      50m (1%)      0 (0%)      100Mi (0%)       0 (0%)         132m\n  kube-system                vpn-85755bfd8b-mgkzx                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         108m\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         59m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-dzdbt    0 (0%)        0 (0%)      0 (0%)           0 (0%)         59m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                595m (15%)     1 (25%)\n  memory             707090Ki (5%)  5617828Ki (41%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Oct 21 20:54:23.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 describe namespace e2e-tests-kubectl-skqtn'
Oct 21 20:54:23.872: INFO: stderr: ""
Oct 21 20:54:23.873: INFO: stdout: "Name:         e2e-tests-kubectl-skqtn\nLabels:       e2e-framework=kubectl\n              e2e-run=acd199f2-f43c-11e9-a616-8a530cf33301\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:54:23.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-skqtn" for this suite.
Oct 21 20:54:47.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:54:48.249: INFO: namespace: e2e-tests-kubectl-skqtn, resource: bindings, ignored listing per whitelist
Oct 21 20:54:48.313: INFO: namespace e2e-tests-kubectl-skqtn deletion completed in 24.430227836s

â€¢ [SLOW TEST:28.250 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:54:48.314: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-ctr79
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 20:54:48.674: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct 21 20:54:48.691: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct 21 20:54:53.699: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct 21 20:54:53.699: INFO: Creating deployment "test-rolling-update-deployment"
Oct 21 20:54:53.709: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct 21 20:54:53.728: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct 21 20:54:55.744: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct 21 20:54:55.750: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707288093, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707288093, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63707288093, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707288093, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct 21 20:54:57.759: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Oct 21 20:54:57.781: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-ctr79,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ctr79/deployments/test-rolling-update-deployment,UID:0814bde7-f445-11e9-8a4f-8adb5f5fcc88,ResourceVersion:30120,Generation:1,CreationTimestamp:2019-10-21 20:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-10-21 20:54:53 +0000 UTC 2019-10-21 20:54:53 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-10-21 20:54:55 +0000 UTC 2019-10-21 20:54:53 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Oct 21 20:54:57.791: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-ctr79,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ctr79/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:081abc78-f445-11e9-9086-ba4ceb9f210a,ResourceVersion:30108,Generation:1,CreationTimestamp:2019-10-21 20:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0814bde7-f445-11e9-8a4f-8adb5f5fcc88 0xc000351617 0xc000351618}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Oct 21 20:54:57.791: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct 21 20:54:57.791: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-ctr79,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-ctr79/replicasets/test-rolling-update-controller,UID:0515f9cd-f445-11e9-8a4f-8adb5f5fcc88,ResourceVersion:30119,Generation:2,CreationTimestamp:2019-10-21 20:54:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0814bde7-f445-11e9-8a4f-8adb5f5fcc88 0xc0003514f7 0xc0003514f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Oct 21 20:54:57.798: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-9qqv2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-9qqv2,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-ctr79,SelfLink:/api/v1/namespaces/e2e-tests-deployment-ctr79/pods/test-rolling-update-deployment-68b55d7bc6-9qqv2,UID:081c226b-f445-11e9-9086-ba4ceb9f210a,ResourceVersion:30107,Generation:0,CreationTimestamp:2019-10-21 20:54:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 081abc78-f445-11e9-9086-ba4ceb9f210a 0xc0000eb457 0xc0000eb458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-jlv97 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-jlv97,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-jlv97 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.151.141,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0000eb510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0000eb560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:54:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:54:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:54:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-21 20:54:53 +0000 UTC  }],Message:,Reason:,HostIP:10.170.151.141,PodIP:172.30.204.99,StartTime:2019-10-21 20:54:53 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-10-21 20:54:54 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://81680db7de9370970ae43cc449475301b100cb410747ea385362e3a50746dbb5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:54:57.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-ctr79" for this suite.
Oct 21 20:55:03.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:55:04.030: INFO: namespace: e2e-tests-deployment-ctr79, resource: bindings, ignored listing per whitelist
Oct 21 20:55:04.113: INFO: namespace e2e-tests-deployment-ctr79 deletion completed in 6.30346857s

â€¢ [SLOW TEST:15.799 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:55:04.113: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-zq62t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Oct 21 20:55:04.426: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:55:08.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-zq62t" for this suite.
Oct 21 20:55:32.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:55:33.104: INFO: namespace: e2e-tests-init-container-zq62t, resource: bindings, ignored listing per whitelist
Oct 21 20:55:33.244: INFO: namespace e2e-tests-init-container-zq62t deletion completed in 24.332714896s

â€¢ [SLOW TEST:29.131 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:55:33.246: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-78pzq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-78pzq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 20:55:33.566: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 20:55:57.729: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.96.68 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-78pzq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:55:57.729: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:55:58.942: INFO: Found all expected endpoints: [netserver-0]
Oct 21 20:55:58.949: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.198.171 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-78pzq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:55:58.949: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:56:00.170: INFO: Found all expected endpoints: [netserver-1]
Oct 21 20:56:00.178: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.204.100 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-78pzq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 20:56:00.178: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 20:56:01.468: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:56:01.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-78pzq" for this suite.
Oct 21 20:56:25.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:56:26.213: INFO: namespace: e2e-tests-pod-network-test-78pzq, resource: bindings, ignored listing per whitelist
Oct 21 20:56:26.302: INFO: namespace e2e-tests-pod-network-test-78pzq deletion completed in 24.823496727s

â€¢ [SLOW TEST:53.057 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:56:26.305: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9fzlq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Oct 21 20:56:26.610: INFO: namespace e2e-tests-kubectl-9fzlq
Oct 21 20:56:26.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 create -f - --namespace=e2e-tests-kubectl-9fzlq'
Oct 21 20:56:26.880: INFO: stderr: ""
Oct 21 20:56:26.880: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct 21 20:56:27.888: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:56:27.888: INFO: Found 0 / 1
Oct 21 20:56:28.888: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:56:28.888: INFO: Found 0 / 1
Oct 21 20:56:29.888: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:56:29.888: INFO: Found 1 / 1
Oct 21 20:56:29.888: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct 21 20:56:29.895: INFO: Selector matched 1 pods for map[app:redis]
Oct 21 20:56:29.895: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct 21 20:56:29.895: INFO: wait on redis-master startup in e2e-tests-kubectl-9fzlq 
Oct 21 20:56:29.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 logs redis-master-wdgwx redis-master --namespace=e2e-tests-kubectl-9fzlq'
Oct 21 20:56:30.063: INFO: stderr: ""
Oct 21 20:56:30.063: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Oct 20:56:28.175 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Oct 20:56:28.176 # Server started, Redis version 3.2.12\n1:M 21 Oct 20:56:28.176 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Oct 20:56:28.176 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Oct 21 20:56:30.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-9fzlq'
Oct 21 20:56:30.233: INFO: stderr: ""
Oct 21 20:56:30.233: INFO: stdout: "service/rm2 exposed\n"
Oct 21 20:56:30.243: INFO: Service rm2 in namespace e2e-tests-kubectl-9fzlq found.
STEP: exposing service
Oct 21 20:56:32.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-9fzlq'
Oct 21 20:56:32.432: INFO: stderr: ""
Oct 21 20:56:32.432: INFO: stdout: "service/rm3 exposed\n"
Oct 21 20:56:32.442: INFO: Service rm3 in namespace e2e-tests-kubectl-9fzlq found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:56:34.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9fzlq" for this suite.
Oct 21 20:56:58.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:56:58.771: INFO: namespace: e2e-tests-kubectl-9fzlq, resource: bindings, ignored listing per whitelist
Oct 21 20:56:58.784: INFO: namespace e2e-tests-kubectl-9fzlq deletion completed in 24.316436042s

â€¢ [SLOW TEST:32.479 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:56:58.784: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-thbm7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-52d2da91-f445-11e9-a616-8a530cf33301
Oct 21 20:56:59.113: INFO: Pod name my-hostname-basic-52d2da91-f445-11e9-a616-8a530cf33301: Found 0 pods out of 1
Oct 21 20:57:04.122: INFO: Pod name my-hostname-basic-52d2da91-f445-11e9-a616-8a530cf33301: Found 1 pods out of 1
Oct 21 20:57:04.122: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-52d2da91-f445-11e9-a616-8a530cf33301" are running
Oct 21 20:57:04.129: INFO: Pod "my-hostname-basic-52d2da91-f445-11e9-a616-8a530cf33301-hzt94" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 20:56:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 20:57:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 20:57:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-21 20:56:59 +0000 UTC Reason: Message:}])
Oct 21 20:57:04.129: INFO: Trying to dial the pod
Oct 21 20:57:09.161: INFO: Controller my-hostname-basic-52d2da91-f445-11e9-a616-8a530cf33301: Got expected result from replica 1 [my-hostname-basic-52d2da91-f445-11e9-a616-8a530cf33301-hzt94]: "my-hostname-basic-52d2da91-f445-11e9-a616-8a530cf33301-hzt94", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:57:09.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-thbm7" for this suite.
Oct 21 20:57:15.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:57:15.463: INFO: namespace: e2e-tests-replication-controller-thbm7, resource: bindings, ignored listing per whitelist
Oct 21 20:57:15.614: INFO: namespace e2e-tests-replication-controller-thbm7 deletion completed in 6.429003884s

â€¢ [SLOW TEST:16.830 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:57:15.615: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-d59ck
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct 21 20:57:15.947: INFO: Waiting up to 5m0s for pod "pod-5cdb8065-f445-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-d59ck" to be "success or failure"
Oct 21 20:57:15.954: INFO: Pod "pod-5cdb8065-f445-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.28592ms
Oct 21 20:57:17.961: INFO: Pod "pod-5cdb8065-f445-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013980838s
Oct 21 20:57:19.969: INFO: Pod "pod-5cdb8065-f445-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021898889s
STEP: Saw pod success
Oct 21 20:57:19.969: INFO: Pod "pod-5cdb8065-f445-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:57:19.976: INFO: Trying to get logs from node 10.170.151.141 pod pod-5cdb8065-f445-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:57:20.023: INFO: Waiting for pod pod-5cdb8065-f445-11e9-a616-8a530cf33301 to disappear
Oct 21 20:57:20.030: INFO: Pod pod-5cdb8065-f445-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:57:20.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d59ck" for this suite.
Oct 21 20:57:26.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:57:26.170: INFO: namespace: e2e-tests-emptydir-d59ck, resource: bindings, ignored listing per whitelist
Oct 21 20:57:26.481: INFO: namespace e2e-tests-emptydir-d59ck deletion completed in 6.436567037s

â€¢ [SLOW TEST:10.867 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:57:26.481: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-ngwjg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-9kkbq
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-x5r8j
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:57:33.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-ngwjg" for this suite.
Oct 21 20:57:39.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:57:39.479: INFO: namespace: e2e-tests-namespaces-ngwjg, resource: bindings, ignored listing per whitelist
Oct 21 20:57:39.544: INFO: namespace e2e-tests-namespaces-ngwjg deletion completed in 6.288323133s
STEP: Destroying namespace "e2e-tests-nsdeletetest-9kkbq" for this suite.
Oct 21 20:57:39.553: INFO: Namespace e2e-tests-nsdeletetest-9kkbq was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-x5r8j" for this suite.
Oct 21 20:57:45.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:57:45.662: INFO: namespace: e2e-tests-nsdeletetest-x5r8j, resource: bindings, ignored listing per whitelist
Oct 21 20:57:45.907: INFO: namespace e2e-tests-nsdeletetest-x5r8j deletion completed in 6.353698666s

â€¢ [SLOW TEST:19.425 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:57:45.907: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b8lph
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Oct 21 20:57:46.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 --namespace=e2e-tests-kubectl-b8lph run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct 21 20:57:48.444: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct 21 20:57:48.444: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:57:50.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b8lph" for this suite.
Oct 21 20:57:56.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:57:56.523: INFO: namespace: e2e-tests-kubectl-b8lph, resource: bindings, ignored listing per whitelist
Oct 21 20:57:56.782: INFO: namespace e2e-tests-kubectl-b8lph deletion completed in 6.3143078s

â€¢ [SLOW TEST:10.875 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:57:56.782: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-8852x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:57:57.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-8852x" for this suite.
Oct 21 20:58:03.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:58:03.355: INFO: namespace: e2e-tests-services-8852x, resource: bindings, ignored listing per whitelist
Oct 21 20:58:03.462: INFO: namespace e2e-tests-services-8852x deletion completed in 6.354264437s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:6.679 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:58:03.463: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-swcz2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct 21 20:58:03.934: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-swcz2,SelfLink:/api/v1/namespaces/e2e-tests-watch-swcz2/configmaps/e2e-watch-test-resource-version,UID:796d2226-f445-11e9-8a4f-8adb5f5fcc88,ResourceVersion:30892,Generation:0,CreationTimestamp:2019-10-21 20:58:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 20:58:03.934: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-swcz2,SelfLink:/api/v1/namespaces/e2e-tests-watch-swcz2/configmaps/e2e-watch-test-resource-version,UID:796d2226-f445-11e9-8a4f-8adb5f5fcc88,ResourceVersion:30893,Generation:0,CreationTimestamp:2019-10-21 20:58:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:58:03.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-swcz2" for this suite.
Oct 21 20:58:09.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:58:10.217: INFO: namespace: e2e-tests-watch-swcz2, resource: bindings, ignored listing per whitelist
Oct 21 20:58:10.343: INFO: namespace e2e-tests-watch-swcz2 deletion completed in 6.39878326s

â€¢ [SLOW TEST:6.880 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:58:10.343: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tg6qx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 20:58:10.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-tg6qx'
Oct 21 20:58:10.790: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct 21 20:58:10.790: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Oct 21 20:58:12.813: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-br96w]
Oct 21 20:58:12.813: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-br96w" in namespace "e2e-tests-kubectl-tg6qx" to be "running and ready"
Oct 21 20:58:12.819: INFO: Pod "e2e-test-nginx-rc-br96w": Phase="Running", Reason="", readiness=true. Elapsed: 6.409757ms
Oct 21 20:58:12.819: INFO: Pod "e2e-test-nginx-rc-br96w" satisfied condition "running and ready"
Oct 21 20:58:12.819: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-br96w]
Oct 21 20:58:12.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tg6qx'
Oct 21 20:58:12.995: INFO: stderr: ""
Oct 21 20:58:12.995: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Oct 21 20:58:12.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tg6qx'
Oct 21 20:58:13.172: INFO: stderr: ""
Oct 21 20:58:13.172: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:58:13.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tg6qx" for this suite.
Oct 21 20:58:37.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:58:37.431: INFO: namespace: e2e-tests-kubectl-tg6qx, resource: bindings, ignored listing per whitelist
Oct 21 20:58:37.476: INFO: namespace e2e-tests-kubectl-tg6qx deletion completed in 24.293502807s

â€¢ [SLOW TEST:27.133 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:58:37.476: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-v76zx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-v76zx
Oct 21 20:58:39.840: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-v76zx
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 20:58:39.846: INFO: Initial restart count of pod liveness-exec is 0
Oct 21 20:59:26.024: INFO: Restart count of pod e2e-tests-container-probe-v76zx/liveness-exec is now 1 (46.178557306s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:59:26.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-v76zx" for this suite.
Oct 21 20:59:32.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:59:32.321: INFO: namespace: e2e-tests-container-probe-v76zx, resource: bindings, ignored listing per whitelist
Oct 21 20:59:32.334: INFO: namespace e2e-tests-container-probe-v76zx deletion completed in 6.280778085s

â€¢ [SLOW TEST:54.858 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:59:32.335: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ppwvv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 21 20:59:32.654: INFO: Waiting up to 5m0s for pod "pod-ae575549-f445-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-ppwvv" to be "success or failure"
Oct 21 20:59:32.661: INFO: Pod "pod-ae575549-f445-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.714479ms
Oct 21 20:59:34.670: INFO: Pod "pod-ae575549-f445-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016076263s
STEP: Saw pod success
Oct 21 20:59:34.670: INFO: Pod "pod-ae575549-f445-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:59:34.676: INFO: Trying to get logs from node 10.170.151.156 pod pod-ae575549-f445-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 20:59:34.719: INFO: Waiting for pod pod-ae575549-f445-11e9-a616-8a530cf33301 to disappear
Oct 21 20:59:34.725: INFO: Pod pod-ae575549-f445-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:59:34.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ppwvv" for this suite.
Oct 21 20:59:40.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:59:40.958: INFO: namespace: e2e-tests-emptydir-ppwvv, resource: bindings, ignored listing per whitelist
Oct 21 20:59:41.047: INFO: namespace e2e-tests-emptydir-ppwvv deletion completed in 6.309736374s

â€¢ [SLOW TEST:8.712 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:59:41.048: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-n2rvc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b3a79150-f445-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 20:59:41.578: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b3a8d9a8-f445-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-n2rvc" to be "success or failure"
Oct 21 20:59:41.584: INFO: Pod "pod-projected-secrets-b3a8d9a8-f445-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 5.999331ms
Oct 21 20:59:43.591: INFO: Pod "pod-projected-secrets-b3a8d9a8-f445-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013161921s
STEP: Saw pod success
Oct 21 20:59:43.591: INFO: Pod "pod-projected-secrets-b3a8d9a8-f445-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 20:59:43.597: INFO: Trying to get logs from node 10.170.151.156 pod pod-projected-secrets-b3a8d9a8-f445-11e9-a616-8a530cf33301 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 20:59:43.634: INFO: Waiting for pod pod-projected-secrets-b3a8d9a8-f445-11e9-a616-8a530cf33301 to disappear
Oct 21 20:59:43.641: INFO: Pod pod-projected-secrets-b3a8d9a8-f445-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 20:59:43.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n2rvc" for this suite.
Oct 21 20:59:49.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 20:59:50.117: INFO: namespace: e2e-tests-projected-n2rvc, resource: bindings, ignored listing per whitelist
Oct 21 20:59:50.132: INFO: namespace e2e-tests-projected-n2rvc deletion completed in 6.480115035s

â€¢ [SLOW TEST:9.084 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 20:59:50.132: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-hc459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hc459
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 20:59:50.432: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 21:00:08.614: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.198.173:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hc459 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:00:08.614: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:00:08.878: INFO: Found all expected endpoints: [netserver-0]
Oct 21 21:00:08.886: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.96.74:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hc459 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:00:08.886: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:00:09.129: INFO: Found all expected endpoints: [netserver-1]
Oct 21 21:00:09.136: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.204.102:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hc459 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:00:09.136: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:00:09.363: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:00:09.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hc459" for this suite.
Oct 21 21:00:33.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:00:33.468: INFO: namespace: e2e-tests-pod-network-test-hc459, resource: bindings, ignored listing per whitelist
Oct 21 21:00:33.747: INFO: namespace e2e-tests-pod-network-test-hc459 deletion completed in 24.372697905s

â€¢ [SLOW TEST:43.615 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:00:33.748: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6j4nq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-d2f2514b-f445-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 21:00:34.074: INFO: Waiting up to 5m0s for pod "pod-secrets-d2f37015-f445-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-6j4nq" to be "success or failure"
Oct 21 21:00:34.082: INFO: Pod "pod-secrets-d2f37015-f445-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.439026ms
Oct 21 21:00:36.094: INFO: Pod "pod-secrets-d2f37015-f445-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019422795s
STEP: Saw pod success
Oct 21 21:00:36.094: INFO: Pod "pod-secrets-d2f37015-f445-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:00:36.102: INFO: Trying to get logs from node 10.170.151.145 pod pod-secrets-d2f37015-f445-11e9-a616-8a530cf33301 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 21:00:36.143: INFO: Waiting for pod pod-secrets-d2f37015-f445-11e9-a616-8a530cf33301 to disappear
Oct 21 21:00:36.149: INFO: Pod pod-secrets-d2f37015-f445-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:00:36.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6j4nq" for this suite.
Oct 21 21:00:42.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:00:42.707: INFO: namespace: e2e-tests-secrets-6j4nq, resource: bindings, ignored listing per whitelist
Oct 21 21:00:42.730: INFO: namespace e2e-tests-secrets-6j4nq deletion completed in 6.570817637s

â€¢ [SLOW TEST:8.982 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:00:42.731: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-h89kn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-h89kn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-h89kn to expose endpoints map[]
Oct 21 21:00:43.209: INFO: Get endpoints failed (7.000147ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct 21 21:00:44.216: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-h89kn exposes endpoints map[] (1.013895225s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-h89kn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-h89kn to expose endpoints map[pod1:[100]]
Oct 21 21:00:46.269: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-h89kn exposes endpoints map[pod1:[100]] (2.039500852s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-h89kn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-h89kn to expose endpoints map[pod1:[100] pod2:[101]]
Oct 21 21:00:48.346: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-h89kn exposes endpoints map[pod2:[101] pod1:[100]] (2.066386028s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-h89kn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-h89kn to expose endpoints map[pod2:[101]]
Oct 21 21:00:49.389: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-h89kn exposes endpoints map[pod2:[101]] (1.027709661s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-h89kn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-h89kn to expose endpoints map[]
Oct 21 21:00:50.417: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-h89kn exposes endpoints map[] (1.014974116s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:00:50.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-h89kn" for this suite.
Oct 21 21:01:14.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:01:14.736: INFO: namespace: e2e-tests-services-h89kn, resource: bindings, ignored listing per whitelist
Oct 21 21:01:14.797: INFO: namespace e2e-tests-services-h89kn deletion completed in 24.293688055s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

â€¢ [SLOW TEST:32.066 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:01:14.797: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-65jzl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 21 21:01:15.143: INFO: Waiting up to 5m0s for pod "downward-api-eb6d9139-f445-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-65jzl" to be "success or failure"
Oct 21 21:01:15.159: INFO: Pod "downward-api-eb6d9139-f445-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 15.869701ms
Oct 21 21:01:17.166: INFO: Pod "downward-api-eb6d9139-f445-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023390299s
STEP: Saw pod success
Oct 21 21:01:17.166: INFO: Pod "downward-api-eb6d9139-f445-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:01:17.173: INFO: Trying to get logs from node 10.170.151.141 pod downward-api-eb6d9139-f445-11e9-a616-8a530cf33301 container dapi-container: <nil>
STEP: delete the pod
Oct 21 21:01:17.227: INFO: Waiting for pod downward-api-eb6d9139-f445-11e9-a616-8a530cf33301 to disappear
Oct 21 21:01:17.234: INFO: Pod downward-api-eb6d9139-f445-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:01:17.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-65jzl" for this suite.
Oct 21 21:01:23.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:01:23.374: INFO: namespace: e2e-tests-downward-api-65jzl, resource: bindings, ignored listing per whitelist
Oct 21 21:01:23.550: INFO: namespace e2e-tests-downward-api-65jzl deletion completed in 6.305623916s

â€¢ [SLOW TEST:8.753 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:01:23.550: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hcbnv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 21:01:23.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 version'
Oct 21 21:01:23.950: INFO: stderr: ""
Oct 21 21:01:23.950: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.12+IKS\", GitCommit:\"3ecb21a65b58680a3cdc42cb69a55fe7d6ec0c31\", GitTreeState:\"clean\", BuildDate:\"2019-10-17T10:49:17Z\", GoVersion:\"go1.11.13\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:01:23.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hcbnv" for this suite.
Oct 21 21:01:29.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:01:30.088: INFO: namespace: e2e-tests-kubectl-hcbnv, resource: bindings, ignored listing per whitelist
Oct 21 21:01:30.261: INFO: namespace e2e-tests-kubectl-hcbnv deletion completed in 6.300826915s

â€¢ [SLOW TEST:6.711 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:01:30.262: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-krnf5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct 21 21:01:30.595: INFO: Waiting up to 5m0s for pod "pod-f4a3cc0b-f445-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-krnf5" to be "success or failure"
Oct 21 21:01:30.601: INFO: Pod "pod-f4a3cc0b-f445-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.200135ms
Oct 21 21:01:32.608: INFO: Pod "pod-f4a3cc0b-f445-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013373385s
Oct 21 21:01:34.617: INFO: Pod "pod-f4a3cc0b-f445-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021906035s
STEP: Saw pod success
Oct 21 21:01:34.617: INFO: Pod "pod-f4a3cc0b-f445-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:01:34.625: INFO: Trying to get logs from node 10.170.151.145 pod pod-f4a3cc0b-f445-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 21:01:34.662: INFO: Waiting for pod pod-f4a3cc0b-f445-11e9-a616-8a530cf33301 to disappear
Oct 21 21:01:34.670: INFO: Pod pod-f4a3cc0b-f445-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:01:34.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-krnf5" for this suite.
Oct 21 21:01:40.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:01:40.952: INFO: namespace: e2e-tests-emptydir-krnf5, resource: bindings, ignored listing per whitelist
Oct 21 21:01:40.976: INFO: namespace e2e-tests-emptydir-krnf5 deletion completed in 6.294501578s

â€¢ [SLOW TEST:10.714 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:01:40.977: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-dpw67
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 21:01:41.368: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:01:42.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-dpw67" for this suite.
Oct 21 21:01:48.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:01:48.552: INFO: namespace: e2e-tests-custom-resource-definition-dpw67, resource: bindings, ignored listing per whitelist
Oct 21 21:01:48.799: INFO: namespace e2e-tests-custom-resource-definition-dpw67 deletion completed in 6.318640375s

â€¢ [SLOW TEST:7.823 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:01:48.801: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-bwx6w
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ffac74c4-f445-11e9-a616-8a530cf33301
STEP: Creating secret with name s-test-opt-upd-ffac7525-f445-11e9-a616-8a530cf33301
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ffac74c4-f445-11e9-a616-8a530cf33301
STEP: Updating secret s-test-opt-upd-ffac7525-f445-11e9-a616-8a530cf33301
STEP: Creating secret with name s-test-opt-create-ffac7555-f445-11e9-a616-8a530cf33301
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:03:02.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bwx6w" for this suite.
Oct 21 21:03:26.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:03:26.334: INFO: namespace: e2e-tests-secrets-bwx6w, resource: bindings, ignored listing per whitelist
Oct 21 21:03:26.365: INFO: namespace e2e-tests-secrets-bwx6w deletion completed in 24.32938433s

â€¢ [SLOW TEST:97.564 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:03:26.366: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-c2cvs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 21:03:46.724: INFO: Container started at 2019-10-21 21:03:27 +0000 UTC, pod became ready at 2019-10-21 21:03:45 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:03:46.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c2cvs" for this suite.
Oct 21 21:04:08.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:04:08.842: INFO: namespace: e2e-tests-container-probe-c2cvs, resource: bindings, ignored listing per whitelist
Oct 21 21:04:09.028: INFO: namespace e2e-tests-container-probe-c2cvs deletion completed in 22.293645189s

â€¢ [SLOW TEST:42.662 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:04:09.028: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-n8pqd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-n8pqd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 21:04:09.340: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 21:04:29.525: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.204.106:8080/dial?request=hostName&protocol=udp&host=172.30.96.76&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-n8pqd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:04:29.525: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:04:29.761: INFO: Waiting for endpoints: map[]
Oct 21 21:04:29.769: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.204.106:8080/dial?request=hostName&protocol=udp&host=172.30.198.179&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-n8pqd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:04:29.769: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:04:29.991: INFO: Waiting for endpoints: map[]
Oct 21 21:04:29.998: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.204.106:8080/dial?request=hostName&protocol=udp&host=172.30.204.105&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-n8pqd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:04:29.998: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:04:30.245: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:04:30.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-n8pqd" for this suite.
Oct 21 21:04:54.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:04:54.751: INFO: namespace: e2e-tests-pod-network-test-n8pqd, resource: bindings, ignored listing per whitelist
Oct 21 21:04:54.788: INFO: namespace e2e-tests-pod-network-test-n8pqd deletion completed in 24.531534005s

â€¢ [SLOW TEST:45.759 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:04:54.788: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-7qwv5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct 21 21:04:59.644: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6e892c85-f446-11e9-a616-8a530cf33301"
Oct 21 21:04:59.644: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6e892c85-f446-11e9-a616-8a530cf33301" in namespace "e2e-tests-pods-7qwv5" to be "terminated due to deadline exceeded"
Oct 21 21:04:59.650: INFO: Pod "pod-update-activedeadlineseconds-6e892c85-f446-11e9-a616-8a530cf33301": Phase="Running", Reason="", readiness=true. Elapsed: 5.871678ms
Oct 21 21:05:01.657: INFO: Pod "pod-update-activedeadlineseconds-6e892c85-f446-11e9-a616-8a530cf33301": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.013169954s
Oct 21 21:05:01.657: INFO: Pod "pod-update-activedeadlineseconds-6e892c85-f446-11e9-a616-8a530cf33301" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:05:01.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7qwv5" for this suite.
Oct 21 21:05:07.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:05:07.817: INFO: namespace: e2e-tests-pods-7qwv5, resource: bindings, ignored listing per whitelist
Oct 21 21:05:08.053: INFO: namespace e2e-tests-pods-7qwv5 deletion completed in 6.386207297s

â€¢ [SLOW TEST:13.265 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:05:08.056: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6f8sm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Oct 21 21:05:10.969: INFO: Successfully updated pod "annotationupdate76745df9-f446-11e9-a616-8a530cf33301"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:05:15.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6f8sm" for this suite.
Oct 21 21:05:39.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:05:39.196: INFO: namespace: e2e-tests-downward-api-6f8sm, resource: bindings, ignored listing per whitelist
Oct 21 21:05:39.332: INFO: namespace e2e-tests-downward-api-6f8sm deletion completed in 24.30374522s

â€¢ [SLOW TEST:31.277 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:05:39.333: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fd4h8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-8914ffd4-f446-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 21:05:39.650: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89166e7c-f446-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-fd4h8" to be "success or failure"
Oct 21 21:05:39.656: INFO: Pod "pod-projected-configmaps-89166e7c-f446-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.378143ms
Oct 21 21:05:41.665: INFO: Pod "pod-projected-configmaps-89166e7c-f446-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014948988s
STEP: Saw pod success
Oct 21 21:05:41.665: INFO: Pod "pod-projected-configmaps-89166e7c-f446-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:05:41.671: INFO: Trying to get logs from node 10.170.151.156 pod pod-projected-configmaps-89166e7c-f446-11e9-a616-8a530cf33301 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 21:05:41.718: INFO: Waiting for pod pod-projected-configmaps-89166e7c-f446-11e9-a616-8a530cf33301 to disappear
Oct 21 21:05:41.725: INFO: Pod pod-projected-configmaps-89166e7c-f446-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:05:41.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fd4h8" for this suite.
Oct 21 21:05:47.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:05:47.930: INFO: namespace: e2e-tests-projected-fd4h8, resource: bindings, ignored listing per whitelist
Oct 21 21:05:48.082: INFO: namespace e2e-tests-projected-fd4h8 deletion completed in 6.345242249s

â€¢ [SLOW TEST:8.749 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:05:48.084: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-qdh9d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct 21 21:05:48.383: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-a,UID:8e4c0ee0-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32475,Generation:0,CreationTimestamp:2019-10-21 21:05:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 21:05:48.384: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-a,UID:8e4c0ee0-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32475,Generation:0,CreationTimestamp:2019-10-21 21:05:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct 21 21:05:58.405: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-a,UID:8e4c0ee0-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32492,Generation:0,CreationTimestamp:2019-10-21 21:05:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct 21 21:05:58.405: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-a,UID:8e4c0ee0-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32492,Generation:0,CreationTimestamp:2019-10-21 21:05:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct 21 21:06:08.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-a,UID:8e4c0ee0-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32509,Generation:0,CreationTimestamp:2019-10-21 21:05:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 21:06:08.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-a,UID:8e4c0ee0-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32509,Generation:0,CreationTimestamp:2019-10-21 21:05:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct 21 21:06:18.445: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-a,UID:8e4c0ee0-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32526,Generation:0,CreationTimestamp:2019-10-21 21:05:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct 21 21:06:18.445: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-a,UID:8e4c0ee0-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32526,Generation:0,CreationTimestamp:2019-10-21 21:05:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct 21 21:06:28.463: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-b,UID:a62ea410-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32542,Generation:0,CreationTimestamp:2019-10-21 21:06:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 21:06:28.463: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-b,UID:a62ea410-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32542,Generation:0,CreationTimestamp:2019-10-21 21:06:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct 21 21:06:38.483: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-b,UID:a62ea410-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32559,Generation:0,CreationTimestamp:2019-10-21 21:06:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct 21 21:06:38.484: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qdh9d,SelfLink:/api/v1/namespaces/e2e-tests-watch-qdh9d/configmaps/e2e-watch-test-configmap-b,UID:a62ea410-f446-11e9-8a4f-8adb5f5fcc88,ResourceVersion:32559,Generation:0,CreationTimestamp:2019-10-21 21:06:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:06:48.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qdh9d" for this suite.
Oct 21 21:06:54.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:06:54.678: INFO: namespace: e2e-tests-watch-qdh9d, resource: bindings, ignored listing per whitelist
Oct 21 21:06:54.909: INFO: namespace e2e-tests-watch-qdh9d deletion completed in 6.411833792s

â€¢ [SLOW TEST:66.826 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:06:54.910: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-c8hcm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct 21 21:06:55.238: INFO: Waiting up to 5m0s for pod "pod-b6238a18-f446-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-c8hcm" to be "success or failure"
Oct 21 21:06:55.245: INFO: Pod "pod-b6238a18-f446-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.572667ms
Oct 21 21:06:57.252: INFO: Pod "pod-b6238a18-f446-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013643154s
STEP: Saw pod success
Oct 21 21:06:57.252: INFO: Pod "pod-b6238a18-f446-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:06:57.258: INFO: Trying to get logs from node 10.170.151.141 pod pod-b6238a18-f446-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 21:06:57.294: INFO: Waiting for pod pod-b6238a18-f446-11e9-a616-8a530cf33301 to disappear
Oct 21 21:06:57.300: INFO: Pod pod-b6238a18-f446-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:06:57.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c8hcm" for this suite.
Oct 21 21:07:03.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:07:03.368: INFO: namespace: e2e-tests-emptydir-c8hcm, resource: bindings, ignored listing per whitelist
Oct 21 21:07:03.668: INFO: namespace e2e-tests-emptydir-c8hcm deletion completed in 6.358742639s

â€¢ [SLOW TEST:8.758 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:07:03.668: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-vn2m8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-vclv
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 21:07:04.015: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-vclv" in namespace "e2e-tests-subpath-vn2m8" to be "success or failure"
Oct 21 21:07:04.023: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.430881ms
Oct 21 21:07:06.038: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022799612s
Oct 21 21:07:08.045: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 4.030362694s
Oct 21 21:07:10.053: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 6.038443298s
Oct 21 21:07:12.060: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 8.045656222s
Oct 21 21:07:14.092: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 10.077015294s
Oct 21 21:07:16.100: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 12.085512716s
Oct 21 21:07:18.108: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 14.093028052s
Oct 21 21:07:20.117: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 16.101917723s
Oct 21 21:07:22.127: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 18.111992416s
Oct 21 21:07:24.151: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 20.135998485s
Oct 21 21:07:26.158: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Running", Reason="", readiness=false. Elapsed: 22.143175989s
Oct 21 21:07:28.166: INFO: Pod "pod-subpath-test-projected-vclv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.150997045s
STEP: Saw pod success
Oct 21 21:07:28.166: INFO: Pod "pod-subpath-test-projected-vclv" satisfied condition "success or failure"
Oct 21 21:07:28.174: INFO: Trying to get logs from node 10.170.151.145 pod pod-subpath-test-projected-vclv container test-container-subpath-projected-vclv: <nil>
STEP: delete the pod
Oct 21 21:07:28.214: INFO: Waiting for pod pod-subpath-test-projected-vclv to disappear
Oct 21 21:07:28.219: INFO: Pod pod-subpath-test-projected-vclv no longer exists
STEP: Deleting pod pod-subpath-test-projected-vclv
Oct 21 21:07:28.220: INFO: Deleting pod "pod-subpath-test-projected-vclv" in namespace "e2e-tests-subpath-vn2m8"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:07:28.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vn2m8" for this suite.
Oct 21 21:07:36.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:07:36.343: INFO: namespace: e2e-tests-subpath-vn2m8, resource: bindings, ignored listing per whitelist
Oct 21 21:07:36.567: INFO: namespace e2e-tests-subpath-vn2m8 deletion completed in 8.330398574s

â€¢ [SLOW TEST:32.899 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:07:36.568: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-kqvmd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-q9tbp
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Oct 21 21:07:46.253: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-x6mm2
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:08:04.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-kqvmd" for this suite.
Oct 21 21:08:10.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:08:10.635: INFO: namespace: e2e-tests-namespaces-kqvmd, resource: bindings, ignored listing per whitelist
Oct 21 21:08:10.759: INFO: namespace e2e-tests-namespaces-kqvmd deletion completed in 6.395469975s
STEP: Destroying namespace "e2e-tests-nsdeletetest-q9tbp" for this suite.
Oct 21 21:08:10.767: INFO: Namespace e2e-tests-nsdeletetest-q9tbp was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-x6mm2" for this suite.
Oct 21 21:08:16.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:08:17.067: INFO: namespace: e2e-tests-nsdeletetest-x6mm2, resource: bindings, ignored listing per whitelist
Oct 21 21:08:17.106: INFO: namespace e2e-tests-nsdeletetest-x6mm2 deletion completed in 6.338164629s

â€¢ [SLOW TEST:40.538 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:08:17.106: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-2qjj9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct 21 21:08:17.480: INFO: Number of nodes with available pods: 0
Oct 21 21:08:17.480: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 21:08:18.500: INFO: Number of nodes with available pods: 0
Oct 21 21:08:18.500: INFO: Node 10.170.151.141 is running more than one daemon pod
Oct 21 21:08:19.498: INFO: Number of nodes with available pods: 1
Oct 21 21:08:19.498: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:20.503: INFO: Number of nodes with available pods: 3
Oct 21 21:08:20.503: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct 21 21:08:20.556: INFO: Number of nodes with available pods: 2
Oct 21 21:08:20.556: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:21.576: INFO: Number of nodes with available pods: 2
Oct 21 21:08:21.576: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:22.575: INFO: Number of nodes with available pods: 2
Oct 21 21:08:22.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:23.576: INFO: Number of nodes with available pods: 2
Oct 21 21:08:23.576: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:24.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:24.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:25.575: INFO: Number of nodes with available pods: 2
Oct 21 21:08:25.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:26.580: INFO: Number of nodes with available pods: 2
Oct 21 21:08:26.580: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:27.586: INFO: Number of nodes with available pods: 2
Oct 21 21:08:27.586: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:28.576: INFO: Number of nodes with available pods: 2
Oct 21 21:08:28.576: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:29.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:29.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:30.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:30.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:31.575: INFO: Number of nodes with available pods: 2
Oct 21 21:08:31.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:32.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:32.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:33.575: INFO: Number of nodes with available pods: 2
Oct 21 21:08:33.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:34.575: INFO: Number of nodes with available pods: 2
Oct 21 21:08:34.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:35.579: INFO: Number of nodes with available pods: 2
Oct 21 21:08:35.579: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:36.576: INFO: Number of nodes with available pods: 2
Oct 21 21:08:36.576: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:37.578: INFO: Number of nodes with available pods: 2
Oct 21 21:08:37.578: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:38.575: INFO: Number of nodes with available pods: 2
Oct 21 21:08:38.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:39.577: INFO: Number of nodes with available pods: 2
Oct 21 21:08:39.578: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:40.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:40.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:41.580: INFO: Number of nodes with available pods: 2
Oct 21 21:08:41.580: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:42.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:42.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:43.575: INFO: Number of nodes with available pods: 2
Oct 21 21:08:43.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:44.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:44.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:45.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:45.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:46.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:46.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:47.577: INFO: Number of nodes with available pods: 2
Oct 21 21:08:47.577: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:48.577: INFO: Number of nodes with available pods: 2
Oct 21 21:08:48.577: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:49.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:49.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:50.576: INFO: Number of nodes with available pods: 2
Oct 21 21:08:50.576: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:51.576: INFO: Number of nodes with available pods: 2
Oct 21 21:08:51.576: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:52.577: INFO: Number of nodes with available pods: 2
Oct 21 21:08:52.577: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:53.576: INFO: Number of nodes with available pods: 2
Oct 21 21:08:53.577: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:54.574: INFO: Number of nodes with available pods: 2
Oct 21 21:08:54.574: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:55.575: INFO: Number of nodes with available pods: 2
Oct 21 21:08:55.575: INFO: Node 10.170.151.145 is running more than one daemon pod
Oct 21 21:08:56.579: INFO: Number of nodes with available pods: 3
Oct 21 21:08:56.580: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2qjj9, will wait for the garbage collector to delete the pods
Oct 21 21:08:56.668: INFO: Deleting DaemonSet.extensions daemon-set took: 21.424337ms
Oct 21 21:08:56.768: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.246553ms
Oct 21 21:09:37.578: INFO: Number of nodes with available pods: 0
Oct 21 21:09:37.578: INFO: Number of running nodes: 0, number of available pods: 0
Oct 21 21:09:37.586: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2qjj9/daemonsets","resourceVersion":"33114"},"items":null}

Oct 21 21:09:37.593: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2qjj9/pods","resourceVersion":"33114"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:09:37.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2qjj9" for this suite.
Oct 21 21:09:43.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:09:43.961: INFO: namespace: e2e-tests-daemonsets-2qjj9, resource: bindings, ignored listing per whitelist
Oct 21 21:09:44.174: INFO: namespace e2e-tests-daemonsets-2qjj9 deletion completed in 6.541075382s

â€¢ [SLOW TEST:87.068 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:09:44.175: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-snctg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct 21 21:09:44.612: INFO: Waiting up to 5m0s for pod "pod-1b18648f-f447-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-snctg" to be "success or failure"
Oct 21 21:09:44.620: INFO: Pod "pod-1b18648f-f447-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.915475ms
Oct 21 21:09:46.630: INFO: Pod "pod-1b18648f-f447-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018078663s
Oct 21 21:09:48.639: INFO: Pod "pod-1b18648f-f447-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026986842s
STEP: Saw pod success
Oct 21 21:09:48.639: INFO: Pod "pod-1b18648f-f447-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:09:48.646: INFO: Trying to get logs from node 10.170.151.145 pod pod-1b18648f-f447-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 21:09:48.683: INFO: Waiting for pod pod-1b18648f-f447-11e9-a616-8a530cf33301 to disappear
Oct 21 21:09:48.690: INFO: Pod pod-1b18648f-f447-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:09:48.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-snctg" for this suite.
Oct 21 21:09:54.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:09:54.844: INFO: namespace: e2e-tests-emptydir-snctg, resource: bindings, ignored listing per whitelist
Oct 21 21:09:55.021: INFO: namespace e2e-tests-emptydir-snctg deletion completed in 6.300678488s

â€¢ [SLOW TEST:10.846 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:09:55.022: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lm8hn
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-217ecde1-f447-11e9-a616-8a530cf33301
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-217ecde1-f447-11e9-a616-8a530cf33301
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:09:59.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lm8hn" for this suite.
Oct 21 21:10:13.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:10:13.691: INFO: namespace: e2e-tests-configmap-lm8hn, resource: bindings, ignored listing per whitelist
Oct 21 21:10:13.817: INFO: namespace e2e-tests-configmap-lm8hn deletion completed in 14.324075388s

â€¢ [SLOW TEST:18.795 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:10:13.818: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-8wgjd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-m4bj
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 21:10:14.207: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-m4bj" in namespace "e2e-tests-subpath-8wgjd" to be "success or failure"
Oct 21 21:10:14.213: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058209ms
Oct 21 21:10:16.220: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0133256s
Oct 21 21:10:18.229: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 4.021496352s
Oct 21 21:10:20.236: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 6.028598376s
Oct 21 21:10:22.243: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 8.035419003s
Oct 21 21:10:24.250: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 10.042592175s
Oct 21 21:10:26.257: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 12.050144198s
Oct 21 21:10:28.265: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 14.058174824s
Oct 21 21:10:30.273: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 16.066300039s
Oct 21 21:10:32.281: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 18.073421812s
Oct 21 21:10:34.288: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 20.080599424s
Oct 21 21:10:36.295: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Running", Reason="", readiness=false. Elapsed: 22.087652665s
Oct 21 21:10:38.302: INFO: Pod "pod-subpath-test-configmap-m4bj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.094990301s
STEP: Saw pod success
Oct 21 21:10:38.302: INFO: Pod "pod-subpath-test-configmap-m4bj" satisfied condition "success or failure"
Oct 21 21:10:38.308: INFO: Trying to get logs from node 10.170.151.156 pod pod-subpath-test-configmap-m4bj container test-container-subpath-configmap-m4bj: <nil>
STEP: delete the pod
Oct 21 21:10:38.347: INFO: Waiting for pod pod-subpath-test-configmap-m4bj to disappear
Oct 21 21:10:38.352: INFO: Pod pod-subpath-test-configmap-m4bj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-m4bj
Oct 21 21:10:38.352: INFO: Deleting pod "pod-subpath-test-configmap-m4bj" in namespace "e2e-tests-subpath-8wgjd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:10:38.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8wgjd" for this suite.
Oct 21 21:10:44.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:10:44.531: INFO: namespace: e2e-tests-subpath-8wgjd, resource: bindings, ignored listing per whitelist
Oct 21 21:10:44.706: INFO: namespace e2e-tests-subpath-8wgjd deletion completed in 6.337575287s

â€¢ [SLOW TEST:30.888 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:10:44.706: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-q2c5k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 21:10:45.055: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3f1ea1a4-f447-11e9-8a4f-8adb5f5fcc88", Controller:(*bool)(0xc002048d2e), BlockOwnerDeletion:(*bool)(0xc002048d2f)}}
Oct 21 21:10:45.065: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3f1b6b02-f447-11e9-8a4f-8adb5f5fcc88", Controller:(*bool)(0xc00261967e), BlockOwnerDeletion:(*bool)(0xc00261967f)}}
Oct 21 21:10:45.083: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"3f1cd794-f447-11e9-8a4f-8adb5f5fcc88", Controller:(*bool)(0xc002160ce6), BlockOwnerDeletion:(*bool)(0xc002160ce7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:10:50.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-q2c5k" for this suite.
Oct 21 21:10:56.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:10:56.409: INFO: namespace: e2e-tests-gc-q2c5k, resource: bindings, ignored listing per whitelist
Oct 21 21:10:56.434: INFO: namespace e2e-tests-gc-q2c5k deletion completed in 6.32013396s

â€¢ [SLOW TEST:11.728 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:10:56.434: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ph9lh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 21:10:56.764: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4619ae8d-f447-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-ph9lh" to be "success or failure"
Oct 21 21:10:56.771: INFO: Pod "downwardapi-volume-4619ae8d-f447-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.567317ms
Oct 21 21:10:58.782: INFO: Pod "downwardapi-volume-4619ae8d-f447-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01728233s
Oct 21 21:11:00.790: INFO: Pod "downwardapi-volume-4619ae8d-f447-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025711802s
STEP: Saw pod success
Oct 21 21:11:00.790: INFO: Pod "downwardapi-volume-4619ae8d-f447-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:11:00.797: INFO: Trying to get logs from node 10.170.151.145 pod downwardapi-volume-4619ae8d-f447-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 21:11:00.842: INFO: Waiting for pod downwardapi-volume-4619ae8d-f447-11e9-a616-8a530cf33301 to disappear
Oct 21 21:11:00.848: INFO: Pod downwardapi-volume-4619ae8d-f447-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:11:00.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ph9lh" for this suite.
Oct 21 21:11:06.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:11:07.154: INFO: namespace: e2e-tests-projected-ph9lh, resource: bindings, ignored listing per whitelist
Oct 21 21:11:07.169: INFO: namespace e2e-tests-projected-ph9lh deletion completed in 6.307132981s

â€¢ [SLOW TEST:10.736 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:11:07.173: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-6h6js
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 21 21:11:13.573: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 21:11:13.581: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 21:11:15.582: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 21:11:15.589: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 21:11:17.582: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 21:11:17.590: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 21:11:19.581: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 21:11:19.589: INFO: Pod pod-with-prestop-http-hook still exists
Oct 21 21:11:21.584: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct 21 21:11:21.592: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:11:21.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6h6js" for this suite.
Oct 21 21:11:45.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:11:45.721: INFO: namespace: e2e-tests-container-lifecycle-hook-6h6js, resource: bindings, ignored listing per whitelist
Oct 21 21:11:45.923: INFO: namespace e2e-tests-container-lifecycle-hook-6h6js deletion completed in 24.299195732s

â€¢ [SLOW TEST:38.750 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:11:45.923: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-p7ssv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Oct 21 21:11:46.263: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:11:49.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-p7ssv" for this suite.
Oct 21 21:11:55.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:11:56.233: INFO: namespace: e2e-tests-init-container-p7ssv, resource: bindings, ignored listing per whitelist
Oct 21 21:11:56.258: INFO: namespace e2e-tests-init-container-p7ssv deletion completed in 6.295313333s

â€¢ [SLOW TEST:10.335 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:11:56.260: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fjjzt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1021 21:12:02.650021      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct 21 21:12:02.650: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:12:02.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fjjzt" for this suite.
Oct 21 21:12:10.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:12:10.707: INFO: namespace: e2e-tests-gc-fjjzt, resource: bindings, ignored listing per whitelist
Oct 21 21:12:10.968: INFO: namespace e2e-tests-gc-fjjzt deletion completed in 8.309961488s

â€¢ [SLOW TEST:14.708 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:12:10.968: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-kgp6x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:12:33.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-kgp6x" for this suite.
Oct 21 21:12:39.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:12:39.821: INFO: namespace: e2e-tests-container-runtime-kgp6x, resource: bindings, ignored listing per whitelist
Oct 21 21:12:40.019: INFO: namespace e2e-tests-container-runtime-kgp6x deletion completed in 6.341713849s

â€¢ [SLOW TEST:29.051 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:12:40.019: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-rghp2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Oct 21 21:12:40.349: INFO: Waiting up to 5m0s for pod "var-expansion-83d8433a-f447-11e9-a616-8a530cf33301" in namespace "e2e-tests-var-expansion-rghp2" to be "success or failure"
Oct 21 21:12:40.357: INFO: Pod "var-expansion-83d8433a-f447-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 8.24437ms
Oct 21 21:12:42.366: INFO: Pod "var-expansion-83d8433a-f447-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016874559s
STEP: Saw pod success
Oct 21 21:12:42.366: INFO: Pod "var-expansion-83d8433a-f447-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:12:42.373: INFO: Trying to get logs from node 10.170.151.145 pod var-expansion-83d8433a-f447-11e9-a616-8a530cf33301 container dapi-container: <nil>
STEP: delete the pod
Oct 21 21:12:42.413: INFO: Waiting for pod var-expansion-83d8433a-f447-11e9-a616-8a530cf33301 to disappear
Oct 21 21:12:42.419: INFO: Pod var-expansion-83d8433a-f447-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:12:42.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rghp2" for this suite.
Oct 21 21:12:48.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:12:48.511: INFO: namespace: e2e-tests-var-expansion-rghp2, resource: bindings, ignored listing per whitelist
Oct 21 21:12:48.755: INFO: namespace e2e-tests-var-expansion-rghp2 deletion completed in 6.326151049s

â€¢ [SLOW TEST:8.736 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:12:48.756: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-9x6jv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Oct 21 21:12:53.127: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-890dc2f3-f447-11e9-a616-8a530cf33301", GenerateName:"", Namespace:"e2e-tests-pods-9x6jv", SelfLink:"/api/v1/namespaces/e2e-tests-pods-9x6jv/pods/pod-submit-remove-890dc2f3-f447-11e9-a616-8a530cf33301", UID:"89105d38-f447-11e9-8a4f-8adb5f5fcc88", ResourceVersion:"34221", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63707289169, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"74668827"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-mnfz8", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002038700), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mnfz8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001fbf718), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.170.151.145", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0018dc0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001fbf890)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001fbf8b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001fbf8b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001fbf8bc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707289169, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707289171, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707289171, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63707289169, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.170.151.145", PodIP:"172.30.198.130", StartTime:(*v1.Time)(0xc001e53920), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001e53940), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"containerd://7f0a357349608ceaecbc8263582f0b31d2909bfa1ff27b86fbcfe5f8285d34c1"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:13:01.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9x6jv" for this suite.
Oct 21 21:13:07.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:13:07.540: INFO: namespace: e2e-tests-pods-9x6jv, resource: bindings, ignored listing per whitelist
Oct 21 21:13:07.728: INFO: namespace e2e-tests-pods-9x6jv deletion completed in 6.31952144s

â€¢ [SLOW TEST:18.972 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:13:07.729: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-mswbr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-8hpp
STEP: Creating a pod to test atomic-volume-subpath
Oct 21 21:13:08.107: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8hpp" in namespace "e2e-tests-subpath-mswbr" to be "success or failure"
Oct 21 21:13:08.114: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.838509ms
Oct 21 21:13:10.122: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014660731s
Oct 21 21:13:12.130: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 4.022192593s
Oct 21 21:13:14.137: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 6.029598494s
Oct 21 21:13:16.145: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 8.037189676s
Oct 21 21:13:18.152: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 10.044830915s
Oct 21 21:13:20.160: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 12.052669376s
Oct 21 21:13:22.168: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 14.060156277s
Oct 21 21:13:24.175: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 16.067506634s
Oct 21 21:13:26.182: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 18.074970453s
Oct 21 21:13:28.190: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 20.082573863s
Oct 21 21:13:30.198: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Running", Reason="", readiness=false. Elapsed: 22.090190592s
Oct 21 21:13:32.205: INFO: Pod "pod-subpath-test-configmap-8hpp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.097845688s
STEP: Saw pod success
Oct 21 21:13:32.206: INFO: Pod "pod-subpath-test-configmap-8hpp" satisfied condition "success or failure"
Oct 21 21:13:32.212: INFO: Trying to get logs from node 10.170.151.141 pod pod-subpath-test-configmap-8hpp container test-container-subpath-configmap-8hpp: <nil>
STEP: delete the pod
Oct 21 21:13:32.255: INFO: Waiting for pod pod-subpath-test-configmap-8hpp to disappear
Oct 21 21:13:32.261: INFO: Pod pod-subpath-test-configmap-8hpp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8hpp
Oct 21 21:13:32.261: INFO: Deleting pod "pod-subpath-test-configmap-8hpp" in namespace "e2e-tests-subpath-mswbr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:13:32.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mswbr" for this suite.
Oct 21 21:13:38.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:13:38.473: INFO: namespace: e2e-tests-subpath-mswbr, resource: bindings, ignored listing per whitelist
Oct 21 21:13:38.584: INFO: namespace e2e-tests-subpath-mswbr deletion completed in 6.307717076s

â€¢ [SLOW TEST:30.855 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:13:38.585: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-84znw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-84znw
Oct 21 21:13:42.931: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-84znw
STEP: checking the pod's current state and verifying that restartCount is present
Oct 21 21:13:42.938: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:17:44.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-84znw" for this suite.
Oct 21 21:17:50.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:17:50.095: INFO: namespace: e2e-tests-container-probe-84znw, resource: bindings, ignored listing per whitelist
Oct 21 21:17:50.316: INFO: namespace e2e-tests-container-probe-84znw deletion completed in 6.299648451s

â€¢ [SLOW TEST:251.731 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:17:50.316: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-r6wnz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 21 21:17:54.731: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:17:54.738: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:17:56.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:17:56.746: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:17:58.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:17:58.746: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:00.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:00.746: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:02.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:02.746: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:04.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:04.745: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:06.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:06.746: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:08.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:08.745: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:10.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:10.746: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:12.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:12.746: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:14.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:14.747: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:16.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:16.747: INFO: Pod pod-with-poststart-exec-hook still exists
Oct 21 21:18:18.738: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct 21 21:18:18.745: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:18:18.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-r6wnz" for this suite.
Oct 21 21:18:42.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:18:43.310: INFO: namespace: e2e-tests-container-lifecycle-hook-r6wnz, resource: bindings, ignored listing per whitelist
Oct 21 21:18:43.310: INFO: namespace e2e-tests-container-lifecycle-hook-r6wnz deletion completed in 24.553582236s

â€¢ [SLOW TEST:52.994 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:18:43.310: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-sxmbh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 21:18:43.681: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5c682b0d-f448-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-sxmbh" to be "success or failure"
Oct 21 21:18:43.692: INFO: Pod "downwardapi-volume-5c682b0d-f448-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 10.721466ms
Oct 21 21:18:45.700: INFO: Pod "downwardapi-volume-5c682b0d-f448-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018838503s
Oct 21 21:18:47.708: INFO: Pod "downwardapi-volume-5c682b0d-f448-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027180811s
STEP: Saw pod success
Oct 21 21:18:47.708: INFO: Pod "downwardapi-volume-5c682b0d-f448-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:18:47.715: INFO: Trying to get logs from node 10.170.151.145 pod downwardapi-volume-5c682b0d-f448-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 21:18:47.756: INFO: Waiting for pod downwardapi-volume-5c682b0d-f448-11e9-a616-8a530cf33301 to disappear
Oct 21 21:18:47.762: INFO: Pod downwardapi-volume-5c682b0d-f448-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:18:47.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sxmbh" for this suite.
Oct 21 21:18:53.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:18:53.862: INFO: namespace: e2e-tests-downward-api-sxmbh, resource: bindings, ignored listing per whitelist
Oct 21 21:18:54.098: INFO: namespace e2e-tests-downward-api-sxmbh deletion completed in 6.325285936s

â€¢ [SLOW TEST:10.788 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:18:54.099: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qwkrf
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-62d163fd-f448-11e9-a616-8a530cf33301
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-62d163fd-f448-11e9-a616-8a530cf33301
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:18:58.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qwkrf" for this suite.
Oct 21 21:19:22.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:19:22.751: INFO: namespace: e2e-tests-projected-qwkrf, resource: bindings, ignored listing per whitelist
Oct 21 21:19:22.911: INFO: namespace e2e-tests-projected-qwkrf deletion completed in 24.361192804s

â€¢ [SLOW TEST:28.813 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:19:22.911: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gqqxt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Oct 21 21:19:23.210: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-571745635 proxy --unix-socket=/tmp/kubectl-proxy-unix308120934/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:19:23.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gqqxt" for this suite.
Oct 21 21:19:29.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:19:29.586: INFO: namespace: e2e-tests-kubectl-gqqxt, resource: bindings, ignored listing per whitelist
Oct 21 21:19:29.594: INFO: namespace e2e-tests-kubectl-gqqxt deletion completed in 6.2920571s

â€¢ [SLOW TEST:6.682 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:19:29.594: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-k7kv2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Oct 21 21:19:29.898: INFO: Waiting up to 5m0s for pod "downward-api-77f42e53-f448-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-k7kv2" to be "success or failure"
Oct 21 21:19:29.904: INFO: Pod "downward-api-77f42e53-f448-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 5.859266ms
Oct 21 21:19:31.911: INFO: Pod "downward-api-77f42e53-f448-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013145611s
STEP: Saw pod success
Oct 21 21:19:31.911: INFO: Pod "downward-api-77f42e53-f448-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:19:31.918: INFO: Trying to get logs from node 10.170.151.141 pod downward-api-77f42e53-f448-11e9-a616-8a530cf33301 container dapi-container: <nil>
STEP: delete the pod
Oct 21 21:19:31.957: INFO: Waiting for pod downward-api-77f42e53-f448-11e9-a616-8a530cf33301 to disappear
Oct 21 21:19:31.963: INFO: Pod downward-api-77f42e53-f448-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:19:31.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k7kv2" for this suite.
Oct 21 21:19:38.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:19:38.791: INFO: namespace: e2e-tests-downward-api-k7kv2, resource: bindings, ignored listing per whitelist
Oct 21 21:19:38.863: INFO: namespace e2e-tests-downward-api-k7kv2 deletion completed in 6.890781353s

â€¢ [SLOW TEST:9.270 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:19:38.864: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-kqpq4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Oct 21 21:19:39.175: INFO: Waiting up to 5m0s for pod "var-expansion-7d7bdc6e-f448-11e9-a616-8a530cf33301" in namespace "e2e-tests-var-expansion-kqpq4" to be "success or failure"
Oct 21 21:19:39.184: INFO: Pod "var-expansion-7d7bdc6e-f448-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 9.325047ms
Oct 21 21:19:41.191: INFO: Pod "var-expansion-7d7bdc6e-f448-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016658596s
STEP: Saw pod success
Oct 21 21:19:41.191: INFO: Pod "var-expansion-7d7bdc6e-f448-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:19:41.198: INFO: Trying to get logs from node 10.170.151.156 pod var-expansion-7d7bdc6e-f448-11e9-a616-8a530cf33301 container dapi-container: <nil>
STEP: delete the pod
Oct 21 21:19:41.238: INFO: Waiting for pod var-expansion-7d7bdc6e-f448-11e9-a616-8a530cf33301 to disappear
Oct 21 21:19:41.243: INFO: Pod var-expansion-7d7bdc6e-f448-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:19:41.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kqpq4" for this suite.
Oct 21 21:19:47.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:19:47.761: INFO: namespace: e2e-tests-var-expansion-kqpq4, resource: bindings, ignored listing per whitelist
Oct 21 21:19:47.791: INFO: namespace e2e-tests-var-expansion-kqpq4 deletion completed in 6.533924469s

â€¢ [SLOW TEST:8.927 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:19:47.792: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-fnj6w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Oct 21 21:19:48.175: INFO: Waiting up to 5m0s for pod "client-containers-82d8e2ff-f448-11e9-a616-8a530cf33301" in namespace "e2e-tests-containers-fnj6w" to be "success or failure"
Oct 21 21:19:48.184: INFO: Pod "client-containers-82d8e2ff-f448-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 9.284666ms
Oct 21 21:19:50.195: INFO: Pod "client-containers-82d8e2ff-f448-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020128423s
STEP: Saw pod success
Oct 21 21:19:50.195: INFO: Pod "client-containers-82d8e2ff-f448-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:19:50.202: INFO: Trying to get logs from node 10.170.151.141 pod client-containers-82d8e2ff-f448-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 21:19:50.238: INFO: Waiting for pod client-containers-82d8e2ff-f448-11e9-a616-8a530cf33301 to disappear
Oct 21 21:19:50.244: INFO: Pod client-containers-82d8e2ff-f448-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:19:50.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fnj6w" for this suite.
Oct 21 21:19:56.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:19:56.457: INFO: namespace: e2e-tests-containers-fnj6w, resource: bindings, ignored listing per whitelist
Oct 21 21:19:56.609: INFO: namespace e2e-tests-containers-fnj6w deletion completed in 6.351906493s

â€¢ [SLOW TEST:8.818 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:19:56.610: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-cm8tl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8810dafd-f448-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 21:19:56.939: INFO: Waiting up to 5m0s for pod "pod-configmaps-88129bf6-f448-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-cm8tl" to be "success or failure"
Oct 21 21:19:56.946: INFO: Pod "pod-configmaps-88129bf6-f448-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380972ms
Oct 21 21:19:58.965: INFO: Pod "pod-configmaps-88129bf6-f448-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0253472s
STEP: Saw pod success
Oct 21 21:19:58.965: INFO: Pod "pod-configmaps-88129bf6-f448-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:19:58.971: INFO: Trying to get logs from node 10.170.151.141 pod pod-configmaps-88129bf6-f448-11e9-a616-8a530cf33301 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 21:19:59.007: INFO: Waiting for pod pod-configmaps-88129bf6-f448-11e9-a616-8a530cf33301 to disappear
Oct 21 21:19:59.013: INFO: Pod pod-configmaps-88129bf6-f448-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:19:59.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cm8tl" for this suite.
Oct 21 21:20:05.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:20:05.076: INFO: namespace: e2e-tests-configmap-cm8tl, resource: bindings, ignored listing per whitelist
Oct 21 21:20:05.317: INFO: namespace e2e-tests-configmap-cm8tl deletion completed in 6.294781965s

â€¢ [SLOW TEST:8.707 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:20:05.318: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-gqhjj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct 21 21:20:09.679: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:09.686: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:11.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:11.695: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:13.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:13.694: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:15.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:15.695: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:17.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:17.694: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:19.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:19.694: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:21.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:21.694: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:23.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:23.695: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:25.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:25.695: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:27.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:27.696: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:29.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:29.694: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:31.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:31.694: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:33.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:33.695: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:35.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:35.695: INFO: Pod pod-with-prestop-exec-hook still exists
Oct 21 21:20:37.687: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct 21 21:20:37.696: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:20:37.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gqhjj" for this suite.
Oct 21 21:21:01.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:21:01.971: INFO: namespace: e2e-tests-container-lifecycle-hook-gqhjj, resource: bindings, ignored listing per whitelist
Oct 21 21:21:02.023: INFO: namespace e2e-tests-container-lifecycle-hook-gqhjj deletion completed in 24.30017981s

â€¢ [SLOW TEST:56.705 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:21:02.027: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-9lf2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9lf2p
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Oct 21 21:21:02.365: INFO: Found 0 stateful pods, waiting for 3
Oct 21 21:21:12.375: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 21:21:12.375: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 21:21:12.375: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Oct 21 21:21:12.503: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct 21 21:21:22.556: INFO: Updating stateful set ss2
Oct 21 21:21:22.569: INFO: Waiting for Pod e2e-tests-statefulset-9lf2p/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Oct 21 21:21:32.635: INFO: Found 1 stateful pods, waiting for 3
Oct 21 21:21:42.643: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 21:21:42.643: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 21:21:42.643: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct 21 21:21:42.683: INFO: Updating stateful set ss2
Oct 21 21:21:42.696: INFO: Waiting for Pod e2e-tests-statefulset-9lf2p/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Oct 21 21:21:52.738: INFO: Updating stateful set ss2
Oct 21 21:21:52.751: INFO: Waiting for StatefulSet e2e-tests-statefulset-9lf2p/ss2 to complete update
Oct 21 21:21:52.751: INFO: Waiting for Pod e2e-tests-statefulset-9lf2p/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 21:22:02.766: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9lf2p
Oct 21 21:22:02.772: INFO: Scaling statefulset ss2 to 0
Oct 21 21:22:22.802: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 21:22:22.814: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:22:22.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9lf2p" for this suite.
Oct 21 21:22:28.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:22:28.923: INFO: namespace: e2e-tests-statefulset-9lf2p, resource: bindings, ignored listing per whitelist
Oct 21 21:22:29.177: INFO: namespace e2e-tests-statefulset-9lf2p deletion completed in 6.322746498s

â€¢ [SLOW TEST:87.150 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:22:29.179: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-n8jpg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e300fa1d-f448-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 21:22:29.506: INFO: Waiting up to 5m0s for pod "pod-configmaps-e302899f-f448-11e9-a616-8a530cf33301" in namespace "e2e-tests-configmap-n8jpg" to be "success or failure"
Oct 21 21:22:29.512: INFO: Pod "pod-configmaps-e302899f-f448-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040589ms
Oct 21 21:22:31.520: INFO: Pod "pod-configmaps-e302899f-f448-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013740544s
STEP: Saw pod success
Oct 21 21:22:31.520: INFO: Pod "pod-configmaps-e302899f-f448-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:22:31.526: INFO: Trying to get logs from node 10.170.151.145 pod pod-configmaps-e302899f-f448-11e9-a616-8a530cf33301 container configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 21:22:31.563: INFO: Waiting for pod pod-configmaps-e302899f-f448-11e9-a616-8a530cf33301 to disappear
Oct 21 21:22:31.569: INFO: Pod pod-configmaps-e302899f-f448-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:22:31.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n8jpg" for this suite.
Oct 21 21:22:37.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:22:37.742: INFO: namespace: e2e-tests-configmap-n8jpg, resource: bindings, ignored listing per whitelist
Oct 21 21:22:37.884: INFO: namespace e2e-tests-configmap-n8jpg deletion completed in 6.304719176s

â€¢ [SLOW TEST:8.705 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:22:37.885: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-tg5zd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tg5zd
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-tg5zd
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-tg5zd
Oct 21 21:22:38.190: INFO: Found 0 stateful pods, waiting for 1
Oct 21 21:22:48.198: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct 21 21:22:48.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 21:22:48.602: INFO: stderr: ""
Oct 21 21:22:48.602: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 21:22:48.602: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 21:22:48.610: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct 21 21:22:58.618: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 21:22:58.618: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 21:22:58.646: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999809s
Oct 21 21:22:59.653: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993572939s
Oct 21 21:23:00.661: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.985726207s
Oct 21 21:23:01.669: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.978630986s
Oct 21 21:23:02.677: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.969798657s
Oct 21 21:23:03.684: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.96188111s
Oct 21 21:23:04.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.954947319s
Oct 21 21:23:05.699: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.947462262s
Oct 21 21:23:06.707: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.939956073s
Oct 21 21:23:07.714: INFO: Verifying statefulset ss doesn't scale past 1 for another 932.498871ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-tg5zd
Oct 21 21:23:08.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:23:09.090: INFO: stderr: ""
Oct 21 21:23:09.090: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 21:23:09.090: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 21:23:09.098: INFO: Found 1 stateful pods, waiting for 3
Oct 21 21:23:19.106: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 21:23:19.106: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct 21 21:23:19.106: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct 21 21:23:19.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 21:23:19.461: INFO: stderr: ""
Oct 21 21:23:19.461: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 21:23:19.461: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 21:23:19.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 21:23:19.805: INFO: stderr: ""
Oct 21 21:23:19.805: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 21:23:19.805: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 21:23:19.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Oct 21 21:23:20.187: INFO: stderr: ""
Oct 21 21:23:20.187: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Oct 21 21:23:20.187: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Oct 21 21:23:20.187: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 21:23:20.195: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Oct 21 21:23:30.210: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 21:23:30.210: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 21:23:30.210: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct 21 21:23:30.235: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999997984s
Oct 21 21:23:31.243: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99047286s
Oct 21 21:23:32.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982678978s
Oct 21 21:23:33.261: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.971822987s
Oct 21 21:23:34.269: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963963453s
Oct 21 21:23:35.277: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.956623892s
Oct 21 21:23:36.286: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.94771311s
Oct 21 21:23:37.294: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.93892009s
Oct 21 21:23:38.302: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.93126489s
Oct 21 21:23:39.310: INFO: Verifying statefulset ss doesn't scale past 3 for another 923.178744ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-tg5zd
Oct 21 21:23:40.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:23:40.712: INFO: stderr: ""
Oct 21 21:23:40.712: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 21:23:40.712: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 21:23:40.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:23:41.124: INFO: stderr: ""
Oct 21 21:23:41.124: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Oct 21 21:23:41.124: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Oct 21 21:23:41.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:23:41.343: INFO: rc: 1
Oct 21 21:23:41.343: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0020366f0 exit status 1 <nil> <nil> true [0xc000a06528 0xc000a06540 0xc000a06558] [0xc000a06528 0xc000a06540 0xc000a06558] [0xc000a06538 0xc000a06550] [0x92f8e0 0x92f8e0] 0xc00230f980 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Oct 21 21:23:51.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:23:51.479: INFO: rc: 1
Oct 21 21:23:51.479: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013a6cf0 exit status 1 <nil> <nil> true [0xc000a8fcc8 0xc001236aa8 0xc001236ac0] [0xc000a8fcc8 0xc001236aa8 0xc001236ac0] [0xc001236aa0 0xc001236ab8] [0x92f8e0 0x92f8e0] 0xc002400c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:24:01.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:24:01.607: INFO: rc: 1
Oct 21 21:24:01.607: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f0600 exit status 1 <nil> <nil> true [0xc00000e890 0xc00000eb40 0xc00000ebe8] [0xc00000e890 0xc00000eb40 0xc00000ebe8] [0xc00000eac8 0xc00000eb98] [0x92f8e0 0x92f8e0] 0xc0021b2240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:24:11.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:24:11.726: INFO: rc: 1
Oct 21 21:24:11.726: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020dc600 exit status 1 <nil> <nil> true [0xc0000ca028 0xc0000ca088 0xc0000ca0e8] [0xc0000ca028 0xc0000ca088 0xc0000ca0e8] [0xc0000ca080 0xc0000ca0b8] [0x92f8e0 0x92f8e0] 0xc001dee240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:24:21.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:24:21.850: INFO: rc: 1
Oct 21 21:24:21.850: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017d43c0 exit status 1 <nil> <nil> true [0xc000368098 0xc000368fa0 0xc000369218] [0xc000368098 0xc000368fa0 0xc000369218] [0xc0003687a8 0xc000369168] [0x92f8e0 0x92f8e0] 0xc0020542a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:24:31.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:24:31.966: INFO: rc: 1
Oct 21 21:24:31.966: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f09f0 exit status 1 <nil> <nil> true [0xc00000ec68 0xc00000ed60 0xc00000ee18] [0xc00000ec68 0xc00000ed60 0xc00000ee18] [0xc00000ecd0 0xc00000edf8] [0x92f8e0 0x92f8e0] 0xc0021b2540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:24:41.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:24:42.073: INFO: rc: 1
Oct 21 21:24:42.073: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002454720 exit status 1 <nil> <nil> true [0xc000437c10 0xc000437df0 0xc000437ed0] [0xc000437c10 0xc000437df0 0xc000437ed0] [0xc000437de0 0xc000437ea0] [0x92f8e0 0x92f8e0] 0xc0009b69c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:24:52.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:24:52.205: INFO: rc: 1
Oct 21 21:24:52.205: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f0de0 exit status 1 <nil> <nil> true [0xc00000ee30 0xc00000eef8 0xc00000efc8] [0xc00000ee30 0xc00000eef8 0xc00000efc8] [0xc00000eef0 0xc00000ef90] [0x92f8e0 0x92f8e0] 0xc0021b28a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:25:02.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:25:02.333: INFO: rc: 1
Oct 21 21:25:02.333: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002454c30 exit status 1 <nil> <nil> true [0xc000437ef0 0xc000437f68 0xc000437fc8] [0xc000437ef0 0xc000437f68 0xc000437fc8] [0xc000437f08 0xc000437fb8] [0x92f8e0 0x92f8e0] 0xc0009b70e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:25:12.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:25:12.457: INFO: rc: 1
Oct 21 21:25:12.457: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001ca8420 exit status 1 <nil> <nil> true [0xc000437fd0 0xc000a06008 0xc000a06020] [0xc000437fd0 0xc000a06008 0xc000a06020] [0xc000a06000 0xc000a06018] [0x92f8e0 0x92f8e0] 0xc0009b7620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:25:22.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:25:22.586: INFO: rc: 1
Oct 21 21:25:22.587: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001ca8a50 exit status 1 <nil> <nil> true [0xc000a06028 0xc000a06040 0xc000a06058] [0xc000a06028 0xc000a06040 0xc000a06058] [0xc000a06038 0xc000a06050] [0x92f8e0 0x92f8e0] 0xc0009b7a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:25:32.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:25:32.712: INFO: rc: 1
Oct 21 21:25:32.712: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020dca50 exit status 1 <nil> <nil> true [0xc0000ca0f0 0xc0000ca168 0xc0000ca220] [0xc0000ca0f0 0xc0000ca168 0xc0000ca220] [0xc0000ca130 0xc0000ca1b0] [0x92f8e0 0x92f8e0] 0xc001dee5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:25:42.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:25:42.838: INFO: rc: 1
Oct 21 21:25:42.838: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020dce40 exit status 1 <nil> <nil> true [0xc0000ca230 0xc0000ca290 0xc0000ca2c8] [0xc0000ca230 0xc0000ca290 0xc0000ca2c8] [0xc0000ca260 0xc0000ca2b8] [0x92f8e0 0x92f8e0] 0xc001dee900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:25:52.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:25:52.971: INFO: rc: 1
Oct 21 21:25:52.971: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017d4420 exit status 1 <nil> <nil> true [0xc0000ca3b8 0xc0000ca510 0xc0000ca5c0] [0xc0000ca3b8 0xc0000ca510 0xc0000ca5c0] [0xc0000ca4e0 0xc0000ca5a8] [0x92f8e0 0x92f8e0] 0xc002054360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:26:02.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:26:03.094: INFO: rc: 1
Oct 21 21:26:03.094: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002454750 exit status 1 <nil> <nil> true [0xc000437d70 0xc000437e28 0xc000437ef0] [0xc000437d70 0xc000437e28 0xc000437ef0] [0xc000437df0 0xc000437ed0] [0x92f8e0 0x92f8e0] 0xc0009b69c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:26:13.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:26:13.209: INFO: rc: 1
Oct 21 21:26:13.209: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001ca8ab0 exit status 1 <nil> <nil> true [0xc000a06000 0xc000a06018 0xc000a06030] [0xc000a06000 0xc000a06018 0xc000a06030] [0xc000a06010 0xc000a06028] [0x92f8e0 0x92f8e0] 0xc001dee240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:26:23.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:26:23.346: INFO: rc: 1
Oct 21 21:26:23.347: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002454cf0 exit status 1 <nil> <nil> true [0xc000437ef8 0xc000437fb0 0xc000437fd0] [0xc000437ef8 0xc000437fb0 0xc000437fd0] [0xc000437f68 0xc000437fc8] [0x92f8e0 0x92f8e0] 0xc0009b70e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:26:33.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:26:33.459: INFO: rc: 1
Oct 21 21:26:33.459: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020dc630 exit status 1 <nil> <nil> true [0xc0000ca028 0xc0000ca088 0xc0000ca0e8] [0xc0000ca028 0xc0000ca088 0xc0000ca0e8] [0xc0000ca080 0xc0000ca0b8] [0x92f8e0 0x92f8e0] 0xc0020542a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:26:43.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:26:43.595: INFO: rc: 1
Oct 21 21:26:43.595: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001ca8f90 exit status 1 <nil> <nil> true [0xc000a06038 0xc000a06050 0xc000a06068] [0xc000a06038 0xc000a06050 0xc000a06068] [0xc000a06048 0xc000a06060] [0x92f8e0 0x92f8e0] 0xc001dee5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:26:53.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:26:53.727: INFO: rc: 1
Oct 21 21:26:53.727: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017d40c0 exit status 1 <nil> <nil> true [0xc000437ff0 0xc0003687a8 0xc000369168] [0xc000437ff0 0xc0003687a8 0xc000369168] [0xc0003682f8 0xc000369120] [0x92f8e0 0x92f8e0] 0xc0009b7620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:27:03.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:27:03.842: INFO: rc: 1
Oct 21 21:27:03.843: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017d4510 exit status 1 <nil> <nil> true [0xc000369218 0xc0003694d0 0xc000369698] [0xc000369218 0xc0003694d0 0xc000369698] [0xc000369308 0xc0003695b0] [0x92f8e0 0x92f8e0] 0xc0009b7a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:27:13.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:27:13.981: INFO: rc: 1
Oct 21 21:27:13.981: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020dca20 exit status 1 <nil> <nil> true [0xc0000ca0f0 0xc0000ca168 0xc0000ca220] [0xc0000ca0f0 0xc0000ca168 0xc0000ca220] [0xc0000ca130 0xc0000ca1b0] [0x92f8e0 0x92f8e0] 0xc002054660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:27:23.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:27:24.115: INFO: rc: 1
Oct 21 21:27:24.115: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017d4ae0 exit status 1 <nil> <nil> true [0xc000369710 0xc000369930 0xc000369978] [0xc000369710 0xc000369930 0xc000369978] [0xc0003698b8 0xc000369970] [0x92f8e0 0x92f8e0] 0xc0021b2000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:27:34.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:27:34.249: INFO: rc: 1
Oct 21 21:27:34.249: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f0630 exit status 1 <nil> <nil> true [0xc00000e6f8 0xc00000eac8 0xc00000eb98] [0xc00000e6f8 0xc00000eac8 0xc00000eb98] [0xc00000e8c8 0xc00000eb80] [0x92f8e0 0x92f8e0] 0xc001e1ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:27:44.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:27:44.388: INFO: rc: 1
Oct 21 21:27:44.388: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f0a20 exit status 1 <nil> <nil> true [0xc00000ebe8 0xc00000ecd0 0xc00000edf8] [0xc00000ebe8 0xc00000ecd0 0xc00000edf8] [0xc00000eca0 0xc00000edb0] [0x92f8e0 0x92f8e0] 0xc001e1f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:27:54.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:27:54.524: INFO: rc: 1
Oct 21 21:27:54.524: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017d4f60 exit status 1 <nil> <nil> true [0xc000369a30 0xc000369aa0 0xc000369b40] [0xc000369a30 0xc000369aa0 0xc000369b40] [0xc000369a98 0xc000369b18] [0x92f8e0 0x92f8e0] 0xc0021b2300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:28:04.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:28:04.648: INFO: rc: 1
Oct 21 21:28:04.648: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f0600 exit status 1 <nil> <nil> true [0xc000437c10 0xc000437df0 0xc000437ed0] [0xc000437c10 0xc000437df0 0xc000437ed0] [0xc000437de0 0xc000437ea0] [0x92f8e0 0x92f8e0] 0xc0009b69c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:28:14.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:28:14.772: INFO: rc: 1
Oct 21 21:28:14.772: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f0a50 exit status 1 <nil> <nil> true [0xc000437ef0 0xc000437f68 0xc000437fc8] [0xc000437ef0 0xc000437f68 0xc000437fc8] [0xc000437f08 0xc000437fb8] [0x92f8e0 0x92f8e0] 0xc0009b70e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:28:24.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:28:24.897: INFO: rc: 1
Oct 21 21:28:24.897: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002454780 exit status 1 <nil> <nil> true [0xc00000e6f8 0xc00000eac8 0xc00000eb98] [0xc00000e6f8 0xc00000eac8 0xc00000eb98] [0xc00000e8c8 0xc00000eb80] [0x92f8e0 0x92f8e0] 0xc001e1ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:28:34.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:28:35.026: INFO: rc: 1
Oct 21 21:28:35.026: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002454cc0 exit status 1 <nil> <nil> true [0xc00000ebe8 0xc00000ecd0 0xc00000edf8] [0xc00000ebe8 0xc00000ecd0 0xc00000edf8] [0xc00000eca0 0xc00000edb0] [0x92f8e0 0x92f8e0] 0xc001e1f3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Oct 21 21:28:45.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 exec --namespace=e2e-tests-statefulset-tg5zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Oct 21 21:28:45.147: INFO: rc: 1
Oct 21 21:28:45.147: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Oct 21 21:28:45.147: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Oct 21 21:28:45.170: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tg5zd
Oct 21 21:28:45.176: INFO: Scaling statefulset ss to 0
Oct 21 21:28:45.196: INFO: Waiting for statefulset status.replicas updated to 0
Oct 21 21:28:45.203: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:28:45.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tg5zd" for this suite.
Oct 21 21:28:51.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:28:51.366: INFO: namespace: e2e-tests-statefulset-tg5zd, resource: bindings, ignored listing per whitelist
Oct 21 21:28:51.563: INFO: namespace e2e-tests-statefulset-tg5zd deletion completed in 6.316010979s

â€¢ [SLOW TEST:373.678 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:28:51.564: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-zf79l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-c6ed0c00-f449-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 21:28:51.896: INFO: Waiting up to 5m0s for pod "pod-secrets-c6ee4e09-f449-11e9-a616-8a530cf33301" in namespace "e2e-tests-secrets-zf79l" to be "success or failure"
Oct 21 21:28:51.902: INFO: Pod "pod-secrets-c6ee4e09-f449-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 5.99868ms
Oct 21 21:28:53.910: INFO: Pod "pod-secrets-c6ee4e09-f449-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01392659s
STEP: Saw pod success
Oct 21 21:28:53.910: INFO: Pod "pod-secrets-c6ee4e09-f449-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:28:53.916: INFO: Trying to get logs from node 10.170.151.141 pod pod-secrets-c6ee4e09-f449-11e9-a616-8a530cf33301 container secret-volume-test: <nil>
STEP: delete the pod
Oct 21 21:28:53.954: INFO: Waiting for pod pod-secrets-c6ee4e09-f449-11e9-a616-8a530cf33301 to disappear
Oct 21 21:28:53.960: INFO: Pod pod-secrets-c6ee4e09-f449-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:28:53.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zf79l" for this suite.
Oct 21 21:29:00.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:29:00.040: INFO: namespace: e2e-tests-secrets-zf79l, resource: bindings, ignored listing per whitelist
Oct 21 21:29:00.252: INFO: namespace e2e-tests-secrets-zf79l deletion completed in 6.282312075s

â€¢ [SLOW TEST:8.688 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:29:00.253: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-gz64n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 21:29:00.550: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc16df8e-f449-11e9-a616-8a530cf33301" in namespace "e2e-tests-downward-api-gz64n" to be "success or failure"
Oct 21 21:29:00.557: INFO: Pod "downwardapi-volume-cc16df8e-f449-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.629003ms
Oct 21 21:29:02.564: INFO: Pod "downwardapi-volume-cc16df8e-f449-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013681672s
STEP: Saw pod success
Oct 21 21:29:02.564: INFO: Pod "downwardapi-volume-cc16df8e-f449-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:29:02.570: INFO: Trying to get logs from node 10.170.151.156 pod downwardapi-volume-cc16df8e-f449-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 21:29:02.613: INFO: Waiting for pod downwardapi-volume-cc16df8e-f449-11e9-a616-8a530cf33301 to disappear
Oct 21 21:29:02.619: INFO: Pod downwardapi-volume-cc16df8e-f449-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:29:02.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gz64n" for this suite.
Oct 21 21:29:08.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:29:08.694: INFO: namespace: e2e-tests-downward-api-gz64n, resource: bindings, ignored listing per whitelist
Oct 21 21:29:08.927: INFO: namespace e2e-tests-downward-api-gz64n deletion completed in 6.298031539s

â€¢ [SLOW TEST:8.674 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:29:08.928: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8qsj4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Oct 21 21:29:09.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-8qsj4'
Oct 21 21:29:09.561: INFO: stderr: ""
Oct 21 21:29:09.561: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Oct 21 21:29:09.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-571745635 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8qsj4'
Oct 21 21:29:21.388: INFO: stderr: ""
Oct 21 21:29:21.388: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:29:21.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8qsj4" for this suite.
Oct 21 21:29:27.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:29:27.533: INFO: namespace: e2e-tests-kubectl-8qsj4, resource: bindings, ignored listing per whitelist
Oct 21 21:29:27.707: INFO: namespace e2e-tests-kubectl-8qsj4 deletion completed in 6.307577533s

â€¢ [SLOW TEST:18.779 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:29:27.707: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-2hk5l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct 21 21:29:28.026: INFO: Waiting up to 5m0s for pod "pod-dc773e94-f449-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-2hk5l" to be "success or failure"
Oct 21 21:29:28.035: INFO: Pod "pod-dc773e94-f449-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 8.287141ms
Oct 21 21:29:30.042: INFO: Pod "pod-dc773e94-f449-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015823114s
STEP: Saw pod success
Oct 21 21:29:30.042: INFO: Pod "pod-dc773e94-f449-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:29:30.049: INFO: Trying to get logs from node 10.170.151.141 pod pod-dc773e94-f449-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 21:29:30.082: INFO: Waiting for pod pod-dc773e94-f449-11e9-a616-8a530cf33301 to disappear
Oct 21 21:29:30.089: INFO: Pod pod-dc773e94-f449-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:29:30.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2hk5l" for this suite.
Oct 21 21:29:36.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:29:36.229: INFO: namespace: e2e-tests-emptydir-2hk5l, resource: bindings, ignored listing per whitelist
Oct 21 21:29:36.386: INFO: namespace e2e-tests-emptydir-2hk5l deletion completed in 6.285280414s

â€¢ [SLOW TEST:8.680 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:29:36.387: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-p8ggn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Oct 21 21:29:36.704: INFO: (0) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.852889ms)
Oct 21 21:29:36.719: INFO: (1) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.889404ms)
Oct 21 21:29:36.731: INFO: (2) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.095096ms)
Oct 21 21:29:36.742: INFO: (3) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.512454ms)
Oct 21 21:29:36.752: INFO: (4) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.504748ms)
Oct 21 21:29:36.763: INFO: (5) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.598723ms)
Oct 21 21:29:36.774: INFO: (6) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.998457ms)
Oct 21 21:29:36.784: INFO: (7) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.36745ms)
Oct 21 21:29:36.795: INFO: (8) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.70373ms)
Oct 21 21:29:36.806: INFO: (9) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.863808ms)
Oct 21 21:29:36.817: INFO: (10) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.720538ms)
Oct 21 21:29:36.828: INFO: (11) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.715317ms)
Oct 21 21:29:36.838: INFO: (12) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.405459ms)
Oct 21 21:29:36.849: INFO: (13) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.646612ms)
Oct 21 21:29:36.860: INFO: (14) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.85044ms)
Oct 21 21:29:36.871: INFO: (15) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.887269ms)
Oct 21 21:29:36.883: INFO: (16) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.62943ms)
Oct 21 21:29:36.894: INFO: (17) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.836405ms)
Oct 21 21:29:36.906: INFO: (18) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.443243ms)
Oct 21 21:29:36.916: INFO: (19) /api/v1/nodes/10.170.151.141:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 10.411054ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:29:36.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-p8ggn" for this suite.
Oct 21 21:29:42.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:29:43.159: INFO: namespace: e2e-tests-proxy-p8ggn, resource: bindings, ignored listing per whitelist
Oct 21 21:29:43.314: INFO: namespace e2e-tests-proxy-p8ggn deletion completed in 6.389139896s

â€¢ [SLOW TEST:6.927 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:29:43.315: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-twmpn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e5c5f13a-f449-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume configMaps
Oct 21 21:29:43.658: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e5c79a0c-f449-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-twmpn" to be "success or failure"
Oct 21 21:29:43.665: INFO: Pod "pod-projected-configmaps-e5c79a0c-f449-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 7.090018ms
Oct 21 21:29:45.672: INFO: Pod "pod-projected-configmaps-e5c79a0c-f449-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014038087s
STEP: Saw pod success
Oct 21 21:29:45.672: INFO: Pod "pod-projected-configmaps-e5c79a0c-f449-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:29:45.678: INFO: Trying to get logs from node 10.170.151.156 pod pod-projected-configmaps-e5c79a0c-f449-11e9-a616-8a530cf33301 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct 21 21:29:45.716: INFO: Waiting for pod pod-projected-configmaps-e5c79a0c-f449-11e9-a616-8a530cf33301 to disappear
Oct 21 21:29:45.723: INFO: Pod pod-projected-configmaps-e5c79a0c-f449-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:29:45.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-twmpn" for this suite.
Oct 21 21:29:51.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:29:51.856: INFO: namespace: e2e-tests-projected-twmpn, resource: bindings, ignored listing per whitelist
Oct 21 21:29:52.023: INFO: namespace e2e-tests-projected-twmpn deletion completed in 6.290141282s

â€¢ [SLOW TEST:8.708 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:29:52.024: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mn466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Oct 21 21:29:52.330: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eaf3ba34-f449-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-mn466" to be "success or failure"
Oct 21 21:29:52.336: INFO: Pod "downwardapi-volume-eaf3ba34-f449-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.561073ms
Oct 21 21:29:54.345: INFO: Pod "downwardapi-volume-eaf3ba34-f449-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01554964s
STEP: Saw pod success
Oct 21 21:29:54.345: INFO: Pod "downwardapi-volume-eaf3ba34-f449-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:29:54.352: INFO: Trying to get logs from node 10.170.151.145 pod downwardapi-volume-eaf3ba34-f449-11e9-a616-8a530cf33301 container client-container: <nil>
STEP: delete the pod
Oct 21 21:29:54.391: INFO: Waiting for pod downwardapi-volume-eaf3ba34-f449-11e9-a616-8a530cf33301 to disappear
Oct 21 21:29:54.396: INFO: Pod downwardapi-volume-eaf3ba34-f449-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:29:54.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mn466" for this suite.
Oct 21 21:30:00.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:30:00.523: INFO: namespace: e2e-tests-projected-mn466, resource: bindings, ignored listing per whitelist
Oct 21 21:30:00.710: INFO: namespace e2e-tests-projected-mn466 deletion completed in 6.301948179s

â€¢ [SLOW TEST:8.686 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:30:00.710: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-79mnj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct 21 21:30:07.131: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 21:30:07.138: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 21:30:09.138: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 21:30:09.146: INFO: Pod pod-with-poststart-http-hook still exists
Oct 21 21:30:11.138: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct 21 21:30:11.146: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:30:11.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-79mnj" for this suite.
Oct 21 21:30:35.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:30:35.326: INFO: namespace: e2e-tests-container-lifecycle-hook-79mnj, resource: bindings, ignored listing per whitelist
Oct 21 21:30:35.450: INFO: namespace e2e-tests-container-lifecycle-hook-79mnj deletion completed in 24.293127288s

â€¢ [SLOW TEST:34.739 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:30:35.450: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-fsmkh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:30:37.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-fsmkh" for this suite.
Oct 21 21:30:43.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:30:44.121: INFO: namespace: e2e-tests-emptydir-wrapper-fsmkh, resource: bindings, ignored listing per whitelist
Oct 21 21:30:44.285: INFO: namespace e2e-tests-emptydir-wrapper-fsmkh deletion completed in 6.416821446s

â€¢ [SLOW TEST:8.836 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:30:44.286: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-rcbfm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-rcbfm
I1021 21:30:44.580553      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-rcbfm, replica count: 1
I1021 21:30:45.631125      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1021 21:30:46.631340      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct 21 21:30:46.757: INFO: Created: latency-svc-c7cnm
Oct 21 21:30:46.776: INFO: Got endpoints: latency-svc-c7cnm [44.623499ms]
Oct 21 21:30:46.797: INFO: Created: latency-svc-zxj2l
Oct 21 21:30:46.804: INFO: Got endpoints: latency-svc-zxj2l [27.456193ms]
Oct 21 21:30:46.808: INFO: Created: latency-svc-cc5vj
Oct 21 21:30:46.814: INFO: Got endpoints: latency-svc-cc5vj [38.025911ms]
Oct 21 21:30:46.823: INFO: Created: latency-svc-ff94v
Oct 21 21:30:46.827: INFO: Got endpoints: latency-svc-ff94v [50.289543ms]
Oct 21 21:30:46.838: INFO: Created: latency-svc-sxzkl
Oct 21 21:30:46.843: INFO: Got endpoints: latency-svc-sxzkl [66.708551ms]
Oct 21 21:30:46.851: INFO: Created: latency-svc-h82lp
Oct 21 21:30:46.855: INFO: Got endpoints: latency-svc-h82lp [78.513544ms]
Oct 21 21:30:46.865: INFO: Created: latency-svc-zfmsj
Oct 21 21:30:46.871: INFO: Got endpoints: latency-svc-zfmsj [93.669201ms]
Oct 21 21:30:46.877: INFO: Created: latency-svc-848vb
Oct 21 21:30:46.882: INFO: Got endpoints: latency-svc-848vb [105.229455ms]
Oct 21 21:30:46.888: INFO: Created: latency-svc-gmsxj
Oct 21 21:30:46.893: INFO: Got endpoints: latency-svc-gmsxj [116.857261ms]
Oct 21 21:30:46.899: INFO: Created: latency-svc-mbd59
Oct 21 21:30:46.904: INFO: Got endpoints: latency-svc-mbd59 [126.926884ms]
Oct 21 21:30:46.910: INFO: Created: latency-svc-c22vw
Oct 21 21:30:46.916: INFO: Got endpoints: latency-svc-c22vw [138.651202ms]
Oct 21 21:30:46.922: INFO: Created: latency-svc-hvct2
Oct 21 21:30:46.927: INFO: Got endpoints: latency-svc-hvct2 [150.293844ms]
Oct 21 21:30:46.935: INFO: Created: latency-svc-d4ztt
Oct 21 21:30:46.941: INFO: Got endpoints: latency-svc-d4ztt [163.577835ms]
Oct 21 21:30:46.947: INFO: Created: latency-svc-84hdp
Oct 21 21:30:46.952: INFO: Got endpoints: latency-svc-84hdp [174.629542ms]
Oct 21 21:30:46.958: INFO: Created: latency-svc-h7kk7
Oct 21 21:30:46.964: INFO: Got endpoints: latency-svc-h7kk7 [187.026191ms]
Oct 21 21:30:46.971: INFO: Created: latency-svc-hdm2s
Oct 21 21:30:46.976: INFO: Got endpoints: latency-svc-hdm2s [198.624162ms]
Oct 21 21:30:46.982: INFO: Created: latency-svc-cqm4m
Oct 21 21:30:46.987: INFO: Got endpoints: latency-svc-cqm4m [183.773361ms]
Oct 21 21:30:46.993: INFO: Created: latency-svc-d87d9
Oct 21 21:30:46.998: INFO: Got endpoints: latency-svc-d87d9 [184.521167ms]
Oct 21 21:30:47.006: INFO: Created: latency-svc-bdjd6
Oct 21 21:30:47.011: INFO: Got endpoints: latency-svc-bdjd6 [184.603256ms]
Oct 21 21:30:47.017: INFO: Created: latency-svc-bhfvz
Oct 21 21:30:47.022: INFO: Got endpoints: latency-svc-bhfvz [179.246085ms]
Oct 21 21:30:47.028: INFO: Created: latency-svc-tw2rb
Oct 21 21:30:47.033: INFO: Got endpoints: latency-svc-tw2rb [177.601019ms]
Oct 21 21:30:47.041: INFO: Created: latency-svc-8qndv
Oct 21 21:30:47.047: INFO: Got endpoints: latency-svc-8qndv [176.716533ms]
Oct 21 21:30:47.054: INFO: Created: latency-svc-s8m7v
Oct 21 21:30:47.059: INFO: Got endpoints: latency-svc-s8m7v [177.075654ms]
Oct 21 21:30:47.069: INFO: Created: latency-svc-6jj67
Oct 21 21:30:47.074: INFO: Got endpoints: latency-svc-6jj67 [180.739565ms]
Oct 21 21:30:47.081: INFO: Created: latency-svc-f9lt7
Oct 21 21:30:47.086: INFO: Got endpoints: latency-svc-f9lt7 [182.147366ms]
Oct 21 21:30:47.099: INFO: Created: latency-svc-h2v7x
Oct 21 21:30:47.103: INFO: Got endpoints: latency-svc-h2v7x [187.3139ms]
Oct 21 21:30:47.110: INFO: Created: latency-svc-d977m
Oct 21 21:30:47.116: INFO: Got endpoints: latency-svc-d977m [188.227091ms]
Oct 21 21:30:47.122: INFO: Created: latency-svc-cfbg7
Oct 21 21:30:47.127: INFO: Got endpoints: latency-svc-cfbg7 [185.633255ms]
Oct 21 21:30:47.133: INFO: Created: latency-svc-m5n5c
Oct 21 21:30:47.140: INFO: Got endpoints: latency-svc-m5n5c [188.164451ms]
Oct 21 21:30:47.146: INFO: Created: latency-svc-9sjcm
Oct 21 21:30:47.152: INFO: Got endpoints: latency-svc-9sjcm [187.877829ms]
Oct 21 21:30:47.157: INFO: Created: latency-svc-5947k
Oct 21 21:30:47.164: INFO: Got endpoints: latency-svc-5947k [187.668324ms]
Oct 21 21:30:47.171: INFO: Created: latency-svc-7h887
Oct 21 21:30:47.176: INFO: Got endpoints: latency-svc-7h887 [188.67168ms]
Oct 21 21:30:47.182: INFO: Created: latency-svc-5k92s
Oct 21 21:30:47.188: INFO: Got endpoints: latency-svc-5k92s [189.357179ms]
Oct 21 21:30:47.194: INFO: Created: latency-svc-szwl9
Oct 21 21:30:47.199: INFO: Got endpoints: latency-svc-szwl9 [187.905403ms]
Oct 21 21:30:47.206: INFO: Created: latency-svc-tf27t
Oct 21 21:30:47.213: INFO: Got endpoints: latency-svc-tf27t [190.149514ms]
Oct 21 21:30:47.218: INFO: Created: latency-svc-kkhsd
Oct 21 21:30:47.224: INFO: Got endpoints: latency-svc-kkhsd [190.737413ms]
Oct 21 21:30:47.231: INFO: Created: latency-svc-hdvjn
Oct 21 21:30:47.237: INFO: Got endpoints: latency-svc-hdvjn [189.812838ms]
Oct 21 21:30:47.244: INFO: Created: latency-svc-2q6h5
Oct 21 21:30:47.250: INFO: Got endpoints: latency-svc-2q6h5 [190.485353ms]
Oct 21 21:30:47.259: INFO: Created: latency-svc-7p9rd
Oct 21 21:30:47.264: INFO: Got endpoints: latency-svc-7p9rd [190.048213ms]
Oct 21 21:30:47.272: INFO: Created: latency-svc-g5qvx
Oct 21 21:30:47.278: INFO: Got endpoints: latency-svc-g5qvx [27.953246ms]
Oct 21 21:30:47.284: INFO: Created: latency-svc-zwn2h
Oct 21 21:30:47.295: INFO: Created: latency-svc-stn4m
Oct 21 21:30:47.306: INFO: Created: latency-svc-48n4l
Oct 21 21:30:47.312: INFO: Got endpoints: latency-svc-zwn2h [225.592919ms]
Oct 21 21:30:47.318: INFO: Created: latency-svc-9ldc2
Oct 21 21:30:47.332: INFO: Created: latency-svc-mq6rm
Oct 21 21:30:47.345: INFO: Created: latency-svc-gm72f
Oct 21 21:30:47.357: INFO: Created: latency-svc-dhmbk
Oct 21 21:30:47.362: INFO: Got endpoints: latency-svc-stn4m [259.11266ms]
Oct 21 21:30:47.369: INFO: Created: latency-svc-6mc5p
Oct 21 21:30:47.388: INFO: Created: latency-svc-tzf6t
Oct 21 21:30:47.398: INFO: Created: latency-svc-hq7qn
Oct 21 21:30:47.410: INFO: Created: latency-svc-9cgjj
Oct 21 21:30:47.412: INFO: Got endpoints: latency-svc-48n4l [296.461788ms]
Oct 21 21:30:47.422: INFO: Created: latency-svc-6wb5x
Oct 21 21:30:47.434: INFO: Created: latency-svc-pcwkv
Oct 21 21:30:47.445: INFO: Created: latency-svc-ntzfd
Oct 21 21:30:47.459: INFO: Created: latency-svc-jwd2x
Oct 21 21:30:47.462: INFO: Got endpoints: latency-svc-9ldc2 [335.05364ms]
Oct 21 21:30:47.470: INFO: Created: latency-svc-ctwf8
Oct 21 21:30:47.480: INFO: Created: latency-svc-l6m2z
Oct 21 21:30:47.494: INFO: Created: latency-svc-k5kp5
Oct 21 21:30:47.504: INFO: Created: latency-svc-rxnr9
Oct 21 21:30:47.512: INFO: Got endpoints: latency-svc-mq6rm [371.906107ms]
Oct 21 21:30:47.531: INFO: Created: latency-svc-dhl9n
Oct 21 21:30:47.562: INFO: Got endpoints: latency-svc-gm72f [409.906619ms]
Oct 21 21:30:47.582: INFO: Created: latency-svc-dsbtv
Oct 21 21:30:47.614: INFO: Got endpoints: latency-svc-dhmbk [449.964983ms]
Oct 21 21:30:47.635: INFO: Created: latency-svc-zmzcp
Oct 21 21:30:47.667: INFO: Got endpoints: latency-svc-6mc5p [490.881625ms]
Oct 21 21:30:47.688: INFO: Created: latency-svc-lgrh6
Oct 21 21:30:47.713: INFO: Got endpoints: latency-svc-tzf6t [525.174492ms]
Oct 21 21:30:47.734: INFO: Created: latency-svc-fffdx
Oct 21 21:30:47.763: INFO: Got endpoints: latency-svc-hq7qn [563.243395ms]
Oct 21 21:30:47.786: INFO: Created: latency-svc-kfpr8
Oct 21 21:30:47.817: INFO: Got endpoints: latency-svc-9cgjj [604.461957ms]
Oct 21 21:30:47.839: INFO: Created: latency-svc-cc9gx
Oct 21 21:30:47.863: INFO: Got endpoints: latency-svc-6wb5x [638.697686ms]
Oct 21 21:30:47.884: INFO: Created: latency-svc-2fk7r
Oct 21 21:30:47.912: INFO: Got endpoints: latency-svc-pcwkv [675.046078ms]
Oct 21 21:30:47.934: INFO: Created: latency-svc-txzmk
Oct 21 21:30:47.963: INFO: Got endpoints: latency-svc-ntzfd [698.962993ms]
Oct 21 21:30:47.984: INFO: Created: latency-svc-nvls2
Oct 21 21:30:48.033: INFO: Got endpoints: latency-svc-jwd2x [755.630792ms]
Oct 21 21:30:48.059: INFO: Created: latency-svc-v7t6w
Oct 21 21:30:48.062: INFO: Got endpoints: latency-svc-ctwf8 [750.099558ms]
Oct 21 21:30:48.083: INFO: Created: latency-svc-srhbr
Oct 21 21:30:48.113: INFO: Got endpoints: latency-svc-l6m2z [750.390651ms]
Oct 21 21:30:48.137: INFO: Created: latency-svc-2ffrz
Oct 21 21:30:48.163: INFO: Got endpoints: latency-svc-k5kp5 [750.733805ms]
Oct 21 21:30:48.184: INFO: Created: latency-svc-s9845
Oct 21 21:30:48.213: INFO: Got endpoints: latency-svc-rxnr9 [751.410147ms]
Oct 21 21:30:48.239: INFO: Created: latency-svc-sfjhw
Oct 21 21:30:48.263: INFO: Got endpoints: latency-svc-dhl9n [751.321228ms]
Oct 21 21:30:48.284: INFO: Created: latency-svc-x4lwj
Oct 21 21:30:48.313: INFO: Got endpoints: latency-svc-dsbtv [750.811443ms]
Oct 21 21:30:48.335: INFO: Created: latency-svc-xndbb
Oct 21 21:30:48.363: INFO: Got endpoints: latency-svc-zmzcp [749.415852ms]
Oct 21 21:30:48.400: INFO: Created: latency-svc-wmhch
Oct 21 21:30:48.413: INFO: Got endpoints: latency-svc-lgrh6 [745.357952ms]
Oct 21 21:30:48.436: INFO: Created: latency-svc-768xg
Oct 21 21:30:48.463: INFO: Got endpoints: latency-svc-fffdx [749.875816ms]
Oct 21 21:30:48.490: INFO: Created: latency-svc-z5kpv
Oct 21 21:30:48.514: INFO: Got endpoints: latency-svc-kfpr8 [750.790576ms]
Oct 21 21:30:48.533: INFO: Created: latency-svc-4b4k9
Oct 21 21:30:48.563: INFO: Got endpoints: latency-svc-cc9gx [745.407684ms]
Oct 21 21:30:48.583: INFO: Created: latency-svc-pzhxb
Oct 21 21:30:48.614: INFO: Got endpoints: latency-svc-2fk7r [751.431159ms]
Oct 21 21:30:48.638: INFO: Created: latency-svc-4wzd7
Oct 21 21:30:48.663: INFO: Got endpoints: latency-svc-txzmk [750.520858ms]
Oct 21 21:30:48.687: INFO: Created: latency-svc-5xcvd
Oct 21 21:30:48.713: INFO: Got endpoints: latency-svc-nvls2 [749.908809ms]
Oct 21 21:30:48.738: INFO: Created: latency-svc-qgplq
Oct 21 21:30:48.763: INFO: Got endpoints: latency-svc-v7t6w [729.758816ms]
Oct 21 21:30:48.786: INFO: Created: latency-svc-t72vf
Oct 21 21:30:48.813: INFO: Got endpoints: latency-svc-srhbr [750.708041ms]
Oct 21 21:30:48.835: INFO: Created: latency-svc-zn7g4
Oct 21 21:30:48.864: INFO: Got endpoints: latency-svc-2ffrz [751.224806ms]
Oct 21 21:30:48.885: INFO: Created: latency-svc-hfvjx
Oct 21 21:30:48.913: INFO: Got endpoints: latency-svc-s9845 [750.139506ms]
Oct 21 21:30:48.935: INFO: Created: latency-svc-ttggk
Oct 21 21:30:48.963: INFO: Got endpoints: latency-svc-sfjhw [749.28855ms]
Oct 21 21:30:48.984: INFO: Created: latency-svc-75zww
Oct 21 21:30:49.014: INFO: Got endpoints: latency-svc-x4lwj [750.229769ms]
Oct 21 21:30:49.035: INFO: Created: latency-svc-pbbsn
Oct 21 21:30:49.063: INFO: Got endpoints: latency-svc-xndbb [749.484687ms]
Oct 21 21:30:49.084: INFO: Created: latency-svc-9jbl6
Oct 21 21:30:49.113: INFO: Got endpoints: latency-svc-wmhch [749.171607ms]
Oct 21 21:30:49.134: INFO: Created: latency-svc-mztq6
Oct 21 21:30:49.164: INFO: Got endpoints: latency-svc-768xg [750.830063ms]
Oct 21 21:30:49.186: INFO: Created: latency-svc-c5nn6
Oct 21 21:30:49.213: INFO: Got endpoints: latency-svc-z5kpv [750.142043ms]
Oct 21 21:30:49.237: INFO: Created: latency-svc-g55n4
Oct 21 21:30:49.263: INFO: Got endpoints: latency-svc-4b4k9 [749.02988ms]
Oct 21 21:30:49.284: INFO: Created: latency-svc-lkmsp
Oct 21 21:30:49.316: INFO: Got endpoints: latency-svc-pzhxb [753.448138ms]
Oct 21 21:30:49.339: INFO: Created: latency-svc-q8xqm
Oct 21 21:30:49.364: INFO: Got endpoints: latency-svc-4wzd7 [749.942792ms]
Oct 21 21:30:49.384: INFO: Created: latency-svc-h4dks
Oct 21 21:30:49.414: INFO: Got endpoints: latency-svc-5xcvd [750.884844ms]
Oct 21 21:30:49.438: INFO: Created: latency-svc-tfrpw
Oct 21 21:30:49.463: INFO: Got endpoints: latency-svc-qgplq [749.629993ms]
Oct 21 21:30:49.486: INFO: Created: latency-svc-lqkx8
Oct 21 21:30:49.514: INFO: Got endpoints: latency-svc-t72vf [750.357487ms]
Oct 21 21:30:49.535: INFO: Created: latency-svc-tww7c
Oct 21 21:30:49.563: INFO: Got endpoints: latency-svc-zn7g4 [750.325628ms]
Oct 21 21:30:49.585: INFO: Created: latency-svc-g5clt
Oct 21 21:30:49.613: INFO: Got endpoints: latency-svc-hfvjx [748.600999ms]
Oct 21 21:30:49.638: INFO: Created: latency-svc-vjm6z
Oct 21 21:30:49.663: INFO: Got endpoints: latency-svc-ttggk [750.080378ms]
Oct 21 21:30:49.691: INFO: Created: latency-svc-75q7x
Oct 21 21:30:49.713: INFO: Got endpoints: latency-svc-75zww [749.803273ms]
Oct 21 21:30:49.735: INFO: Created: latency-svc-qh4lf
Oct 21 21:30:49.763: INFO: Got endpoints: latency-svc-pbbsn [749.222874ms]
Oct 21 21:30:49.785: INFO: Created: latency-svc-gdl5d
Oct 21 21:30:49.813: INFO: Got endpoints: latency-svc-9jbl6 [749.915134ms]
Oct 21 21:30:49.834: INFO: Created: latency-svc-r2fjf
Oct 21 21:30:49.863: INFO: Got endpoints: latency-svc-mztq6 [750.225237ms]
Oct 21 21:30:49.884: INFO: Created: latency-svc-vjxnn
Oct 21 21:30:49.913: INFO: Got endpoints: latency-svc-c5nn6 [749.307641ms]
Oct 21 21:30:49.936: INFO: Created: latency-svc-gvtx4
Oct 21 21:30:49.965: INFO: Got endpoints: latency-svc-g55n4 [751.476955ms]
Oct 21 21:30:49.988: INFO: Created: latency-svc-k6vgt
Oct 21 21:30:50.012: INFO: Got endpoints: latency-svc-lkmsp [749.653849ms]
Oct 21 21:30:50.042: INFO: Created: latency-svc-c9xjq
Oct 21 21:30:50.063: INFO: Got endpoints: latency-svc-q8xqm [746.452608ms]
Oct 21 21:30:50.086: INFO: Created: latency-svc-x7j44
Oct 21 21:30:50.115: INFO: Got endpoints: latency-svc-h4dks [750.8915ms]
Oct 21 21:30:50.138: INFO: Created: latency-svc-8jvjc
Oct 21 21:30:50.167: INFO: Got endpoints: latency-svc-tfrpw [752.644197ms]
Oct 21 21:30:50.190: INFO: Created: latency-svc-tvgl7
Oct 21 21:30:50.214: INFO: Got endpoints: latency-svc-lqkx8 [750.961781ms]
Oct 21 21:30:50.240: INFO: Created: latency-svc-blgjt
Oct 21 21:30:50.264: INFO: Got endpoints: latency-svc-tww7c [749.931092ms]
Oct 21 21:30:50.286: INFO: Created: latency-svc-947k7
Oct 21 21:30:50.313: INFO: Got endpoints: latency-svc-g5clt [749.382837ms]
Oct 21 21:30:50.334: INFO: Created: latency-svc-lt7qp
Oct 21 21:30:50.363: INFO: Got endpoints: latency-svc-vjm6z [749.737135ms]
Oct 21 21:30:50.384: INFO: Created: latency-svc-lmdq4
Oct 21 21:30:50.413: INFO: Got endpoints: latency-svc-75q7x [749.79104ms]
Oct 21 21:30:50.439: INFO: Created: latency-svc-5km75
Oct 21 21:30:50.462: INFO: Got endpoints: latency-svc-qh4lf [749.789303ms]
Oct 21 21:30:50.486: INFO: Created: latency-svc-lc87g
Oct 21 21:30:50.513: INFO: Got endpoints: latency-svc-gdl5d [749.363337ms]
Oct 21 21:30:50.533: INFO: Created: latency-svc-hvjzs
Oct 21 21:30:50.563: INFO: Got endpoints: latency-svc-r2fjf [750.6933ms]
Oct 21 21:30:50.584: INFO: Created: latency-svc-tf7wk
Oct 21 21:30:50.614: INFO: Got endpoints: latency-svc-vjxnn [751.09744ms]
Oct 21 21:30:50.635: INFO: Created: latency-svc-k2vh8
Oct 21 21:30:50.663: INFO: Got endpoints: latency-svc-gvtx4 [749.911838ms]
Oct 21 21:30:50.683: INFO: Created: latency-svc-65wwr
Oct 21 21:30:50.713: INFO: Got endpoints: latency-svc-k6vgt [747.986003ms]
Oct 21 21:30:50.733: INFO: Created: latency-svc-hr484
Oct 21 21:30:50.763: INFO: Got endpoints: latency-svc-c9xjq [750.481093ms]
Oct 21 21:30:50.789: INFO: Created: latency-svc-v7gqh
Oct 21 21:30:50.813: INFO: Got endpoints: latency-svc-x7j44 [750.248867ms]
Oct 21 21:30:50.833: INFO: Created: latency-svc-8lv8t
Oct 21 21:30:50.864: INFO: Got endpoints: latency-svc-8jvjc [748.512391ms]
Oct 21 21:30:50.892: INFO: Created: latency-svc-nsrx8
Oct 21 21:30:50.913: INFO: Got endpoints: latency-svc-tvgl7 [745.917817ms]
Oct 21 21:30:50.973: INFO: Got endpoints: latency-svc-blgjt [758.366952ms]
Oct 21 21:30:50.976: INFO: Created: latency-svc-p2l2v
Oct 21 21:30:50.995: INFO: Created: latency-svc-tx8gj
Oct 21 21:30:51.014: INFO: Got endpoints: latency-svc-947k7 [750.263164ms]
Oct 21 21:30:51.042: INFO: Created: latency-svc-zcq5w
Oct 21 21:30:51.062: INFO: Got endpoints: latency-svc-lt7qp [749.395097ms]
Oct 21 21:30:51.083: INFO: Created: latency-svc-8l2v7
Oct 21 21:30:51.113: INFO: Got endpoints: latency-svc-lmdq4 [749.987434ms]
Oct 21 21:30:51.134: INFO: Created: latency-svc-br9qf
Oct 21 21:30:51.163: INFO: Got endpoints: latency-svc-5km75 [749.56519ms]
Oct 21 21:30:51.192: INFO: Created: latency-svc-8d64c
Oct 21 21:30:51.213: INFO: Got endpoints: latency-svc-lc87g [750.943498ms]
Oct 21 21:30:51.263: INFO: Got endpoints: latency-svc-hvjzs [750.236802ms]
Oct 21 21:30:51.295: INFO: Created: latency-svc-9zg2k
Oct 21 21:30:51.310: INFO: Created: latency-svc-pt588
Oct 21 21:30:51.313: INFO: Got endpoints: latency-svc-tf7wk [749.160979ms]
Oct 21 21:30:51.335: INFO: Created: latency-svc-zh9l2
Oct 21 21:30:51.365: INFO: Got endpoints: latency-svc-k2vh8 [751.003438ms]
Oct 21 21:30:51.385: INFO: Created: latency-svc-xhv7v
Oct 21 21:30:51.414: INFO: Got endpoints: latency-svc-65wwr [750.526499ms]
Oct 21 21:30:51.438: INFO: Created: latency-svc-hxwrw
Oct 21 21:30:51.463: INFO: Got endpoints: latency-svc-hr484 [750.387054ms]
Oct 21 21:30:51.483: INFO: Created: latency-svc-wckht
Oct 21 21:30:51.513: INFO: Got endpoints: latency-svc-v7gqh [749.675456ms]
Oct 21 21:30:51.536: INFO: Created: latency-svc-4wz7m
Oct 21 21:30:51.567: INFO: Got endpoints: latency-svc-8lv8t [753.464445ms]
Oct 21 21:30:51.589: INFO: Created: latency-svc-kgzxv
Oct 21 21:30:51.614: INFO: Got endpoints: latency-svc-nsrx8 [750.127918ms]
Oct 21 21:30:51.636: INFO: Created: latency-svc-lrvmv
Oct 21 21:30:51.668: INFO: Got endpoints: latency-svc-p2l2v [754.990257ms]
Oct 21 21:30:51.689: INFO: Created: latency-svc-89g2v
Oct 21 21:30:51.713: INFO: Got endpoints: latency-svc-tx8gj [740.250626ms]
Oct 21 21:30:51.734: INFO: Created: latency-svc-s6ldf
Oct 21 21:30:51.765: INFO: Got endpoints: latency-svc-zcq5w [750.522745ms]
Oct 21 21:30:51.788: INFO: Created: latency-svc-cllxw
Oct 21 21:30:51.817: INFO: Got endpoints: latency-svc-8l2v7 [754.347196ms]
Oct 21 21:30:51.837: INFO: Created: latency-svc-rjrmb
Oct 21 21:30:51.863: INFO: Got endpoints: latency-svc-br9qf [750.610139ms]
Oct 21 21:30:51.885: INFO: Created: latency-svc-gx4d6
Oct 21 21:30:51.913: INFO: Got endpoints: latency-svc-8d64c [750.461201ms]
Oct 21 21:30:51.934: INFO: Created: latency-svc-r95dw
Oct 21 21:30:51.964: INFO: Got endpoints: latency-svc-9zg2k [700.882214ms]
Oct 21 21:30:51.985: INFO: Created: latency-svc-mkhm4
Oct 21 21:30:52.013: INFO: Got endpoints: latency-svc-pt588 [799.169191ms]
Oct 21 21:30:52.034: INFO: Created: latency-svc-q6qbw
Oct 21 21:30:52.063: INFO: Got endpoints: latency-svc-zh9l2 [750.460596ms]
Oct 21 21:30:52.102: INFO: Created: latency-svc-hftwj
Oct 21 21:30:52.113: INFO: Got endpoints: latency-svc-xhv7v [748.123678ms]
Oct 21 21:30:52.137: INFO: Created: latency-svc-666fh
Oct 21 21:30:52.163: INFO: Got endpoints: latency-svc-hxwrw [749.547229ms]
Oct 21 21:30:52.184: INFO: Created: latency-svc-lh79s
Oct 21 21:30:52.214: INFO: Got endpoints: latency-svc-wckht [750.505103ms]
Oct 21 21:30:52.235: INFO: Created: latency-svc-zr7xv
Oct 21 21:30:52.263: INFO: Got endpoints: latency-svc-4wz7m [750.22453ms]
Oct 21 21:30:52.370: INFO: Got endpoints: latency-svc-lrvmv [755.62578ms]
Oct 21 21:30:52.371: INFO: Got endpoints: latency-svc-kgzxv [803.984003ms]
Oct 21 21:30:52.374: INFO: Created: latency-svc-h5xzt
Oct 21 21:30:52.393: INFO: Created: latency-svc-bw86j
Oct 21 21:30:52.404: INFO: Created: latency-svc-45cvd
Oct 21 21:30:52.412: INFO: Got endpoints: latency-svc-89g2v [744.33384ms]
Oct 21 21:30:52.470: INFO: Got endpoints: latency-svc-s6ldf [757.15238ms]
Oct 21 21:30:52.474: INFO: Created: latency-svc-zmrf9
Oct 21 21:30:52.494: INFO: Created: latency-svc-2fpq9
Oct 21 21:30:52.513: INFO: Got endpoints: latency-svc-cllxw [748.561719ms]
Oct 21 21:30:52.534: INFO: Created: latency-svc-xltc5
Oct 21 21:30:52.564: INFO: Got endpoints: latency-svc-rjrmb [747.710974ms]
Oct 21 21:30:52.584: INFO: Created: latency-svc-76r2h
Oct 21 21:30:52.613: INFO: Got endpoints: latency-svc-gx4d6 [749.446354ms]
Oct 21 21:30:52.635: INFO: Created: latency-svc-hzxwn
Oct 21 21:30:52.664: INFO: Got endpoints: latency-svc-r95dw [750.35159ms]
Oct 21 21:30:52.685: INFO: Created: latency-svc-s2gdh
Oct 21 21:30:52.713: INFO: Got endpoints: latency-svc-mkhm4 [749.33268ms]
Oct 21 21:30:52.736: INFO: Created: latency-svc-tqt7b
Oct 21 21:30:52.763: INFO: Got endpoints: latency-svc-q6qbw [750.304517ms]
Oct 21 21:30:52.786: INFO: Created: latency-svc-bvnrw
Oct 21 21:30:52.813: INFO: Got endpoints: latency-svc-hftwj [749.509184ms]
Oct 21 21:30:52.841: INFO: Created: latency-svc-7tqw2
Oct 21 21:30:52.863: INFO: Got endpoints: latency-svc-666fh [749.992022ms]
Oct 21 21:30:52.889: INFO: Created: latency-svc-5xnb9
Oct 21 21:30:52.913: INFO: Got endpoints: latency-svc-lh79s [749.718722ms]
Oct 21 21:30:52.935: INFO: Created: latency-svc-lxbmb
Oct 21 21:30:52.964: INFO: Got endpoints: latency-svc-zr7xv [749.869634ms]
Oct 21 21:30:52.985: INFO: Created: latency-svc-bv6ts
Oct 21 21:30:53.014: INFO: Got endpoints: latency-svc-h5xzt [751.004954ms]
Oct 21 21:30:53.037: INFO: Created: latency-svc-6qnqr
Oct 21 21:30:53.064: INFO: Got endpoints: latency-svc-bw86j [693.73698ms]
Oct 21 21:30:53.092: INFO: Created: latency-svc-4gwvp
Oct 21 21:30:53.114: INFO: Got endpoints: latency-svc-45cvd [742.99881ms]
Oct 21 21:30:53.134: INFO: Created: latency-svc-bhgzk
Oct 21 21:30:53.163: INFO: Got endpoints: latency-svc-zmrf9 [751.120078ms]
Oct 21 21:30:53.185: INFO: Created: latency-svc-8s8lm
Oct 21 21:30:53.212: INFO: Got endpoints: latency-svc-2fpq9 [742.166311ms]
Oct 21 21:30:53.234: INFO: Created: latency-svc-5tsdj
Oct 21 21:30:53.263: INFO: Got endpoints: latency-svc-xltc5 [750.083228ms]
Oct 21 21:30:53.284: INFO: Created: latency-svc-wl6nl
Oct 21 21:30:53.313: INFO: Got endpoints: latency-svc-76r2h [748.783346ms]
Oct 21 21:30:53.336: INFO: Created: latency-svc-b65td
Oct 21 21:30:53.363: INFO: Got endpoints: latency-svc-hzxwn [749.876067ms]
Oct 21 21:30:53.383: INFO: Created: latency-svc-4m4lq
Oct 21 21:30:53.414: INFO: Got endpoints: latency-svc-s2gdh [749.898661ms]
Oct 21 21:30:53.434: INFO: Created: latency-svc-9nmxc
Oct 21 21:30:53.463: INFO: Got endpoints: latency-svc-tqt7b [749.745697ms]
Oct 21 21:30:53.484: INFO: Created: latency-svc-dw9ht
Oct 21 21:30:53.512: INFO: Got endpoints: latency-svc-bvnrw [749.296778ms]
Oct 21 21:30:53.535: INFO: Created: latency-svc-mhp95
Oct 21 21:30:53.564: INFO: Got endpoints: latency-svc-7tqw2 [751.274884ms]
Oct 21 21:30:53.592: INFO: Created: latency-svc-58pzb
Oct 21 21:30:53.613: INFO: Got endpoints: latency-svc-5xnb9 [749.349788ms]
Oct 21 21:30:53.634: INFO: Created: latency-svc-gqw2q
Oct 21 21:30:53.663: INFO: Got endpoints: latency-svc-lxbmb [749.6276ms]
Oct 21 21:30:53.684: INFO: Created: latency-svc-4hql7
Oct 21 21:30:53.713: INFO: Got endpoints: latency-svc-bv6ts [749.16185ms]
Oct 21 21:30:53.733: INFO: Created: latency-svc-rwnws
Oct 21 21:30:53.765: INFO: Got endpoints: latency-svc-6qnqr [750.853775ms]
Oct 21 21:30:53.791: INFO: Created: latency-svc-pfbgh
Oct 21 21:30:53.813: INFO: Got endpoints: latency-svc-4gwvp [748.846646ms]
Oct 21 21:30:53.833: INFO: Created: latency-svc-2kxlk
Oct 21 21:30:53.863: INFO: Got endpoints: latency-svc-bhgzk [748.876669ms]
Oct 21 21:30:53.884: INFO: Created: latency-svc-rzksh
Oct 21 21:30:53.913: INFO: Got endpoints: latency-svc-8s8lm [749.11939ms]
Oct 21 21:30:53.934: INFO: Created: latency-svc-kv7tl
Oct 21 21:30:53.963: INFO: Got endpoints: latency-svc-5tsdj [750.160228ms]
Oct 21 21:30:53.984: INFO: Created: latency-svc-bsb6q
Oct 21 21:30:54.026: INFO: Got endpoints: latency-svc-wl6nl [762.790334ms]
Oct 21 21:30:54.048: INFO: Created: latency-svc-pgsk4
Oct 21 21:30:54.063: INFO: Got endpoints: latency-svc-b65td [749.905313ms]
Oct 21 21:30:54.085: INFO: Created: latency-svc-p472r
Oct 21 21:30:54.113: INFO: Got endpoints: latency-svc-4m4lq [750.592152ms]
Oct 21 21:30:54.138: INFO: Created: latency-svc-hd7n9
Oct 21 21:30:54.163: INFO: Got endpoints: latency-svc-9nmxc [749.04834ms]
Oct 21 21:30:54.183: INFO: Created: latency-svc-5rbjb
Oct 21 21:30:54.213: INFO: Got endpoints: latency-svc-dw9ht [750.490196ms]
Oct 21 21:30:54.234: INFO: Created: latency-svc-t9ns5
Oct 21 21:30:54.263: INFO: Got endpoints: latency-svc-mhp95 [750.54425ms]
Oct 21 21:30:54.285: INFO: Created: latency-svc-vfxvz
Oct 21 21:30:54.313: INFO: Got endpoints: latency-svc-58pzb [749.287335ms]
Oct 21 21:30:54.370: INFO: Got endpoints: latency-svc-gqw2q [757.165001ms]
Oct 21 21:30:54.376: INFO: Created: latency-svc-5kjb9
Oct 21 21:30:54.389: INFO: Created: latency-svc-f4dkm
Oct 21 21:30:54.413: INFO: Got endpoints: latency-svc-4hql7 [749.911463ms]
Oct 21 21:30:54.435: INFO: Created: latency-svc-925gh
Oct 21 21:30:54.463: INFO: Got endpoints: latency-svc-rwnws [750.301676ms]
Oct 21 21:30:54.486: INFO: Created: latency-svc-d8dvw
Oct 21 21:30:54.513: INFO: Got endpoints: latency-svc-pfbgh [748.252088ms]
Oct 21 21:30:54.534: INFO: Created: latency-svc-7qn7j
Oct 21 21:30:54.564: INFO: Got endpoints: latency-svc-2kxlk [751.085112ms]
Oct 21 21:30:54.584: INFO: Created: latency-svc-qsjfk
Oct 21 21:30:54.614: INFO: Got endpoints: latency-svc-rzksh [751.509684ms]
Oct 21 21:30:54.664: INFO: Got endpoints: latency-svc-kv7tl [751.233167ms]
Oct 21 21:30:54.713: INFO: Got endpoints: latency-svc-bsb6q [749.940246ms]
Oct 21 21:30:54.763: INFO: Got endpoints: latency-svc-pgsk4 [736.941704ms]
Oct 21 21:30:54.813: INFO: Got endpoints: latency-svc-p472r [749.149645ms]
Oct 21 21:30:54.864: INFO: Got endpoints: latency-svc-hd7n9 [750.865864ms]
Oct 21 21:30:54.913: INFO: Got endpoints: latency-svc-5rbjb [750.089825ms]
Oct 21 21:30:54.963: INFO: Got endpoints: latency-svc-t9ns5 [749.11239ms]
Oct 21 21:30:55.013: INFO: Got endpoints: latency-svc-vfxvz [749.735993ms]
Oct 21 21:30:55.063: INFO: Got endpoints: latency-svc-5kjb9 [749.793046ms]
Oct 21 21:30:55.112: INFO: Got endpoints: latency-svc-f4dkm [742.461333ms]
Oct 21 21:30:55.164: INFO: Got endpoints: latency-svc-925gh [750.763783ms]
Oct 21 21:30:55.213: INFO: Got endpoints: latency-svc-d8dvw [749.543936ms]
Oct 21 21:30:55.263: INFO: Got endpoints: latency-svc-7qn7j [749.710211ms]
Oct 21 21:30:55.313: INFO: Got endpoints: latency-svc-qsjfk [749.34231ms]
Oct 21 21:30:55.313: INFO: Latencies: [27.456193ms 27.953246ms 38.025911ms 50.289543ms 66.708551ms 78.513544ms 93.669201ms 105.229455ms 116.857261ms 126.926884ms 138.651202ms 150.293844ms 163.577835ms 174.629542ms 176.716533ms 177.075654ms 177.601019ms 179.246085ms 180.739565ms 182.147366ms 183.773361ms 184.521167ms 184.603256ms 185.633255ms 187.026191ms 187.3139ms 187.668324ms 187.877829ms 187.905403ms 188.164451ms 188.227091ms 188.67168ms 189.357179ms 189.812838ms 190.048213ms 190.149514ms 190.485353ms 190.737413ms 198.624162ms 225.592919ms 259.11266ms 296.461788ms 335.05364ms 371.906107ms 409.906619ms 449.964983ms 490.881625ms 525.174492ms 563.243395ms 604.461957ms 638.697686ms 675.046078ms 693.73698ms 698.962993ms 700.882214ms 729.758816ms 736.941704ms 740.250626ms 742.166311ms 742.461333ms 742.99881ms 744.33384ms 745.357952ms 745.407684ms 745.917817ms 746.452608ms 747.710974ms 747.986003ms 748.123678ms 748.252088ms 748.512391ms 748.561719ms 748.600999ms 748.783346ms 748.846646ms 748.876669ms 749.02988ms 749.04834ms 749.11239ms 749.11939ms 749.149645ms 749.160979ms 749.16185ms 749.171607ms 749.222874ms 749.287335ms 749.28855ms 749.296778ms 749.307641ms 749.33268ms 749.34231ms 749.349788ms 749.363337ms 749.382837ms 749.395097ms 749.415852ms 749.446354ms 749.484687ms 749.509184ms 749.543936ms 749.547229ms 749.56519ms 749.6276ms 749.629993ms 749.653849ms 749.675456ms 749.710211ms 749.718722ms 749.735993ms 749.737135ms 749.745697ms 749.789303ms 749.79104ms 749.793046ms 749.803273ms 749.869634ms 749.875816ms 749.876067ms 749.898661ms 749.905313ms 749.908809ms 749.911463ms 749.911838ms 749.915134ms 749.931092ms 749.940246ms 749.942792ms 749.987434ms 749.992022ms 750.080378ms 750.083228ms 750.089825ms 750.099558ms 750.127918ms 750.139506ms 750.142043ms 750.160228ms 750.22453ms 750.225237ms 750.229769ms 750.236802ms 750.248867ms 750.263164ms 750.301676ms 750.304517ms 750.325628ms 750.35159ms 750.357487ms 750.387054ms 750.390651ms 750.460596ms 750.461201ms 750.481093ms 750.490196ms 750.505103ms 750.520858ms 750.522745ms 750.526499ms 750.54425ms 750.592152ms 750.610139ms 750.6933ms 750.708041ms 750.733805ms 750.763783ms 750.790576ms 750.811443ms 750.830063ms 750.853775ms 750.865864ms 750.884844ms 750.8915ms 750.943498ms 750.961781ms 751.003438ms 751.004954ms 751.085112ms 751.09744ms 751.120078ms 751.224806ms 751.233167ms 751.274884ms 751.321228ms 751.410147ms 751.431159ms 751.476955ms 751.509684ms 752.644197ms 753.448138ms 753.464445ms 754.347196ms 754.990257ms 755.62578ms 755.630792ms 757.15238ms 757.165001ms 758.366952ms 762.790334ms 799.169191ms 803.984003ms]
Oct 21 21:30:55.313: INFO: 50 %ile: 749.547229ms
Oct 21 21:30:55.313: INFO: 90 %ile: 751.233167ms
Oct 21 21:30:55.314: INFO: 99 %ile: 799.169191ms
Oct 21 21:30:55.314: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:30:55.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-rcbfm" for this suite.
Oct 21 21:31:21.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:31:21.492: INFO: namespace: e2e-tests-svc-latency-rcbfm, resource: bindings, ignored listing per whitelist
Oct 21 21:31:21.631: INFO: namespace e2e-tests-svc-latency-rcbfm deletion completed in 26.307169078s

â€¢ [SLOW TEST:37.345 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:31:21.631: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-8stkh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct 21 21:31:21.973: INFO: Waiting up to 5m0s for pod "pod-205f8e90-f44a-11e9-a616-8a530cf33301" in namespace "e2e-tests-emptydir-8stkh" to be "success or failure"
Oct 21 21:31:21.979: INFO: Pod "pod-205f8e90-f44a-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.411522ms
Oct 21 21:31:23.987: INFO: Pod "pod-205f8e90-f44a-11e9-a616-8a530cf33301": Phase="Running", Reason="", readiness=true. Elapsed: 2.013880824s
Oct 21 21:31:25.994: INFO: Pod "pod-205f8e90-f44a-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021135869s
STEP: Saw pod success
Oct 21 21:31:25.994: INFO: Pod "pod-205f8e90-f44a-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:31:26.001: INFO: Trying to get logs from node 10.170.151.156 pod pod-205f8e90-f44a-11e9-a616-8a530cf33301 container test-container: <nil>
STEP: delete the pod
Oct 21 21:31:26.040: INFO: Waiting for pod pod-205f8e90-f44a-11e9-a616-8a530cf33301 to disappear
Oct 21 21:31:26.046: INFO: Pod pod-205f8e90-f44a-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:31:26.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8stkh" for this suite.
Oct 21 21:31:32.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:31:32.354: INFO: namespace: e2e-tests-emptydir-8stkh, resource: bindings, ignored listing per whitelist
Oct 21 21:31:32.408: INFO: namespace e2e-tests-emptydir-8stkh deletion completed in 6.35273844s

â€¢ [SLOW TEST:10.777 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:31:32.409: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-njldr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-njldr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct 21 21:31:32.710: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct 21 21:31:50.868: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.204.80:8080/dial?request=hostName&protocol=http&host=172.30.96.93&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-njldr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:31:50.868: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:31:51.094: INFO: Waiting for endpoints: map[]
Oct 21 21:31:51.101: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.204.80:8080/dial?request=hostName&protocol=http&host=172.30.204.78&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-njldr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:31:51.101: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:31:51.303: INFO: Waiting for endpoints: map[]
Oct 21 21:31:51.310: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.204.80:8080/dial?request=hostName&protocol=http&host=172.30.198.140&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-njldr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct 21 21:31:51.310: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
Oct 21 21:31:51.522: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:31:51.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-njldr" for this suite.
Oct 21 21:32:15.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:32:15.713: INFO: namespace: e2e-tests-pod-network-test-njldr, resource: bindings, ignored listing per whitelist
Oct 21 21:32:15.837: INFO: namespace e2e-tests-pod-network-test-njldr deletion completed in 24.304124815s

â€¢ [SLOW TEST:43.428 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:32:15.838: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-jdncb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Oct 21 21:32:16.132: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct 21 21:32:16.153: INFO: Waiting for terminating namespaces to be deleted...
Oct 21 21:32:16.160: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.141 before test
Oct 21 21:32:16.182: INFO: coredns-autoscaler-64f9c5b4df-9r7mj from kube-system started at 2019-10-21 19:07:19 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.182: INFO: 	Container autoscaler ready: true, restart count 0
Oct 21 21:32:16.182: INFO: ibm-file-plugin-5978669657-p76mk from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.182: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Oct 21 21:32:16.182: INFO: sonobuoy from sonobuoy started at 2019-10-21 19:54:34 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.182: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct 21 21:32:16.182: INFO: vpn-85755bfd8b-mgkzx from kube-system started at 2019-10-21 19:05:50 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.182: INFO: 	Container vpn ready: true, restart count 0
Oct 21 21:32:16.182: INFO: coredns-6d59786485-bqmjp from kube-system started at 2019-10-21 19:08:10 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.182: INFO: 	Container coredns ready: true, restart count 0
Oct 21 21:32:16.182: INFO: calico-node-bzvgs from kube-system started at 2019-10-21 18:42:09 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.182: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 21:32:16.182: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-dzdbt from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 21:32:16.182: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 21:32:16.182: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 21:32:16.182: INFO: ibm-cloud-provider-ip-169-45-227-188-d7c997c79-ss8xf from ibm-system started at 2019-10-21 18:42:59 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.182: INFO: 	Container ibm-cloud-provider-ip-169-45-227-188 ready: true, restart count 0
Oct 21 21:32:16.182: INFO: ibm-master-proxy-static-10.170.151.141 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 21:32:16.183: INFO: ibm-storage-watcher-6d9866b77c-h5m5n from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.183: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Oct 21 21:32:16.183: INFO: ibm-keepalived-watcher-vxdfw from kube-system started at 2019-10-21 18:42:09 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.183: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 21:32:16.183: INFO: ibm-kube-fluentd-sk72w from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.183: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 21:32:16.183: INFO: calico-kube-controllers-94b69ddc9-g4p7g from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.183: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Oct 21 21:32:16.183: INFO: kubernetes-dashboard-7996b848f4-5kt8s from kube-system started at 2019-10-21 18:42:19 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.183: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Oct 21 21:32:16.183: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.145 before test
Oct 21 21:32:16.207: INFO: ibm-master-proxy-static-10.170.151.145 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 21:32:16.207: INFO: ibm-keepalived-watcher-xwtxv from kube-system started at 2019-10-21 18:42:43 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.207: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 21:32:16.207: INFO: public-crbmmvhg4w0qp7koa8k1fg-alb1-6b94587c89-tkmzl from kube-system started at 2019-10-21 18:47:24 +0000 UTC (4 container statuses recorded)
Oct 21 21:32:16.207: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 21:32:16.207: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 21:32:16.207: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 21:32:16.207: INFO: 	Container nginx-ingress ready: true, restart count 0
Oct 21 21:32:16.207: INFO: ibm-kube-fluentd-x96pz from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.207: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 21:32:16.207: INFO: coredns-6d59786485-27lhz from kube-system started at 2019-10-21 19:08:10 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.207: INFO: 	Container coredns ready: true, restart count 0
Oct 21 21:32:16.207: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-gzf4s from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 21:32:16.207: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 21:32:16.207: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 21:32:16.207: INFO: calico-node-6pp5r from kube-system started at 2019-10-21 18:42:43 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.207: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 21:32:16.207: INFO: sonobuoy-e2e-job-ed893f17f84e497d from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 21:32:16.207: INFO: 	Container e2e ready: true, restart count 0
Oct 21 21:32:16.207: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct 21 21:32:16.207: INFO: 
Logging pods the kubelet thinks is on node 10.170.151.156 before test
Oct 21 21:32:16.230: INFO: ibm-master-proxy-static-10.170.151.156 from kube-system started at <nil> (0 container statuses recorded)
Oct 21 21:32:16.230: INFO: metrics-server-c64cd58dc-7bp6m from kube-system started at 2019-10-21 18:42:53 +0000 UTC (2 container statuses recorded)
Oct 21 21:32:16.230: INFO: 	Container metrics-server ready: true, restart count 0
Oct 21 21:32:16.230: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Oct 21 21:32:16.230: INFO: calico-node-mjzv8 from kube-system started at 2019-10-21 18:42:35 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.230: INFO: 	Container calico-node ready: true, restart count 0
Oct 21 21:32:16.230: INFO: ibm-kube-fluentd-pkfzs from kube-system started at 2019-10-21 18:45:48 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.230: INFO: 	Container fluentd ready: true, restart count 0
Oct 21 21:32:16.230: INFO: ibm-keepalived-watcher-zb6kn from kube-system started at 2019-10-21 18:42:35 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.230: INFO: 	Container keepalived-watcher ready: true, restart count 0
Oct 21 21:32:16.231: INFO: ibm-cloud-provider-ip-169-45-227-188-d7c997c79-qtsb6 from ibm-system started at 2019-10-21 18:42:59 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.231: INFO: 	Container ibm-cloud-provider-ip-169-45-227-188 ready: true, restart count 0
Oct 21 21:32:16.231: INFO: sonobuoy-systemd-logs-daemon-set-4089b2f209b0442c-44c55 from sonobuoy started at 2019-10-21 19:54:39 +0000 UTC (2 container statuses recorded)
Oct 21 21:32:16.231: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Oct 21 21:32:16.231: INFO: 	Container systemd-logs ready: true, restart count 1
Oct 21 21:32:16.231: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-10-21 18:46:38 +0000 UTC (1 container statuses recorded)
Oct 21 21:32:16.231: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Oct 21 21:32:16.231: INFO: public-crbmmvhg4w0qp7koa8k1fg-alb1-6b94587c89-dxlp4 from kube-system started at 2019-10-21 18:47:24 +0000 UTC (4 container statuses recorded)
Oct 21 21:32:16.231: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Oct 21 21:32:16.231: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Oct 21 21:32:16.231: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Oct 21 21:32:16.231: INFO: 	Container nginx-ingress ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4326cf5e-f44a-11e9-a616-8a530cf33301 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-4326cf5e-f44a-11e9-a616-8a530cf33301 off the node 10.170.151.156
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4326cf5e-f44a-11e9-a616-8a530cf33301
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:32:24.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-jdncb" for this suite.
Oct 21 21:32:32.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:32:32.577: INFO: namespace: e2e-tests-sched-pred-jdncb, resource: bindings, ignored listing per whitelist
Oct 21 21:32:32.679: INFO: namespace e2e-tests-sched-pred-jdncb deletion completed in 8.301950247s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

â€¢ [SLOW TEST:16.842 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Oct 21 21:32:32.680: INFO: >>> kubeConfig: /tmp/kubeconfig-571745635
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s6qbr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4aba018b-f44a-11e9-a616-8a530cf33301
STEP: Creating a pod to test consume secrets
Oct 21 21:32:33.020: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4abb5323-f44a-11e9-a616-8a530cf33301" in namespace "e2e-tests-projected-s6qbr" to be "success or failure"
Oct 21 21:32:33.026: INFO: Pod "pod-projected-secrets-4abb5323-f44a-11e9-a616-8a530cf33301": Phase="Pending", Reason="", readiness=false. Elapsed: 6.726752ms
Oct 21 21:32:35.034: INFO: Pod "pod-projected-secrets-4abb5323-f44a-11e9-a616-8a530cf33301": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013939443s
STEP: Saw pod success
Oct 21 21:32:35.034: INFO: Pod "pod-projected-secrets-4abb5323-f44a-11e9-a616-8a530cf33301" satisfied condition "success or failure"
Oct 21 21:32:35.040: INFO: Trying to get logs from node 10.170.151.141 pod pod-projected-secrets-4abb5323-f44a-11e9-a616-8a530cf33301 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct 21 21:32:35.075: INFO: Waiting for pod pod-projected-secrets-4abb5323-f44a-11e9-a616-8a530cf33301 to disappear
Oct 21 21:32:35.081: INFO: Pod pod-projected-secrets-4abb5323-f44a-11e9-a616-8a530cf33301 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Oct 21 21:32:35.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s6qbr" for this suite.
Oct 21 21:32:41.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct 21 21:32:41.319: INFO: namespace: e2e-tests-projected-s6qbr, resource: bindings, ignored listing per whitelist
Oct 21 21:32:41.441: INFO: namespace e2e-tests-projected-s6qbr deletion completed in 6.350061316s

â€¢ [SLOW TEST:8.760 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
Oct 21 21:32:41.441: INFO: Running AfterSuite actions on all nodes
Oct 21 21:32:41.441: INFO: Running AfterSuite actions on node 1
Oct 21 21:32:41.441: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5855.884 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h37m36.928204768s
Test Suite Passed
