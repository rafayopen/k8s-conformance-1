I0521 06:59:21.461630      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-151895369
I0521 06:59:21.461752      15 e2e.go:224] Starting e2e run "f56544fb-7b95-11e9-8b08-72649ad3cdd7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1558421960 - Will randomize all specs
Will run 201 of 1946 specs

May 21 06:59:21.614: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 06:59:21.616: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 21 06:59:21.634: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 06:59:21.663: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:21.663: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 06:59:21.663: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:21.663: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:21.663: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:21.663: INFO: 
May 21 06:59:23.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:23.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (2 seconds elapsed)
May 21 06:59:23.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:23.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:23.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:23.678: INFO: 
May 21 06:59:25.676: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:25.676: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (4 seconds elapsed)
May 21 06:59:25.676: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:25.676: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:25.676: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:25.676: INFO: 
May 21 06:59:27.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:27.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (6 seconds elapsed)
May 21 06:59:27.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:27.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:27.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:27.677: INFO: 
May 21 06:59:29.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:29.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (8 seconds elapsed)
May 21 06:59:29.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:29.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:29.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:29.677: INFO: 
May 21 06:59:31.679: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:31.680: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (10 seconds elapsed)
May 21 06:59:31.680: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:31.680: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:31.680: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:31.680: INFO: 
May 21 06:59:33.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:33.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (12 seconds elapsed)
May 21 06:59:33.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:33.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:33.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:33.678: INFO: 
May 21 06:59:35.690: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:35.690: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (14 seconds elapsed)
May 21 06:59:35.690: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:35.690: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:35.690: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:35.690: INFO: 
May 21 06:59:37.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:37.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (16 seconds elapsed)
May 21 06:59:37.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:37.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:37.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:37.677: INFO: 
May 21 06:59:39.682: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:39.682: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (18 seconds elapsed)
May 21 06:59:39.682: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:39.682: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:39.682: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:39.682: INFO: 
May 21 06:59:41.684: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:41.684: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (20 seconds elapsed)
May 21 06:59:41.684: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:41.684: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:41.684: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:41.684: INFO: 
May 21 06:59:43.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:43.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (22 seconds elapsed)
May 21 06:59:43.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:43.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:43.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:43.677: INFO: 
May 21 06:59:45.683: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:45.683: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (24 seconds elapsed)
May 21 06:59:45.683: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:45.683: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:45.683: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:45.683: INFO: 
May 21 06:59:47.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:47.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (26 seconds elapsed)
May 21 06:59:47.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:47.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:47.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:47.677: INFO: 
May 21 06:59:49.676: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:49.676: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (28 seconds elapsed)
May 21 06:59:49.676: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:49.676: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:49.676: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:49.676: INFO: 
May 21 06:59:51.679: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:51.679: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (30 seconds elapsed)
May 21 06:59:51.679: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:51.679: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:51.679: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:51.679: INFO: 
May 21 06:59:53.679: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:53.679: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (32 seconds elapsed)
May 21 06:59:53.679: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:53.679: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:53.679: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:53.679: INFO: 
May 21 06:59:55.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:55.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (34 seconds elapsed)
May 21 06:59:55.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:55.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:55.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:55.678: INFO: 
May 21 06:59:57.682: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:57.682: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (36 seconds elapsed)
May 21 06:59:57.682: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:57.682: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:57.682: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:57.682: INFO: 
May 21 06:59:59.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 06:59:59.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (38 seconds elapsed)
May 21 06:59:59.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 06:59:59.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 06:59:59.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 06:59:59.677: INFO: 
May 21 07:00:01.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:01.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (40 seconds elapsed)
May 21 07:00:01.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:01.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:01.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:01.677: INFO: 
May 21 07:00:03.685: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:03.685: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (42 seconds elapsed)
May 21 07:00:03.685: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:03.685: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:03.685: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:03.685: INFO: 
May 21 07:00:05.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:05.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (44 seconds elapsed)
May 21 07:00:05.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:05.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:05.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:05.677: INFO: 
May 21 07:00:07.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:07.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (46 seconds elapsed)
May 21 07:00:07.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:07.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:07.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:07.678: INFO: 
May 21 07:00:09.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:09.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (48 seconds elapsed)
May 21 07:00:09.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:09.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:09.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:09.677: INFO: 
May 21 07:00:11.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:11.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (50 seconds elapsed)
May 21 07:00:11.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:11.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:11.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:11.678: INFO: 
May 21 07:00:13.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:13.679: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (52 seconds elapsed)
May 21 07:00:13.679: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:13.679: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:13.679: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:13.679: INFO: 
May 21 07:00:15.681: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:15.681: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (54 seconds elapsed)
May 21 07:00:15.681: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:15.681: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:15.681: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:15.681: INFO: 
May 21 07:00:17.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:17.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (56 seconds elapsed)
May 21 07:00:17.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:17.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:17.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:17.678: INFO: 
May 21 07:00:19.684: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:19.684: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (58 seconds elapsed)
May 21 07:00:19.684: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:19.684: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:19.684: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:19.684: INFO: 
May 21 07:00:21.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:21.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (60 seconds elapsed)
May 21 07:00:21.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:21.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:21.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:21.678: INFO: 
May 21 07:00:23.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:23.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (62 seconds elapsed)
May 21 07:00:23.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:23.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:23.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:23.677: INFO: 
May 21 07:00:25.686: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:25.686: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (64 seconds elapsed)
May 21 07:00:25.686: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:25.686: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:25.686: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:25.686: INFO: 
May 21 07:00:27.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:27.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (66 seconds elapsed)
May 21 07:00:27.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:27.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:27.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:27.677: INFO: 
May 21 07:00:29.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:29.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (68 seconds elapsed)
May 21 07:00:29.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:29.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:29.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:29.677: INFO: 
May 21 07:00:31.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:31.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (70 seconds elapsed)
May 21 07:00:31.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:31.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:31.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:31.678: INFO: 
May 21 07:00:33.685: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:33.685: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (72 seconds elapsed)
May 21 07:00:33.685: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:33.685: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:33.685: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:33.685: INFO: 
May 21 07:00:35.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:35.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (74 seconds elapsed)
May 21 07:00:35.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:35.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:35.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:35.678: INFO: 
May 21 07:00:37.683: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:37.683: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (76 seconds elapsed)
May 21 07:00:37.683: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:37.683: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:37.683: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:37.683: INFO: 
May 21 07:00:39.676: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:39.676: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (78 seconds elapsed)
May 21 07:00:39.676: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:39.676: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:39.676: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:39.676: INFO: 
May 21 07:00:41.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:41.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (80 seconds elapsed)
May 21 07:00:41.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:41.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:41.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:41.677: INFO: 
May 21 07:00:43.684: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:43.684: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (82 seconds elapsed)
May 21 07:00:43.684: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:43.684: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:43.684: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:43.684: INFO: 
May 21 07:00:45.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:45.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (84 seconds elapsed)
May 21 07:00:45.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:45.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:45.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:45.677: INFO: 
May 21 07:00:47.690: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:47.690: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (86 seconds elapsed)
May 21 07:00:47.690: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:47.690: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:47.690: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:47.690: INFO: 
May 21 07:00:49.683: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:49.683: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (88 seconds elapsed)
May 21 07:00:49.683: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:49.683: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:49.683: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:49.683: INFO: 
May 21 07:00:51.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:51.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (90 seconds elapsed)
May 21 07:00:51.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:51.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:51.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:51.678: INFO: 
May 21 07:00:53.679: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:53.679: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (92 seconds elapsed)
May 21 07:00:53.679: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:53.679: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:53.679: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:53.679: INFO: 
May 21 07:00:55.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:55.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (94 seconds elapsed)
May 21 07:00:55.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:55.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:55.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:55.677: INFO: 
May 21 07:00:57.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:57.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (96 seconds elapsed)
May 21 07:00:57.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:57.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:57.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:57.677: INFO: 
May 21 07:00:59.685: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:00:59.685: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (98 seconds elapsed)
May 21 07:00:59.685: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:00:59.685: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:00:59.685: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:00:59.685: INFO: 
May 21 07:01:01.679: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:01.679: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (100 seconds elapsed)
May 21 07:01:01.679: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:01.679: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:01.679: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:01.679: INFO: 
May 21 07:01:03.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:03.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (102 seconds elapsed)
May 21 07:01:03.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:03.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:03.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:03.677: INFO: 
May 21 07:01:05.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:05.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (104 seconds elapsed)
May 21 07:01:05.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:05.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:05.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:05.678: INFO: 
May 21 07:01:07.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:07.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (106 seconds elapsed)
May 21 07:01:07.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:07.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:07.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:07.677: INFO: 
May 21 07:01:09.684: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:09.684: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (108 seconds elapsed)
May 21 07:01:09.684: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:09.684: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:09.684: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:09.684: INFO: 
May 21 07:01:11.683: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:11.683: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (110 seconds elapsed)
May 21 07:01:11.683: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:11.683: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:11.683: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:11.683: INFO: 
May 21 07:01:13.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:13.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (112 seconds elapsed)
May 21 07:01:13.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:13.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:13.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:13.677: INFO: 
May 21 07:01:15.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:15.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (114 seconds elapsed)
May 21 07:01:15.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:15.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:15.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:15.677: INFO: 
May 21 07:01:17.681: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:17.681: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (116 seconds elapsed)
May 21 07:01:17.681: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:17.681: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:17.681: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:17.681: INFO: 
May 21 07:01:19.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:19.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (118 seconds elapsed)
May 21 07:01:19.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:19.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:19.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:19.678: INFO: 
May 21 07:01:21.680: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:21.680: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (120 seconds elapsed)
May 21 07:01:21.680: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:21.680: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:21.680: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:21.680: INFO: 
May 21 07:01:23.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:23.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (122 seconds elapsed)
May 21 07:01:23.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:23.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:23.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:23.677: INFO: 
May 21 07:01:25.677: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:25.677: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (124 seconds elapsed)
May 21 07:01:25.677: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:25.677: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:25.677: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:25.677: INFO: 
May 21 07:01:27.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:27.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (126 seconds elapsed)
May 21 07:01:27.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:27.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:27.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:27.678: INFO: 
May 21 07:01:29.679: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:29.679: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (128 seconds elapsed)
May 21 07:01:29.679: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:29.679: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:29.679: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:29.679: INFO: 
May 21 07:01:31.682: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:31.682: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (130 seconds elapsed)
May 21 07:01:31.682: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:31.682: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:31.682: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:31.682: INFO: 
May 21 07:01:33.683: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:33.683: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (132 seconds elapsed)
May 21 07:01:33.683: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:33.683: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:33.683: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:33.683: INFO: 
May 21 07:01:35.678: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:35.678: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (134 seconds elapsed)
May 21 07:01:35.678: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:35.678: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:35.678: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:35.678: INFO: 
May 21 07:01:37.684: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:37.684: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (136 seconds elapsed)
May 21 07:01:37.684: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:37.684: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:37.684: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:37.684: INFO: 
May 21 07:01:39.684: INFO: The status of Pod system-monitor-6d59b9f944-4kb5c is Running (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
May 21 07:01:39.684: INFO: 32 / 33 pods in namespace 'kube-system' are running and ready (138 seconds elapsed)
May 21 07:01:39.684: INFO: expected 8 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 07:01:39.684: INFO: POD                              NODE          PHASE    GRACE  CONDITIONS
May 21 07:01:39.684: INFO: system-monitor-6d59b9f944-4kb5c  192.168.5.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 06:56:28 +0000 UTC ContainersNotReady containers with unready status: [system-monitor]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 04:24:56 +0000 UTC  }]
May 21 07:01:39.684: INFO: 
May 21 07:01:41.678: INFO: 33 / 33 pods in namespace 'kube-system' are running and ready (140 seconds elapsed)
May 21 07:01:41.678: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
May 21 07:01:41.678: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 21 07:01:41.688: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'ksc-flexvolume-ds' (0 seconds elapsed)
May 21 07:01:41.688: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
May 21 07:01:41.688: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May 21 07:01:41.688: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
May 21 07:01:41.688: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'traefik-ingress-controller' (0 seconds elapsed)
May 21 07:01:41.688: INFO: e2e test version: v1.13.0
May 21 07:01:41.689: INFO: kube-apiserver version: v1.13.4
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:01:41.690: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
May 21 07:01:41.733: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 07:01:41.740: INFO: Waiting up to 5m0s for pod "pod-49585396-7b96-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-gsqk8" to be "success or failure"
May 21 07:01:41.742: INFO: Pod "pod-49585396-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.14751ms
May 21 07:01:43.744: INFO: Pod "pod-49585396-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00470748s
May 21 07:01:45.746: INFO: Pod "pod-49585396-7b96-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006747397s
STEP: Saw pod success
May 21 07:01:45.746: INFO: Pod "pod-49585396-7b96-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:01:45.748: INFO: Trying to get logs from node 192.168.5.21 pod pod-49585396-7b96-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:01:45.767: INFO: Waiting for pod pod-49585396-7b96-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:01:45.769: INFO: Pod pod-49585396-7b96-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:01:45.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gsqk8" for this suite.
May 21 07:01:51.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:01:51.827: INFO: namespace: e2e-tests-emptydir-gsqk8, resource: bindings, ignored listing per whitelist
May 21 07:01:51.838: INFO: namespace e2e-tests-emptydir-gsqk8 deletion completed in 6.066811454s

• [SLOW TEST:10.149 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:01:51.839: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-4f64792e-7b96-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:01:51.887: INFO: Waiting up to 5m0s for pod "pod-secrets-4f6503d6-7b96-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-dxk7x" to be "success or failure"
May 21 07:01:51.890: INFO: Pod "pod-secrets-4f6503d6-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.926914ms
May 21 07:01:53.893: INFO: Pod "pod-secrets-4f6503d6-7b96-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005743428s
STEP: Saw pod success
May 21 07:01:53.893: INFO: Pod "pod-secrets-4f6503d6-7b96-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:01:53.895: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-4f6503d6-7b96-11e9-8b08-72649ad3cdd7 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:01:53.908: INFO: Waiting for pod pod-secrets-4f6503d6-7b96-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:01:53.910: INFO: Pod pod-secrets-4f6503d6-7b96-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:01:53.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dxk7x" for this suite.
May 21 07:01:59.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:01:59.944: INFO: namespace: e2e-tests-secrets-dxk7x, resource: bindings, ignored listing per whitelist
May 21 07:01:59.977: INFO: namespace e2e-tests-secrets-dxk7x deletion completed in 6.064640874s

• [SLOW TEST:8.138 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:01:59.977: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
May 21 07:02:00.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 api-versions'
May 21 07:02:00.107: INFO: stderr: ""
May 21 07:02:00.107: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:02:00.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z2l52" for this suite.
May 21 07:02:06.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:02:06.163: INFO: namespace: e2e-tests-kubectl-z2l52, resource: bindings, ignored listing per whitelist
May 21 07:02:06.182: INFO: namespace e2e-tests-kubectl-z2l52 deletion completed in 6.072431526s

• [SLOW TEST:6.205 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:02:06.182: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-b7sl2/configmap-test-57f37307-7b96-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:02:06.252: INFO: Waiting up to 5m0s for pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-b7sl2" to be "success or failure"
May 21 07:02:06.255: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.755631ms
May 21 07:02:08.263: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01091742s
May 21 07:02:10.267: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015197486s
May 21 07:02:12.273: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020466196s
May 21 07:02:14.275: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022678318s
May 21 07:02:16.277: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.025234181s
May 21 07:02:18.280: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.027606641s
May 21 07:02:20.282: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.030082142s
May 21 07:02:22.287: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.035049485s
May 21 07:02:24.290: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.037971063s
May 21 07:02:26.295: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.043222363s
May 21 07:02:28.298: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.046242052s
STEP: Saw pod success
May 21 07:02:28.299: INFO: Pod "pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:02:28.300: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7 container env-test: <nil>
STEP: delete the pod
May 21 07:02:28.315: INFO: Waiting for pod pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:02:28.317: INFO: Pod pod-configmaps-57f4d8fe-7b96-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:02:28.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b7sl2" for this suite.
May 21 07:02:34.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:02:34.343: INFO: namespace: e2e-tests-configmap-b7sl2, resource: bindings, ignored listing per whitelist
May 21 07:02:34.384: INFO: namespace e2e-tests-configmap-b7sl2 deletion completed in 6.064582912s

• [SLOW TEST:28.202 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:02:34.384: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-v5js2
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-v5js2
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-v5js2
May 21 07:02:34.448: INFO: Found 0 stateful pods, waiting for 1
May 21 07:02:44.455: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May 21 07:02:54.451: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
May 21 07:03:04.454: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 21 07:03:04.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-v5js2 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:03:04.667: INFO: stderr: ""
May 21 07:03:04.667: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:03:04.667: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:03:04.670: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 21 07:03:14.677: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 07:03:14.677: INFO: Waiting for statefulset status.replicas updated to 0
May 21 07:03:14.687: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999972s
May 21 07:03:15.690: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996441721s
May 21 07:03:16.693: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993706413s
May 21 07:03:17.695: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990986503s
May 21 07:03:18.698: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988201437s
May 21 07:03:19.701: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.985211857s
May 21 07:03:20.704: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.982231709s
May 21 07:03:21.707: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.979394298s
May 21 07:03:22.710: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.976319697s
May 21 07:03:23.713: INFO: Verifying statefulset ss doesn't scale past 1 for another 973.471903ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-v5js2
May 21 07:03:24.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-v5js2 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:03:24.955: INFO: stderr: ""
May 21 07:03:24.955: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:03:24.955: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:03:24.958: INFO: Found 1 stateful pods, waiting for 3
May 21 07:03:34.966: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 07:03:34.966: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 07:03:34.966: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 21 07:03:34.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-v5js2 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:03:35.157: INFO: stderr: ""
May 21 07:03:35.157: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:03:35.157: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:03:35.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-v5js2 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:03:35.352: INFO: stderr: ""
May 21 07:03:35.352: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:03:35.352: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:03:35.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-v5js2 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:03:35.559: INFO: stderr: ""
May 21 07:03:35.559: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:03:35.559: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:03:35.559: INFO: Waiting for statefulset status.replicas updated to 0
May 21 07:03:35.561: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 21 07:03:45.571: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 07:03:45.571: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 21 07:03:45.571: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 21 07:03:45.579: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999759s
May 21 07:03:46.582: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996182546s
May 21 07:03:47.585: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993208478s
May 21 07:03:48.589: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990032431s
May 21 07:03:49.591: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986689877s
May 21 07:03:50.595: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.984017958s
May 21 07:03:51.599: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.980369735s
May 21 07:03:52.601: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.976697337s
May 21 07:03:53.604: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.973836399s
May 21 07:03:54.608: INFO: Verifying statefulset ss doesn't scale past 3 for another 970.894374ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-v5js2
May 21 07:03:55.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-v5js2 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:03:55.816: INFO: stderr: ""
May 21 07:03:55.816: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:03:55.816: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:03:55.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-v5js2 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:03:56.005: INFO: stderr: ""
May 21 07:03:56.005: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:03:56.005: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:03:56.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-v5js2 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:03:56.211: INFO: stderr: ""
May 21 07:03:56.211: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:03:56.211: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:03:56.211: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 07:04:06.226: INFO: Deleting all statefulset in ns e2e-tests-statefulset-v5js2
May 21 07:04:06.228: INFO: Scaling statefulset ss to 0
May 21 07:04:06.233: INFO: Waiting for statefulset status.replicas updated to 0
May 21 07:04:06.234: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:04:06.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-v5js2" for this suite.
May 21 07:04:12.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:04:12.308: INFO: namespace: e2e-tests-statefulset-v5js2, resource: bindings, ignored listing per whitelist
May 21 07:04:12.310: INFO: namespace e2e-tests-statefulset-v5js2 deletion completed in 6.062015742s

• [SLOW TEST:97.926 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:04:12.310: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-jxp2r
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-jxp2r
STEP: Deleting pre-stop pod
May 21 07:04:25.388: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:04:25.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-jxp2r" for this suite.
May 21 07:05:03.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:05:03.452: INFO: namespace: e2e-tests-prestop-jxp2r, resource: bindings, ignored listing per whitelist
May 21 07:05:03.464: INFO: namespace e2e-tests-prestop-jxp2r deletion completed in 38.068420696s

• [SLOW TEST:51.154 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:05:03.464: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:05:03.510: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c19bfeee-7b96-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-p876r" to be "success or failure"
May 21 07:05:03.513: INFO: Pod "downwardapi-volume-c19bfeee-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.820959ms
May 21 07:05:05.516: INFO: Pod "downwardapi-volume-c19bfeee-7b96-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005437768s
STEP: Saw pod success
May 21 07:05:05.516: INFO: Pod "downwardapi-volume-c19bfeee-7b96-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:05:05.518: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-c19bfeee-7b96-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:05:05.531: INFO: Waiting for pod downwardapi-volume-c19bfeee-7b96-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:05:05.533: INFO: Pod downwardapi-volume-c19bfeee-7b96-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:05:05.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p876r" for this suite.
May 21 07:05:11.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:05:11.568: INFO: namespace: e2e-tests-downward-api-p876r, resource: bindings, ignored listing per whitelist
May 21 07:05:11.596: INFO: namespace e2e-tests-downward-api-p876r deletion completed in 6.060545264s

• [SLOW TEST:8.131 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:05:11.596: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:05:11.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-744g9" for this suite.
May 21 07:05:17.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:05:17.678: INFO: namespace: e2e-tests-services-744g9, resource: bindings, ignored listing per whitelist
May 21 07:05:17.704: INFO: namespace e2e-tests-services-744g9 deletion completed in 6.05481962s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.108 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:05:17.704: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:05:17.761: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ca1a857b-7b96-11e9-926e-fa163e6dedea", Controller:(*bool)(0xc001536136), BlockOwnerDeletion:(*bool)(0xc001536137)}}
May 21 07:05:17.764: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ca1944c1-7b96-11e9-926e-fa163e6dedea", Controller:(*bool)(0xc001536386), BlockOwnerDeletion:(*bool)(0xc001536387)}}
May 21 07:05:17.767: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ca1a1959-7b96-11e9-926e-fa163e6dedea", Controller:(*bool)(0xc00178765e), BlockOwnerDeletion:(*bool)(0xc00178765f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:05:22.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-n2qpd" for this suite.
May 21 07:05:28.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:05:28.801: INFO: namespace: e2e-tests-gc-n2qpd, resource: bindings, ignored listing per whitelist
May 21 07:05:28.841: INFO: namespace e2e-tests-gc-n2qpd deletion completed in 6.061412301s

• [SLOW TEST:11.137 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:05:28.841: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-d0bc4cf8-7b96-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:05:28.889: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d0bcd6fa-7b96-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-jfzg9" to be "success or failure"
May 21 07:05:28.891: INFO: Pod "pod-projected-secrets-d0bcd6fa-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.257813ms
May 21 07:05:30.894: INFO: Pod "pod-projected-secrets-d0bcd6fa-7b96-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00458624s
STEP: Saw pod success
May 21 07:05:30.894: INFO: Pod "pod-projected-secrets-d0bcd6fa-7b96-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:05:30.895: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-d0bcd6fa-7b96-11e9-8b08-72649ad3cdd7 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 07:05:30.912: INFO: Waiting for pod pod-projected-secrets-d0bcd6fa-7b96-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:05:30.914: INFO: Pod pod-projected-secrets-d0bcd6fa-7b96-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:05:30.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jfzg9" for this suite.
May 21 07:05:36.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:05:36.972: INFO: namespace: e2e-tests-projected-jfzg9, resource: bindings, ignored listing per whitelist
May 21 07:05:36.975: INFO: namespace e2e-tests-projected-jfzg9 deletion completed in 6.058379667s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:05:36.975: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d59474db-7b96-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:05:37.016: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d594edeb-7b96-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-wflwm" to be "success or failure"
May 21 07:05:37.017: INFO: Pod "pod-projected-configmaps-d594edeb-7b96-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.557455ms
May 21 07:05:39.020: INFO: Pod "pod-projected-configmaps-d594edeb-7b96-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004231516s
STEP: Saw pod success
May 21 07:05:39.020: INFO: Pod "pod-projected-configmaps-d594edeb-7b96-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:05:39.022: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-d594edeb-7b96-11e9-8b08-72649ad3cdd7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:05:39.035: INFO: Waiting for pod pod-projected-configmaps-d594edeb-7b96-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:05:39.038: INFO: Pod pod-projected-configmaps-d594edeb-7b96-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:05:39.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wflwm" for this suite.
May 21 07:05:45.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:05:45.069: INFO: namespace: e2e-tests-projected-wflwm, resource: bindings, ignored listing per whitelist
May 21 07:05:45.106: INFO: namespace e2e-tests-projected-wflwm deletion completed in 6.065514569s

• [SLOW TEST:8.131 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:05:45.107: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
May 21 07:05:45.146: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 21 07:05:45.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:05:45.416: INFO: stderr: ""
May 21 07:05:45.416: INFO: stdout: "service/redis-slave created\n"
May 21 07:05:45.416: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 21 07:05:45.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:05:45.594: INFO: stderr: ""
May 21 07:05:45.594: INFO: stdout: "service/redis-master created\n"
May 21 07:05:45.594: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 21 07:05:45.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:05:45.792: INFO: stderr: ""
May 21 07:05:45.792: INFO: stdout: "service/frontend created\n"
May 21 07:05:45.792: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 21 07:05:45.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:05:45.926: INFO: stderr: ""
May 21 07:05:45.926: INFO: stdout: "deployment.extensions/frontend created\n"
May 21 07:05:45.926: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 21 07:05:45.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:05:46.089: INFO: stderr: ""
May 21 07:05:46.090: INFO: stdout: "deployment.extensions/redis-master created\n"
May 21 07:05:46.090: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 21 07:05:46.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:05:46.261: INFO: stderr: ""
May 21 07:05:46.261: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 21 07:05:46.261: INFO: Waiting for all frontend pods to be Running.
May 21 07:06:26.314: INFO: Waiting for frontend to serve content.
May 21 07:06:31.334: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

May 21 07:06:36.348: INFO: Trying to add a new entry to the guestbook.
May 21 07:06:36.355: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 21 07:06:36.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:06:36.471: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:06:36.471: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 21 07:06:36.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:06:36.559: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:06:36.559: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 21 07:06:36.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:06:36.650: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:06:36.650: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 21 07:06:36.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:06:36.728: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:06:36.728: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 21 07:06:36.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:06:36.800: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:06:36.800: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 21 07:06:36.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hz2cd'
May 21 07:06:36.911: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:06:36.911: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:06:36.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hz2cd" for this suite.
May 21 07:07:14.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:07:14.948: INFO: namespace: e2e-tests-kubectl-hz2cd, resource: bindings, ignored listing per whitelist
May 21 07:07:14.997: INFO: namespace e2e-tests-kubectl-hz2cd deletion completed in 38.081178498s

• [SLOW TEST:89.891 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:07:14.998: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-xnmg
STEP: Creating a pod to test atomic-volume-subpath
May 21 07:07:15.101: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xnmg" in namespace "e2e-tests-subpath-7dt6l" to be "success or failure"
May 21 07:07:15.104: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Pending", Reason="", readiness=false. Elapsed: 3.223622ms
May 21 07:07:17.107: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005666501s
May 21 07:07:19.114: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 4.012430836s
May 21 07:07:21.120: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 6.018440405s
May 21 07:07:23.122: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 8.021298542s
May 21 07:07:25.125: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 10.024171068s
May 21 07:07:27.128: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 12.026747809s
May 21 07:07:29.131: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 14.029655672s
May 21 07:07:31.137: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 16.035668663s
May 21 07:07:33.140: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 18.038450812s
May 21 07:07:35.143: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 20.041624261s
May 21 07:07:37.146: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Running", Reason="", readiness=false. Elapsed: 22.044619393s
May 21 07:07:39.149: INFO: Pod "pod-subpath-test-configmap-xnmg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.04736965s
STEP: Saw pod success
May 21 07:07:39.149: INFO: Pod "pod-subpath-test-configmap-xnmg" satisfied condition "success or failure"
May 21 07:07:39.151: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-configmap-xnmg container test-container-subpath-configmap-xnmg: <nil>
STEP: delete the pod
May 21 07:07:39.165: INFO: Waiting for pod pod-subpath-test-configmap-xnmg to disappear
May 21 07:07:39.167: INFO: Pod pod-subpath-test-configmap-xnmg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xnmg
May 21 07:07:39.167: INFO: Deleting pod "pod-subpath-test-configmap-xnmg" in namespace "e2e-tests-subpath-7dt6l"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:07:39.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-7dt6l" for this suite.
May 21 07:07:45.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:07:45.189: INFO: namespace: e2e-tests-subpath-7dt6l, resource: bindings, ignored listing per whitelist
May 21 07:07:45.231: INFO: namespace e2e-tests-subpath-7dt6l deletion completed in 6.057643898s

• [SLOW TEST:30.233 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:07:45.231: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-bp7lr/secret-test-2207c1ee-7b97-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:07:45.279: INFO: Waiting up to 5m0s for pod "pod-configmaps-22084f85-7b97-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-bp7lr" to be "success or failure"
May 21 07:07:45.281: INFO: Pod "pod-configmaps-22084f85-7b97-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.979745ms
May 21 07:07:47.283: INFO: Pod "pod-configmaps-22084f85-7b97-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004274009s
STEP: Saw pod success
May 21 07:07:47.283: INFO: Pod "pod-configmaps-22084f85-7b97-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:07:47.285: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-22084f85-7b97-11e9-8b08-72649ad3cdd7 container env-test: <nil>
STEP: delete the pod
May 21 07:07:47.300: INFO: Waiting for pod pod-configmaps-22084f85-7b97-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:07:47.302: INFO: Pod pod-configmaps-22084f85-7b97-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:07:47.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bp7lr" for this suite.
May 21 07:07:53.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:07:53.340: INFO: namespace: e2e-tests-secrets-bp7lr, resource: bindings, ignored listing per whitelist
May 21 07:07:53.365: INFO: namespace e2e-tests-secrets-bp7lr deletion completed in 6.060609607s

• [SLOW TEST:8.134 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:07:53.365: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 21 07:07:53.415: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:53.415: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:53.415: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:53.417: INFO: Number of nodes with available pods: 0
May 21 07:07:53.417: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:07:54.420: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:54.420: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:54.420: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:54.422: INFO: Number of nodes with available pods: 0
May 21 07:07:54.422: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:07:55.420: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:55.420: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:55.420: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:55.422: INFO: Number of nodes with available pods: 0
May 21 07:07:55.422: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:07:56.421: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:56.421: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:56.421: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:56.423: INFO: Number of nodes with available pods: 0
May 21 07:07:56.423: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:07:57.420: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:57.420: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:57.420: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:57.422: INFO: Number of nodes with available pods: 1
May 21 07:07:57.422: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 21 07:07:57.431: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:57.431: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:57.431: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:07:57.434: INFO: Number of nodes with available pods: 1
May 21 07:07:57.434: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-92pwf, will wait for the garbage collector to delete the pods
May 21 07:07:58.496: INFO: Deleting DaemonSet.extensions daemon-set took: 4.464511ms
May 21 07:07:58.597: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.1699ms
May 21 07:10:04.103: INFO: Number of nodes with available pods: 0
May 21 07:10:04.103: INFO: Number of running nodes: 0, number of available pods: 0
May 21 07:10:04.107: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-92pwf/daemonsets","resourceVersion":"15976"},"items":null}

May 21 07:10:04.109: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-92pwf/pods","resourceVersion":"15976"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:10:04.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-92pwf" for this suite.
May 21 07:10:10.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:10:10.153: INFO: namespace: e2e-tests-daemonsets-92pwf, resource: bindings, ignored listing per whitelist
May 21 07:10:10.185: INFO: namespace e2e-tests-daemonsets-92pwf deletion completed in 6.067271513s

• [SLOW TEST:136.820 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:10:10.186: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-78711b78-7b97-11e9-8b08-72649ad3cdd7
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-78711b78-7b97-11e9-8b08-72649ad3cdd7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:10:14.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mnm7r" for this suite.
May 21 07:10:36.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:10:36.308: INFO: namespace: e2e-tests-configmap-mnm7r, resource: bindings, ignored listing per whitelist
May 21 07:10:36.354: INFO: namespace e2e-tests-configmap-mnm7r deletion completed in 22.068042629s

• [SLOW TEST:26.169 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:10:36.355: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:10:36.414: INFO: Waiting up to 5m0s for pod "downwardapi-volume-88091cf6-7b97-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-4d5dh" to be "success or failure"
May 21 07:10:36.416: INFO: Pod "downwardapi-volume-88091cf6-7b97-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.200078ms
May 21 07:10:38.418: INFO: Pod "downwardapi-volume-88091cf6-7b97-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004348628s
STEP: Saw pod success
May 21 07:10:38.418: INFO: Pod "downwardapi-volume-88091cf6-7b97-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:10:38.420: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-88091cf6-7b97-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:10:38.432: INFO: Waiting for pod downwardapi-volume-88091cf6-7b97-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:10:38.435: INFO: Pod downwardapi-volume-88091cf6-7b97-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:10:38.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4d5dh" for this suite.
May 21 07:10:44.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:10:44.509: INFO: namespace: e2e-tests-downward-api-4d5dh, resource: bindings, ignored listing per whitelist
May 21 07:10:44.512: INFO: namespace e2e-tests-downward-api-4d5dh deletion completed in 6.071878255s

• [SLOW TEST:8.157 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:10:44.512: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8ce387b2-7b97-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:10:44.558: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ce41ef9-7b97-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-n54zc" to be "success or failure"
May 21 07:10:44.561: INFO: Pod "pod-configmaps-8ce41ef9-7b97-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.594179ms
May 21 07:10:46.566: INFO: Pod "pod-configmaps-8ce41ef9-7b97-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007885852s
STEP: Saw pod success
May 21 07:10:46.566: INFO: Pod "pod-configmaps-8ce41ef9-7b97-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:10:46.568: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-8ce41ef9-7b97-11e9-8b08-72649ad3cdd7 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:10:46.581: INFO: Waiting for pod pod-configmaps-8ce41ef9-7b97-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:10:46.582: INFO: Pod pod-configmaps-8ce41ef9-7b97-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:10:46.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n54zc" for this suite.
May 21 07:10:52.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:10:52.648: INFO: namespace: e2e-tests-configmap-n54zc, resource: bindings, ignored listing per whitelist
May 21 07:10:52.648: INFO: namespace e2e-tests-configmap-n54zc deletion completed in 6.06310542s

• [SLOW TEST:8.136 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:10:52.648: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 07:10:52.688: INFO: Waiting up to 5m0s for pod "downward-api-91bc8842-7b97-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-gf5j4" to be "success or failure"
May 21 07:10:52.691: INFO: Pod "downward-api-91bc8842-7b97-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.396791ms
May 21 07:10:54.694: INFO: Pod "downward-api-91bc8842-7b97-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00517337s
STEP: Saw pod success
May 21 07:10:54.694: INFO: Pod "downward-api-91bc8842-7b97-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:10:54.695: INFO: Trying to get logs from node 192.168.5.21 pod downward-api-91bc8842-7b97-11e9-8b08-72649ad3cdd7 container dapi-container: <nil>
STEP: delete the pod
May 21 07:10:54.707: INFO: Waiting for pod downward-api-91bc8842-7b97-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:10:54.710: INFO: Pod downward-api-91bc8842-7b97-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:10:54.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gf5j4" for this suite.
May 21 07:11:00.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:11:00.754: INFO: namespace: e2e-tests-downward-api-gf5j4, resource: bindings, ignored listing per whitelist
May 21 07:11:00.772: INFO: namespace e2e-tests-downward-api-gf5j4 deletion completed in 6.059809495s

• [SLOW TEST:8.125 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:11:00.773: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0521 07:11:31.349697      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 07:11:31.349: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:11:31.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gnn8w" for this suite.
May 21 07:11:37.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:11:37.395: INFO: namespace: e2e-tests-gc-gnn8w, resource: bindings, ignored listing per whitelist
May 21 07:11:37.410: INFO: namespace e2e-tests-gc-gnn8w deletion completed in 6.058395082s

• [SLOW TEST:36.637 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:11:37.410: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ac6abfb2-7b97-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:11:37.453: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ac6b3a6b-7b97-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-zllbv" to be "success or failure"
May 21 07:11:37.455: INFO: Pod "pod-projected-configmaps-ac6b3a6b-7b97-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.903708ms
May 21 07:11:39.457: INFO: Pod "pod-projected-configmaps-ac6b3a6b-7b97-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004302701s
STEP: Saw pod success
May 21 07:11:39.457: INFO: Pod "pod-projected-configmaps-ac6b3a6b-7b97-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:11:39.459: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-ac6b3a6b-7b97-11e9-8b08-72649ad3cdd7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:11:39.473: INFO: Waiting for pod pod-projected-configmaps-ac6b3a6b-7b97-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:11:39.474: INFO: Pod pod-projected-configmaps-ac6b3a6b-7b97-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:11:39.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zllbv" for this suite.
May 21 07:11:45.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:11:45.536: INFO: namespace: e2e-tests-projected-zllbv, resource: bindings, ignored listing per whitelist
May 21 07:11:45.545: INFO: namespace e2e-tests-projected-zllbv deletion completed in 6.068363441s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:11:45.545: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rvrpv
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-rvrpv
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-rvrpv
May 21 07:11:45.598: INFO: Found 0 stateful pods, waiting for 1
May 21 07:11:55.604: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 21 07:11:55.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-rvrpv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:11:55.801: INFO: stderr: ""
May 21 07:11:55.801: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:11:55.801: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:11:55.804: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 21 07:12:05.810: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 07:12:05.810: INFO: Waiting for statefulset status.replicas updated to 0
May 21 07:12:05.820: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 07:12:05.820: INFO: ss-0  192.168.5.21  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:56 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  }]
May 21 07:12:05.820: INFO: 
May 21 07:12:05.820: INFO: StatefulSet ss has not reached scale 3, at 1
May 21 07:12:06.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996236946s
May 21 07:12:07.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993439586s
May 21 07:12:08.829: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989912355s
May 21 07:12:09.833: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986809303s
May 21 07:12:10.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.983166713s
May 21 07:12:11.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.979439283s
May 21 07:12:12.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.976443858s
May 21 07:12:13.846: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.973487785s
May 21 07:12:14.849: INFO: Verifying statefulset ss doesn't scale past 3 for another 970.303893ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-rvrpv
May 21 07:12:15.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-rvrpv ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:12:16.062: INFO: stderr: ""
May 21 07:12:16.062: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:12:16.062: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:12:16.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-rvrpv ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:12:16.272: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 21 07:12:16.272: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:12:16.272: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:12:16.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-rvrpv ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:12:16.480: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 21 07:12:16.480: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:12:16.480: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:12:16.483: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 07:12:16.483: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 07:12:16.483: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 21 07:12:16.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-rvrpv ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:12:16.677: INFO: stderr: ""
May 21 07:12:16.677: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:12:16.677: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:12:16.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-rvrpv ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:12:16.874: INFO: stderr: ""
May 21 07:12:16.874: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:12:16.874: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:12:16.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-rvrpv ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:12:17.070: INFO: stderr: ""
May 21 07:12:17.070: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:12:17.070: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:12:17.070: INFO: Waiting for statefulset status.replicas updated to 0
May 21 07:12:17.073: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 21 07:12:27.081: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 07:12:27.081: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 21 07:12:27.081: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 21 07:12:27.088: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 07:12:27.088: INFO: ss-0  192.168.5.21  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  }]
May 21 07:12:27.088: INFO: ss-1  192.168.5.21  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:27.088: INFO: ss-2  192.168.5.21  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:27.088: INFO: 
May 21 07:12:27.088: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 07:12:28.091: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 07:12:28.091: INFO: ss-0  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  }]
May 21 07:12:28.091: INFO: ss-1  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:28.091: INFO: ss-2  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:28.091: INFO: 
May 21 07:12:28.091: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 07:12:29.094: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 07:12:29.094: INFO: ss-0  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  }]
May 21 07:12:29.094: INFO: ss-1  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:29.094: INFO: ss-2  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:29.094: INFO: 
May 21 07:12:29.094: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 07:12:30.097: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 07:12:30.097: INFO: ss-0  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  }]
May 21 07:12:30.097: INFO: ss-1  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:30.097: INFO: ss-2  192.168.5.21  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:30.097: INFO: 
May 21 07:12:30.097: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 07:12:31.100: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 07:12:31.100: INFO: ss-0  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  }]
May 21 07:12:31.100: INFO: ss-1  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:31.101: INFO: ss-2  192.168.5.21  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:31.101: INFO: 
May 21 07:12:31.101: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 07:12:32.104: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 07:12:32.104: INFO: ss-0  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  }]
May 21 07:12:32.104: INFO: ss-1  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:32.104: INFO: ss-2  192.168.5.21  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:32.104: INFO: 
May 21 07:12:32.104: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 07:12:33.108: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
May 21 07:12:33.108: INFO: ss-0  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:11:45 +0000 UTC  }]
May 21 07:12:33.108: INFO: ss-1  192.168.5.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:33.108: INFO: ss-2  192.168.5.21  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:12:05 +0000 UTC  }]
May 21 07:12:33.108: INFO: 
May 21 07:12:33.108: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 07:12:34.110: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.977719518s
May 21 07:12:35.113: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.975199842s
May 21 07:12:36.116: INFO: Verifying statefulset ss doesn't scale past 0 for another 972.588356ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-rvrpv
May 21 07:12:37.121: INFO: Scaling statefulset ss to 0
May 21 07:12:37.126: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 07:12:37.128: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rvrpv
May 21 07:12:37.129: INFO: Scaling statefulset ss to 0
May 21 07:12:37.134: INFO: Waiting for statefulset status.replicas updated to 0
May 21 07:12:37.135: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:12:37.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rvrpv" for this suite.
May 21 07:12:43.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:12:43.173: INFO: namespace: e2e-tests-statefulset-rvrpv, resource: bindings, ignored listing per whitelist
May 21 07:12:43.211: INFO: namespace e2e-tests-statefulset-rvrpv deletion completed in 6.065515859s

• [SLOW TEST:57.666 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:12:43.211: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d3a38282-7b97-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:12:43.257: INFO: Waiting up to 5m0s for pod "pod-secrets-d3a4103e-7b97-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-82b78" to be "success or failure"
May 21 07:12:43.258: INFO: Pod "pod-secrets-d3a4103e-7b97-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.467205ms
May 21 07:12:45.260: INFO: Pod "pod-secrets-d3a4103e-7b97-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003864953s
STEP: Saw pod success
May 21 07:12:45.260: INFO: Pod "pod-secrets-d3a4103e-7b97-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:12:45.262: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-d3a4103e-7b97-11e9-8b08-72649ad3cdd7 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:12:45.274: INFO: Waiting for pod pod-secrets-d3a4103e-7b97-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:12:45.275: INFO: Pod pod-secrets-d3a4103e-7b97-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:12:45.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-82b78" for this suite.
May 21 07:12:51.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:12:51.326: INFO: namespace: e2e-tests-secrets-82b78, resource: bindings, ignored listing per whitelist
May 21 07:12:51.342: INFO: namespace e2e-tests-secrets-82b78 deletion completed in 6.064096757s

• [SLOW TEST:8.131 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:12:51.342: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d87c041c-7b97-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:12:51.387: INFO: Waiting up to 5m0s for pod "pod-secrets-d87c96bd-7b97-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-4kblj" to be "success or failure"
May 21 07:12:51.389: INFO: Pod "pod-secrets-d87c96bd-7b97-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.505569ms
May 21 07:12:53.391: INFO: Pod "pod-secrets-d87c96bd-7b97-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003947484s
STEP: Saw pod success
May 21 07:12:53.391: INFO: Pod "pod-secrets-d87c96bd-7b97-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:12:53.393: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-d87c96bd-7b97-11e9-8b08-72649ad3cdd7 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:12:53.405: INFO: Waiting for pod pod-secrets-d87c96bd-7b97-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:12:53.406: INFO: Pod pod-secrets-d87c96bd-7b97-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:12:53.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4kblj" for this suite.
May 21 07:12:59.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:12:59.442: INFO: namespace: e2e-tests-secrets-4kblj, resource: bindings, ignored listing per whitelist
May 21 07:12:59.472: INFO: namespace e2e-tests-secrets-4kblj deletion completed in 6.063172256s

• [SLOW TEST:8.130 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:12:59.472: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:12:59.533: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 21 07:12:59.539: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:12:59.539: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:12:59.539: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:12:59.543: INFO: Number of nodes with available pods: 0
May 21 07:12:59.543: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:13:00.545: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:00.546: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:00.546: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:00.547: INFO: Number of nodes with available pods: 0
May 21 07:13:00.547: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:13:01.546: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:01.546: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:01.546: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:01.548: INFO: Number of nodes with available pods: 1
May 21 07:13:01.548: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 21 07:13:01.563: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:01.566: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:01.566: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:01.566: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:02.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:02.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:02.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:02.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:03.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:03.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:03.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:03.573: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:04.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:04.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:04.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:04.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:05.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:05.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:05.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:05.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:06.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:06.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:06.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:06.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:07.572: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:07.576: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:07.576: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:07.576: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:08.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:08.573: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:08.573: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:08.573: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:09.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:09.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:09.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:09.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:10.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:10.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:10.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:10.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:11.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:11.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:11.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:11.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:12.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:12.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:12.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:12.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:13.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:13.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:13.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:13.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:14.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:14.573: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:14.573: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:14.573: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:15.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:15.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:15.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:15.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:16.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:16.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:16.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:16.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:17.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:17.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:17.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:17.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:18.572: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:18.576: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:18.576: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:18.576: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:19.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:19.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:19.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:19.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:20.570: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:20.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:20.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:20.573: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:21.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:21.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:21.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:21.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:22.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:22.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:22.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:22.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:23.572: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:23.578: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:23.578: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:23.578: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:24.570: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:24.574: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:24.574: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:24.574: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:25.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:25.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:25.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:25.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:26.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:26.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:26.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:26.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:27.568: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:27.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:27.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:27.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:28.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:28.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:28.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:28.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:29.574: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:29.577: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:29.577: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:29.577: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:30.570: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:30.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:30.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:30.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:31.571: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:31.576: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:31.576: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:31.576: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:32.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:32.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:32.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:32.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:33.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:33.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:33.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:33.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:34.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:34.569: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:34.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:34.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:34.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:35.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:35.569: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:35.573: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:35.573: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:35.573: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:36.574: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:36.574: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:36.581: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:36.581: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:36.581: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:37.568: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:37.568: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:37.570: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:37.570: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:37.570: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:38.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:38.569: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:38.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:38.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:38.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:39.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:39.569: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:39.571: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:39.571: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:39.571: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:40.572: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:40.572: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:40.575: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:40.575: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:40.575: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:41.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:41.569: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:41.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:41.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:41.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:42.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:42.569: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:42.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:42.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:42.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:43.569: INFO: Wrong image for pod: daemon-set-gdxbt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 21 07:13:43.569: INFO: Pod daemon-set-gdxbt is not available
May 21 07:13:43.572: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:43.572: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:43.572: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:44.569: INFO: Pod daemon-set-7wxmn is not available
May 21 07:13:44.573: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:44.573: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:44.573: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May 21 07:13:44.575: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:44.575: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:44.575: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:44.576: INFO: Number of nodes with available pods: 0
May 21 07:13:44.576: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:13:45.580: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:45.580: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:45.580: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:13:45.582: INFO: Number of nodes with available pods: 1
May 21 07:13:45.582: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-jf6hx, will wait for the garbage collector to delete the pods
May 21 07:13:45.649: INFO: Deleting DaemonSet.extensions daemon-set took: 4.296429ms
May 21 07:13:45.749: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.173874ms
May 21 07:13:54.054: INFO: Number of nodes with available pods: 0
May 21 07:13:54.054: INFO: Number of running nodes: 0, number of available pods: 0
May 21 07:13:54.055: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jf6hx/daemonsets","resourceVersion":"16790"},"items":null}

May 21 07:13:54.056: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jf6hx/pods","resourceVersion":"16790"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:13:54.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jf6hx" for this suite.
May 21 07:14:00.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:14:00.094: INFO: namespace: e2e-tests-daemonsets-jf6hx, resource: bindings, ignored listing per whitelist
May 21 07:14:00.125: INFO: namespace e2e-tests-daemonsets-jf6hx deletion completed in 6.06375919s

• [SLOW TEST:60.653 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:14:00.125: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:14:00.172: INFO: Waiting up to 5m0s for pod "downwardapi-volume-017c022c-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-chjtd" to be "success or failure"
May 21 07:14:00.177: INFO: Pod "downwardapi-volume-017c022c-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.171115ms
May 21 07:14:02.180: INFO: Pod "downwardapi-volume-017c022c-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007137881s
STEP: Saw pod success
May 21 07:14:02.180: INFO: Pod "downwardapi-volume-017c022c-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:14:02.181: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-017c022c-7b98-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:14:02.194: INFO: Waiting for pod downwardapi-volume-017c022c-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:14:02.195: INFO: Pod downwardapi-volume-017c022c-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:14:02.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-chjtd" for this suite.
May 21 07:14:08.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:14:08.226: INFO: namespace: e2e-tests-downward-api-chjtd, resource: bindings, ignored listing per whitelist
May 21 07:14:08.260: INFO: namespace e2e-tests-downward-api-chjtd deletion completed in 6.062788649s

• [SLOW TEST:8.135 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:14:08.261: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 07:14:08.306: INFO: Waiting up to 5m0s for pod "pod-065572bd-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-s86m8" to be "success or failure"
May 21 07:14:08.309: INFO: Pod "pod-065572bd-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.086718ms
May 21 07:14:10.311: INFO: Pod "pod-065572bd-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005379789s
STEP: Saw pod success
May 21 07:14:10.311: INFO: Pod "pod-065572bd-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:14:10.313: INFO: Trying to get logs from node 192.168.5.21 pod pod-065572bd-7b98-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:14:10.326: INFO: Waiting for pod pod-065572bd-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:14:10.329: INFO: Pod pod-065572bd-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:14:10.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s86m8" for this suite.
May 21 07:14:16.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:14:16.378: INFO: namespace: e2e-tests-emptydir-s86m8, resource: bindings, ignored listing per whitelist
May 21 07:14:16.405: INFO: namespace e2e-tests-emptydir-s86m8 deletion completed in 6.071286745s

• [SLOW TEST:8.144 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:14:16.405: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0521 07:14:56.475437      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 07:14:56.475: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:14:56.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8mdpx" for this suite.
May 21 07:15:02.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:15:02.509: INFO: namespace: e2e-tests-gc-8mdpx, resource: bindings, ignored listing per whitelist
May 21 07:15:02.592: INFO: namespace e2e-tests-gc-8mdpx deletion completed in 6.115305145s

• [SLOW TEST:46.187 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:15:02.593: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-26bdeace-7b98-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:15:02.684: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-qzfk9" to be "success or failure"
May 21 07:15:02.686: INFO: Pod "pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.99013ms
May 21 07:15:04.692: INFO: Pod "pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007297591s
May 21 07:15:06.697: INFO: Pod "pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012635712s
May 21 07:15:08.700: INFO: Pod "pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015180154s
STEP: Saw pod success
May 21 07:15:08.700: INFO: Pod "pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:15:08.702: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:15:08.717: INFO: Waiting for pod pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:15:08.719: INFO: Pod pod-projected-configmaps-26be9084-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:15:08.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qzfk9" for this suite.
May 21 07:15:14.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:15:14.778: INFO: namespace: e2e-tests-projected-qzfk9, resource: bindings, ignored listing per whitelist
May 21 07:15:14.797: INFO: namespace e2e-tests-projected-qzfk9 deletion completed in 6.074844156s

• [SLOW TEST:12.204 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:15:14.797: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
May 21 07:15:14.836: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-151895369 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:15:14.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w7k74" for this suite.
May 21 07:15:20.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:15:20.944: INFO: namespace: e2e-tests-kubectl-w7k74, resource: bindings, ignored listing per whitelist
May 21 07:15:20.971: INFO: namespace e2e-tests-kubectl-w7k74 deletion completed in 6.063272596s

• [SLOW TEST:6.174 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:15:20.971: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:15:21.018: INFO: Waiting up to 5m0s for pod "downwardapi-volume-31ac434a-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-bx4fn" to be "success or failure"
May 21 07:15:21.024: INFO: Pod "downwardapi-volume-31ac434a-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.226138ms
May 21 07:15:23.026: INFO: Pod "downwardapi-volume-31ac434a-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007795041s
STEP: Saw pod success
May 21 07:15:23.026: INFO: Pod "downwardapi-volume-31ac434a-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:15:23.028: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-31ac434a-7b98-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:15:23.041: INFO: Waiting for pod downwardapi-volume-31ac434a-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:15:23.043: INFO: Pod downwardapi-volume-31ac434a-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:15:23.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bx4fn" for this suite.
May 21 07:15:29.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:15:29.101: INFO: namespace: e2e-tests-projected-bx4fn, resource: bindings, ignored listing per whitelist
May 21 07:15:29.110: INFO: namespace e2e-tests-projected-bx4fn deletion completed in 6.064876932s

• [SLOW TEST:8.139 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:15:29.110: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:15:50.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-2qt8f" for this suite.
May 21 07:15:56.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:15:56.343: INFO: namespace: e2e-tests-container-runtime-2qt8f, resource: bindings, ignored listing per whitelist
May 21 07:15:56.363: INFO: namespace e2e-tests-container-runtime-2qt8f deletion completed in 6.060869615s

• [SLOW TEST:27.252 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:15:56.363: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-46c416e5-7b98-11e9-8b08-72649ad3cdd7
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-46c416e5-7b98-11e9-8b08-72649ad3cdd7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:16:00.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gqbvn" for this suite.
May 21 07:16:22.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:16:22.471: INFO: namespace: e2e-tests-projected-gqbvn, resource: bindings, ignored listing per whitelist
May 21 07:16:22.516: INFO: namespace e2e-tests-projected-gqbvn deletion completed in 22.063482497s

• [SLOW TEST:26.153 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:16:22.516: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6rhnq
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-6rhnq
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-6rhnq
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-6rhnq
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-6rhnq
May 21 07:16:24.597: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6rhnq, name: ss-0, uid: 57366e51-7b98-11e9-8844-fa163e715483, status phase: Pending. Waiting for statefulset controller to delete.
May 21 07:16:24.983: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6rhnq, name: ss-0, uid: 57366e51-7b98-11e9-8844-fa163e715483, status phase: Failed. Waiting for statefulset controller to delete.
May 21 07:16:24.987: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-6rhnq, name: ss-0, uid: 57366e51-7b98-11e9-8844-fa163e715483, status phase: Failed. Waiting for statefulset controller to delete.
May 21 07:16:24.989: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-6rhnq
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-6rhnq
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-6rhnq and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 07:16:29.009: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6rhnq
May 21 07:16:29.011: INFO: Scaling statefulset ss to 0
May 21 07:16:39.026: INFO: Waiting for statefulset status.replicas updated to 0
May 21 07:16:39.028: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:16:39.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6rhnq" for this suite.
May 21 07:16:45.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:16:45.062: INFO: namespace: e2e-tests-statefulset-6rhnq, resource: bindings, ignored listing per whitelist
May 21 07:16:45.099: INFO: namespace e2e-tests-statefulset-6rhnq deletion completed in 6.060929802s

• [SLOW TEST:22.583 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:16:45.100: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 07:16:45.148: INFO: Waiting up to 5m0s for pod "pod-63d18935-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-zmfs8" to be "success or failure"
May 21 07:16:45.151: INFO: Pod "pod-63d18935-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.610842ms
May 21 07:16:47.154: INFO: Pod "pod-63d18935-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005446239s
May 21 07:16:49.160: INFO: Pod "pod-63d18935-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011177644s
STEP: Saw pod success
May 21 07:16:49.160: INFO: Pod "pod-63d18935-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:16:49.161: INFO: Trying to get logs from node 192.168.5.21 pod pod-63d18935-7b98-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:16:49.173: INFO: Waiting for pod pod-63d18935-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:16:49.174: INFO: Pod pod-63d18935-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:16:49.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zmfs8" for this suite.
May 21 07:16:55.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:16:55.228: INFO: namespace: e2e-tests-emptydir-zmfs8, resource: bindings, ignored listing per whitelist
May 21 07:16:55.233: INFO: namespace e2e-tests-emptydir-zmfs8 deletion completed in 6.056567493s

• [SLOW TEST:10.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:16:55.233: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:16:57.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-2j9v5" for this suite.
May 21 07:17:35.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:17:35.311: INFO: namespace: e2e-tests-kubelet-test-2j9v5, resource: bindings, ignored listing per whitelist
May 21 07:17:35.352: INFO: namespace e2e-tests-kubelet-test-2j9v5 deletion completed in 38.065854606s

• [SLOW TEST:40.118 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:17:35.352: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:17:35.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81c6cc91-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-hvdlj" to be "success or failure"
May 21 07:17:35.412: INFO: Pod "downwardapi-volume-81c6cc91-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.310612ms
May 21 07:17:37.415: INFO: Pod "downwardapi-volume-81c6cc91-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005126658s
STEP: Saw pod success
May 21 07:17:37.415: INFO: Pod "downwardapi-volume-81c6cc91-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:17:37.417: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-81c6cc91-7b98-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:17:37.429: INFO: Waiting for pod downwardapi-volume-81c6cc91-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:17:37.430: INFO: Pod downwardapi-volume-81c6cc91-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:17:37.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hvdlj" for this suite.
May 21 07:17:43.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:17:43.468: INFO: namespace: e2e-tests-projected-hvdlj, resource: bindings, ignored listing per whitelist
May 21 07:17:43.497: INFO: namespace e2e-tests-projected-hvdlj deletion completed in 6.061940584s

• [SLOW TEST:8.145 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:17:43.497: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:17:43.544: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86a009aa-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-s8ckx" to be "success or failure"
May 21 07:17:43.546: INFO: Pod "downwardapi-volume-86a009aa-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.393593ms
May 21 07:17:45.552: INFO: Pod "downwardapi-volume-86a009aa-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007937124s
STEP: Saw pod success
May 21 07:17:45.552: INFO: Pod "downwardapi-volume-86a009aa-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:17:45.553: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-86a009aa-7b98-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:17:45.566: INFO: Waiting for pod downwardapi-volume-86a009aa-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:17:45.569: INFO: Pod downwardapi-volume-86a009aa-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:17:45.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s8ckx" for this suite.
May 21 07:17:51.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:17:51.614: INFO: namespace: e2e-tests-downward-api-s8ckx, resource: bindings, ignored listing per whitelist
May 21 07:17:51.631: INFO: namespace e2e-tests-downward-api-s8ckx deletion completed in 6.059132249s

• [SLOW TEST:8.134 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:17:51.631: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-47wvl.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-47wvl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-47wvl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-47wvl.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-47wvl.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-47wvl.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 07:18:19.738: INFO: DNS probes using e2e-tests-dns-47wvl/dns-test-8b7a7925-7b98-11e9-8b08-72649ad3cdd7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:18:19.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-47wvl" for this suite.
May 21 07:18:25.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:18:25.780: INFO: namespace: e2e-tests-dns-47wvl, resource: bindings, ignored listing per whitelist
May 21 07:18:25.812: INFO: namespace e2e-tests-dns-47wvl deletion completed in 6.062941668s

• [SLOW TEST:34.181 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:18:25.813: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
May 21 07:18:25.900: INFO: Waiting up to 5m0s for pod "client-containers-9fdcb056-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-containers-8c8kr" to be "success or failure"
May 21 07:18:25.902: INFO: Pod "client-containers-9fdcb056-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.819779ms
May 21 07:18:27.904: INFO: Pod "client-containers-9fdcb056-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00443056s
May 21 07:18:29.910: INFO: Pod "client-containers-9fdcb056-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010520459s
STEP: Saw pod success
May 21 07:18:29.910: INFO: Pod "client-containers-9fdcb056-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:18:29.912: INFO: Trying to get logs from node 192.168.5.21 pod client-containers-9fdcb056-7b98-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:18:29.927: INFO: Waiting for pod client-containers-9fdcb056-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:18:29.928: INFO: Pod client-containers-9fdcb056-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:18:29.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8c8kr" for this suite.
May 21 07:18:35.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:18:35.967: INFO: namespace: e2e-tests-containers-8c8kr, resource: bindings, ignored listing per whitelist
May 21 07:18:35.989: INFO: namespace e2e-tests-containers-8c8kr deletion completed in 6.057780444s

• [SLOW TEST:10.176 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:18:35.989: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 21 07:18:36.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:36.334: INFO: stderr: ""
May 21 07:18:36.334: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:18:36.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:36.409: INFO: stderr: ""
May 21 07:18:36.409: INFO: stdout: "update-demo-nautilus-ddr88 update-demo-nautilus-l6lfb "
May 21 07:18:36.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-ddr88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:36.474: INFO: stderr: ""
May 21 07:18:36.474: INFO: stdout: ""
May 21 07:18:36.474: INFO: update-demo-nautilus-ddr88 is created but not running
May 21 07:18:41.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:41.545: INFO: stderr: ""
May 21 07:18:41.545: INFO: stdout: "update-demo-nautilus-ddr88 update-demo-nautilus-l6lfb "
May 21 07:18:41.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-ddr88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:41.613: INFO: stderr: ""
May 21 07:18:41.613: INFO: stdout: "true"
May 21 07:18:41.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-ddr88 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:41.678: INFO: stderr: ""
May 21 07:18:41.678: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:18:41.678: INFO: validating pod update-demo-nautilus-ddr88
May 21 07:18:41.681: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:18:41.681: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:18:41.681: INFO: update-demo-nautilus-ddr88 is verified up and running
May 21 07:18:41.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-l6lfb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:41.742: INFO: stderr: ""
May 21 07:18:41.742: INFO: stdout: "true"
May 21 07:18:41.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-l6lfb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:41.813: INFO: stderr: ""
May 21 07:18:41.813: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:18:41.813: INFO: validating pod update-demo-nautilus-l6lfb
May 21 07:18:41.816: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:18:41.816: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:18:41.816: INFO: update-demo-nautilus-l6lfb is verified up and running
STEP: scaling down the replication controller
May 21 07:18:41.817: INFO: scanned /root for discovery docs: <nil>
May 21 07:18:41.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:42.905: INFO: stderr: ""
May 21 07:18:42.905: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:18:42.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:42.978: INFO: stderr: ""
May 21 07:18:42.978: INFO: stdout: "update-demo-nautilus-ddr88 update-demo-nautilus-l6lfb "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 21 07:18:47.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:48.060: INFO: stderr: ""
May 21 07:18:48.060: INFO: stdout: "update-demo-nautilus-ddr88 update-demo-nautilus-l6lfb "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 21 07:18:53.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:53.137: INFO: stderr: ""
May 21 07:18:53.137: INFO: stdout: "update-demo-nautilus-ddr88 update-demo-nautilus-l6lfb "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 21 07:18:58.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:58.212: INFO: stderr: ""
May 21 07:18:58.212: INFO: stdout: "update-demo-nautilus-ddr88 "
May 21 07:18:58.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-ddr88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:58.279: INFO: stderr: ""
May 21 07:18:58.279: INFO: stdout: "true"
May 21 07:18:58.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-ddr88 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:58.344: INFO: stderr: ""
May 21 07:18:58.344: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:18:58.344: INFO: validating pod update-demo-nautilus-ddr88
May 21 07:18:58.346: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:18:58.346: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:18:58.346: INFO: update-demo-nautilus-ddr88 is verified up and running
STEP: scaling up the replication controller
May 21 07:18:58.347: INFO: scanned /root for discovery docs: <nil>
May 21 07:18:58.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:59.436: INFO: stderr: ""
May 21 07:18:59.436: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:18:59.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:59.505: INFO: stderr: ""
May 21 07:18:59.505: INFO: stdout: "update-demo-nautilus-ddr88 update-demo-nautilus-kfwsh "
May 21 07:18:59.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-ddr88 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:59.565: INFO: stderr: ""
May 21 07:18:59.565: INFO: stdout: "true"
May 21 07:18:59.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-ddr88 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:59.632: INFO: stderr: ""
May 21 07:18:59.632: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:18:59.632: INFO: validating pod update-demo-nautilus-ddr88
May 21 07:18:59.634: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:18:59.634: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:18:59.634: INFO: update-demo-nautilus-ddr88 is verified up and running
May 21 07:18:59.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-kfwsh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:59.705: INFO: stderr: ""
May 21 07:18:59.705: INFO: stdout: "true"
May 21 07:18:59.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-kfwsh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:59.761: INFO: stderr: ""
May 21 07:18:59.761: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:18:59.761: INFO: validating pod update-demo-nautilus-kfwsh
May 21 07:18:59.764: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:18:59.764: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:18:59.764: INFO: update-demo-nautilus-kfwsh is verified up and running
STEP: using delete to clean up resources
May 21 07:18:59.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:59.823: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:18:59.823: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 21 07:18:59.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-h8nj9'
May 21 07:18:59.913: INFO: stderr: "No resources found.\n"
May 21 07:18:59.913: INFO: stdout: ""
May 21 07:18:59.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -l name=update-demo --namespace=e2e-tests-kubectl-h8nj9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 07:18:59.984: INFO: stderr: ""
May 21 07:18:59.984: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:18:59.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h8nj9" for this suite.
May 21 07:19:21.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:19:22.015: INFO: namespace: e2e-tests-kubectl-h8nj9, resource: bindings, ignored listing per whitelist
May 21 07:19:22.064: INFO: namespace e2e-tests-kubectl-h8nj9 deletion completed in 22.077139302s

• [SLOW TEST:46.075 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:19:22.064: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 21 07:19:22.117: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bj7s4,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj7s4/configmaps/e2e-watch-test-label-changed,UID:c160617d-7b98-11e9-926e-fa163e6dedea,ResourceVersion:18057,Generation:0,CreationTimestamp:2019-05-21 07:19:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 07:19:22.117: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bj7s4,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj7s4/configmaps/e2e-watch-test-label-changed,UID:c160617d-7b98-11e9-926e-fa163e6dedea,ResourceVersion:18058,Generation:0,CreationTimestamp:2019-05-21 07:19:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 21 07:19:22.117: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bj7s4,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj7s4/configmaps/e2e-watch-test-label-changed,UID:c160617d-7b98-11e9-926e-fa163e6dedea,ResourceVersion:18059,Generation:0,CreationTimestamp:2019-05-21 07:19:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 21 07:19:32.136: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bj7s4,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj7s4/configmaps/e2e-watch-test-label-changed,UID:c160617d-7b98-11e9-926e-fa163e6dedea,ResourceVersion:18075,Generation:0,CreationTimestamp:2019-05-21 07:19:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 07:19:32.136: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bj7s4,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj7s4/configmaps/e2e-watch-test-label-changed,UID:c160617d-7b98-11e9-926e-fa163e6dedea,ResourceVersion:18076,Generation:0,CreationTimestamp:2019-05-21 07:19:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 21 07:19:32.137: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-bj7s4,SelfLink:/api/v1/namespaces/e2e-tests-watch-bj7s4/configmaps/e2e-watch-test-label-changed,UID:c160617d-7b98-11e9-926e-fa163e6dedea,ResourceVersion:18077,Generation:0,CreationTimestamp:2019-05-21 07:19:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:19:32.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-bj7s4" for this suite.
May 21 07:19:38.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:19:38.166: INFO: namespace: e2e-tests-watch-bj7s4, resource: bindings, ignored listing per whitelist
May 21 07:19:38.198: INFO: namespace e2e-tests-watch-bj7s4 deletion completed in 6.057869141s

• [SLOW TEST:16.134 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:19:38.198: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 07:19:38.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-62lmx'
May 21 07:19:38.342: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 07:19:38.342: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
May 21 07:19:40.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-62lmx'
May 21 07:19:40.424: INFO: stderr: ""
May 21 07:19:40.424: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:19:40.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-62lmx" for this suite.
May 21 07:20:02.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:20:02.466: INFO: namespace: e2e-tests-kubectl-62lmx, resource: bindings, ignored listing per whitelist
May 21 07:20:02.489: INFO: namespace e2e-tests-kubectl-62lmx deletion completed in 22.061737425s

• [SLOW TEST:24.291 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:20:02.489: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
May 21 07:20:02.538: INFO: Waiting up to 5m0s for pod "var-expansion-d978bc19-7b98-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-var-expansion-h9rc9" to be "success or failure"
May 21 07:20:02.540: INFO: Pod "var-expansion-d978bc19-7b98-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.623156ms
May 21 07:20:04.546: INFO: Pod "var-expansion-d978bc19-7b98-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008100021s
STEP: Saw pod success
May 21 07:20:04.546: INFO: Pod "var-expansion-d978bc19-7b98-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:20:04.547: INFO: Trying to get logs from node 192.168.5.21 pod var-expansion-d978bc19-7b98-11e9-8b08-72649ad3cdd7 container dapi-container: <nil>
STEP: delete the pod
May 21 07:20:04.563: INFO: Waiting for pod var-expansion-d978bc19-7b98-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:20:04.566: INFO: Pod var-expansion-d978bc19-7b98-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:20:04.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-h9rc9" for this suite.
May 21 07:20:10.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:20:10.618: INFO: namespace: e2e-tests-var-expansion-h9rc9, resource: bindings, ignored listing per whitelist
May 21 07:20:10.632: INFO: namespace e2e-tests-var-expansion-h9rc9 deletion completed in 6.062704761s

• [SLOW TEST:8.143 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:20:10.632: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-k4mt6
May 21 07:20:12.680: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-k4mt6
STEP: checking the pod's current state and verifying that restartCount is present
May 21 07:20:12.681: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:24:13.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-k4mt6" for this suite.
May 21 07:24:19.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:24:19.179: INFO: namespace: e2e-tests-container-probe-k4mt6, resource: bindings, ignored listing per whitelist
May 21 07:24:19.191: INFO: namespace e2e-tests-container-probe-k4mt6 deletion completed in 6.06279386s

• [SLOW TEST:248.559 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:24:19.191: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 21 07:24:19.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:19.400: INFO: stderr: ""
May 21 07:24:19.400: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:24:19.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:19.470: INFO: stderr: ""
May 21 07:24:19.470: INFO: stdout: "update-demo-nautilus-sgwxx update-demo-nautilus-tts5j "
May 21 07:24:19.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-sgwxx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:19.533: INFO: stderr: ""
May 21 07:24:19.533: INFO: stdout: ""
May 21 07:24:19.533: INFO: update-demo-nautilus-sgwxx is created but not running
May 21 07:24:24.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:24.626: INFO: stderr: ""
May 21 07:24:24.626: INFO: stdout: "update-demo-nautilus-sgwxx update-demo-nautilus-tts5j "
May 21 07:24:24.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-sgwxx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:24.696: INFO: stderr: ""
May 21 07:24:24.696: INFO: stdout: "true"
May 21 07:24:24.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-sgwxx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:24.756: INFO: stderr: ""
May 21 07:24:24.756: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:24:24.756: INFO: validating pod update-demo-nautilus-sgwxx
May 21 07:24:24.759: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:24:24.760: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:24:24.760: INFO: update-demo-nautilus-sgwxx is verified up and running
May 21 07:24:24.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-tts5j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:24.831: INFO: stderr: ""
May 21 07:24:24.831: INFO: stdout: "true"
May 21 07:24:24.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-tts5j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:24.897: INFO: stderr: ""
May 21 07:24:24.897: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:24:24.897: INFO: validating pod update-demo-nautilus-tts5j
May 21 07:24:24.900: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:24:24.900: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:24:24.900: INFO: update-demo-nautilus-tts5j is verified up and running
STEP: using delete to clean up resources
May 21 07:24:24.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:24.966: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:24:24.966: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 21 07:24:24.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-554g7'
May 21 07:24:25.069: INFO: stderr: "No resources found.\n"
May 21 07:24:25.069: INFO: stdout: ""
May 21 07:24:25.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -l name=update-demo --namespace=e2e-tests-kubectl-554g7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 07:24:25.153: INFO: stderr: ""
May 21 07:24:25.153: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:24:25.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-554g7" for this suite.
May 21 07:24:31.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:24:31.200: INFO: namespace: e2e-tests-kubectl-554g7, resource: bindings, ignored listing per whitelist
May 21 07:24:31.218: INFO: namespace e2e-tests-kubectl-554g7 deletion completed in 6.058589791s

• [SLOW TEST:12.027 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:24:31.218: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:24:31.272: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 21 07:24:31.281: INFO: Number of nodes with available pods: 0
May 21 07:24:31.281: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 21 07:24:31.291: INFO: Number of nodes with available pods: 0
May 21 07:24:31.291: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:32.293: INFO: Number of nodes with available pods: 0
May 21 07:24:32.293: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:33.293: INFO: Number of nodes with available pods: 1
May 21 07:24:33.293: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 21 07:24:33.304: INFO: Number of nodes with available pods: 1
May 21 07:24:33.304: INFO: Number of running nodes: 0, number of available pods: 1
May 21 07:24:34.311: INFO: Number of nodes with available pods: 0
May 21 07:24:34.311: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 21 07:24:34.324: INFO: Number of nodes with available pods: 0
May 21 07:24:34.324: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:35.329: INFO: Number of nodes with available pods: 0
May 21 07:24:35.329: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:36.327: INFO: Number of nodes with available pods: 0
May 21 07:24:36.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:37.327: INFO: Number of nodes with available pods: 0
May 21 07:24:37.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:38.327: INFO: Number of nodes with available pods: 0
May 21 07:24:38.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:39.327: INFO: Number of nodes with available pods: 0
May 21 07:24:39.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:40.327: INFO: Number of nodes with available pods: 0
May 21 07:24:40.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:41.327: INFO: Number of nodes with available pods: 0
May 21 07:24:41.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:42.327: INFO: Number of nodes with available pods: 0
May 21 07:24:42.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:43.327: INFO: Number of nodes with available pods: 0
May 21 07:24:43.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:44.329: INFO: Number of nodes with available pods: 0
May 21 07:24:44.329: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:45.328: INFO: Number of nodes with available pods: 0
May 21 07:24:45.328: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:46.330: INFO: Number of nodes with available pods: 0
May 21 07:24:46.330: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:47.327: INFO: Number of nodes with available pods: 0
May 21 07:24:47.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:48.327: INFO: Number of nodes with available pods: 0
May 21 07:24:48.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:49.327: INFO: Number of nodes with available pods: 0
May 21 07:24:49.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:50.327: INFO: Number of nodes with available pods: 0
May 21 07:24:50.328: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:51.327: INFO: Number of nodes with available pods: 0
May 21 07:24:51.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:52.327: INFO: Number of nodes with available pods: 0
May 21 07:24:52.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:53.327: INFO: Number of nodes with available pods: 0
May 21 07:24:53.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:54.327: INFO: Number of nodes with available pods: 0
May 21 07:24:54.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:55.327: INFO: Number of nodes with available pods: 0
May 21 07:24:55.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:56.327: INFO: Number of nodes with available pods: 0
May 21 07:24:56.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:57.330: INFO: Number of nodes with available pods: 0
May 21 07:24:57.330: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:58.327: INFO: Number of nodes with available pods: 0
May 21 07:24:58.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:24:59.327: INFO: Number of nodes with available pods: 0
May 21 07:24:59.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:00.327: INFO: Number of nodes with available pods: 0
May 21 07:25:00.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:01.327: INFO: Number of nodes with available pods: 0
May 21 07:25:01.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:02.327: INFO: Number of nodes with available pods: 0
May 21 07:25:02.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:03.327: INFO: Number of nodes with available pods: 0
May 21 07:25:03.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:04.328: INFO: Number of nodes with available pods: 0
May 21 07:25:04.328: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:05.327: INFO: Number of nodes with available pods: 0
May 21 07:25:05.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:06.327: INFO: Number of nodes with available pods: 0
May 21 07:25:06.327: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:07.329: INFO: Number of nodes with available pods: 0
May 21 07:25:07.329: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:25:08.331: INFO: Number of nodes with available pods: 1
May 21 07:25:08.331: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-2dw6h, will wait for the garbage collector to delete the pods
May 21 07:25:08.416: INFO: Deleting DaemonSet.extensions daemon-set took: 20.648843ms
May 21 07:25:08.516: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.187213ms
May 21 07:25:42.122: INFO: Number of nodes with available pods: 0
May 21 07:25:42.122: INFO: Number of running nodes: 0, number of available pods: 0
May 21 07:25:42.124: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2dw6h/daemonsets","resourceVersion":"18807"},"items":null}

May 21 07:25:42.126: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2dw6h/pods","resourceVersion":"18807"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:25:42.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2dw6h" for this suite.
May 21 07:25:48.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:25:48.157: INFO: namespace: e2e-tests-daemonsets-2dw6h, resource: bindings, ignored listing per whitelist
May 21 07:25:48.210: INFO: namespace e2e-tests-daemonsets-2dw6h deletion completed in 6.068430168s

• [SLOW TEST:76.991 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:25:48.210: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-9qm2b/configmap-test-a78936d8-7b99-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:25:48.258: INFO: Waiting up to 5m0s for pod "pod-configmaps-a789c1bc-7b99-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-9qm2b" to be "success or failure"
May 21 07:25:48.261: INFO: Pod "pod-configmaps-a789c1bc-7b99-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.198762ms
May 21 07:25:50.263: INFO: Pod "pod-configmaps-a789c1bc-7b99-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004868127s
STEP: Saw pod success
May 21 07:25:50.263: INFO: Pod "pod-configmaps-a789c1bc-7b99-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:25:50.265: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-a789c1bc-7b99-11e9-8b08-72649ad3cdd7 container env-test: <nil>
STEP: delete the pod
May 21 07:25:50.279: INFO: Waiting for pod pod-configmaps-a789c1bc-7b99-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:25:50.281: INFO: Pod pod-configmaps-a789c1bc-7b99-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:25:50.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9qm2b" for this suite.
May 21 07:25:56.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:25:56.310: INFO: namespace: e2e-tests-configmap-9qm2b, resource: bindings, ignored listing per whitelist
May 21 07:25:56.349: INFO: namespace e2e-tests-configmap-9qm2b deletion completed in 6.064996993s

• [SLOW TEST:8.139 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:25:56.349: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-ac62a358-7b99-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:25:56.394: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ac632adc-7b99-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-shw6v" to be "success or failure"
May 21 07:25:56.396: INFO: Pod "pod-projected-configmaps-ac632adc-7b99-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.256106ms
May 21 07:25:58.402: INFO: Pod "pod-projected-configmaps-ac632adc-7b99-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008173346s
STEP: Saw pod success
May 21 07:25:58.402: INFO: Pod "pod-projected-configmaps-ac632adc-7b99-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:25:58.404: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-ac632adc-7b99-11e9-8b08-72649ad3cdd7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:25:58.423: INFO: Waiting for pod pod-projected-configmaps-ac632adc-7b99-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:25:58.425: INFO: Pod pod-projected-configmaps-ac632adc-7b99-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:25:58.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-shw6v" for this suite.
May 21 07:26:04.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:26:04.474: INFO: namespace: e2e-tests-projected-shw6v, resource: bindings, ignored listing per whitelist
May 21 07:26:04.497: INFO: namespace e2e-tests-projected-shw6v deletion completed in 6.066734048s

• [SLOW TEST:8.148 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:26:04.498: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b13eb0ab-7b99-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:26:04.547: INFO: Waiting up to 5m0s for pod "pod-secrets-b13f3945-7b99-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-jgtlt" to be "success or failure"
May 21 07:26:04.548: INFO: Pod "pod-secrets-b13f3945-7b99-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.73972ms
May 21 07:26:06.552: INFO: Pod "pod-secrets-b13f3945-7b99-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004943909s
STEP: Saw pod success
May 21 07:26:06.552: INFO: Pod "pod-secrets-b13f3945-7b99-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:26:06.553: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-b13f3945-7b99-11e9-8b08-72649ad3cdd7 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:26:06.565: INFO: Waiting for pod pod-secrets-b13f3945-7b99-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:26:06.567: INFO: Pod pod-secrets-b13f3945-7b99-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:26:06.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jgtlt" for this suite.
May 21 07:26:12.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:26:12.625: INFO: namespace: e2e-tests-secrets-jgtlt, resource: bindings, ignored listing per whitelist
May 21 07:26:12.634: INFO: namespace e2e-tests-secrets-jgtlt deletion completed in 6.064774879s

• [SLOW TEST:8.137 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:26:12.634: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-pdw7j
May 21 07:26:14.682: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-pdw7j
STEP: checking the pod's current state and verifying that restartCount is present
May 21 07:26:14.684: INFO: Initial restart count of pod liveness-exec is 0
May 21 07:27:02.774: INFO: Restart count of pod e2e-tests-container-probe-pdw7j/liveness-exec is now 1 (48.090234256s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:27:02.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pdw7j" for this suite.
May 21 07:27:08.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:27:08.854: INFO: namespace: e2e-tests-container-probe-pdw7j, resource: bindings, ignored listing per whitelist
May 21 07:27:08.855: INFO: namespace e2e-tests-container-probe-pdw7j deletion completed in 6.063180385s

• [SLOW TEST:56.221 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:27:08.855: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d79b3b33-7b99-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:27:08.907: INFO: Waiting up to 5m0s for pod "pod-configmaps-d79bbcd9-7b99-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-9grmm" to be "success or failure"
May 21 07:27:08.910: INFO: Pod "pod-configmaps-d79bbcd9-7b99-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.476318ms
May 21 07:27:10.914: INFO: Pod "pod-configmaps-d79bbcd9-7b99-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006900834s
STEP: Saw pod success
May 21 07:27:10.914: INFO: Pod "pod-configmaps-d79bbcd9-7b99-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:27:10.915: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-d79bbcd9-7b99-11e9-8b08-72649ad3cdd7 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:27:10.929: INFO: Waiting for pod pod-configmaps-d79bbcd9-7b99-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:27:10.931: INFO: Pod pod-configmaps-d79bbcd9-7b99-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:27:10.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9grmm" for this suite.
May 21 07:27:16.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:27:16.985: INFO: namespace: e2e-tests-configmap-9grmm, resource: bindings, ignored listing per whitelist
May 21 07:27:17.003: INFO: namespace e2e-tests-configmap-9grmm deletion completed in 6.069586387s

• [SLOW TEST:8.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:27:17.003: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:28:17.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-t7thj" for this suite.
May 21 07:28:39.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:28:39.084: INFO: namespace: e2e-tests-container-probe-t7thj, resource: bindings, ignored listing per whitelist
May 21 07:28:39.117: INFO: namespace e2e-tests-container-probe-t7thj deletion completed in 22.060403257s

• [SLOW TEST:82.114 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:28:39.118: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 21 07:28:47.194: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 07:28:47.196: INFO: Pod pod-with-poststart-http-hook still exists
May 21 07:28:49.196: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 07:28:49.199: INFO: Pod pod-with-poststart-http-hook still exists
May 21 07:28:51.196: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 07:28:51.199: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:28:51.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9xzs2" for this suite.
May 21 07:29:13.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:29:13.236: INFO: namespace: e2e-tests-container-lifecycle-hook-9xzs2, resource: bindings, ignored listing per whitelist
May 21 07:29:13.263: INFO: namespace e2e-tests-container-lifecycle-hook-9xzs2 deletion completed in 22.059029776s

• [SLOW TEST:34.145 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:29:13.263: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 21 07:29:13.308: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-58khv,SelfLink:/api/v1/namespaces/e2e-tests-watch-58khv/configmaps/e2e-watch-test-watch-closed,UID:21c169a2-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19355,Generation:0,CreationTimestamp:2019-05-21 07:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 07:29:13.308: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-58khv,SelfLink:/api/v1/namespaces/e2e-tests-watch-58khv/configmaps/e2e-watch-test-watch-closed,UID:21c169a2-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19356,Generation:0,CreationTimestamp:2019-05-21 07:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 21 07:29:13.315: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-58khv,SelfLink:/api/v1/namespaces/e2e-tests-watch-58khv/configmaps/e2e-watch-test-watch-closed,UID:21c169a2-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19357,Generation:0,CreationTimestamp:2019-05-21 07:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 07:29:13.315: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-58khv,SelfLink:/api/v1/namespaces/e2e-tests-watch-58khv/configmaps/e2e-watch-test-watch-closed,UID:21c169a2-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19358,Generation:0,CreationTimestamp:2019-05-21 07:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:29:13.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-58khv" for this suite.
May 21 07:29:19.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:29:19.337: INFO: namespace: e2e-tests-watch-58khv, resource: bindings, ignored listing per whitelist
May 21 07:29:19.378: INFO: namespace e2e-tests-watch-58khv deletion completed in 6.060581904s

• [SLOW TEST:6.115 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:29:19.378: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:29:19.416: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:29:25.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-lqfgr" for this suite.
May 21 07:29:31.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:29:31.487: INFO: namespace: e2e-tests-custom-resource-definition-lqfgr, resource: bindings, ignored listing per whitelist
May 21 07:29:31.503: INFO: namespace e2e-tests-custom-resource-definition-lqfgr deletion completed in 6.059501285s

• [SLOW TEST:12.125 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:29:31.504: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 07:29:31.552: INFO: Waiting up to 5m0s for pod "pod-2ca1727b-7b9a-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-88vgf" to be "success or failure"
May 21 07:29:31.557: INFO: Pod "pod-2ca1727b-7b9a-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.176593ms
May 21 07:29:33.562: INFO: Pod "pod-2ca1727b-7b9a-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010542414s
STEP: Saw pod success
May 21 07:29:33.562: INFO: Pod "pod-2ca1727b-7b9a-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:29:33.565: INFO: Trying to get logs from node 192.168.5.21 pod pod-2ca1727b-7b9a-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:29:33.580: INFO: Waiting for pod pod-2ca1727b-7b9a-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:29:33.582: INFO: Pod pod-2ca1727b-7b9a-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:29:33.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-88vgf" for this suite.
May 21 07:29:39.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:29:39.612: INFO: namespace: e2e-tests-emptydir-88vgf, resource: bindings, ignored listing per whitelist
May 21 07:29:39.649: INFO: namespace e2e-tests-emptydir-88vgf deletion completed in 6.064519489s

• [SLOW TEST:8.145 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:29:39.649: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 21 07:29:39.693: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-a,UID:317bee20-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19451,Generation:0,CreationTimestamp:2019-05-21 07:29:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 07:29:39.693: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-a,UID:317bee20-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19451,Generation:0,CreationTimestamp:2019-05-21 07:29:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 21 07:29:49.700: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-a,UID:317bee20-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19466,Generation:0,CreationTimestamp:2019-05-21 07:29:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 21 07:29:49.700: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-a,UID:317bee20-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19466,Generation:0,CreationTimestamp:2019-05-21 07:29:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 21 07:29:59.707: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-a,UID:317bee20-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19481,Generation:0,CreationTimestamp:2019-05-21 07:29:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 07:29:59.707: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-a,UID:317bee20-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19481,Generation:0,CreationTimestamp:2019-05-21 07:29:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 21 07:30:09.714: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-a,UID:317bee20-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19497,Generation:0,CreationTimestamp:2019-05-21 07:29:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 07:30:09.714: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-a,UID:317bee20-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19497,Generation:0,CreationTimestamp:2019-05-21 07:29:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 21 07:30:19.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-b,UID:495844f3-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19512,Generation:0,CreationTimestamp:2019-05-21 07:30:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 07:30:19.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-b,UID:495844f3-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19512,Generation:0,CreationTimestamp:2019-05-21 07:30:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 21 07:30:29.732: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-b,UID:495844f3-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19528,Generation:0,CreationTimestamp:2019-05-21 07:30:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 07:30:29.732: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-d555x,SelfLink:/api/v1/namespaces/e2e-tests-watch-d555x/configmaps/e2e-watch-test-configmap-b,UID:495844f3-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19528,Generation:0,CreationTimestamp:2019-05-21 07:30:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:30:39.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-d555x" for this suite.
May 21 07:30:45.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:30:45.791: INFO: namespace: e2e-tests-watch-d555x, resource: bindings, ignored listing per whitelist
May 21 07:30:45.803: INFO: namespace e2e-tests-watch-d555x deletion completed in 6.063004454s

• [SLOW TEST:66.154 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:30:45.803: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 21 07:30:45.869: INFO: namespace e2e-tests-kubectl-qrh4h
May 21 07:30:45.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-qrh4h'
May 21 07:30:46.104: INFO: stderr: ""
May 21 07:30:46.104: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 07:30:47.114: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:30:47.114: INFO: Found 1 / 1
May 21 07:30:47.114: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 07:30:47.116: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:30:47.116: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 07:30:47.116: INFO: wait on redis-master startup in e2e-tests-kubectl-qrh4h 
May 21 07:30:47.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 logs redis-master-cpzc8 redis-master --namespace=e2e-tests-kubectl-qrh4h'
May 21 07:30:47.188: INFO: stderr: ""
May 21 07:30:47.188: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 07:30:46.832 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 07:30:46.832 # Server started, Redis version 3.2.12\n1:M 21 May 07:30:46.832 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 07:30:46.832 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 21 07:30:47.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-qrh4h'
May 21 07:30:47.279: INFO: stderr: ""
May 21 07:30:47.279: INFO: stdout: "service/rm2 exposed\n"
May 21 07:30:47.281: INFO: Service rm2 in namespace e2e-tests-kubectl-qrh4h found.
STEP: exposing service
May 21 07:30:49.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-qrh4h'
May 21 07:30:49.364: INFO: stderr: ""
May 21 07:30:49.364: INFO: stdout: "service/rm3 exposed\n"
May 21 07:30:49.366: INFO: Service rm3 in namespace e2e-tests-kubectl-qrh4h found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:30:51.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qrh4h" for this suite.
May 21 07:31:13.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:31:13.432: INFO: namespace: e2e-tests-kubectl-qrh4h, resource: bindings, ignored listing per whitelist
May 21 07:31:13.442: INFO: namespace e2e-tests-kubectl-qrh4h deletion completed in 22.065818153s

• [SLOW TEST:27.639 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:31:13.443: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-k8m89
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k8m89 to expose endpoints map[]
May 21 07:31:13.494: INFO: Get endpoints failed (2.709607ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 21 07:31:14.496: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k8m89 exposes endpoints map[] (1.004631768s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-k8m89
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k8m89 to expose endpoints map[pod1:[100]]
May 21 07:31:15.517: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k8m89 exposes endpoints map[pod1:[100]] (1.012039043s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-k8m89
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k8m89 to expose endpoints map[pod2:[101] pod1:[100]]
May 21 07:31:17.542: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k8m89 exposes endpoints map[pod1:[100] pod2:[101]] (2.022889879s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-k8m89
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k8m89 to expose endpoints map[pod2:[101]]
May 21 07:31:18.556: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k8m89 exposes endpoints map[pod2:[101]] (1.009266575s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-k8m89
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-k8m89 to expose endpoints map[]
May 21 07:31:18.563: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-k8m89 exposes endpoints map[] (1.595503ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:31:18.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-k8m89" for this suite.
May 21 07:31:40.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:31:40.642: INFO: namespace: e2e-tests-services-k8m89, resource: bindings, ignored listing per whitelist
May 21 07:31:40.649: INFO: namespace e2e-tests-services-k8m89 deletion completed in 22.060463857s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.207 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:31:40.649: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:31:40.698: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 21 07:31:45.701: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 07:31:45.701: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 07:31:45.711: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-bhb4z,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bhb4z/deployments/test-cleanup-deployment,UID:7c987f2f-7b9a-11e9-926e-fa163e6dedea,ResourceVersion:19756,Generation:1,CreationTimestamp:2019-05-21 07:31:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

May 21 07:31:45.713: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:31:45.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bhb4z" for this suite.
May 21 07:31:51.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:31:51.736: INFO: namespace: e2e-tests-deployment-bhb4z, resource: bindings, ignored listing per whitelist
May 21 07:31:51.781: INFO: namespace e2e-tests-deployment-bhb4z deletion completed in 6.061337395s

• [SLOW TEST:11.132 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:31:51.782: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0521 07:32:01.847754      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 07:32:01.847: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:32:01.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pvmr6" for this suite.
May 21 07:32:07.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:32:07.899: INFO: namespace: e2e-tests-gc-pvmr6, resource: bindings, ignored listing per whitelist
May 21 07:32:07.911: INFO: namespace e2e-tests-gc-pvmr6 deletion completed in 6.060759152s

• [SLOW TEST:16.129 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:32:07.911: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 21 07:32:07.956: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:32:11.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vkmkq" for this suite.
May 21 07:32:33.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:32:33.777: INFO: namespace: e2e-tests-init-container-vkmkq, resource: bindings, ignored listing per whitelist
May 21 07:32:33.806: INFO: namespace e2e-tests-init-container-vkmkq deletion completed in 22.063012112s

• [SLOW TEST:25.896 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:32:33.807: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 21 07:32:37.874: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:37.874: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:37.987: INFO: Exec stderr: ""
May 21 07:32:37.987: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:37.987: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:38.130: INFO: Exec stderr: ""
May 21 07:32:38.130: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:38.130: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:38.265: INFO: Exec stderr: ""
May 21 07:32:38.265: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:38.265: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:38.412: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 21 07:32:38.412: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:38.412: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:38.565: INFO: Exec stderr: ""
May 21 07:32:38.565: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:38.565: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:38.703: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 21 07:32:38.704: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:38.704: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:38.828: INFO: Exec stderr: ""
May 21 07:32:38.828: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:38.828: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:38.950: INFO: Exec stderr: ""
May 21 07:32:38.950: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:38.950: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:39.088: INFO: Exec stderr: ""
May 21 07:32:39.088: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-p5mbm PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:32:39.088: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:32:39.232: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:32:39.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-p5mbm" for this suite.
May 21 07:33:17.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:33:17.263: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-p5mbm, resource: bindings, ignored listing per whitelist
May 21 07:33:17.297: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-p5mbm deletion completed in 38.061698536s

• [SLOW TEST:43.491 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:33:17.298: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
May 21 07:33:17.338: INFO: Waiting up to 5m0s for pod "client-containers-b335d73c-7b9a-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-containers-h67kr" to be "success or failure"
May 21 07:33:17.340: INFO: Pod "client-containers-b335d73c-7b9a-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.793107ms
May 21 07:33:19.342: INFO: Pod "client-containers-b335d73c-7b9a-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004116943s
STEP: Saw pod success
May 21 07:33:19.342: INFO: Pod "client-containers-b335d73c-7b9a-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:33:19.344: INFO: Trying to get logs from node 192.168.5.21 pod client-containers-b335d73c-7b9a-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:33:19.355: INFO: Waiting for pod client-containers-b335d73c-7b9a-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:33:19.356: INFO: Pod client-containers-b335d73c-7b9a-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:33:19.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-h67kr" for this suite.
May 21 07:33:25.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:33:25.382: INFO: namespace: e2e-tests-containers-h67kr, resource: bindings, ignored listing per whitelist
May 21 07:33:25.417: INFO: namespace e2e-tests-containers-h67kr deletion completed in 6.057508964s

• [SLOW TEST:8.119 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:33:25.417: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
May 21 07:33:25.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:25.616: INFO: stderr: ""
May 21 07:33:25.616: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:33:25.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:25.685: INFO: stderr: ""
May 21 07:33:25.685: INFO: stdout: "update-demo-nautilus-64h2h update-demo-nautilus-vfx4s "
May 21 07:33:25.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-64h2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:25.752: INFO: stderr: ""
May 21 07:33:25.752: INFO: stdout: ""
May 21 07:33:25.752: INFO: update-demo-nautilus-64h2h is created but not running
May 21 07:33:30.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:30.821: INFO: stderr: ""
May 21 07:33:30.821: INFO: stdout: "update-demo-nautilus-64h2h update-demo-nautilus-vfx4s "
May 21 07:33:30.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-64h2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:30.885: INFO: stderr: ""
May 21 07:33:30.885: INFO: stdout: "true"
May 21 07:33:30.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-64h2h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:30.953: INFO: stderr: ""
May 21 07:33:30.953: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:33:30.953: INFO: validating pod update-demo-nautilus-64h2h
May 21 07:33:30.957: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:33:30.957: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:33:30.957: INFO: update-demo-nautilus-64h2h is verified up and running
May 21 07:33:30.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-vfx4s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:31.021: INFO: stderr: ""
May 21 07:33:31.021: INFO: stdout: "true"
May 21 07:33:31.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-nautilus-vfx4s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:31.082: INFO: stderr: ""
May 21 07:33:31.082: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 21 07:33:31.082: INFO: validating pod update-demo-nautilus-vfx4s
May 21 07:33:31.084: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 07:33:31.084: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 07:33:31.084: INFO: update-demo-nautilus-vfx4s is verified up and running
STEP: rolling-update to new replication controller
May 21 07:33:31.086: INFO: scanned /root for discovery docs: <nil>
May 21 07:33:31.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:53.370: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 21 07:33:53.370: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 07:33:53.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:53.453: INFO: stderr: ""
May 21 07:33:53.453: INFO: stdout: "update-demo-kitten-cks96 update-demo-kitten-w6bq4 update-demo-nautilus-64h2h "
STEP: Replicas for name=update-demo: expected=2 actual=3
May 21 07:33:58.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:58.529: INFO: stderr: ""
May 21 07:33:58.529: INFO: stdout: "update-demo-kitten-cks96 update-demo-kitten-w6bq4 "
May 21 07:33:58.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-kitten-cks96 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:58.601: INFO: stderr: ""
May 21 07:33:58.601: INFO: stdout: "true"
May 21 07:33:58.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-kitten-cks96 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:58.663: INFO: stderr: ""
May 21 07:33:58.663: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 21 07:33:58.663: INFO: validating pod update-demo-kitten-cks96
May 21 07:33:58.666: INFO: got data: {
  "image": "kitten.jpg"
}

May 21 07:33:58.666: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 21 07:33:58.666: INFO: update-demo-kitten-cks96 is verified up and running
May 21 07:33:58.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-kitten-w6bq4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:58.733: INFO: stderr: ""
May 21 07:33:58.733: INFO: stdout: "true"
May 21 07:33:58.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods update-demo-kitten-w6bq4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-w4p6w'
May 21 07:33:58.792: INFO: stderr: ""
May 21 07:33:58.792: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 21 07:33:58.792: INFO: validating pod update-demo-kitten-w6bq4
May 21 07:33:58.795: INFO: got data: {
  "image": "kitten.jpg"
}

May 21 07:33:58.795: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 21 07:33:58.795: INFO: update-demo-kitten-w6bq4 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:33:58.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w4p6w" for this suite.
May 21 07:34:20.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:34:20.836: INFO: namespace: e2e-tests-kubectl-w4p6w, resource: bindings, ignored listing per whitelist
May 21 07:34:20.857: INFO: namespace e2e-tests-kubectl-w4p6w deletion completed in 22.059902234s

• [SLOW TEST:55.441 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:34:20.858: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-95zdq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 07:34:20.898: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 07:34:42.949: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.8.3.103 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-95zdq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:34:42.949: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:34:44.080: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:34:44.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-95zdq" for this suite.
May 21 07:35:06.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:35:06.117: INFO: namespace: e2e-tests-pod-network-test-95zdq, resource: bindings, ignored listing per whitelist
May 21 07:35:06.148: INFO: namespace e2e-tests-pod-network-test-95zdq deletion completed in 22.063942007s

• [SLOW TEST:45.291 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:35:06.149: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:35:06.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-j69xv" for this suite.
May 21 07:35:28.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:35:28.257: INFO: namespace: e2e-tests-pods-j69xv, resource: bindings, ignored listing per whitelist
May 21 07:35:28.261: INFO: namespace e2e-tests-pods-j69xv deletion completed in 22.058885927s

• [SLOW TEST:22.113 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:35:28.261: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 07:35:28.304: INFO: Waiting up to 5m0s for pod "pod-01458fba-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-d8n4n" to be "success or failure"
May 21 07:35:28.306: INFO: Pod "pod-01458fba-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.525606ms
May 21 07:35:30.308: INFO: Pod "pod-01458fba-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004181559s
STEP: Saw pod success
May 21 07:35:30.308: INFO: Pod "pod-01458fba-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:35:30.310: INFO: Trying to get logs from node 192.168.5.21 pod pod-01458fba-7b9b-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:35:30.322: INFO: Waiting for pod pod-01458fba-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:35:30.324: INFO: Pod pod-01458fba-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:35:30.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d8n4n" for this suite.
May 21 07:35:36.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:35:36.355: INFO: namespace: e2e-tests-emptydir-d8n4n, resource: bindings, ignored listing per whitelist
May 21 07:35:36.388: INFO: namespace e2e-tests-emptydir-d8n4n deletion completed in 6.0620457s

• [SLOW TEST:8.127 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:35:36.389: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 21 07:35:40.492: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:40.494: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:42.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:42.497: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:44.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:44.500: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:46.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:46.498: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:48.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:48.498: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:50.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:50.497: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:52.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:52.497: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:54.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:54.497: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:56.495: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:56.504: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:35:58.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:35:58.497: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 07:36:00.494: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 07:36:00.497: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:36:00.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-nvg7s" for this suite.
May 21 07:36:22.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:36:22.560: INFO: namespace: e2e-tests-container-lifecycle-hook-nvg7s, resource: bindings, ignored listing per whitelist
May 21 07:36:22.565: INFO: namespace e2e-tests-container-lifecycle-hook-nvg7s deletion completed in 22.065270714s

• [SLOW TEST:46.177 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:36:22.566: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
May 21 07:36:22.622: INFO: Waiting up to 5m0s for pod "var-expansion-21a5d061-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-var-expansion-47p2p" to be "success or failure"
May 21 07:36:22.624: INFO: Pod "var-expansion-21a5d061-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.456777ms
May 21 07:36:24.627: INFO: Pod "var-expansion-21a5d061-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005045106s
STEP: Saw pod success
May 21 07:36:24.627: INFO: Pod "var-expansion-21a5d061-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:36:24.629: INFO: Trying to get logs from node 192.168.5.21 pod var-expansion-21a5d061-7b9b-11e9-8b08-72649ad3cdd7 container dapi-container: <nil>
STEP: delete the pod
May 21 07:36:24.641: INFO: Waiting for pod var-expansion-21a5d061-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:36:24.642: INFO: Pod var-expansion-21a5d061-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:36:24.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-47p2p" for this suite.
May 21 07:36:30.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:36:30.696: INFO: namespace: e2e-tests-var-expansion-47p2p, resource: bindings, ignored listing per whitelist
May 21 07:36:30.703: INFO: namespace e2e-tests-var-expansion-47p2p deletion completed in 6.057864007s

• [SLOW TEST:8.137 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:36:30.703: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 07:36:30.738: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 07:36:30.742: INFO: Waiting for terminating namespaces to be deleted...
May 21 07:36:30.744: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.21 before test
May 21 07:36:30.749: INFO: disk-provisioner-5895cdc8b7-q64vs from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container disk-provisioner ready: true, restart count 0
May 21 07:36:30.749: INFO: kube-proxy-bqckm from kube-system started at 2019-05-21 04:30:34 +0000 UTC (1 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container kube-proxy ready: true, restart count 0
May 21 07:36:30.749: INFO: sonobuoy-e2e-job-cbf016e40c124e85 from heptio-sonobuoy started at 2019-05-21 06:58:22 +0000 UTC (2 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container e2e ready: true, restart count 0
May 21 07:36:30.749: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 07:36:30.749: INFO: ksc-flexvolume-ds-tjvtw from kube-system started at 2019-05-21 04:30:34 +0000 UTC (1 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
May 21 07:36:30.749: INFO: traefik-ingress-controller-tbxgz from kube-system started at 2019-05-21 04:31:34 +0000 UTC (1 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
May 21 07:36:30.749: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-21 06:58:08 +0000 UTC (1 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 07:36:30.749: INFO: sonobuoy-systemd-logs-daemon-set-55252047aa2d4aa6-ghxm4 from heptio-sonobuoy started at 2019-05-21 06:58:22 +0000 UTC (2 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 07:36:30.749: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 07:36:30.749: INFO: cloud-controller-manager-86df4567b9-59nqv from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container cloud-controller-manager ready: true, restart count 0
May 21 07:36:30.749: INFO: kube-flannel-4kgbz from kube-system started at 2019-05-21 04:30:34 +0000 UTC (2 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container install-cni ready: true, restart count 0
May 21 07:36:30.749: INFO: 	Container kube-flannel ready: true, restart count 1
May 21 07:36:30.749: INFO: metrics-server-5b9ff87b5f-rpq6w from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 07:36:30.749: INFO: 	Container metrics-server ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 192.168.5.21
May 21 07:36:30.768: INFO: Pod sonobuoy requesting resource cpu=0m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod sonobuoy-e2e-job-cbf016e40c124e85 requesting resource cpu=0m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod sonobuoy-systemd-logs-daemon-set-55252047aa2d4aa6-ghxm4 requesting resource cpu=0m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod cloud-controller-manager-86df4567b9-59nqv requesting resource cpu=0m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod disk-provisioner-5895cdc8b7-q64vs requesting resource cpu=0m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod ksc-flexvolume-ds-tjvtw requesting resource cpu=0m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod kube-flannel-4kgbz requesting resource cpu=150m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod kube-proxy-bqckm requesting resource cpu=0m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod metrics-server-5b9ff87b5f-rpq6w requesting resource cpu=0m on Node 192.168.5.21
May 21 07:36:30.768: INFO: Pod traefik-ingress-controller-tbxgz requesting resource cpu=0m on Node 192.168.5.21
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2681a6ec-7b9b-11e9-8b08-72649ad3cdd7.15a0a28b6cc1ca35], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-tdxqt/filler-pod-2681a6ec-7b9b-11e9-8b08-72649ad3cdd7 to 192.168.5.21]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2681a6ec-7b9b-11e9-8b08-72649ad3cdd7.15a0a28b8f6d1c6b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2681a6ec-7b9b-11e9-8b08-72649ad3cdd7.15a0a28b8ff641c8], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2681a6ec-7b9b-11e9-8b08-72649ad3cdd7.15a0a28b9667292b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a0a28be460bf93], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node 192.168.5.21
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:36:33.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-tdxqt" for this suite.
May 21 07:36:39.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:36:39.841: INFO: namespace: e2e-tests-sched-pred-tdxqt, resource: bindings, ignored listing per whitelist
May 21 07:36:39.875: INFO: namespace e2e-tests-sched-pred-tdxqt deletion completed in 6.074400274s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.172 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:36:39.875: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-2bf680d7-7b9b-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:36:39.931: INFO: Waiting up to 5m0s for pod "pod-configmaps-2bf7019c-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-2pqx9" to be "success or failure"
May 21 07:36:39.936: INFO: Pod "pod-configmaps-2bf7019c-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.501009ms
May 21 07:36:41.938: INFO: Pod "pod-configmaps-2bf7019c-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006862386s
STEP: Saw pod success
May 21 07:36:41.938: INFO: Pod "pod-configmaps-2bf7019c-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:36:41.940: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-2bf7019c-7b9b-11e9-8b08-72649ad3cdd7 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:36:41.951: INFO: Waiting for pod pod-configmaps-2bf7019c-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:36:41.953: INFO: Pod pod-configmaps-2bf7019c-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:36:41.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2pqx9" for this suite.
May 21 07:36:47.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:36:47.972: INFO: namespace: e2e-tests-configmap-2pqx9, resource: bindings, ignored listing per whitelist
May 21 07:36:48.019: INFO: namespace e2e-tests-configmap-2pqx9 deletion completed in 6.063669496s

• [SLOW TEST:8.144 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:36:48.019: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-30d003e3-7b9b-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:36:48.067: INFO: Waiting up to 5m0s for pod "pod-configmaps-30d086a7-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-8c8k2" to be "success or failure"
May 21 07:36:48.070: INFO: Pod "pod-configmaps-30d086a7-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.795508ms
May 21 07:36:50.075: INFO: Pod "pod-configmaps-30d086a7-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008389796s
STEP: Saw pod success
May 21 07:36:50.075: INFO: Pod "pod-configmaps-30d086a7-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:36:50.076: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-30d086a7-7b9b-11e9-8b08-72649ad3cdd7 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:36:50.089: INFO: Waiting for pod pod-configmaps-30d086a7-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:36:50.090: INFO: Pod pod-configmaps-30d086a7-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:36:50.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8c8k2" for this suite.
May 21 07:36:56.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:36:56.150: INFO: namespace: e2e-tests-configmap-8c8k2, resource: bindings, ignored listing per whitelist
May 21 07:36:56.154: INFO: namespace e2e-tests-configmap-8c8k2 deletion completed in 6.056104039s

• [SLOW TEST:8.135 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:36:56.154: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 07:36:56.193: INFO: Waiting up to 5m0s for pod "downward-api-35a87090-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-jhf94" to be "success or failure"
May 21 07:36:56.197: INFO: Pod "downward-api-35a87090-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.192256ms
May 21 07:36:58.200: INFO: Pod "downward-api-35a87090-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006179689s
STEP: Saw pod success
May 21 07:36:58.200: INFO: Pod "downward-api-35a87090-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:36:58.201: INFO: Trying to get logs from node 192.168.5.21 pod downward-api-35a87090-7b9b-11e9-8b08-72649ad3cdd7 container dapi-container: <nil>
STEP: delete the pod
May 21 07:36:58.213: INFO: Waiting for pod downward-api-35a87090-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:36:58.215: INFO: Pod downward-api-35a87090-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:36:58.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jhf94" for this suite.
May 21 07:37:04.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:37:04.270: INFO: namespace: e2e-tests-downward-api-jhf94, resource: bindings, ignored listing per whitelist
May 21 07:37:04.284: INFO: namespace e2e-tests-downward-api-jhf94 deletion completed in 6.066220157s

• [SLOW TEST:8.130 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:37:04.284: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3a820bb5-7b9b-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:37:04.333: INFO: Waiting up to 5m0s for pod "pod-secrets-3a829da7-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-7qwct" to be "success or failure"
May 21 07:37:04.336: INFO: Pod "pod-secrets-3a829da7-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.025631ms
May 21 07:37:06.338: INFO: Pod "pod-secrets-3a829da7-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005499598s
STEP: Saw pod success
May 21 07:37:06.338: INFO: Pod "pod-secrets-3a829da7-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:37:06.340: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-3a829da7-7b9b-11e9-8b08-72649ad3cdd7 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:37:06.351: INFO: Waiting for pod pod-secrets-3a829da7-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:37:06.352: INFO: Pod pod-secrets-3a829da7-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:37:06.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7qwct" for this suite.
May 21 07:37:12.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:37:12.397: INFO: namespace: e2e-tests-secrets-7qwct, resource: bindings, ignored listing per whitelist
May 21 07:37:12.413: INFO: namespace e2e-tests-secrets-7qwct deletion completed in 6.058354368s

• [SLOW TEST:8.129 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:37:12.413: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-3f5a9b63-7b9b-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:37:12.463: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3f5b2885-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-zmd8z" to be "success or failure"
May 21 07:37:12.465: INFO: Pod "pod-projected-secrets-3f5b2885-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.882036ms
May 21 07:37:14.468: INFO: Pod "pod-projected-secrets-3f5b2885-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004568577s
STEP: Saw pod success
May 21 07:37:14.468: INFO: Pod "pod-projected-secrets-3f5b2885-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:37:14.469: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-3f5b2885-7b9b-11e9-8b08-72649ad3cdd7 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 07:37:14.484: INFO: Waiting for pod pod-projected-secrets-3f5b2885-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:37:14.486: INFO: Pod pod-projected-secrets-3f5b2885-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:37:14.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zmd8z" for this suite.
May 21 07:37:20.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:37:20.520: INFO: namespace: e2e-tests-projected-zmd8z, resource: bindings, ignored listing per whitelist
May 21 07:37:20.550: INFO: namespace e2e-tests-projected-zmd8z deletion completed in 6.061236169s

• [SLOW TEST:8.137 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:37:20.550: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
May 21 07:37:21.107: INFO: created pod pod-service-account-defaultsa
May 21 07:37:21.107: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 21 07:37:21.110: INFO: created pod pod-service-account-mountsa
May 21 07:37:21.110: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 21 07:37:21.115: INFO: created pod pod-service-account-nomountsa
May 21 07:37:21.115: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 21 07:37:21.119: INFO: created pod pod-service-account-defaultsa-mountspec
May 21 07:37:21.119: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 21 07:37:21.125: INFO: created pod pod-service-account-mountsa-mountspec
May 21 07:37:21.125: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 21 07:37:21.129: INFO: created pod pod-service-account-nomountsa-mountspec
May 21 07:37:21.129: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 21 07:37:21.132: INFO: created pod pod-service-account-defaultsa-nomountspec
May 21 07:37:21.132: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 21 07:37:21.134: INFO: created pod pod-service-account-mountsa-nomountspec
May 21 07:37:21.134: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 21 07:37:21.138: INFO: created pod pod-service-account-nomountsa-nomountspec
May 21 07:37:21.138: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:37:21.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-cd6rc" for this suite.
May 21 07:37:43.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:37:43.187: INFO: namespace: e2e-tests-svcaccounts-cd6rc, resource: bindings, ignored listing per whitelist
May 21 07:37:43.203: INFO: namespace e2e-tests-svcaccounts-cd6rc deletion completed in 22.061931116s

• [SLOW TEST:22.653 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:37:43.203: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
May 21 07:37:45.273: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:38:09.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-9khhb" for this suite.
May 21 07:38:15.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:38:15.358: INFO: namespace: e2e-tests-namespaces-9khhb, resource: bindings, ignored listing per whitelist
May 21 07:38:15.372: INFO: namespace e2e-tests-namespaces-9khhb deletion completed in 6.067808012s
STEP: Destroying namespace "e2e-tests-nsdeletetest-ph8d4" for this suite.
May 21 07:38:15.373: INFO: Namespace e2e-tests-nsdeletetest-ph8d4 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-vhmmn" for this suite.
May 21 07:38:21.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:38:21.395: INFO: namespace: e2e-tests-nsdeletetest-vhmmn, resource: bindings, ignored listing per whitelist
May 21 07:38:21.434: INFO: namespace e2e-tests-nsdeletetest-vhmmn deletion completed in 6.060471135s

• [SLOW TEST:38.231 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:38:21.434: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:38:21.478: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 21 07:38:26.494: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 07:38:26.495: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 21 07:38:28.497: INFO: Creating deployment "test-rollover-deployment"
May 21 07:38:28.504: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 21 07:38:30.509: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 21 07:38:30.513: INFO: Ensure that both replica sets have 1 created replica
May 21 07:38:30.517: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 21 07:38:30.521: INFO: Updating deployment test-rollover-deployment
May 21 07:38:30.521: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 21 07:38:32.524: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 21 07:38:32.531: INFO: Make sure deployment "test-rollover-deployment" is complete
May 21 07:38:32.539: INFO: all replica sets need to contain the pod-template-hash label
May 21 07:38:32.539: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021112, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 07:38:34.544: INFO: all replica sets need to contain the pod-template-hash label
May 21 07:38:34.544: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021112, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 07:38:36.549: INFO: all replica sets need to contain the pod-template-hash label
May 21 07:38:36.549: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021112, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 07:38:38.544: INFO: all replica sets need to contain the pod-template-hash label
May 21 07:38:38.545: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021112, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 07:38:40.548: INFO: all replica sets need to contain the pod-template-hash label
May 21 07:38:40.548: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021112, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021108, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 07:38:42.545: INFO: 
May 21 07:38:42.545: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 07:38:42.552: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-x5dkz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x5dkz/deployments/test-rollover-deployment,UID:6cadba34-7b9b-11e9-926e-fa163e6dedea,ResourceVersion:21282,Generation:2,CreationTimestamp:2019-05-21 07:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-21 07:38:28 +0000 UTC 2019-05-21 07:38:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-21 07:38:42 +0000 UTC 2019-05-21 07:38:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 21 07:38:42.555: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-x5dkz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x5dkz/replicasets/test-rollover-deployment-6b7f9d6597,UID:6de2eba1-7b9b-11e9-8844-fa163e715483,ResourceVersion:21273,Generation:2,CreationTimestamp:2019-05-21 07:38:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6cadba34-7b9b-11e9-926e-fa163e6dedea 0xc002aa2a97 0xc002aa2a98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 21 07:38:42.555: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 21 07:38:42.555: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-x5dkz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x5dkz/replicasets/test-rollover-controller,UID:687dc748-7b9b-11e9-926e-fa163e6dedea,ResourceVersion:21281,Generation:2,CreationTimestamp:2019-05-21 07:38:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6cadba34-7b9b-11e9-926e-fa163e6dedea 0xc002aa2907 0xc002aa2908}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 07:38:42.555: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-x5dkz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x5dkz/replicasets/test-rollover-deployment-6586df867b,UID:6caf9cfe-7b9b-11e9-8844-fa163e715483,ResourceVersion:21243,Generation:2,CreationTimestamp:2019-05-21 07:38:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 6cadba34-7b9b-11e9-926e-fa163e6dedea 0xc002aa29c7 0xc002aa29c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 07:38:42.558: INFO: Pod "test-rollover-deployment-6b7f9d6597-gmwwl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-gmwwl,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-x5dkz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-x5dkz/pods/test-rollover-deployment-6b7f9d6597-gmwwl,UID:6de5bd96-7b9b-11e9-8844-fa163e715483,ResourceVersion:21255,Generation:0,CreationTimestamp:2019-05-21 07:38:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 6de2eba1-7b9b-11e9-8844-fa163e715483 0xc0020e2b97 0xc0020e2b98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wdj8s {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wdj8s,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wdj8s true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:38:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:38:32 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:38:32 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:38:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.130,StartTime:2019-05-21 07:38:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-21 07:38:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://929565e66cce5ff890388f150ba36ec02793affdcb071221cda94508d3ecaf85}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:38:42.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-x5dkz" for this suite.
May 21 07:38:48.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:38:48.610: INFO: namespace: e2e-tests-deployment-x5dkz, resource: bindings, ignored listing per whitelist
May 21 07:38:48.620: INFO: namespace e2e-tests-deployment-x5dkz deletion completed in 6.059441182s

• [SLOW TEST:27.186 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:38:48.620: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 07:38:48.671: INFO: Waiting up to 5m0s for pod "pod-78b31edd-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-n7wnb" to be "success or failure"
May 21 07:38:48.673: INFO: Pod "pod-78b31edd-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.594904ms
May 21 07:38:50.676: INFO: Pod "pod-78b31edd-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004988091s
STEP: Saw pod success
May 21 07:38:50.676: INFO: Pod "pod-78b31edd-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:38:50.677: INFO: Trying to get logs from node 192.168.5.21 pod pod-78b31edd-7b9b-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:38:50.705: INFO: Waiting for pod pod-78b31edd-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:38:50.709: INFO: Pod pod-78b31edd-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:38:50.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n7wnb" for this suite.
May 21 07:38:56.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:38:56.771: INFO: namespace: e2e-tests-emptydir-n7wnb, resource: bindings, ignored listing per whitelist
May 21 07:38:56.775: INFO: namespace e2e-tests-emptydir-n7wnb deletion completed in 6.063411457s

• [SLOW TEST:8.154 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:38:56.775: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-wlxr8
May 21 07:39:00.822: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-wlxr8
STEP: checking the pod's current state and verifying that restartCount is present
May 21 07:39:00.823: INFO: Initial restart count of pod liveness-http is 0
May 21 07:39:16.857: INFO: Restart count of pod e2e-tests-container-probe-wlxr8/liveness-http is now 1 (16.033040782s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:39:16.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wlxr8" for this suite.
May 21 07:39:22.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:39:22.893: INFO: namespace: e2e-tests-container-probe-wlxr8, resource: bindings, ignored listing per whitelist
May 21 07:39:22.953: INFO: namespace e2e-tests-container-probe-wlxr8 deletion completed in 6.08640523s

• [SLOW TEST:26.178 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:39:22.953: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-8d2b0639-7b9b-11e9-8b08-72649ad3cdd7
May 21 07:39:23.027: INFO: Pod name my-hostname-basic-8d2b0639-7b9b-11e9-8b08-72649ad3cdd7: Found 0 pods out of 1
May 21 07:39:28.033: INFO: Pod name my-hostname-basic-8d2b0639-7b9b-11e9-8b08-72649ad3cdd7: Found 1 pods out of 1
May 21 07:39:28.033: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8d2b0639-7b9b-11e9-8b08-72649ad3cdd7" are running
May 21 07:39:28.036: INFO: Pod "my-hostname-basic-8d2b0639-7b9b-11e9-8b08-72649ad3cdd7-8nrsq" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 07:39:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 07:39:23 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 07:39:23 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 07:39:23 +0000 UTC Reason: Message:}])
May 21 07:39:28.036: INFO: Trying to dial the pod
May 21 07:39:33.045: INFO: Controller my-hostname-basic-8d2b0639-7b9b-11e9-8b08-72649ad3cdd7: Got expected result from replica 1 [my-hostname-basic-8d2b0639-7b9b-11e9-8b08-72649ad3cdd7-8nrsq]: "my-hostname-basic-8d2b0639-7b9b-11e9-8b08-72649ad3cdd7-8nrsq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:39:33.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8gcxv" for this suite.
May 21 07:39:39.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:39:39.082: INFO: namespace: e2e-tests-replication-controller-8gcxv, resource: bindings, ignored listing per whitelist
May 21 07:39:39.119: INFO: namespace e2e-tests-replication-controller-8gcxv deletion completed in 6.07090017s

• [SLOW TEST:16.166 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:39:39.119: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 21 07:39:41.178: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-96cc1348-7b9b-11e9-8b08-72649ad3cdd7", GenerateName:"", Namespace:"e2e-tests-pods-gfzrg", SelfLink:"/api/v1/namespaces/e2e-tests-pods-gfzrg/pods/pod-submit-remove-96cc1348-7b9b-11e9-8b08-72649ad3cdd7", UID:"96cc927f-7b9b-11e9-926e-fa163e6dedea", ResourceVersion:"21512", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694021179, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"161489866"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-q7vp9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0009135c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-q7vp9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001d885f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.5.21", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001bff620), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001d8879c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021179, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021180, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021180, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021179, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.5.21", PodIP:"10.8.3.135", StartTime:(*v1.Time)(0xc001395160), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001395180), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://f0c4aa3950c5e5e1695515c10891f9e6b69ac67e71f0e3185180ee54faa50fd8"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:39:54.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-gfzrg" for this suite.
May 21 07:40:00.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:40:00.082: INFO: namespace: e2e-tests-pods-gfzrg, resource: bindings, ignored listing per whitelist
May 21 07:40:00.091: INFO: namespace e2e-tests-pods-gfzrg deletion completed in 6.060887661s

• [SLOW TEST:20.972 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:40:00.091: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 21 07:40:00.146: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:00.146: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:00.147: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:00.148: INFO: Number of nodes with available pods: 0
May 21 07:40:00.148: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:01.151: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:01.151: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:01.151: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:01.153: INFO: Number of nodes with available pods: 0
May 21 07:40:01.153: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:02.151: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:02.151: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:02.151: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:02.153: INFO: Number of nodes with available pods: 1
May 21 07:40:02.153: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 21 07:40:02.163: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:02.163: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:02.163: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:02.165: INFO: Number of nodes with available pods: 0
May 21 07:40:02.165: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:03.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:03.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:03.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:03.172: INFO: Number of nodes with available pods: 0
May 21 07:40:03.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:04.173: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:04.173: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:04.173: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:04.175: INFO: Number of nodes with available pods: 0
May 21 07:40:04.175: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:05.171: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:05.171: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:05.171: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:05.175: INFO: Number of nodes with available pods: 0
May 21 07:40:05.175: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:06.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:06.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:06.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:06.171: INFO: Number of nodes with available pods: 0
May 21 07:40:06.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:07.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:07.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:07.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:07.171: INFO: Number of nodes with available pods: 0
May 21 07:40:07.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:08.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:08.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:08.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:08.170: INFO: Number of nodes with available pods: 0
May 21 07:40:08.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:09.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:09.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:09.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:09.173: INFO: Number of nodes with available pods: 0
May 21 07:40:09.173: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:10.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:10.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:10.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:10.171: INFO: Number of nodes with available pods: 0
May 21 07:40:10.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:11.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:11.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:11.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:11.171: INFO: Number of nodes with available pods: 0
May 21 07:40:11.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:12.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:12.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:12.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:12.172: INFO: Number of nodes with available pods: 0
May 21 07:40:12.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:13.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:13.168: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:13.168: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:13.170: INFO: Number of nodes with available pods: 0
May 21 07:40:13.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:14.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:14.168: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:14.168: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:14.174: INFO: Number of nodes with available pods: 0
May 21 07:40:14.174: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:15.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:15.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:15.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:15.172: INFO: Number of nodes with available pods: 0
May 21 07:40:15.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:16.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:16.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:16.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:16.171: INFO: Number of nodes with available pods: 0
May 21 07:40:16.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:17.170: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:17.170: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:17.170: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:17.172: INFO: Number of nodes with available pods: 0
May 21 07:40:17.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:18.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:18.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:18.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:18.170: INFO: Number of nodes with available pods: 0
May 21 07:40:18.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:19.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:19.168: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:19.168: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:19.170: INFO: Number of nodes with available pods: 0
May 21 07:40:19.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:20.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:20.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:20.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:20.171: INFO: Number of nodes with available pods: 0
May 21 07:40:20.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:21.170: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:21.170: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:21.170: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:21.173: INFO: Number of nodes with available pods: 0
May 21 07:40:21.173: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:22.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:22.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:22.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:22.171: INFO: Number of nodes with available pods: 0
May 21 07:40:22.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:23.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:23.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:23.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:23.170: INFO: Number of nodes with available pods: 0
May 21 07:40:23.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:24.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:24.168: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:24.168: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:24.170: INFO: Number of nodes with available pods: 0
May 21 07:40:24.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:25.172: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:25.172: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:25.172: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:25.173: INFO: Number of nodes with available pods: 0
May 21 07:40:25.173: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:26.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:26.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:26.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:26.171: INFO: Number of nodes with available pods: 0
May 21 07:40:26.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:27.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:27.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:27.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:27.172: INFO: Number of nodes with available pods: 0
May 21 07:40:27.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:28.170: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:28.170: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:28.170: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:28.172: INFO: Number of nodes with available pods: 0
May 21 07:40:28.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:29.170: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:29.170: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:29.170: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:29.172: INFO: Number of nodes with available pods: 0
May 21 07:40:29.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:30.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:30.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:30.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:30.171: INFO: Number of nodes with available pods: 0
May 21 07:40:30.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:31.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:31.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:31.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:31.172: INFO: Number of nodes with available pods: 0
May 21 07:40:31.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:32.170: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:32.170: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:32.170: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:32.173: INFO: Number of nodes with available pods: 0
May 21 07:40:32.173: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:33.171: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:33.171: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:33.171: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:33.174: INFO: Number of nodes with available pods: 0
May 21 07:40:33.174: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:34.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:34.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:34.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:34.171: INFO: Number of nodes with available pods: 0
May 21 07:40:34.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:35.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:35.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:35.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:35.171: INFO: Number of nodes with available pods: 0
May 21 07:40:35.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:36.171: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:36.172: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:36.172: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:36.173: INFO: Number of nodes with available pods: 0
May 21 07:40:36.173: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:37.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:37.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:37.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:37.171: INFO: Number of nodes with available pods: 0
May 21 07:40:37.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:38.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:38.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:38.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:38.172: INFO: Number of nodes with available pods: 0
May 21 07:40:38.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:39.170: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:39.170: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:39.170: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:39.172: INFO: Number of nodes with available pods: 0
May 21 07:40:39.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:40.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:40.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:40.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:40.170: INFO: Number of nodes with available pods: 0
May 21 07:40:40.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:41.175: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:41.176: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:41.176: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:41.178: INFO: Number of nodes with available pods: 0
May 21 07:40:41.178: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:42.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:42.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:42.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:42.170: INFO: Number of nodes with available pods: 0
May 21 07:40:42.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:43.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:43.170: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:43.170: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:43.172: INFO: Number of nodes with available pods: 0
May 21 07:40:43.172: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:44.169: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:44.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:44.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:44.171: INFO: Number of nodes with available pods: 0
May 21 07:40:44.171: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:45.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:45.168: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:45.168: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:45.170: INFO: Number of nodes with available pods: 0
May 21 07:40:45.170: INFO: Node 192.168.5.21 is running more than one daemon pod
May 21 07:40:46.168: INFO: DaemonSet pods can't tolerate node 192.168.5.14 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:46.169: INFO: DaemonSet pods can't tolerate node 192.168.5.37 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:46.169: INFO: DaemonSet pods can't tolerate node 192.168.5.39 with taints [{Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 07:40:46.170: INFO: Number of nodes with available pods: 1
May 21 07:40:46.170: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-dmx6k, will wait for the garbage collector to delete the pods
May 21 07:40:46.232: INFO: Deleting DaemonSet.extensions daemon-set took: 4.31859ms
May 21 07:40:46.332: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.156941ms
May 21 07:41:20.237: INFO: Number of nodes with available pods: 0
May 21 07:41:20.238: INFO: Number of running nodes: 0, number of available pods: 0
May 21 07:41:20.239: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dmx6k/daemonsets","resourceVersion":"21713"},"items":null}

May 21 07:41:20.241: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dmx6k/pods","resourceVersion":"21713"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:41:20.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dmx6k" for this suite.
May 21 07:41:26.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:41:26.291: INFO: namespace: e2e-tests-daemonsets-dmx6k, resource: bindings, ignored listing per whitelist
May 21 07:41:26.304: INFO: namespace e2e-tests-daemonsets-dmx6k deletion completed in 6.055341147s

• [SLOW TEST:86.212 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:41:26.304: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:41:26.347: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6ae8285-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-llpfn" to be "success or failure"
May 21 07:41:26.349: INFO: Pod "downwardapi-volume-d6ae8285-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.853789ms
May 21 07:41:28.351: INFO: Pod "downwardapi-volume-d6ae8285-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004270249s
STEP: Saw pod success
May 21 07:41:28.351: INFO: Pod "downwardapi-volume-d6ae8285-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:41:28.353: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-d6ae8285-7b9b-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:41:28.364: INFO: Waiting for pod downwardapi-volume-d6ae8285-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:41:28.365: INFO: Pod downwardapi-volume-d6ae8285-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:41:28.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-llpfn" for this suite.
May 21 07:41:34.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:41:34.428: INFO: namespace: e2e-tests-projected-llpfn, resource: bindings, ignored listing per whitelist
May 21 07:41:34.431: INFO: namespace e2e-tests-projected-llpfn deletion completed in 6.062027191s

• [SLOW TEST:8.127 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:41:34.432: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:41:36.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-8f4hf" for this suite.
May 21 07:41:42.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:41:42.543: INFO: namespace: e2e-tests-emptydir-wrapper-8f4hf, resource: bindings, ignored listing per whitelist
May 21 07:41:42.586: INFO: namespace e2e-tests-emptydir-wrapper-8f4hf deletion completed in 6.065980819s

• [SLOW TEST:8.155 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:41:42.587: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:41:42.633: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e063b8e5-7b9b-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-nvnj2" to be "success or failure"
May 21 07:41:42.635: INFO: Pod "downwardapi-volume-e063b8e5-7b9b-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.303597ms
May 21 07:41:44.638: INFO: Pod "downwardapi-volume-e063b8e5-7b9b-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004736427s
STEP: Saw pod success
May 21 07:41:44.638: INFO: Pod "downwardapi-volume-e063b8e5-7b9b-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:41:44.639: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-e063b8e5-7b9b-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:41:44.652: INFO: Waiting for pod downwardapi-volume-e063b8e5-7b9b-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:41:44.653: INFO: Pod downwardapi-volume-e063b8e5-7b9b-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:41:44.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nvnj2" for this suite.
May 21 07:41:50.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:41:50.705: INFO: namespace: e2e-tests-projected-nvnj2, resource: bindings, ignored listing per whitelist
May 21 07:41:50.713: INFO: namespace e2e-tests-projected-nvnj2 deletion completed in 6.05725689s

• [SLOW TEST:8.126 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:41:50.713: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 21 07:41:54.781: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:41:54.784: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:41:56.784: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:41:56.787: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:41:58.784: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:41:58.787: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:42:00.784: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:42:00.790: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:42:02.784: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:42:02.787: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:42:04.784: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:42:04.787: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:42:06.784: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:42:06.788: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:42:08.784: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:42:08.787: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:42:10.786: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:42:10.790: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 07:42:12.784: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 07:42:12.789: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:42:12.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-2m4cz" for this suite.
May 21 07:42:34.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:42:34.841: INFO: namespace: e2e-tests-container-lifecycle-hook-2m4cz, resource: bindings, ignored listing per whitelist
May 21 07:42:34.863: INFO: namespace e2e-tests-container-lifecycle-hook-2m4cz deletion completed in 22.065563154s

• [SLOW TEST:44.150 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:42:34.863: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zncvl
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 07:42:34.905: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 07:42:48.942: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.3.144:8080/dial?request=hostName&protocol=udp&host=10.8.3.143&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-zncvl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 07:42:48.942: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 07:42:49.093: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:42:49.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zncvl" for this suite.
May 21 07:43:11.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:43:11.111: INFO: namespace: e2e-tests-pod-network-test-zncvl, resource: bindings, ignored listing per whitelist
May 21 07:43:11.155: INFO: namespace e2e-tests-pod-network-test-zncvl deletion completed in 22.058742598s

• [SLOW TEST:36.291 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:43:11.155: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
May 21 07:43:13.207: INFO: Pod pod-hostip-152dcbe5-7b9c-11e9-8b08-72649ad3cdd7 has hostIP: 192.168.5.21
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:43:13.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-m4nxb" for this suite.
May 21 07:43:35.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:43:35.277: INFO: namespace: e2e-tests-pods-m4nxb, resource: bindings, ignored listing per whitelist
May 21 07:43:35.286: INFO: namespace e2e-tests-pods-m4nxb deletion completed in 22.076268982s

• [SLOW TEST:24.131 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:43:35.286: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:43:57.394: INFO: Container started at 2019-05-21 07:43:36 +0000 UTC, pod became ready at 2019-05-21 07:43:57 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:43:57.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mjj9j" for this suite.
May 21 07:44:19.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:44:19.421: INFO: namespace: e2e-tests-container-probe-mjj9j, resource: bindings, ignored listing per whitelist
May 21 07:44:19.459: INFO: namespace e2e-tests-container-probe-mjj9j deletion completed in 22.061753017s

• [SLOW TEST:44.173 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:44:19.459: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 07:44:19.503: INFO: Waiting up to 5m0s for pod "pod-3de4172c-7b9c-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-wq5jn" to be "success or failure"
May 21 07:44:19.505: INFO: Pod "pod-3de4172c-7b9c-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.894979ms
May 21 07:44:21.508: INFO: Pod "pod-3de4172c-7b9c-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004760538s
STEP: Saw pod success
May 21 07:44:21.508: INFO: Pod "pod-3de4172c-7b9c-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:44:21.510: INFO: Trying to get logs from node 192.168.5.21 pod pod-3de4172c-7b9c-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:44:21.522: INFO: Waiting for pod pod-3de4172c-7b9c-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:44:21.523: INFO: Pod pod-3de4172c-7b9c-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:44:21.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wq5jn" for this suite.
May 21 07:44:27.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:44:27.551: INFO: namespace: e2e-tests-emptydir-wq5jn, resource: bindings, ignored listing per whitelist
May 21 07:44:27.606: INFO: namespace e2e-tests-emptydir-wq5jn deletion completed in 6.080385996s

• [SLOW TEST:8.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:44:27.607: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 07:44:27.664: INFO: Waiting up to 5m0s for pod "pod-42c0eb5f-7b9c-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-5ft7x" to be "success or failure"
May 21 07:44:27.666: INFO: Pod "pod-42c0eb5f-7b9c-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05787ms
May 21 07:44:29.668: INFO: Pod "pod-42c0eb5f-7b9c-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004377964s
STEP: Saw pod success
May 21 07:44:29.668: INFO: Pod "pod-42c0eb5f-7b9c-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:44:29.669: INFO: Trying to get logs from node 192.168.5.21 pod pod-42c0eb5f-7b9c-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:44:29.683: INFO: Waiting for pod pod-42c0eb5f-7b9c-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:44:29.685: INFO: Pod pod-42c0eb5f-7b9c-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:44:29.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5ft7x" for this suite.
May 21 07:44:35.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:44:35.731: INFO: namespace: e2e-tests-emptydir-5ft7x, resource: bindings, ignored listing per whitelist
May 21 07:44:35.746: INFO: namespace e2e-tests-emptydir-5ft7x deletion completed in 6.059537063s

• [SLOW TEST:8.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:44:35.747: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4799aac7-7b9c-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:44:35.795: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-479a2ff1-7b9c-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-cv8gg" to be "success or failure"
May 21 07:44:35.797: INFO: Pod "pod-projected-configmaps-479a2ff1-7b9c-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.91697ms
May 21 07:44:37.800: INFO: Pod "pod-projected-configmaps-479a2ff1-7b9c-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004877669s
STEP: Saw pod success
May 21 07:44:37.800: INFO: Pod "pod-projected-configmaps-479a2ff1-7b9c-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:44:37.801: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-479a2ff1-7b9c-11e9-8b08-72649ad3cdd7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:44:37.818: INFO: Waiting for pod pod-projected-configmaps-479a2ff1-7b9c-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:44:37.819: INFO: Pod pod-projected-configmaps-479a2ff1-7b9c-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:44:37.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cv8gg" for this suite.
May 21 07:44:43.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:44:43.865: INFO: namespace: e2e-tests-projected-cv8gg, resource: bindings, ignored listing per whitelist
May 21 07:44:43.884: INFO: namespace e2e-tests-projected-cv8gg deletion completed in 6.062976841s

• [SLOW TEST:8.138 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:44:43.885: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:44:43.931: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c737d68-7b9c-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-5bcb5" to be "success or failure"
May 21 07:44:43.933: INFO: Pod "downwardapi-volume-4c737d68-7b9c-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.225818ms
May 21 07:44:45.936: INFO: Pod "downwardapi-volume-4c737d68-7b9c-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004705624s
STEP: Saw pod success
May 21 07:44:45.936: INFO: Pod "downwardapi-volume-4c737d68-7b9c-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:44:45.937: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-4c737d68-7b9c-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:44:45.949: INFO: Waiting for pod downwardapi-volume-4c737d68-7b9c-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:44:45.950: INFO: Pod downwardapi-volume-4c737d68-7b9c-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:44:45.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5bcb5" for this suite.
May 21 07:44:51.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:44:51.978: INFO: namespace: e2e-tests-downward-api-5bcb5, resource: bindings, ignored listing per whitelist
May 21 07:44:52.014: INFO: namespace e2e-tests-downward-api-5bcb5 deletion completed in 6.061372418s

• [SLOW TEST:8.129 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:44:52.014: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-sltzl in namespace e2e-tests-proxy-6pdnh
I0521 07:44:52.064566      15 runners.go:184] Created replication controller with name: proxy-service-sltzl, namespace: e2e-tests-proxy-6pdnh, replica count: 1
I0521 07:44:53.114912      15 runners.go:184] proxy-service-sltzl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:44:54.115083      15 runners.go:184] proxy-service-sltzl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:44:55.115254      15 runners.go:184] proxy-service-sltzl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:44:56.115414      15 runners.go:184] proxy-service-sltzl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 07:44:57.115579      15 runners.go:184] proxy-service-sltzl Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 07:44:57.120: INFO: setup took 5.06617875s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 21 07:44:57.132: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 11.961563ms)
May 21 07:44:57.132: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 11.853624ms)
May 21 07:44:57.132: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 11.362279ms)
May 21 07:44:57.136: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 14.859741ms)
May 21 07:44:57.136: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 15.076354ms)
May 21 07:44:57.136: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 14.978469ms)
May 21 07:44:57.136: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 15.524919ms)
May 21 07:44:57.136: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 15.251636ms)
May 21 07:44:57.136: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 14.902983ms)
May 21 07:44:57.136: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 15.504739ms)
May 21 07:44:57.137: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 16.099564ms)
May 21 07:44:57.138: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 17.368081ms)
May 21 07:44:57.138: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 16.735823ms)
May 21 07:44:57.138: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 17.34619ms)
May 21 07:44:57.138: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 17.181986ms)
May 21 07:44:57.138: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 17.305025ms)
May 21 07:44:57.141: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 2.872248ms)
May 21 07:44:57.141: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 3.069225ms)
May 21 07:44:57.141: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 3.267138ms)
May 21 07:44:57.141: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.116208ms)
May 21 07:44:57.141: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 2.968761ms)
May 21 07:44:57.142: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.795315ms)
May 21 07:44:57.142: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 3.718709ms)
May 21 07:44:57.142: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 3.530022ms)
May 21 07:44:57.143: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 3.706671ms)
May 21 07:44:57.143: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.91743ms)
May 21 07:44:57.143: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 4.656334ms)
May 21 07:44:57.144: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 5.906825ms)
May 21 07:44:57.145: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 6.835372ms)
May 21 07:44:57.145: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 6.19369ms)
May 21 07:44:57.145: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 6.333251ms)
May 21 07:44:57.145: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 6.604187ms)
May 21 07:44:57.149: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 4.00117ms)
May 21 07:44:57.150: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.263915ms)
May 21 07:44:57.150: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 4.392679ms)
May 21 07:44:57.150: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.359012ms)
May 21 07:44:57.150: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 4.574754ms)
May 21 07:44:57.151: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.331125ms)
May 21 07:44:57.151: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 5.015022ms)
May 21 07:44:57.151: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 5.295072ms)
May 21 07:44:57.152: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 5.676002ms)
May 21 07:44:57.152: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 6.56267ms)
May 21 07:44:57.152: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 6.32829ms)
May 21 07:44:57.153: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 7.118651ms)
May 21 07:44:57.153: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 6.673174ms)
May 21 07:44:57.153: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 6.536865ms)
May 21 07:44:57.153: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 7.181822ms)
May 21 07:44:57.153: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 7.123385ms)
May 21 07:44:57.157: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 3.506983ms)
May 21 07:44:57.157: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 4.017521ms)
May 21 07:44:57.157: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 3.73108ms)
May 21 07:44:57.158: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.94836ms)
May 21 07:44:57.159: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 5.394857ms)
May 21 07:44:57.159: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 5.644719ms)
May 21 07:44:57.159: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 5.817451ms)
May 21 07:44:57.159: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 6.005438ms)
May 21 07:44:57.159: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 6.076966ms)
May 21 07:44:57.160: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 5.727709ms)
May 21 07:44:57.160: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 6.902262ms)
May 21 07:44:57.161: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 7.274087ms)
May 21 07:44:57.161: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 7.49724ms)
May 21 07:44:57.161: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 7.203227ms)
May 21 07:44:57.161: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 7.472608ms)
May 21 07:44:57.161: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 8.041457ms)
May 21 07:44:57.164: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.078671ms)
May 21 07:44:57.166: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 4.170262ms)
May 21 07:44:57.166: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.468103ms)
May 21 07:44:57.166: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 4.705669ms)
May 21 07:44:57.166: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.680358ms)
May 21 07:44:57.167: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 5.21206ms)
May 21 07:44:57.167: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 5.309474ms)
May 21 07:44:57.167: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 5.54479ms)
May 21 07:44:57.167: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 5.357416ms)
May 21 07:44:57.168: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 5.627027ms)
May 21 07:44:57.168: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 6.283112ms)
May 21 07:44:57.168: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 7.042234ms)
May 21 07:44:57.168: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 6.899646ms)
May 21 07:44:57.170: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 7.549982ms)
May 21 07:44:57.170: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 8.05769ms)
May 21 07:44:57.171: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 8.765158ms)
May 21 07:44:57.175: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.072325ms)
May 21 07:44:57.175: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 4.457575ms)
May 21 07:44:57.175: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 4.576325ms)
May 21 07:44:57.175: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.541801ms)
May 21 07:44:57.175: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.655874ms)
May 21 07:44:57.176: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 4.50987ms)
May 21 07:44:57.176: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 4.654333ms)
May 21 07:44:57.176: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 5.209573ms)
May 21 07:44:57.176: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 5.299543ms)
May 21 07:44:57.176: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 5.096229ms)
May 21 07:44:57.177: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 5.920915ms)
May 21 07:44:57.177: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 6.197919ms)
May 21 07:44:57.177: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 6.406857ms)
May 21 07:44:57.178: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 6.928946ms)
May 21 07:44:57.179: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 7.431384ms)
May 21 07:44:57.179: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 7.343259ms)
May 21 07:44:57.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 3.916458ms)
May 21 07:44:57.183: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.50054ms)
May 21 07:44:57.184: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.608498ms)
May 21 07:44:57.184: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 4.813017ms)
May 21 07:44:57.184: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 5.198565ms)
May 21 07:44:57.184: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 5.004722ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 6.770998ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 7.352155ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 6.790562ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 6.863303ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 7.071646ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 7.036394ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 7.300351ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 6.830678ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 6.829338ms)
May 21 07:44:57.186: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 7.291444ms)
May 21 07:44:57.189: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 2.643465ms)
May 21 07:44:57.189: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 2.447957ms)
May 21 07:44:57.189: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 2.291188ms)
May 21 07:44:57.189: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 2.577213ms)
May 21 07:44:57.190: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 2.983025ms)
May 21 07:44:57.190: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.23715ms)
May 21 07:44:57.191: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 3.506138ms)
May 21 07:44:57.191: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.749701ms)
May 21 07:44:57.191: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 4.15325ms)
May 21 07:44:57.191: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.306627ms)
May 21 07:44:57.193: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 6.035674ms)
May 21 07:44:57.194: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 7.0824ms)
May 21 07:44:57.195: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 7.97681ms)
May 21 07:44:57.195: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 8.455123ms)
May 21 07:44:57.195: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 8.39912ms)
May 21 07:44:57.195: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 7.997899ms)
May 21 07:44:57.198: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 2.812202ms)
May 21 07:44:57.199: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.240425ms)
May 21 07:44:57.199: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.65523ms)
May 21 07:44:57.199: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 3.837714ms)
May 21 07:44:57.199: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.0476ms)
May 21 07:44:57.199: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 4.152151ms)
May 21 07:44:57.200: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 4.182255ms)
May 21 07:44:57.200: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 4.075628ms)
May 21 07:44:57.200: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.041714ms)
May 21 07:44:57.200: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 4.20646ms)
May 21 07:44:57.201: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 4.950683ms)
May 21 07:44:57.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 5.856056ms)
May 21 07:44:57.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 6.685455ms)
May 21 07:44:57.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 6.641153ms)
May 21 07:44:57.202: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 7.398695ms)
May 21 07:44:57.203: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 7.091662ms)
May 21 07:44:57.206: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 3.911109ms)
May 21 07:44:57.207: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 3.723034ms)
May 21 07:44:57.207: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 4.149076ms)
May 21 07:44:57.207: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 4.349946ms)
May 21 07:44:57.207: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.841667ms)
May 21 07:44:57.208: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 5.13923ms)
May 21 07:44:57.208: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 4.826575ms)
May 21 07:44:57.208: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 5.115289ms)
May 21 07:44:57.208: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 5.384767ms)
May 21 07:44:57.209: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 5.620891ms)
May 21 07:44:57.210: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 6.741796ms)
May 21 07:44:57.210: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 7.494352ms)
May 21 07:44:57.210: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 7.699117ms)
May 21 07:44:57.211: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 7.812412ms)
May 21 07:44:57.211: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 7.760146ms)
May 21 07:44:57.211: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 7.904193ms)
May 21 07:44:57.215: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 3.812385ms)
May 21 07:44:57.215: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.029014ms)
May 21 07:44:57.216: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 4.580994ms)
May 21 07:44:57.216: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.000283ms)
May 21 07:44:57.216: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 5.153305ms)
May 21 07:44:57.217: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 5.491059ms)
May 21 07:44:57.218: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 6.28368ms)
May 21 07:44:57.218: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 5.898225ms)
May 21 07:44:57.218: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 6.279209ms)
May 21 07:44:57.218: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 6.59143ms)
May 21 07:44:57.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 7.208803ms)
May 21 07:44:57.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 7.283204ms)
May 21 07:44:57.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 7.370162ms)
May 21 07:44:57.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 7.193449ms)
May 21 07:44:57.219: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 7.656601ms)
May 21 07:44:57.220: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 8.213114ms)
May 21 07:44:57.222: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 2.167803ms)
May 21 07:44:57.222: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 2.614271ms)
May 21 07:44:57.222: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 2.401922ms)
May 21 07:44:57.222: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 2.653097ms)
May 21 07:44:57.223: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 2.89787ms)
May 21 07:44:57.224: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 3.58558ms)
May 21 07:44:57.224: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.070639ms)
May 21 07:44:57.224: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 4.18431ms)
May 21 07:44:57.225: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.58424ms)
May 21 07:44:57.225: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 4.524051ms)
May 21 07:44:57.225: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 4.708727ms)
May 21 07:44:57.226: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 5.572159ms)
May 21 07:44:57.226: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 6.312481ms)
May 21 07:44:57.226: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 5.986277ms)
May 21 07:44:57.226: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 6.68976ms)
May 21 07:44:57.227: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 6.16762ms)
May 21 07:44:57.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 3.950763ms)
May 21 07:44:57.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.957117ms)
May 21 07:44:57.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 4.198325ms)
May 21 07:44:57.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 4.451929ms)
May 21 07:44:57.231: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.445908ms)
May 21 07:44:57.232: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 5.133874ms)
May 21 07:44:57.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 5.365917ms)
May 21 07:44:57.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 6.370118ms)
May 21 07:44:57.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 6.030051ms)
May 21 07:44:57.233: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 6.291169ms)
May 21 07:44:57.234: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 6.791555ms)
May 21 07:44:57.234: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 6.461275ms)
May 21 07:44:57.234: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 7.459702ms)
May 21 07:44:57.234: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 6.909991ms)
May 21 07:44:57.241: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 13.65382ms)
May 21 07:44:57.241: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 13.711113ms)
May 21 07:44:57.247: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 5.545973ms)
May 21 07:44:57.248: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 6.288423ms)
May 21 07:44:57.249: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 7.29414ms)
May 21 07:44:57.249: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 7.094541ms)
May 21 07:44:57.249: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 6.846438ms)
May 21 07:44:57.249: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 7.15554ms)
May 21 07:44:57.249: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 7.163937ms)
May 21 07:44:57.249: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 7.656478ms)
May 21 07:44:57.249: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 8.038815ms)
May 21 07:44:57.250: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 8.136165ms)
May 21 07:44:57.251: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 9.157187ms)
May 21 07:44:57.259: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 17.738468ms)
May 21 07:44:57.260: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 18.953667ms)
May 21 07:44:57.261: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 19.393529ms)
May 21 07:44:57.261: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 19.749458ms)
May 21 07:44:57.269: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 27.401751ms)
May 21 07:44:57.273: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.893061ms)
May 21 07:44:57.273: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.97999ms)
May 21 07:44:57.275: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 5.85439ms)
May 21 07:44:57.276: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 6.305136ms)
May 21 07:44:57.276: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 6.430619ms)
May 21 07:44:57.276: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 6.581443ms)
May 21 07:44:57.280: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 10.998508ms)
May 21 07:44:57.282: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 12.48375ms)
May 21 07:44:57.282: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 12.775205ms)
May 21 07:44:57.282: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 12.881725ms)
May 21 07:44:57.283: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 13.594619ms)
May 21 07:44:57.284: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 14.622768ms)
May 21 07:44:57.284: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 14.927951ms)
May 21 07:44:57.285: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 15.213737ms)
May 21 07:44:57.285: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 15.385236ms)
May 21 07:44:57.285: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 16.064181ms)
May 21 07:44:57.289: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.015048ms)
May 21 07:44:57.289: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 2.967094ms)
May 21 07:44:57.289: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 3.339288ms)
May 21 07:44:57.289: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 3.262002ms)
May 21 07:44:57.289: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 3.802809ms)
May 21 07:44:57.290: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 3.376563ms)
May 21 07:44:57.290: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.290043ms)
May 21 07:44:57.290: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 4.396831ms)
May 21 07:44:57.294: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 7.91788ms)
May 21 07:44:57.294: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 8.136922ms)
May 21 07:44:57.295: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 9.246527ms)
May 21 07:44:57.299: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 13.799383ms)
May 21 07:44:57.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 14.290423ms)
May 21 07:44:57.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 14.206803ms)
May 21 07:44:57.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 14.507355ms)
May 21 07:44:57.300: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 14.975113ms)
May 21 07:44:57.303: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 2.089462ms)
May 21 07:44:57.303: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 2.964725ms)
May 21 07:44:57.304: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 3.050766ms)
May 21 07:44:57.304: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 3.040072ms)
May 21 07:44:57.305: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 3.782482ms)
May 21 07:44:57.305: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.972878ms)
May 21 07:44:57.306: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 4.921793ms)
May 21 07:44:57.306: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 5.201038ms)
May 21 07:44:57.306: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.929731ms)
May 21 07:44:57.306: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 5.151585ms)
May 21 07:44:57.311: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 9.991441ms)
May 21 07:44:57.313: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 11.801193ms)
May 21 07:44:57.313: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 12.712226ms)
May 21 07:44:57.313: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 12.13386ms)
May 21 07:44:57.313: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 12.588414ms)
May 21 07:44:57.314: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 12.426019ms)
May 21 07:44:57.318: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 3.635783ms)
May 21 07:44:57.318: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 4.619254ms)
May 21 07:44:57.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.144219ms)
May 21 07:44:57.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.51299ms)
May 21 07:44:57.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 4.825078ms)
May 21 07:44:57.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.880255ms)
May 21 07:44:57.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 4.741561ms)
May 21 07:44:57.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 5.083523ms)
May 21 07:44:57.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.843467ms)
May 21 07:44:57.319: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 4.718862ms)
May 21 07:44:57.324: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 9.94553ms)
May 21 07:44:57.331: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 17.018749ms)
May 21 07:44:57.331: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 17.212611ms)
May 21 07:44:57.331: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 17.292852ms)
May 21 07:44:57.331: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 17.173949ms)
May 21 07:44:57.331: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 16.972934ms)
May 21 07:44:57.335: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.974098ms)
May 21 07:44:57.336: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 4.582983ms)
May 21 07:44:57.336: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 4.299696ms)
May 21 07:44:57.336: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 4.828833ms)
May 21 07:44:57.337: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 4.920833ms)
May 21 07:44:57.337: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 5.52158ms)
May 21 07:44:57.337: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 5.598259ms)
May 21 07:44:57.337: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 5.687441ms)
May 21 07:44:57.343: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 11.299537ms)
May 21 07:44:57.344: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 11.517193ms)
May 21 07:44:57.345: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 13.403367ms)
May 21 07:44:57.346: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 13.973205ms)
May 21 07:44:57.346: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 14.514803ms)
May 21 07:44:57.346: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 14.261699ms)
May 21 07:44:57.346: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 14.244377ms)
May 21 07:44:57.346: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 15.030132ms)
May 21 07:44:57.349: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 2.630496ms)
May 21 07:44:57.350: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:443/proxy/... (200; 3.070914ms)
May 21 07:44:57.350: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:1080/proxy/... (200; 3.476117ms)
May 21 07:44:57.350: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:1080/proxy/rewri... (200; 3.371ms)
May 21 07:44:57.350: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.317352ms)
May 21 07:44:57.351: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd/proxy/rewriteme"... (200; 3.261148ms)
May 21 07:44:57.351: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/http:proxy-service-sltzl-d9wjd:160/proxy/: foo (200; 3.906555ms)
May 21 07:44:57.351: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:460/proxy/: tls baz (200; 3.663512ms)
May 21 07:44:57.351: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/proxy-service-sltzl-d9wjd:162/proxy/: bar (200; 3.81093ms)
May 21 07:44:57.351: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/pods/https:proxy-service-sltzl-d9wjd:462/proxy/: tls qux (200; 4.099672ms)
May 21 07:44:57.352: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname2/proxy/: tls qux (200; 5.188778ms)
May 21 07:44:57.353: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/https:proxy-service-sltzl:tlsportname1/proxy/: tls baz (200; 6.430972ms)
May 21 07:44:57.354: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname2/proxy/: bar (200; 7.045055ms)
May 21 07:44:57.354: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname1/proxy/: foo (200; 7.46945ms)
May 21 07:44:57.354: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/proxy-service-sltzl:portname1/proxy/: foo (200; 7.092799ms)
May 21 07:44:57.354: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6pdnh/services/http:proxy-service-sltzl:portname2/proxy/: bar (200; 7.040179ms)
STEP: deleting ReplicationController proxy-service-sltzl in namespace e2e-tests-proxy-6pdnh, will wait for the garbage collector to delete the pods
May 21 07:44:57.411: INFO: Deleting ReplicationController proxy-service-sltzl took: 4.817672ms
May 21 07:44:57.511: INFO: Terminating ReplicationController proxy-service-sltzl pods took: 100.147393ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:45:04.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-6pdnh" for this suite.
May 21 07:45:10.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:45:10.145: INFO: namespace: e2e-tests-proxy-6pdnh, resource: bindings, ignored listing per whitelist
May 21 07:45:10.178: INFO: namespace e2e-tests-proxy-6pdnh deletion completed in 6.062929991s

• [SLOW TEST:18.164 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:45:10.179: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
May 21 07:45:10.221: INFO: Waiting up to 5m0s for pod "client-containers-5c1eef72-7b9c-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-containers-qc6xs" to be "success or failure"
May 21 07:45:10.222: INFO: Pod "client-containers-5c1eef72-7b9c-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.57833ms
May 21 07:45:12.225: INFO: Pod "client-containers-5c1eef72-7b9c-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004051687s
STEP: Saw pod success
May 21 07:45:12.225: INFO: Pod "client-containers-5c1eef72-7b9c-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:45:12.226: INFO: Trying to get logs from node 192.168.5.21 pod client-containers-5c1eef72-7b9c-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:45:12.242: INFO: Waiting for pod client-containers-5c1eef72-7b9c-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:45:12.243: INFO: Pod client-containers-5c1eef72-7b9c-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:45:12.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-qc6xs" for this suite.
May 21 07:45:18.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:45:18.274: INFO: namespace: e2e-tests-containers-qc6xs, resource: bindings, ignored listing per whitelist
May 21 07:45:18.315: INFO: namespace e2e-tests-containers-qc6xs deletion completed in 6.069237798s

• [SLOW TEST:8.136 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:45:18.315: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-tpv8h
I0521 07:45:18.357251      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-tpv8h, replica count: 1
I0521 07:45:19.407572      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 07:45:20.407760      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 07:45:20.517: INFO: Created: latency-svc-p88sk
May 21 07:45:20.521: INFO: Got endpoints: latency-svc-p88sk [13.595757ms]
May 21 07:45:20.546: INFO: Created: latency-svc-8s6qv
May 21 07:45:20.550: INFO: Got endpoints: latency-svc-8s6qv [28.259358ms]
May 21 07:45:20.550: INFO: Created: latency-svc-r4s2h
May 21 07:45:20.572: INFO: Got endpoints: latency-svc-r4s2h [49.952193ms]
May 21 07:45:20.572: INFO: Created: latency-svc-zgvcj
May 21 07:45:20.593: INFO: Created: latency-svc-9dkwz
May 21 07:45:20.594: INFO: Got endpoints: latency-svc-zgvcj [72.109251ms]
May 21 07:45:20.597: INFO: Got endpoints: latency-svc-9dkwz [75.354474ms]
May 21 07:45:20.602: INFO: Created: latency-svc-l4t6r
May 21 07:45:20.608: INFO: Got endpoints: latency-svc-l4t6r [85.360826ms]
May 21 07:45:20.608: INFO: Created: latency-svc-5ltxw
May 21 07:45:20.612: INFO: Got endpoints: latency-svc-5ltxw [89.828042ms]
May 21 07:45:20.617: INFO: Created: latency-svc-bjmq6
May 21 07:45:20.622: INFO: Got endpoints: latency-svc-bjmq6 [99.473684ms]
May 21 07:45:20.628: INFO: Created: latency-svc-lbppw
May 21 07:45:20.645: INFO: Got endpoints: latency-svc-lbppw [122.009402ms]
May 21 07:45:20.648: INFO: Created: latency-svc-dgdpg
May 21 07:45:20.653: INFO: Got endpoints: latency-svc-dgdpg [129.794359ms]
May 21 07:45:20.657: INFO: Created: latency-svc-jzjls
May 21 07:45:20.662: INFO: Got endpoints: latency-svc-jzjls [138.602431ms]
May 21 07:45:20.664: INFO: Created: latency-svc-wtfn4
May 21 07:45:20.668: INFO: Got endpoints: latency-svc-wtfn4 [144.153101ms]
May 21 07:45:20.669: INFO: Created: latency-svc-69sff
May 21 07:45:20.674: INFO: Got endpoints: latency-svc-69sff [149.931804ms]
May 21 07:45:20.676: INFO: Created: latency-svc-z5qmd
May 21 07:45:20.680: INFO: Got endpoints: latency-svc-z5qmd [156.096857ms]
May 21 07:45:20.682: INFO: Created: latency-svc-4lcgb
May 21 07:45:20.685: INFO: Got endpoints: latency-svc-4lcgb [160.781913ms]
May 21 07:45:20.686: INFO: Created: latency-svc-8xmf7
May 21 07:45:20.689: INFO: Got endpoints: latency-svc-8xmf7 [164.981067ms]
May 21 07:45:20.691: INFO: Created: latency-svc-gqfl7
May 21 07:45:20.699: INFO: Got endpoints: latency-svc-gqfl7 [148.849628ms]
May 21 07:45:20.699: INFO: Created: latency-svc-hlpqj
May 21 07:45:20.702: INFO: Created: latency-svc-xcfl7
May 21 07:45:20.706: INFO: Got endpoints: latency-svc-hlpqj [134.831305ms]
May 21 07:45:20.707: INFO: Got endpoints: latency-svc-xcfl7 [113.3634ms]
May 21 07:45:20.710: INFO: Created: latency-svc-rk88z
May 21 07:45:20.714: INFO: Created: latency-svc-zc666
May 21 07:45:20.721: INFO: Created: latency-svc-wvd88
May 21 07:45:20.721: INFO: Got endpoints: latency-svc-rk88z [124.087653ms]
May 21 07:45:20.722: INFO: Got endpoints: latency-svc-zc666 [113.906015ms]
May 21 07:45:20.729: INFO: Got endpoints: latency-svc-wvd88 [117.275086ms]
May 21 07:45:20.731: INFO: Created: latency-svc-fhblh
May 21 07:45:20.739: INFO: Got endpoints: latency-svc-fhblh [117.141492ms]
May 21 07:45:20.740: INFO: Created: latency-svc-9drwn
May 21 07:45:20.746: INFO: Got endpoints: latency-svc-9drwn [101.194457ms]
May 21 07:45:20.753: INFO: Created: latency-svc-m5p7t
May 21 07:45:20.759: INFO: Created: latency-svc-8zrcg
May 21 07:45:20.764: INFO: Got endpoints: latency-svc-m5p7t [111.666981ms]
May 21 07:45:20.765: INFO: Got endpoints: latency-svc-8zrcg [103.712706ms]
May 21 07:45:20.767: INFO: Created: latency-svc-rl5gc
May 21 07:45:20.779: INFO: Created: latency-svc-wpfjd
May 21 07:45:20.785: INFO: Created: latency-svc-lv49k
May 21 07:45:20.791: INFO: Created: latency-svc-w9z8b
May 21 07:45:20.794: INFO: Created: latency-svc-hnxld
May 21 07:45:20.799: INFO: Created: latency-svc-4v4rv
May 21 07:45:20.804: INFO: Created: latency-svc-kmjmp
May 21 07:45:20.808: INFO: Got endpoints: latency-svc-rl5gc [140.032204ms]
May 21 07:45:20.818: INFO: Created: latency-svc-j6c26
May 21 07:45:20.818: INFO: Got endpoints: latency-svc-4v4rv [119.915857ms]
May 21 07:45:20.819: INFO: Got endpoints: latency-svc-lv49k [138.958135ms]
May 21 07:45:20.819: INFO: Got endpoints: latency-svc-hnxld [130.09717ms]
May 21 07:45:20.819: INFO: Got endpoints: latency-svc-wpfjd [145.145861ms]
May 21 07:45:20.819: INFO: Got endpoints: latency-svc-w9z8b [134.28674ms]
May 21 07:45:20.826: INFO: Got endpoints: latency-svc-kmjmp [119.897977ms]
May 21 07:45:20.827: INFO: Got endpoints: latency-svc-j6c26 [119.275897ms]
May 21 07:45:20.842: INFO: Created: latency-svc-l2wgz
May 21 07:45:20.849: INFO: Got endpoints: latency-svc-l2wgz [127.061807ms]
May 21 07:45:20.865: INFO: Created: latency-svc-8mbwv
May 21 07:45:20.875: INFO: Got endpoints: latency-svc-8mbwv [153.767346ms]
May 21 07:45:20.876: INFO: Created: latency-svc-m2pql
May 21 07:45:20.880: INFO: Got endpoints: latency-svc-m2pql [151.131434ms]
May 21 07:45:20.884: INFO: Created: latency-svc-6rlgj
May 21 07:45:20.885: INFO: Created: latency-svc-gk8jd
May 21 07:45:20.908: INFO: Created: latency-svc-t9pls
May 21 07:45:20.925: INFO: Got endpoints: latency-svc-6rlgj [185.480344ms]
May 21 07:45:20.928: INFO: Created: latency-svc-lk9pd
May 21 07:45:20.936: INFO: Created: latency-svc-k6s5j
May 21 07:45:20.950: INFO: Created: latency-svc-47lxl
May 21 07:45:20.955: INFO: Created: latency-svc-62mvs
May 21 07:45:20.965: INFO: Created: latency-svc-t2bd4
May 21 07:45:20.973: INFO: Got endpoints: latency-svc-gk8jd [226.876967ms]
May 21 07:45:20.976: INFO: Created: latency-svc-v5vtd
May 21 07:45:20.982: INFO: Created: latency-svc-9j96j
May 21 07:45:21.001: INFO: Created: latency-svc-rlggd
May 21 07:45:21.013: INFO: Created: latency-svc-ktnh2
May 21 07:45:21.019: INFO: Created: latency-svc-xj56p
May 21 07:45:21.023: INFO: Got endpoints: latency-svc-t9pls [259.031566ms]
May 21 07:45:21.025: INFO: Created: latency-svc-cb6j9
May 21 07:45:21.037: INFO: Created: latency-svc-mthk7
May 21 07:45:21.047: INFO: Created: latency-svc-nlrjt
May 21 07:45:21.062: INFO: Created: latency-svc-gtfj6
May 21 07:45:21.067: INFO: Created: latency-svc-7pjv5
May 21 07:45:21.071: INFO: Got endpoints: latency-svc-lk9pd [305.505062ms]
May 21 07:45:21.077: INFO: Created: latency-svc-mqrfl
May 21 07:45:21.122: INFO: Got endpoints: latency-svc-k6s5j [313.903797ms]
May 21 07:45:21.143: INFO: Created: latency-svc-qwx7x
May 21 07:45:21.172: INFO: Got endpoints: latency-svc-47lxl [353.781682ms]
May 21 07:45:21.187: INFO: Created: latency-svc-9gq2v
May 21 07:45:21.221: INFO: Got endpoints: latency-svc-62mvs [402.537725ms]
May 21 07:45:21.227: INFO: Created: latency-svc-rmg67
May 21 07:45:21.273: INFO: Got endpoints: latency-svc-t2bd4 [453.925599ms]
May 21 07:45:21.281: INFO: Created: latency-svc-vnxzs
May 21 07:45:21.323: INFO: Got endpoints: latency-svc-v5vtd [504.460996ms]
May 21 07:45:21.329: INFO: Created: latency-svc-wm2kn
May 21 07:45:21.372: INFO: Got endpoints: latency-svc-9j96j [552.548305ms]
May 21 07:45:21.380: INFO: Created: latency-svc-kjqws
May 21 07:45:21.422: INFO: Got endpoints: latency-svc-rlggd [596.009037ms]
May 21 07:45:21.440: INFO: Created: latency-svc-tlstc
May 21 07:45:21.472: INFO: Got endpoints: latency-svc-ktnh2 [645.818798ms]
May 21 07:45:21.484: INFO: Created: latency-svc-pslhf
May 21 07:45:21.524: INFO: Got endpoints: latency-svc-xj56p [675.457499ms]
May 21 07:45:21.534: INFO: Created: latency-svc-csft9
May 21 07:45:21.580: INFO: Got endpoints: latency-svc-cb6j9 [704.918639ms]
May 21 07:45:21.587: INFO: Created: latency-svc-f66wg
May 21 07:45:21.624: INFO: Got endpoints: latency-svc-mthk7 [743.203118ms]
May 21 07:45:21.630: INFO: Created: latency-svc-rd4rw
May 21 07:45:21.677: INFO: Got endpoints: latency-svc-nlrjt [752.533036ms]
May 21 07:45:21.685: INFO: Created: latency-svc-4rlx8
May 21 07:45:21.722: INFO: Got endpoints: latency-svc-gtfj6 [748.254345ms]
May 21 07:45:21.735: INFO: Created: latency-svc-mtt2q
May 21 07:45:21.775: INFO: Got endpoints: latency-svc-7pjv5 [751.373031ms]
May 21 07:45:21.786: INFO: Created: latency-svc-kthld
May 21 07:45:21.827: INFO: Got endpoints: latency-svc-mqrfl [755.741986ms]
May 21 07:45:21.836: INFO: Created: latency-svc-49gvv
May 21 07:45:21.878: INFO: Got endpoints: latency-svc-qwx7x [755.949783ms]
May 21 07:45:21.884: INFO: Created: latency-svc-b9ndk
May 21 07:45:21.922: INFO: Got endpoints: latency-svc-9gq2v [749.358691ms]
May 21 07:45:21.933: INFO: Created: latency-svc-7tdmz
May 21 07:45:21.977: INFO: Got endpoints: latency-svc-rmg67 [755.807062ms]
May 21 07:45:21.988: INFO: Created: latency-svc-vvm6t
May 21 07:45:22.023: INFO: Got endpoints: latency-svc-vnxzs [750.436479ms]
May 21 07:45:22.039: INFO: Created: latency-svc-j982g
May 21 07:45:22.074: INFO: Got endpoints: latency-svc-wm2kn [750.850459ms]
May 21 07:45:22.081: INFO: Created: latency-svc-vrhdj
May 21 07:45:22.122: INFO: Got endpoints: latency-svc-kjqws [750.803223ms]
May 21 07:45:22.133: INFO: Created: latency-svc-ld84d
May 21 07:45:22.171: INFO: Got endpoints: latency-svc-tlstc [748.746091ms]
May 21 07:45:22.179: INFO: Created: latency-svc-k6s6l
May 21 07:45:22.225: INFO: Got endpoints: latency-svc-pslhf [752.989732ms]
May 21 07:45:22.245: INFO: Created: latency-svc-l5l2g
May 21 07:45:22.278: INFO: Got endpoints: latency-svc-csft9 [753.972656ms]
May 21 07:45:22.289: INFO: Created: latency-svc-9vd9c
May 21 07:45:22.322: INFO: Got endpoints: latency-svc-f66wg [741.164885ms]
May 21 07:45:22.328: INFO: Created: latency-svc-5wprd
May 21 07:45:22.372: INFO: Got endpoints: latency-svc-rd4rw [748.509506ms]
May 21 07:45:22.393: INFO: Created: latency-svc-dpvpf
May 21 07:45:22.421: INFO: Got endpoints: latency-svc-4rlx8 [743.992948ms]
May 21 07:45:22.432: INFO: Created: latency-svc-m6kqw
May 21 07:45:22.472: INFO: Got endpoints: latency-svc-mtt2q [749.955457ms]
May 21 07:45:22.479: INFO: Created: latency-svc-t5hns
May 21 07:45:22.523: INFO: Got endpoints: latency-svc-kthld [748.003315ms]
May 21 07:45:22.531: INFO: Created: latency-svc-z5h4z
May 21 07:45:22.572: INFO: Got endpoints: latency-svc-49gvv [745.629269ms]
May 21 07:45:22.579: INFO: Created: latency-svc-ggwxs
May 21 07:45:22.627: INFO: Got endpoints: latency-svc-b9ndk [749.059213ms]
May 21 07:45:22.651: INFO: Created: latency-svc-tflcc
May 21 07:45:22.671: INFO: Got endpoints: latency-svc-7tdmz [749.333144ms]
May 21 07:45:22.682: INFO: Created: latency-svc-fb98b
May 21 07:45:22.721: INFO: Got endpoints: latency-svc-vvm6t [744.20073ms]
May 21 07:45:22.728: INFO: Created: latency-svc-xhhdw
May 21 07:45:22.779: INFO: Got endpoints: latency-svc-j982g [755.943739ms]
May 21 07:45:22.787: INFO: Created: latency-svc-pdb54
May 21 07:45:22.821: INFO: Got endpoints: latency-svc-vrhdj [746.95788ms]
May 21 07:45:22.830: INFO: Created: latency-svc-q66ld
May 21 07:45:22.873: INFO: Got endpoints: latency-svc-ld84d [751.011154ms]
May 21 07:45:22.884: INFO: Created: latency-svc-c6shk
May 21 07:45:22.930: INFO: Got endpoints: latency-svc-k6s6l [759.216549ms]
May 21 07:45:22.941: INFO: Created: latency-svc-tvmx4
May 21 07:45:22.971: INFO: Got endpoints: latency-svc-l5l2g [745.978192ms]
May 21 07:45:22.980: INFO: Created: latency-svc-k4bqg
May 21 07:45:23.023: INFO: Got endpoints: latency-svc-9vd9c [745.082915ms]
May 21 07:45:23.042: INFO: Created: latency-svc-fp6pj
May 21 07:45:23.079: INFO: Got endpoints: latency-svc-5wprd [757.31977ms]
May 21 07:45:23.090: INFO: Created: latency-svc-vpjnp
May 21 07:45:23.123: INFO: Got endpoints: latency-svc-dpvpf [750.826192ms]
May 21 07:45:23.132: INFO: Created: latency-svc-9zkpd
May 21 07:45:23.172: INFO: Got endpoints: latency-svc-m6kqw [751.029788ms]
May 21 07:45:23.181: INFO: Created: latency-svc-5crsf
May 21 07:45:23.228: INFO: Got endpoints: latency-svc-t5hns [756.760754ms]
May 21 07:45:23.240: INFO: Created: latency-svc-s66hl
May 21 07:45:23.273: INFO: Got endpoints: latency-svc-z5h4z [750.415515ms]
May 21 07:45:23.292: INFO: Created: latency-svc-nf797
May 21 07:45:23.323: INFO: Got endpoints: latency-svc-ggwxs [750.754885ms]
May 21 07:45:23.333: INFO: Created: latency-svc-72rqq
May 21 07:45:23.378: INFO: Got endpoints: latency-svc-tflcc [751.73396ms]
May 21 07:45:23.386: INFO: Created: latency-svc-mw9gd
May 21 07:45:23.422: INFO: Got endpoints: latency-svc-fb98b [750.533344ms]
May 21 07:45:23.432: INFO: Created: latency-svc-6klsl
May 21 07:45:23.478: INFO: Got endpoints: latency-svc-xhhdw [756.215071ms]
May 21 07:45:23.487: INFO: Created: latency-svc-4fqjq
May 21 07:45:23.524: INFO: Got endpoints: latency-svc-pdb54 [744.452057ms]
May 21 07:45:23.533: INFO: Created: latency-svc-wfsq2
May 21 07:45:23.571: INFO: Got endpoints: latency-svc-q66ld [750.009554ms]
May 21 07:45:23.581: INFO: Created: latency-svc-k9ct2
May 21 07:45:23.623: INFO: Got endpoints: latency-svc-c6shk [749.932597ms]
May 21 07:45:23.630: INFO: Created: latency-svc-wd752
May 21 07:45:23.672: INFO: Got endpoints: latency-svc-tvmx4 [741.73572ms]
May 21 07:45:23.681: INFO: Created: latency-svc-ncbf6
May 21 07:45:23.728: INFO: Got endpoints: latency-svc-k4bqg [756.115047ms]
May 21 07:45:23.744: INFO: Created: latency-svc-skg87
May 21 07:45:23.772: INFO: Got endpoints: latency-svc-fp6pj [749.167732ms]
May 21 07:45:23.780: INFO: Created: latency-svc-xfd7v
May 21 07:45:23.823: INFO: Got endpoints: latency-svc-vpjnp [743.586745ms]
May 21 07:45:23.833: INFO: Created: latency-svc-q6xxs
May 21 07:45:23.872: INFO: Got endpoints: latency-svc-9zkpd [749.323227ms]
May 21 07:45:23.884: INFO: Created: latency-svc-t4k97
May 21 07:45:23.921: INFO: Got endpoints: latency-svc-5crsf [748.988797ms]
May 21 07:45:23.930: INFO: Created: latency-svc-dbg2w
May 21 07:45:23.972: INFO: Got endpoints: latency-svc-s66hl [743.88064ms]
May 21 07:45:23.979: INFO: Created: latency-svc-szmqb
May 21 07:45:24.022: INFO: Got endpoints: latency-svc-nf797 [749.099629ms]
May 21 07:45:24.037: INFO: Created: latency-svc-cnjpk
May 21 07:45:24.072: INFO: Got endpoints: latency-svc-72rqq [749.282213ms]
May 21 07:45:24.078: INFO: Created: latency-svc-k8x9j
May 21 07:45:24.121: INFO: Got endpoints: latency-svc-mw9gd [742.92436ms]
May 21 07:45:24.128: INFO: Created: latency-svc-lxz5s
May 21 07:45:24.171: INFO: Got endpoints: latency-svc-6klsl [749.866902ms]
May 21 07:45:24.180: INFO: Created: latency-svc-skccf
May 21 07:45:24.221: INFO: Got endpoints: latency-svc-4fqjq [743.455015ms]
May 21 07:45:24.230: INFO: Created: latency-svc-b7ckm
May 21 07:45:24.280: INFO: Got endpoints: latency-svc-wfsq2 [756.658411ms]
May 21 07:45:24.292: INFO: Created: latency-svc-q9nwn
May 21 07:45:24.322: INFO: Got endpoints: latency-svc-k9ct2 [750.826067ms]
May 21 07:45:24.328: INFO: Created: latency-svc-9whtv
May 21 07:45:24.380: INFO: Got endpoints: latency-svc-wd752 [756.911461ms]
May 21 07:45:24.399: INFO: Created: latency-svc-b2pcm
May 21 07:45:24.421: INFO: Got endpoints: latency-svc-ncbf6 [749.116812ms]
May 21 07:45:24.429: INFO: Created: latency-svc-qkrrl
May 21 07:45:24.477: INFO: Got endpoints: latency-svc-skg87 [749.133844ms]
May 21 07:45:24.483: INFO: Created: latency-svc-cvj7j
May 21 07:45:24.521: INFO: Got endpoints: latency-svc-xfd7v [749.035535ms]
May 21 07:45:24.528: INFO: Created: latency-svc-hp4nh
May 21 07:45:24.572: INFO: Got endpoints: latency-svc-q6xxs [749.472882ms]
May 21 07:45:24.577: INFO: Created: latency-svc-wptgt
May 21 07:45:24.621: INFO: Got endpoints: latency-svc-t4k97 [748.740939ms]
May 21 07:45:24.632: INFO: Created: latency-svc-jg2rh
May 21 07:45:24.672: INFO: Got endpoints: latency-svc-dbg2w [751.023086ms]
May 21 07:45:24.680: INFO: Created: latency-svc-j778p
May 21 07:45:24.724: INFO: Got endpoints: latency-svc-szmqb [751.372582ms]
May 21 07:45:24.738: INFO: Created: latency-svc-6zxhq
May 21 07:45:24.772: INFO: Got endpoints: latency-svc-cnjpk [749.994815ms]
May 21 07:45:24.782: INFO: Created: latency-svc-vwmbz
May 21 07:45:24.827: INFO: Got endpoints: latency-svc-k8x9j [754.948496ms]
May 21 07:45:24.852: INFO: Created: latency-svc-8bhkh
May 21 07:45:24.874: INFO: Got endpoints: latency-svc-lxz5s [753.027744ms]
May 21 07:45:24.892: INFO: Created: latency-svc-dpfbg
May 21 07:45:24.927: INFO: Got endpoints: latency-svc-skccf [755.075033ms]
May 21 07:45:24.948: INFO: Created: latency-svc-mjd2m
May 21 07:45:24.973: INFO: Got endpoints: latency-svc-b7ckm [752.343494ms]
May 21 07:45:24.982: INFO: Created: latency-svc-jd4d9
May 21 07:45:25.041: INFO: Got endpoints: latency-svc-q9nwn [760.796401ms]
May 21 07:45:25.051: INFO: Created: latency-svc-9fv2h
May 21 07:45:25.072: INFO: Got endpoints: latency-svc-9whtv [750.101216ms]
May 21 07:45:25.079: INFO: Created: latency-svc-2f9cz
May 21 07:45:25.122: INFO: Got endpoints: latency-svc-b2pcm [741.392592ms]
May 21 07:45:25.131: INFO: Created: latency-svc-2zl6b
May 21 07:45:25.171: INFO: Got endpoints: latency-svc-qkrrl [749.913534ms]
May 21 07:45:25.180: INFO: Created: latency-svc-g7vpt
May 21 07:45:25.223: INFO: Got endpoints: latency-svc-cvj7j [745.912716ms]
May 21 07:45:25.240: INFO: Created: latency-svc-f7jl4
May 21 07:45:25.282: INFO: Got endpoints: latency-svc-hp4nh [760.401898ms]
May 21 07:45:25.298: INFO: Created: latency-svc-jqdrd
May 21 07:45:25.323: INFO: Got endpoints: latency-svc-wptgt [750.819536ms]
May 21 07:45:25.334: INFO: Created: latency-svc-sxk8g
May 21 07:45:25.379: INFO: Got endpoints: latency-svc-jg2rh [758.147854ms]
May 21 07:45:25.392: INFO: Created: latency-svc-l2499
May 21 07:45:25.423: INFO: Got endpoints: latency-svc-j778p [750.806574ms]
May 21 07:45:25.432: INFO: Created: latency-svc-crp8j
May 21 07:45:25.475: INFO: Got endpoints: latency-svc-6zxhq [751.065134ms]
May 21 07:45:25.482: INFO: Created: latency-svc-bxjc8
May 21 07:45:25.522: INFO: Got endpoints: latency-svc-vwmbz [749.334678ms]
May 21 07:45:25.531: INFO: Created: latency-svc-9x922
May 21 07:45:25.571: INFO: Got endpoints: latency-svc-8bhkh [744.097105ms]
May 21 07:45:25.578: INFO: Created: latency-svc-dnmzk
May 21 07:45:25.622: INFO: Got endpoints: latency-svc-dpfbg [747.82369ms]
May 21 07:45:25.631: INFO: Created: latency-svc-xghgp
May 21 07:45:25.674: INFO: Got endpoints: latency-svc-mjd2m [747.906057ms]
May 21 07:45:25.698: INFO: Created: latency-svc-mgbxm
May 21 07:45:25.724: INFO: Got endpoints: latency-svc-jd4d9 [750.76234ms]
May 21 07:45:25.735: INFO: Created: latency-svc-qdxwg
May 21 07:45:25.773: INFO: Got endpoints: latency-svc-9fv2h [731.712573ms]
May 21 07:45:25.779: INFO: Created: latency-svc-k57n6
May 21 07:45:25.823: INFO: Got endpoints: latency-svc-2f9cz [750.621632ms]
May 21 07:45:25.830: INFO: Created: latency-svc-sbrwp
May 21 07:45:25.871: INFO: Got endpoints: latency-svc-2zl6b [749.128755ms]
May 21 07:45:25.877: INFO: Created: latency-svc-nkdwf
May 21 07:45:25.921: INFO: Got endpoints: latency-svc-g7vpt [749.732452ms]
May 21 07:45:25.929: INFO: Created: latency-svc-7m94h
May 21 07:45:25.971: INFO: Got endpoints: latency-svc-f7jl4 [748.605721ms]
May 21 07:45:25.983: INFO: Created: latency-svc-qq8bv
May 21 07:45:26.023: INFO: Got endpoints: latency-svc-jqdrd [741.273012ms]
May 21 07:45:26.031: INFO: Created: latency-svc-5cdpv
May 21 07:45:26.073: INFO: Got endpoints: latency-svc-sxk8g [750.408251ms]
May 21 07:45:26.084: INFO: Created: latency-svc-qd4gf
May 21 07:45:26.121: INFO: Got endpoints: latency-svc-l2499 [741.939138ms]
May 21 07:45:26.127: INFO: Created: latency-svc-74hwq
May 21 07:45:26.179: INFO: Got endpoints: latency-svc-crp8j [755.819052ms]
May 21 07:45:26.186: INFO: Created: latency-svc-svrxr
May 21 07:45:26.222: INFO: Got endpoints: latency-svc-bxjc8 [747.258265ms]
May 21 07:45:26.230: INFO: Created: latency-svc-llbqz
May 21 07:45:26.274: INFO: Got endpoints: latency-svc-9x922 [752.575413ms]
May 21 07:45:26.283: INFO: Created: latency-svc-bjq9p
May 21 07:45:26.321: INFO: Got endpoints: latency-svc-dnmzk [749.809381ms]
May 21 07:45:26.330: INFO: Created: latency-svc-gfrq7
May 21 07:45:26.373: INFO: Got endpoints: latency-svc-xghgp [750.741609ms]
May 21 07:45:26.381: INFO: Created: latency-svc-52rxg
May 21 07:45:26.421: INFO: Got endpoints: latency-svc-mgbxm [746.853137ms]
May 21 07:45:26.429: INFO: Created: latency-svc-cbvnn
May 21 07:45:26.471: INFO: Got endpoints: latency-svc-qdxwg [747.290215ms]
May 21 07:45:26.480: INFO: Created: latency-svc-fxtbd
May 21 07:45:26.523: INFO: Got endpoints: latency-svc-k57n6 [749.579831ms]
May 21 07:45:26.528: INFO: Created: latency-svc-h9jnh
May 21 07:45:26.573: INFO: Got endpoints: latency-svc-sbrwp [749.625888ms]
May 21 07:45:26.578: INFO: Created: latency-svc-m4pr5
May 21 07:45:26.621: INFO: Got endpoints: latency-svc-nkdwf [750.190754ms]
May 21 07:45:26.632: INFO: Created: latency-svc-hh2rg
May 21 07:45:26.674: INFO: Got endpoints: latency-svc-7m94h [753.253213ms]
May 21 07:45:26.684: INFO: Created: latency-svc-cp8ml
May 21 07:45:26.726: INFO: Got endpoints: latency-svc-qq8bv [754.267171ms]
May 21 07:45:26.739: INFO: Created: latency-svc-92zbs
May 21 07:45:26.772: INFO: Got endpoints: latency-svc-5cdpv [749.23996ms]
May 21 07:45:26.785: INFO: Created: latency-svc-mnsv9
May 21 07:45:26.822: INFO: Got endpoints: latency-svc-qd4gf [748.932007ms]
May 21 07:45:26.832: INFO: Created: latency-svc-dwt7p
May 21 07:45:26.876: INFO: Got endpoints: latency-svc-74hwq [755.008266ms]
May 21 07:45:26.884: INFO: Created: latency-svc-8ln6g
May 21 07:45:26.922: INFO: Got endpoints: latency-svc-svrxr [743.167091ms]
May 21 07:45:26.932: INFO: Created: latency-svc-phk9n
May 21 07:45:26.973: INFO: Got endpoints: latency-svc-llbqz [750.44924ms]
May 21 07:45:26.983: INFO: Created: latency-svc-t6rqp
May 21 07:45:27.028: INFO: Got endpoints: latency-svc-bjq9p [753.361328ms]
May 21 07:45:27.035: INFO: Created: latency-svc-wdvx2
May 21 07:45:27.075: INFO: Got endpoints: latency-svc-gfrq7 [754.086091ms]
May 21 07:45:27.086: INFO: Created: latency-svc-sp78c
May 21 07:45:27.129: INFO: Got endpoints: latency-svc-52rxg [756.33085ms]
May 21 07:45:27.141: INFO: Created: latency-svc-72w99
May 21 07:45:27.171: INFO: Got endpoints: latency-svc-cbvnn [749.627483ms]
May 21 07:45:27.179: INFO: Created: latency-svc-mf2p8
May 21 07:45:27.221: INFO: Got endpoints: latency-svc-fxtbd [749.744572ms]
May 21 07:45:27.241: INFO: Created: latency-svc-2c97t
May 21 07:45:27.273: INFO: Got endpoints: latency-svc-h9jnh [749.875716ms]
May 21 07:45:27.280: INFO: Created: latency-svc-cpdb2
May 21 07:45:27.324: INFO: Got endpoints: latency-svc-m4pr5 [750.907869ms]
May 21 07:45:27.332: INFO: Created: latency-svc-zlrbx
May 21 07:45:27.371: INFO: Got endpoints: latency-svc-hh2rg [750.202257ms]
May 21 07:45:27.379: INFO: Created: latency-svc-wcqzc
May 21 07:45:27.423: INFO: Got endpoints: latency-svc-cp8ml [748.170245ms]
May 21 07:45:27.433: INFO: Created: latency-svc-vp2jn
May 21 07:45:27.472: INFO: Got endpoints: latency-svc-92zbs [746.503223ms]
May 21 07:45:27.482: INFO: Created: latency-svc-lx5k8
May 21 07:45:27.521: INFO: Got endpoints: latency-svc-mnsv9 [748.871915ms]
May 21 07:45:27.532: INFO: Created: latency-svc-5t7qd
May 21 07:45:27.575: INFO: Got endpoints: latency-svc-dwt7p [752.208361ms]
May 21 07:45:27.594: INFO: Created: latency-svc-65hnv
May 21 07:45:27.626: INFO: Got endpoints: latency-svc-8ln6g [749.184519ms]
May 21 07:45:27.634: INFO: Created: latency-svc-jmmx9
May 21 07:45:27.672: INFO: Got endpoints: latency-svc-phk9n [749.852586ms]
May 21 07:45:27.682: INFO: Created: latency-svc-4vmmp
May 21 07:45:27.722: INFO: Got endpoints: latency-svc-t6rqp [748.943774ms]
May 21 07:45:27.732: INFO: Created: latency-svc-v5qlf
May 21 07:45:27.771: INFO: Got endpoints: latency-svc-wdvx2 [743.30181ms]
May 21 07:45:27.778: INFO: Created: latency-svc-ltck7
May 21 07:45:27.824: INFO: Got endpoints: latency-svc-sp78c [748.20834ms]
May 21 07:45:27.831: INFO: Created: latency-svc-86769
May 21 07:45:27.872: INFO: Got endpoints: latency-svc-72w99 [742.997991ms]
May 21 07:45:27.879: INFO: Created: latency-svc-sjhhv
May 21 07:45:27.922: INFO: Got endpoints: latency-svc-mf2p8 [751.292873ms]
May 21 07:45:27.932: INFO: Created: latency-svc-2dfmd
May 21 07:45:27.972: INFO: Got endpoints: latency-svc-2c97t [751.065571ms]
May 21 07:45:27.983: INFO: Created: latency-svc-zv4wc
May 21 07:45:28.022: INFO: Got endpoints: latency-svc-cpdb2 [749.554873ms]
May 21 07:45:28.031: INFO: Created: latency-svc-gpnzg
May 21 07:45:28.078: INFO: Got endpoints: latency-svc-zlrbx [754.164681ms]
May 21 07:45:28.088: INFO: Created: latency-svc-68k6b
May 21 07:45:28.123: INFO: Got endpoints: latency-svc-wcqzc [751.929999ms]
May 21 07:45:28.131: INFO: Created: latency-svc-r6l7c
May 21 07:45:28.171: INFO: Got endpoints: latency-svc-vp2jn [748.4113ms]
May 21 07:45:28.178: INFO: Created: latency-svc-phx9l
May 21 07:45:28.226: INFO: Got endpoints: latency-svc-lx5k8 [753.486792ms]
May 21 07:45:28.236: INFO: Created: latency-svc-bxhjl
May 21 07:45:28.271: INFO: Got endpoints: latency-svc-5t7qd [749.94335ms]
May 21 07:45:28.282: INFO: Created: latency-svc-k5zrz
May 21 07:45:28.322: INFO: Got endpoints: latency-svc-65hnv [747.144781ms]
May 21 07:45:28.338: INFO: Created: latency-svc-4w8g5
May 21 07:45:28.373: INFO: Got endpoints: latency-svc-jmmx9 [746.830499ms]
May 21 07:45:28.422: INFO: Got endpoints: latency-svc-4vmmp [750.024208ms]
May 21 07:45:28.474: INFO: Got endpoints: latency-svc-v5qlf [752.002507ms]
May 21 07:45:28.525: INFO: Got endpoints: latency-svc-ltck7 [754.303648ms]
May 21 07:45:28.575: INFO: Got endpoints: latency-svc-86769 [750.99043ms]
May 21 07:45:28.622: INFO: Got endpoints: latency-svc-sjhhv [749.649459ms]
May 21 07:45:28.673: INFO: Got endpoints: latency-svc-2dfmd [750.867562ms]
May 21 07:45:28.733: INFO: Got endpoints: latency-svc-zv4wc [760.404111ms]
May 21 07:45:28.772: INFO: Got endpoints: latency-svc-gpnzg [750.134254ms]
May 21 07:45:28.822: INFO: Got endpoints: latency-svc-68k6b [743.753525ms]
May 21 07:45:28.871: INFO: Got endpoints: latency-svc-r6l7c [747.883788ms]
May 21 07:45:28.929: INFO: Got endpoints: latency-svc-phx9l [758.036558ms]
May 21 07:45:28.979: INFO: Got endpoints: latency-svc-bxhjl [753.660845ms]
May 21 07:45:29.022: INFO: Got endpoints: latency-svc-k5zrz [751.072221ms]
May 21 07:45:29.071: INFO: Got endpoints: latency-svc-4w8g5 [749.624682ms]
May 21 07:45:29.072: INFO: Latencies: [28.259358ms 49.952193ms 72.109251ms 75.354474ms 85.360826ms 89.828042ms 99.473684ms 101.194457ms 103.712706ms 111.666981ms 113.3634ms 113.906015ms 117.141492ms 117.275086ms 119.275897ms 119.897977ms 119.915857ms 122.009402ms 124.087653ms 127.061807ms 129.794359ms 130.09717ms 134.28674ms 134.831305ms 138.602431ms 138.958135ms 140.032204ms 144.153101ms 145.145861ms 148.849628ms 149.931804ms 151.131434ms 153.767346ms 156.096857ms 160.781913ms 164.981067ms 185.480344ms 226.876967ms 259.031566ms 305.505062ms 313.903797ms 353.781682ms 402.537725ms 453.925599ms 504.460996ms 552.548305ms 596.009037ms 645.818798ms 675.457499ms 704.918639ms 731.712573ms 741.164885ms 741.273012ms 741.392592ms 741.73572ms 741.939138ms 742.92436ms 742.997991ms 743.167091ms 743.203118ms 743.30181ms 743.455015ms 743.586745ms 743.753525ms 743.88064ms 743.992948ms 744.097105ms 744.20073ms 744.452057ms 745.082915ms 745.629269ms 745.912716ms 745.978192ms 746.503223ms 746.830499ms 746.853137ms 746.95788ms 747.144781ms 747.258265ms 747.290215ms 747.82369ms 747.883788ms 747.906057ms 748.003315ms 748.170245ms 748.20834ms 748.254345ms 748.4113ms 748.509506ms 748.605721ms 748.740939ms 748.746091ms 748.871915ms 748.932007ms 748.943774ms 748.988797ms 749.035535ms 749.059213ms 749.099629ms 749.116812ms 749.128755ms 749.133844ms 749.167732ms 749.184519ms 749.23996ms 749.282213ms 749.323227ms 749.333144ms 749.334678ms 749.358691ms 749.472882ms 749.554873ms 749.579831ms 749.624682ms 749.625888ms 749.627483ms 749.649459ms 749.732452ms 749.744572ms 749.809381ms 749.852586ms 749.866902ms 749.875716ms 749.913534ms 749.932597ms 749.94335ms 749.955457ms 749.994815ms 750.009554ms 750.024208ms 750.101216ms 750.134254ms 750.190754ms 750.202257ms 750.408251ms 750.415515ms 750.436479ms 750.44924ms 750.533344ms 750.621632ms 750.741609ms 750.754885ms 750.76234ms 750.803223ms 750.806574ms 750.819536ms 750.826067ms 750.826192ms 750.850459ms 750.867562ms 750.907869ms 750.99043ms 751.011154ms 751.023086ms 751.029788ms 751.065134ms 751.065571ms 751.072221ms 751.292873ms 751.372582ms 751.373031ms 751.73396ms 751.929999ms 752.002507ms 752.208361ms 752.343494ms 752.533036ms 752.575413ms 752.989732ms 753.027744ms 753.253213ms 753.361328ms 753.486792ms 753.660845ms 753.972656ms 754.086091ms 754.164681ms 754.267171ms 754.303648ms 754.948496ms 755.008266ms 755.075033ms 755.741986ms 755.807062ms 755.819052ms 755.943739ms 755.949783ms 756.115047ms 756.215071ms 756.33085ms 756.658411ms 756.760754ms 756.911461ms 757.31977ms 758.036558ms 758.147854ms 759.216549ms 760.401898ms 760.404111ms 760.796401ms]
May 21 07:45:29.072: INFO: 50 %ile: 749.128755ms
May 21 07:45:29.072: INFO: 90 %ile: 755.008266ms
May 21 07:45:29.072: INFO: 99 %ile: 760.404111ms
May 21 07:45:29.072: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:45:29.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-tpv8h" for this suite.
May 21 07:45:43.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:45:43.150: INFO: namespace: e2e-tests-svc-latency-tpv8h, resource: bindings, ignored listing per whitelist
May 21 07:45:43.166: INFO: namespace e2e-tests-svc-latency-tpv8h deletion completed in 14.088582149s

• [SLOW TEST:24.850 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:45:43.166: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-8b4ls
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
May 21 07:45:43.218: INFO: Found 0 stateful pods, waiting for 3
May 21 07:45:53.226: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 07:45:53.226: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 07:45:53.226: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 21 07:45:53.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-8b4ls ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:45:53.462: INFO: stderr: ""
May 21 07:45:53.462: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:45:53.462: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 21 07:46:03.497: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 21 07:46:13.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-8b4ls ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:46:13.761: INFO: stderr: ""
May 21 07:46:13.761: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:46:13.761: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:46:23.778: INFO: Waiting for StatefulSet e2e-tests-statefulset-8b4ls/ss2 to complete update
May 21 07:46:23.778: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 07:46:23.778: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 07:46:23.778: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 07:46:33.788: INFO: Waiting for StatefulSet e2e-tests-statefulset-8b4ls/ss2 to complete update
May 21 07:46:33.788: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 07:46:33.788: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 07:46:43.783: INFO: Waiting for StatefulSet e2e-tests-statefulset-8b4ls/ss2 to complete update
May 21 07:46:43.783: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 07:46:43.783: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 07:46:53.787: INFO: Waiting for StatefulSet e2e-tests-statefulset-8b4ls/ss2 to complete update
May 21 07:46:53.787: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 07:46:53.787: INFO: Waiting for Pod e2e-tests-statefulset-8b4ls/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
May 21 07:47:03.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-8b4ls ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 21 07:47:03.993: INFO: stderr: ""
May 21 07:47:03.993: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 21 07:47:03.993: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 21 07:47:14.023: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 21 07:47:24.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 exec --namespace=e2e-tests-statefulset-8b4ls ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 21 07:47:24.258: INFO: stderr: ""
May 21 07:47:24.258: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 21 07:47:24.258: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 21 07:47:44.295: INFO: Waiting for StatefulSet e2e-tests-statefulset-8b4ls/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 07:47:54.303: INFO: Deleting all statefulset in ns e2e-tests-statefulset-8b4ls
May 21 07:47:54.306: INFO: Scaling statefulset ss2 to 0
May 21 07:48:04.320: INFO: Waiting for statefulset status.replicas updated to 0
May 21 07:48:04.321: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:48:04.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-8b4ls" for this suite.
May 21 07:48:10.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:48:10.355: INFO: namespace: e2e-tests-statefulset-8b4ls, resource: bindings, ignored listing per whitelist
May 21 07:48:10.391: INFO: namespace e2e-tests-statefulset-8b4ls deletion completed in 6.059711405s

• [SLOW TEST:147.225 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:48:10.391: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:48:12.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-n8b4n" for this suite.
May 21 07:48:56.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:48:56.504: INFO: namespace: e2e-tests-kubelet-test-n8b4n, resource: bindings, ignored listing per whitelist
May 21 07:48:56.521: INFO: namespace e2e-tests-kubelet-test-n8b4n deletion completed in 44.060947188s

• [SLOW TEST:46.130 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:48:56.522: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 07:48:56.567: INFO: Waiting up to 5m0s for pod "pod-e308b567-7b9c-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-dqwtf" to be "success or failure"
May 21 07:48:56.569: INFO: Pod "pod-e308b567-7b9c-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612035ms
May 21 07:48:58.572: INFO: Pod "pod-e308b567-7b9c-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005453389s
STEP: Saw pod success
May 21 07:48:58.572: INFO: Pod "pod-e308b567-7b9c-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:48:58.574: INFO: Trying to get logs from node 192.168.5.21 pod pod-e308b567-7b9c-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:48:58.591: INFO: Waiting for pod pod-e308b567-7b9c-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:48:58.593: INFO: Pod pod-e308b567-7b9c-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:48:58.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dqwtf" for this suite.
May 21 07:49:04.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:49:04.640: INFO: namespace: e2e-tests-emptydir-dqwtf, resource: bindings, ignored listing per whitelist
May 21 07:49:04.687: INFO: namespace e2e-tests-emptydir-dqwtf deletion completed in 6.081675357s

• [SLOW TEST:8.165 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:49:04.687: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:49:06.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-phtrd" for this suite.
May 21 07:49:56.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:49:56.786: INFO: namespace: e2e-tests-kubelet-test-phtrd, resource: bindings, ignored listing per whitelist
May 21 07:49:56.825: INFO: namespace e2e-tests-kubelet-test-phtrd deletion completed in 50.078711249s

• [SLOW TEST:52.139 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:49:56.826: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kvzh6 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kvzh6 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kvzh6.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kvzh6.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kvzh6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-kvzh6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kvzh6.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-kvzh6.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kvzh6.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 91.14.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.14.91_udp@PTR;check="$$(dig +tcp +noall +answer +search 91.14.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.14.91_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kvzh6 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-kvzh6;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kvzh6 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kvzh6.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kvzh6.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kvzh6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-kvzh6.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kvzh6.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-kvzh6.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kvzh6.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 91.14.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.14.91_udp@PTR;check="$$(dig +tcp +noall +answer +search 91.14.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.14.91_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 07:49:58.900: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.902: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.904: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.906: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.908: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.910: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.926: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.928: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.930: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.931: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.933: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.935: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.936: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.938: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:49:58.949: INFO: Lookups using e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc]

May 21 07:50:03.952: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.954: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.956: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.958: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.960: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.962: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.984: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.992: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.996: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:03.998: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:04.002: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:04.006: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:04.010: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:04.013: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:04.038: INFO: Lookups using e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc]

May 21 07:50:08.955: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.957: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.959: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.961: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.963: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.965: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.981: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.982: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.984: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.986: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.988: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.989: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.991: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:08.993: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:09.007: INFO: Lookups using e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc]

May 21 07:50:13.952: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.954: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.956: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.959: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.960: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.962: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.988: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.990: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.992: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.997: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:13.999: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:14.002: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:14.004: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:14.007: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:14.033: INFO: Lookups using e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc]

May 21 07:50:18.955: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.957: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.959: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.960: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.962: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.964: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.980: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.981: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.983: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.985: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.987: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.988: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.990: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:18.992: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:19.007: INFO: Lookups using e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc]

May 21 07:50:23.952: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.955: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.961: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.963: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.964: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.966: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.982: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.983: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.985: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.987: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.989: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.990: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.992: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:23.994: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:24.004: INFO: Lookups using e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc wheezy_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-kvzh6 jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6 jessie_udp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc]

May 21 07:50:28.962: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:28.968: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:28.998: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:29.013: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc from pod e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7: the server could not find the requested resource (get pods dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7)
May 21 07:50:29.026: INFO: Lookups using e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7 failed for: [wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6 wheezy_udp@dns-test-service.e2e-tests-dns-kvzh6.svc jessie_tcp@dns-test-service jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kvzh6.svc]

May 21 07:50:34.034: INFO: DNS probes using e2e-tests-dns-kvzh6/dns-test-06fb7a2e-7b9d-11e9-8b08-72649ad3cdd7 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:50:34.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-kvzh6" for this suite.
May 21 07:50:40.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:50:40.152: INFO: namespace: e2e-tests-dns-kvzh6, resource: bindings, ignored listing per whitelist
May 21 07:50:40.152: INFO: namespace e2e-tests-dns-kvzh6 deletion completed in 6.069947434s

• [SLOW TEST:43.326 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:50:40.152: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:50:40.198: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20cd9a08-7b9d-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-mfdjn" to be "success or failure"
May 21 07:50:40.200: INFO: Pod "downwardapi-volume-20cd9a08-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.898662ms
May 21 07:50:42.204: INFO: Pod "downwardapi-volume-20cd9a08-7b9d-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005660759s
STEP: Saw pod success
May 21 07:50:42.204: INFO: Pod "downwardapi-volume-20cd9a08-7b9d-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:50:42.206: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-20cd9a08-7b9d-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:50:42.219: INFO: Waiting for pod downwardapi-volume-20cd9a08-7b9d-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:50:42.221: INFO: Pod downwardapi-volume-20cd9a08-7b9d-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:50:42.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mfdjn" for this suite.
May 21 07:50:48.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:50:48.275: INFO: namespace: e2e-tests-projected-mfdjn, resource: bindings, ignored listing per whitelist
May 21 07:50:48.292: INFO: namespace e2e-tests-projected-mfdjn deletion completed in 6.065820459s

• [SLOW TEST:8.140 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:50:48.292: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:50:48.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25a791ed-7b9d-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-ncwd7" to be "success or failure"
May 21 07:50:48.341: INFO: Pod "downwardapi-volume-25a791ed-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.440055ms
May 21 07:50:50.347: INFO: Pod "downwardapi-volume-25a791ed-7b9d-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008529448s
STEP: Saw pod success
May 21 07:50:50.347: INFO: Pod "downwardapi-volume-25a791ed-7b9d-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:50:50.349: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-25a791ed-7b9d-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:50:50.363: INFO: Waiting for pod downwardapi-volume-25a791ed-7b9d-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:50:50.366: INFO: Pod downwardapi-volume-25a791ed-7b9d-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:50:50.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ncwd7" for this suite.
May 21 07:50:56.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:50:56.393: INFO: namespace: e2e-tests-downward-api-ncwd7, resource: bindings, ignored listing per whitelist
May 21 07:50:56.441: INFO: namespace e2e-tests-downward-api-ncwd7 deletion completed in 6.068327908s

• [SLOW TEST:8.149 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:50:56.442: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2a82b1b6-7b9d-11e9-8b08-72649ad3cdd7
STEP: Creating secret with name s-test-opt-upd-2a82b229-7b9d-11e9-8b08-72649ad3cdd7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2a82b1b6-7b9d-11e9-8b08-72649ad3cdd7
STEP: Updating secret s-test-opt-upd-2a82b229-7b9d-11e9-8b08-72649ad3cdd7
STEP: Creating secret with name s-test-opt-create-2a82b240-7b9d-11e9-8b08-72649ad3cdd7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:52:26.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9q9xg" for this suite.
May 21 07:52:48.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:52:48.945: INFO: namespace: e2e-tests-secrets-9q9xg, resource: bindings, ignored listing per whitelist
May 21 07:52:48.952: INFO: namespace e2e-tests-secrets-9q9xg deletion completed in 22.067496342s

• [SLOW TEST:112.510 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:52:48.952: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 07:52:49.002: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d92d303-7b9d-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-8c595" to be "success or failure"
May 21 07:52:49.005: INFO: Pod "downwardapi-volume-6d92d303-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.122455ms
May 21 07:52:51.008: INFO: Pod "downwardapi-volume-6d92d303-7b9d-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005886893s
STEP: Saw pod success
May 21 07:52:51.008: INFO: Pod "downwardapi-volume-6d92d303-7b9d-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:52:51.009: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-6d92d303-7b9d-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 07:52:51.023: INFO: Waiting for pod downwardapi-volume-6d92d303-7b9d-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:52:51.025: INFO: Pod downwardapi-volume-6d92d303-7b9d-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:52:51.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8c595" for this suite.
May 21 07:52:57.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:52:57.059: INFO: namespace: e2e-tests-projected-8c595, resource: bindings, ignored listing per whitelist
May 21 07:52:57.088: INFO: namespace e2e-tests-projected-8c595 deletion completed in 6.061303959s

• [SLOW TEST:8.136 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:52:57.088: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 21 07:52:57.126: INFO: PodSpec: initContainers in spec.initContainers
May 21 07:53:40.243: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-726bd14f-7b9d-11e9-8b08-72649ad3cdd7", GenerateName:"", Namespace:"e2e-tests-init-container-gmx4f", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-gmx4f/pods/pod-init-726bd14f-7b9d-11e9-8b08-72649ad3cdd7", UID:"726c3030-7b9d-11e9-926e-fa163e6dedea", ResourceVersion:"25024", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63694021977, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"126130250"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-rszll", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001568fc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rszll", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rszll", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rszll", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001290998), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.5.21", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00266d140), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001290b00)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021977, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021977, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021977, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63694021977, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.5.21", PodIP:"10.8.3.171", StartTime:(*v1.Time)(0xc00228ae60), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002365650)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0023656c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://92fb7e369ed367b37cd222da41d12cc6bce0734d3cc18989ee0d548c9e999358"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00228aea0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00228ae80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:53:40.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-gmx4f" for this suite.
May 21 07:54:02.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:54:02.306: INFO: namespace: e2e-tests-init-container-gmx4f, resource: bindings, ignored listing per whitelist
May 21 07:54:02.329: INFO: namespace e2e-tests-init-container-gmx4f deletion completed in 22.072008841s

• [SLOW TEST:65.240 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:54:02.329: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 07:54:04.886: INFO: Successfully updated pod "pod-update-994ede94-7b9d-11e9-8b08-72649ad3cdd7"
STEP: verifying the updated pod is in kubernetes
May 21 07:54:04.889: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:54:04.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hdnpx" for this suite.
May 21 07:54:26.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:54:26.952: INFO: namespace: e2e-tests-pods-hdnpx, resource: bindings, ignored listing per whitelist
May 21 07:54:26.953: INFO: namespace e2e-tests-pods-hdnpx deletion completed in 22.061833815s

• [SLOW TEST:24.625 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:54:26.954: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 07:54:26.996: INFO: Waiting up to 5m0s for pod "downward-api-a7fc1754-7b9d-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-h8dbd" to be "success or failure"
May 21 07:54:26.999: INFO: Pod "downward-api-a7fc1754-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.71607ms
May 21 07:54:29.001: INFO: Pod "downward-api-a7fc1754-7b9d-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005140247s
STEP: Saw pod success
May 21 07:54:29.001: INFO: Pod "downward-api-a7fc1754-7b9d-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:54:29.003: INFO: Trying to get logs from node 192.168.5.21 pod downward-api-a7fc1754-7b9d-11e9-8b08-72649ad3cdd7 container dapi-container: <nil>
STEP: delete the pod
May 21 07:54:29.017: INFO: Waiting for pod downward-api-a7fc1754-7b9d-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:54:29.019: INFO: Pod downward-api-a7fc1754-7b9d-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:54:29.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-h8dbd" for this suite.
May 21 07:54:35.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:54:35.077: INFO: namespace: e2e-tests-downward-api-h8dbd, resource: bindings, ignored listing per whitelist
May 21 07:54:35.086: INFO: namespace e2e-tests-downward-api-h8dbd deletion completed in 6.065103696s

• [SLOW TEST:8.133 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:54:35.087: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:54:35.128: INFO: Creating deployment "nginx-deployment"
May 21 07:54:35.132: INFO: Waiting for observed generation 1
May 21 07:54:37.138: INFO: Waiting for all required pods to come up
May 21 07:54:37.140: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 21 07:54:43.147: INFO: Waiting for deployment "nginx-deployment" to complete
May 21 07:54:43.151: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 21 07:54:43.159: INFO: Updating deployment nginx-deployment
May 21 07:54:43.159: INFO: Waiting for observed generation 2
May 21 07:54:45.165: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 21 07:54:45.167: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 21 07:54:45.168: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 21 07:54:45.173: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 21 07:54:45.173: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 21 07:54:45.174: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 21 07:54:45.177: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 21 07:54:45.177: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 21 07:54:45.181: INFO: Updating deployment nginx-deployment
May 21 07:54:45.181: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 21 07:54:45.184: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 21 07:54:45.186: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 07:54:47.195: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8kp4q/deployments/nginx-deployment,UID:acd5e27f-7b9d-11e9-926e-fa163e6dedea,ResourceVersion:25433,Generation:3,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-05-21 07:54:45 +0000 UTC 2019-05-21 07:54:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-21 07:54:45 +0000 UTC 2019-05-21 07:54:35 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

May 21 07:54:47.208: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8kp4q/replicasets/nginx-deployment-65bbdb5f8,UID:b19f8a52-7b9d-11e9-8844-fa163e715483,ResourceVersion:25431,Generation:3,CreationTimestamp:2019-05-21 07:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment acd5e27f-7b9d-11e9-926e-fa163e6dedea 0xc001b39507 0xc001b39508}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 07:54:47.208: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 21 07:54:47.208: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8kp4q/replicasets/nginx-deployment-555b55d965,UID:acd6d6d6-7b9d-11e9-8844-fa163e715483,ResourceVersion:25425,Generation:3,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment acd5e27f-7b9d-11e9-926e-fa163e6dedea 0xc001b39437 0xc001b39438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 21 07:54:47.215: INFO: Pod "nginx-deployment-555b55d965-27mrw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-27mrw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-27mrw,UID:b2d60003-7b9d-11e9-8844-fa163e715483,ResourceVersion:25393,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc001544d57 0xc001544d58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.215: INFO: Pod "nginx-deployment-555b55d965-28z4m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-28z4m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-28z4m,UID:b2da9e4f-7b9d-11e9-8844-fa163e715483,ResourceVersion:25419,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc001545027 0xc001545028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.215: INFO: Pod "nginx-deployment-555b55d965-6rprk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6rprk,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-6rprk,UID:acda9672-7b9d-11e9-8844-fa163e715483,ResourceVersion:25290,Generation:0,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc0015450f0 0xc0015450f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.179,StartTime:2019-05-21 07:54:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 07:54:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://63d1b39c191770d301513b61bc91c90ab59c60dbd451034c8200f5d15d2855a6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.215: INFO: Pod "nginx-deployment-555b55d965-78lss" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-78lss,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-78lss,UID:acdc4ebf-7b9d-11e9-8844-fa163e715483,ResourceVersion:25296,Generation:0,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc0015453c0 0xc0015453c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.180,StartTime:2019-05-21 07:54:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 07:54:39 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a3103e90b62dcee882929528ee67cf9753aa3849d87dc95517d375dea653b9b8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.215: INFO: Pod "nginx-deployment-555b55d965-8qzdb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8qzdb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-8qzdb,UID:acd9831a-7b9d-11e9-8844-fa163e715483,ResourceVersion:25265,Generation:0,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc0015454d0 0xc0015454d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.174,StartTime:2019-05-21 07:54:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 07:54:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a384cb7a42c47385d657ebf3f2d73312be1371ef2de63fae9fd08ef04f2a2696}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.216: INFO: Pod "nginx-deployment-555b55d965-9jsx9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9jsx9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-9jsx9,UID:b2d7bb51-7b9d-11e9-8844-fa163e715483,ResourceVersion:25404,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc0015457f0 0xc0015457f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.216: INFO: Pod "nginx-deployment-555b55d965-d49zz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d49zz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-d49zz,UID:b2da9ab7-7b9d-11e9-8844-fa163e715483,ResourceVersion:25418,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc0015459f0 0xc0015459f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.216: INFO: Pod "nginx-deployment-555b55d965-gcbfz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gcbfz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-gcbfz,UID:acd9464d-7b9d-11e9-8844-fa163e715483,ResourceVersion:25270,Generation:0,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc001545b20 0xc001545b21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.182,StartTime:2019-05-21 07:54:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 07:54:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1c1add4e503444c6566dd3983f125492cd38f69496232f85a96ad32c0409dfc4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.216: INFO: Pod "nginx-deployment-555b55d965-j7x24" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j7x24,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-j7x24,UID:acdc58e8-7b9d-11e9-8844-fa163e715483,ResourceVersion:25259,Generation:0,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc001545cf0 0xc001545cf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.175,StartTime:2019-05-21 07:54:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 07:54:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f5e9a1016f06309ace8cc1f732760b2a0165bcef5b4991677eeca5b5c577c923}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.216: INFO: Pod "nginx-deployment-555b55d965-jffrr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jffrr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-jffrr,UID:b2d7abe9-7b9d-11e9-8844-fa163e715483,ResourceVersion:25402,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc001545ed0 0xc001545ed1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.216: INFO: Pod "nginx-deployment-555b55d965-k89vf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k89vf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-k89vf,UID:b2d4dd82-7b9d-11e9-8844-fa163e715483,ResourceVersion:25381,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc001545f90 0xc001545f91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.217: INFO: Pod "nginx-deployment-555b55d965-l7v8j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l7v8j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-l7v8j,UID:acdc3602-7b9d-11e9-8844-fa163e715483,ResourceVersion:25262,Generation:0,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002566287 0xc002566288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.178,StartTime:2019-05-21 07:54:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 07:54:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6064e3ce200e5feb19a0f4b8c2040d36cc5157cc24038933d30efc68eb6a69fe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.217: INFO: Pod "nginx-deployment-555b55d965-mdbns" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mdbns,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-mdbns,UID:acd869fa-7b9d-11e9-8844-fa163e715483,ResourceVersion:25282,Generation:0,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002566650 0xc002566651}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.181,StartTime:2019-05-21 07:54:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 07:54:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6a5d5e7532192ec81617f5f7a870f849b475af42931941ccb1bbbe810f446dcb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.217: INFO: Pod "nginx-deployment-555b55d965-mw95p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mw95p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-mw95p,UID:b2d5df7e-7b9d-11e9-8844-fa163e715483,ResourceVersion:25460,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002566900 0xc002566901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.217: INFO: Pod "nginx-deployment-555b55d965-nvz8p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nvz8p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-nvz8p,UID:acdadd38-7b9d-11e9-8844-fa163e715483,ResourceVersion:25275,Generation:0,CreationTimestamp:2019-05-21 07:54:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002566b27 0xc002566b28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:35 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.176,StartTime:2019-05-21 07:54:35 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-21 07:54:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://390239d165aedcf176f89167f79cd33f15a480783a4329e9722699b086bd35e8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.217: INFO: Pod "nginx-deployment-555b55d965-r4tm4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-r4tm4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-r4tm4,UID:b2d7ca60-7b9d-11e9-8844-fa163e715483,ResourceVersion:25471,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002566c70 0xc002566c71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.217: INFO: Pod "nginx-deployment-555b55d965-swsbl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-swsbl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-swsbl,UID:b2da0f51-7b9d-11e9-8844-fa163e715483,ResourceVersion:25414,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002566e87 0xc002566e88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.217: INFO: Pod "nginx-deployment-555b55d965-tn9vz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tn9vz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-tn9vz,UID:b2da221d-7b9d-11e9-8844-fa163e715483,ResourceVersion:25415,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002567030 0xc002567031}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-555b55d965-tnnpn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tnnpn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-tnnpn,UID:b2da96e1-7b9d-11e9-8844-fa163e715483,ResourceVersion:25424,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002567160 0xc002567161}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-555b55d965-zcx2m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zcx2m,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-555b55d965-zcx2m,UID:b2d7a172-7b9d-11e9-8844-fa163e715483,ResourceVersion:25400,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 acd6d6d6-7b9d-11e9-8844-fa163e715483 0xc002567220 0xc002567221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-65bbdb5f8-c7tcz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-c7tcz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-c7tcz,UID:b2d612ce-7b9d-11e9-8844-fa163e715483,ResourceVersion:25450,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc0025673c0 0xc0025673c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-65bbdb5f8-cllts" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cllts,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-cllts,UID:b2dcb952-7b9d-11e9-8844-fa163e715483,ResourceVersion:25429,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc002567590 0xc002567591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-65bbdb5f8-fb7wd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fb7wd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-fb7wd,UID:b1a14ec6-7b9d-11e9-8844-fa163e715483,ResourceVersion:25340,Generation:0,CreationTimestamp:2019-05-21 07:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc002567660 0xc002567661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-65bbdb5f8-fxdhc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fxdhc,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-fxdhc,UID:b2d7b542-7b9d-11e9-8844-fa163e715483,ResourceVersion:25469,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc0025677f0 0xc0025677f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-65bbdb5f8-jtxtd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jtxtd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-jtxtd,UID:b1a01134-7b9d-11e9-8844-fa163e715483,ResourceVersion:25327,Generation:0,CreationTimestamp:2019-05-21 07:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc0025679c0 0xc0025679c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-65bbdb5f8-mhh75" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mhh75,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-mhh75,UID:b1ad80d0-7b9d-11e9-8844-fa163e715483,ResourceVersion:25357,Generation:0,CreationTimestamp:2019-05-21 07:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc002567c20 0xc002567c21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.218: INFO: Pod "nginx-deployment-65bbdb5f8-nls2s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nls2s,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-nls2s,UID:b1b0008c-7b9d-11e9-8844-fa163e715483,ResourceVersion:25363,Generation:0,CreationTimestamp:2019-05-21 07:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc002567d40 0xc002567d41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.219: INFO: Pod "nginx-deployment-65bbdb5f8-nth45" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nth45,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-nth45,UID:b2d9a9a9-7b9d-11e9-8844-fa163e715483,ResourceVersion:25417,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc002567f50 0xc002567f51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.219: INFO: Pod "nginx-deployment-65bbdb5f8-r7nk4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-r7nk4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-r7nk4,UID:b1a16904-7b9d-11e9-8844-fa163e715483,ResourceVersion:25336,Generation:0,CreationTimestamp:2019-05-21 07:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc0025b4090 0xc0025b4091}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.219: INFO: Pod "nginx-deployment-65bbdb5f8-s4k7b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-s4k7b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-s4k7b,UID:b2da30b7-7b9d-11e9-8844-fa163e715483,ResourceVersion:25423,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc0025b4220 0xc0025b4221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.219: INFO: Pod "nginx-deployment-65bbdb5f8-x6xbs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x6xbs,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-x6xbs,UID:b2da298f-7b9d-11e9-8844-fa163e715483,ResourceVersion:25416,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc0025b42f0 0xc0025b42f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.219: INFO: Pod "nginx-deployment-65bbdb5f8-x7n9s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x7n9s,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-x7n9s,UID:b2d75ad9-7b9d-11e9-8844-fa163e715483,ResourceVersion:25401,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc0025b4400 0xc0025b4401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 21 07:54:47.219: INFO: Pod "nginx-deployment-65bbdb5f8-zfhhv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zfhhv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-8kp4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8kp4q/pods/nginx-deployment-65bbdb5f8-zfhhv,UID:b2da920d-7b9d-11e9-8844-fa163e715483,ResourceVersion:25468,Generation:0,CreationTimestamp:2019-05-21 07:54:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 b19f8a52-7b9d-11e9-8844-fa163e715483 0xc0025b4500 0xc0025b4501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-m52hh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-m52hh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-m52hh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:54:45 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:54:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:54:47.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8kp4q" for this suite.
May 21 07:54:53.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:54:53.302: INFO: namespace: e2e-tests-deployment-8kp4q, resource: bindings, ignored listing per whitelist
May 21 07:54:53.322: INFO: namespace e2e-tests-deployment-8kp4q deletion completed in 6.096666234s

• [SLOW TEST:18.236 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:54:53.322: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-b7b758ef-7b9d-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 07:54:53.392: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-qgnc2" to be "success or failure"
May 21 07:54:53.396: INFO: Pod "pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.328997ms
May 21 07:54:55.401: INFO: Pod "pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008644997s
May 21 07:54:57.404: INFO: Pod "pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011686625s
May 21 07:54:59.406: INFO: Pod "pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014094624s
May 21 07:55:01.410: INFO: Pod "pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018137085s
May 21 07:55:03.413: INFO: Pod "pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.021094839s
STEP: Saw pod success
May 21 07:55:03.413: INFO: Pod "pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:55:03.415: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7 container secret-volume-test: <nil>
STEP: delete the pod
May 21 07:55:03.432: INFO: Waiting for pod pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:55:03.434: INFO: Pod pod-projected-secrets-b7b81a8c-7b9d-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:55:03.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qgnc2" for this suite.
May 21 07:55:09.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:09.509: INFO: namespace: e2e-tests-projected-qgnc2, resource: bindings, ignored listing per whitelist
May 21 07:55:09.513: INFO: namespace e2e-tests-projected-qgnc2 deletion completed in 6.075297875s

• [SLOW TEST:16.191 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:55:09.514: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0521 07:55:15.582727      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 07:55:15.582: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:55:15.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-v9pqs" for this suite.
May 21 07:55:21.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:21.626: INFO: namespace: e2e-tests-gc-v9pqs, resource: bindings, ignored listing per whitelist
May 21 07:55:21.656: INFO: namespace e2e-tests-gc-v9pqs deletion completed in 6.071609042s

• [SLOW TEST:12.142 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:55:21.656: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 21 07:55:21.697: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:55:24.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2mbpq" for this suite.
May 21 07:55:30.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:30.820: INFO: namespace: e2e-tests-init-container-2mbpq, resource: bindings, ignored listing per whitelist
May 21 07:55:30.845: INFO: namespace e2e-tests-init-container-2mbpq deletion completed in 6.057611872s

• [SLOW TEST:9.189 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:55:30.845: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0521 07:55:40.939001      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 07:55:40.939: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:55:40.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9744d" for this suite.
May 21 07:55:46.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:46.981: INFO: namespace: e2e-tests-gc-9744d, resource: bindings, ignored listing per whitelist
May 21 07:55:47.003: INFO: namespace e2e-tests-gc-9744d deletion completed in 6.061826741s

• [SLOW TEST:16.158 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:55:47.003: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 21 07:55:47.049: INFO: Pod name pod-release: Found 0 pods out of 1
May 21 07:55:52.054: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:55:53.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-6c25t" for this suite.
May 21 07:55:59.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:55:59.125: INFO: namespace: e2e-tests-replication-controller-6c25t, resource: bindings, ignored listing per whitelist
May 21 07:55:59.129: INFO: namespace e2e-tests-replication-controller-6c25t deletion completed in 6.06272286s

• [SLOW TEST:12.125 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:55:59.129: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
May 21 07:55:59.179: INFO: Waiting up to 5m0s for pod "pod-deee2aee-7b9d-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-77h6h" to be "success or failure"
May 21 07:55:59.182: INFO: Pod "pod-deee2aee-7b9d-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.065022ms
May 21 07:56:01.184: INFO: Pod "pod-deee2aee-7b9d-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005646995s
STEP: Saw pod success
May 21 07:56:01.184: INFO: Pod "pod-deee2aee-7b9d-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:56:01.186: INFO: Trying to get logs from node 192.168.5.21 pod pod-deee2aee-7b9d-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 07:56:01.201: INFO: Waiting for pod pod-deee2aee-7b9d-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:56:01.204: INFO: Pod pod-deee2aee-7b9d-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:56:01.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-77h6h" for this suite.
May 21 07:56:07.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:56:07.267: INFO: namespace: e2e-tests-emptydir-77h6h, resource: bindings, ignored listing per whitelist
May 21 07:56:07.272: INFO: namespace e2e-tests-emptydir-77h6h deletion completed in 6.063983492s

• [SLOW TEST:8.143 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:56:07.272: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 21 07:56:07.505: INFO: Pod name wrapped-volume-race-e3d6f79e-7b9d-11e9-8b08-72649ad3cdd7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e3d6f79e-7b9d-11e9-8b08-72649ad3cdd7 in namespace e2e-tests-emptydir-wrapper-9thr7, will wait for the garbage collector to delete the pods
May 21 07:56:23.615: INFO: Deleting ReplicationController wrapped-volume-race-e3d6f79e-7b9d-11e9-8b08-72649ad3cdd7 took: 5.012788ms
May 21 07:56:23.715: INFO: Terminating ReplicationController wrapped-volume-race-e3d6f79e-7b9d-11e9-8b08-72649ad3cdd7 pods took: 100.164009ms
STEP: Creating RC which spawns configmap-volume pods
May 21 07:57:04.532: INFO: Pod name wrapped-volume-race-05e0778d-7b9e-11e9-8b08-72649ad3cdd7: Found 0 pods out of 5
May 21 07:57:09.538: INFO: Pod name wrapped-volume-race-05e0778d-7b9e-11e9-8b08-72649ad3cdd7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-05e0778d-7b9e-11e9-8b08-72649ad3cdd7 in namespace e2e-tests-emptydir-wrapper-9thr7, will wait for the garbage collector to delete the pods
May 21 07:57:21.613: INFO: Deleting ReplicationController wrapped-volume-race-05e0778d-7b9e-11e9-8b08-72649ad3cdd7 took: 5.95927ms
May 21 07:57:21.714: INFO: Terminating ReplicationController wrapped-volume-race-05e0778d-7b9e-11e9-8b08-72649ad3cdd7 pods took: 100.854817ms
STEP: Creating RC which spawns configmap-volume pods
May 21 07:58:04.532: INFO: Pod name wrapped-volume-race-29a3a34f-7b9e-11e9-8b08-72649ad3cdd7: Found 0 pods out of 5
May 21 07:58:09.544: INFO: Pod name wrapped-volume-race-29a3a34f-7b9e-11e9-8b08-72649ad3cdd7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-29a3a34f-7b9e-11e9-8b08-72649ad3cdd7 in namespace e2e-tests-emptydir-wrapper-9thr7, will wait for the garbage collector to delete the pods
May 21 07:58:21.618: INFO: Deleting ReplicationController wrapped-volume-race-29a3a34f-7b9e-11e9-8b08-72649ad3cdd7 took: 5.541825ms
May 21 07:58:21.719: INFO: Terminating ReplicationController wrapped-volume-race-29a3a34f-7b9e-11e9-8b08-72649ad3cdd7 pods took: 100.165124ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:59:05.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-9thr7" for this suite.
May 21 07:59:11.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:59:11.403: INFO: namespace: e2e-tests-emptydir-wrapper-9thr7, resource: bindings, ignored listing per whitelist
May 21 07:59:11.434: INFO: namespace e2e-tests-emptydir-wrapper-9thr7 deletion completed in 6.064865674s

• [SLOW TEST:184.162 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:59:11.434: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
May 21 07:59:11.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-ts5qg'
May 21 07:59:11.704: INFO: stderr: ""
May 21 07:59:11.704: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
May 21 07:59:12.706: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:59:12.706: INFO: Found 0 / 1
May 21 07:59:13.706: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:59:13.706: INFO: Found 1 / 1
May 21 07:59:13.706: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 07:59:13.708: INFO: Selector matched 1 pods for map[app:redis]
May 21 07:59:13.708: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 21 07:59:13.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 logs redis-master-rzsgw redis-master --namespace=e2e-tests-kubectl-ts5qg'
May 21 07:59:13.779: INFO: stderr: ""
May 21 07:59:13.779: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 07:59:12.424 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 07:59:12.424 # Server started, Redis version 3.2.12\n1:M 21 May 07:59:12.424 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 07:59:12.424 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 21 07:59:13.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 log redis-master-rzsgw redis-master --namespace=e2e-tests-kubectl-ts5qg --tail=1'
May 21 07:59:13.860: INFO: stderr: ""
May 21 07:59:13.860: INFO: stdout: "1:M 21 May 07:59:12.424 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 21 07:59:13.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 log redis-master-rzsgw redis-master --namespace=e2e-tests-kubectl-ts5qg --limit-bytes=1'
May 21 07:59:13.938: INFO: stderr: ""
May 21 07:59:13.938: INFO: stdout: " "
STEP: exposing timestamps
May 21 07:59:13.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 log redis-master-rzsgw redis-master --namespace=e2e-tests-kubectl-ts5qg --tail=1 --timestamps'
May 21 07:59:14.010: INFO: stderr: ""
May 21 07:59:14.010: INFO: stdout: "2019-05-21T07:59:12.424913223Z 1:M 21 May 07:59:12.424 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 21 07:59:16.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 log redis-master-rzsgw redis-master --namespace=e2e-tests-kubectl-ts5qg --since=1s'
May 21 07:59:16.581: INFO: stderr: ""
May 21 07:59:16.581: INFO: stdout: ""
May 21 07:59:16.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 log redis-master-rzsgw redis-master --namespace=e2e-tests-kubectl-ts5qg --since=24h'
May 21 07:59:16.652: INFO: stderr: ""
May 21 07:59:16.652: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 May 07:59:12.424 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 07:59:12.424 # Server started, Redis version 3.2.12\n1:M 21 May 07:59:12.424 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 07:59:12.424 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
May 21 07:59:16.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ts5qg'
May 21 07:59:16.720: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 07:59:16.720: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 21 07:59:16.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-ts5qg'
May 21 07:59:16.795: INFO: stderr: "No resources found.\n"
May 21 07:59:16.795: INFO: stdout: ""
May 21 07:59:16.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -l name=nginx --namespace=e2e-tests-kubectl-ts5qg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 07:59:16.863: INFO: stderr: ""
May 21 07:59:16.863: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:59:16.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ts5qg" for this suite.
May 21 07:59:22.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:59:22.905: INFO: namespace: e2e-tests-kubectl-ts5qg, resource: bindings, ignored listing per whitelist
May 21 07:59:22.945: INFO: namespace e2e-tests-kubectl-ts5qg deletion completed in 6.07865312s

• [SLOW TEST:11.512 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:59:22.946: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5868aa66-7b9e-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 07:59:22.988: INFO: Waiting up to 5m0s for pod "pod-configmaps-5869300f-7b9e-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-wtnmn" to be "success or failure"
May 21 07:59:22.991: INFO: Pod "pod-configmaps-5869300f-7b9e-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.550575ms
May 21 07:59:24.993: INFO: Pod "pod-configmaps-5869300f-7b9e-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004896726s
STEP: Saw pod success
May 21 07:59:24.993: INFO: Pod "pod-configmaps-5869300f-7b9e-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 07:59:24.995: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-5869300f-7b9e-11e9-8b08-72649ad3cdd7 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 07:59:25.006: INFO: Waiting for pod pod-configmaps-5869300f-7b9e-11e9-8b08-72649ad3cdd7 to disappear
May 21 07:59:25.007: INFO: Pod pod-configmaps-5869300f-7b9e-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:59:25.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wtnmn" for this suite.
May 21 07:59:31.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:59:31.044: INFO: namespace: e2e-tests-configmap-wtnmn, resource: bindings, ignored listing per whitelist
May 21 07:59:31.068: INFO: namespace e2e-tests-configmap-wtnmn deletion completed in 6.058267607s

• [SLOW TEST:8.122 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:59:31.068: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 07:59:31.106: INFO: Creating deployment "test-recreate-deployment"
May 21 07:59:31.109: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 21 07:59:31.113: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May 21 07:59:33.117: INFO: Waiting deployment "test-recreate-deployment" to complete
May 21 07:59:33.118: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 21 07:59:33.122: INFO: Updating deployment test-recreate-deployment
May 21 07:59:33.122: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 07:59:33.173: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-z6brr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z6brr/deployments/test-recreate-deployment,UID:5d402c23-7b9e-11e9-926e-fa163e6dedea,ResourceVersion:27586,Generation:2,CreationTimestamp:2019-05-21 07:59:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-21 07:59:33 +0000 UTC 2019-05-21 07:59:33 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-21 07:59:33 +0000 UTC 2019-05-21 07:59:31 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 21 07:59:33.176: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-z6brr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z6brr/replicasets/test-recreate-deployment-697fbf54bf,UID:5e77461c-7b9e-11e9-8844-fa163e715483,ResourceVersion:27585,Generation:1,CreationTimestamp:2019-05-21 07:59:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5d402c23-7b9e-11e9-926e-fa163e6dedea 0xc0020874d7 0xc0020874d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 07:59:33.176: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 21 07:59:33.176: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-z6brr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z6brr/replicasets/test-recreate-deployment-5dfdcc846d,UID:5d41185e-7b9e-11e9-8844-fa163e715483,ResourceVersion:27574,Generation:2,CreationTimestamp:2019-05-21 07:59:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5d402c23-7b9e-11e9-926e-fa163e6dedea 0xc0020872d7 0xc0020872d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 07:59:33.178: INFO: Pod "test-recreate-deployment-697fbf54bf-r6cpk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-r6cpk,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-z6brr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z6brr/pods/test-recreate-deployment-697fbf54bf-r6cpk,UID:5e77d30d-7b9e-11e9-8844-fa163e715483,ResourceVersion:27584,Generation:0,CreationTimestamp:2019-05-21 07:59:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 5e77461c-7b9e-11e9-8844-fa163e715483 0xc00081f177 0xc00081f178}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hxhv7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hxhv7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-hxhv7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:59:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:59:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:59:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 07:59:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:,StartTime:2019-05-21 07:59:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 07:59:33.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-z6brr" for this suite.
May 21 07:59:39.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 07:59:39.237: INFO: namespace: e2e-tests-deployment-z6brr, resource: bindings, ignored listing per whitelist
May 21 07:59:39.248: INFO: namespace e2e-tests-deployment-z6brr deletion completed in 6.067956249s

• [SLOW TEST:8.180 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 07:59:39.248: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-5z8ks
May 21 07:59:41.297: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-5z8ks
STEP: checking the pod's current state and verifying that restartCount is present
May 21 07:59:41.299: INFO: Initial restart count of pod liveness-http is 0
May 21 07:59:53.318: INFO: Restart count of pod e2e-tests-container-probe-5z8ks/liveness-http is now 1 (12.019326406s elapsed)
May 21 08:00:13.353: INFO: Restart count of pod e2e-tests-container-probe-5z8ks/liveness-http is now 2 (32.053967864s elapsed)
May 21 08:00:33.385: INFO: Restart count of pod e2e-tests-container-probe-5z8ks/liveness-http is now 3 (52.086686934s elapsed)
May 21 08:00:53.420: INFO: Restart count of pod e2e-tests-container-probe-5z8ks/liveness-http is now 4 (1m12.121669138s elapsed)
May 21 08:01:55.528: INFO: Restart count of pod e2e-tests-container-probe-5z8ks/liveness-http is now 5 (2m14.2291894s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:01:55.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5z8ks" for this suite.
May 21 08:02:01.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:01.589: INFO: namespace: e2e-tests-container-probe-5z8ks, resource: bindings, ignored listing per whitelist
May 21 08:02:01.601: INFO: namespace e2e-tests-container-probe-5z8ks deletion completed in 6.062801754s

• [SLOW TEST:142.353 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:02:01.601: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 21 08:02:01.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-pm6xf'
May 21 08:02:01.796: INFO: stderr: ""
May 21 08:02:01.796: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 08:02:02.799: INFO: Selector matched 1 pods for map[app:redis]
May 21 08:02:02.799: INFO: Found 0 / 1
May 21 08:02:03.799: INFO: Selector matched 1 pods for map[app:redis]
May 21 08:02:03.799: INFO: Found 1 / 1
May 21 08:02:03.799: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 21 08:02:03.800: INFO: Selector matched 1 pods for map[app:redis]
May 21 08:02:03.800: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 08:02:03.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 patch pod redis-master-26pk4 --namespace=e2e-tests-kubectl-pm6xf -p {"metadata":{"annotations":{"x":"y"}}}'
May 21 08:02:03.871: INFO: stderr: ""
May 21 08:02:03.871: INFO: stdout: "pod/redis-master-26pk4 patched\n"
STEP: checking annotations
May 21 08:02:03.873: INFO: Selector matched 1 pods for map[app:redis]
May 21 08:02:03.873: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:02:03.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pm6xf" for this suite.
May 21 08:02:25.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:25.934: INFO: namespace: e2e-tests-kubectl-pm6xf, resource: bindings, ignored listing per whitelist
May 21 08:02:25.942: INFO: namespace e2e-tests-kubectl-pm6xf deletion completed in 22.066157741s

• [SLOW TEST:24.341 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:02:25.943: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:02:30.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-9tgzt" for this suite.
May 21 08:02:36.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:36.067: INFO: namespace: e2e-tests-kubelet-test-9tgzt, resource: bindings, ignored listing per whitelist
May 21 08:02:36.073: INFO: namespace e2e-tests-kubelet-test-9tgzt deletion completed in 6.064444809s

• [SLOW TEST:10.130 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:02:36.073: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:02:36.124: INFO: (0) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 3.856725ms)
May 21 08:02:36.127: INFO: (1) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.41445ms)
May 21 08:02:36.129: INFO: (2) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.072547ms)
May 21 08:02:36.131: INFO: (3) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.177522ms)
May 21 08:02:36.134: INFO: (4) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.408093ms)
May 21 08:02:36.136: INFO: (5) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.074658ms)
May 21 08:02:36.139: INFO: (6) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.129331ms)
May 21 08:02:36.141: INFO: (7) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.28406ms)
May 21 08:02:36.143: INFO: (8) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.990169ms)
May 21 08:02:36.145: INFO: (9) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.431833ms)
May 21 08:02:36.148: INFO: (10) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.141076ms)
May 21 08:02:36.152: INFO: (11) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 4.437761ms)
May 21 08:02:36.154: INFO: (12) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.278682ms)
May 21 08:02:36.157: INFO: (13) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.20671ms)
May 21 08:02:36.159: INFO: (14) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.331034ms)
May 21 08:02:36.161: INFO: (15) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.100275ms)
May 21 08:02:36.163: INFO: (16) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.371635ms)
May 21 08:02:36.166: INFO: (17) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.111032ms)
May 21 08:02:36.168: INFO: (18) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.080408ms)
May 21 08:02:36.170: INFO: (19) /api/v1/nodes/192.168.5.21/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.116167ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:02:36.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9mzlz" for this suite.
May 21 08:02:42.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:42.224: INFO: namespace: e2e-tests-proxy-9mzlz, resource: bindings, ignored listing per whitelist
May 21 08:02:42.235: INFO: namespace e2e-tests-proxy-9mzlz deletion completed in 6.063437173s

• [SLOW TEST:6.162 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:02:42.236: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 08:02:42.281: INFO: Waiting up to 5m0s for pod "pod-cf32c85f-7b9e-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-p8jh2" to be "success or failure"
May 21 08:02:42.283: INFO: Pod "pod-cf32c85f-7b9e-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.709883ms
May 21 08:02:44.286: INFO: Pod "pod-cf32c85f-7b9e-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004516034s
STEP: Saw pod success
May 21 08:02:44.286: INFO: Pod "pod-cf32c85f-7b9e-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:02:44.287: INFO: Trying to get logs from node 192.168.5.21 pod pod-cf32c85f-7b9e-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 08:02:44.303: INFO: Waiting for pod pod-cf32c85f-7b9e-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:02:44.305: INFO: Pod pod-cf32c85f-7b9e-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:02:44.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p8jh2" for this suite.
May 21 08:02:50.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:50.365: INFO: namespace: e2e-tests-emptydir-p8jh2, resource: bindings, ignored listing per whitelist
May 21 08:02:50.375: INFO: namespace e2e-tests-emptydir-p8jh2 deletion completed in 6.067020959s

• [SLOW TEST:8.139 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:02:50.375: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 08:02:50.418: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 08:02:50.422: INFO: Waiting for terminating namespaces to be deleted...
May 21 08:02:50.423: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.21 before test
May 21 08:02:50.428: INFO: kube-flannel-4kgbz from kube-system started at 2019-05-21 04:30:34 +0000 UTC (2 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container install-cni ready: true, restart count 0
May 21 08:02:50.428: INFO: 	Container kube-flannel ready: true, restart count 1
May 21 08:02:50.428: INFO: kube-proxy-bqckm from kube-system started at 2019-05-21 04:30:34 +0000 UTC (1 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container kube-proxy ready: true, restart count 0
May 21 08:02:50.428: INFO: ksc-flexvolume-ds-tjvtw from kube-system started at 2019-05-21 04:30:34 +0000 UTC (1 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
May 21 08:02:50.428: INFO: sonobuoy-e2e-job-cbf016e40c124e85 from heptio-sonobuoy started at 2019-05-21 06:58:22 +0000 UTC (2 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container e2e ready: true, restart count 0
May 21 08:02:50.428: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 08:02:50.428: INFO: sonobuoy-systemd-logs-daemon-set-55252047aa2d4aa6-ghxm4 from heptio-sonobuoy started at 2019-05-21 06:58:22 +0000 UTC (2 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 08:02:50.428: INFO: 	Container systemd-logs ready: true, restart count 1
May 21 08:02:50.428: INFO: cloud-controller-manager-86df4567b9-59nqv from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container cloud-controller-manager ready: true, restart count 0
May 21 08:02:50.428: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-21 06:58:08 +0000 UTC (1 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 08:02:50.428: INFO: metrics-server-5b9ff87b5f-rpq6w from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container metrics-server ready: true, restart count 0
May 21 08:02:50.428: INFO: disk-provisioner-5895cdc8b7-q64vs from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container disk-provisioner ready: true, restart count 0
May 21 08:02:50.428: INFO: traefik-ingress-controller-tbxgz from kube-system started at 2019-05-21 04:31:34 +0000 UTC (1 container statuses recorded)
May 21 08:02:50.428: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a0a3fb386f5fbb], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:02:51.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-q4t5x" for this suite.
May 21 08:02:57.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:02:57.484: INFO: namespace: e2e-tests-sched-pred-q4t5x, resource: bindings, ignored listing per whitelist
May 21 08:02:57.524: INFO: namespace e2e-tests-sched-pred-q4t5x deletion completed in 6.070367233s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.149 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:02:57.524: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 08:02:57.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-nmgjq'
May 21 08:02:57.647: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 08:02:57.647: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
May 21 08:02:57.656: INFO: scanned /root for discovery docs: <nil>
May 21 08:02:57.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-nmgjq'
May 21 08:03:13.409: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 21 08:03:13.409: INFO: stdout: "Created e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c\nScaling up e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 21 08:03:13.409: INFO: stdout: "Created e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c\nScaling up e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 21 08:03:13.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nmgjq'
May 21 08:03:13.481: INFO: stderr: ""
May 21 08:03:13.481: INFO: stdout: "e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c-7s5mv "
May 21 08:03:13.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c-7s5mv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nmgjq'
May 21 08:03:13.550: INFO: stderr: ""
May 21 08:03:13.550: INFO: stdout: "true"
May 21 08:03:13.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c-7s5mv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nmgjq'
May 21 08:03:13.620: INFO: stderr: ""
May 21 08:03:13.620: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 21 08:03:13.620: INFO: e2e-test-nginx-rc-8107c37ac47dd2fb52c3e0d4f3ed518c-7s5mv is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
May 21 08:03:13.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nmgjq'
May 21 08:03:13.700: INFO: stderr: ""
May 21 08:03:13.700: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:03:13.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nmgjq" for this suite.
May 21 08:03:35.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:03:35.813: INFO: namespace: e2e-tests-kubectl-nmgjq, resource: bindings, ignored listing per whitelist
May 21 08:03:35.834: INFO: namespace e2e-tests-kubectl-nmgjq deletion completed in 22.131802656s

• [SLOW TEST:38.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:03:35.835: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 21 08:03:56.902: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:03:57.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-hwpk5" for this suite.
May 21 08:04:19.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:04:19.957: INFO: namespace: e2e-tests-replicaset-hwpk5, resource: bindings, ignored listing per whitelist
May 21 08:04:19.973: INFO: namespace e2e-tests-replicaset-hwpk5 deletion completed in 22.059525837s

• [SLOW TEST:44.138 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:04:19.973: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-09754c86-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:04:22.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t7dtq" for this suite.
May 21 08:04:44.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:04:44.102: INFO: namespace: e2e-tests-configmap-t7dtq, resource: bindings, ignored listing per whitelist
May 21 08:04:44.112: INFO: namespace e2e-tests-configmap-t7dtq deletion completed in 22.064739382s

• [SLOW TEST:24.139 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:04:44.112: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-17d71b5e-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 08:04:44.157: INFO: Waiting up to 5m0s for pod "pod-configmaps-17d7a39b-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-9c4t6" to be "success or failure"
May 21 08:04:44.159: INFO: Pod "pod-configmaps-17d7a39b-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009287ms
May 21 08:04:46.162: INFO: Pod "pod-configmaps-17d7a39b-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004549046s
STEP: Saw pod success
May 21 08:04:46.162: INFO: Pod "pod-configmaps-17d7a39b-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:04:46.164: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-17d7a39b-7b9f-11e9-8b08-72649ad3cdd7 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 08:04:46.175: INFO: Waiting for pod pod-configmaps-17d7a39b-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:04:46.177: INFO: Pod pod-configmaps-17d7a39b-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:04:46.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9c4t6" for this suite.
May 21 08:04:52.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:04:52.233: INFO: namespace: e2e-tests-configmap-9c4t6, resource: bindings, ignored listing per whitelist
May 21 08:04:52.238: INFO: namespace e2e-tests-configmap-9c4t6 deletion completed in 6.058533634s

• [SLOW TEST:8.125 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:04:52.238: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 21 08:04:54.797: INFO: Successfully updated pod "labelsupdate1caecb73-7b9f-11e9-8b08-72649ad3cdd7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:04:58.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2p9xf" for this suite.
May 21 08:05:20.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:05:20.888: INFO: namespace: e2e-tests-projected-2p9xf, resource: bindings, ignored listing per whitelist
May 21 08:05:20.891: INFO: namespace e2e-tests-projected-2p9xf deletion completed in 22.062086224s

• [SLOW TEST:28.653 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:05:20.891: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 08:05:20.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-r5tbl'
May 21 08:05:21.018: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 08:05:21.018: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
May 21 08:05:21.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-r5tbl'
May 21 08:05:21.102: INFO: stderr: ""
May 21 08:05:21.102: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:05:21.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r5tbl" for this suite.
May 21 08:05:27.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:05:27.120: INFO: namespace: e2e-tests-kubectl-r5tbl, resource: bindings, ignored listing per whitelist
May 21 08:05:27.166: INFO: namespace e2e-tests-kubectl-r5tbl deletion completed in 6.062190563s

• [SLOW TEST:6.275 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:05:27.167: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
May 21 08:05:27.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 cluster-info'
May 21 08:05:27.272: INFO: stderr: ""
May 21 08:05:27.273: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mmonitoring-influxdb\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:05:27.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n7ssm" for this suite.
May 21 08:05:33.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:05:33.332: INFO: namespace: e2e-tests-kubectl-n7ssm, resource: bindings, ignored listing per whitelist
May 21 08:05:33.337: INFO: namespace e2e-tests-kubectl-n7ssm deletion completed in 6.061552794s

• [SLOW TEST:6.170 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:05:33.337: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-352f6615-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating configMap with name cm-test-opt-upd-352f6653-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-352f6615-7b9f-11e9-8b08-72649ad3cdd7
STEP: Updating configmap cm-test-opt-upd-352f6653-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating configMap with name cm-test-opt-create-352f6667-7b9f-11e9-8b08-72649ad3cdd7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:05:37.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-np55v" for this suite.
May 21 08:05:59.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:05:59.503: INFO: namespace: e2e-tests-configmap-np55v, resource: bindings, ignored listing per whitelist
May 21 08:05:59.521: INFO: namespace e2e-tests-configmap-np55v deletion completed in 22.0718291s

• [SLOW TEST:26.184 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:05:59.521: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-44c9bedf-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 08:05:59.567: INFO: Waiting up to 5m0s for pod "pod-secrets-44ca571c-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-48l4w" to be "success or failure"
May 21 08:05:59.568: INFO: Pod "pod-secrets-44ca571c-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.51991ms
May 21 08:06:01.571: INFO: Pod "pod-secrets-44ca571c-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004244034s
STEP: Saw pod success
May 21 08:06:01.571: INFO: Pod "pod-secrets-44ca571c-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:06:01.574: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-44ca571c-7b9f-11e9-8b08-72649ad3cdd7 container secret-volume-test: <nil>
STEP: delete the pod
May 21 08:06:01.587: INFO: Waiting for pod pod-secrets-44ca571c-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:06:01.589: INFO: Pod pod-secrets-44ca571c-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:06:01.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-48l4w" for this suite.
May 21 08:06:07.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:06:07.636: INFO: namespace: e2e-tests-secrets-48l4w, resource: bindings, ignored listing per whitelist
May 21 08:06:07.659: INFO: namespace e2e-tests-secrets-48l4w deletion completed in 6.066320808s

• [SLOW TEST:8.139 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:06:07.660: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-49a4400d-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 08:06:07.710: INFO: Waiting up to 5m0s for pod "pod-configmaps-49a4c2cd-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-configmap-k6c6l" to be "success or failure"
May 21 08:06:07.719: INFO: Pod "pod-configmaps-49a4c2cd-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.122707ms
May 21 08:06:09.722: INFO: Pod "pod-configmaps-49a4c2cd-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011871237s
STEP: Saw pod success
May 21 08:06:09.722: INFO: Pod "pod-configmaps-49a4c2cd-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:06:09.723: INFO: Trying to get logs from node 192.168.5.21 pod pod-configmaps-49a4c2cd-7b9f-11e9-8b08-72649ad3cdd7 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 08:06:09.735: INFO: Waiting for pod pod-configmaps-49a4c2cd-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:06:09.736: INFO: Pod pod-configmaps-49a4c2cd-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:06:09.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-k6c6l" for this suite.
May 21 08:06:15.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:06:15.763: INFO: namespace: e2e-tests-configmap-k6c6l, resource: bindings, ignored listing per whitelist
May 21 08:06:15.801: INFO: namespace e2e-tests-configmap-k6c6l deletion completed in 6.062405055s

• [SLOW TEST:8.141 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:06:15.801: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:06:36.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-5nskb" for this suite.
May 21 08:06:58.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:06:58.900: INFO: namespace: e2e-tests-replication-controller-5nskb, resource: bindings, ignored listing per whitelist
May 21 08:06:58.937: INFO: namespace e2e-tests-replication-controller-5nskb deletion completed in 22.071632304s

• [SLOW TEST:43.136 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:06:58.937: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 08:06:58.982: INFO: Waiting up to 5m0s for pod "pod-68342ca7-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-qrhwg" to be "success or failure"
May 21 08:06:58.984: INFO: Pod "pod-68342ca7-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.405683ms
May 21 08:07:00.988: INFO: Pod "pod-68342ca7-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005445616s
STEP: Saw pod success
May 21 08:07:00.988: INFO: Pod "pod-68342ca7-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:07:00.990: INFO: Trying to get logs from node 192.168.5.21 pod pod-68342ca7-7b9f-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 08:07:01.002: INFO: Waiting for pod pod-68342ca7-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:07:01.004: INFO: Pod pod-68342ca7-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:07:01.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qrhwg" for this suite.
May 21 08:07:07.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:07:07.049: INFO: namespace: e2e-tests-emptydir-qrhwg, resource: bindings, ignored listing per whitelist
May 21 08:07:07.068: INFO: namespace e2e-tests-emptydir-qrhwg deletion completed in 6.061174685s

• [SLOW TEST:8.131 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:07:07.069: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-rsnj
STEP: Creating a pod to test atomic-volume-subpath
May 21 08:07:07.118: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-rsnj" in namespace "e2e-tests-subpath-89ps8" to be "success or failure"
May 21 08:07:07.124: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.639013ms
May 21 08:07:09.130: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 2.011826621s
May 21 08:07:11.132: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 4.014510337s
May 21 08:07:13.136: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 6.017986926s
May 21 08:07:15.139: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 8.021259872s
May 21 08:07:17.142: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 10.024070539s
May 21 08:07:19.149: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 12.03092773s
May 21 08:07:21.152: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 14.034091036s
May 21 08:07:23.154: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 16.036697882s
May 21 08:07:25.159: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 18.041501459s
May 21 08:07:27.163: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 20.045301656s
May 21 08:07:29.170: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Running", Reason="", readiness=false. Elapsed: 22.052091409s
May 21 08:07:31.173: INFO: Pod "pod-subpath-test-downwardapi-rsnj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.055354938s
STEP: Saw pod success
May 21 08:07:31.173: INFO: Pod "pod-subpath-test-downwardapi-rsnj" satisfied condition "success or failure"
May 21 08:07:31.175: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-downwardapi-rsnj container test-container-subpath-downwardapi-rsnj: <nil>
STEP: delete the pod
May 21 08:07:31.191: INFO: Waiting for pod pod-subpath-test-downwardapi-rsnj to disappear
May 21 08:07:31.195: INFO: Pod pod-subpath-test-downwardapi-rsnj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-rsnj
May 21 08:07:31.195: INFO: Deleting pod "pod-subpath-test-downwardapi-rsnj" in namespace "e2e-tests-subpath-89ps8"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:07:31.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-89ps8" for this suite.
May 21 08:07:37.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:07:37.261: INFO: namespace: e2e-tests-subpath-89ps8, resource: bindings, ignored listing per whitelist
May 21 08:07:37.266: INFO: namespace e2e-tests-subpath-89ps8 deletion completed in 6.06521818s

• [SLOW TEST:30.198 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:07:37.267: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 08:07:37.313: INFO: Waiting up to 5m0s for pod "downward-api-7f0ce02e-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-2f665" to be "success or failure"
May 21 08:07:37.317: INFO: Pod "downward-api-7f0ce02e-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.7081ms
May 21 08:07:39.323: INFO: Pod "downward-api-7f0ce02e-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009736947s
STEP: Saw pod success
May 21 08:07:39.323: INFO: Pod "downward-api-7f0ce02e-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:07:39.324: INFO: Trying to get logs from node 192.168.5.21 pod downward-api-7f0ce02e-7b9f-11e9-8b08-72649ad3cdd7 container dapi-container: <nil>
STEP: delete the pod
May 21 08:07:39.340: INFO: Waiting for pod downward-api-7f0ce02e-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:07:39.343: INFO: Pod downward-api-7f0ce02e-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:07:39.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2f665" for this suite.
May 21 08:07:45.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:07:45.359: INFO: namespace: e2e-tests-downward-api-2f665, resource: bindings, ignored listing per whitelist
May 21 08:07:45.405: INFO: namespace e2e-tests-downward-api-2f665 deletion completed in 6.059487382s

• [SLOW TEST:8.138 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:07:45.405: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 08:07:45.447: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83e60d8d-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-xscdd" to be "success or failure"
May 21 08:07:45.449: INFO: Pod "downwardapi-volume-83e60d8d-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.801299ms
May 21 08:07:47.453: INFO: Pod "downwardapi-volume-83e60d8d-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006017196s
STEP: Saw pod success
May 21 08:07:47.453: INFO: Pod "downwardapi-volume-83e60d8d-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:07:47.455: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-83e60d8d-7b9f-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 08:07:47.468: INFO: Waiting for pod downwardapi-volume-83e60d8d-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:07:47.470: INFO: Pod downwardapi-volume-83e60d8d-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:07:47.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xscdd" for this suite.
May 21 08:07:53.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:07:53.491: INFO: namespace: e2e-tests-projected-xscdd, resource: bindings, ignored listing per whitelist
May 21 08:07:53.539: INFO: namespace e2e-tests-projected-xscdd deletion completed in 6.066544658s

• [SLOW TEST:8.134 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:07:53.539: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-vtj6z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtj6z to expose endpoints map[]
May 21 08:07:53.585: INFO: Get endpoints failed (2.252475ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 21 08:07:54.587: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtj6z exposes endpoints map[] (1.004259603s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-vtj6z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtj6z to expose endpoints map[pod1:[80]]
May 21 08:07:55.599: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtj6z exposes endpoints map[pod1:[80]] (1.007088011s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-vtj6z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtj6z to expose endpoints map[pod1:[80] pod2:[80]]
May 21 08:07:56.614: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtj6z exposes endpoints map[pod2:[80] pod1:[80]] (1.013113165s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-vtj6z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtj6z to expose endpoints map[pod2:[80]]
May 21 08:07:57.625: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtj6z exposes endpoints map[pod2:[80]] (1.007414438s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-vtj6z
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-vtj6z to expose endpoints map[]
May 21 08:07:58.634: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-vtj6z exposes endpoints map[] (1.004848713s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:07:58.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-vtj6z" for this suite.
May 21 08:08:20.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:20.693: INFO: namespace: e2e-tests-services-vtj6z, resource: bindings, ignored listing per whitelist
May 21 08:08:20.732: INFO: namespace e2e-tests-services-vtj6z deletion completed in 22.071214891s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:27.193 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:08:20.733: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
May 21 08:08:20.783: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-151895369 proxy --unix-socket=/tmp/kubectl-proxy-unix021709844/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:08:20.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jcmvh" for this suite.
May 21 08:08:26.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:26.903: INFO: namespace: e2e-tests-kubectl-jcmvh, resource: bindings, ignored listing per whitelist
May 21 08:08:26.917: INFO: namespace e2e-tests-kubectl-jcmvh deletion completed in 6.068049417s

• [SLOW TEST:6.184 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:08:26.917: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
May 21 08:08:26.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 --namespace=e2e-tests-kubectl-8n6hs run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 21 08:08:28.987: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 21 08:08:28.987: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:08:30.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8n6hs" for this suite.
May 21 08:08:37.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:37.032: INFO: namespace: e2e-tests-kubectl-8n6hs, resource: bindings, ignored listing per whitelist
May 21 08:08:37.057: INFO: namespace e2e-tests-kubectl-8n6hs deletion completed in 6.061727329s

• [SLOW TEST:10.140 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:08:37.057: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 08:08:37.109: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2b1095a-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-h99bs" to be "success or failure"
May 21 08:08:37.112: INFO: Pod "downwardapi-volume-a2b1095a-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.157774ms
May 21 08:08:39.122: INFO: Pod "downwardapi-volume-a2b1095a-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01287784s
STEP: Saw pod success
May 21 08:08:39.122: INFO: Pod "downwardapi-volume-a2b1095a-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:08:39.124: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-a2b1095a-7b9f-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 08:08:39.140: INFO: Waiting for pod downwardapi-volume-a2b1095a-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:08:39.143: INFO: Pod downwardapi-volume-a2b1095a-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:08:39.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-h99bs" for this suite.
May 21 08:08:45.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:45.202: INFO: namespace: e2e-tests-downward-api-h99bs, resource: bindings, ignored listing per whitelist
May 21 08:08:45.208: INFO: namespace e2e-tests-downward-api-h99bs deletion completed in 6.060482244s

• [SLOW TEST:8.151 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:08:45.208: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
May 21 08:08:45.261: INFO: Waiting up to 5m0s for pod "client-containers-a78c8198-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-containers-t4h7b" to be "success or failure"
May 21 08:08:45.262: INFO: Pod "client-containers-a78c8198-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.60703ms
May 21 08:08:47.265: INFO: Pod "client-containers-a78c8198-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004481107s
STEP: Saw pod success
May 21 08:08:47.265: INFO: Pod "client-containers-a78c8198-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:08:47.267: INFO: Trying to get logs from node 192.168.5.21 pod client-containers-a78c8198-7b9f-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 08:08:47.278: INFO: Waiting for pod client-containers-a78c8198-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:08:47.280: INFO: Pod client-containers-a78c8198-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:08:47.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-t4h7b" for this suite.
May 21 08:08:53.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:08:53.345: INFO: namespace: e2e-tests-containers-t4h7b, resource: bindings, ignored listing per whitelist
May 21 08:08:53.352: INFO: namespace e2e-tests-containers-t4h7b deletion completed in 6.06706511s

• [SLOW TEST:8.144 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:08:53.352: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-ac6e569c-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating secret with name secret-projected-all-test-volume-ac6e5688-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test Check all projections for projected volume plugin
May 21 08:08:53.454: INFO: Waiting up to 5m0s for pod "projected-volume-ac6e5653-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-4hj2m" to be "success or failure"
May 21 08:08:53.457: INFO: Pod "projected-volume-ac6e5653-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.577862ms
May 21 08:08:55.460: INFO: Pod "projected-volume-ac6e5653-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006433906s
STEP: Saw pod success
May 21 08:08:55.460: INFO: Pod "projected-volume-ac6e5653-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:08:55.462: INFO: Trying to get logs from node 192.168.5.21 pod projected-volume-ac6e5653-7b9f-11e9-8b08-72649ad3cdd7 container projected-all-volume-test: <nil>
STEP: delete the pod
May 21 08:08:55.476: INFO: Waiting for pod projected-volume-ac6e5653-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:08:55.478: INFO: Pod projected-volume-ac6e5653-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:08:55.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4hj2m" for this suite.
May 21 08:09:01.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:09:01.515: INFO: namespace: e2e-tests-projected-4hj2m, resource: bindings, ignored listing per whitelist
May 21 08:09:01.549: INFO: namespace e2e-tests-projected-4hj2m deletion completed in 6.065210045s

• [SLOW TEST:8.197 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:09:01.549: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:09:01.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 version --client'
May 21 08:09:01.647: INFO: stderr: ""
May 21 08:09:01.647: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 21 08:09:01.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-mbfvp'
May 21 08:09:01.798: INFO: stderr: ""
May 21 08:09:01.798: INFO: stdout: "replicationcontroller/redis-master created\n"
May 21 08:09:01.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-mbfvp'
May 21 08:09:01.938: INFO: stderr: ""
May 21 08:09:01.938: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 08:09:02.941: INFO: Selector matched 1 pods for map[app:redis]
May 21 08:09:02.941: INFO: Found 0 / 1
May 21 08:09:03.944: INFO: Selector matched 1 pods for map[app:redis]
May 21 08:09:03.944: INFO: Found 1 / 1
May 21 08:09:03.944: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 08:09:03.945: INFO: Selector matched 1 pods for map[app:redis]
May 21 08:09:03.945: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 08:09:03.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 describe pod redis-master-zzl52 --namespace=e2e-tests-kubectl-mbfvp'
May 21 08:09:04.020: INFO: stderr: ""
May 21 08:09:04.020: INFO: stdout: "Name:           redis-master-zzl52\nNamespace:      e2e-tests-kubectl-mbfvp\nNode:           192.168.5.21/192.168.5.21\nStart Time:     Tue, 21 May 2019 08:09:01 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.8.3.33\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://76ce0cdb32146b5e6dd3c02d0a53a1a23f3cf8fc85ab4d7f8262b549e237a53c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 21 May 2019 08:09:02 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-dnx9m (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-dnx9m:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-dnx9m\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  3s    default-scheduler      Successfully assigned e2e-tests-kubectl-mbfvp/redis-master-zzl52 to 192.168.5.21\n  Normal  Pulled     2s    kubelet, 192.168.5.21  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 192.168.5.21  Created container\n  Normal  Started    2s    kubelet, 192.168.5.21  Started container\n"
May 21 08:09:04.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 describe rc redis-master --namespace=e2e-tests-kubectl-mbfvp'
May 21 08:09:04.106: INFO: stderr: ""
May 21 08:09:04.106: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-mbfvp\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-zzl52\n"
May 21 08:09:04.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 describe service redis-master --namespace=e2e-tests-kubectl-mbfvp'
May 21 08:09:04.179: INFO: stderr: ""
May 21 08:09:04.179: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-mbfvp\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.106.103\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.8.3.33:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 21 08:09:04.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 describe node 192.168.5.14'
May 21 08:09:04.260: INFO: stderr: ""
May 21 08:09:04.260: INFO: stdout: "Name:               192.168.5.14\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-east-1\n                    failure-domain.beta.kubernetes.io/zone=eu-east-1b\n                    kubernetes.io/hostname=192.168.5.14\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: null\n                    flannel.alpha.coreos.com/backend-type: \n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.5.14\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 21 May 2019 04:23:23 +0000\nTaints:             dedicated=master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 21 May 2019 08:08:58 +0000   Tue, 21 May 2019 04:23:18 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 21 May 2019 08:08:58 +0000   Tue, 21 May 2019 04:23:18 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 21 May 2019 08:08:58 +0000   Tue, 21 May 2019 04:23:18 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 21 May 2019 08:08:58 +0000   Tue, 21 May 2019 04:24:33 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.5.14\n  Hostname:    192.168.5.14\nCapacity:\n cpu:                2\n ephemeral-storage:  51474912Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3882036Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  47439278821\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3779636Ki\n pods:               110\nSystem Info:\n Machine ID:                 6a698a2ef7b94026a90df0cb2cdff1f9\n System UUID:                EAE0C931-943E-4A83-A93B-78C69555F721\n Boot ID:                    caf8e3fa-1e01-4bc9-9839-01111f7265ed\n Kernel Version:             3.10.0-514.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.13.4\n Kube-Proxy Version:         v1.13.4\nPodCIDR:                     10.8.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-55252047aa2d4aa6-qr2mx    0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                coredns-5447594c47-z6c2d                                   100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     3h44m\n  kube-system                etcd-192.168.5.14                                          300m (15%)    0 (0%)      0 (0%)           0 (0%)         3h44m\n  kube-system                ksc-flexvolume-ds-hxgqx                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h44m\n  kube-system                kube-apiserver-192.168.5.14                                250m (12%)    0 (0%)      0 (0%)           0 (0%)         3h44m\n  kube-system                kube-controller-manager-192.168.5.14                       200m (10%)    0 (0%)      0 (0%)           0 (0%)         3h44m\n  kube-system                kube-flannel-mtw6t                                         150m (7%)     300m (15%)  64M (1%)         500M (12%)     3h44m\n  kube-system                kube-proxy-6hfcx                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h45m\n  kube-system                kube-scheduler-192.168.5.14                                100m (5%)     0 (0%)      0 (0%)           0 (0%)         3h44m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                1100m (55%)    300m (15%)\n  memory             134180Ki (3%)  678257920 (17%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
May 21 08:09:04.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 describe namespace e2e-tests-kubectl-mbfvp'
May 21 08:09:04.325: INFO: stderr: ""
May 21 08:09:04.325: INFO: stdout: "Name:         e2e-tests-kubectl-mbfvp\nLabels:       e2e-framework=kubectl\n              e2e-run=f56544fb-7b95-11e9-8b08-72649ad3cdd7\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:09:04.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mbfvp" for this suite.
May 21 08:09:26.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:09:26.374: INFO: namespace: e2e-tests-kubectl-mbfvp, resource: bindings, ignored listing per whitelist
May 21 08:09:26.389: INFO: namespace e2e-tests-kubectl-mbfvp deletion completed in 22.061042824s

• [SLOW TEST:24.840 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:09:26.389: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 08:09:26.439: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c017e450-7b9f-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-rqgsh" to be "success or failure"
May 21 08:09:26.445: INFO: Pod "downwardapi-volume-c017e450-7b9f-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.523198ms
May 21 08:09:28.448: INFO: Pod "downwardapi-volume-c017e450-7b9f-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008338185s
STEP: Saw pod success
May 21 08:09:28.448: INFO: Pod "downwardapi-volume-c017e450-7b9f-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:09:28.449: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-c017e450-7b9f-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 08:09:28.463: INFO: Waiting for pod downwardapi-volume-c017e450-7b9f-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:09:28.464: INFO: Pod downwardapi-volume-c017e450-7b9f-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:09:28.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rqgsh" for this suite.
May 21 08:09:34.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:09:34.524: INFO: namespace: e2e-tests-downward-api-rqgsh, resource: bindings, ignored listing per whitelist
May 21 08:09:34.528: INFO: namespace e2e-tests-downward-api-rqgsh deletion completed in 6.060908154s

• [SLOW TEST:8.139 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:09:34.528: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
May 21 08:09:34.582: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-lj9wp" to be "success or failure"
May 21 08:09:34.584: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.200406ms
May 21 08:09:36.590: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00788736s
STEP: Saw pod success
May 21 08:09:36.590: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 21 08:09:36.591: INFO: Trying to get logs from node 192.168.5.21 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 21 08:09:36.604: INFO: Waiting for pod pod-host-path-test to disappear
May 21 08:09:36.609: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:09:36.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-lj9wp" for this suite.
May 21 08:09:42.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:09:42.631: INFO: namespace: e2e-tests-hostpath-lj9wp, resource: bindings, ignored listing per whitelist
May 21 08:09:42.670: INFO: namespace e2e-tests-hostpath-lj9wp deletion completed in 6.058024748s

• [SLOW TEST:8.142 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:09:42.670: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-8sx4
STEP: Creating a pod to test atomic-volume-subpath
May 21 08:09:42.728: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8sx4" in namespace "e2e-tests-subpath-h4cln" to be "success or failure"
May 21 08:09:42.732: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.221607ms
May 21 08:09:44.735: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006795326s
May 21 08:09:46.741: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 4.012889459s
May 21 08:09:48.744: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 6.01575777s
May 21 08:09:50.746: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 8.018360045s
May 21 08:09:52.750: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 10.0222386s
May 21 08:09:54.753: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 12.025169287s
May 21 08:09:56.760: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 14.031771365s
May 21 08:09:58.763: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 16.034854822s
May 21 08:10:00.766: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 18.037972302s
May 21 08:10:02.769: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 20.040859272s
May 21 08:10:04.772: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Running", Reason="", readiness=false. Elapsed: 22.043969962s
May 21 08:10:06.778: INFO: Pod "pod-subpath-test-projected-8sx4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.05036617s
STEP: Saw pod success
May 21 08:10:06.778: INFO: Pod "pod-subpath-test-projected-8sx4" satisfied condition "success or failure"
May 21 08:10:06.780: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-projected-8sx4 container test-container-subpath-projected-8sx4: <nil>
STEP: delete the pod
May 21 08:10:06.800: INFO: Waiting for pod pod-subpath-test-projected-8sx4 to disappear
May 21 08:10:06.803: INFO: Pod pod-subpath-test-projected-8sx4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-8sx4
May 21 08:10:06.803: INFO: Deleting pod "pod-subpath-test-projected-8sx4" in namespace "e2e-tests-subpath-h4cln"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:10:06.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-h4cln" for this suite.
May 21 08:10:12.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:10:12.835: INFO: namespace: e2e-tests-subpath-h4cln, resource: bindings, ignored listing per whitelist
May 21 08:10:12.869: INFO: namespace e2e-tests-subpath-h4cln deletion completed in 6.061478245s

• [SLOW TEST:30.199 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:10:12.869: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 21 08:10:15.434: INFO: Successfully updated pod "annotationupdatedbcbc9e9-7b9f-11e9-8b08-72649ad3cdd7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:10:19.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z4ptl" for this suite.
May 21 08:10:41.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:10:41.487: INFO: namespace: e2e-tests-projected-z4ptl, resource: bindings, ignored listing per whitelist
May 21 08:10:41.519: INFO: namespace e2e-tests-projected-z4ptl deletion completed in 22.060340996s

• [SLOW TEST:28.650 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:10:41.519: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ece01b82-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating configMap with name cm-test-opt-upd-ece01bee-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ece01b82-7b9f-11e9-8b08-72649ad3cdd7
STEP: Updating configmap cm-test-opt-upd-ece01bee-7b9f-11e9-8b08-72649ad3cdd7
STEP: Creating configMap with name cm-test-opt-create-ece01c06-7b9f-11e9-8b08-72649ad3cdd7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:10:47.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ln66h" for this suite.
May 21 08:11:09.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:11:09.683: INFO: namespace: e2e-tests-projected-ln66h, resource: bindings, ignored listing per whitelist
May 21 08:11:09.707: INFO: namespace e2e-tests-projected-ln66h deletion completed in 22.064757221s

• [SLOW TEST:28.188 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:11:09.708: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 08:11:09.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5x7sv'
May 21 08:11:09.918: INFO: stderr: ""
May 21 08:11:09.918: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
May 21 08:11:09.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-5x7sv'
May 21 08:11:14.025: INFO: stderr: ""
May 21 08:11:14.025: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:11:14.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5x7sv" for this suite.
May 21 08:11:20.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:11:20.086: INFO: namespace: e2e-tests-kubectl-5x7sv, resource: bindings, ignored listing per whitelist
May 21 08:11:20.092: INFO: namespace e2e-tests-kubectl-5x7sv deletion completed in 6.061269743s

• [SLOW TEST:10.385 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:11:20.092: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-03dd393d-7ba0-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 08:11:20.140: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-03ddd24c-7ba0-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-tmh8p" to be "success or failure"
May 21 08:11:20.142: INFO: Pod "pod-projected-secrets-03ddd24c-7ba0-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.857553ms
May 21 08:11:22.144: INFO: Pod "pod-projected-secrets-03ddd24c-7ba0-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004357538s
STEP: Saw pod success
May 21 08:11:22.144: INFO: Pod "pod-projected-secrets-03ddd24c-7ba0-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:11:22.146: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-03ddd24c-7ba0-11e9-8b08-72649ad3cdd7 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 08:11:22.158: INFO: Waiting for pod pod-projected-secrets-03ddd24c-7ba0-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:11:22.161: INFO: Pod pod-projected-secrets-03ddd24c-7ba0-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:11:22.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tmh8p" for this suite.
May 21 08:11:28.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:11:28.200: INFO: namespace: e2e-tests-projected-tmh8p, resource: bindings, ignored listing per whitelist
May 21 08:11:28.219: INFO: namespace e2e-tests-projected-tmh8p deletion completed in 6.05594475s

• [SLOW TEST:8.127 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:11:28.219: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:11:28.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-mmptm" for this suite.
May 21 08:11:34.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:11:34.319: INFO: namespace: e2e-tests-kubelet-test-mmptm, resource: bindings, ignored listing per whitelist
May 21 08:11:34.347: INFO: namespace e2e-tests-kubelet-test-mmptm deletion completed in 6.069903576s

• [SLOW TEST:6.128 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:11:34.347: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 21 08:11:36.936: INFO: Successfully updated pod "labelsupdate0c5e6c43-7ba0-11e9-8b08-72649ad3cdd7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:11:40.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dmqgp" for this suite.
May 21 08:12:02.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:12:03.011: INFO: namespace: e2e-tests-downward-api-dmqgp, resource: bindings, ignored listing per whitelist
May 21 08:12:03.024: INFO: namespace e2e-tests-downward-api-dmqgp deletion completed in 22.067621219s

• [SLOW TEST:28.677 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:12:03.024: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1d741f01-7ba0-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 08:12:03.071: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1d74a6be-7ba0-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-58zqg" to be "success or failure"
May 21 08:12:03.073: INFO: Pod "pod-projected-secrets-1d74a6be-7ba0-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.161103ms
May 21 08:12:05.083: INFO: Pod "pod-projected-secrets-1d74a6be-7ba0-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011240984s
STEP: Saw pod success
May 21 08:12:05.083: INFO: Pod "pod-projected-secrets-1d74a6be-7ba0-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:12:05.090: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-1d74a6be-7ba0-11e9-8b08-72649ad3cdd7 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 08:12:05.113: INFO: Waiting for pod pod-projected-secrets-1d74a6be-7ba0-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:12:05.117: INFO: Pod pod-projected-secrets-1d74a6be-7ba0-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:12:05.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-58zqg" for this suite.
May 21 08:12:11.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:12:11.150: INFO: namespace: e2e-tests-projected-58zqg, resource: bindings, ignored listing per whitelist
May 21 08:12:11.187: INFO: namespace e2e-tests-projected-58zqg deletion completed in 6.068045854s

• [SLOW TEST:8.163 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:12:11.188: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
May 21 08:12:11.229: INFO: Waiting up to 5m0s for pod "pod-22515124-7ba0-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-4hpvs" to be "success or failure"
May 21 08:12:11.231: INFO: Pod "pod-22515124-7ba0-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.909803ms
May 21 08:12:13.234: INFO: Pod "pod-22515124-7ba0-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004062572s
STEP: Saw pod success
May 21 08:12:13.234: INFO: Pod "pod-22515124-7ba0-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:12:13.235: INFO: Trying to get logs from node 192.168.5.21 pod pod-22515124-7ba0-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 08:12:13.247: INFO: Waiting for pod pod-22515124-7ba0-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:12:13.248: INFO: Pod pod-22515124-7ba0-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:12:13.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4hpvs" for this suite.
May 21 08:12:19.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:12:19.294: INFO: namespace: e2e-tests-emptydir-4hpvs, resource: bindings, ignored listing per whitelist
May 21 08:12:19.320: INFO: namespace e2e-tests-emptydir-4hpvs deletion completed in 6.067035977s

• [SLOW TEST:8.132 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:12:19.320: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 08:12:19.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qxw4z'
May 21 08:12:19.448: INFO: stderr: ""
May 21 08:12:19.448: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 21 08:12:24.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qxw4z -o json'
May 21 08:12:24.563: INFO: stderr: ""
May 21 08:12:24.563: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-05-21T08:12:19Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-qxw4z\",\n        \"resourceVersion\": \"29906\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-qxw4z/pods/e2e-test-nginx-pod\",\n        \"uid\": \"2736debd-7ba0-11e9-8844-fa163e715483\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-7fpcz\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.5.21\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-7fpcz\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-7fpcz\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-21T08:12:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-21T08:12:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-21T08:12:21Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-21T08:12:19Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://3bc600c6cdde6c2bb6dd9dd2fe299795a04f94ceacb4f2db24020d194bf80181\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-21T08:12:20Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.5.21\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.8.3.43\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-21T08:12:19Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 21 08:12:24.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 replace -f - --namespace=e2e-tests-kubectl-qxw4z'
May 21 08:12:24.709: INFO: stderr: ""
May 21 08:12:24.709: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
May 21 08:12:24.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-qxw4z'
May 21 08:12:26.122: INFO: stderr: ""
May 21 08:12:26.122: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:12:26.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qxw4z" for this suite.
May 21 08:12:32.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:12:32.147: INFO: namespace: e2e-tests-kubectl-qxw4z, resource: bindings, ignored listing per whitelist
May 21 08:12:32.187: INFO: namespace e2e-tests-kubectl-qxw4z deletion completed in 6.062132386s

• [SLOW TEST:12.867 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:12:32.187: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
May 21 08:12:32.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 create -f - --namespace=e2e-tests-kubectl-q2lst'
May 21 08:12:32.392: INFO: stderr: ""
May 21 08:12:32.392: INFO: stdout: "pod/pause created\n"
May 21 08:12:32.392: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 21 08:12:32.392: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-q2lst" to be "running and ready"
May 21 08:12:32.397: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.883504ms
May 21 08:12:34.400: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007231289s
May 21 08:12:34.400: INFO: Pod "pause" satisfied condition "running and ready"
May 21 08:12:34.400: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
May 21 08:12:34.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-q2lst'
May 21 08:12:34.468: INFO: stderr: ""
May 21 08:12:34.468: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 21 08:12:34.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pod pause -L testing-label --namespace=e2e-tests-kubectl-q2lst'
May 21 08:12:34.533: INFO: stderr: ""
May 21 08:12:34.533: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 21 08:12:34.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 label pods pause testing-label- --namespace=e2e-tests-kubectl-q2lst'
May 21 08:12:34.601: INFO: stderr: ""
May 21 08:12:34.601: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 21 08:12:34.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pod pause -L testing-label --namespace=e2e-tests-kubectl-q2lst'
May 21 08:12:34.661: INFO: stderr: ""
May 21 08:12:34.661: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
May 21 08:12:34.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-q2lst'
May 21 08:12:34.733: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 08:12:34.733: INFO: stdout: "pod \"pause\" force deleted\n"
May 21 08:12:34.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-q2lst'
May 21 08:12:34.816: INFO: stderr: "No resources found.\n"
May 21 08:12:34.816: INFO: stdout: ""
May 21 08:12:34.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 get pods -l name=pause --namespace=e2e-tests-kubectl-q2lst -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 08:12:34.888: INFO: stderr: ""
May 21 08:12:34.888: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:12:34.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q2lst" for this suite.
May 21 08:12:40.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:12:40.951: INFO: namespace: e2e-tests-kubectl-q2lst, resource: bindings, ignored listing per whitelist
May 21 08:12:40.955: INFO: namespace e2e-tests-kubectl-q2lst deletion completed in 6.063691706s

• [SLOW TEST:8.768 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:12:40.955: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 21 08:12:45.022: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 08:12:45.024: INFO: Pod pod-with-prestop-http-hook still exists
May 21 08:12:47.024: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 08:12:47.027: INFO: Pod pod-with-prestop-http-hook still exists
May 21 08:12:49.024: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 08:12:49.030: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:12:49.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-lnzkg" for this suite.
May 21 08:13:11.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:13:11.092: INFO: namespace: e2e-tests-container-lifecycle-hook-lnzkg, resource: bindings, ignored listing per whitelist
May 21 08:13:11.102: INFO: namespace e2e-tests-container-lifecycle-hook-lnzkg deletion completed in 22.06379661s

• [SLOW TEST:30.147 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:13:11.102: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-tdh89
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 08:13:11.141: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 08:13:27.183: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.8.3.48:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-tdh89 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 08:13:27.183: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 08:13:27.308: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:13:27.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-tdh89" for this suite.
May 21 08:13:43.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:13:43.365: INFO: namespace: e2e-tests-pod-network-test-tdh89, resource: bindings, ignored listing per whitelist
May 21 08:13:43.377: INFO: namespace e2e-tests-pod-network-test-tdh89 deletion completed in 16.065564846s

• [SLOW TEST:32.276 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:13:43.377: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:13:43.423: INFO: (0) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.560303ms)
May 21 08:13:43.425: INFO: (1) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.025931ms)
May 21 08:13:43.427: INFO: (2) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.892769ms)
May 21 08:13:43.429: INFO: (3) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.954396ms)
May 21 08:13:43.431: INFO: (4) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.966816ms)
May 21 08:13:43.433: INFO: (5) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.049405ms)
May 21 08:13:43.435: INFO: (6) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.003014ms)
May 21 08:13:43.437: INFO: (7) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.962425ms)
May 21 08:13:43.439: INFO: (8) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.919937ms)
May 21 08:13:43.441: INFO: (9) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.037712ms)
May 21 08:13:43.443: INFO: (10) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.918445ms)
May 21 08:13:43.445: INFO: (11) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.985579ms)
May 21 08:13:43.447: INFO: (12) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.030092ms)
May 21 08:13:43.449: INFO: (13) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.006428ms)
May 21 08:13:43.451: INFO: (14) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.944904ms)
May 21 08:13:43.454: INFO: (15) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.385795ms)
May 21 08:13:43.456: INFO: (16) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.99465ms)
May 21 08:13:43.458: INFO: (17) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 2.274953ms)
May 21 08:13:43.460: INFO: (18) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.905485ms)
May 21 08:13:43.462: INFO: (19) /api/v1/nodes/192.168.5.21:10250/proxy/logs/: <pre>
<a href="AgentMonitor.log">AgentMonitor.log</a>
<a href="CloudAgent.log">CloudAgent.log</a>... (200; 1.956766ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:13:43.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-c6pq6" for this suite.
May 21 08:13:49.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:13:49.491: INFO: namespace: e2e-tests-proxy-c6pq6, resource: bindings, ignored listing per whitelist
May 21 08:13:49.522: INFO: namespace e2e-tests-proxy-c6pq6 deletion completed in 6.05789543s

• [SLOW TEST:6.144 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:13:49.522: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 21 08:13:49.623: INFO: Waiting up to 5m0s for pod "downward-api-5cf266cc-7ba0-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-4bwdp" to be "success or failure"
May 21 08:13:49.627: INFO: Pod "downward-api-5cf266cc-7ba0-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.785829ms
May 21 08:13:51.630: INFO: Pod "downward-api-5cf266cc-7ba0-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007102107s
STEP: Saw pod success
May 21 08:13:51.630: INFO: Pod "downward-api-5cf266cc-7ba0-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:13:51.636: INFO: Trying to get logs from node 192.168.5.21 pod downward-api-5cf266cc-7ba0-11e9-8b08-72649ad3cdd7 container dapi-container: <nil>
STEP: delete the pod
May 21 08:13:51.672: INFO: Waiting for pod downward-api-5cf266cc-7ba0-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:13:51.675: INFO: Pod downward-api-5cf266cc-7ba0-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:13:51.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4bwdp" for this suite.
May 21 08:13:57.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:13:57.738: INFO: namespace: e2e-tests-downward-api-4bwdp, resource: bindings, ignored listing per whitelist
May 21 08:13:57.742: INFO: namespace e2e-tests-downward-api-4bwdp deletion completed in 6.064699085s

• [SLOW TEST:8.220 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:13:57.742: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 21 08:13:57.779: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:14:01.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hzs2j" for this suite.
May 21 08:14:07.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:14:07.459: INFO: namespace: e2e-tests-init-container-hzs2j, resource: bindings, ignored listing per whitelist
May 21 08:14:07.474: INFO: namespace e2e-tests-init-container-hzs2j deletion completed in 6.064743011s

• [SLOW TEST:9.732 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:14:07.474: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-67a11a3d-7ba0-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 08:14:07.518: INFO: Waiting up to 5m0s for pod "pod-secrets-67a1aeda-7ba0-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-jlqw5" to be "success or failure"
May 21 08:14:07.520: INFO: Pod "pod-secrets-67a1aeda-7ba0-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.712421ms
May 21 08:14:09.523: INFO: Pod "pod-secrets-67a1aeda-7ba0-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005379627s
STEP: Saw pod success
May 21 08:14:09.523: INFO: Pod "pod-secrets-67a1aeda-7ba0-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:14:09.525: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-67a1aeda-7ba0-11e9-8b08-72649ad3cdd7 container secret-env-test: <nil>
STEP: delete the pod
May 21 08:14:09.536: INFO: Waiting for pod pod-secrets-67a1aeda-7ba0-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:14:09.537: INFO: Pod pod-secrets-67a1aeda-7ba0-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:14:09.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jlqw5" for this suite.
May 21 08:14:15.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:14:15.607: INFO: namespace: e2e-tests-secrets-jlqw5, resource: bindings, ignored listing per whitelist
May 21 08:14:15.611: INFO: namespace e2e-tests-secrets-jlqw5 deletion completed in 6.070979606s

• [SLOW TEST:8.136 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:14:15.611: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:14:15.651: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:14:17.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vvdwt" for this suite.
May 21 08:15:07.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:15:07.725: INFO: namespace: e2e-tests-pods-vvdwt, resource: bindings, ignored listing per whitelist
May 21 08:15:07.747: INFO: namespace e2e-tests-pods-vvdwt deletion completed in 50.061252046s

• [SLOW TEST:52.136 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:15:07.747: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5p466
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 08:15:07.804: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 08:15:23.853: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.8.3.55:8080/dial?request=hostName&protocol=http&host=10.8.3.54&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-5p466 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 08:15:23.853: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
May 21 08:15:24.002: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:15:24.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5p466" for this suite.
May 21 08:15:46.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:15:46.042: INFO: namespace: e2e-tests-pod-network-test-5p466, resource: bindings, ignored listing per whitelist
May 21 08:15:46.075: INFO: namespace e2e-tests-pod-network-test-5p466 deletion completed in 22.069172118s

• [SLOW TEST:38.328 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:15:46.076: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:15:46.114: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 21 08:15:46.129: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 08:15:48.133: INFO: Creating deployment "test-rolling-update-deployment"
May 21 08:15:48.136: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 21 08:15:48.139: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 21 08:15:50.145: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 21 08:15:50.146: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 21 08:15:50.151: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-m4rgk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-m4rgk/deployments/test-rolling-update-deployment,UID:a39aba9e-7ba0-11e9-926e-fa163e6dedea,ResourceVersion:30573,Generation:1,CreationTimestamp:2019-05-21 08:15:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-21 08:15:48 +0000 UTC 2019-05-21 08:15:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-21 08:15:49 +0000 UTC 2019-05-21 08:15:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 21 08:15:50.154: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-m4rgk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-m4rgk/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:a39c914f-7ba0-11e9-8844-fa163e715483,ResourceVersion:30564,Generation:1,CreationTimestamp:2019-05-21 08:15:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a39aba9e-7ba0-11e9-926e-fa163e6dedea 0xc000db72a7 0xc000db72a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 21 08:15:50.154: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 21 08:15:50.154: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-m4rgk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-m4rgk/replicasets/test-rolling-update-controller,UID:a266b1a2-7ba0-11e9-926e-fa163e6dedea,ResourceVersion:30572,Generation:2,CreationTimestamp:2019-05-21 08:15:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a39aba9e-7ba0-11e9-926e-fa163e6dedea 0xc000db71e7 0xc000db71e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 21 08:15:50.156: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-vgvkw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-vgvkw,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-m4rgk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-m4rgk/pods/test-rolling-update-deployment-68b55d7bc6-vgvkw,UID:a39d3cc7-7ba0-11e9-8844-fa163e715483,ResourceVersion:30563,Generation:0,CreationTimestamp:2019-05-21 08:15:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 a39c914f-7ba0-11e9-8844-fa163e715483 0xc001786657 0xc001786658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fwskw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fwskw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fwskw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 08:15:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 08:15:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 08:15:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 08:15:48 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.57,StartTime:2019-05-21 08:15:48 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-21 08:15:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://19099276a630122cb110049d2031da6e9929ae812add13683c74a53a5008e7ef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:15:50.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-m4rgk" for this suite.
May 21 08:15:56.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:15:56.212: INFO: namespace: e2e-tests-deployment-m4rgk, resource: bindings, ignored listing per whitelist
May 21 08:15:56.220: INFO: namespace e2e-tests-deployment-m4rgk deletion completed in 6.060693102s

• [SLOW TEST:10.144 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:15:56.220: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 08:15:58.779: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a872acaa-7ba0-11e9-8b08-72649ad3cdd7"
May 21 08:15:58.779: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a872acaa-7ba0-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-pods-b2n8t" to be "terminated due to deadline exceeded"
May 21 08:15:58.781: INFO: Pod "pod-update-activedeadlineseconds-a872acaa-7ba0-11e9-8b08-72649ad3cdd7": Phase="Running", Reason="", readiness=true. Elapsed: 1.544295ms
May 21 08:16:00.784: INFO: Pod "pod-update-activedeadlineseconds-a872acaa-7ba0-11e9-8b08-72649ad3cdd7": Phase="Running", Reason="", readiness=true. Elapsed: 2.004450965s
May 21 08:16:02.787: INFO: Pod "pod-update-activedeadlineseconds-a872acaa-7ba0-11e9-8b08-72649ad3cdd7": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007177633s
May 21 08:16:02.787: INFO: Pod "pod-update-activedeadlineseconds-a872acaa-7ba0-11e9-8b08-72649ad3cdd7" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:16:02.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-b2n8t" for this suite.
May 21 08:16:08.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:16:08.826: INFO: namespace: e2e-tests-pods-b2n8t, resource: bindings, ignored listing per whitelist
May 21 08:16:08.852: INFO: namespace e2e-tests-pods-b2n8t deletion completed in 6.059260754s

• [SLOW TEST:12.632 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:16:08.852: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 08:16:08.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-sm9d6'
May 21 08:16:08.984: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 08:16:08.984: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 21 08:16:08.992: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-zdf8f]
May 21 08:16:08.992: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-zdf8f" in namespace "e2e-tests-kubectl-sm9d6" to be "running and ready"
May 21 08:16:08.993: INFO: Pod "e2e-test-nginx-rc-zdf8f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.675414ms
May 21 08:16:10.996: INFO: Pod "e2e-test-nginx-rc-zdf8f": Phase="Running", Reason="", readiness=true. Elapsed: 2.004486571s
May 21 08:16:10.996: INFO: Pod "e2e-test-nginx-rc-zdf8f" satisfied condition "running and ready"
May 21 08:16:10.996: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-zdf8f]
May 21 08:16:10.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-sm9d6'
May 21 08:16:11.079: INFO: stderr: ""
May 21 08:16:11.079: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
May 21 08:16:11.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-sm9d6'
May 21 08:16:11.145: INFO: stderr: ""
May 21 08:16:11.145: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:16:11.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sm9d6" for this suite.
May 21 08:16:17.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:16:17.185: INFO: namespace: e2e-tests-kubectl-sm9d6, resource: bindings, ignored listing per whitelist
May 21 08:16:17.211: INFO: namespace e2e-tests-kubectl-sm9d6 deletion completed in 6.063502073s

• [SLOW TEST:8.359 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:16:17.212: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0521 08:16:18.278452      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 08:16:18.278: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:16:18.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4j6c8" for this suite.
May 21 08:16:24.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:16:24.339: INFO: namespace: e2e-tests-gc-4j6c8, resource: bindings, ignored listing per whitelist
May 21 08:16:24.344: INFO: namespace e2e-tests-gc-4j6c8 deletion completed in 6.063763067s

• [SLOW TEST:7.132 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:16:24.345: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 21 08:16:24.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-5md64'
May 21 08:16:24.472: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 08:16:24.472: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
May 21 08:16:28.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-5md64'
May 21 08:16:28.557: INFO: stderr: ""
May 21 08:16:28.557: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:16:28.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5md64" for this suite.
May 21 08:16:34.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:16:34.587: INFO: namespace: e2e-tests-kubectl-5md64, resource: bindings, ignored listing per whitelist
May 21 08:16:34.622: INFO: namespace e2e-tests-kubectl-5md64 deletion completed in 6.061682981s

• [SLOW TEST:10.278 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:16:34.622: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-75wk9
May 21 08:16:36.680: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-75wk9
STEP: checking the pod's current state and verifying that restartCount is present
May 21 08:16:36.682: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:20:37.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-75wk9" for this suite.
May 21 08:20:43.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:20:43.183: INFO: namespace: e2e-tests-container-probe-75wk9, resource: bindings, ignored listing per whitelist
May 21 08:20:43.221: INFO: namespace e2e-tests-container-probe-75wk9 deletion completed in 6.064164734s

• [SLOW TEST:248.599 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:20:43.221: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 08:20:43.275: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5384f9a0-7ba1-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-zcflq" to be "success or failure"
May 21 08:20:43.276: INFO: Pod "downwardapi-volume-5384f9a0-7ba1-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.549194ms
May 21 08:20:45.279: INFO: Pod "downwardapi-volume-5384f9a0-7ba1-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003954284s
STEP: Saw pod success
May 21 08:20:45.279: INFO: Pod "downwardapi-volume-5384f9a0-7ba1-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:20:45.281: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-5384f9a0-7ba1-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 08:20:45.296: INFO: Waiting for pod downwardapi-volume-5384f9a0-7ba1-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:20:45.298: INFO: Pod downwardapi-volume-5384f9a0-7ba1-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:20:45.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zcflq" for this suite.
May 21 08:20:51.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:20:51.321: INFO: namespace: e2e-tests-projected-zcflq, resource: bindings, ignored listing per whitelist
May 21 08:20:51.375: INFO: namespace e2e-tests-projected-zcflq deletion completed in 6.073135071s

• [SLOW TEST:8.154 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:20:51.375: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:20:51.438: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:20:53.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-grt2d" for this suite.
May 21 08:21:31.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:21:31.612: INFO: namespace: e2e-tests-pods-grt2d, resource: bindings, ignored listing per whitelist
May 21 08:21:31.653: INFO: namespace e2e-tests-pods-grt2d deletion completed in 38.071285084s

• [SLOW TEST:40.278 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:21:31.654: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 21 08:21:31.694: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 08:21:31.698: INFO: Waiting for terminating namespaces to be deleted...
May 21 08:21:31.700: INFO: 
Logging pods the kubelet thinks is on node 192.168.5.21 before test
May 21 08:21:31.705: INFO: traefik-ingress-controller-tbxgz from kube-system started at 2019-05-21 04:31:34 +0000 UTC (1 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container traefik-ingress-lb ready: true, restart count 0
May 21 08:21:31.705: INFO: kube-flannel-4kgbz from kube-system started at 2019-05-21 04:30:34 +0000 UTC (2 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container install-cni ready: true, restart count 0
May 21 08:21:31.705: INFO: 	Container kube-flannel ready: true, restart count 1
May 21 08:21:31.705: INFO: kube-proxy-bqckm from kube-system started at 2019-05-21 04:30:34 +0000 UTC (1 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container kube-proxy ready: true, restart count 0
May 21 08:21:31.705: INFO: ksc-flexvolume-ds-tjvtw from kube-system started at 2019-05-21 04:30:34 +0000 UTC (1 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container ksc-flexvolume-ds ready: true, restart count 0
May 21 08:21:31.705: INFO: sonobuoy-e2e-job-cbf016e40c124e85 from heptio-sonobuoy started at 2019-05-21 06:58:22 +0000 UTC (2 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container e2e ready: true, restart count 0
May 21 08:21:31.705: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 08:21:31.705: INFO: sonobuoy-systemd-logs-daemon-set-55252047aa2d4aa6-ghxm4 from heptio-sonobuoy started at 2019-05-21 06:58:22 +0000 UTC (2 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 08:21:31.705: INFO: 	Container systemd-logs ready: true, restart count 1
May 21 08:21:31.705: INFO: cloud-controller-manager-86df4567b9-59nqv from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container cloud-controller-manager ready: true, restart count 0
May 21 08:21:31.705: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-21 06:58:08 +0000 UTC (1 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 08:21:31.705: INFO: metrics-server-5b9ff87b5f-rpq6w from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container metrics-server ready: true, restart count 0
May 21 08:21:31.705: INFO: disk-provisioner-5895cdc8b7-q64vs from kube-system started at 2019-05-21 04:30:58 +0000 UTC (1 container statuses recorded)
May 21 08:21:31.705: INFO: 	Container disk-provisioner ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7197cf88-7ba1-11e9-8b08-72649ad3cdd7 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-7197cf88-7ba1-11e9-8b08-72649ad3cdd7 off the node 192.168.5.21
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7197cf88-7ba1-11e9-8b08-72649ad3cdd7
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:21:35.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-w9jpv" for this suite.
May 21 08:21:43.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:21:43.820: INFO: namespace: e2e-tests-sched-pred-w9jpv, resource: bindings, ignored listing per whitelist
May 21 08:21:43.827: INFO: namespace e2e-tests-sched-pred-w9jpv deletion completed in 8.061658854s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.173 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:21:43.827: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:21:43.875: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
May 21 08:21:43.879: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qtt46/daemonsets","resourceVersion":"31386"},"items":null}

May 21 08:21:43.881: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qtt46/pods","resourceVersion":"31386"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:21:43.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qtt46" for this suite.
May 21 08:21:49.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:21:49.902: INFO: namespace: e2e-tests-daemonsets-qtt46, resource: bindings, ignored listing per whitelist
May 21 08:21:49.946: INFO: namespace e2e-tests-daemonsets-qtt46 deletion completed in 6.059165712s

S [SKIPPING] [6.119 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  May 21 08:21:43.875: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:21:49.946: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-ddwl
STEP: Creating a pod to test atomic-volume-subpath
May 21 08:21:49.993: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-ddwl" in namespace "e2e-tests-subpath-fg97x" to be "success or failure"
May 21 08:21:49.996: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.169327ms
May 21 08:21:52.001: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007455355s
May 21 08:21:54.004: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 4.010119127s
May 21 08:21:56.006: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 6.012847166s
May 21 08:21:58.009: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 8.015929155s
May 21 08:22:00.015: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 10.02195776s
May 21 08:22:02.022: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 12.028985899s
May 21 08:22:04.027: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 14.033693029s
May 21 08:22:06.031: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 16.037250283s
May 21 08:22:08.034: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 18.0409264s
May 21 08:22:10.037: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 20.043980997s
May 21 08:22:12.044: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Running", Reason="", readiness=false. Elapsed: 22.050182785s
May 21 08:22:14.046: INFO: Pod "pod-subpath-test-configmap-ddwl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.052853914s
STEP: Saw pod success
May 21 08:22:14.046: INFO: Pod "pod-subpath-test-configmap-ddwl" satisfied condition "success or failure"
May 21 08:22:14.048: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-configmap-ddwl container test-container-subpath-configmap-ddwl: <nil>
STEP: delete the pod
May 21 08:22:14.061: INFO: Waiting for pod pod-subpath-test-configmap-ddwl to disappear
May 21 08:22:14.063: INFO: Pod pod-subpath-test-configmap-ddwl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-ddwl
May 21 08:22:14.063: INFO: Deleting pod "pod-subpath-test-configmap-ddwl" in namespace "e2e-tests-subpath-fg97x"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:22:14.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fg97x" for this suite.
May 21 08:22:20.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:22:20.086: INFO: namespace: e2e-tests-subpath-fg97x, resource: bindings, ignored listing per whitelist
May 21 08:22:20.127: INFO: namespace e2e-tests-subpath-fg97x deletion completed in 6.059131587s

• [SLOW TEST:30.181 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:22:20.127: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 21 08:22:20.178: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zqdl8,SelfLink:/api/v1/namespaces/e2e-tests-watch-zqdl8/configmaps/e2e-watch-test-resource-version,UID:8d45a076-7ba1-11e9-926e-fa163e6dedea,ResourceVersion:31492,Generation:0,CreationTimestamp:2019-05-21 08:22:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 08:22:20.178: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zqdl8,SelfLink:/api/v1/namespaces/e2e-tests-watch-zqdl8/configmaps/e2e-watch-test-resource-version,UID:8d45a076-7ba1-11e9-926e-fa163e6dedea,ResourceVersion:31493,Generation:0,CreationTimestamp:2019-05-21 08:22:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:22:20.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zqdl8" for this suite.
May 21 08:22:26.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:22:26.261: INFO: namespace: e2e-tests-watch-zqdl8, resource: bindings, ignored listing per whitelist
May 21 08:22:26.261: INFO: namespace e2e-tests-watch-zqdl8 deletion completed in 6.078108734s

• [SLOW TEST:6.134 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:22:26.261: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 08:22:26.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90f55c0b-7ba1-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-downward-api-47bhk" to be "success or failure"
May 21 08:22:26.352: INFO: Pod "downwardapi-volume-90f55c0b-7ba1-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.516568ms
May 21 08:22:28.355: INFO: Pod "downwardapi-volume-90f55c0b-7ba1-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004099642s
STEP: Saw pod success
May 21 08:22:28.355: INFO: Pod "downwardapi-volume-90f55c0b-7ba1-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:22:28.356: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-90f55c0b-7ba1-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 08:22:28.368: INFO: Waiting for pod downwardapi-volume-90f55c0b-7ba1-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:22:28.371: INFO: Pod downwardapi-volume-90f55c0b-7ba1-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:22:28.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-47bhk" for this suite.
May 21 08:22:34.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:22:34.405: INFO: namespace: e2e-tests-downward-api-47bhk, resource: bindings, ignored listing per whitelist
May 21 08:22:34.452: INFO: namespace e2e-tests-downward-api-47bhk deletion completed in 6.078398437s

• [SLOW TEST:8.191 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:22:34.452: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
May 21 08:22:34.501: INFO: Waiting up to 5m0s for pod "var-expansion-95d0dc18-7ba1-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-var-expansion-rzbbq" to be "success or failure"
May 21 08:22:34.508: INFO: Pod "var-expansion-95d0dc18-7ba1-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.471271ms
May 21 08:22:36.512: INFO: Pod "var-expansion-95d0dc18-7ba1-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01076127s
STEP: Saw pod success
May 21 08:22:36.512: INFO: Pod "var-expansion-95d0dc18-7ba1-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:22:36.513: INFO: Trying to get logs from node 192.168.5.21 pod var-expansion-95d0dc18-7ba1-11e9-8b08-72649ad3cdd7 container dapi-container: <nil>
STEP: delete the pod
May 21 08:22:36.525: INFO: Waiting for pod var-expansion-95d0dc18-7ba1-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:22:36.527: INFO: Pod var-expansion-95d0dc18-7ba1-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:22:36.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rzbbq" for this suite.
May 21 08:22:42.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:22:42.587: INFO: namespace: e2e-tests-var-expansion-rzbbq, resource: bindings, ignored listing per whitelist
May 21 08:22:42.597: INFO: namespace e2e-tests-var-expansion-rzbbq deletion completed in 6.06734807s

• [SLOW TEST:8.145 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:22:42.597: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 21 08:22:44.653: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-9aab80ef-7ba1-11e9-8b08-72649ad3cdd7,GenerateName:,Namespace:e2e-tests-events-5g4zg,SelfLink:/api/v1/namespaces/e2e-tests-events-5g4zg/pods/send-events-9aab80ef-7ba1-11e9-8b08-72649ad3cdd7,UID:9aaaeba5-7ba1-11e9-926e-fa163e6dedea,ResourceVersion:31591,Generation:0,CreationTimestamp:2019-05-21 08:22:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 639294406,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-x5fmz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x5fmz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-x5fmz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:192.168.5.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 08:22:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 08:22:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 08:22:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-21 08:22:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.5.21,PodIP:10.8.3.72,StartTime:2019-05-21 08:22:42 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-21 08:22:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://a7e6751cf605ed3573f4a200ca5184a7ad83525a6bdd4aa3060e003baf41f80f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 21 08:22:46.656: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 21 08:22:48.659: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:22:48.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-5g4zg" for this suite.
May 21 08:23:26.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:23:26.723: INFO: namespace: e2e-tests-events-5g4zg, resource: bindings, ignored listing per whitelist
May 21 08:23:26.750: INFO: namespace e2e-tests-events-5g4zg deletion completed in 38.080108819s

• [SLOW TEST:44.153 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:23:26.751: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:23:26.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-151895369 version'
May 21 08:23:26.865: INFO: stderr: ""
May 21 08:23:26.865: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.4\", GitCommit:\"c27b913fddd1a6c480c229191a087698aa92f0b1\", GitTreeState:\"clean\", BuildDate:\"2019-02-28T13:30:26Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:23:26.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vrm66" for this suite.
May 21 08:23:32.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:23:32.903: INFO: namespace: e2e-tests-kubectl-vrm66, resource: bindings, ignored listing per whitelist
May 21 08:23:32.930: INFO: namespace e2e-tests-kubectl-vrm66 deletion completed in 6.062777541s

• [SLOW TEST:6.180 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:23:32.930: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 21 08:23:35.508: INFO: Successfully updated pod "annotationupdateb8ab664e-7ba1-11e9-8b08-72649ad3cdd7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:23:39.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bcjx7" for this suite.
May 21 08:24:01.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:24:01.586: INFO: namespace: e2e-tests-downward-api-bcjx7, resource: bindings, ignored listing per whitelist
May 21 08:24:01.603: INFO: namespace e2e-tests-downward-api-bcjx7 deletion completed in 22.064519719s

• [SLOW TEST:28.673 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:24:01.604: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mn42m
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
May 21 08:24:01.653: INFO: Found 0 stateful pods, waiting for 3
May 21 08:24:11.660: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 08:24:11.660: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 08:24:11.660: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 21 08:24:11.681: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 21 08:24:21.718: INFO: Updating stateful set ss2
May 21 08:24:21.722: INFO: Waiting for Pod e2e-tests-statefulset-mn42m/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 08:24:31.733: INFO: Waiting for Pod e2e-tests-statefulset-mn42m/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 21 08:24:41.783: INFO: Found 2 stateful pods, waiting for 3
May 21 08:24:51.790: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 08:24:51.790: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 08:24:51.790: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 21 08:24:51.809: INFO: Updating stateful set ss2
May 21 08:24:51.814: INFO: Waiting for Pod e2e-tests-statefulset-mn42m/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 08:25:01.822: INFO: Waiting for Pod e2e-tests-statefulset-mn42m/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 08:25:11.840: INFO: Updating stateful set ss2
May 21 08:25:11.846: INFO: Waiting for StatefulSet e2e-tests-statefulset-mn42m/ss2 to complete update
May 21 08:25:11.846: INFO: Waiting for Pod e2e-tests-statefulset-mn42m/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 21 08:25:21.854: INFO: Waiting for StatefulSet e2e-tests-statefulset-mn42m/ss2 to complete update
May 21 08:25:21.854: INFO: Waiting for Pod e2e-tests-statefulset-mn42m/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 21 08:25:31.854: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mn42m
May 21 08:25:31.856: INFO: Scaling statefulset ss2 to 0
May 21 08:25:51.869: INFO: Waiting for statefulset status.replicas updated to 0
May 21 08:25:51.871: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:25:51.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mn42m" for this suite.
May 21 08:25:57.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:25:57.905: INFO: namespace: e2e-tests-statefulset-mn42m, resource: bindings, ignored listing per whitelist
May 21 08:25:57.948: INFO: namespace e2e-tests-statefulset-mn42m deletion completed in 6.06359326s

• [SLOW TEST:116.345 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:25:57.949: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-0f1bf39b-7ba2-11e9-8b08-72649ad3cdd7
STEP: Creating secret with name s-test-opt-upd-0f1bf3f7-7ba2-11e9-8b08-72649ad3cdd7
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0f1bf39b-7ba2-11e9-8b08-72649ad3cdd7
STEP: Updating secret s-test-opt-upd-0f1bf3f7-7ba2-11e9-8b08-72649ad3cdd7
STEP: Creating secret with name s-test-opt-create-0f1bf40c-7ba2-11e9-8b08-72649ad3cdd7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:26:02.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fgblp" for this suite.
May 21 08:26:24.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:26:24.133: INFO: namespace: e2e-tests-projected-fgblp, resource: bindings, ignored listing per whitelist
May 21 08:26:24.136: INFO: namespace e2e-tests-projected-fgblp deletion completed in 22.078648298s

• [SLOW TEST:26.187 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:26:24.137: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-1eb78463-7ba2-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 08:26:24.191: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1eb800cc-7ba2-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-xk92h" to be "success or failure"
May 21 08:26:24.193: INFO: Pod "pod-projected-configmaps-1eb800cc-7ba2-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.940778ms
May 21 08:26:26.196: INFO: Pod "pod-projected-configmaps-1eb800cc-7ba2-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004614425s
STEP: Saw pod success
May 21 08:26:26.196: INFO: Pod "pod-projected-configmaps-1eb800cc-7ba2-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:26:26.197: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-1eb800cc-7ba2-11e9-8b08-72649ad3cdd7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 08:26:26.210: INFO: Waiting for pod pod-projected-configmaps-1eb800cc-7ba2-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:26:26.212: INFO: Pod pod-projected-configmaps-1eb800cc-7ba2-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:26:26.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xk92h" for this suite.
May 21 08:26:32.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:26:32.268: INFO: namespace: e2e-tests-projected-xk92h, resource: bindings, ignored listing per whitelist
May 21 08:26:32.274: INFO: namespace e2e-tests-projected-xk92h deletion completed in 6.05971313s

• [SLOW TEST:8.138 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:26:32.275: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:26:32.311: INFO: Creating ReplicaSet my-hostname-basic-2390c425-7ba2-11e9-8b08-72649ad3cdd7
May 21 08:26:32.319: INFO: Pod name my-hostname-basic-2390c425-7ba2-11e9-8b08-72649ad3cdd7: Found 0 pods out of 1
May 21 08:26:37.327: INFO: Pod name my-hostname-basic-2390c425-7ba2-11e9-8b08-72649ad3cdd7: Found 1 pods out of 1
May 21 08:26:37.327: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2390c425-7ba2-11e9-8b08-72649ad3cdd7" is running
May 21 08:26:37.329: INFO: Pod "my-hostname-basic-2390c425-7ba2-11e9-8b08-72649ad3cdd7-xj5zz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 08:26:32 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 08:26:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 08:26:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-21 08:26:32 +0000 UTC Reason: Message:}])
May 21 08:26:37.329: INFO: Trying to dial the pod
May 21 08:26:42.337: INFO: Controller my-hostname-basic-2390c425-7ba2-11e9-8b08-72649ad3cdd7: Got expected result from replica 1 [my-hostname-basic-2390c425-7ba2-11e9-8b08-72649ad3cdd7-xj5zz]: "my-hostname-basic-2390c425-7ba2-11e9-8b08-72649ad3cdd7-xj5zz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:26:42.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-wb592" for this suite.
May 21 08:26:48.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:26:48.387: INFO: namespace: e2e-tests-replicaset-wb592, resource: bindings, ignored listing per whitelist
May 21 08:26:48.408: INFO: namespace e2e-tests-replicaset-wb592 deletion completed in 6.067410898s

• [SLOW TEST:16.133 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:26:48.408: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:26:54.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-l8mdq" for this suite.
May 21 08:27:00.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:27:00.563: INFO: namespace: e2e-tests-namespaces-l8mdq, resource: bindings, ignored listing per whitelist
May 21 08:27:00.566: INFO: namespace e2e-tests-namespaces-l8mdq deletion completed in 6.063917689s
STEP: Destroying namespace "e2e-tests-nsdeletetest-mxpt2" for this suite.
May 21 08:27:00.567: INFO: Namespace e2e-tests-nsdeletetest-mxpt2 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-8kmkp" for this suite.
May 21 08:27:06.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:27:06.589: INFO: namespace: e2e-tests-nsdeletetest-8kmkp, resource: bindings, ignored listing per whitelist
May 21 08:27:06.627: INFO: namespace e2e-tests-nsdeletetest-8kmkp deletion completed in 6.060067878s

• [SLOW TEST:18.219 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:27:06.627: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 21 08:27:07.177: INFO: Waiting up to 5m0s for pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-96lhn" in namespace "e2e-tests-svcaccounts-mbfh8" to be "success or failure"
May 21 08:27:07.179: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-96lhn": Phase="Pending", Reason="", readiness=false. Elapsed: 1.627764ms
May 21 08:27:09.185: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-96lhn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008258116s
May 21 08:27:11.188: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-96lhn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011018119s
STEP: Saw pod success
May 21 08:27:11.188: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-96lhn" satisfied condition "success or failure"
May 21 08:27:11.190: INFO: Trying to get logs from node 192.168.5.21 pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-96lhn container token-test: <nil>
STEP: delete the pod
May 21 08:27:11.203: INFO: Waiting for pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-96lhn to disappear
May 21 08:27:11.205: INFO: Pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-96lhn no longer exists
STEP: Creating a pod to test consume service account root CA
May 21 08:27:11.208: INFO: Waiting up to 5m0s for pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-mbjgz" in namespace "e2e-tests-svcaccounts-mbfh8" to be "success or failure"
May 21 08:27:11.211: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-mbjgz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.049461ms
May 21 08:27:13.214: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-mbjgz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005982241s
STEP: Saw pod success
May 21 08:27:13.214: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-mbjgz" satisfied condition "success or failure"
May 21 08:27:13.216: INFO: Trying to get logs from node 192.168.5.21 pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-mbjgz container root-ca-test: <nil>
STEP: delete the pod
May 21 08:27:13.229: INFO: Waiting for pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-mbjgz to disappear
May 21 08:27:13.231: INFO: Pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-mbjgz no longer exists
STEP: Creating a pod to test consume service account namespace
May 21 08:27:13.235: INFO: Waiting up to 5m0s for pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-h4mzf" in namespace "e2e-tests-svcaccounts-mbfh8" to be "success or failure"
May 21 08:27:13.238: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-h4mzf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.913817ms
May 21 08:27:15.241: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-h4mzf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00551679s
STEP: Saw pod success
May 21 08:27:15.241: INFO: Pod "pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-h4mzf" satisfied condition "success or failure"
May 21 08:27:15.243: INFO: Trying to get logs from node 192.168.5.21 pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-h4mzf container namespace-test: <nil>
STEP: delete the pod
May 21 08:27:15.254: INFO: Waiting for pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-h4mzf to disappear
May 21 08:27:15.256: INFO: Pod pod-service-account-3857e9ec-7ba2-11e9-8b08-72649ad3cdd7-h4mzf no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:27:15.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-mbfh8" for this suite.
May 21 08:27:21.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:27:21.314: INFO: namespace: e2e-tests-svcaccounts-mbfh8, resource: bindings, ignored listing per whitelist
May 21 08:27:21.327: INFO: namespace e2e-tests-svcaccounts-mbfh8 deletion completed in 6.069489148s

• [SLOW TEST:14.700 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:27:21.328: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 21 08:27:23.388: INFO: Waiting up to 5m0s for pod "client-envvars-42019f0c-7ba2-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-pods-hcbct" to be "success or failure"
May 21 08:27:23.390: INFO: Pod "client-envvars-42019f0c-7ba2-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.652463ms
May 21 08:27:25.393: INFO: Pod "client-envvars-42019f0c-7ba2-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0053048s
STEP: Saw pod success
May 21 08:27:25.393: INFO: Pod "client-envvars-42019f0c-7ba2-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:27:25.395: INFO: Trying to get logs from node 192.168.5.21 pod client-envvars-42019f0c-7ba2-11e9-8b08-72649ad3cdd7 container env3cont: <nil>
STEP: delete the pod
May 21 08:27:25.406: INFO: Waiting for pod client-envvars-42019f0c-7ba2-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:27:25.408: INFO: Pod client-envvars-42019f0c-7ba2-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:27:25.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hcbct" for this suite.
May 21 08:28:05.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:28:05.469: INFO: namespace: e2e-tests-pods-hcbct, resource: bindings, ignored listing per whitelist
May 21 08:28:05.475: INFO: namespace e2e-tests-pods-hcbct deletion completed in 40.065470767s

• [SLOW TEST:44.148 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:28:05.476: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-5b1fa4fc-7ba2-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 08:28:05.530: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5b202484-7ba2-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-fm2ng" to be "success or failure"
May 21 08:28:05.532: INFO: Pod "pod-projected-secrets-5b202484-7ba2-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.170052ms
May 21 08:28:07.535: INFO: Pod "pod-projected-secrets-5b202484-7ba2-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005103125s
STEP: Saw pod success
May 21 08:28:07.535: INFO: Pod "pod-projected-secrets-5b202484-7ba2-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:28:07.537: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-secrets-5b202484-7ba2-11e9-8b08-72649ad3cdd7 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 08:28:07.550: INFO: Waiting for pod pod-projected-secrets-5b202484-7ba2-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:28:07.551: INFO: Pod pod-projected-secrets-5b202484-7ba2-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:28:07.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fm2ng" for this suite.
May 21 08:28:13.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:28:13.585: INFO: namespace: e2e-tests-projected-fm2ng, resource: bindings, ignored listing per whitelist
May 21 08:28:13.610: INFO: namespace e2e-tests-projected-fm2ng deletion completed in 6.056153485s

• [SLOW TEST:8.134 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:28:13.610: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5ff78d5e-7ba2-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume secrets
May 21 08:28:13.680: INFO: Waiting up to 5m0s for pod "pod-secrets-5ffb917d-7ba2-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-secrets-n8qm6" to be "success or failure"
May 21 08:28:13.683: INFO: Pod "pod-secrets-5ffb917d-7ba2-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.868881ms
May 21 08:28:15.688: INFO: Pod "pod-secrets-5ffb917d-7ba2-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008162755s
STEP: Saw pod success
May 21 08:28:15.688: INFO: Pod "pod-secrets-5ffb917d-7ba2-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:28:15.690: INFO: Trying to get logs from node 192.168.5.21 pod pod-secrets-5ffb917d-7ba2-11e9-8b08-72649ad3cdd7 container secret-volume-test: <nil>
STEP: delete the pod
May 21 08:28:15.703: INFO: Waiting for pod pod-secrets-5ffb917d-7ba2-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:28:15.704: INFO: Pod pod-secrets-5ffb917d-7ba2-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:28:15.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n8qm6" for this suite.
May 21 08:28:21.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:28:21.747: INFO: namespace: e2e-tests-secrets-n8qm6, resource: bindings, ignored listing per whitelist
May 21 08:28:21.774: INFO: namespace e2e-tests-secrets-n8qm6 deletion completed in 6.064052789s
STEP: Destroying namespace "e2e-tests-secret-namespace-ktdbf" for this suite.
May 21 08:28:27.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:28:27.804: INFO: namespace: e2e-tests-secret-namespace-ktdbf, resource: bindings, ignored listing per whitelist
May 21 08:28:27.835: INFO: namespace e2e-tests-secret-namespace-ktdbf deletion completed in 6.060811787s

• [SLOW TEST:14.225 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:28:27.835: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 21 08:28:27.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6873da5d-7ba2-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-hk4jr" to be "success or failure"
May 21 08:28:27.894: INFO: Pod "downwardapi-volume-6873da5d-7ba2-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.656504ms
May 21 08:28:29.898: INFO: Pod "downwardapi-volume-6873da5d-7ba2-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006772676s
STEP: Saw pod success
May 21 08:28:29.898: INFO: Pod "downwardapi-volume-6873da5d-7ba2-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:28:29.899: INFO: Trying to get logs from node 192.168.5.21 pod downwardapi-volume-6873da5d-7ba2-11e9-8b08-72649ad3cdd7 container client-container: <nil>
STEP: delete the pod
May 21 08:28:29.913: INFO: Waiting for pod downwardapi-volume-6873da5d-7ba2-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:28:29.914: INFO: Pod downwardapi-volume-6873da5d-7ba2-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:28:29.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hk4jr" for this suite.
May 21 08:28:35.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:28:36.035: INFO: namespace: e2e-tests-projected-hk4jr, resource: bindings, ignored listing per whitelist
May 21 08:28:36.112: INFO: namespace e2e-tests-projected-hk4jr deletion completed in 6.195457495s

• [SLOW TEST:8.277 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:28:36.113: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6d611c52-7ba2-11e9-8b08-72649ad3cdd7
STEP: Creating a pod to test consume configMaps
May 21 08:28:36.157: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6d619360-7ba2-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-projected-km7pk" to be "success or failure"
May 21 08:28:36.161: INFO: Pod "pod-projected-configmaps-6d619360-7ba2-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.118039ms
May 21 08:28:38.163: INFO: Pod "pod-projected-configmaps-6d619360-7ba2-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00558616s
STEP: Saw pod success
May 21 08:28:38.163: INFO: Pod "pod-projected-configmaps-6d619360-7ba2-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:28:38.165: INFO: Trying to get logs from node 192.168.5.21 pod pod-projected-configmaps-6d619360-7ba2-11e9-8b08-72649ad3cdd7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 08:28:38.177: INFO: Waiting for pod pod-projected-configmaps-6d619360-7ba2-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:28:38.179: INFO: Pod pod-projected-configmaps-6d619360-7ba2-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:28:38.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-km7pk" for this suite.
May 21 08:28:44.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:28:44.195: INFO: namespace: e2e-tests-projected-km7pk, resource: bindings, ignored listing per whitelist
May 21 08:28:44.240: INFO: namespace e2e-tests-projected-km7pk deletion completed in 6.058695632s

• [SLOW TEST:8.127 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:28:44.240: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-dbmf
STEP: Creating a pod to test atomic-volume-subpath
May 21 08:28:44.288: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-dbmf" in namespace "e2e-tests-subpath-4mwvt" to be "success or failure"
May 21 08:28:44.292: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.173557ms
May 21 08:28:46.297: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008544138s
May 21 08:28:48.300: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 4.011117218s
May 21 08:28:50.303: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 6.014646928s
May 21 08:28:52.306: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 8.018000816s
May 21 08:28:54.309: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 10.020530717s
May 21 08:28:56.314: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 12.025869987s
May 21 08:28:58.317: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 14.028801405s
May 21 08:29:00.321: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 16.032150763s
May 21 08:29:02.323: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 18.034872288s
May 21 08:29:04.326: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 20.037878988s
May 21 08:29:06.332: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Running", Reason="", readiness=false. Elapsed: 22.043695756s
May 21 08:29:08.335: INFO: Pod "pod-subpath-test-secret-dbmf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046624772s
STEP: Saw pod success
May 21 08:29:08.335: INFO: Pod "pod-subpath-test-secret-dbmf" satisfied condition "success or failure"
May 21 08:29:08.337: INFO: Trying to get logs from node 192.168.5.21 pod pod-subpath-test-secret-dbmf container test-container-subpath-secret-dbmf: <nil>
STEP: delete the pod
May 21 08:29:08.353: INFO: Waiting for pod pod-subpath-test-secret-dbmf to disappear
May 21 08:29:08.355: INFO: Pod pod-subpath-test-secret-dbmf no longer exists
STEP: Deleting pod pod-subpath-test-secret-dbmf
May 21 08:29:08.355: INFO: Deleting pod "pod-subpath-test-secret-dbmf" in namespace "e2e-tests-subpath-4mwvt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:29:08.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4mwvt" for this suite.
May 21 08:29:14.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:29:14.411: INFO: namespace: e2e-tests-subpath-4mwvt, resource: bindings, ignored listing per whitelist
May 21 08:29:14.442: INFO: namespace e2e-tests-subpath-4mwvt deletion completed in 6.082487414s

• [SLOW TEST:30.202 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 21 08:29:14.442: INFO: >>> kubeConfig: /tmp/kubeconfig-151895369
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 08:29:14.489: INFO: Waiting up to 5m0s for pod "pod-843a3708-7ba2-11e9-8b08-72649ad3cdd7" in namespace "e2e-tests-emptydir-7gfwk" to be "success or failure"
May 21 08:29:14.491: INFO: Pod "pod-843a3708-7ba2-11e9-8b08-72649ad3cdd7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.704479ms
May 21 08:29:16.497: INFO: Pod "pod-843a3708-7ba2-11e9-8b08-72649ad3cdd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007982065s
STEP: Saw pod success
May 21 08:29:16.497: INFO: Pod "pod-843a3708-7ba2-11e9-8b08-72649ad3cdd7" satisfied condition "success or failure"
May 21 08:29:16.499: INFO: Trying to get logs from node 192.168.5.21 pod pod-843a3708-7ba2-11e9-8b08-72649ad3cdd7 container test-container: <nil>
STEP: delete the pod
May 21 08:29:16.514: INFO: Waiting for pod pod-843a3708-7ba2-11e9-8b08-72649ad3cdd7 to disappear
May 21 08:29:16.517: INFO: Pod pod-843a3708-7ba2-11e9-8b08-72649ad3cdd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 21 08:29:16.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7gfwk" for this suite.
May 21 08:29:22.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 08:29:22.538: INFO: namespace: e2e-tests-emptydir-7gfwk, resource: bindings, ignored listing per whitelist
May 21 08:29:22.584: INFO: namespace e2e-tests-emptydir-7gfwk deletion completed in 6.063178191s

• [SLOW TEST:8.142 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
May 21 08:29:22.584: INFO: Running AfterSuite actions on all nodes
May 21 08:29:22.584: INFO: Running AfterSuite actions on node 1
May 21 08:29:22.584: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5400.971 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h30m1.783485037s
Test Suite Passed
