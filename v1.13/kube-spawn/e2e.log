I0204 18:19:23.798838      19 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-030580780
I0204 18:19:23.798900      19 e2e.go:224] Starting e2e run "65c6815a-28a9-11e9-8d1f-5e319961b721" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1549304363 - Will randomize all specs
Will run 201 of 1946 specs

Feb  4 18:19:23.905: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 18:19:23.908: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  4 18:19:39.522: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  4 18:19:39.607: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  4 18:19:39.607: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Feb  4 18:19:39.607: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  4 18:19:39.614: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Feb  4 18:19:39.614: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Feb  4 18:19:39.614: INFO: e2e test version: v1.13.0
Feb  4 18:19:39.615: INFO: kube-apiserver version: v1.13.3
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:19:39.615: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
Feb  4 18:19:39.906: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6fa59413-28a9-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 18:19:39.959: INFO: Waiting up to 5m0s for pod "pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-5vt77" to be "success or failure"
Feb  4 18:19:40.015: INFO: Pod "pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 55.634666ms
Feb  4 18:19:42.023: INFO: Pod "pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06337083s
Feb  4 18:19:44.033: INFO: Pod "pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072947448s
Feb  4 18:19:46.039: INFO: Pod "pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.079738098s
STEP: Saw pod success
Feb  4 18:19:46.040: INFO: Pod "pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:19:46.047: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721 container secret-volume-test: <nil>
STEP: delete the pod
Feb  4 18:19:46.153: INFO: Waiting for pod pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:19:46.159: INFO: Pod pod-secrets-6fa7b2bc-28a9-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:19:46.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5vt77" for this suite.
Feb  4 18:19:52.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:19:52.313: INFO: namespace: e2e-tests-secrets-5vt77, resource: bindings, ignored listing per whitelist
Feb  4 18:19:52.485: INFO: namespace e2e-tests-secrets-5vt77 deletion completed in 6.322761863s

• [SLOW TEST:12.873 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:19:52.488: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  4 18:19:52.796: INFO: Waiting up to 5m0s for pod "downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-6vtc7" to be "success or failure"
Feb  4 18:19:52.800: INFO: Pod "downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 3.636516ms
Feb  4 18:19:54.819: INFO: Pod "downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022176934s
Feb  4 18:19:56.830: INFO: Pod "downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033404134s
Feb  4 18:19:58.839: INFO: Pod "downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.042577845s
STEP: Saw pod success
Feb  4 18:19:58.839: INFO: Pod "downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:19:58.851: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721 container dapi-container: <nil>
STEP: delete the pod
Feb  4 18:19:58.962: INFO: Waiting for pod downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:19:58.973: INFO: Pod downward-api-774d3c1f-28a9-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:19:58.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6vtc7" for this suite.
Feb  4 18:20:05.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:20:05.177: INFO: namespace: e2e-tests-downward-api-6vtc7, resource: bindings, ignored listing per whitelist
Feb  4 18:20:05.224: INFO: namespace e2e-tests-downward-api-6vtc7 deletion completed in 6.248275048s

• [SLOW TEST:12.736 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:20:05.225: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:21:05.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-26nvh" for this suite.
Feb  4 18:21:21.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:21:21.660: INFO: namespace: e2e-tests-container-probe-26nvh, resource: bindings, ignored listing per whitelist
Feb  4 18:21:21.660: INFO: namespace e2e-tests-container-probe-26nvh deletion completed in 16.207775543s

• [SLOW TEST:76.436 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:21:21.661: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  4 18:21:30.456: INFO: Successfully updated pod "pod-update-ac55e8ba-28a9-11e9-8d1f-5e319961b721"
STEP: verifying the updated pod is in kubernetes
Feb  4 18:21:30.510: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:21:30.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5ffvt" for this suite.
Feb  4 18:21:52.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:21:52.682: INFO: namespace: e2e-tests-pods-5ffvt, resource: bindings, ignored listing per whitelist
Feb  4 18:21:52.682: INFO: namespace e2e-tests-pods-5ffvt deletion completed in 22.12073113s

• [SLOW TEST:31.021 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:21:52.682: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb  4 18:21:52.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-q8j96'
Feb  4 18:21:53.777: INFO: stderr: ""
Feb  4 18:21:53.777: INFO: stdout: "pod/pause created\n"
Feb  4 18:21:53.777: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  4 18:21:53.777: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-q8j96" to be "running and ready"
Feb  4 18:21:53.800: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 23.291642ms
Feb  4 18:21:55.811: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034127638s
Feb  4 18:21:57.823: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.045914011s
Feb  4 18:21:57.823: INFO: Pod "pause" satisfied condition "running and ready"
Feb  4 18:21:57.823: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  4 18:21:57.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-q8j96'
Feb  4 18:21:57.976: INFO: stderr: ""
Feb  4 18:21:57.976: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  4 18:21:57.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pod pause -L testing-label --namespace=e2e-tests-kubectl-q8j96'
Feb  4 18:21:58.039: INFO: stderr: ""
Feb  4 18:21:58.039: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  4 18:21:58.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 label pods pause testing-label- --namespace=e2e-tests-kubectl-q8j96'
Feb  4 18:21:58.108: INFO: stderr: ""
Feb  4 18:21:58.108: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  4 18:21:58.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pod pause -L testing-label --namespace=e2e-tests-kubectl-q8j96'
Feb  4 18:21:58.170: INFO: stderr: ""
Feb  4 18:21:58.170: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb  4 18:21:58.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-q8j96'
Feb  4 18:21:58.333: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 18:21:58.333: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  4 18:21:58.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-q8j96'
Feb  4 18:21:58.450: INFO: stderr: "No resources found.\n"
Feb  4 18:21:58.450: INFO: stdout: ""
Feb  4 18:21:58.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -l name=pause --namespace=e2e-tests-kubectl-q8j96 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  4 18:21:58.531: INFO: stderr: ""
Feb  4 18:21:58.532: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:21:58.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q8j96" for this suite.
Feb  4 18:22:04.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:22:04.777: INFO: namespace: e2e-tests-kubectl-q8j96, resource: bindings, ignored listing per whitelist
Feb  4 18:22:04.870: INFO: namespace e2e-tests-kubectl-q8j96 deletion completed in 6.311018252s

• [SLOW TEST:12.189 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:22:04.871: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  4 18:22:04.974: INFO: Waiting up to 5m0s for pod "pod-c619c3ea-28a9-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-mshj8" to be "success or failure"
Feb  4 18:22:04.983: INFO: Pod "pod-c619c3ea-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 8.782774ms
Feb  4 18:22:06.991: INFO: Pod "pod-c619c3ea-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017393634s
Feb  4 18:22:08.999: INFO: Pod "pod-c619c3ea-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025137679s
Feb  4 18:22:11.011: INFO: Pod "pod-c619c3ea-28a9-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.037384955s
STEP: Saw pod success
Feb  4 18:22:11.011: INFO: Pod "pod-c619c3ea-28a9-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:22:11.019: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-c619c3ea-28a9-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:22:11.123: INFO: Waiting for pod pod-c619c3ea-28a9-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:22:11.144: INFO: Pod pod-c619c3ea-28a9-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:22:11.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mshj8" for this suite.
Feb  4 18:22:17.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:22:17.184: INFO: namespace: e2e-tests-emptydir-mshj8, resource: bindings, ignored listing per whitelist
Feb  4 18:22:17.307: INFO: namespace e2e-tests-emptydir-mshj8 deletion completed in 6.159294285s

• [SLOW TEST:12.436 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:22:17.307: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:22:17.492: INFO: Creating ReplicaSet my-hostname-basic-cd90eef1-28a9-11e9-8d1f-5e319961b721
Feb  4 18:22:17.632: INFO: Pod name my-hostname-basic-cd90eef1-28a9-11e9-8d1f-5e319961b721: Found 0 pods out of 1
Feb  4 18:22:22.724: INFO: Pod name my-hostname-basic-cd90eef1-28a9-11e9-8d1f-5e319961b721: Found 1 pods out of 1
Feb  4 18:22:22.725: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-cd90eef1-28a9-11e9-8d1f-5e319961b721" is running
Feb  4 18:22:22.750: INFO: Pod "my-hostname-basic-cd90eef1-28a9-11e9-8d1f-5e319961b721-rz2s5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-04 18:22:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-04 18:22:21 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-04 18:22:21 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-04 18:22:17 +0000 UTC Reason: Message:}])
Feb  4 18:22:22.750: INFO: Trying to dial the pod
Feb  4 18:22:27.785: INFO: Controller my-hostname-basic-cd90eef1-28a9-11e9-8d1f-5e319961b721: Got expected result from replica 1 [my-hostname-basic-cd90eef1-28a9-11e9-8d1f-5e319961b721-rz2s5]: "my-hostname-basic-cd90eef1-28a9-11e9-8d1f-5e319961b721-rz2s5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:22:27.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-8x7sz" for this suite.
Feb  4 18:22:33.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:22:33.969: INFO: namespace: e2e-tests-replicaset-8x7sz, resource: bindings, ignored listing per whitelist
Feb  4 18:22:34.042: INFO: namespace e2e-tests-replicaset-8x7sz deletion completed in 6.244323068s

• [SLOW TEST:16.735 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:22:34.045: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb  4 18:22:34.180: INFO: Waiting up to 5m0s for pod "client-containers-d7808395-28a9-11e9-8d1f-5e319961b721" in namespace "e2e-tests-containers-c2nmm" to be "success or failure"
Feb  4 18:22:34.237: INFO: Pod "client-containers-d7808395-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 57.440474ms
Feb  4 18:22:36.245: INFO: Pod "client-containers-d7808395-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065167291s
Feb  4 18:22:38.254: INFO: Pod "client-containers-d7808395-28a9-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 4.074526784s
Feb  4 18:22:40.278: INFO: Pod "client-containers-d7808395-28a9-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.098668185s
STEP: Saw pod success
Feb  4 18:22:40.278: INFO: Pod "client-containers-d7808395-28a9-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:22:40.299: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod client-containers-d7808395-28a9-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:22:40.368: INFO: Waiting for pod client-containers-d7808395-28a9-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:22:40.376: INFO: Pod client-containers-d7808395-28a9-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:22:40.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-c2nmm" for this suite.
Feb  4 18:22:46.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:22:46.506: INFO: namespace: e2e-tests-containers-c2nmm, resource: bindings, ignored listing per whitelist
Feb  4 18:22:46.513: INFO: namespace e2e-tests-containers-c2nmm deletion completed in 6.133397075s

• [SLOW TEST:12.468 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:22:46.513: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  4 18:22:46.717: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:46.720: INFO: Number of nodes with available pods: 0
Feb  4 18:22:46.720: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:47.723: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:47.728: INFO: Number of nodes with available pods: 0
Feb  4 18:22:47.728: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:48.722: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:48.725: INFO: Number of nodes with available pods: 1
Feb  4 18:22:48.725: INFO: Node kube-spawn-default-worker-pqanhr is running more than one daemon pod
Feb  4 18:22:49.741: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:49.762: INFO: Number of nodes with available pods: 1
Feb  4 18:22:49.762: INFO: Node kube-spawn-default-worker-pqanhr is running more than one daemon pod
Feb  4 18:22:50.729: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:50.734: INFO: Number of nodes with available pods: 1
Feb  4 18:22:50.734: INFO: Node kube-spawn-default-worker-pqanhr is running more than one daemon pod
Feb  4 18:22:51.729: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:51.743: INFO: Number of nodes with available pods: 1
Feb  4 18:22:51.744: INFO: Node kube-spawn-default-worker-pqanhr is running more than one daemon pod
Feb  4 18:22:52.734: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:52.740: INFO: Number of nodes with available pods: 2
Feb  4 18:22:52.740: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  4 18:22:52.776: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:52.780: INFO: Number of nodes with available pods: 1
Feb  4 18:22:52.780: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:53.788: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:53.801: INFO: Number of nodes with available pods: 1
Feb  4 18:22:53.801: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:54.785: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:54.787: INFO: Number of nodes with available pods: 1
Feb  4 18:22:54.787: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:55.809: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:55.822: INFO: Number of nodes with available pods: 1
Feb  4 18:22:55.822: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:56.782: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:56.785: INFO: Number of nodes with available pods: 1
Feb  4 18:22:56.785: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:57.789: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:57.798: INFO: Number of nodes with available pods: 1
Feb  4 18:22:57.799: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:58.783: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:58.785: INFO: Number of nodes with available pods: 1
Feb  4 18:22:58.785: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:22:59.796: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:22:59.804: INFO: Number of nodes with available pods: 1
Feb  4 18:22:59.804: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:00.785: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:00.790: INFO: Number of nodes with available pods: 1
Feb  4 18:23:00.790: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:01.791: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:01.794: INFO: Number of nodes with available pods: 1
Feb  4 18:23:01.794: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:02.789: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:02.806: INFO: Number of nodes with available pods: 1
Feb  4 18:23:02.806: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:03.788: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:03.796: INFO: Number of nodes with available pods: 1
Feb  4 18:23:03.796: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:04.813: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:04.881: INFO: Number of nodes with available pods: 1
Feb  4 18:23:04.881: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:05.783: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:05.787: INFO: Number of nodes with available pods: 1
Feb  4 18:23:05.787: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:06.791: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:06.804: INFO: Number of nodes with available pods: 1
Feb  4 18:23:06.804: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:07.788: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:07.799: INFO: Number of nodes with available pods: 1
Feb  4 18:23:07.799: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:08.782: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:08.787: INFO: Number of nodes with available pods: 1
Feb  4 18:23:08.787: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:09.792: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:09.797: INFO: Number of nodes with available pods: 1
Feb  4 18:23:09.797: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:10.794: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:10.804: INFO: Number of nodes with available pods: 1
Feb  4 18:23:10.805: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:11.791: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:11.817: INFO: Number of nodes with available pods: 1
Feb  4 18:23:11.830: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:12.793: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:12.817: INFO: Number of nodes with available pods: 1
Feb  4 18:23:12.817: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:13.793: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:13.807: INFO: Number of nodes with available pods: 1
Feb  4 18:23:13.808: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:14.824: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:14.827: INFO: Number of nodes with available pods: 1
Feb  4 18:23:14.827: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:15.791: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:15.803: INFO: Number of nodes with available pods: 1
Feb  4 18:23:15.804: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:16.782: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:16.785: INFO: Number of nodes with available pods: 1
Feb  4 18:23:16.785: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:17.798: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:17.810: INFO: Number of nodes with available pods: 1
Feb  4 18:23:17.811: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:18.789: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:18.814: INFO: Number of nodes with available pods: 1
Feb  4 18:23:18.815: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:19.791: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:19.807: INFO: Number of nodes with available pods: 1
Feb  4 18:23:19.811: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:20.802: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:20.808: INFO: Number of nodes with available pods: 1
Feb  4 18:23:20.808: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:21.787: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:21.798: INFO: Number of nodes with available pods: 1
Feb  4 18:23:21.798: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:22.782: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:22.787: INFO: Number of nodes with available pods: 1
Feb  4 18:23:22.787: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:23.795: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:23.799: INFO: Number of nodes with available pods: 1
Feb  4 18:23:23.799: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:24.860: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:24.868: INFO: Number of nodes with available pods: 1
Feb  4 18:23:24.868: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:25.784: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:25.788: INFO: Number of nodes with available pods: 1
Feb  4 18:23:25.788: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:26.783: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:26.787: INFO: Number of nodes with available pods: 1
Feb  4 18:23:26.787: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:23:27.793: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:23:27.828: INFO: Number of nodes with available pods: 2
Feb  4 18:23:27.828: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-r52lw, will wait for the garbage collector to delete the pods
Feb  4 18:23:27.906: INFO: Deleting DaemonSet.extensions daemon-set took: 5.455256ms
Feb  4 18:23:28.006: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.319507ms
Feb  4 18:24:01.010: INFO: Number of nodes with available pods: 0
Feb  4 18:24:01.010: INFO: Number of running nodes: 0, number of available pods: 0
Feb  4 18:24:01.026: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r52lw/daemonsets","resourceVersion":"1536"},"items":null}

Feb  4 18:24:01.061: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r52lw/pods","resourceVersion":"1536"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:24:01.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r52lw" for this suite.
Feb  4 18:24:07.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:24:07.231: INFO: namespace: e2e-tests-daemonsets-r52lw, resource: bindings, ignored listing per whitelist
Feb  4 18:24:07.267: INFO: namespace e2e-tests-daemonsets-r52lw deletion completed in 6.176745192s

• [SLOW TEST:80.754 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:24:07.267: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:24:07.601: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"0f2acb33-28aa-11e9-88b2-2600a3ceccc4", Controller:(*bool)(0xc000d2f56e), BlockOwnerDeletion:(*bool)(0xc000d2f56f)}}
Feb  4 18:24:07.612: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0f201308-28aa-11e9-88b2-2600a3ceccc4", Controller:(*bool)(0xc000f23e06), BlockOwnerDeletion:(*bool)(0xc000f23e07)}}
Feb  4 18:24:07.634: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"0f262adb-28aa-11e9-88b2-2600a3ceccc4", Controller:(*bool)(0xc000d2f7ea), BlockOwnerDeletion:(*bool)(0xc000d2f7eb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:24:12.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cnk4f" for this suite.
Feb  4 18:24:18.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:24:18.788: INFO: namespace: e2e-tests-gc-cnk4f, resource: bindings, ignored listing per whitelist
Feb  4 18:24:18.916: INFO: namespace e2e-tests-gc-cnk4f deletion completed in 6.230495915s

• [SLOW TEST:11.649 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:24:18.917: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  4 18:24:19.136: INFO: Waiting up to 5m0s for pod "pod-1609aac5-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-95zfk" to be "success or failure"
Feb  4 18:24:19.197: INFO: Pod "pod-1609aac5-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 60.738813ms
Feb  4 18:24:21.201: INFO: Pod "pod-1609aac5-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065322938s
Feb  4 18:24:23.209: INFO: Pod "pod-1609aac5-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072826344s
Feb  4 18:24:25.214: INFO: Pod "pod-1609aac5-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.078414228s
STEP: Saw pod success
Feb  4 18:24:25.214: INFO: Pod "pod-1609aac5-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:24:25.225: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-1609aac5-28aa-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:24:25.366: INFO: Waiting for pod pod-1609aac5-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:24:25.378: INFO: Pod pod-1609aac5-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:24:25.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-95zfk" for this suite.
Feb  4 18:24:31.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:24:31.566: INFO: namespace: e2e-tests-emptydir-95zfk, resource: bindings, ignored listing per whitelist
Feb  4 18:24:31.602: INFO: namespace e2e-tests-emptydir-95zfk deletion completed in 6.205577636s

• [SLOW TEST:12.685 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:24:31.602: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 18:24:31.675: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d8a8f26-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-mtzxd" to be "success or failure"
Feb  4 18:24:31.684: INFO: Pod "downwardapi-volume-1d8a8f26-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 9.080447ms
Feb  4 18:24:33.691: INFO: Pod "downwardapi-volume-1d8a8f26-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016057697s
Feb  4 18:24:35.697: INFO: Pod "downwardapi-volume-1d8a8f26-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022507198s
STEP: Saw pod success
Feb  4 18:24:35.697: INFO: Pod "downwardapi-volume-1d8a8f26-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:24:35.712: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-1d8a8f26-28aa-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 18:24:35.845: INFO: Waiting for pod downwardapi-volume-1d8a8f26-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:24:35.852: INFO: Pod downwardapi-volume-1d8a8f26-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:24:35.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mtzxd" for this suite.
Feb  4 18:24:41.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:24:41.965: INFO: namespace: e2e-tests-projected-mtzxd, resource: bindings, ignored listing per whitelist
Feb  4 18:24:42.055: INFO: namespace e2e-tests-projected-mtzxd deletion completed in 6.170023813s

• [SLOW TEST:10.454 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:24:42.056: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 18:24:42.292: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23d4f042-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-svvsm" to be "success or failure"
Feb  4 18:24:42.332: INFO: Pod "downwardapi-volume-23d4f042-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 39.0797ms
Feb  4 18:24:44.350: INFO: Pod "downwardapi-volume-23d4f042-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.057836309s
STEP: Saw pod success
Feb  4 18:24:44.351: INFO: Pod "downwardapi-volume-23d4f042-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:24:44.358: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-23d4f042-28aa-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 18:24:44.391: INFO: Waiting for pod downwardapi-volume-23d4f042-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:24:44.414: INFO: Pod downwardapi-volume-23d4f042-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:24:44.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-svvsm" for this suite.
Feb  4 18:24:50.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:24:50.654: INFO: namespace: e2e-tests-downward-api-svvsm, resource: bindings, ignored listing per whitelist
Feb  4 18:24:50.663: INFO: namespace e2e-tests-downward-api-svvsm deletion completed in 6.245559139s

• [SLOW TEST:8.607 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:24:50.665: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-28eee6b9-28aa-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 18:24:50.832: INFO: Waiting up to 5m0s for pod "pod-secrets-28f4389c-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-p7t48" to be "success or failure"
Feb  4 18:24:50.850: INFO: Pod "pod-secrets-28f4389c-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 17.563729ms
Feb  4 18:24:52.855: INFO: Pod "pod-secrets-28f4389c-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022798762s
STEP: Saw pod success
Feb  4 18:24:52.855: INFO: Pod "pod-secrets-28f4389c-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:24:52.857: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-secrets-28f4389c-28aa-11e9-8d1f-5e319961b721 container secret-volume-test: <nil>
STEP: delete the pod
Feb  4 18:24:52.889: INFO: Waiting for pod pod-secrets-28f4389c-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:24:52.911: INFO: Pod pod-secrets-28f4389c-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:24:52.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-p7t48" for this suite.
Feb  4 18:24:59.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:24:59.178: INFO: namespace: e2e-tests-secrets-p7t48, resource: bindings, ignored listing per whitelist
Feb  4 18:24:59.180: INFO: namespace e2e-tests-secrets-p7t48 deletion completed in 6.265574173s

• [SLOW TEST:8.515 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:24:59.180: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-rs6pr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rs6pr to expose endpoints map[]
Feb  4 18:24:59.344: INFO: Get endpoints failed (24.436622ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb  4 18:25:00.368: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rs6pr exposes endpoints map[] (1.048511246s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rs6pr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rs6pr to expose endpoints map[pod1:[100]]
Feb  4 18:25:03.571: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rs6pr exposes endpoints map[pod1:[100]] (3.16355109s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rs6pr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rs6pr to expose endpoints map[pod1:[100] pod2:[101]]
Feb  4 18:25:05.732: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rs6pr exposes endpoints map[pod1:[100] pod2:[101]] (2.119506165s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rs6pr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rs6pr to expose endpoints map[pod2:[101]]
Feb  4 18:25:05.825: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rs6pr exposes endpoints map[pod2:[101]] (61.888189ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rs6pr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rs6pr to expose endpoints map[]
Feb  4 18:25:05.852: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rs6pr exposes endpoints map[] (12.99062ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:25:05.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rs6pr" for this suite.
Feb  4 18:25:12.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:25:12.279: INFO: namespace: e2e-tests-services-rs6pr, resource: bindings, ignored listing per whitelist
Feb  4 18:25:12.279: INFO: namespace e2e-tests-services-rs6pr deletion completed in 6.287915171s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.099 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:25:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:25:12.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7j6m2" for this suite.
Feb  4 18:25:18.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:25:18.466: INFO: namespace: e2e-tests-services-7j6m2, resource: bindings, ignored listing per whitelist
Feb  4 18:25:18.711: INFO: namespace e2e-tests-services-7j6m2 deletion completed in 6.327159665s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.431 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:25:18.712: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 18:25:18.907: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39aa4cb5-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-bzsrq" to be "success or failure"
Feb  4 18:25:18.921: INFO: Pod "downwardapi-volume-39aa4cb5-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 14.327029ms
Feb  4 18:25:20.924: INFO: Pod "downwardapi-volume-39aa4cb5-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016992952s
STEP: Saw pod success
Feb  4 18:25:20.924: INFO: Pod "downwardapi-volume-39aa4cb5-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:25:20.926: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod downwardapi-volume-39aa4cb5-28aa-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 18:25:20.962: INFO: Waiting for pod downwardapi-volume-39aa4cb5-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:25:20.979: INFO: Pod downwardapi-volume-39aa4cb5-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:25:20.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bzsrq" for this suite.
Feb  4 18:25:27.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:25:27.100: INFO: namespace: e2e-tests-projected-bzsrq, resource: bindings, ignored listing per whitelist
Feb  4 18:25:27.168: INFO: namespace e2e-tests-projected-bzsrq deletion completed in 6.18367359s

• [SLOW TEST:8.456 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:25:27.168: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-cxv72/configmap-test-3eba0df9-28aa-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 18:25:27.443: INFO: Waiting up to 5m0s for pod "pod-configmaps-3ebc5bef-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-cxv72" to be "success or failure"
Feb  4 18:25:27.486: INFO: Pod "pod-configmaps-3ebc5bef-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 43.338854ms
Feb  4 18:25:29.499: INFO: Pod "pod-configmaps-3ebc5bef-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055957546s
Feb  4 18:25:31.515: INFO: Pod "pod-configmaps-3ebc5bef-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071871034s
STEP: Saw pod success
Feb  4 18:25:31.515: INFO: Pod "pod-configmaps-3ebc5bef-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:25:31.525: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-configmaps-3ebc5bef-28aa-11e9-8d1f-5e319961b721 container env-test: <nil>
STEP: delete the pod
Feb  4 18:25:31.584: INFO: Waiting for pod pod-configmaps-3ebc5bef-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:25:31.592: INFO: Pod pod-configmaps-3ebc5bef-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:25:31.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cxv72" for this suite.
Feb  4 18:25:37.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:25:37.701: INFO: namespace: e2e-tests-configmap-cxv72, resource: bindings, ignored listing per whitelist
Feb  4 18:25:37.733: INFO: namespace e2e-tests-configmap-cxv72 deletion completed in 6.139070462s

• [SLOW TEST:10.565 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:25:37.734: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-45033a9b-28aa-11e9-8d1f-5e319961b721
STEP: Creating secret with name secret-projected-all-test-volume-45033a34-28aa-11e9-8d1f-5e319961b721
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  4 18:25:37.949: INFO: Waiting up to 5m0s for pod "projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-5rwsc" to be "success or failure"
Feb  4 18:25:37.956: INFO: Pod "projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 6.492548ms
Feb  4 18:25:39.964: INFO: Pod "projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014565829s
Feb  4 18:25:41.970: INFO: Pod "projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020240147s
Feb  4 18:25:43.987: INFO: Pod "projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.038140462s
STEP: Saw pod success
Feb  4 18:25:43.987: INFO: Pod "projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:25:43.990: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  4 18:25:44.039: INFO: Waiting for pod projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:25:44.050: INFO: Pod projected-volume-4503394f-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:25:44.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5rwsc" for this suite.
Feb  4 18:25:50.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:25:50.235: INFO: namespace: e2e-tests-projected-5rwsc, resource: bindings, ignored listing per whitelist
Feb  4 18:25:50.244: INFO: namespace e2e-tests-projected-5rwsc deletion completed in 6.189412011s

• [SLOW TEST:12.511 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:25:50.245: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 18:25:50.343: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c6d9a86-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-xm74q" to be "success or failure"
Feb  4 18:25:50.352: INFO: Pod "downwardapi-volume-4c6d9a86-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 9.362503ms
Feb  4 18:25:52.355: INFO: Pod "downwardapi-volume-4c6d9a86-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012341736s
Feb  4 18:25:54.362: INFO: Pod "downwardapi-volume-4c6d9a86-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019390574s
STEP: Saw pod success
Feb  4 18:25:54.362: INFO: Pod "downwardapi-volume-4c6d9a86-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:25:54.370: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-4c6d9a86-28aa-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 18:25:54.481: INFO: Waiting for pod downwardapi-volume-4c6d9a86-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:25:54.489: INFO: Pod downwardapi-volume-4c6d9a86-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:25:54.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xm74q" for this suite.
Feb  4 18:26:00.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:26:00.612: INFO: namespace: e2e-tests-downward-api-xm74q, resource: bindings, ignored listing per whitelist
Feb  4 18:26:00.713: INFO: namespace e2e-tests-downward-api-xm74q deletion completed in 6.220107657s

• [SLOW TEST:10.468 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:26:00.713: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0204 18:26:40.917042      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  4 18:26:40.917: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:26:40.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5gxwp" for this suite.
Feb  4 18:26:48.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:26:49.166: INFO: namespace: e2e-tests-gc-5gxwp, resource: bindings, ignored listing per whitelist
Feb  4 18:26:49.166: INFO: namespace e2e-tests-gc-5gxwp deletion completed in 8.200675619s

• [SLOW TEST:48.454 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:26:49.167: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 18:26:49.278: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f88cb99-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-r9q8l" to be "success or failure"
Feb  4 18:26:49.333: INFO: Pod "downwardapi-volume-6f88cb99-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 47.251329ms
Feb  4 18:26:51.342: INFO: Pod "downwardapi-volume-6f88cb99-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056343531s
STEP: Saw pod success
Feb  4 18:26:51.342: INFO: Pod "downwardapi-volume-6f88cb99-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:26:51.349: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod downwardapi-volume-6f88cb99-28aa-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 18:26:51.394: INFO: Waiting for pod downwardapi-volume-6f88cb99-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:26:51.404: INFO: Pod downwardapi-volume-6f88cb99-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:26:51.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r9q8l" for this suite.
Feb  4 18:26:57.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:26:57.429: INFO: namespace: e2e-tests-downward-api-r9q8l, resource: bindings, ignored listing per whitelist
Feb  4 18:26:57.524: INFO: namespace e2e-tests-downward-api-r9q8l deletion completed in 6.118092346s

• [SLOW TEST:8.358 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:26:57.525: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  4 18:26:57.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:26:57.981: INFO: stderr: ""
Feb  4 18:26:57.981: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  4 18:26:57.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:26:58.114: INFO: stderr: ""
Feb  4 18:26:58.114: INFO: stdout: "update-demo-nautilus-qjpdd update-demo-nautilus-r2xrh "
Feb  4 18:26:58.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-qjpdd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:26:58.171: INFO: stderr: ""
Feb  4 18:26:58.171: INFO: stdout: ""
Feb  4 18:26:58.171: INFO: update-demo-nautilus-qjpdd is created but not running
Feb  4 18:27:03.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:27:03.385: INFO: stderr: ""
Feb  4 18:27:03.385: INFO: stdout: "update-demo-nautilus-qjpdd update-demo-nautilus-r2xrh "
Feb  4 18:27:03.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-qjpdd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:27:03.439: INFO: stderr: ""
Feb  4 18:27:03.439: INFO: stdout: "true"
Feb  4 18:27:03.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-qjpdd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:27:03.499: INFO: stderr: ""
Feb  4 18:27:03.499: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 18:27:03.500: INFO: validating pod update-demo-nautilus-qjpdd
Feb  4 18:27:03.502: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 18:27:03.503: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 18:27:03.503: INFO: update-demo-nautilus-qjpdd is verified up and running
Feb  4 18:27:03.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-r2xrh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:27:03.561: INFO: stderr: ""
Feb  4 18:27:03.561: INFO: stdout: "true"
Feb  4 18:27:03.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-r2xrh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:27:03.614: INFO: stderr: ""
Feb  4 18:27:03.614: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 18:27:03.615: INFO: validating pod update-demo-nautilus-r2xrh
Feb  4 18:27:03.623: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 18:27:03.623: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 18:27:03.623: INFO: update-demo-nautilus-r2xrh is verified up and running
STEP: using delete to clean up resources
Feb  4 18:27:03.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:27:03.726: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 18:27:03.726: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  4 18:27:03.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-db4ph'
Feb  4 18:27:03.860: INFO: stderr: "No resources found.\n"
Feb  4 18:27:03.860: INFO: stdout: ""
Feb  4 18:27:03.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -l name=update-demo --namespace=e2e-tests-kubectl-db4ph -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  4 18:27:03.958: INFO: stderr: ""
Feb  4 18:27:03.958: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:27:03.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-db4ph" for this suite.
Feb  4 18:27:09.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:27:10.125: INFO: namespace: e2e-tests-kubectl-db4ph, resource: bindings, ignored listing per whitelist
Feb  4 18:27:10.180: INFO: namespace e2e-tests-kubectl-db4ph deletion completed in 6.219371592s

• [SLOW TEST:12.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:27:10.181: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 18:27:10.350: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c1dbd96-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-sgzw9" to be "success or failure"
Feb  4 18:27:10.361: INFO: Pod "downwardapi-volume-7c1dbd96-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 10.479281ms
Feb  4 18:27:12.371: INFO: Pod "downwardapi-volume-7c1dbd96-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020709035s
Feb  4 18:27:14.377: INFO: Pod "downwardapi-volume-7c1dbd96-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02649937s
STEP: Saw pod success
Feb  4 18:27:14.377: INFO: Pod "downwardapi-volume-7c1dbd96-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:27:14.385: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-7c1dbd96-28aa-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 18:27:14.486: INFO: Waiting for pod downwardapi-volume-7c1dbd96-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:27:14.490: INFO: Pod downwardapi-volume-7c1dbd96-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:27:14.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sgzw9" for this suite.
Feb  4 18:27:20.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:27:20.582: INFO: namespace: e2e-tests-downward-api-sgzw9, resource: bindings, ignored listing per whitelist
Feb  4 18:27:20.729: INFO: namespace e2e-tests-downward-api-sgzw9 deletion completed in 6.234067206s

• [SLOW TEST:10.548 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:27:20.729: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Feb  4 18:27:24.962: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:27:49.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-pc84q" for this suite.
Feb  4 18:27:55.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:27:55.239: INFO: namespace: e2e-tests-namespaces-pc84q, resource: bindings, ignored listing per whitelist
Feb  4 18:27:55.258: INFO: namespace e2e-tests-namespaces-pc84q deletion completed in 6.135279106s
STEP: Destroying namespace "e2e-tests-nsdeletetest-876d9" for this suite.
Feb  4 18:27:55.263: INFO: Namespace e2e-tests-nsdeletetest-876d9 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-p8wx8" for this suite.
Feb  4 18:28:01.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:28:01.358: INFO: namespace: e2e-tests-nsdeletetest-p8wx8, resource: bindings, ignored listing per whitelist
Feb  4 18:28:01.440: INFO: namespace e2e-tests-nsdeletetest-p8wx8 deletion completed in 6.177074458s

• [SLOW TEST:40.711 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:28:01.440: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9aa253f2-28aa-11e9-8d1f-5e319961b721
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9aa253f2-28aa-11e9-8d1f-5e319961b721
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:28:05.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8c8n4" for this suite.
Feb  4 18:28:27.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:28:27.950: INFO: namespace: e2e-tests-projected-8c8n4, resource: bindings, ignored listing per whitelist
Feb  4 18:28:28.003: INFO: namespace e2e-tests-projected-8c8n4 deletion completed in 22.288527974s

• [SLOW TEST:26.563 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:28:28.003: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  4 18:28:28.089: INFO: Waiting up to 5m0s for pod "pod-aa743d97-28aa-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-n9kkk" to be "success or failure"
Feb  4 18:28:28.094: INFO: Pod "pod-aa743d97-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 5.34219ms
Feb  4 18:28:30.102: INFO: Pod "pod-aa743d97-28aa-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012755225s
Feb  4 18:28:32.107: INFO: Pod "pod-aa743d97-28aa-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017726464s
STEP: Saw pod success
Feb  4 18:28:32.107: INFO: Pod "pod-aa743d97-28aa-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:28:32.109: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-aa743d97-28aa-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:28:32.167: INFO: Waiting for pod pod-aa743d97-28aa-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:28:32.170: INFO: Pod pod-aa743d97-28aa-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:28:32.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n9kkk" for this suite.
Feb  4 18:28:38.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:28:38.296: INFO: namespace: e2e-tests-emptydir-n9kkk, resource: bindings, ignored listing per whitelist
Feb  4 18:28:38.317: INFO: namespace e2e-tests-emptydir-n9kkk deletion completed in 6.14334349s

• [SLOW TEST:10.314 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:28:38.318: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:28:38.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 version --client'
Feb  4 18:28:38.459: INFO: stderr: ""
Feb  4 18:28:38.459: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb  4 18:28:38.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-4pzjb'
Feb  4 18:28:38.706: INFO: stderr: ""
Feb  4 18:28:38.706: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  4 18:28:38.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-4pzjb'
Feb  4 18:28:38.962: INFO: stderr: ""
Feb  4 18:28:38.962: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  4 18:28:39.974: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:28:39.974: INFO: Found 0 / 1
Feb  4 18:28:40.969: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:28:40.969: INFO: Found 0 / 1
Feb  4 18:28:41.982: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:28:41.982: INFO: Found 0 / 1
Feb  4 18:28:42.974: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:28:42.974: INFO: Found 1 / 1
Feb  4 18:28:42.975: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  4 18:28:42.988: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:28:42.988: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  4 18:28:42.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 describe pod redis-master-7pfwq --namespace=e2e-tests-kubectl-4pzjb'
Feb  4 18:28:43.124: INFO: stderr: ""
Feb  4 18:28:43.124: INFO: stdout: "Name:               redis-master-7pfwq\nNamespace:          e2e-tests-kubectl-4pzjb\nPriority:           0\nPriorityClassName:  <none>\nNode:               kube-spawn-default-worker-pqanhr/10.22.0.5\nStart Time:         Mon, 04 Feb 2019 18:28:38 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.32.0.3\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://40326cea5966bcbe291598f5e797ce0afaf860be5a93d32db316e2e993c5087c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 04 Feb 2019 18:28:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7gpdq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7gpdq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7gpdq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                       Message\n  ----    ------     ----  ----                                       -------\n  Normal  Scheduled  5s    default-scheduler                          Successfully assigned e2e-tests-kubectl-4pzjb/redis-master-7pfwq to kube-spawn-default-worker-pqanhr\n  Normal  Pulling    4s    kubelet, kube-spawn-default-worker-pqanhr  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     2s    kubelet, kube-spawn-default-worker-pqanhr  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    2s    kubelet, kube-spawn-default-worker-pqanhr  Created container\n  Normal  Started    1s    kubelet, kube-spawn-default-worker-pqanhr  Started container\n"
Feb  4 18:28:43.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 describe rc redis-master --namespace=e2e-tests-kubectl-4pzjb'
Feb  4 18:28:43.197: INFO: stderr: ""
Feb  4 18:28:43.197: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-4pzjb\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  5s    replication-controller  Created pod: redis-master-7pfwq\n"
Feb  4 18:28:43.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 describe service redis-master --namespace=e2e-tests-kubectl-4pzjb'
Feb  4 18:28:43.265: INFO: stderr: ""
Feb  4 18:28:43.265: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-4pzjb\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.102.62.122\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.32.0.3:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  4 18:28:43.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 describe node kube-spawn-default-master-ogc9eo'
Feb  4 18:28:43.363: INFO: stderr: ""
Feb  4 18:28:43.363: INFO: stdout: "Name:               kube-spawn-default-master-ogc9eo\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=kube-spawn-default-master-ogc9eo\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 04 Feb 2019 18:16:03 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 04 Feb 2019 18:16:54 +0000   Mon, 04 Feb 2019 18:16:54 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Mon, 04 Feb 2019 18:28:37 +0000   Mon, 04 Feb 2019 18:15:59 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 04 Feb 2019 18:28:37 +0000   Mon, 04 Feb 2019 18:15:59 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 04 Feb 2019 18:28:37 +0000   Mon, 04 Feb 2019 18:15:59 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 04 Feb 2019 18:28:37 +0000   Mon, 04 Feb 2019 18:16:44 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.22.0.6\n  Hostname:    kube-spawn-default-master-ogc9eo\nCapacity:\n cpu:                4\n ephemeral-storage:  309504832Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16277772Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  309504832Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16277772Ki\n pods:               110\nSystem Info:\n Machine ID:                 3dcf9449efc7457885c45f3baa55f22e\n System UUID:                59f8a424-d788-1d4f-92bc-5b6e4a69d738\n Boot ID:                    2eaadb87-44f2-4de6-9876-a780f2a620bc\n Kernel Version:             4.20.5-200.fc29.x86_64\n OS Image:                   Flatcar Linux by Kinvolk 1967.0.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.0\n Kube-Proxy Version:         v1.13.0\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                        CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                        ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-8dzvv     0 (0%)        0 (0%)      0 (0%)           0 (0%)         10m\n  kube-system                coredns-86c58d9df4-56qj2                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     12m\n  kube-system                coredns-86c58d9df4-mrb26                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     12m\n  kube-system                etcd-kube-spawn-default-master-ogc9eo                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-apiserver-kube-spawn-default-master-ogc9eo             250m (6%)     0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-controller-manager-kube-spawn-default-master-ogc9eo    200m (5%)     0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-proxy-xldbg                                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         12m\n  kube-system                kube-scheduler-kube-spawn-default-master-ogc9eo             100m (2%)     0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                weave-net-jwpr8                                             20m (0%)      0 (0%)      0 (0%)           0 (0%)         12m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                770m (19%)  0 (0%)\n  memory             140Mi (0%)  340Mi (2%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                                          Message\n  ----    ------                   ----               ----                                          -------\n  Normal  Starting                 12m                kubelet, kube-spawn-default-master-ogc9eo     Starting kubelet.\n  Normal  NodeHasSufficientMemory  12m (x8 over 12m)  kubelet, kube-spawn-default-master-ogc9eo     Node kube-spawn-default-master-ogc9eo status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    12m (x8 over 12m)  kubelet, kube-spawn-default-master-ogc9eo     Node kube-spawn-default-master-ogc9eo status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     12m (x8 over 12m)  kubelet, kube-spawn-default-master-ogc9eo     Node kube-spawn-default-master-ogc9eo status is now: NodeHasSufficientPID\n  Normal  Starting                 12m                kube-proxy, kube-spawn-default-master-ogc9eo  Starting kube-proxy.\n"
Feb  4 18:28:43.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 describe namespace e2e-tests-kubectl-4pzjb'
Feb  4 18:28:43.433: INFO: stderr: ""
Feb  4 18:28:43.433: INFO: stdout: "Name:         e2e-tests-kubectl-4pzjb\nLabels:       e2e-framework=kubectl\n              e2e-run=65c6815a-28a9-11e9-8d1f-5e319961b721\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:28:43.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4pzjb" for this suite.
Feb  4 18:29:05.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:29:05.582: INFO: namespace: e2e-tests-kubectl-4pzjb, resource: bindings, ignored listing per whitelist
Feb  4 18:29:05.598: INFO: namespace e2e-tests-kubectl-4pzjb deletion completed in 22.163019158s

• [SLOW TEST:27.280 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:29:05.598: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  4 18:29:05.726: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fm78f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fm78f/configmaps/e2e-watch-test-label-changed,UID:c0df36b9-28aa-11e9-88b2-2600a3ceccc4,ResourceVersion:2758,Generation:0,CreationTimestamp:2019-02-04 18:29:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  4 18:29:05.726: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fm78f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fm78f/configmaps/e2e-watch-test-label-changed,UID:c0df36b9-28aa-11e9-88b2-2600a3ceccc4,ResourceVersion:2759,Generation:0,CreationTimestamp:2019-02-04 18:29:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  4 18:29:05.726: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fm78f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fm78f/configmaps/e2e-watch-test-label-changed,UID:c0df36b9-28aa-11e9-88b2-2600a3ceccc4,ResourceVersion:2760,Generation:0,CreationTimestamp:2019-02-04 18:29:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  4 18:29:15.841: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fm78f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fm78f/configmaps/e2e-watch-test-label-changed,UID:c0df36b9-28aa-11e9-88b2-2600a3ceccc4,ResourceVersion:2776,Generation:0,CreationTimestamp:2019-02-04 18:29:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  4 18:29:15.844: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fm78f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fm78f/configmaps/e2e-watch-test-label-changed,UID:c0df36b9-28aa-11e9-88b2-2600a3ceccc4,ResourceVersion:2777,Generation:0,CreationTimestamp:2019-02-04 18:29:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  4 18:29:15.845: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fm78f,SelfLink:/api/v1/namespaces/e2e-tests-watch-fm78f/configmaps/e2e-watch-test-label-changed,UID:c0df36b9-28aa-11e9-88b2-2600a3ceccc4,ResourceVersion:2778,Generation:0,CreationTimestamp:2019-02-04 18:29:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:29:15.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fm78f" for this suite.
Feb  4 18:29:21.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:29:21.891: INFO: namespace: e2e-tests-watch-fm78f, resource: bindings, ignored listing per whitelist
Feb  4 18:29:21.980: INFO: namespace e2e-tests-watch-fm78f deletion completed in 6.129244534s

• [SLOW TEST:16.381 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:29:21.981: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:29:22.142: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  4 18:29:22.162: INFO: Number of nodes with available pods: 0
Feb  4 18:29:22.162: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  4 18:29:22.193: INFO: Number of nodes with available pods: 0
Feb  4 18:29:22.193: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:23.250: INFO: Number of nodes with available pods: 0
Feb  4 18:29:23.250: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:24.213: INFO: Number of nodes with available pods: 0
Feb  4 18:29:24.213: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:25.230: INFO: Number of nodes with available pods: 1
Feb  4 18:29:25.231: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  4 18:29:25.319: INFO: Number of nodes with available pods: 0
Feb  4 18:29:25.319: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  4 18:29:25.400: INFO: Number of nodes with available pods: 0
Feb  4 18:29:25.400: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:26.410: INFO: Number of nodes with available pods: 0
Feb  4 18:29:26.410: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:27.403: INFO: Number of nodes with available pods: 0
Feb  4 18:29:27.403: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:28.408: INFO: Number of nodes with available pods: 0
Feb  4 18:29:28.408: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:29.409: INFO: Number of nodes with available pods: 0
Feb  4 18:29:29.409: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:30.410: INFO: Number of nodes with available pods: 0
Feb  4 18:29:30.410: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:31.407: INFO: Number of nodes with available pods: 0
Feb  4 18:29:31.408: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:32.406: INFO: Number of nodes with available pods: 0
Feb  4 18:29:32.406: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:33.408: INFO: Number of nodes with available pods: 0
Feb  4 18:29:33.408: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:34.409: INFO: Number of nodes with available pods: 0
Feb  4 18:29:34.410: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:35.409: INFO: Number of nodes with available pods: 0
Feb  4 18:29:35.409: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:36.409: INFO: Number of nodes with available pods: 0
Feb  4 18:29:36.409: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:37.407: INFO: Number of nodes with available pods: 0
Feb  4 18:29:37.407: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:38.407: INFO: Number of nodes with available pods: 0
Feb  4 18:29:38.407: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:39.409: INFO: Number of nodes with available pods: 0
Feb  4 18:29:39.409: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:40.406: INFO: Number of nodes with available pods: 0
Feb  4 18:29:40.406: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:41.406: INFO: Number of nodes with available pods: 0
Feb  4 18:29:41.406: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:42.408: INFO: Number of nodes with available pods: 0
Feb  4 18:29:42.408: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:43.403: INFO: Number of nodes with available pods: 0
Feb  4 18:29:43.403: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:44.409: INFO: Number of nodes with available pods: 0
Feb  4 18:29:44.410: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:45.408: INFO: Number of nodes with available pods: 0
Feb  4 18:29:45.408: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:46.407: INFO: Number of nodes with available pods: 0
Feb  4 18:29:46.407: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:47.409: INFO: Number of nodes with available pods: 0
Feb  4 18:29:47.409: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:48.408: INFO: Number of nodes with available pods: 0
Feb  4 18:29:48.408: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:49.432: INFO: Number of nodes with available pods: 0
Feb  4 18:29:49.432: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:50.406: INFO: Number of nodes with available pods: 0
Feb  4 18:29:50.406: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:51.407: INFO: Number of nodes with available pods: 0
Feb  4 18:29:51.407: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:52.406: INFO: Number of nodes with available pods: 0
Feb  4 18:29:52.406: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:53.408: INFO: Number of nodes with available pods: 0
Feb  4 18:29:53.408: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:54.407: INFO: Number of nodes with available pods: 0
Feb  4 18:29:54.407: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:55.408: INFO: Number of nodes with available pods: 0
Feb  4 18:29:55.408: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:56.412: INFO: Number of nodes with available pods: 0
Feb  4 18:29:56.412: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:57.404: INFO: Number of nodes with available pods: 0
Feb  4 18:29:57.404: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:58.448: INFO: Number of nodes with available pods: 0
Feb  4 18:29:58.448: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:29:59.428: INFO: Number of nodes with available pods: 0
Feb  4 18:29:59.428: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:30:00.425: INFO: Number of nodes with available pods: 0
Feb  4 18:30:00.425: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:30:01.410: INFO: Number of nodes with available pods: 1
Feb  4 18:30:01.411: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-nbmcq, will wait for the garbage collector to delete the pods
Feb  4 18:30:01.549: INFO: Deleting DaemonSet.extensions daemon-set took: 31.449206ms
Feb  4 18:30:01.649: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.847543ms
Feb  4 18:30:35.056: INFO: Number of nodes with available pods: 0
Feb  4 18:30:35.056: INFO: Number of running nodes: 0, number of available pods: 0
Feb  4 18:30:35.059: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nbmcq/daemonsets","resourceVersion":"2944"},"items":null}

Feb  4 18:30:35.064: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nbmcq/pods","resourceVersion":"2944"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:30:35.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nbmcq" for this suite.
Feb  4 18:30:41.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:30:41.255: INFO: namespace: e2e-tests-daemonsets-nbmcq, resource: bindings, ignored listing per whitelist
Feb  4 18:30:41.268: INFO: namespace e2e-tests-daemonsets-nbmcq deletion completed in 6.16808598s

• [SLOW TEST:79.288 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:30:41.269: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  4 18:30:41.335: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  4 18:30:41.341: INFO: Waiting for terminating namespaces to be deleted...
Feb  4 18:30:41.343: INFO: 
Logging pods the kubelet thinks is on node kube-spawn-default-worker-iurq7e before test
Feb  4 18:30:41.348: INFO: kube-proxy-c42lk from kube-system started at 2019-02-04 18:16:18 +0000 UTC (1 container statuses recorded)
Feb  4 18:30:41.348: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  4 18:30:41.348: INFO: weave-net-8pp25 from kube-system started at 2019-02-04 18:16:21 +0000 UTC (2 container statuses recorded)
Feb  4 18:30:41.348: INFO: 	Container weave ready: true, restart count 0
Feb  4 18:30:41.348: INFO: 	Container weave-npc ready: true, restart count 0
Feb  4 18:30:41.348: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-04 18:17:42 +0000 UTC (1 container statuses recorded)
Feb  4 18:30:41.348: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  4 18:30:41.348: INFO: sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-gnwqq from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:30:41.348: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  4 18:30:41.348: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  4 18:30:41.348: INFO: 
Logging pods the kubelet thinks is on node kube-spawn-default-worker-pqanhr before test
Feb  4 18:30:41.357: INFO: sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-7dxn8 from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:30:41.357: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  4 18:30:41.357: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  4 18:30:41.357: INFO: weave-net-vvvzf from kube-system started at 2019-02-04 18:16:21 +0000 UTC (2 container statuses recorded)
Feb  4 18:30:41.357: INFO: 	Container weave ready: true, restart count 0
Feb  4 18:30:41.357: INFO: 	Container weave-npc ready: true, restart count 0
Feb  4 18:30:41.357: INFO: sonobuoy-e2e-job-b8fb7d0ddcfd4df7 from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:30:41.357: INFO: 	Container e2e ready: true, restart count 0
Feb  4 18:30:41.357: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  4 18:30:41.357: INFO: kube-proxy-5n6ck from kube-system started at 2019-02-04 18:16:18 +0000 UTC (1 container statuses recorded)
Feb  4 18:30:41.357: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fc54f7f2-28aa-11e9-8d1f-5e319961b721 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fc54f7f2-28aa-11e9-8d1f-5e319961b721 off the node kube-spawn-default-worker-pqanhr
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fc54f7f2-28aa-11e9-8d1f-5e319961b721
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:30:49.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-2qx6q" for this suite.
Feb  4 18:30:57.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:30:57.576: INFO: namespace: e2e-tests-sched-pred-2qx6q, resource: bindings, ignored listing per whitelist
Feb  4 18:30:57.618: INFO: namespace e2e-tests-sched-pred-2qx6q deletion completed in 8.075445876s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.350 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:30:57.621: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  4 18:30:57.814: INFO: Waiting up to 5m0s for pod "downward-api-03b2698b-28ab-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-28q7t" to be "success or failure"
Feb  4 18:30:57.826: INFO: Pod "downward-api-03b2698b-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 11.509892ms
Feb  4 18:30:59.831: INFO: Pod "downward-api-03b2698b-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017119201s
Feb  4 18:31:01.833: INFO: Pod "downward-api-03b2698b-28ab-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019299414s
STEP: Saw pod success
Feb  4 18:31:01.833: INFO: Pod "downward-api-03b2698b-28ab-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:31:01.836: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downward-api-03b2698b-28ab-11e9-8d1f-5e319961b721 container dapi-container: <nil>
STEP: delete the pod
Feb  4 18:31:01.859: INFO: Waiting for pod downward-api-03b2698b-28ab-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:31:01.882: INFO: Pod downward-api-03b2698b-28ab-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:31:01.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-28q7t" for this suite.
Feb  4 18:31:07.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:31:07.928: INFO: namespace: e2e-tests-downward-api-28q7t, resource: bindings, ignored listing per whitelist
Feb  4 18:31:07.957: INFO: namespace e2e-tests-downward-api-28q7t deletion completed in 6.071072678s

• [SLOW TEST:10.336 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:31:07.958: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  4 18:31:08.042: INFO: Waiting up to 5m0s for pod "pod-09caa44c-28ab-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-864fq" to be "success or failure"
Feb  4 18:31:08.059: INFO: Pod "pod-09caa44c-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 17.102472ms
Feb  4 18:31:10.062: INFO: Pod "pod-09caa44c-28ab-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020463605s
STEP: Saw pod success
Feb  4 18:31:10.062: INFO: Pod "pod-09caa44c-28ab-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:31:10.066: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-09caa44c-28ab-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:31:10.103: INFO: Waiting for pod pod-09caa44c-28ab-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:31:10.110: INFO: Pod pod-09caa44c-28ab-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:31:10.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-864fq" for this suite.
Feb  4 18:31:16.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:31:16.136: INFO: namespace: e2e-tests-emptydir-864fq, resource: bindings, ignored listing per whitelist
Feb  4 18:31:16.179: INFO: namespace e2e-tests-emptydir-864fq deletion completed in 6.064758011s

• [SLOW TEST:8.221 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:31:16.179: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:31:16.245: INFO: Creating deployment "test-recreate-deployment"
Feb  4 18:31:16.253: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  4 18:31:16.274: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb  4 18:31:18.277: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  4 18:31:18.280: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  4 18:31:18.286: INFO: Updating deployment test-recreate-deployment
Feb  4 18:31:18.286: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  4 18:31:18.456: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-c6b75,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c6b75/deployments/test-recreate-deployment,UID:0eb05482-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3162,Generation:2,CreationTimestamp:2019-02-04 18:31:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-04 18:31:18 +0000 UTC 2019-02-04 18:31:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-04 18:31:18 +0000 UTC 2019-02-04 18:31:16 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb  4 18:31:18.459: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-c6b75,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c6b75/replicasets/test-recreate-deployment-697fbf54bf,UID:0ff3c582-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3161,Generation:1,CreationTimestamp:2019-02-04 18:31:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0eb05482-28ab-11e9-88b2-2600a3ceccc4 0xc001f4c617 0xc001f4c618}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  4 18:31:18.459: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  4 18:31:18.459: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-c6b75,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-c6b75/replicasets/test-recreate-deployment-5dfdcc846d,UID:0eb47a15-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3151,Generation:2,CreationTimestamp:2019-02-04 18:31:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 0eb05482-28ab-11e9-88b2-2600a3ceccc4 0xc001f4c567 0xc001f4c568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  4 18:31:18.462: INFO: Pod "test-recreate-deployment-697fbf54bf-4sjw2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-4sjw2,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-c6b75,SelfLink:/api/v1/namespaces/e2e-tests-deployment-c6b75/pods/test-recreate-deployment-697fbf54bf-4sjw2,UID:0ff5c5e4-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3163,Generation:0,CreationTimestamp:2019-02-04 18:31:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 0ff3c582-28ab-11e9-88b2-2600a3ceccc4 0xc001f4ce67 0xc001f4ce68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zbd69 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zbd69,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zbd69 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001f4ced0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001f4cef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:31:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:31:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:31:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:31:18 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:,StartTime:2019-02-04 18:31:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:31:18.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-c6b75" for this suite.
Feb  4 18:31:24.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:31:24.584: INFO: namespace: e2e-tests-deployment-c6b75, resource: bindings, ignored listing per whitelist
Feb  4 18:31:24.598: INFO: namespace e2e-tests-deployment-c6b75 deletion completed in 6.109397767s

• [SLOW TEST:8.419 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:31:24.599: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  4 18:31:24.841: INFO: Waiting up to 5m0s for pod "pod-13c94faf-28ab-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-8w5fn" to be "success or failure"
Feb  4 18:31:24.865: INFO: Pod "pod-13c94faf-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 23.698197ms
Feb  4 18:31:26.874: INFO: Pod "pod-13c94faf-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03273721s
Feb  4 18:31:28.882: INFO: Pod "pod-13c94faf-28ab-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041452009s
STEP: Saw pod success
Feb  4 18:31:28.883: INFO: Pod "pod-13c94faf-28ab-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:31:28.895: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-13c94faf-28ab-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:31:28.989: INFO: Waiting for pod pod-13c94faf-28ab-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:31:29.020: INFO: Pod pod-13c94faf-28ab-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:31:29.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8w5fn" for this suite.
Feb  4 18:31:35.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:31:35.242: INFO: namespace: e2e-tests-emptydir-8w5fn, resource: bindings, ignored listing per whitelist
Feb  4 18:31:35.254: INFO: namespace e2e-tests-emptydir-8w5fn deletion completed in 6.211757691s

• [SLOW TEST:10.655 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:31:35.254: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  4 18:31:35.372: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xbl66,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbl66/configmaps/e2e-watch-test-watch-closed,UID:1a145d5d-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3240,Generation:0,CreationTimestamp:2019-02-04 18:31:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  4 18:31:35.372: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xbl66,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbl66/configmaps/e2e-watch-test-watch-closed,UID:1a145d5d-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3241,Generation:0,CreationTimestamp:2019-02-04 18:31:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  4 18:31:35.397: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xbl66,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbl66/configmaps/e2e-watch-test-watch-closed,UID:1a145d5d-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3242,Generation:0,CreationTimestamp:2019-02-04 18:31:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  4 18:31:35.398: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xbl66,SelfLink:/api/v1/namespaces/e2e-tests-watch-xbl66/configmaps/e2e-watch-test-watch-closed,UID:1a145d5d-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3243,Generation:0,CreationTimestamp:2019-02-04 18:31:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:31:35.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-xbl66" for this suite.
Feb  4 18:31:41.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:31:41.525: INFO: namespace: e2e-tests-watch-xbl66, resource: bindings, ignored listing per whitelist
Feb  4 18:31:41.554: INFO: namespace e2e-tests-watch-xbl66 deletion completed in 6.144953913s

• [SLOW TEST:6.300 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:31:41.554: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  4 18:31:41.688: INFO: Waiting up to 5m0s for pod "downward-api-1dd5fb96-28ab-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-md9tx" to be "success or failure"
Feb  4 18:31:41.696: INFO: Pod "downward-api-1dd5fb96-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 7.817864ms
Feb  4 18:31:43.703: INFO: Pod "downward-api-1dd5fb96-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014544955s
Feb  4 18:31:45.709: INFO: Pod "downward-api-1dd5fb96-28ab-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02113724s
STEP: Saw pod success
Feb  4 18:31:45.709: INFO: Pod "downward-api-1dd5fb96-28ab-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:31:45.720: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downward-api-1dd5fb96-28ab-11e9-8d1f-5e319961b721 container dapi-container: <nil>
STEP: delete the pod
Feb  4 18:31:45.812: INFO: Waiting for pod downward-api-1dd5fb96-28ab-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:31:45.824: INFO: Pod downward-api-1dd5fb96-28ab-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:31:45.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-md9tx" for this suite.
Feb  4 18:31:51.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:31:51.954: INFO: namespace: e2e-tests-downward-api-md9tx, resource: bindings, ignored listing per whitelist
Feb  4 18:31:52.015: INFO: namespace e2e-tests-downward-api-md9tx deletion completed in 6.18547757s

• [SLOW TEST:10.461 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:31:52.015: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-49jjc
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-49jjc
STEP: Deleting pre-stop pod
Feb  4 18:32:07.277: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:32:07.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-49jjc" for this suite.
Feb  4 18:32:47.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:32:47.434: INFO: namespace: e2e-tests-prestop-49jjc, resource: bindings, ignored listing per whitelist
Feb  4 18:32:47.477: INFO: namespace e2e-tests-prestop-49jjc deletion completed in 40.141417354s

• [SLOW TEST:55.462 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:32:47.478: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:33:13.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-4z894" for this suite.
Feb  4 18:33:19.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:33:19.527: INFO: namespace: e2e-tests-container-runtime-4z894, resource: bindings, ignored listing per whitelist
Feb  4 18:33:19.579: INFO: namespace e2e-tests-container-runtime-4z894 deletion completed in 6.20207309s

• [SLOW TEST:32.102 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:33:19.579: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  4 18:33:23.745: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-583e4324-28ab-11e9-8d1f-5e319961b721,GenerateName:,Namespace:e2e-tests-events-64g96,SelfLink:/api/v1/namespaces/e2e-tests-events-64g96/pods/send-events-583e4324-28ab-11e9-8d1f-5e319961b721,UID:583ea82f-28ab-11e9-88b2-2600a3ceccc4,ResourceVersion:3550,Generation:0,CreationTimestamp:2019-02-04 18:33:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 650491199,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6t42x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6t42x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-6t42x true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002262c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002262c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:33:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:33:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:33:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:33:19 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:10.46.0.2,StartTime:2019-02-04 18:33:19 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-04 18:33:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://24820ac4d1abd0032f5476015418975e5dcfbcac18c7e1a19d5a882b2ee587af}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb  4 18:33:25.756: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  4 18:33:27.764: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:33:27.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-64g96" for this suite.
Feb  4 18:34:05.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:34:06.054: INFO: namespace: e2e-tests-events-64g96, resource: bindings, ignored listing per whitelist
Feb  4 18:34:06.103: INFO: namespace e2e-tests-events-64g96 deletion completed in 38.288501274s

• [SLOW TEST:46.524 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:34:06.104: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  4 18:34:06.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-2cv8j'
Feb  4 18:34:06.940: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  4 18:34:06.940: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb  4 18:34:06.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-2cv8j'
Feb  4 18:34:07.104: INFO: stderr: ""
Feb  4 18:34:07.104: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:34:07.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2cv8j" for this suite.
Feb  4 18:34:13.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:34:13.157: INFO: namespace: e2e-tests-kubectl-2cv8j, resource: bindings, ignored listing per whitelist
Feb  4 18:34:13.173: INFO: namespace e2e-tests-kubectl-2cv8j deletion completed in 6.066084739s

• [SLOW TEST:7.069 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:34:13.173: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-jbsf
STEP: Creating a pod to test atomic-volume-subpath
Feb  4 18:34:13.321: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jbsf" in namespace "e2e-tests-subpath-xtf6k" to be "success or failure"
Feb  4 18:34:13.358: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Pending", Reason="", readiness=false. Elapsed: 31.820032ms
Feb  4 18:34:15.365: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039506898s
Feb  4 18:34:17.373: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 4.047464676s
Feb  4 18:34:19.376: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 6.050093014s
Feb  4 18:34:21.387: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 8.060767671s
Feb  4 18:34:23.396: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 10.069896895s
Feb  4 18:34:25.405: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 12.078734674s
Feb  4 18:34:27.416: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 14.090213223s
Feb  4 18:34:29.419: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 16.092846952s
Feb  4 18:34:31.429: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 18.102999454s
Feb  4 18:34:33.442: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 20.116606625s
Feb  4 18:34:35.446: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Running", Reason="", readiness=false. Elapsed: 22.120092338s
Feb  4 18:34:37.448: INFO: Pod "pod-subpath-test-configmap-jbsf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.121932617s
STEP: Saw pod success
Feb  4 18:34:37.448: INFO: Pod "pod-subpath-test-configmap-jbsf" satisfied condition "success or failure"
Feb  4 18:34:37.449: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-subpath-test-configmap-jbsf container test-container-subpath-configmap-jbsf: <nil>
STEP: delete the pod
Feb  4 18:34:37.483: INFO: Waiting for pod pod-subpath-test-configmap-jbsf to disappear
Feb  4 18:34:37.493: INFO: Pod pod-subpath-test-configmap-jbsf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jbsf
Feb  4 18:34:37.493: INFO: Deleting pod "pod-subpath-test-configmap-jbsf" in namespace "e2e-tests-subpath-xtf6k"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:34:37.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xtf6k" for this suite.
Feb  4 18:34:43.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:34:43.635: INFO: namespace: e2e-tests-subpath-xtf6k, resource: bindings, ignored listing per whitelist
Feb  4 18:34:43.649: INFO: namespace e2e-tests-subpath-xtf6k deletion completed in 6.144064526s

• [SLOW TEST:30.476 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:34:43.649: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  4 18:34:43.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-zv8w6'
Feb  4 18:34:43.900: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  4 18:34:43.900: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb  4 18:34:45.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-zv8w6'
Feb  4 18:34:46.063: INFO: stderr: ""
Feb  4 18:34:46.063: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:34:46.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zv8w6" for this suite.
Feb  4 18:34:52.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:34:52.273: INFO: namespace: e2e-tests-kubectl-zv8w6, resource: bindings, ignored listing per whitelist
Feb  4 18:34:52.315: INFO: namespace e2e-tests-kubectl-zv8w6 deletion completed in 6.248756465s

• [SLOW TEST:8.666 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:34:52.315: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-d9gp7.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-d9gp7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d9gp7.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-d9gp7.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-d9gp7.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-d9gp7.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  4 18:35:14.553: INFO: Unable to read jessie_udp@kubernetes.default from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.556: INFO: Unable to read jessie_tcp@kubernetes.default from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.559: INFO: Unable to read jessie_udp@kubernetes.default.svc from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.562: INFO: Unable to read jessie_tcp@kubernetes.default.svc from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.565: INFO: Unable to read jessie_udp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.567: INFO: Unable to read jessie_tcp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.571: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-d9gp7.svc.cluster.local from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.580: INFO: Unable to read jessie_hosts@dns-querier-1 from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.584: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.586: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721)
Feb  4 18:35:14.587: INFO: Lookups using e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721 failed for: [jessie_udp@kubernetes.default jessie_tcp@kubernetes.default jessie_udp@kubernetes.default.svc jessie_tcp@kubernetes.default.svc jessie_udp@kubernetes.default.svc.cluster.local jessie_tcp@kubernetes.default.svc.cluster.local jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-d9gp7.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Feb  4 18:35:19.683: INFO: DNS probes using e2e-tests-dns-d9gp7/dns-test-8f8663a2-28ab-11e9-8d1f-5e319961b721 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:35:19.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-d9gp7" for this suite.
Feb  4 18:35:25.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:35:25.801: INFO: namespace: e2e-tests-dns-d9gp7, resource: bindings, ignored listing per whitelist
Feb  4 18:35:25.915: INFO: namespace e2e-tests-dns-d9gp7 deletion completed in 6.183034905s

• [SLOW TEST:33.599 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:35:25.915: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  4 18:35:26.028: INFO: Waiting up to 5m0s for pod "downward-api-a3908fb4-28ab-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-7pp8b" to be "success or failure"
Feb  4 18:35:26.034: INFO: Pod "downward-api-a3908fb4-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 6.445642ms
Feb  4 18:35:28.050: INFO: Pod "downward-api-a3908fb4-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022627027s
Feb  4 18:35:30.064: INFO: Pod "downward-api-a3908fb4-28ab-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036187499s
STEP: Saw pod success
Feb  4 18:35:30.064: INFO: Pod "downward-api-a3908fb4-28ab-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:35:30.095: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod downward-api-a3908fb4-28ab-11e9-8d1f-5e319961b721 container dapi-container: <nil>
STEP: delete the pod
Feb  4 18:35:30.196: INFO: Waiting for pod downward-api-a3908fb4-28ab-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:35:30.210: INFO: Pod downward-api-a3908fb4-28ab-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:35:30.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7pp8b" for this suite.
Feb  4 18:35:36.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:35:36.272: INFO: namespace: e2e-tests-downward-api-7pp8b, resource: bindings, ignored listing per whitelist
Feb  4 18:35:36.420: INFO: namespace e2e-tests-downward-api-7pp8b deletion completed in 6.207032463s

• [SLOW TEST:10.506 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:35:36.421: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb  4 18:35:53.648: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:35:54.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-lqgjp" for this suite.
Feb  4 18:36:16.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:36:16.834: INFO: namespace: e2e-tests-replicaset-lqgjp, resource: bindings, ignored listing per whitelist
Feb  4 18:36:16.891: INFO: namespace e2e-tests-replicaset-lqgjp deletion completed in 22.175048762s

• [SLOW TEST:40.470 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:36:16.891: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-c1ed696c-28ab-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 18:36:17.065: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1ef732d-28ab-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-84hqw" to be "success or failure"
Feb  4 18:36:17.098: INFO: Pod "pod-configmaps-c1ef732d-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 32.321978ms
Feb  4 18:36:19.100: INFO: Pod "pod-configmaps-c1ef732d-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034824676s
Feb  4 18:36:21.107: INFO: Pod "pod-configmaps-c1ef732d-28ab-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041730525s
STEP: Saw pod success
Feb  4 18:36:21.107: INFO: Pod "pod-configmaps-c1ef732d-28ab-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:36:21.117: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-configmaps-c1ef732d-28ab-11e9-8d1f-5e319961b721 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 18:36:21.208: INFO: Waiting for pod pod-configmaps-c1ef732d-28ab-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:36:21.222: INFO: Pod pod-configmaps-c1ef732d-28ab-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:36:21.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-84hqw" for this suite.
Feb  4 18:36:27.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:36:27.363: INFO: namespace: e2e-tests-configmap-84hqw, resource: bindings, ignored listing per whitelist
Feb  4 18:36:27.401: INFO: namespace e2e-tests-configmap-84hqw deletion completed in 6.176909943s

• [SLOW TEST:10.511 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:36:27.401: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c8430c2d-28ab-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 18:36:27.646: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c847d571-28ab-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-bzj9v" to be "success or failure"
Feb  4 18:36:27.661: INFO: Pod "pod-projected-secrets-c847d571-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 14.508675ms
Feb  4 18:36:29.686: INFO: Pod "pod-projected-secrets-c847d571-28ab-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039360988s
Feb  4 18:36:31.698: INFO: Pod "pod-projected-secrets-c847d571-28ab-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051788282s
STEP: Saw pod success
Feb  4 18:36:31.698: INFO: Pod "pod-projected-secrets-c847d571-28ab-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:36:31.722: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-projected-secrets-c847d571-28ab-11e9-8d1f-5e319961b721 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  4 18:36:31.814: INFO: Waiting for pod pod-projected-secrets-c847d571-28ab-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:36:31.819: INFO: Pod pod-projected-secrets-c847d571-28ab-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:36:31.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bzj9v" for this suite.
Feb  4 18:36:37.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:36:37.978: INFO: namespace: e2e-tests-projected-bzj9v, resource: bindings, ignored listing per whitelist
Feb  4 18:36:37.992: INFO: namespace e2e-tests-projected-bzj9v deletion completed in 6.1703236s

• [SLOW TEST:10.590 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:36:37.992: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb  4 18:36:38.878: INFO: Pod name wrapped-volume-race-cef2cd6f-28ab-11e9-8d1f-5e319961b721: Found 0 pods out of 5
Feb  4 18:36:43.897: INFO: Pod name wrapped-volume-race-cef2cd6f-28ab-11e9-8d1f-5e319961b721: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cef2cd6f-28ab-11e9-8d1f-5e319961b721 in namespace e2e-tests-emptydir-wrapper-5cmx6, will wait for the garbage collector to delete the pods
Feb  4 18:36:54.112: INFO: Deleting ReplicationController wrapped-volume-race-cef2cd6f-28ab-11e9-8d1f-5e319961b721 took: 28.045944ms
Feb  4 18:36:54.313: INFO: Terminating ReplicationController wrapped-volume-race-cef2cd6f-28ab-11e9-8d1f-5e319961b721 pods took: 200.547634ms
STEP: Creating RC which spawns configmap-volume pods
Feb  4 18:37:37.736: INFO: Pod name wrapped-volume-race-f20fa614-28ab-11e9-8d1f-5e319961b721: Found 0 pods out of 5
Feb  4 18:37:42.765: INFO: Pod name wrapped-volume-race-f20fa614-28ab-11e9-8d1f-5e319961b721: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f20fa614-28ab-11e9-8d1f-5e319961b721 in namespace e2e-tests-emptydir-wrapper-5cmx6, will wait for the garbage collector to delete the pods
Feb  4 18:37:54.942: INFO: Deleting ReplicationController wrapped-volume-race-f20fa614-28ab-11e9-8d1f-5e319961b721 took: 23.713209ms
Feb  4 18:37:55.152: INFO: Terminating ReplicationController wrapped-volume-race-f20fa614-28ab-11e9-8d1f-5e319961b721 pods took: 210.466419ms
STEP: Creating RC which spawns configmap-volume pods
Feb  4 18:38:37.786: INFO: Pod name wrapped-volume-race-15d8e4dc-28ac-11e9-8d1f-5e319961b721: Found 0 pods out of 5
Feb  4 18:38:42.790: INFO: Pod name wrapped-volume-race-15d8e4dc-28ac-11e9-8d1f-5e319961b721: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-15d8e4dc-28ac-11e9-8d1f-5e319961b721 in namespace e2e-tests-emptydir-wrapper-5cmx6, will wait for the garbage collector to delete the pods
Feb  4 18:38:52.908: INFO: Deleting ReplicationController wrapped-volume-race-15d8e4dc-28ac-11e9-8d1f-5e319961b721 took: 33.376548ms
Feb  4 18:38:53.109: INFO: Terminating ReplicationController wrapped-volume-race-15d8e4dc-28ac-11e9-8d1f-5e319961b721 pods took: 200.172611ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:39:32.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-5cmx6" for this suite.
Feb  4 18:39:42.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:39:42.626: INFO: namespace: e2e-tests-emptydir-wrapper-5cmx6, resource: bindings, ignored listing per whitelist
Feb  4 18:39:42.629: INFO: namespace e2e-tests-emptydir-wrapper-5cmx6 deletion completed in 10.118137435s

• [SLOW TEST:184.637 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:39:42.629: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  4 18:39:50.864: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  4 18:39:50.878: INFO: Pod pod-with-prestop-http-hook still exists
Feb  4 18:39:52.878: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  4 18:39:52.887: INFO: Pod pod-with-prestop-http-hook still exists
Feb  4 18:39:54.878: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  4 18:39:54.891: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:39:54.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-tlcjx" for this suite.
Feb  4 18:40:16.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:40:17.036: INFO: namespace: e2e-tests-container-lifecycle-hook-tlcjx, resource: bindings, ignored listing per whitelist
Feb  4 18:40:17.059: INFO: namespace e2e-tests-container-lifecycle-hook-tlcjx deletion completed in 22.154408901s

• [SLOW TEST:34.429 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:40:17.059: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-slkl
STEP: Creating a pod to test atomic-volume-subpath
Feb  4 18:40:17.224: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-slkl" in namespace "e2e-tests-subpath-xdf5v" to be "success or failure"
Feb  4 18:40:17.238: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Pending", Reason="", readiness=false. Elapsed: 13.833935ms
Feb  4 18:40:19.265: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041077185s
Feb  4 18:40:21.275: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 4.051277377s
Feb  4 18:40:23.285: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 6.061635692s
Feb  4 18:40:25.294: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 8.070522577s
Feb  4 18:40:27.302: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 10.077943128s
Feb  4 18:40:29.307: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 12.083086482s
Feb  4 18:40:31.314: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 14.089847044s
Feb  4 18:40:33.320: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 16.095874703s
Feb  4 18:40:35.328: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 18.103984559s
Feb  4 18:40:37.335: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 20.111212383s
Feb  4 18:40:39.348: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Running", Reason="", readiness=false. Elapsed: 22.124250742s
Feb  4 18:40:41.357: INFO: Pod "pod-subpath-test-downwardapi-slkl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.133213862s
STEP: Saw pod success
Feb  4 18:40:41.357: INFO: Pod "pod-subpath-test-downwardapi-slkl" satisfied condition "success or failure"
Feb  4 18:40:41.371: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-subpath-test-downwardapi-slkl container test-container-subpath-downwardapi-slkl: <nil>
STEP: delete the pod
Feb  4 18:40:41.461: INFO: Waiting for pod pod-subpath-test-downwardapi-slkl to disappear
Feb  4 18:40:41.481: INFO: Pod pod-subpath-test-downwardapi-slkl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-slkl
Feb  4 18:40:41.481: INFO: Deleting pod "pod-subpath-test-downwardapi-slkl" in namespace "e2e-tests-subpath-xdf5v"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:40:41.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xdf5v" for this suite.
Feb  4 18:40:47.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:40:47.725: INFO: namespace: e2e-tests-subpath-xdf5v, resource: bindings, ignored listing per whitelist
Feb  4 18:40:47.732: INFO: namespace e2e-tests-subpath-xdf5v deletion completed in 6.215335248s

• [SLOW TEST:30.673 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:40:47.732: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-63674099-28ac-11e9-8d1f-5e319961b721
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-63674099-28ac-11e9-8d1f-5e319961b721
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:40:52.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-swcdg" for this suite.
Feb  4 18:41:14.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:41:14.161: INFO: namespace: e2e-tests-configmap-swcdg, resource: bindings, ignored listing per whitelist
Feb  4 18:41:14.193: INFO: namespace e2e-tests-configmap-swcdg deletion completed in 22.174105913s

• [SLOW TEST:26.461 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:41:14.194: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  4 18:44:04.442: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:04.451: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:06.451: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:06.460: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:08.451: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:08.460: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:10.451: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:10.483: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:12.451: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:12.460: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:14.454: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:14.488: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:16.452: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:16.460: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:18.452: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:18.459: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:20.451: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:20.466: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:22.452: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:22.462: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  4 18:44:24.451: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  4 18:44:24.469: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:44:24.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-v5jgk" for this suite.
Feb  4 18:44:46.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:44:46.653: INFO: namespace: e2e-tests-container-lifecycle-hook-v5jgk, resource: bindings, ignored listing per whitelist
Feb  4 18:44:46.669: INFO: namespace e2e-tests-container-lifecycle-hook-v5jgk deletion completed in 22.193090142s

• [SLOW TEST:212.475 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:44:46.669: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:44:48.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-f2hbz" for this suite.
Feb  4 18:45:26.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:45:27.021: INFO: namespace: e2e-tests-kubelet-test-f2hbz, resource: bindings, ignored listing per whitelist
Feb  4 18:45:27.069: INFO: namespace e2e-tests-kubelet-test-f2hbz deletion completed in 38.229111416s

• [SLOW TEST:40.400 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:45:27.070: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:45:27.195: INFO: (0) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 56.383379ms)
Feb  4 18:45:27.214: INFO: (1) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 19.477839ms)
Feb  4 18:45:27.233: INFO: (2) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 18.654781ms)
Feb  4 18:45:27.252: INFO: (3) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 18.175519ms)
Feb  4 18:45:27.266: INFO: (4) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.866151ms)
Feb  4 18:45:27.274: INFO: (5) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 8.453261ms)
Feb  4 18:45:27.279: INFO: (6) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.04099ms)
Feb  4 18:45:27.283: INFO: (7) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.90166ms)
Feb  4 18:45:27.286: INFO: (8) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.33038ms)
Feb  4 18:45:27.292: INFO: (9) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 5.86446ms)
Feb  4 18:45:27.298: INFO: (10) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.759766ms)
Feb  4 18:45:27.300: INFO: (11) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.338745ms)
Feb  4 18:45:27.303: INFO: (12) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.150718ms)
Feb  4 18:45:27.307: INFO: (13) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.590908ms)
Feb  4 18:45:27.310: INFO: (14) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.521646ms)
Feb  4 18:45:27.312: INFO: (15) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.512784ms)
Feb  4 18:45:27.315: INFO: (16) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.688224ms)
Feb  4 18:45:27.318: INFO: (17) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.87961ms)
Feb  4 18:45:27.321: INFO: (18) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.738848ms)
Feb  4 18:45:27.324: INFO: (19) /api/v1/nodes/kube-spawn-default-worker-iurq7e/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.514764ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:45:27.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-mngzp" for this suite.
Feb  4 18:45:33.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:45:33.474: INFO: namespace: e2e-tests-proxy-mngzp, resource: bindings, ignored listing per whitelist
Feb  4 18:45:33.520: INFO: namespace e2e-tests-proxy-mngzp deletion completed in 6.194065572s

• [SLOW TEST:6.451 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:45:33.521: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb  4 18:45:34.162: INFO: Waiting up to 5m0s for pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-6h85v" in namespace "e2e-tests-svcaccounts-cbh7v" to be "success or failure"
Feb  4 18:45:34.229: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-6h85v": Phase="Pending", Reason="", readiness=false. Elapsed: 65.270036ms
Feb  4 18:45:36.253: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-6h85v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088882394s
Feb  4 18:45:38.261: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-6h85v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.097033771s
STEP: Saw pod success
Feb  4 18:45:38.261: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-6h85v" satisfied condition "success or failure"
Feb  4 18:45:38.271: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-6h85v container token-test: <nil>
STEP: delete the pod
Feb  4 18:45:38.379: INFO: Waiting for pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-6h85v to disappear
Feb  4 18:45:38.391: INFO: Pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-6h85v no longer exists
STEP: Creating a pod to test consume service account root CA
Feb  4 18:45:38.396: INFO: Waiting up to 5m0s for pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw" in namespace "e2e-tests-svcaccounts-cbh7v" to be "success or failure"
Feb  4 18:45:38.408: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw": Phase="Pending", Reason="", readiness=false. Elapsed: 8.321667ms
Feb  4 18:45:40.411: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011282941s
Feb  4 18:45:42.418: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017818782s
Feb  4 18:45:44.421: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02117966s
STEP: Saw pod success
Feb  4 18:45:44.421: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw" satisfied condition "success or failure"
Feb  4 18:45:44.429: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw container root-ca-test: <nil>
STEP: delete the pod
Feb  4 18:45:44.477: INFO: Waiting for pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw to disappear
Feb  4 18:45:44.496: INFO: Pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-pk7pw no longer exists
STEP: Creating a pod to test consume service account namespace
Feb  4 18:45:44.514: INFO: Waiting up to 5m0s for pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q" in namespace "e2e-tests-svcaccounts-cbh7v" to be "success or failure"
Feb  4 18:45:44.525: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q": Phase="Pending", Reason="", readiness=false. Elapsed: 10.567139ms
Feb  4 18:45:46.534: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01936956s
Feb  4 18:45:48.568: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053927759s
Feb  4 18:45:50.612: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.09711424s
STEP: Saw pod success
Feb  4 18:45:50.612: INFO: Pod "pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q" satisfied condition "success or failure"
Feb  4 18:45:50.634: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q container namespace-test: <nil>
STEP: delete the pod
Feb  4 18:45:50.685: INFO: Waiting for pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q to disappear
Feb  4 18:45:50.690: INFO: Pod pod-service-account-0e07517a-28ad-11e9-8d1f-5e319961b721-spg8q no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:45:50.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-cbh7v" for this suite.
Feb  4 18:45:56.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:45:56.824: INFO: namespace: e2e-tests-svcaccounts-cbh7v, resource: bindings, ignored listing per whitelist
Feb  4 18:45:56.839: INFO: namespace e2e-tests-svcaccounts-cbh7v deletion completed in 6.145682562s

• [SLOW TEST:23.318 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:45:56.839: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-w2hs
STEP: Creating a pod to test atomic-volume-subpath
Feb  4 18:45:56.936: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-w2hs" in namespace "e2e-tests-subpath-wsd9q" to be "success or failure"
Feb  4 18:45:56.943: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.293506ms
Feb  4 18:45:58.949: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01287984s
Feb  4 18:46:00.956: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 4.019557947s
Feb  4 18:46:02.967: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 6.030599208s
Feb  4 18:46:04.970: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 8.033145177s
Feb  4 18:46:06.971: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 10.034664615s
Feb  4 18:46:08.977: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 12.040154299s
Feb  4 18:46:10.983: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 14.046726647s
Feb  4 18:46:12.989: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 16.052694712s
Feb  4 18:46:15.014: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 18.077209829s
Feb  4 18:46:17.016: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 20.080017516s
Feb  4 18:46:19.027: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 22.090663633s
Feb  4 18:46:21.033: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Running", Reason="", readiness=false. Elapsed: 24.096790976s
Feb  4 18:46:23.040: INFO: Pod "pod-subpath-test-secret-w2hs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.103769798s
STEP: Saw pod success
Feb  4 18:46:23.041: INFO: Pod "pod-subpath-test-secret-w2hs" satisfied condition "success or failure"
Feb  4 18:46:23.049: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-subpath-test-secret-w2hs container test-container-subpath-secret-w2hs: <nil>
STEP: delete the pod
Feb  4 18:46:23.107: INFO: Waiting for pod pod-subpath-test-secret-w2hs to disappear
Feb  4 18:46:23.115: INFO: Pod pod-subpath-test-secret-w2hs no longer exists
STEP: Deleting pod pod-subpath-test-secret-w2hs
Feb  4 18:46:23.115: INFO: Deleting pod "pod-subpath-test-secret-w2hs" in namespace "e2e-tests-subpath-wsd9q"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:46:23.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wsd9q" for this suite.
Feb  4 18:46:29.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:46:29.271: INFO: namespace: e2e-tests-subpath-wsd9q, resource: bindings, ignored listing per whitelist
Feb  4 18:46:29.277: INFO: namespace e2e-tests-subpath-wsd9q deletion completed in 6.15664267s

• [SLOW TEST:32.438 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:46:29.277: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-k48nr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  4 18:46:29.360: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  4 18:46:55.628: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.4:8080/dial?request=hostName&protocol=udp&host=10.32.0.3&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-k48nr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 18:46:55.628: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 18:46:55.919: INFO: Waiting for endpoints: map[]
Feb  4 18:46:55.921: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.4:8080/dial?request=hostName&protocol=udp&host=10.46.0.2&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-k48nr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 18:46:55.921: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 18:46:55.997: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:46:55.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-k48nr" for this suite.
Feb  4 18:47:18.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:47:18.136: INFO: namespace: e2e-tests-pod-network-test-k48nr, resource: bindings, ignored listing per whitelist
Feb  4 18:47:18.175: INFO: namespace e2e-tests-pod-network-test-k48nr deletion completed in 22.1733889s

• [SLOW TEST:48.898 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:47:18.175: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4c18223f-28ad-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 18:47:18.280: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c19ddd0-28ad-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-gnclt" to be "success or failure"
Feb  4 18:47:18.287: INFO: Pod "pod-projected-configmaps-4c19ddd0-28ad-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 6.963784ms
Feb  4 18:47:20.294: INFO: Pod "pod-projected-configmaps-4c19ddd0-28ad-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01401223s
STEP: Saw pod success
Feb  4 18:47:20.295: INFO: Pod "pod-projected-configmaps-4c19ddd0-28ad-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:47:20.298: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-projected-configmaps-4c19ddd0-28ad-11e9-8d1f-5e319961b721 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 18:47:20.320: INFO: Waiting for pod pod-projected-configmaps-4c19ddd0-28ad-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:47:20.326: INFO: Pod pod-projected-configmaps-4c19ddd0-28ad-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:47:20.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gnclt" for this suite.
Feb  4 18:47:26.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:47:26.419: INFO: namespace: e2e-tests-projected-gnclt, resource: bindings, ignored listing per whitelist
Feb  4 18:47:26.513: INFO: namespace e2e-tests-projected-gnclt deletion completed in 6.17701623s

• [SLOW TEST:8.338 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:47:26.514: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  4 18:47:26.604: INFO: namespace e2e-tests-kubectl-2khxs
Feb  4 18:47:26.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-2khxs'
Feb  4 18:47:27.504: INFO: stderr: ""
Feb  4 18:47:27.504: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  4 18:47:28.511: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:47:28.511: INFO: Found 0 / 1
Feb  4 18:47:29.532: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:47:29.532: INFO: Found 0 / 1
Feb  4 18:47:30.507: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:47:30.507: INFO: Found 0 / 1
Feb  4 18:47:31.510: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:47:31.510: INFO: Found 0 / 1
Feb  4 18:47:32.513: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:47:32.513: INFO: Found 1 / 1
Feb  4 18:47:32.513: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  4 18:47:32.524: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 18:47:32.524: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  4 18:47:32.524: INFO: wait on redis-master startup in e2e-tests-kubectl-2khxs 
Feb  4 18:47:32.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 logs redis-master-5s9st redis-master --namespace=e2e-tests-kubectl-2khxs'
Feb  4 18:47:32.702: INFO: stderr: ""
Feb  4 18:47:32.702: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Feb 18:47:31.474 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Feb 18:47:31.474 # Server started, Redis version 3.2.12\n1:M 04 Feb 18:47:31.474 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Feb 18:47:31.474 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb  4 18:47:32.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-2khxs'
Feb  4 18:47:32.815: INFO: stderr: ""
Feb  4 18:47:32.816: INFO: stdout: "service/rm2 exposed\n"
Feb  4 18:47:32.838: INFO: Service rm2 in namespace e2e-tests-kubectl-2khxs found.
STEP: exposing service
Feb  4 18:47:34.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-2khxs'
Feb  4 18:47:35.033: INFO: stderr: ""
Feb  4 18:47:35.033: INFO: stdout: "service/rm3 exposed\n"
Feb  4 18:47:35.040: INFO: Service rm3 in namespace e2e-tests-kubectl-2khxs found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:47:37.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2khxs" for this suite.
Feb  4 18:47:59.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:47:59.211: INFO: namespace: e2e-tests-kubectl-2khxs, resource: bindings, ignored listing per whitelist
Feb  4 18:47:59.264: INFO: namespace e2e-tests-kubectl-2khxs deletion completed in 22.181950095s

• [SLOW TEST:32.750 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:47:59.265: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  4 18:47:59.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-m9jx8'
Feb  4 18:47:59.407: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  4 18:47:59.407: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb  4 18:47:59.428: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-kw6jt]
Feb  4 18:47:59.428: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-kw6jt" in namespace "e2e-tests-kubectl-m9jx8" to be "running and ready"
Feb  4 18:47:59.436: INFO: Pod "e2e-test-nginx-rc-kw6jt": Phase="Pending", Reason="", readiness=false. Elapsed: 7.830089ms
Feb  4 18:48:01.439: INFO: Pod "e2e-test-nginx-rc-kw6jt": Phase="Running", Reason="", readiness=true. Elapsed: 2.010939606s
Feb  4 18:48:01.439: INFO: Pod "e2e-test-nginx-rc-kw6jt" satisfied condition "running and ready"
Feb  4 18:48:01.439: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-kw6jt]
Feb  4 18:48:01.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-m9jx8'
Feb  4 18:48:01.625: INFO: stderr: ""
Feb  4 18:48:01.625: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb  4 18:48:01.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-m9jx8'
Feb  4 18:48:01.744: INFO: stderr: ""
Feb  4 18:48:01.744: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:48:01.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m9jx8" for this suite.
Feb  4 18:48:07.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:48:07.914: INFO: namespace: e2e-tests-kubectl-m9jx8, resource: bindings, ignored listing per whitelist
Feb  4 18:48:07.986: INFO: namespace e2e-tests-kubectl-m9jx8 deletion completed in 6.211683252s

• [SLOW TEST:8.721 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:48:07.986: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  4 18:48:10.680: INFO: Successfully updated pod "annotationupdate69cd8cca-28ad-11e9-8d1f-5e319961b721"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:48:14.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jlvcz" for this suite.
Feb  4 18:48:36.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:48:36.951: INFO: namespace: e2e-tests-downward-api-jlvcz, resource: bindings, ignored listing per whitelist
Feb  4 18:48:36.971: INFO: namespace e2e-tests-downward-api-jlvcz deletion completed in 22.202546369s

• [SLOW TEST:28.985 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:48:36.971: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  4 18:48:37.048: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  4 18:48:37.054: INFO: Waiting for terminating namespaces to be deleted...
Feb  4 18:48:37.055: INFO: 
Logging pods the kubelet thinks is on node kube-spawn-default-worker-iurq7e before test
Feb  4 18:48:37.060: INFO: kube-proxy-c42lk from kube-system started at 2019-02-04 18:16:18 +0000 UTC (1 container statuses recorded)
Feb  4 18:48:37.060: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  4 18:48:37.060: INFO: weave-net-8pp25 from kube-system started at 2019-02-04 18:16:21 +0000 UTC (2 container statuses recorded)
Feb  4 18:48:37.060: INFO: 	Container weave ready: true, restart count 0
Feb  4 18:48:37.060: INFO: 	Container weave-npc ready: true, restart count 0
Feb  4 18:48:37.060: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-04 18:17:42 +0000 UTC (1 container statuses recorded)
Feb  4 18:48:37.060: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  4 18:48:37.060: INFO: sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-gnwqq from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:48:37.060: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  4 18:48:37.060: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  4 18:48:37.060: INFO: 
Logging pods the kubelet thinks is on node kube-spawn-default-worker-pqanhr before test
Feb  4 18:48:37.066: INFO: kube-proxy-5n6ck from kube-system started at 2019-02-04 18:16:18 +0000 UTC (1 container statuses recorded)
Feb  4 18:48:37.066: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  4 18:48:37.066: INFO: sonobuoy-e2e-job-b8fb7d0ddcfd4df7 from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:48:37.066: INFO: 	Container e2e ready: true, restart count 0
Feb  4 18:48:37.066: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  4 18:48:37.066: INFO: weave-net-vvvzf from kube-system started at 2019-02-04 18:16:21 +0000 UTC (2 container statuses recorded)
Feb  4 18:48:37.066: INFO: 	Container weave ready: true, restart count 0
Feb  4 18:48:37.066: INFO: 	Container weave-npc ready: true, restart count 0
Feb  4 18:48:37.066: INFO: sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-7dxn8 from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:48:37.066: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  4 18:48:37.066: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15803db475446252], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:48:38.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ww7kc" for this suite.
Feb  4 18:48:44.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:48:44.217: INFO: namespace: e2e-tests-sched-pred-ww7kc, resource: bindings, ignored listing per whitelist
Feb  4 18:48:44.227: INFO: namespace e2e-tests-sched-pred-ww7kc deletion completed in 6.124890376s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.256 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:48:44.227: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7f621308-28ad-11e9-8d1f-5e319961b721
STEP: Creating secret with name s-test-opt-upd-7f62133d-28ad-11e9-8d1f-5e319961b721
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7f621308-28ad-11e9-8d1f-5e319961b721
STEP: Updating secret s-test-opt-upd-7f62133d-28ad-11e9-8d1f-5e319961b721
STEP: Creating secret with name s-test-opt-create-7f621351-28ad-11e9-8d1f-5e319961b721
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:50:09.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4fnb7" for this suite.
Feb  4 18:50:31.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:50:31.724: INFO: namespace: e2e-tests-secrets-4fnb7, resource: bindings, ignored listing per whitelist
Feb  4 18:50:31.807: INFO: namespace e2e-tests-secrets-4fnb7 deletion completed in 22.212719588s

• [SLOW TEST:107.580 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:50:31.807: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:50:31.874: INFO: Creating deployment "nginx-deployment"
Feb  4 18:50:31.877: INFO: Waiting for observed generation 1
Feb  4 18:50:33.913: INFO: Waiting for all required pods to come up
Feb  4 18:50:33.938: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  4 18:50:37.957: INFO: Waiting for deployment "nginx-deployment" to complete
Feb  4 18:50:37.971: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb  4 18:50:38.000: INFO: Updating deployment nginx-deployment
Feb  4 18:50:38.003: INFO: Waiting for observed generation 2
Feb  4 18:50:40.042: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  4 18:50:40.045: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  4 18:50:40.051: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  4 18:50:40.074: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  4 18:50:40.074: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  4 18:50:40.076: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  4 18:50:40.083: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb  4 18:50:40.083: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb  4 18:50:40.089: INFO: Updating deployment nginx-deployment
Feb  4 18:50:40.089: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb  4 18:50:40.105: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  4 18:50:40.138: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  4 18:50:40.220: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tz2qb/deployments/nginx-deployment,UID:bf7f4047-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6914,Generation:3,CreationTimestamp:2019-02-04 18:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-02-04 18:50:38 +0000 UTC 2019-02-04 18:50:31 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-02-04 18:50:40 +0000 UTC 2019-02-04 18:50:40 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb  4 18:50:40.259: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tz2qb/replicasets/nginx-deployment-65bbdb5f8,UID:c325cfa2-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6905,Generation:3,CreationTimestamp:2019-02-04 18:50:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bf7f4047-28ad-11e9-88b2-2600a3ceccc4 0xc0010900c7 0xc0010900c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  4 18:50:40.259: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb  4 18:50:40.259: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tz2qb/replicasets/nginx-deployment-555b55d965,UID:bf8698ab-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6949,Generation:3,CreationTimestamp:2019-02-04 18:50:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bf7f4047-28ad-11e9-88b2-2600a3ceccc4 0xc0008dfff7 0xc0008dfff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb  4 18:50:40.328: INFO: Pod "nginx-deployment-555b55d965-4qvq9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4qvq9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-4qvq9,UID:bfa35d1a-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6807,Generation:0,CreationTimestamp:2019-02-04 18:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001bbb400 0xc001bbb401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bbb4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bbb510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.5,PodIP:10.32.0.6,StartTime:2019-02-04 18:50:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-04 18:50:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://16390e592f645d35d95b71aa9500c4b1671b80b110fc5c3fcfc7e1e40aaad2d0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.328: INFO: Pod "nginx-deployment-555b55d965-4s5q9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4s5q9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-4s5q9,UID:bf9c9b1a-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6799,Generation:0,CreationTimestamp:2019-02-04 18:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001bbb5d0 0xc001bbb5d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bbb780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bbb7a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:34 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:34 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.5,PodIP:10.32.0.3,StartTime:2019-02-04 18:50:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-04 18:50:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://4a0375d970e12bdaa228b203602abff5656cae4bb27b89a2cacbdd01e6dbea16}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.328: INFO: Pod "nginx-deployment-555b55d965-6cc9c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6cc9c,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-6cc9c,UID:c46db1e8-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6940,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001bbb930 0xc001bbb931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bbb9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bbba00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.331: INFO: Pod "nginx-deployment-555b55d965-6g4xs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6g4xs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-6g4xs,UID:c46ddbab-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6942,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001bbba70 0xc001bbba71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001bbbec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001bbbee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.331: INFO: Pod "nginx-deployment-555b55d965-87n7d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-87n7d,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-87n7d,UID:bf9c7097-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6826,Generation:0,CreationTimestamp:2019-02-04 18:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001bbbff0 0xc001bbbff1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001472080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001472240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:10.46.0.6,StartTime:2019-02-04 18:50:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-04 18:50:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://a60190cd1062d8259c0be9a1296cadd1210953ff571626452c6f3ec6037bfb09}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.331: INFO: Pod "nginx-deployment-555b55d965-bskpr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bskpr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-bskpr,UID:c468af80-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6960,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001472300 0xc001472301}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001472360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001472380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.5,PodIP:,StartTime:2019-02-04 18:50:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.331: INFO: Pod "nginx-deployment-555b55d965-bth9d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bth9d,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-bth9d,UID:c46dcfbc-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6941,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001472510 0xc001472511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001472570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001472590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.332: INFO: Pod "nginx-deployment-555b55d965-cfnkn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cfnkn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-cfnkn,UID:c472de9f-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6956,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001472600 0xc001472601}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001472720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001472740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.332: INFO: Pod "nginx-deployment-555b55d965-f2bqf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f2bqf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-f2bqf,UID:bfa38522-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6817,Generation:0,CreationTimestamp:2019-02-04 18:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc0014727c0 0xc0014727c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001472840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014729e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:10.46.0.5,StartTime:2019-02-04 18:50:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-04 18:50:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://efb082146499bf439285a0033775783a470750ad3c73b2ba68b8349082b3f795}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.332: INFO: Pod "nginx-deployment-555b55d965-hpkw4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hpkw4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-hpkw4,UID:c46910ca-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6961,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001472ae0 0xc001472ae1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001472bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001472bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:,StartTime:2019-02-04 18:50:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-j84mw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-j84mw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-j84mw,UID:c472d0d7-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6954,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001472ce0 0xc001472ce1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001472d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001472d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-kxbs7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kxbs7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-kxbs7,UID:c466360c-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6938,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001472eb0 0xc001472eb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001472fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001472fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.5,PodIP:,StartTime:2019-02-04 18:50:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-lhfcb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lhfcb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-lhfcb,UID:c46db900-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6939,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc0014730e0 0xc0014730e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001473140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001473170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-lhr7f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lhr7f,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-lhr7f,UID:c472e311-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6952,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001473fb0 0xc001473fb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001218020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001218670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-s8t9j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s8t9j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-s8t9j,UID:c471dcde-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6953,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001218700 0xc001218701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001218780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012187a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-t97jq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-t97jq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-t97jq,UID:bf971878-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6829,Generation:0,CreationTimestamp:2019-02-04 18:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001218b70 0xc001218b71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001218bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001218bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:10.46.0.2,StartTime:2019-02-04 18:50:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-04 18:50:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://c9493ff6924ff33084ba81668ac0c71d72a768e64d83f82954dc0d670150d933}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-tczzh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tczzh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-tczzh,UID:bf988b9f-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6823,Generation:0,CreationTimestamp:2019-02-04 18:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001218cc0 0xc001218cc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001218d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012192c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:10.46.0.3,StartTime:2019-02-04 18:50:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-04 18:50:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://9db7722a1f312c5bc0f594dcc0327e159700d3af70281397abe24f9d78cbf071}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-v7qk2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-v7qk2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-v7qk2,UID:bf98d3d5-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6810,Generation:0,CreationTimestamp:2019-02-04 18:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001219530 0xc001219531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001219590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012195b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.5,PodIP:10.32.0.4,StartTime:2019-02-04 18:50:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-04 18:50:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://b4c20232856cab2f9216adf7e3c7762ebb6fd53beca7dbabbc9d4faf94bf8415}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.333: INFO: Pod "nginx-deployment-555b55d965-vzxwh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vzxwh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-vzxwh,UID:c471a345-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6948,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc0012196d0 0xc0012196d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001219730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001219750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.334: INFO: Pod "nginx-deployment-555b55d965-zn9lv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zn9lv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-555b55d965-zn9lv,UID:bf9c900d-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6820,Generation:0,CreationTimestamp:2019-02-04 18:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bf8698ab-28ad-11e9-88b2-2600a3ceccc4 0xc001219870 0xc001219871}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001219910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001219930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:32 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:10.46.0.4,StartTime:2019-02-04 18:50:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-04 18:50:34 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://f5be5917782e39946072bfa2fbe84c3c603c8bdbf117625c31f4fd1564cb98c8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.334: INFO: Pod "nginx-deployment-65bbdb5f8-4jtm6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4jtm6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-4jtm6,UID:c46bae25-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6931,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc001219a70 0xc001219a71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001219b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001219b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.334: INFO: Pod "nginx-deployment-65bbdb5f8-5mzth" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5mzth,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-5mzth,UID:c4703ca8-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6943,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc001219c20 0xc001219c21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001219ca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001219cc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.334: INFO: Pod "nginx-deployment-65bbdb5f8-78nlk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-78nlk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-78nlk,UID:c46b5880-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6928,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc001219da0 0xc001219da1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001219e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001219e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.334: INFO: Pod "nginx-deployment-65bbdb5f8-fn986" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-fn986,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-fn986,UID:c35289c1-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6889,Generation:0,CreationTimestamp:2019-02-04 18:50:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc001219eb0 0xc001219eb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001219fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001219fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.5,PodIP:,StartTime:2019-02-04 18:50:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.334: INFO: Pod "nginx-deployment-65bbdb5f8-h985m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-h985m,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-h985m,UID:c32bb5cb-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6861,Generation:0,CreationTimestamp:2019-02-04 18:50:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112a400 0xc00112a401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112a4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112a510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:,StartTime:2019-02-04 18:50:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.334: INFO: Pod "nginx-deployment-65bbdb5f8-jsqcs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jsqcs,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-jsqcs,UID:c470ebc1-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6947,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112a9f0 0xc00112a9f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112aa70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112aa90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.334: INFO: Pod "nginx-deployment-65bbdb5f8-k6hwx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-k6hwx,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-k6hwx,UID:c47059c4-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6944,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112ad70 0xc00112ad71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112adf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112ae50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.335: INFO: Pod "nginx-deployment-65bbdb5f8-khpxh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-khpxh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-khpxh,UID:c33407f5-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6862,Generation:0,CreationTimestamp:2019-02-04 18:50:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112af30 0xc00112af31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112b010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112b030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.5,PodIP:,StartTime:2019-02-04 18:50:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.335: INFO: Pod "nginx-deployment-65bbdb5f8-lndg5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lndg5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-lndg5,UID:c4710364-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6950,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112b180 0xc00112b181}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112b1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112b210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.335: INFO: Pod "nginx-deployment-65bbdb5f8-mtbq7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mtbq7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-mtbq7,UID:c3343676-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6869,Generation:0,CreationTimestamp:2019-02-04 18:50:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112b2c0 0xc00112b2c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112b3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112b3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:,StartTime:2019-02-04 18:50:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.335: INFO: Pod "nginx-deployment-65bbdb5f8-p72n2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-p72n2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-p72n2,UID:c4675341-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6920,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112b530 0xc00112b531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112b5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112b6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.349: INFO: Pod "nginx-deployment-65bbdb5f8-p89fh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-p89fh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-p89fh,UID:c4780927-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6959,Generation:0,CreationTimestamp:2019-02-04 18:50:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112b760 0xc00112b761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112b7d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112b7f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:40 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  4 18:50:40.353: INFO: Pod "nginx-deployment-65bbdb5f8-rlgxr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rlgxr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-tz2qb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tz2qb/pods/nginx-deployment-65bbdb5f8-rlgxr,UID:c3547942-28ad-11e9-88b2-2600a3ceccc4,ResourceVersion:6891,Generation:0,CreationTimestamp:2019-02-04 18:50:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 c325cfa2-28ad-11e9-88b2-2600a3ceccc4 0xc00112b8f0 0xc00112b8f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rh89g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rh89g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-rh89g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00112b960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00112b980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 18:50:38 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:,StartTime:2019-02-04 18:50:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:50:40.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-tz2qb" for this suite.
Feb  4 18:50:50.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:50:50.520: INFO: namespace: e2e-tests-deployment-tz2qb, resource: bindings, ignored listing per whitelist
Feb  4 18:50:50.546: INFO: namespace e2e-tests-deployment-tz2qb deletion completed in 10.16417975s

• [SLOW TEST:18.739 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:50:50.546: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-caadd143-28ad-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 18:50:50.649: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-caaf01cd-28ad-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-6blcz" to be "success or failure"
Feb  4 18:50:50.682: INFO: Pod "pod-projected-configmaps-caaf01cd-28ad-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 33.050473ms
Feb  4 18:50:52.689: INFO: Pod "pod-projected-configmaps-caaf01cd-28ad-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040139666s
STEP: Saw pod success
Feb  4 18:50:52.689: INFO: Pod "pod-projected-configmaps-caaf01cd-28ad-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:50:52.691: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-projected-configmaps-caaf01cd-28ad-11e9-8d1f-5e319961b721 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 18:50:52.727: INFO: Waiting for pod pod-projected-configmaps-caaf01cd-28ad-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:50:52.734: INFO: Pod pod-projected-configmaps-caaf01cd-28ad-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:50:52.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6blcz" for this suite.
Feb  4 18:50:58.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:50:58.837: INFO: namespace: e2e-tests-projected-6blcz, resource: bindings, ignored listing per whitelist
Feb  4 18:50:58.897: INFO: namespace e2e-tests-projected-6blcz deletion completed in 6.160063293s

• [SLOW TEST:8.351 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:50:58.897: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  4 18:50:58.974: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  4 18:50:59.024: INFO: Waiting for terminating namespaces to be deleted...
Feb  4 18:50:59.030: INFO: 
Logging pods the kubelet thinks is on node kube-spawn-default-worker-iurq7e before test
Feb  4 18:50:59.036: INFO: weave-net-8pp25 from kube-system started at 2019-02-04 18:16:21 +0000 UTC (2 container statuses recorded)
Feb  4 18:50:59.036: INFO: 	Container weave ready: true, restart count 0
Feb  4 18:50:59.036: INFO: 	Container weave-npc ready: true, restart count 0
Feb  4 18:50:59.036: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-04 18:17:42 +0000 UTC (1 container statuses recorded)
Feb  4 18:50:59.036: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  4 18:50:59.036: INFO: kube-proxy-c42lk from kube-system started at 2019-02-04 18:16:18 +0000 UTC (1 container statuses recorded)
Feb  4 18:50:59.036: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  4 18:50:59.036: INFO: sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-gnwqq from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:50:59.036: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  4 18:50:59.037: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  4 18:50:59.037: INFO: 
Logging pods the kubelet thinks is on node kube-spawn-default-worker-pqanhr before test
Feb  4 18:50:59.044: INFO: sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-7dxn8 from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:50:59.044: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  4 18:50:59.044: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  4 18:50:59.044: INFO: kube-proxy-5n6ck from kube-system started at 2019-02-04 18:16:18 +0000 UTC (1 container statuses recorded)
Feb  4 18:50:59.044: INFO: 	Container kube-proxy ready: true, restart count 0
Feb  4 18:50:59.044: INFO: sonobuoy-e2e-job-b8fb7d0ddcfd4df7 from heptio-sonobuoy started at 2019-02-04 18:17:50 +0000 UTC (2 container statuses recorded)
Feb  4 18:50:59.044: INFO: 	Container e2e ready: true, restart count 0
Feb  4 18:50:59.044: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  4 18:50:59.044: INFO: weave-net-vvvzf from kube-system started at 2019-02-04 18:16:21 +0000 UTC (2 container statuses recorded)
Feb  4 18:50:59.044: INFO: 	Container weave ready: true, restart count 0
Feb  4 18:50:59.044: INFO: 	Container weave-npc ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node kube-spawn-default-worker-iurq7e
STEP: verifying the node has the label node kube-spawn-default-worker-pqanhr
Feb  4 18:50:59.101: INFO: Pod sonobuoy requesting resource cpu=0m on Node kube-spawn-default-worker-iurq7e
Feb  4 18:50:59.101: INFO: Pod sonobuoy-e2e-job-b8fb7d0ddcfd4df7 requesting resource cpu=0m on Node kube-spawn-default-worker-pqanhr
Feb  4 18:50:59.101: INFO: Pod sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-7dxn8 requesting resource cpu=0m on Node kube-spawn-default-worker-pqanhr
Feb  4 18:50:59.101: INFO: Pod sonobuoy-systemd-logs-daemon-set-f73ce7c1f6ca472e-gnwqq requesting resource cpu=0m on Node kube-spawn-default-worker-iurq7e
Feb  4 18:50:59.101: INFO: Pod kube-proxy-5n6ck requesting resource cpu=0m on Node kube-spawn-default-worker-pqanhr
Feb  4 18:50:59.101: INFO: Pod kube-proxy-c42lk requesting resource cpu=0m on Node kube-spawn-default-worker-iurq7e
Feb  4 18:50:59.101: INFO: Pod weave-net-8pp25 requesting resource cpu=20m on Node kube-spawn-default-worker-iurq7e
Feb  4 18:50:59.101: INFO: Pod weave-net-vvvzf requesting resource cpu=20m on Node kube-spawn-default-worker-pqanhr
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cfb9b827-28ad-11e9-8d1f-5e319961b721.15803dd586fc713b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-w8hkk/filler-pod-cfb9b827-28ad-11e9-8d1f-5e319961b721 to kube-spawn-default-worker-iurq7e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cfb9b827-28ad-11e9-8d1f-5e319961b721.15803dd5c0537bbd], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cfb9b827-28ad-11e9-8d1f-5e319961b721.15803dd5c53f967c], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cfb9b827-28ad-11e9-8d1f-5e319961b721.15803dd5d14e358c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cfbade30-28ad-11e9-8d1f-5e319961b721.15803dd587c618c6], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-w8hkk/filler-pod-cfbade30-28ad-11e9-8d1f-5e319961b721 to kube-spawn-default-worker-pqanhr]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cfbade30-28ad-11e9-8d1f-5e319961b721.15803dd5c008f850], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cfbade30-28ad-11e9-8d1f-5e319961b721.15803dd5c5491d30], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cfbade30-28ad-11e9-8d1f-5e319961b721.15803dd5d1d6a840], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15803dd606defb7d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node kube-spawn-default-worker-iurq7e
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node kube-spawn-default-worker-pqanhr
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:51:02.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-w8hkk" for this suite.
Feb  4 18:51:08.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:51:08.626: INFO: namespace: e2e-tests-sched-pred-w8hkk, resource: bindings, ignored listing per whitelist
Feb  4 18:51:08.666: INFO: namespace e2e-tests-sched-pred-w8hkk deletion completed in 6.149411745s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.770 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:51:08.667: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-d576b063-28ad-11e9-8d1f-5e319961b721
STEP: Creating configMap with name cm-test-opt-upd-d576b09d-28ad-11e9-8d1f-5e319961b721
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d576b063-28ad-11e9-8d1f-5e319961b721
STEP: Updating configmap cm-test-opt-upd-d576b09d-28ad-11e9-8d1f-5e319961b721
STEP: Creating configMap with name cm-test-opt-create-d576b0b5-28ad-11e9-8d1f-5e319961b721
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:51:12.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-99n8t" for this suite.
Feb  4 18:51:35.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:51:35.046: INFO: namespace: e2e-tests-projected-99n8t, resource: bindings, ignored listing per whitelist
Feb  4 18:51:35.085: INFO: namespace e2e-tests-projected-99n8t deletion completed in 22.110389537s

• [SLOW TEST:26.418 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:51:35.085: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:51:35.231: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  4 18:51:35.244: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:35.246: INFO: Number of nodes with available pods: 0
Feb  4 18:51:35.246: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:51:36.259: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:36.276: INFO: Number of nodes with available pods: 0
Feb  4 18:51:36.276: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:51:37.336: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:37.352: INFO: Number of nodes with available pods: 1
Feb  4 18:51:37.352: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 18:51:38.254: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:38.270: INFO: Number of nodes with available pods: 2
Feb  4 18:51:38.270: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  4 18:51:38.348: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:38.348: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:38.363: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:39.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:39.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:39.388: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:40.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:40.371: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:40.385: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:41.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:41.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:41.381: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:42.373: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:42.373: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:42.389: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:43.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:43.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:43.402: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:44.369: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:44.369: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:44.380: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:45.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:45.376: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:45.405: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:46.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:46.371: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:46.387: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:47.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:47.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:47.390: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:48.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:48.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:48.382: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:49.374: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:49.374: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:49.387: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:50.367: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:50.368: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:50.373: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:51.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:51.371: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:51.384: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:52.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:52.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:52.379: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:53.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:53.371: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:53.382: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:54.369: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:54.369: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:54.385: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:55.372: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:55.372: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:55.392: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:56.368: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:56.368: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:56.388: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:57.369: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:57.369: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:57.379: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:58.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:58.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:58.385: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:51:59.377: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:59.377: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:51:59.406: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:00.366: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:00.366: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:00.383: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:01.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:01.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:01.383: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:02.373: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:02.374: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:02.389: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:03.372: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:03.372: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:03.385: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:04.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:04.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:04.382: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:05.366: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:05.366: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:05.373: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:06.385: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:06.385: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:06.397: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:07.372: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:07.372: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:07.381: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:08.372: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:08.372: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:08.389: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:09.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:09.371: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:09.381: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:10.391: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:10.395: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:10.417: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:11.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:11.370: INFO: Wrong image for pod: daemon-set-zm7d8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:11.370: INFO: Pod daemon-set-zm7d8 is not available
Feb  4 18:52:11.386: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:12.372: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:12.373: INFO: Pod daemon-set-qcthx is not available
Feb  4 18:52:12.392: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:13.368: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:13.368: INFO: Pod daemon-set-qcthx is not available
Feb  4 18:52:13.378: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:14.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:14.382: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:15.375: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:15.392: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:16.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:16.380: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:17.365: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:17.368: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:18.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:18.383: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:19.372: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:19.382: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:20.368: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:20.375: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:21.365: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:21.368: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:22.369: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:22.382: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:23.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:23.380: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:24.369: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:24.380: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:25.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:25.382: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:26.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:26.383: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:27.378: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:27.395: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:28.399: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:28.410: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:29.367: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:29.372: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:30.368: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:30.374: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:31.400: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:31.407: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:32.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:32.385: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:33.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:33.382: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:34.372: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:34.386: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:35.373: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:35.385: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:36.369: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:36.379: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:37.417: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:37.432: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:38.389: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:38.401: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:39.372: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:39.397: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:40.378: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:40.392: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:41.371: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:41.381: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:42.369: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:42.381: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:43.370: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:43.380: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:44.367: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:44.372: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:45.367: INFO: Wrong image for pod: daemon-set-n6sbw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  4 18:52:45.367: INFO: Pod daemon-set-n6sbw is not available
Feb  4 18:52:45.374: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:46.398: INFO: Pod daemon-set-sgkpc is not available
Feb  4 18:52:46.412: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  4 18:52:46.428: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:46.449: INFO: Number of nodes with available pods: 1
Feb  4 18:52:46.449: INFO: Node kube-spawn-default-worker-pqanhr is running more than one daemon pod
Feb  4 18:52:47.466: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:47.474: INFO: Number of nodes with available pods: 1
Feb  4 18:52:47.474: INFO: Node kube-spawn-default-worker-pqanhr is running more than one daemon pod
Feb  4 18:52:48.461: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 18:52:48.498: INFO: Number of nodes with available pods: 2
Feb  4 18:52:48.499: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-x8gn7, will wait for the garbage collector to delete the pods
Feb  4 18:52:48.624: INFO: Deleting DaemonSet.extensions daemon-set took: 13.217688ms
Feb  4 18:52:48.724: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.331984ms
Feb  4 18:52:52.428: INFO: Number of nodes with available pods: 0
Feb  4 18:52:52.428: INFO: Number of running nodes: 0, number of available pods: 0
Feb  4 18:52:52.434: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-x8gn7/daemonsets","resourceVersion":"7583"},"items":null}

Feb  4 18:52:52.437: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-x8gn7/pods","resourceVersion":"7583"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:52:52.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-x8gn7" for this suite.
Feb  4 18:52:58.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:52:58.668: INFO: namespace: e2e-tests-daemonsets-x8gn7, resource: bindings, ignored listing per whitelist
Feb  4 18:52:58.701: INFO: namespace e2e-tests-daemonsets-x8gn7 deletion completed in 6.252389153s

• [SLOW TEST:83.616 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:52:58.702: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1713162e-28ae-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 18:52:58.821: INFO: Waiting up to 5m0s for pod "pod-secrets-1714a4cd-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-6mlfr" to be "success or failure"
Feb  4 18:52:58.831: INFO: Pod "pod-secrets-1714a4cd-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 9.814312ms
Feb  4 18:53:00.834: INFO: Pod "pod-secrets-1714a4cd-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012553381s
STEP: Saw pod success
Feb  4 18:53:00.834: INFO: Pod "pod-secrets-1714a4cd-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:53:00.837: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-secrets-1714a4cd-28ae-11e9-8d1f-5e319961b721 container secret-volume-test: <nil>
STEP: delete the pod
Feb  4 18:53:00.923: INFO: Waiting for pod pod-secrets-1714a4cd-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:53:00.927: INFO: Pod pod-secrets-1714a4cd-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:53:00.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6mlfr" for this suite.
Feb  4 18:53:06.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:53:07.031: INFO: namespace: e2e-tests-secrets-6mlfr, resource: bindings, ignored listing per whitelist
Feb  4 18:53:07.109: INFO: namespace e2e-tests-secrets-6mlfr deletion completed in 6.177515814s

• [SLOW TEST:8.408 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:53:07.109: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zb46w
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  4 18:53:07.187: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  4 18:53:29.461: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.32.0.3:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zb46w PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 18:53:29.461: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 18:53:29.566: INFO: Found all expected endpoints: [netserver-0]
Feb  4 18:53:29.569: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.46.0.2:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zb46w PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 18:53:29.569: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 18:53:29.650: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:53:29.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zb46w" for this suite.
Feb  4 18:53:51.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:53:51.721: INFO: namespace: e2e-tests-pod-network-test-zb46w, resource: bindings, ignored listing per whitelist
Feb  4 18:53:51.750: INFO: namespace e2e-tests-pod-network-test-zb46w deletion completed in 22.097569411s

• [SLOW TEST:44.641 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:53:51.750: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  4 18:53:51.843: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:53:54.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pn5z8" for this suite.
Feb  4 18:54:00.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:54:00.467: INFO: namespace: e2e-tests-init-container-pn5z8, resource: bindings, ignored listing per whitelist
Feb  4 18:54:00.469: INFO: namespace e2e-tests-init-container-pn5z8 deletion completed in 6.157334067s

• [SLOW TEST:8.719 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:54:00.470: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0204 18:54:06.596688      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  4 18:54:06.596: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:54:06.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w2wkb" for this suite.
Feb  4 18:54:12.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:54:12.834: INFO: namespace: e2e-tests-gc-w2wkb, resource: bindings, ignored listing per whitelist
Feb  4 18:54:12.885: INFO: namespace e2e-tests-gc-w2wkb deletion completed in 6.286373615s

• [SLOW TEST:12.416 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:54:12.886: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-fx8jx
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  4 18:54:12.981: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  4 18:54:35.113: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.4:8080/dial?request=hostName&protocol=http&host=10.46.0.2&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-fx8jx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 18:54:35.113: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 18:54:35.221: INFO: Waiting for endpoints: map[]
Feb  4 18:54:35.223: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.4:8080/dial?request=hostName&protocol=http&host=10.32.0.3&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-fx8jx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 18:54:35.223: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 18:54:35.360: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:54:35.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-fx8jx" for this suite.
Feb  4 18:54:57.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:54:57.434: INFO: namespace: e2e-tests-pod-network-test-fx8jx, resource: bindings, ignored listing per whitelist
Feb  4 18:54:57.522: INFO: namespace e2e-tests-pod-network-test-fx8jx deletion completed in 22.159932216s

• [SLOW TEST:44.636 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:54:57.522: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 18:54:57.656: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:54:58.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-d7njv" for this suite.
Feb  4 18:55:04.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:55:04.866: INFO: namespace: e2e-tests-custom-resource-definition-d7njv, resource: bindings, ignored listing per whitelist
Feb  4 18:55:04.919: INFO: namespace e2e-tests-custom-resource-definition-d7njv deletion completed in 6.083177282s

• [SLOW TEST:7.397 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:55:04.919: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-624a841e-28ae-11e9-8d1f-5e319961b721
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:55:07.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ljwdn" for this suite.
Feb  4 18:55:29.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:55:29.254: INFO: namespace: e2e-tests-configmap-ljwdn, resource: bindings, ignored listing per whitelist
Feb  4 18:55:29.316: INFO: namespace e2e-tests-configmap-ljwdn deletion completed in 22.187495889s

• [SLOW TEST:24.397 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:55:29.316: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0204 18:56:00.049735      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  4 18:56:00.049: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:56:00.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l2hwm" for this suite.
Feb  4 18:56:06.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:56:06.185: INFO: namespace: e2e-tests-gc-l2hwm, resource: bindings, ignored listing per whitelist
Feb  4 18:56:06.219: INFO: namespace e2e-tests-gc-l2hwm deletion completed in 6.154363591s

• [SLOW TEST:36.903 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:56:06.220: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 18:56:06.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86da88a9-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-22d8h" to be "success or failure"
Feb  4 18:56:06.407: INFO: Pod "downwardapi-volume-86da88a9-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 55.938302ms
Feb  4 18:56:08.415: INFO: Pod "downwardapi-volume-86da88a9-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063219583s
Feb  4 18:56:10.424: INFO: Pod "downwardapi-volume-86da88a9-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.072589021s
STEP: Saw pod success
Feb  4 18:56:10.424: INFO: Pod "downwardapi-volume-86da88a9-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:56:10.433: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-86da88a9-28ae-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 18:56:10.532: INFO: Waiting for pod downwardapi-volume-86da88a9-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:56:10.539: INFO: Pod downwardapi-volume-86da88a9-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:56:10.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-22d8h" for this suite.
Feb  4 18:56:16.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:56:16.665: INFO: namespace: e2e-tests-projected-22d8h, resource: bindings, ignored listing per whitelist
Feb  4 18:56:16.776: INFO: namespace e2e-tests-projected-22d8h deletion completed in 6.232920447s

• [SLOW TEST:10.556 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:56:16.776: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  4 18:56:16.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-srwc2'
Feb  4 18:56:16.993: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  4 18:56:16.993: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Feb  4 18:56:17.016: INFO: scanned /root for discovery docs: <nil>
Feb  4 18:56:17.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-srwc2'
Feb  4 18:56:32.983: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  4 18:56:32.983: INFO: stdout: "Created e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056\nScaling up e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb  4 18:56:32.983: INFO: stdout: "Created e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056\nScaling up e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb  4 18:56:32.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-srwc2'
Feb  4 18:56:33.099: INFO: stderr: ""
Feb  4 18:56:33.099: INFO: stdout: "e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056-9xdn2 "
Feb  4 18:56:33.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056-9xdn2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-srwc2'
Feb  4 18:56:33.162: INFO: stderr: ""
Feb  4 18:56:33.162: INFO: stdout: "true"
Feb  4 18:56:33.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056-9xdn2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-srwc2'
Feb  4 18:56:33.222: INFO: stderr: ""
Feb  4 18:56:33.222: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb  4 18:56:33.222: INFO: e2e-test-nginx-rc-0a4d7a3059cfe481237b898a8b5ff056-9xdn2 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb  4 18:56:33.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-srwc2'
Feb  4 18:56:33.325: INFO: stderr: ""
Feb  4 18:56:33.326: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:56:33.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-srwc2" for this suite.
Feb  4 18:56:39.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:56:39.570: INFO: namespace: e2e-tests-kubectl-srwc2, resource: bindings, ignored listing per whitelist
Feb  4 18:56:39.576: INFO: namespace e2e-tests-kubectl-srwc2 deletion completed in 6.188382439s

• [SLOW TEST:22.800 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:56:39.578: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:56:45.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-2cmt5" for this suite.
Feb  4 18:56:52.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:56:52.089: INFO: namespace: e2e-tests-namespaces-2cmt5, resource: bindings, ignored listing per whitelist
Feb  4 18:56:52.150: INFO: namespace e2e-tests-namespaces-2cmt5 deletion completed in 6.194214986s
STEP: Destroying namespace "e2e-tests-nsdeletetest-2kvx9" for this suite.
Feb  4 18:56:52.153: INFO: Namespace e2e-tests-nsdeletetest-2kvx9 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-gxl59" for this suite.
Feb  4 18:56:58.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:56:58.266: INFO: namespace: e2e-tests-nsdeletetest-gxl59, resource: bindings, ignored listing per whitelist
Feb  4 18:56:58.354: INFO: namespace e2e-tests-nsdeletetest-gxl59 deletion completed in 6.201394633s

• [SLOW TEST:18.776 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:56:58.354: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a5ee55ef-28ae-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 18:56:58.511: INFO: Waiting up to 5m0s for pod "pod-secrets-a5f1a703-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-mn55f" to be "success or failure"
Feb  4 18:56:58.530: INFO: Pod "pod-secrets-a5f1a703-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 18.808439ms
Feb  4 18:57:00.546: INFO: Pod "pod-secrets-a5f1a703-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03520185s
STEP: Saw pod success
Feb  4 18:57:00.554: INFO: Pod "pod-secrets-a5f1a703-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:57:00.562: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-secrets-a5f1a703-28ae-11e9-8d1f-5e319961b721 container secret-volume-test: <nil>
STEP: delete the pod
Feb  4 18:57:00.596: INFO: Waiting for pod pod-secrets-a5f1a703-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:57:00.600: INFO: Pod pod-secrets-a5f1a703-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:57:00.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mn55f" for this suite.
Feb  4 18:57:06.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:57:06.672: INFO: namespace: e2e-tests-secrets-mn55f, resource: bindings, ignored listing per whitelist
Feb  4 18:57:06.784: INFO: namespace e2e-tests-secrets-mn55f deletion completed in 6.18158346s

• [SLOW TEST:8.430 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:57:06.785: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  4 18:57:06.944: INFO: Waiting up to 5m0s for pod "pod-aaf859cd-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-njncc" to be "success or failure"
Feb  4 18:57:06.962: INFO: Pod "pod-aaf859cd-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 17.847431ms
Feb  4 18:57:08.968: INFO: Pod "pod-aaf859cd-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024067279s
STEP: Saw pod success
Feb  4 18:57:08.968: INFO: Pod "pod-aaf859cd-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:57:08.977: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-aaf859cd-28ae-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:57:09.071: INFO: Waiting for pod pod-aaf859cd-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:57:09.080: INFO: Pod pod-aaf859cd-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:57:09.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-njncc" for this suite.
Feb  4 18:57:15.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:57:15.149: INFO: namespace: e2e-tests-emptydir-njncc, resource: bindings, ignored listing per whitelist
Feb  4 18:57:15.261: INFO: namespace e2e-tests-emptydir-njncc deletion completed in 6.175764222s

• [SLOW TEST:8.476 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:57:15.262: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  4 18:57:15.396: INFO: Waiting up to 5m0s for pod "pod-b0021c29-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-j4tl9" to be "success or failure"
Feb  4 18:57:15.410: INFO: Pod "pod-b0021c29-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 13.758611ms
Feb  4 18:57:17.421: INFO: Pod "pod-b0021c29-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0257132s
STEP: Saw pod success
Feb  4 18:57:17.421: INFO: Pod "pod-b0021c29-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:57:17.424: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-b0021c29-28ae-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:57:17.462: INFO: Waiting for pod pod-b0021c29-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:57:17.466: INFO: Pod pod-b0021c29-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:57:17.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j4tl9" for this suite.
Feb  4 18:57:23.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:57:23.625: INFO: namespace: e2e-tests-emptydir-j4tl9, resource: bindings, ignored listing per whitelist
Feb  4 18:57:23.628: INFO: namespace e2e-tests-emptydir-j4tl9 deletion completed in 6.158805082s

• [SLOW TEST:8.366 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:57:23.628: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b4f85300-28ae-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 18:57:23.734: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b4f8dd31-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-f4gr4" to be "success or failure"
Feb  4 18:57:23.743: INFO: Pod "pod-projected-configmaps-b4f8dd31-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 9.057292ms
Feb  4 18:57:25.750: INFO: Pod "pod-projected-configmaps-b4f8dd31-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015967176s
Feb  4 18:57:27.757: INFO: Pod "pod-projected-configmaps-b4f8dd31-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023476725s
STEP: Saw pod success
Feb  4 18:57:27.758: INFO: Pod "pod-projected-configmaps-b4f8dd31-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:57:27.768: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-projected-configmaps-b4f8dd31-28ae-11e9-8d1f-5e319961b721 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 18:57:27.949: INFO: Waiting for pod pod-projected-configmaps-b4f8dd31-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:57:27.958: INFO: Pod pod-projected-configmaps-b4f8dd31-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:57:27.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f4gr4" for this suite.
Feb  4 18:57:34.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:57:34.100: INFO: namespace: e2e-tests-projected-f4gr4, resource: bindings, ignored listing per whitelist
Feb  4 18:57:34.107: INFO: namespace e2e-tests-projected-f4gr4 deletion completed in 6.137252884s

• [SLOW TEST:10.479 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:57:34.107: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb  4 18:57:34.212: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-030580780 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:57:34.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bx4v9" for this suite.
Feb  4 18:57:40.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:57:40.455: INFO: namespace: e2e-tests-kubectl-bx4v9, resource: bindings, ignored listing per whitelist
Feb  4 18:57:40.506: INFO: namespace e2e-tests-kubectl-bx4v9 deletion completed in 6.13432566s

• [SLOW TEST:6.399 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:57:40.506: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-q4t5c
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-q4t5c to expose endpoints map[]
Feb  4 18:57:40.661: INFO: Get endpoints failed (9.499328ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb  4 18:57:41.668: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-q4t5c exposes endpoints map[] (1.016362813s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-q4t5c
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-q4t5c to expose endpoints map[pod1:[80]]
Feb  4 18:57:44.807: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-q4t5c exposes endpoints map[pod1:[80]] (3.111016708s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-q4t5c
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-q4t5c to expose endpoints map[pod1:[80] pod2:[80]]
Feb  4 18:57:46.981: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-q4t5c exposes endpoints map[pod2:[80] pod1:[80]] (2.148142626s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-q4t5c
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-q4t5c to expose endpoints map[pod2:[80]]
Feb  4 18:57:47.062: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-q4t5c exposes endpoints map[pod2:[80]] (44.259435ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-q4t5c
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-q4t5c to expose endpoints map[]
Feb  4 18:57:47.084: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-q4t5c exposes endpoints map[] (12.180894ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:57:47.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-q4t5c" for this suite.
Feb  4 18:57:53.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:57:53.299: INFO: namespace: e2e-tests-services-q4t5c, resource: bindings, ignored listing per whitelist
Feb  4 18:57:53.316: INFO: namespace e2e-tests-services-q4t5c deletion completed in 6.132474254s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:12.810 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:57:53.316: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  4 18:57:53.423: INFO: Waiting up to 5m0s for pod "pod-c6acc55c-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-d5jsl" to be "success or failure"
Feb  4 18:57:53.430: INFO: Pod "pod-c6acc55c-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 6.376178ms
Feb  4 18:57:55.447: INFO: Pod "pod-c6acc55c-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023664996s
Feb  4 18:57:57.459: INFO: Pod "pod-c6acc55c-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035689807s
STEP: Saw pod success
Feb  4 18:57:57.459: INFO: Pod "pod-c6acc55c-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:57:57.477: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-c6acc55c-28ae-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:57:57.573: INFO: Waiting for pod pod-c6acc55c-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:57:57.578: INFO: Pod pod-c6acc55c-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:57:57.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-d5jsl" for this suite.
Feb  4 18:58:03.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:58:03.864: INFO: namespace: e2e-tests-emptydir-d5jsl, resource: bindings, ignored listing per whitelist
Feb  4 18:58:03.875: INFO: namespace e2e-tests-emptydir-d5jsl deletion completed in 6.288112401s

• [SLOW TEST:10.559 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:58:03.876: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb  4 18:58:03.963: INFO: Waiting up to 5m0s for pod "client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-containers-nzl4h" to be "success or failure"
Feb  4 18:58:03.992: INFO: Pod "client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 28.18746ms
Feb  4 18:58:05.999: INFO: Pod "client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035345766s
Feb  4 18:58:08.003: INFO: Pod "client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039565088s
Feb  4 18:58:10.013: INFO: Pod "client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050080285s
STEP: Saw pod success
Feb  4 18:58:10.014: INFO: Pod "client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:58:10.023: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:58:10.144: INFO: Waiting for pod client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:58:10.151: INFO: Pod client-containers-ccf50029-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:58:10.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nzl4h" for this suite.
Feb  4 18:58:16.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:58:16.326: INFO: namespace: e2e-tests-containers-nzl4h, resource: bindings, ignored listing per whitelist
Feb  4 18:58:16.330: INFO: namespace e2e-tests-containers-nzl4h deletion completed in 6.174248132s

• [SLOW TEST:12.454 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:58:16.330: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  4 18:58:16.452: INFO: Waiting up to 5m0s for pod "pod-d465e115-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-cqk9h" to be "success or failure"
Feb  4 18:58:16.461: INFO: Pod "pod-d465e115-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 8.964175ms
Feb  4 18:58:18.467: INFO: Pod "pod-d465e115-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015363948s
STEP: Saw pod success
Feb  4 18:58:18.468: INFO: Pod "pod-d465e115-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:58:18.477: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-d465e115-28ae-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:58:18.514: INFO: Waiting for pod pod-d465e115-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:58:18.522: INFO: Pod pod-d465e115-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:58:18.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cqk9h" for this suite.
Feb  4 18:58:24.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:58:24.645: INFO: namespace: e2e-tests-emptydir-cqk9h, resource: bindings, ignored listing per whitelist
Feb  4 18:58:24.716: INFO: namespace e2e-tests-emptydir-cqk9h deletion completed in 6.191170503s

• [SLOW TEST:8.386 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:58:24.716: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d966159b-28ae-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 18:58:24.854: INFO: Waiting up to 5m0s for pod "pod-configmaps-d9684c7d-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-b2xrw" to be "success or failure"
Feb  4 18:58:24.870: INFO: Pod "pod-configmaps-d9684c7d-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 11.997272ms
Feb  4 18:58:26.894: INFO: Pod "pod-configmaps-d9684c7d-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035335789s
Feb  4 18:58:28.901: INFO: Pod "pod-configmaps-d9684c7d-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042351353s
STEP: Saw pod success
Feb  4 18:58:28.901: INFO: Pod "pod-configmaps-d9684c7d-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:58:28.906: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-configmaps-d9684c7d-28ae-11e9-8d1f-5e319961b721 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 18:58:28.944: INFO: Waiting for pod pod-configmaps-d9684c7d-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:58:28.951: INFO: Pod pod-configmaps-d9684c7d-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:58:28.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b2xrw" for this suite.
Feb  4 18:58:34.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:58:35.085: INFO: namespace: e2e-tests-configmap-b2xrw, resource: bindings, ignored listing per whitelist
Feb  4 18:58:35.099: INFO: namespace e2e-tests-configmap-b2xrw deletion completed in 6.145722011s

• [SLOW TEST:10.382 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:58:35.100: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  4 18:58:35.213: INFO: Waiting up to 5m0s for pod "pod-df958fda-28ae-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-kzvlb" to be "success or failure"
Feb  4 18:58:35.226: INFO: Pod "pod-df958fda-28ae-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 12.479414ms
Feb  4 18:58:37.234: INFO: Pod "pod-df958fda-28ae-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020747744s
STEP: Saw pod success
Feb  4 18:58:37.234: INFO: Pod "pod-df958fda-28ae-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 18:58:37.247: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-df958fda-28ae-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 18:58:37.325: INFO: Waiting for pod pod-df958fda-28ae-11e9-8d1f-5e319961b721 to disappear
Feb  4 18:58:37.330: INFO: Pod pod-df958fda-28ae-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:58:37.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kzvlb" for this suite.
Feb  4 18:58:43.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:58:43.393: INFO: namespace: e2e-tests-emptydir-kzvlb, resource: bindings, ignored listing per whitelist
Feb  4 18:58:43.508: INFO: namespace e2e-tests-emptydir-kzvlb deletion completed in 6.174792009s

• [SLOW TEST:8.409 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:58:43.510: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  4 18:58:43.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-9bf4g'
Feb  4 18:58:44.448: INFO: stderr: ""
Feb  4 18:58:44.448: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb  4 18:58:44.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-9bf4g'
Feb  4 18:58:45.838: INFO: stderr: ""
Feb  4 18:58:45.838: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:58:45.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9bf4g" for this suite.
Feb  4 18:58:51.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:58:52.031: INFO: namespace: e2e-tests-kubectl-9bf4g, resource: bindings, ignored listing per whitelist
Feb  4 18:58:52.097: INFO: namespace e2e-tests-kubectl-9bf4g deletion completed in 6.249121605s

• [SLOW TEST:8.587 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:58:52.098: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-8vjc9
Feb  4 18:58:56.250: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-8vjc9
STEP: checking the pod's current state and verifying that restartCount is present
Feb  4 18:58:56.259: INFO: Initial restart count of pod liveness-exec is 0
Feb  4 18:59:44.567: INFO: Restart count of pod e2e-tests-container-probe-8vjc9/liveness-exec is now 1 (48.306847846s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 18:59:44.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8vjc9" for this suite.
Feb  4 18:59:50.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 18:59:50.777: INFO: namespace: e2e-tests-container-probe-8vjc9, resource: bindings, ignored listing per whitelist
Feb  4 18:59:50.870: INFO: namespace e2e-tests-container-probe-8vjc9 deletion completed in 6.19222314s

• [SLOW TEST:58.773 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 18:59:50.870: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-8mhdr
Feb  4 18:59:57.059: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-8mhdr
STEP: checking the pod's current state and verifying that restartCount is present
Feb  4 18:59:57.068: INFO: Initial restart count of pod liveness-http is 0
Feb  4 19:00:13.147: INFO: Restart count of pod e2e-tests-container-probe-8mhdr/liveness-http is now 1 (16.07969628s elapsed)
Feb  4 19:00:33.221: INFO: Restart count of pod e2e-tests-container-probe-8mhdr/liveness-http is now 2 (36.152970993s elapsed)
Feb  4 19:00:53.269: INFO: Restart count of pod e2e-tests-container-probe-8mhdr/liveness-http is now 3 (56.201231454s elapsed)
Feb  4 19:01:13.335: INFO: Restart count of pod e2e-tests-container-probe-8mhdr/liveness-http is now 4 (1m16.267067816s elapsed)
Feb  4 19:02:13.681: INFO: Restart count of pod e2e-tests-container-probe-8mhdr/liveness-http is now 5 (2m16.61316858s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:02:13.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8mhdr" for this suite.
Feb  4 19:02:19.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:02:19.837: INFO: namespace: e2e-tests-container-probe-8mhdr, resource: bindings, ignored listing per whitelist
Feb  4 19:02:19.979: INFO: namespace e2e-tests-container-probe-8mhdr deletion completed in 6.251694526s

• [SLOW TEST:149.109 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:02:19.979: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-659d3c2a-28af-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:02:20.085: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-659db82a-28af-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-swlt5" to be "success or failure"
Feb  4 19:02:20.125: INFO: Pod "pod-projected-secrets-659db82a-28af-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 39.540483ms
Feb  4 19:02:22.133: INFO: Pod "pod-projected-secrets-659db82a-28af-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047031231s
Feb  4 19:02:24.142: INFO: Pod "pod-projected-secrets-659db82a-28af-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056302925s
STEP: Saw pod success
Feb  4 19:02:24.142: INFO: Pod "pod-projected-secrets-659db82a-28af-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:02:24.148: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-projected-secrets-659db82a-28af-11e9-8d1f-5e319961b721 container secret-volume-test: <nil>
STEP: delete the pod
Feb  4 19:02:24.230: INFO: Waiting for pod pod-projected-secrets-659db82a-28af-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:02:24.237: INFO: Pod pod-projected-secrets-659db82a-28af-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:02:24.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-swlt5" for this suite.
Feb  4 19:02:30.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:02:30.420: INFO: namespace: e2e-tests-projected-swlt5, resource: bindings, ignored listing per whitelist
Feb  4 19:02:30.453: INFO: namespace e2e-tests-projected-swlt5 deletion completed in 6.210706687s

• [SLOW TEST:10.474 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:02:30.454: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-gtfd2
Feb  4 19:02:34.645: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-gtfd2
STEP: checking the pod's current state and verifying that restartCount is present
Feb  4 19:02:34.662: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:06:35.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gtfd2" for this suite.
Feb  4 19:06:41.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:06:42.020: INFO: namespace: e2e-tests-container-probe-gtfd2, resource: bindings, ignored listing per whitelist
Feb  4 19:06:42.030: INFO: namespace e2e-tests-container-probe-gtfd2 deletion completed in 6.243690232s

• [SLOW TEST:251.576 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:06:42.030: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  4 19:06:42.213: INFO: Waiting up to 5m0s for pod "pod-01d8e37c-28b0-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-7qrn9" to be "success or failure"
Feb  4 19:06:42.245: INFO: Pod "pod-01d8e37c-28b0-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 32.480282ms
Feb  4 19:06:44.247: INFO: Pod "pod-01d8e37c-28b0-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034330609s
Feb  4 19:06:46.252: INFO: Pod "pod-01d8e37c-28b0-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039069492s
STEP: Saw pod success
Feb  4 19:06:46.252: INFO: Pod "pod-01d8e37c-28b0-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:06:46.257: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-01d8e37c-28b0-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 19:06:46.310: INFO: Waiting for pod pod-01d8e37c-28b0-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:06:46.340: INFO: Pod pod-01d8e37c-28b0-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:06:46.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-7qrn9" for this suite.
Feb  4 19:06:52.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:06:52.490: INFO: namespace: e2e-tests-emptydir-7qrn9, resource: bindings, ignored listing per whitelist
Feb  4 19:06:52.518: INFO: namespace e2e-tests-emptydir-7qrn9 deletion completed in 6.174897667s

• [SLOW TEST:10.488 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:06:52.519: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2nm9p
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-2nm9p
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-2nm9p
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-2nm9p
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-2nm9p
Feb  4 19:06:56.862: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2nm9p, name: ss-0, uid: 0a7acf62-28b0-11e9-88b2-2600a3ceccc4, status phase: Pending. Waiting for statefulset controller to delete.
Feb  4 19:06:57.197: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2nm9p, name: ss-0, uid: 0a7acf62-28b0-11e9-88b2-2600a3ceccc4, status phase: Failed. Waiting for statefulset controller to delete.
Feb  4 19:06:57.217: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2nm9p, name: ss-0, uid: 0a7acf62-28b0-11e9-88b2-2600a3ceccc4, status phase: Failed. Waiting for statefulset controller to delete.
Feb  4 19:06:57.236: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-2nm9p
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-2nm9p
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-2nm9p and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  4 19:07:01.350: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2nm9p
Feb  4 19:07:01.366: INFO: Scaling statefulset ss to 0
Feb  4 19:07:11.433: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:07:11.441: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:07:11.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2nm9p" for this suite.
Feb  4 19:07:17.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:07:17.617: INFO: namespace: e2e-tests-statefulset-2nm9p, resource: bindings, ignored listing per whitelist
Feb  4 19:07:17.656: INFO: namespace e2e-tests-statefulset-2nm9p deletion completed in 6.142832501s

• [SLOW TEST:25.138 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:07:17.657: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0204 19:07:27.868154      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  4 19:07:27.868: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:07:27.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-p2976" for this suite.
Feb  4 19:07:33.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:07:34.103: INFO: namespace: e2e-tests-gc-p2976, resource: bindings, ignored listing per whitelist
Feb  4 19:07:34.114: INFO: namespace e2e-tests-gc-p2976 deletion completed in 6.233951687s

• [SLOW TEST:16.458 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:07:34.115: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  4 19:07:38.760: INFO: Successfully updated pod "pod-update-activedeadlineseconds-20d9876d-28b0-11e9-8d1f-5e319961b721"
Feb  4 19:07:38.760: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-20d9876d-28b0-11e9-8d1f-5e319961b721" in namespace "e2e-tests-pods-xfqq6" to be "terminated due to deadline exceeded"
Feb  4 19:07:38.790: INFO: Pod "pod-update-activedeadlineseconds-20d9876d-28b0-11e9-8d1f-5e319961b721": Phase="Running", Reason="", readiness=true. Elapsed: 30.68054ms
Feb  4 19:07:40.802: INFO: Pod "pod-update-activedeadlineseconds-20d9876d-28b0-11e9-8d1f-5e319961b721": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.042228688s
Feb  4 19:07:40.802: INFO: Pod "pod-update-activedeadlineseconds-20d9876d-28b0-11e9-8d1f-5e319961b721" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:07:40.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xfqq6" for this suite.
Feb  4 19:07:46.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:07:47.095: INFO: namespace: e2e-tests-pods-xfqq6, resource: bindings, ignored listing per whitelist
Feb  4 19:07:47.121: INFO: namespace e2e-tests-pods-xfqq6 deletion completed in 6.298236777s

• [SLOW TEST:13.007 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:07:47.125: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:07:47.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-x5r66" for this suite.
Feb  4 19:08:09.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:08:09.449: INFO: namespace: e2e-tests-pods-x5r66, resource: bindings, ignored listing per whitelist
Feb  4 19:08:09.529: INFO: namespace e2e-tests-pods-x5r66 deletion completed in 22.231450274s

• [SLOW TEST:22.405 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:08:09.530: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  4 19:08:17.883: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:17.914: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:19.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:19.951: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:21.917: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:21.938: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:23.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:23.980: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:25.915: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:25.922: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:27.915: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:27.926: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:29.915: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:29.922: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:31.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:31.922: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:33.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:33.924: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  4 19:08:35.914: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  4 19:08:35.921: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:08:35.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-49pcr" for this suite.
Feb  4 19:08:58.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:08:58.051: INFO: namespace: e2e-tests-container-lifecycle-hook-49pcr, resource: bindings, ignored listing per whitelist
Feb  4 19:08:58.172: INFO: namespace e2e-tests-container-lifecycle-hook-49pcr deletion completed in 22.199926511s

• [SLOW TEST:48.642 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:08:58.172: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qmf2j
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb  4 19:08:58.380: INFO: Found 0 stateful pods, waiting for 3
Feb  4 19:09:08.390: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:09:08.391: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:09:08.391: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  4 19:09:08.465: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  4 19:09:18.559: INFO: Updating stateful set ss2
Feb  4 19:09:18.579: INFO: Waiting for Pod e2e-tests-statefulset-qmf2j/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb  4 19:09:28.769: INFO: Found 1 stateful pods, waiting for 3
Feb  4 19:09:38.778: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:09:38.778: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:09:38.778: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  4 19:09:38.840: INFO: Updating stateful set ss2
Feb  4 19:09:38.904: INFO: Waiting for Pod e2e-tests-statefulset-qmf2j/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  4 19:09:48.950: INFO: Updating stateful set ss2
Feb  4 19:09:48.977: INFO: Waiting for StatefulSet e2e-tests-statefulset-qmf2j/ss2 to complete update
Feb  4 19:09:48.977: INFO: Waiting for Pod e2e-tests-statefulset-qmf2j/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  4 19:09:58.988: INFO: Waiting for StatefulSet e2e-tests-statefulset-qmf2j/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  4 19:10:08.996: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qmf2j
Feb  4 19:10:09.004: INFO: Scaling statefulset ss2 to 0
Feb  4 19:10:19.086: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:10:19.098: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:10:19.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qmf2j" for this suite.
Feb  4 19:10:27.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:10:27.342: INFO: namespace: e2e-tests-statefulset-qmf2j, resource: bindings, ignored listing per whitelist
Feb  4 19:10:27.431: INFO: namespace e2e-tests-statefulset-qmf2j deletion completed in 8.255546813s

• [SLOW TEST:89.259 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:10:27.434: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb  4 19:10:27.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 --namespace=e2e-tests-kubectl-5m44z run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  4 19:10:31.067: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  4 19:10:31.067: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:10:33.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5m44z" for this suite.
Feb  4 19:10:39.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:10:39.232: INFO: namespace: e2e-tests-kubectl-5m44z, resource: bindings, ignored listing per whitelist
Feb  4 19:10:39.251: INFO: namespace e2e-tests-kubectl-5m44z deletion completed in 6.177534858s

• [SLOW TEST:11.817 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:10:39.251: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  4 19:10:39.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:39.529: INFO: stderr: ""
Feb  4 19:10:39.529: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  4 19:10:39.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:39.634: INFO: stderr: ""
Feb  4 19:10:39.634: INFO: stdout: "update-demo-nautilus-5k7z6 update-demo-nautilus-7fb28 "
Feb  4 19:10:39.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-5k7z6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:39.714: INFO: stderr: ""
Feb  4 19:10:39.714: INFO: stdout: ""
Feb  4 19:10:39.714: INFO: update-demo-nautilus-5k7z6 is created but not running
Feb  4 19:10:44.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:44.915: INFO: stderr: ""
Feb  4 19:10:44.915: INFO: stdout: "update-demo-nautilus-5k7z6 update-demo-nautilus-7fb28 "
Feb  4 19:10:44.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-5k7z6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:44.983: INFO: stderr: ""
Feb  4 19:10:44.983: INFO: stdout: "true"
Feb  4 19:10:44.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-5k7z6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:45.037: INFO: stderr: ""
Feb  4 19:10:45.037: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 19:10:45.037: INFO: validating pod update-demo-nautilus-5k7z6
Feb  4 19:10:45.049: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 19:10:45.050: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 19:10:45.050: INFO: update-demo-nautilus-5k7z6 is verified up and running
Feb  4 19:10:45.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-7fb28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:45.135: INFO: stderr: ""
Feb  4 19:10:45.135: INFO: stdout: "true"
Feb  4 19:10:45.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-7fb28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:45.203: INFO: stderr: ""
Feb  4 19:10:45.203: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 19:10:45.203: INFO: validating pod update-demo-nautilus-7fb28
Feb  4 19:10:45.207: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 19:10:45.207: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 19:10:45.207: INFO: update-demo-nautilus-7fb28 is verified up and running
STEP: scaling down the replication controller
Feb  4 19:10:45.208: INFO: scanned /root for discovery docs: <nil>
Feb  4 19:10:45.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:46.317: INFO: stderr: ""
Feb  4 19:10:46.317: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  4 19:10:46.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:46.387: INFO: stderr: ""
Feb  4 19:10:46.387: INFO: stdout: "update-demo-nautilus-5k7z6 update-demo-nautilus-7fb28 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  4 19:10:51.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:51.541: INFO: stderr: ""
Feb  4 19:10:51.541: INFO: stdout: "update-demo-nautilus-7fb28 "
Feb  4 19:10:51.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-7fb28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:51.597: INFO: stderr: ""
Feb  4 19:10:51.597: INFO: stdout: "true"
Feb  4 19:10:51.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-7fb28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:51.657: INFO: stderr: ""
Feb  4 19:10:51.657: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 19:10:51.657: INFO: validating pod update-demo-nautilus-7fb28
Feb  4 19:10:51.659: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 19:10:51.659: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 19:10:51.659: INFO: update-demo-nautilus-7fb28 is verified up and running
STEP: scaling up the replication controller
Feb  4 19:10:51.661: INFO: scanned /root for discovery docs: <nil>
Feb  4 19:10:51.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:52.867: INFO: stderr: ""
Feb  4 19:10:52.867: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  4 19:10:52.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:52.981: INFO: stderr: ""
Feb  4 19:10:52.981: INFO: stdout: "update-demo-nautilus-7fb28 update-demo-nautilus-9rp27 "
Feb  4 19:10:52.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-7fb28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:53.064: INFO: stderr: ""
Feb  4 19:10:53.064: INFO: stdout: "true"
Feb  4 19:10:53.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-7fb28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:53.129: INFO: stderr: ""
Feb  4 19:10:53.129: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 19:10:53.129: INFO: validating pod update-demo-nautilus-7fb28
Feb  4 19:10:53.132: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 19:10:53.132: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 19:10:53.132: INFO: update-demo-nautilus-7fb28 is verified up and running
Feb  4 19:10:53.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-9rp27 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:53.187: INFO: stderr: ""
Feb  4 19:10:53.187: INFO: stdout: ""
Feb  4 19:10:53.187: INFO: update-demo-nautilus-9rp27 is created but not running
Feb  4 19:10:58.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:58.349: INFO: stderr: ""
Feb  4 19:10:58.349: INFO: stdout: "update-demo-nautilus-7fb28 update-demo-nautilus-9rp27 "
Feb  4 19:10:58.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-7fb28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:58.406: INFO: stderr: ""
Feb  4 19:10:58.406: INFO: stdout: "true"
Feb  4 19:10:58.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-7fb28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:58.463: INFO: stderr: ""
Feb  4 19:10:58.463: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 19:10:58.463: INFO: validating pod update-demo-nautilus-7fb28
Feb  4 19:10:58.465: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 19:10:58.465: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 19:10:58.465: INFO: update-demo-nautilus-7fb28 is verified up and running
Feb  4 19:10:58.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-9rp27 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:58.522: INFO: stderr: ""
Feb  4 19:10:58.522: INFO: stdout: "true"
Feb  4 19:10:58.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-9rp27 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:58.585: INFO: stderr: ""
Feb  4 19:10:58.585: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 19:10:58.585: INFO: validating pod update-demo-nautilus-9rp27
Feb  4 19:10:58.588: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 19:10:58.588: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 19:10:58.588: INFO: update-demo-nautilus-9rp27 is verified up and running
STEP: using delete to clean up resources
Feb  4 19:10:58.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:58.659: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 19:10:58.659: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  4 19:10:58.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bn9f5'
Feb  4 19:10:58.760: INFO: stderr: "No resources found.\n"
Feb  4 19:10:58.760: INFO: stdout: ""
Feb  4 19:10:58.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -l name=update-demo --namespace=e2e-tests-kubectl-bn9f5 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  4 19:10:58.831: INFO: stderr: ""
Feb  4 19:10:58.831: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:10:58.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bn9f5" for this suite.
Feb  4 19:11:04.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:11:04.955: INFO: namespace: e2e-tests-kubectl-bn9f5, resource: bindings, ignored listing per whitelist
Feb  4 19:11:05.024: INFO: namespace e2e-tests-kubectl-bn9f5 deletion completed in 6.179154012s

• [SLOW TEST:25.772 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:11:05.024: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:11:09.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tph57" for this suite.
Feb  4 19:11:55.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:11:55.375: INFO: namespace: e2e-tests-kubelet-test-tph57, resource: bindings, ignored listing per whitelist
Feb  4 19:11:55.390: INFO: namespace e2e-tests-kubelet-test-tph57 deletion completed in 46.179210832s

• [SLOW TEST:50.366 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:11:55.390: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-wx2v
STEP: Creating a pod to test atomic-volume-subpath
Feb  4 19:11:55.569: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wx2v" in namespace "e2e-tests-subpath-474z7" to be "success or failure"
Feb  4 19:11:55.590: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Pending", Reason="", readiness=false. Elapsed: 21.054604ms
Feb  4 19:11:57.601: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032266749s
Feb  4 19:11:59.630: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 4.061118737s
Feb  4 19:12:01.636: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 6.067041611s
Feb  4 19:12:03.642: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 8.073744408s
Feb  4 19:12:05.645: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 10.076644475s
Feb  4 19:12:07.663: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 12.094447795s
Feb  4 19:12:09.671: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 14.10262461s
Feb  4 19:12:11.678: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 16.109370782s
Feb  4 19:12:13.701: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 18.131873562s
Feb  4 19:12:15.706: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 20.137655122s
Feb  4 19:12:17.713: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Running", Reason="", readiness=false. Elapsed: 22.143803739s
Feb  4 19:12:19.726: INFO: Pod "pod-subpath-test-configmap-wx2v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.157700237s
STEP: Saw pod success
Feb  4 19:12:19.726: INFO: Pod "pod-subpath-test-configmap-wx2v" satisfied condition "success or failure"
Feb  4 19:12:19.737: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-subpath-test-configmap-wx2v container test-container-subpath-configmap-wx2v: <nil>
STEP: delete the pod
Feb  4 19:12:19.825: INFO: Waiting for pod pod-subpath-test-configmap-wx2v to disappear
Feb  4 19:12:19.829: INFO: Pod pod-subpath-test-configmap-wx2v no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wx2v
Feb  4 19:12:19.829: INFO: Deleting pod "pod-subpath-test-configmap-wx2v" in namespace "e2e-tests-subpath-474z7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:12:19.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-474z7" for this suite.
Feb  4 19:12:25.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:12:25.914: INFO: namespace: e2e-tests-subpath-474z7, resource: bindings, ignored listing per whitelist
Feb  4 19:12:25.917: INFO: namespace e2e-tests-subpath-474z7 deletion completed in 6.076385706s

• [SLOW TEST:30.527 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:12:25.917: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-rp6lf/configmap-test-cec3ff53-28b0-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:12:26.001: INFO: Waiting up to 5m0s for pod "pod-configmaps-cec4f355-28b0-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-rp6lf" to be "success or failure"
Feb  4 19:12:26.014: INFO: Pod "pod-configmaps-cec4f355-28b0-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 12.677926ms
Feb  4 19:12:28.023: INFO: Pod "pod-configmaps-cec4f355-28b0-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020984006s
STEP: Saw pod success
Feb  4 19:12:28.023: INFO: Pod "pod-configmaps-cec4f355-28b0-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:12:28.039: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-configmaps-cec4f355-28b0-11e9-8d1f-5e319961b721 container env-test: <nil>
STEP: delete the pod
Feb  4 19:12:28.125: INFO: Waiting for pod pod-configmaps-cec4f355-28b0-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:12:28.134: INFO: Pod pod-configmaps-cec4f355-28b0-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:12:28.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rp6lf" for this suite.
Feb  4 19:12:34.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:12:34.315: INFO: namespace: e2e-tests-configmap-rp6lf, resource: bindings, ignored listing per whitelist
Feb  4 19:12:34.345: INFO: namespace e2e-tests-configmap-rp6lf deletion completed in 6.204068195s

• [SLOW TEST:8.428 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:12:34.345: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb  4 19:12:34.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:12:34.712: INFO: stderr: ""
Feb  4 19:12:34.712: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  4 19:12:34.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:12:34.794: INFO: stderr: ""
Feb  4 19:12:34.794: INFO: stdout: "update-demo-nautilus-jmpvd update-demo-nautilus-lh9q5 "
Feb  4 19:12:34.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-jmpvd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:12:34.852: INFO: stderr: ""
Feb  4 19:12:34.852: INFO: stdout: ""
Feb  4 19:12:34.852: INFO: update-demo-nautilus-jmpvd is created but not running
Feb  4 19:12:39.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:12:40.072: INFO: stderr: ""
Feb  4 19:12:40.072: INFO: stdout: "update-demo-nautilus-jmpvd update-demo-nautilus-lh9q5 "
Feb  4 19:12:40.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-jmpvd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:12:40.133: INFO: stderr: ""
Feb  4 19:12:40.133: INFO: stdout: "true"
Feb  4 19:12:40.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-jmpvd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:12:40.189: INFO: stderr: ""
Feb  4 19:12:40.189: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 19:12:40.189: INFO: validating pod update-demo-nautilus-jmpvd
Feb  4 19:12:40.200: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 19:12:40.200: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 19:12:40.200: INFO: update-demo-nautilus-jmpvd is verified up and running
Feb  4 19:12:40.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-lh9q5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:12:40.256: INFO: stderr: ""
Feb  4 19:12:40.256: INFO: stdout: "true"
Feb  4 19:12:40.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-nautilus-lh9q5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:12:40.311: INFO: stderr: ""
Feb  4 19:12:40.311: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  4 19:12:40.311: INFO: validating pod update-demo-nautilus-lh9q5
Feb  4 19:12:40.322: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  4 19:12:40.322: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  4 19:12:40.322: INFO: update-demo-nautilus-lh9q5 is verified up and running
STEP: rolling-update to new replication controller
Feb  4 19:12:40.323: INFO: scanned /root for discovery docs: <nil>
Feb  4 19:12:40.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:13:03.167: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  4 19:13:03.167: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  4 19:13:03.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:13:03.241: INFO: stderr: ""
Feb  4 19:13:03.241: INFO: stdout: "update-demo-kitten-69rf7 update-demo-kitten-r2kw7 "
Feb  4 19:13:03.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-kitten-69rf7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:13:03.297: INFO: stderr: ""
Feb  4 19:13:03.297: INFO: stdout: "true"
Feb  4 19:13:03.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-kitten-69rf7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:13:03.351: INFO: stderr: ""
Feb  4 19:13:03.351: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  4 19:13:03.351: INFO: validating pod update-demo-kitten-69rf7
Feb  4 19:13:03.355: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  4 19:13:03.355: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  4 19:13:03.355: INFO: update-demo-kitten-69rf7 is verified up and running
Feb  4 19:13:03.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-kitten-r2kw7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:13:03.412: INFO: stderr: ""
Feb  4 19:13:03.412: INFO: stdout: "true"
Feb  4 19:13:03.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods update-demo-kitten-r2kw7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-wbkf9'
Feb  4 19:13:03.467: INFO: stderr: ""
Feb  4 19:13:03.467: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  4 19:13:03.467: INFO: validating pod update-demo-kitten-r2kw7
Feb  4 19:13:03.471: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  4 19:13:03.471: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  4 19:13:03.471: INFO: update-demo-kitten-r2kw7 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:13:03.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wbkf9" for this suite.
Feb  4 19:13:27.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:13:27.627: INFO: namespace: e2e-tests-kubectl-wbkf9, resource: bindings, ignored listing per whitelist
Feb  4 19:13:27.652: INFO: namespace e2e-tests-kubectl-wbkf9 deletion completed in 24.178701697s

• [SLOW TEST:53.307 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:13:27.652: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-kvvs
STEP: Creating a pod to test atomic-volume-subpath
Feb  4 19:13:27.762: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-kvvs" in namespace "e2e-tests-subpath-v8xnd" to be "success or failure"
Feb  4 19:13:27.767: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Pending", Reason="", readiness=false. Elapsed: 4.97684ms
Feb  4 19:13:29.776: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01346504s
Feb  4 19:13:31.783: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 4.020988465s
Feb  4 19:13:33.791: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 6.02869966s
Feb  4 19:13:35.839: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 8.076903615s
Feb  4 19:13:37.848: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 10.085641686s
Feb  4 19:13:39.854: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 12.091259643s
Feb  4 19:13:41.862: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 14.099308987s
Feb  4 19:13:43.868: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 16.106006155s
Feb  4 19:13:45.875: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 18.112183956s
Feb  4 19:13:47.881: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 20.118730237s
Feb  4 19:13:49.888: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Running", Reason="", readiness=false. Elapsed: 22.125625359s
Feb  4 19:13:51.890: INFO: Pod "pod-subpath-test-projected-kvvs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.127912404s
STEP: Saw pod success
Feb  4 19:13:51.890: INFO: Pod "pod-subpath-test-projected-kvvs" satisfied condition "success or failure"
Feb  4 19:13:51.894: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-subpath-test-projected-kvvs container test-container-subpath-projected-kvvs: <nil>
STEP: delete the pod
Feb  4 19:13:51.954: INFO: Waiting for pod pod-subpath-test-projected-kvvs to disappear
Feb  4 19:13:51.969: INFO: Pod pod-subpath-test-projected-kvvs no longer exists
STEP: Deleting pod pod-subpath-test-projected-kvvs
Feb  4 19:13:51.969: INFO: Deleting pod "pod-subpath-test-projected-kvvs" in namespace "e2e-tests-subpath-v8xnd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:13:51.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-v8xnd" for this suite.
Feb  4 19:13:58.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:13:58.154: INFO: namespace: e2e-tests-subpath-v8xnd, resource: bindings, ignored listing per whitelist
Feb  4 19:13:58.187: INFO: namespace e2e-tests-subpath-v8xnd deletion completed in 6.172803481s

• [SLOW TEST:30.535 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:13:58.188: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:13:58.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 version'
Feb  4 19:13:58.303: INFO: stderr: ""
Feb  4 19:13:58.303: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.3\", GitCommit:\"721bfa751924da8d1680787490c54b9179b1fed0\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T20:00:57Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:13:58.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-558pv" for this suite.
Feb  4 19:14:04.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:14:04.444: INFO: namespace: e2e-tests-kubectl-558pv, resource: bindings, ignored listing per whitelist
Feb  4 19:14:04.521: INFO: namespace e2e-tests-kubectl-558pv deletion completed in 6.203173298s

• [SLOW TEST:6.333 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:14:04.521: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb  4 19:14:04.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-s5976'
Feb  4 19:14:04.762: INFO: stderr: ""
Feb  4 19:14:04.762: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb  4 19:14:05.771: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 19:14:05.771: INFO: Found 0 / 1
Feb  4 19:14:06.770: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 19:14:06.770: INFO: Found 0 / 1
Feb  4 19:14:07.770: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 19:14:07.770: INFO: Found 1 / 1
Feb  4 19:14:07.770: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  4 19:14:07.781: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 19:14:07.781: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb  4 19:14:07.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 logs redis-master-l5qht redis-master --namespace=e2e-tests-kubectl-s5976'
Feb  4 19:14:08.103: INFO: stderr: ""
Feb  4 19:14:08.103: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Feb 19:14:06.092 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Feb 19:14:06.092 # Server started, Redis version 3.2.12\n1:M 04 Feb 19:14:06.092 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Feb 19:14:06.093 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb  4 19:14:08.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 log redis-master-l5qht redis-master --namespace=e2e-tests-kubectl-s5976 --tail=1'
Feb  4 19:14:08.223: INFO: stderr: ""
Feb  4 19:14:08.223: INFO: stdout: "1:M 04 Feb 19:14:06.093 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb  4 19:14:08.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 log redis-master-l5qht redis-master --namespace=e2e-tests-kubectl-s5976 --limit-bytes=1'
Feb  4 19:14:08.290: INFO: stderr: ""
Feb  4 19:14:08.290: INFO: stdout: " "
STEP: exposing timestamps
Feb  4 19:14:08.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 log redis-master-l5qht redis-master --namespace=e2e-tests-kubectl-s5976 --tail=1 --timestamps'
Feb  4 19:14:08.354: INFO: stderr: ""
Feb  4 19:14:08.354: INFO: stdout: "2019-02-04T19:14:06.097965546Z 1:M 04 Feb 19:14:06.093 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb  4 19:14:10.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 log redis-master-l5qht redis-master --namespace=e2e-tests-kubectl-s5976 --since=1s'
Feb  4 19:14:11.045: INFO: stderr: ""
Feb  4 19:14:11.045: INFO: stdout: ""
Feb  4 19:14:11.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 log redis-master-l5qht redis-master --namespace=e2e-tests-kubectl-s5976 --since=24h'
Feb  4 19:14:11.121: INFO: stderr: ""
Feb  4 19:14:11.121: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Feb 19:14:06.092 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Feb 19:14:06.092 # Server started, Redis version 3.2.12\n1:M 04 Feb 19:14:06.092 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Feb 19:14:06.093 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb  4 19:14:11.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s5976'
Feb  4 19:14:11.195: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 19:14:11.195: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb  4 19:14:11.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-s5976'
Feb  4 19:14:11.263: INFO: stderr: "No resources found.\n"
Feb  4 19:14:11.263: INFO: stdout: ""
Feb  4 19:14:11.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pods -l name=nginx --namespace=e2e-tests-kubectl-s5976 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  4 19:14:11.320: INFO: stderr: ""
Feb  4 19:14:11.320: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:14:11.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s5976" for this suite.
Feb  4 19:14:17.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:14:17.471: INFO: namespace: e2e-tests-kubectl-s5976, resource: bindings, ignored listing per whitelist
Feb  4 19:14:17.485: INFO: namespace e2e-tests-kubectl-s5976 deletion completed in 6.16288472s

• [SLOW TEST:12.964 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:14:17.486: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:14:23.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-cs7x7" for this suite.
Feb  4 19:14:29.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:14:29.962: INFO: namespace: e2e-tests-emptydir-wrapper-cs7x7, resource: bindings, ignored listing per whitelist
Feb  4 19:14:30.097: INFO: namespace e2e-tests-emptydir-wrapper-cs7x7 deletion completed in 6.238472999s

• [SLOW TEST:12.612 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:14:30.098: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-18d2917e-28b1-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:14:30.261: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-18d51043-28b1-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-btwfq" to be "success or failure"
Feb  4 19:14:30.270: INFO: Pod "pod-projected-secrets-18d51043-28b1-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 9.19339ms
Feb  4 19:14:32.272: INFO: Pod "pod-projected-secrets-18d51043-28b1-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011180695s
STEP: Saw pod success
Feb  4 19:14:32.272: INFO: Pod "pod-projected-secrets-18d51043-28b1-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:14:32.274: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-projected-secrets-18d51043-28b1-11e9-8d1f-5e319961b721 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  4 19:14:32.314: INFO: Waiting for pod pod-projected-secrets-18d51043-28b1-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:14:32.326: INFO: Pod pod-projected-secrets-18d51043-28b1-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:14:32.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-btwfq" for this suite.
Feb  4 19:14:38.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:14:38.461: INFO: namespace: e2e-tests-projected-btwfq, resource: bindings, ignored listing per whitelist
Feb  4 19:14:38.501: INFO: namespace e2e-tests-projected-btwfq deletion completed in 6.172043978s

• [SLOW TEST:8.403 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:14:38.501: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb  4 19:14:38.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 cluster-info'
Feb  4 19:14:38.689: INFO: stderr: ""
Feb  4 19:14:38.689: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:14:38.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pd6qb" for this suite.
Feb  4 19:14:44.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:14:44.795: INFO: namespace: e2e-tests-kubectl-pd6qb, resource: bindings, ignored listing per whitelist
Feb  4 19:14:44.899: INFO: namespace e2e-tests-kubectl-pd6qb deletion completed in 6.206972177s

• [SLOW TEST:6.398 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:14:44.900: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  4 19:14:51.115: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.115: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:51.291: INFO: Exec stderr: ""
Feb  4 19:14:51.292: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.292: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:51.363: INFO: Exec stderr: ""
Feb  4 19:14:51.363: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.363: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:51.425: INFO: Exec stderr: ""
Feb  4 19:14:51.425: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.425: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:51.508: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  4 19:14:51.508: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.508: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:51.582: INFO: Exec stderr: ""
Feb  4 19:14:51.582: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.582: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:51.652: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  4 19:14:51.652: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:51.873: INFO: Exec stderr: ""
Feb  4 19:14:51.873: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.873: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:51.939: INFO: Exec stderr: ""
Feb  4 19:14:51.939: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:51.939: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:52.017: INFO: Exec stderr: ""
Feb  4 19:14:52.017: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-8dnks PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:14:52.017: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:14:52.084: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:14:52.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-8dnks" for this suite.
Feb  4 19:15:32.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:15:32.175: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-8dnks, resource: bindings, ignored listing per whitelist
Feb  4 19:15:32.295: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-8dnks deletion completed in 40.208620359s

• [SLOW TEST:47.396 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:15:32.296: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:15:32.447: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb  4 19:15:32.480: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-sv8q2/daemonsets","resourceVersion":"11732"},"items":null}

Feb  4 19:15:32.486: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-sv8q2/pods","resourceVersion":"11732"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:15:32.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-sv8q2" for this suite.
Feb  4 19:15:38.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:15:38.715: INFO: namespace: e2e-tests-daemonsets-sv8q2, resource: bindings, ignored listing per whitelist
Feb  4 19:15:38.794: INFO: namespace e2e-tests-daemonsets-sv8q2 deletion completed in 6.254573611s

S [SKIPPING] [6.498 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb  4 19:15:32.447: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:15:38.794: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb  4 19:15:39.409: INFO: created pod pod-service-account-defaultsa
Feb  4 19:15:39.409: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  4 19:15:39.426: INFO: created pod pod-service-account-mountsa
Feb  4 19:15:39.426: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  4 19:15:39.507: INFO: created pod pod-service-account-nomountsa
Feb  4 19:15:39.509: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  4 19:15:39.568: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  4 19:15:39.568: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  4 19:15:39.608: INFO: created pod pod-service-account-mountsa-mountspec
Feb  4 19:15:39.609: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  4 19:15:39.641: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  4 19:15:39.641: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  4 19:15:39.668: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  4 19:15:39.669: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  4 19:15:39.678: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  4 19:15:39.678: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  4 19:15:39.840: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  4 19:15:39.840: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:15:39.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-xcjwh" for this suite.
Feb  4 19:15:46.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:15:46.287: INFO: namespace: e2e-tests-svcaccounts-xcjwh, resource: bindings, ignored listing per whitelist
Feb  4 19:15:46.341: INFO: namespace e2e-tests-svcaccounts-xcjwh deletion completed in 6.241258902s

• [SLOW TEST:7.547 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:15:46.341: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:15:46.482: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4642dc1f-28b1-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-xj6b2" to be "success or failure"
Feb  4 19:15:46.498: INFO: Pod "downwardapi-volume-4642dc1f-28b1-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 16.29745ms
Feb  4 19:15:48.505: INFO: Pod "downwardapi-volume-4642dc1f-28b1-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02334549s
Feb  4 19:15:50.512: INFO: Pod "downwardapi-volume-4642dc1f-28b1-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030114741s
STEP: Saw pod success
Feb  4 19:15:50.512: INFO: Pod "downwardapi-volume-4642dc1f-28b1-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:15:50.520: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-4642dc1f-28b1-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:15:50.633: INFO: Waiting for pod downwardapi-volume-4642dc1f-28b1-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:15:50.651: INFO: Pod downwardapi-volume-4642dc1f-28b1-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:15:50.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xj6b2" for this suite.
Feb  4 19:15:56.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:15:56.800: INFO: namespace: e2e-tests-downward-api-xj6b2, resource: bindings, ignored listing per whitelist
Feb  4 19:15:56.809: INFO: namespace e2e-tests-downward-api-xj6b2 deletion completed in 6.147317994s

• [SLOW TEST:10.467 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:15:56.809: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb  4 19:15:56.893: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-030580780 proxy --unix-socket=/tmp/kubectl-proxy-unix742876059/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:15:56.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bpc95" for this suite.
Feb  4 19:16:02.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:16:03.009: INFO: namespace: e2e-tests-kubectl-bpc95, resource: bindings, ignored listing per whitelist
Feb  4 19:16:03.086: INFO: namespace e2e-tests-kubectl-bpc95 deletion completed in 6.102350831s

• [SLOW TEST:6.277 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:16:03.086: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:16:03.144: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:16:07.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wg97m" for this suite.
Feb  4 19:16:51.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:16:51.646: INFO: namespace: e2e-tests-pods-wg97m, resource: bindings, ignored listing per whitelist
Feb  4 19:16:51.651: INFO: namespace e2e-tests-pods-wg97m deletion completed in 44.177258715s

• [SLOW TEST:48.565 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:16:51.651: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:16:51.749: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:16:55.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hfm76" for this suite.
Feb  4 19:17:33.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:17:34.030: INFO: namespace: e2e-tests-pods-hfm76, resource: bindings, ignored listing per whitelist
Feb  4 19:17:34.062: INFO: namespace e2e-tests-pods-hfm76 deletion completed in 38.221566426s

• [SLOW TEST:42.411 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:17:34.063: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:17:54.167: INFO: Container started at 2019-02-04 19:17:35 +0000 UTC, pod became ready at 2019-02-04 19:17:53 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:17:54.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bpr85" for this suite.
Feb  4 19:18:16.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:18:16.432: INFO: namespace: e2e-tests-container-probe-bpr85, resource: bindings, ignored listing per whitelist
Feb  4 19:18:16.494: INFO: namespace e2e-tests-container-probe-bpr85 deletion completed in 22.315580998s

• [SLOW TEST:42.432 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:18:16.495: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:18:25.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-94bwt" for this suite.
Feb  4 19:18:47.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:18:47.927: INFO: namespace: e2e-tests-replication-controller-94bwt, resource: bindings, ignored listing per whitelist
Feb  4 19:18:48.027: INFO: namespace e2e-tests-replication-controller-94bwt deletion completed in 22.249997654s

• [SLOW TEST:31.532 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:18:48.027: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  4 19:18:48.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-pw6nj'
Feb  4 19:18:48.365: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  4 19:18:48.365: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb  4 19:18:52.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-pw6nj'
Feb  4 19:18:52.583: INFO: stderr: ""
Feb  4 19:18:52.583: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:18:52.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pw6nj" for this suite.
Feb  4 19:18:58.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:18:58.734: INFO: namespace: e2e-tests-kubectl-pw6nj, resource: bindings, ignored listing per whitelist
Feb  4 19:18:58.834: INFO: namespace e2e-tests-kubectl-pw6nj deletion completed in 6.235691782s

• [SLOW TEST:10.807 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:18:58.834: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:18:58.947: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8fc6798-28b1-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-5jg7k" to be "success or failure"
Feb  4 19:18:58.976: INFO: Pod "downwardapi-volume-b8fc6798-28b1-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 26.309004ms
Feb  4 19:19:00.986: INFO: Pod "downwardapi-volume-b8fc6798-28b1-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036756082s
STEP: Saw pod success
Feb  4 19:19:00.986: INFO: Pod "downwardapi-volume-b8fc6798-28b1-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:19:01.009: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-b8fc6798-28b1-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:19:01.053: INFO: Waiting for pod downwardapi-volume-b8fc6798-28b1-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:19:01.058: INFO: Pod downwardapi-volume-b8fc6798-28b1-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:19:01.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5jg7k" for this suite.
Feb  4 19:19:07.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:19:07.156: INFO: namespace: e2e-tests-downward-api-5jg7k, resource: bindings, ignored listing per whitelist
Feb  4 19:19:07.373: INFO: namespace e2e-tests-downward-api-5jg7k deletion completed in 6.311437615s

• [SLOW TEST:8.538 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:19:07.373: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  4 19:19:07.573: INFO: Waiting up to 5m0s for pod "pod-be1ef476-28b1-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-lhb6s" to be "success or failure"
Feb  4 19:19:07.578: INFO: Pod "pod-be1ef476-28b1-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 4.637349ms
Feb  4 19:19:09.597: INFO: Pod "pod-be1ef476-28b1-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023514106s
Feb  4 19:19:11.623: INFO: Pod "pod-be1ef476-28b1-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049636941s
STEP: Saw pod success
Feb  4 19:19:11.624: INFO: Pod "pod-be1ef476-28b1-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:19:11.633: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-be1ef476-28b1-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 19:19:11.695: INFO: Waiting for pod pod-be1ef476-28b1-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:19:11.703: INFO: Pod pod-be1ef476-28b1-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:19:11.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lhb6s" for this suite.
Feb  4 19:19:17.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:19:17.917: INFO: namespace: e2e-tests-emptydir-lhb6s, resource: bindings, ignored listing per whitelist
Feb  4 19:19:17.924: INFO: namespace e2e-tests-emptydir-lhb6s deletion completed in 6.216752446s

• [SLOW TEST:10.551 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:19:17.924: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb  4 19:19:17.994: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  4 19:19:17.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:19:18.156: INFO: stderr: ""
Feb  4 19:19:18.156: INFO: stdout: "service/redis-slave created\n"
Feb  4 19:19:18.156: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  4 19:19:18.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:19:18.449: INFO: stderr: ""
Feb  4 19:19:18.449: INFO: stdout: "service/redis-master created\n"
Feb  4 19:19:18.449: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  4 19:19:18.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:19:18.671: INFO: stderr: ""
Feb  4 19:19:18.671: INFO: stdout: "service/frontend created\n"
Feb  4 19:19:18.671: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  4 19:19:18.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:19:18.933: INFO: stderr: ""
Feb  4 19:19:18.933: INFO: stdout: "deployment.extensions/frontend created\n"
Feb  4 19:19:18.933: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  4 19:19:18.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:19:19.185: INFO: stderr: ""
Feb  4 19:19:19.185: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb  4 19:19:19.185: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  4 19:19:19.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:19:19.405: INFO: stderr: ""
Feb  4 19:19:19.405: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb  4 19:19:19.405: INFO: Waiting for all frontend pods to be Running.
Feb  4 19:21:24.464: INFO: Waiting for frontend to serve content.
Feb  4 19:21:29.519: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb  4 19:21:39.545: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb  4 19:21:44.614: INFO: Trying to add a new entry to the guestbook.
Feb  4 19:21:44.682: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Feb  4 19:21:44.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:21:45.616: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 19:21:45.616: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  4 19:21:45.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:21:45.736: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 19:21:45.736: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  4 19:21:45.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:21:45.843: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 19:21:45.843: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  4 19:21:45.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:21:45.931: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 19:21:45.931: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  4 19:21:45.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:21:46.046: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 19:21:46.046: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  4 19:21:46.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hqc6x'
Feb  4 19:21:46.210: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  4 19:21:46.210: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:21:46.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hqc6x" for this suite.
Feb  4 19:22:26.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:22:26.437: INFO: namespace: e2e-tests-kubectl-hqc6x, resource: bindings, ignored listing per whitelist
Feb  4 19:22:26.505: INFO: namespace e2e-tests-kubectl-hqc6x deletion completed in 40.239491902s

• [SLOW TEST:188.581 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:22:26.505: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb  4 19:22:26.671: INFO: Waiting up to 5m0s for pod "client-containers-34c9f36a-28b2-11e9-8d1f-5e319961b721" in namespace "e2e-tests-containers-mzxp4" to be "success or failure"
Feb  4 19:22:26.711: INFO: Pod "client-containers-34c9f36a-28b2-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 39.658566ms
Feb  4 19:22:28.714: INFO: Pod "client-containers-34c9f36a-28b2-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042478255s
STEP: Saw pod success
Feb  4 19:22:28.714: INFO: Pod "client-containers-34c9f36a-28b2-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:22:28.717: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod client-containers-34c9f36a-28b2-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 19:22:28.753: INFO: Waiting for pod client-containers-34c9f36a-28b2-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:22:28.779: INFO: Pod client-containers-34c9f36a-28b2-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:22:28.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mzxp4" for this suite.
Feb  4 19:22:34.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:22:34.944: INFO: namespace: e2e-tests-containers-mzxp4, resource: bindings, ignored listing per whitelist
Feb  4 19:22:34.964: INFO: namespace e2e-tests-containers-mzxp4 deletion completed in 6.18188726s

• [SLOW TEST:8.459 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:22:34.965: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-39ce92b9-28b2-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:22:35.113: INFO: Waiting up to 5m0s for pod "pod-configmaps-39d19daf-28b2-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-cdjzz" to be "success or failure"
Feb  4 19:22:35.143: INFO: Pod "pod-configmaps-39d19daf-28b2-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 29.484646ms
Feb  4 19:22:37.153: INFO: Pod "pod-configmaps-39d19daf-28b2-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03914602s
Feb  4 19:22:39.166: INFO: Pod "pod-configmaps-39d19daf-28b2-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052383181s
STEP: Saw pod success
Feb  4 19:22:39.166: INFO: Pod "pod-configmaps-39d19daf-28b2-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:22:39.177: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-configmaps-39d19daf-28b2-11e9-8d1f-5e319961b721 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:22:39.269: INFO: Waiting for pod pod-configmaps-39d19daf-28b2-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:22:39.277: INFO: Pod pod-configmaps-39d19daf-28b2-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:22:39.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cdjzz" for this suite.
Feb  4 19:22:45.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:22:45.494: INFO: namespace: e2e-tests-configmap-cdjzz, resource: bindings, ignored listing per whitelist
Feb  4 19:22:45.537: INFO: namespace e2e-tests-configmap-cdjzz deletion completed in 6.256431136s

• [SLOW TEST:10.573 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:22:45.538: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:22:45.612: INFO: (0) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.4747ms)
Feb  4 19:22:45.615: INFO: (1) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.126804ms)
Feb  4 19:22:45.618: INFO: (2) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.368724ms)
Feb  4 19:22:45.620: INFO: (3) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.420518ms)
Feb  4 19:22:45.624: INFO: (4) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.776324ms)
Feb  4 19:22:45.627: INFO: (5) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.482722ms)
Feb  4 19:22:45.630: INFO: (6) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.859996ms)
Feb  4 19:22:45.633: INFO: (7) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.523644ms)
Feb  4 19:22:45.635: INFO: (8) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.262992ms)
Feb  4 19:22:45.638: INFO: (9) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.070967ms)
Feb  4 19:22:45.641: INFO: (10) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.46273ms)
Feb  4 19:22:45.654: INFO: (11) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.506187ms)
Feb  4 19:22:45.657: INFO: (12) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.196804ms)
Feb  4 19:22:45.659: INFO: (13) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.314902ms)
Feb  4 19:22:45.662: INFO: (14) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.906546ms)
Feb  4 19:22:45.664: INFO: (15) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.33269ms)
Feb  4 19:22:45.667: INFO: (16) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.410961ms)
Feb  4 19:22:45.669: INFO: (17) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.545869ms)
Feb  4 19:22:45.672: INFO: (18) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.213169ms)
Feb  4 19:22:45.674: INFO: (19) /api/v1/nodes/kube-spawn-default-worker-iurq7e:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.302621ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:22:45.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jp2vp" for this suite.
Feb  4 19:22:51.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:22:51.737: INFO: namespace: e2e-tests-proxy-jp2vp, resource: bindings, ignored listing per whitelist
Feb  4 19:22:51.897: INFO: namespace e2e-tests-proxy-jp2vp deletion completed in 6.221047063s

• [SLOW TEST:6.360 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:22:51.897: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-43e3bfbb-28b2-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:22:52.111: INFO: Waiting up to 5m0s for pod "pod-secrets-43f3abd0-28b2-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-5m5vd" to be "success or failure"
Feb  4 19:22:52.127: INFO: Pod "pod-secrets-43f3abd0-28b2-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 15.996922ms
Feb  4 19:22:54.144: INFO: Pod "pod-secrets-43f3abd0-28b2-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033542722s
STEP: Saw pod success
Feb  4 19:22:54.144: INFO: Pod "pod-secrets-43f3abd0-28b2-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:22:54.174: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-secrets-43f3abd0-28b2-11e9-8d1f-5e319961b721 container secret-volume-test: <nil>
STEP: delete the pod
Feb  4 19:22:54.242: INFO: Waiting for pod pod-secrets-43f3abd0-28b2-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:22:54.245: INFO: Pod pod-secrets-43f3abd0-28b2-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:22:54.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5m5vd" for this suite.
Feb  4 19:23:00.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:23:00.502: INFO: namespace: e2e-tests-secrets-5m5vd, resource: bindings, ignored listing per whitelist
Feb  4 19:23:00.533: INFO: namespace e2e-tests-secrets-5m5vd deletion completed in 6.283836686s
STEP: Destroying namespace "e2e-tests-secret-namespace-vm8k4" for this suite.
Feb  4 19:23:06.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:23:06.687: INFO: namespace: e2e-tests-secret-namespace-vm8k4, resource: bindings, ignored listing per whitelist
Feb  4 19:23:06.714: INFO: namespace e2e-tests-secret-namespace-vm8k4 deletion completed in 6.181216877s

• [SLOW TEST:14.817 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:23:06.718: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4cc44abd-28b2-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:23:06.919: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4cc63136-28b2-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-wtzl7" to be "success or failure"
Feb  4 19:23:06.949: INFO: Pod "pod-projected-configmaps-4cc63136-28b2-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 30.635529ms
Feb  4 19:23:08.956: INFO: Pod "pod-projected-configmaps-4cc63136-28b2-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036859071s
STEP: Saw pod success
Feb  4 19:23:08.956: INFO: Pod "pod-projected-configmaps-4cc63136-28b2-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:23:08.963: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-projected-configmaps-4cc63136-28b2-11e9-8d1f-5e319961b721 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:23:09.053: INFO: Waiting for pod pod-projected-configmaps-4cc63136-28b2-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:23:09.065: INFO: Pod pod-projected-configmaps-4cc63136-28b2-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:23:09.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wtzl7" for this suite.
Feb  4 19:23:15.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:23:15.116: INFO: namespace: e2e-tests-projected-wtzl7, resource: bindings, ignored listing per whitelist
Feb  4 19:23:15.170: INFO: namespace e2e-tests-projected-wtzl7 deletion completed in 6.098414623s

• [SLOW TEST:8.455 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:23:15.170: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb  4 19:23:15.316: INFO: Pod name pod-release: Found 0 pods out of 1
Feb  4 19:23:20.329: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:23:21.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-hrdwg" for this suite.
Feb  4 19:23:27.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:23:27.584: INFO: namespace: e2e-tests-replication-controller-hrdwg, resource: bindings, ignored listing per whitelist
Feb  4 19:23:27.636: INFO: namespace e2e-tests-replication-controller-hrdwg deletion completed in 6.1901036s

• [SLOW TEST:12.466 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:23:27.637: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-592e5753-28b2-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:23:27.713: INFO: Waiting up to 5m0s for pod "pod-secrets-592edc7f-28b2-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-jcdxz" to be "success or failure"
Feb  4 19:23:27.719: INFO: Pod "pod-secrets-592edc7f-28b2-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 6.213734ms
Feb  4 19:23:29.723: INFO: Pod "pod-secrets-592edc7f-28b2-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009895793s
Feb  4 19:23:31.736: INFO: Pod "pod-secrets-592edc7f-28b2-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023234478s
STEP: Saw pod success
Feb  4 19:23:31.738: INFO: Pod "pod-secrets-592edc7f-28b2-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:23:31.758: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-secrets-592edc7f-28b2-11e9-8d1f-5e319961b721 container secret-volume-test: <nil>
STEP: delete the pod
Feb  4 19:23:31.818: INFO: Waiting for pod pod-secrets-592edc7f-28b2-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:23:31.824: INFO: Pod pod-secrets-592edc7f-28b2-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:23:31.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jcdxz" for this suite.
Feb  4 19:23:37.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:23:37.991: INFO: namespace: e2e-tests-secrets-jcdxz, resource: bindings, ignored listing per whitelist
Feb  4 19:23:38.023: INFO: namespace e2e-tests-secrets-jcdxz deletion completed in 6.195371671s

• [SLOW TEST:10.387 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:23:38.023: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-5f65343b-28b2-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:23:38.142: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f65afca-28b2-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-hhlpc" to be "success or failure"
Feb  4 19:23:38.161: INFO: Pod "pod-configmaps-5f65afca-28b2-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 18.988667ms
Feb  4 19:23:40.174: INFO: Pod "pod-configmaps-5f65afca-28b2-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031586978s
STEP: Saw pod success
Feb  4 19:23:40.174: INFO: Pod "pod-configmaps-5f65afca-28b2-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:23:40.176: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-configmaps-5f65afca-28b2-11e9-8d1f-5e319961b721 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:23:40.211: INFO: Waiting for pod pod-configmaps-5f65afca-28b2-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:23:40.243: INFO: Pod pod-configmaps-5f65afca-28b2-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:23:40.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hhlpc" for this suite.
Feb  4 19:23:46.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:23:46.350: INFO: namespace: e2e-tests-configmap-hhlpc, resource: bindings, ignored listing per whitelist
Feb  4 19:23:46.531: INFO: namespace e2e-tests-configmap-hhlpc deletion completed in 6.283717101s

• [SLOW TEST:8.507 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:23:46.531: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  4 19:23:46.607: INFO: PodSpec: initContainers in spec.initContainers
Feb  4 19:24:28.653: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-64732990-28b2-11e9-8d1f-5e319961b721", GenerateName:"", Namespace:"e2e-tests-init-container-hdf6z", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-hdf6z/pods/pod-init-64732990-28b2-11e9-8d1f-5e319961b721", UID:"64748670-28b2-11e9-88b2-2600a3ceccc4", ResourceVersion:"13306", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63684905026, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"607002516", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6g62l", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002584e40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6g62l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6g62l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6g62l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001eddf38), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kube-spawn-default-worker-iurq7e", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002515a40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001eddfb0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001eddfd0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001eddfd8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001eddfdc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905026, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905026, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905026, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905026, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.22.0.7", PodIP:"10.46.0.2", StartTime:(*v1.Time)(0xc0025b60c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0023bd420)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0023bd490)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c2d0a43a4d66e530f47c5e826801c6c03558e5156ac700d1c201d6fcc3db6ea7"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0025b6100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0025b60e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:24:28.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hdf6z" for this suite.
Feb  4 19:24:50.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:24:50.845: INFO: namespace: e2e-tests-init-container-hdf6z, resource: bindings, ignored listing per whitelist
Feb  4 19:24:50.854: INFO: namespace e2e-tests-init-container-hdf6z deletion completed in 22.173417731s

• [SLOW TEST:64.323 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:24:50.855: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rpztj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  4 19:24:50.957: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  4 19:25:09.224: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.46.0.2 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rpztj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:25:09.224: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:25:10.502: INFO: Found all expected endpoints: [netserver-0]
Feb  4 19:25:10.509: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.32.0.3 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rpztj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  4 19:25:10.510: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
Feb  4 19:25:11.642: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:25:11.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rpztj" for this suite.
Feb  4 19:25:35.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:25:35.795: INFO: namespace: e2e-tests-pod-network-test-rpztj, resource: bindings, ignored listing per whitelist
Feb  4 19:25:35.869: INFO: namespace e2e-tests-pod-network-test-rpztj deletion completed in 24.221981756s

• [SLOW TEST:45.014 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:25:35.869: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-bxchq
Feb  4 19:25:40.021: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-bxchq
STEP: checking the pod's current state and verifying that restartCount is present
Feb  4 19:25:40.030: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:29:41.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bxchq" for this suite.
Feb  4 19:29:47.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:29:47.374: INFO: namespace: e2e-tests-container-probe-bxchq, resource: bindings, ignored listing per whitelist
Feb  4 19:29:47.416: INFO: namespace e2e-tests-container-probe-bxchq deletion completed in 6.191051685s

• [SLOW TEST:251.547 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:29:47.416: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  4 19:29:47.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-fvk98'
Feb  4 19:29:47.596: INFO: stderr: ""
Feb  4 19:29:47.596: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb  4 19:29:52.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-fvk98 -o json'
Feb  4 19:29:52.862: INFO: stderr: ""
Feb  4 19:29:52.863: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-02-04T19:29:47Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-fvk98\",\n        \"resourceVersion\": \"13870\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-fvk98/pods/e2e-test-nginx-pod\",\n        \"uid\": \"3b9bd023-28b3-11e9-88b2-2600a3ceccc4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-pmvg5\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"kube-spawn-default-worker-iurq7e\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-pmvg5\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-pmvg5\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-04T19:29:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-04T19:29:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-04T19:29:50Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-04T19:29:47Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://fc23ff7cc4ef964df5d2f1dbb90dec6ab5874935aef20c966364c21d8abd8ffb\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-04T19:29:49Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.22.0.7\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.46.0.2\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-04T19:29:47Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  4 19:29:52.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 replace -f - --namespace=e2e-tests-kubectl-fvk98'
Feb  4 19:29:53.050: INFO: stderr: ""
Feb  4 19:29:53.050: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb  4 19:29:53.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-fvk98'
Feb  4 19:29:55.773: INFO: stderr: ""
Feb  4 19:29:55.773: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:29:55.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fvk98" for this suite.
Feb  4 19:30:01.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:30:01.919: INFO: namespace: e2e-tests-kubectl-fvk98, resource: bindings, ignored listing per whitelist
Feb  4 19:30:01.993: INFO: namespace e2e-tests-kubectl-fvk98 deletion completed in 6.21244797s

• [SLOW TEST:14.577 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:30:01.993: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:30:02.130: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb  4 19:30:07.137: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  4 19:30:07.138: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  4 19:30:09.141: INFO: Creating deployment "test-rollover-deployment"
Feb  4 19:30:09.155: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  4 19:30:11.161: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  4 19:30:11.166: INFO: Ensure that both replica sets have 1 created replica
Feb  4 19:30:11.172: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  4 19:30:11.177: INFO: Updating deployment test-rollover-deployment
Feb  4 19:30:11.177: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  4 19:30:13.193: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  4 19:30:13.198: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  4 19:30:13.203: INFO: all replica sets need to contain the pod-template-hash label
Feb  4 19:30:13.203: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905413, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  4 19:30:15.208: INFO: all replica sets need to contain the pod-template-hash label
Feb  4 19:30:15.208: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905413, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  4 19:30:17.222: INFO: all replica sets need to contain the pod-template-hash label
Feb  4 19:30:17.222: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905413, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  4 19:30:19.208: INFO: all replica sets need to contain the pod-template-hash label
Feb  4 19:30:19.208: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905413, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  4 19:30:21.208: INFO: all replica sets need to contain the pod-template-hash label
Feb  4 19:30:21.208: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905413, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  4 19:30:23.236: INFO: 
Feb  4 19:30:23.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905423, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905409, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  4 19:30:25.207: INFO: 
Feb  4 19:30:25.207: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  4 19:30:25.215: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-x7ljd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x7ljd/deployments/test-rollover-deployment,UID:4875acce-28b3-11e9-88b2-2600a3ceccc4,ResourceVersion:14015,Generation:2,CreationTimestamp:2019-02-04 19:30:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-04 19:30:09 +0000 UTC 2019-02-04 19:30:09 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-04 19:30:23 +0000 UTC 2019-02-04 19:30:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  4 19:30:25.227: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-x7ljd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x7ljd/replicasets/test-rollover-deployment-6b7f9d6597,UID:49abec62-28b3-11e9-88b2-2600a3ceccc4,ResourceVersion:14004,Generation:2,CreationTimestamp:2019-02-04 19:30:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 4875acce-28b3-11e9-88b2-2600a3ceccc4 0xc001bbb687 0xc001bbb688}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  4 19:30:25.227: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  4 19:30:25.227: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-x7ljd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x7ljd/replicasets/test-rollover-controller,UID:44438cd5-28b3-11e9-88b2-2600a3ceccc4,ResourceVersion:14014,Generation:2,CreationTimestamp:2019-02-04 19:30:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 4875acce-28b3-11e9-88b2-2600a3ceccc4 0xc001bbb437 0xc001bbb438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  4 19:30:25.227: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-x7ljd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x7ljd/replicasets/test-rollover-deployment-6586df867b,UID:48795804-28b3-11e9-88b2-2600a3ceccc4,ResourceVersion:13978,Generation:2,CreationTimestamp:2019-02-04 19:30:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 4875acce-28b3-11e9-88b2-2600a3ceccc4 0xc001bbb557 0xc001bbb558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  4 19:30:25.232: INFO: Pod "test-rollover-deployment-6b7f9d6597-zcx78" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-zcx78,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-x7ljd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-x7ljd/pods/test-rollover-deployment-6b7f9d6597-zcx78,UID:49ba0698-28b3-11e9-88b2-2600a3ceccc4,ResourceVersion:13987,Generation:0,CreationTimestamp:2019-02-04 19:30:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 49abec62-28b3-11e9-88b2-2600a3ceccc4 0xc001b17fe7 0xc001b17fe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wf94t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wf94t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wf94t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-pqanhr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0004b64b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0004b6930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:30:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:30:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:30:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:30:11 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.5,PodIP:10.32.0.4,StartTime:2019-02-04 19:30:11 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-04 19:30:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://37bd337895bed807cc5afc7c12b0f9231d0412a9c32bacb523ca11ece82226db}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:30:25.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-x7ljd" for this suite.
Feb  4 19:30:31.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:30:31.282: INFO: namespace: e2e-tests-deployment-x7ljd, resource: bindings, ignored listing per whitelist
Feb  4 19:30:31.336: INFO: namespace e2e-tests-deployment-x7ljd deletion completed in 6.098779001s

• [SLOW TEST:29.342 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:30:31.343: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-55bbab1b-28b3-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:30:31.428: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-55bce730-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-klshj" to be "success or failure"
Feb  4 19:30:31.465: INFO: Pod "pod-projected-secrets-55bce730-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 37.236881ms
Feb  4 19:30:33.467: INFO: Pod "pod-projected-secrets-55bce730-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038937696s
STEP: Saw pod success
Feb  4 19:30:33.467: INFO: Pod "pod-projected-secrets-55bce730-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:30:33.472: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-projected-secrets-55bce730-28b3-11e9-8d1f-5e319961b721 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  4 19:30:33.514: INFO: Waiting for pod pod-projected-secrets-55bce730-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:30:33.531: INFO: Pod pod-projected-secrets-55bce730-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:30:33.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-klshj" for this suite.
Feb  4 19:30:39.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:30:39.608: INFO: namespace: e2e-tests-projected-klshj, resource: bindings, ignored listing per whitelist
Feb  4 19:30:39.640: INFO: namespace e2e-tests-projected-klshj deletion completed in 6.104251419s

• [SLOW TEST:8.296 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:30:39.641: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb  4 19:30:41.730: INFO: Pod pod-hostip-5aadc153-28b3-11e9-8d1f-5e319961b721 has hostIP: 10.22.0.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:30:41.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tz85f" for this suite.
Feb  4 19:31:03.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:31:03.786: INFO: namespace: e2e-tests-pods-tz85f, resource: bindings, ignored listing per whitelist
Feb  4 19:31:03.805: INFO: namespace e2e-tests-pods-tz85f deletion completed in 22.073044661s

• [SLOW TEST:24.164 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:31:03.805: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  4 19:31:06.434: INFO: Successfully updated pod "annotationupdate6916224a-28b3-11e9-8d1f-5e319961b721"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:31:10.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wlnk7" for this suite.
Feb  4 19:31:22.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:31:22.633: INFO: namespace: e2e-tests-projected-wlnk7, resource: bindings, ignored listing per whitelist
Feb  4 19:31:22.647: INFO: namespace e2e-tests-projected-wlnk7 deletion completed in 12.162723915s

• [SLOW TEST:18.841 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:31:22.647: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-ns6v4
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-ns6v4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-ns6v4
Feb  4 19:31:22.751: INFO: Found 0 stateful pods, waiting for 1
Feb  4 19:31:32.758: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  4 19:31:32.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-ns6v4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:31:33.045: INFO: stderr: ""
Feb  4 19:31:33.045: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:31:33.045: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:31:33.047: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  4 19:31:43.051: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  4 19:31:43.051: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:31:43.089: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Feb  4 19:31:43.090: INFO: ss-0  kube-spawn-default-worker-pqanhr  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:22 +0000 UTC  }]
Feb  4 19:31:43.094: INFO: 
Feb  4 19:31:43.094: INFO: StatefulSet ss has not reached scale 3, at 1
Feb  4 19:31:44.103: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.971267827s
Feb  4 19:31:45.116: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.962963694s
Feb  4 19:31:46.126: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.949252338s
Feb  4 19:31:47.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.93925719s
Feb  4 19:31:48.143: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.930777692s
Feb  4 19:31:49.152: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.921040441s
Feb  4 19:31:50.160: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.913574769s
Feb  4 19:31:51.169: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.905455139s
Feb  4 19:31:52.183: INFO: Verifying statefulset ss doesn't scale past 3 for another 896.155372ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-ns6v4
Feb  4 19:31:53.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-ns6v4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:31:53.361: INFO: stderr: ""
Feb  4 19:31:53.361: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:31:53.361: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:31:53.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-ns6v4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:31:53.502: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  4 19:31:53.502: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:31:53.502: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:31:53.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-ns6v4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:31:53.626: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  4 19:31:53.626: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:31:53.626: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:31:53.629: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Feb  4 19:32:03.637: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:32:03.637: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:32:03.637: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  4 19:32:03.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-ns6v4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:32:03.884: INFO: stderr: ""
Feb  4 19:32:03.884: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:32:03.884: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:32:03.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-ns6v4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:32:04.047: INFO: stderr: ""
Feb  4 19:32:04.047: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:32:04.047: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:32:04.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-ns6v4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:32:04.179: INFO: stderr: ""
Feb  4 19:32:04.179: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:32:04.179: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:32:04.179: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:32:04.181: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  4 19:32:14.229: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  4 19:32:14.229: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  4 19:32:14.229: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  4 19:32:14.266: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Feb  4 19:32:14.266: INFO: ss-0  kube-spawn-default-worker-pqanhr  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:22 +0000 UTC  }]
Feb  4 19:32:14.266: INFO: ss-1  kube-spawn-default-worker-iurq7e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  }]
Feb  4 19:32:14.266: INFO: ss-2  kube-spawn-default-worker-pqanhr  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  }]
Feb  4 19:32:14.266: INFO: 
Feb  4 19:32:14.266: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  4 19:32:15.273: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Feb  4 19:32:15.273: INFO: ss-0  kube-spawn-default-worker-pqanhr  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:22 +0000 UTC  }]
Feb  4 19:32:15.273: INFO: ss-1  kube-spawn-default-worker-iurq7e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  }]
Feb  4 19:32:15.273: INFO: ss-2  kube-spawn-default-worker-pqanhr  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  }]
Feb  4 19:32:15.274: INFO: 
Feb  4 19:32:15.274: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  4 19:32:16.289: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Feb  4 19:32:16.289: INFO: ss-0  kube-spawn-default-worker-pqanhr  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:22 +0000 UTC  }]
Feb  4 19:32:16.289: INFO: ss-1  kube-spawn-default-worker-iurq7e  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  }]
Feb  4 19:32:16.289: INFO: ss-2  kube-spawn-default-worker-pqanhr  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  }]
Feb  4 19:32:16.289: INFO: 
Feb  4 19:32:16.289: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  4 19:32:17.297: INFO: POD   NODE                              PHASE    GRACE  CONDITIONS
Feb  4 19:32:17.297: INFO: ss-2  kube-spawn-default-worker-pqanhr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:32:04 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:31:43 +0000 UTC  }]
Feb  4 19:32:17.297: INFO: 
Feb  4 19:32:17.298: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  4 19:32:18.306: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.960678939s
Feb  4 19:32:19.312: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.954698348s
Feb  4 19:32:20.334: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.948632188s
Feb  4 19:32:21.340: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.926577452s
Feb  4 19:32:22.347: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.920541229s
Feb  4 19:32:23.353: INFO: Verifying statefulset ss doesn't scale past 0 for another 913.481717ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-ns6v4
Feb  4 19:32:24.360: INFO: Scaling statefulset ss to 0
Feb  4 19:32:24.406: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  4 19:32:24.415: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ns6v4
Feb  4 19:32:24.422: INFO: Scaling statefulset ss to 0
Feb  4 19:32:24.438: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:32:24.441: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:32:24.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ns6v4" for this suite.
Feb  4 19:32:30.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:32:30.551: INFO: namespace: e2e-tests-statefulset-ns6v4, resource: bindings, ignored listing per whitelist
Feb  4 19:32:30.673: INFO: namespace e2e-tests-statefulset-ns6v4 deletion completed in 6.213664364s

• [SLOW TEST:68.026 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:32:30.674: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:32:30.853: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ce6087d-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-hbbtg" to be "success or failure"
Feb  4 19:32:30.867: INFO: Pod "downwardapi-volume-9ce6087d-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 13.536233ms
Feb  4 19:32:32.875: INFO: Pod "downwardapi-volume-9ce6087d-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021945595s
STEP: Saw pod success
Feb  4 19:32:32.875: INFO: Pod "downwardapi-volume-9ce6087d-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:32:32.888: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-9ce6087d-28b3-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:32:32.968: INFO: Waiting for pod downwardapi-volume-9ce6087d-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:32:32.982: INFO: Pod downwardapi-volume-9ce6087d-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:32:32.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hbbtg" for this suite.
Feb  4 19:32:39.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:32:39.104: INFO: namespace: e2e-tests-projected-hbbtg, resource: bindings, ignored listing per whitelist
Feb  4 19:32:39.189: INFO: namespace e2e-tests-projected-hbbtg deletion completed in 6.203223125s

• [SLOW TEST:8.515 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:32:39.189: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb  4 19:32:39.312: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-4gvhx" to be "success or failure"
Feb  4 19:32:39.330: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 17.440903ms
Feb  4 19:32:41.343: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030916393s
Feb  4 19:32:43.350: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037383213s
STEP: Saw pod success
Feb  4 19:32:43.350: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  4 19:32:43.359: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  4 19:32:43.450: INFO: Waiting for pod pod-host-path-test to disappear
Feb  4 19:32:43.481: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:32:43.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-4gvhx" for this suite.
Feb  4 19:32:49.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:32:49.634: INFO: namespace: e2e-tests-hostpath-4gvhx, resource: bindings, ignored listing per whitelist
Feb  4 19:32:49.644: INFO: namespace e2e-tests-hostpath-4gvhx deletion completed in 6.152157507s

• [SLOW TEST:10.455 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:32:49.644: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-x6tqp in namespace e2e-tests-proxy-mk2xk
I0204 19:32:49.739062      19 runners.go:184] Created replication controller with name: proxy-service-x6tqp, namespace: e2e-tests-proxy-mk2xk, replica count: 1
I0204 19:32:50.790106      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0204 19:32:51.790621      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0204 19:32:52.791140      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0204 19:32:53.791460      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0204 19:32:54.791798      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0204 19:32:55.793321      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0204 19:32:56.795663      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0204 19:32:57.797577      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0204 19:32:58.798060      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0204 19:32:59.798793      19 runners.go:184] proxy-service-x6tqp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  4 19:32:59.819: INFO: setup took 10.10998883s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  4 19:32:59.864: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 41.847875ms)
Feb  4 19:32:59.864: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 43.229849ms)
Feb  4 19:32:59.864: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 43.024383ms)
Feb  4 19:32:59.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 49.172913ms)
Feb  4 19:32:59.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 48.487342ms)
Feb  4 19:32:59.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 50.242836ms)
Feb  4 19:32:59.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 48.074673ms)
Feb  4 19:32:59.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 48.289958ms)
Feb  4 19:32:59.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 50.510607ms)
Feb  4 19:32:59.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 49.592368ms)
Feb  4 19:32:59.870: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 50.594592ms)
Feb  4 19:32:59.887: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 67.21684ms)
Feb  4 19:32:59.887: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 66.388193ms)
Feb  4 19:32:59.889: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 68.16542ms)
Feb  4 19:32:59.889: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 69.527213ms)
Feb  4 19:32:59.892: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 71.695439ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 16.188812ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 16.354906ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 16.458925ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 16.399085ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 16.363209ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 17.84026ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 16.500226ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 16.468211ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 16.58118ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 16.754068ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 16.479917ms)
Feb  4 19:32:59.910: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 16.685552ms)
Feb  4 19:32:59.911: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 16.613683ms)
Feb  4 19:32:59.911: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 16.729365ms)
Feb  4 19:32:59.911: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 16.810091ms)
Feb  4 19:32:59.911: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 17.29797ms)
Feb  4 19:32:59.924: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 13.274961ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 13.819483ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 13.484858ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 13.71315ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 14.094985ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 13.391011ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 13.566487ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 14.293046ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 13.522666ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 13.401247ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 13.845767ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 13.725575ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 14.008017ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 14.112902ms)
Feb  4 19:32:59.926: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 13.541489ms)
Feb  4 19:32:59.927: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 14.328845ms)
Feb  4 19:32:59.933: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 6.109918ms)
Feb  4 19:32:59.934: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 7.768373ms)
Feb  4 19:32:59.934: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 7.706171ms)
Feb  4 19:32:59.938: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 10.774519ms)
Feb  4 19:32:59.938: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 9.21106ms)
Feb  4 19:32:59.938: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 9.166535ms)
Feb  4 19:32:59.938: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 9.267363ms)
Feb  4 19:32:59.938: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 11.089741ms)
Feb  4 19:32:59.939: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 9.71668ms)
Feb  4 19:32:59.939: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 11.75404ms)
Feb  4 19:32:59.941: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 12.086832ms)
Feb  4 19:32:59.941: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 14.188757ms)
Feb  4 19:32:59.942: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 14.965782ms)
Feb  4 19:32:59.942: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 13.611013ms)
Feb  4 19:32:59.944: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 16.612156ms)
Feb  4 19:32:59.944: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 15.298076ms)
Feb  4 19:32:59.949: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 5.43274ms)
Feb  4 19:32:59.949: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 5.664259ms)
Feb  4 19:32:59.953: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 9.404142ms)
Feb  4 19:32:59.954: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 9.164601ms)
Feb  4 19:32:59.954: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 9.212656ms)
Feb  4 19:32:59.955: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 10.64409ms)
Feb  4 19:32:59.957: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 12.729017ms)
Feb  4 19:32:59.961: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 16.489546ms)
Feb  4 19:32:59.961: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 16.245182ms)
Feb  4 19:32:59.962: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 17.793998ms)
Feb  4 19:32:59.963: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 18.400102ms)
Feb  4 19:32:59.963: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 18.692834ms)
Feb  4 19:32:59.963: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 18.930471ms)
Feb  4 19:32:59.963: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 19.070562ms)
Feb  4 19:32:59.964: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 19.606641ms)
Feb  4 19:32:59.964: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 19.94076ms)
Feb  4 19:32:59.972: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 7.482972ms)
Feb  4 19:32:59.972: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 8.057792ms)
Feb  4 19:32:59.972: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 7.48121ms)
Feb  4 19:32:59.972: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 7.625516ms)
Feb  4 19:32:59.974: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 10.392401ms)
Feb  4 19:32:59.974: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 10.551275ms)
Feb  4 19:32:59.974: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 10.38195ms)
Feb  4 19:32:59.975: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 10.40997ms)
Feb  4 19:32:59.975: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 10.652334ms)
Feb  4 19:32:59.975: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 10.59249ms)
Feb  4 19:32:59.975: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 10.799168ms)
Feb  4 19:32:59.976: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 11.767327ms)
Feb  4 19:32:59.976: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 11.782836ms)
Feb  4 19:32:59.976: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 11.938622ms)
Feb  4 19:32:59.976: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 11.789708ms)
Feb  4 19:32:59.976: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 11.735829ms)
Feb  4 19:32:59.986: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 9.998052ms)
Feb  4 19:32:59.987: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 7.199968ms)
Feb  4 19:32:59.987: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 11.217431ms)
Feb  4 19:32:59.987: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 6.17335ms)
Feb  4 19:32:59.987: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 10.971263ms)
Feb  4 19:32:59.987: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 10.433873ms)
Feb  4 19:32:59.987: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 10.674526ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 11.167709ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 11.626518ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 11.281928ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 11.173313ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 11.408291ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 11.010919ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 11.154174ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 11.225522ms)
Feb  4 19:32:59.988: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 11.745158ms)
Feb  4 19:32:59.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 5.690572ms)
Feb  4 19:32:59.994: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 5.752789ms)
Feb  4 19:32:59.998: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 9.314547ms)
Feb  4 19:32:59.999: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 10.229128ms)
Feb  4 19:32:59.999: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 10.801828ms)
Feb  4 19:32:59.999: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 10.677554ms)
Feb  4 19:33:00.000: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 12.060282ms)
Feb  4 19:33:00.000: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 11.408035ms)
Feb  4 19:33:00.001: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 12.726018ms)
Feb  4 19:33:00.001: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 12.693439ms)
Feb  4 19:33:00.002: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 13.356502ms)
Feb  4 19:33:00.002: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 12.868705ms)
Feb  4 19:33:00.003: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 14.011054ms)
Feb  4 19:33:00.003: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 14.386068ms)
Feb  4 19:33:00.003: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 13.992558ms)
Feb  4 19:33:00.004: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 15.701965ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 8.164953ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 8.289446ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 8.281133ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 8.889055ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 8.977696ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 8.390407ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 8.465937ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 8.405762ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 8.394284ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 8.463658ms)
Feb  4 19:33:00.013: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 8.360005ms)
Feb  4 19:33:00.016: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 12.002191ms)
Feb  4 19:33:00.016: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 11.365155ms)
Feb  4 19:33:00.016: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 11.243978ms)
Feb  4 19:33:00.016: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 11.452889ms)
Feb  4 19:33:00.016: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 11.395365ms)
Feb  4 19:33:00.024: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 7.453442ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 12.092654ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 12.136256ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 12.152214ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 12.106785ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 12.119576ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 12.177011ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 12.161439ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 12.300036ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 12.28096ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 12.196572ms)
Feb  4 19:33:00.029: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 12.327107ms)
Feb  4 19:33:00.031: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 14.001909ms)
Feb  4 19:33:00.031: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 14.07908ms)
Feb  4 19:33:00.031: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 14.014475ms)
Feb  4 19:33:00.031: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 14.691668ms)
Feb  4 19:33:00.046: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 13.79365ms)
Feb  4 19:33:00.046: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 13.76329ms)
Feb  4 19:33:00.046: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 14.203193ms)
Feb  4 19:33:00.046: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 14.29006ms)
Feb  4 19:33:00.046: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 13.686726ms)
Feb  4 19:33:00.046: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 14.530036ms)
Feb  4 19:33:00.046: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 14.126856ms)
Feb  4 19:33:00.047: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 14.741013ms)
Feb  4 19:33:00.047: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 14.842708ms)
Feb  4 19:33:00.047: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 15.23501ms)
Feb  4 19:33:00.047: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 15.649857ms)
Feb  4 19:33:00.048: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 15.979687ms)
Feb  4 19:33:00.048: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 16.197489ms)
Feb  4 19:33:00.049: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 17.434828ms)
Feb  4 19:33:00.049: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 17.074419ms)
Feb  4 19:33:00.050: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 17.624523ms)
Feb  4 19:33:00.057: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 6.56985ms)
Feb  4 19:33:00.064: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 14.124033ms)
Feb  4 19:33:00.064: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 12.05089ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 14.355192ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 14.118838ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 14.495979ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 14.204919ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 14.417028ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 14.250468ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 14.207294ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 14.325669ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 14.310521ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 14.489263ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 14.456897ms)
Feb  4 19:33:00.065: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 14.854277ms)
Feb  4 19:33:00.067: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 16.904938ms)
Feb  4 19:33:00.072: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 5.119486ms)
Feb  4 19:33:00.080: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 13.17083ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 13.026145ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 12.991929ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 13.231947ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 13.417569ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 13.295789ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 13.124855ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 13.432179ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 13.291097ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 13.21834ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 13.538043ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 13.263472ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 13.116455ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 13.21971ms)
Feb  4 19:33:00.081: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 13.207085ms)
Feb  4 19:33:00.089: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 8.262245ms)
Feb  4 19:33:00.089: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 8.53521ms)
Feb  4 19:33:00.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 9.056036ms)
Feb  4 19:33:00.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 7.936912ms)
Feb  4 19:33:00.090: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 8.010394ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 10.330157ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 10.656723ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 10.541933ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 10.816021ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 9.097089ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 11.804095ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 10.548611ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 12.23091ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 11.991463ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 10.670987ms)
Feb  4 19:33:00.093: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 10.655452ms)
Feb  4 19:33:00.099: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 5.44915ms)
Feb  4 19:33:00.100: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 6.881098ms)
Feb  4 19:33:00.100: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 5.841017ms)
Feb  4 19:33:00.101: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 6.729176ms)
Feb  4 19:33:00.101: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 7.052081ms)
Feb  4 19:33:00.101: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 7.990535ms)
Feb  4 19:33:00.106: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 11.189138ms)
Feb  4 19:33:00.106: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 11.766501ms)
Feb  4 19:33:00.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 12.070106ms)
Feb  4 19:33:00.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 12.281742ms)
Feb  4 19:33:00.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 12.260825ms)
Feb  4 19:33:00.107: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 12.470559ms)
Feb  4 19:33:00.111: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 16.136536ms)
Feb  4 19:33:00.113: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 18.443973ms)
Feb  4 19:33:00.113: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 18.594754ms)
Feb  4 19:33:00.113: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 18.722902ms)
Feb  4 19:33:00.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 7.312291ms)
Feb  4 19:33:00.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 7.106616ms)
Feb  4 19:33:00.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 6.986398ms)
Feb  4 19:33:00.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 7.888896ms)
Feb  4 19:33:00.121: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 7.090468ms)
Feb  4 19:33:00.122: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 7.800082ms)
Feb  4 19:33:00.123: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 9.334156ms)
Feb  4 19:33:00.123: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 10.377854ms)
Feb  4 19:33:00.123: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 9.971647ms)
Feb  4 19:33:00.123: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 9.617244ms)
Feb  4 19:33:00.123: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 9.763714ms)
Feb  4 19:33:00.124: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 10.135723ms)
Feb  4 19:33:00.124: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 9.674883ms)
Feb  4 19:33:00.124: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 10.173675ms)
Feb  4 19:33:00.124: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 9.633855ms)
Feb  4 19:33:00.125: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 11.754034ms)
Feb  4 19:33:00.133: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 6.818844ms)
Feb  4 19:33:00.133: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 8.438184ms)
Feb  4 19:33:00.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 9.637058ms)
Feb  4 19:33:00.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 10.003741ms)
Feb  4 19:33:00.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 9.943242ms)
Feb  4 19:33:00.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 9.930469ms)
Feb  4 19:33:00.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 9.920049ms)
Feb  4 19:33:00.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 8.766577ms)
Feb  4 19:33:00.135: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 10.304096ms)
Feb  4 19:33:00.136: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 11.463315ms)
Feb  4 19:33:00.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 14.455164ms)
Feb  4 19:33:00.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 13.378146ms)
Feb  4 19:33:00.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 14.24816ms)
Feb  4 19:33:00.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 14.547347ms)
Feb  4 19:33:00.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 14.217633ms)
Feb  4 19:33:00.189: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 63.869022ms)
Feb  4 19:33:00.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 6.155237ms)
Feb  4 19:33:00.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 6.18432ms)
Feb  4 19:33:00.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 6.601399ms)
Feb  4 19:33:00.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 6.298257ms)
Feb  4 19:33:00.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 6.62492ms)
Feb  4 19:33:00.196: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 6.494278ms)
Feb  4 19:33:00.199: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 9.295464ms)
Feb  4 19:33:00.199: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 9.763767ms)
Feb  4 19:33:00.199: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 9.62929ms)
Feb  4 19:33:00.199: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 8.903317ms)
Feb  4 19:33:00.199: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 9.799168ms)
Feb  4 19:33:00.199: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 9.484072ms)
Feb  4 19:33:00.199: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 9.66195ms)
Feb  4 19:33:00.199: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 9.905533ms)
Feb  4 19:33:00.200: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 10.650961ms)
Feb  4 19:33:00.200: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 11.094343ms)
Feb  4 19:33:00.209: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 7.80073ms)
Feb  4 19:33:00.211: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 9.581079ms)
Feb  4 19:33:00.211: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 9.397775ms)
Feb  4 19:33:00.211: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 9.94527ms)
Feb  4 19:33:00.211: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 9.511725ms)
Feb  4 19:33:00.211: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 10.032293ms)
Feb  4 19:33:00.211: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 9.985484ms)
Feb  4 19:33:00.211: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 9.798725ms)
Feb  4 19:33:00.214: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 12.411279ms)
Feb  4 19:33:00.214: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 12.433799ms)
Feb  4 19:33:00.215: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 13.340179ms)
Feb  4 19:33:00.215: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 14.00552ms)
Feb  4 19:33:00.217: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 15.173971ms)
Feb  4 19:33:00.217: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 15.150127ms)
Feb  4 19:33:00.217: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 15.203534ms)
Feb  4 19:33:00.218: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 15.803641ms)
Feb  4 19:33:00.224: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:1080/proxy/rewri... (200; 5.879074ms)
Feb  4 19:33:00.225: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv/proxy/rewriteme"... (200; 5.511928ms)
Feb  4 19:33:00.226: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:462/proxy/: tls qux (200; 8.29434ms)
Feb  4 19:33:00.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:1080/proxy/... (200; 6.778587ms)
Feb  4 19:33:00.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 8.892441ms)
Feb  4 19:33:00.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:160/proxy/: foo (200; 9.102846ms)
Feb  4 19:33:00.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 9.001478ms)
Feb  4 19:33:00.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/http:proxy-service-x6tqp-kxbkv:162/proxy/: bar (200; 7.527809ms)
Feb  4 19:33:00.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:460/proxy/: tls baz (200; 9.188474ms)
Feb  4 19:33:00.227: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mk2xk/pods/https:proxy-service-x6tqp-kxbkv:443/proxy/... (200; 9.271624ms)
Feb  4 19:33:00.231: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname2/proxy/: bar (200; 12.924921ms)
Feb  4 19:33:00.232: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname2/proxy/: bar (200; 12.315116ms)
Feb  4 19:33:00.232: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname2/proxy/: tls qux (200; 12.24133ms)
Feb  4 19:33:00.232: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/proxy-service-x6tqp:portname1/proxy/: foo (200; 12.106433ms)
Feb  4 19:33:00.232: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/http:proxy-service-x6tqp:portname1/proxy/: foo (200; 12.484634ms)
Feb  4 19:33:00.232: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mk2xk/services/https:proxy-service-x6tqp:tlsportname1/proxy/: tls baz (200; 14.160049ms)
STEP: deleting ReplicationController proxy-service-x6tqp in namespace e2e-tests-proxy-mk2xk, will wait for the garbage collector to delete the pods
Feb  4 19:33:00.293: INFO: Deleting ReplicationController proxy-service-x6tqp took: 7.386347ms
Feb  4 19:33:00.393: INFO: Terminating ReplicationController proxy-service-x6tqp pods took: 100.400108ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:33:02.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-mk2xk" for this suite.
Feb  4 19:33:08.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:33:08.327: INFO: namespace: e2e-tests-proxy-mk2xk, resource: bindings, ignored listing per whitelist
Feb  4 19:33:08.393: INFO: namespace e2e-tests-proxy-mk2xk deletion completed in 6.196041446s

• [SLOW TEST:18.749 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:33:08.393: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb  4 19:33:10.552: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-b357deb9-28b3-11e9-8d1f-5e319961b721", GenerateName:"", Namespace:"e2e-tests-pods-t9g9s", SelfLink:"/api/v1/namespaces/e2e-tests-pods-t9g9s/pods/pod-submit-remove-b357deb9-28b3-11e9-8d1f-5e319961b721", UID:"b35e03cc-28b3-11e9-88b2-2600a3ceccc4", ResourceVersion:"14641", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63684905588, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"464817986"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-qf2n8", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001d23600), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qf2n8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0020deff8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"kube-spawn-default-worker-pqanhr", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001d32600), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020df030)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0020df050)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0020df058), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0020df05c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905588, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905590, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905590, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684905588, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.22.0.5", PodIP:"10.32.0.3", StartTime:(*v1.Time)(0xc00075b1c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00075b1e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://b01fc069821b3e568907c6707b00808e098181e5f834af4250a8845efeb684b1"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb  4 19:33:15.618: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:33:15.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-t9g9s" for this suite.
Feb  4 19:33:21.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:33:21.810: INFO: namespace: e2e-tests-pods-t9g9s, resource: bindings, ignored listing per whitelist
Feb  4 19:33:21.836: INFO: namespace e2e-tests-pods-t9g9s deletion completed in 6.190425616s

• [SLOW TEST:13.443 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:33:21.836: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-bb6cf83a-28b3-11e9-8d1f-5e319961b721
STEP: Creating secret with name s-test-opt-upd-bb6cf908-28b3-11e9-8d1f-5e319961b721
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-bb6cf83a-28b3-11e9-8d1f-5e319961b721
STEP: Updating secret s-test-opt-upd-bb6cf908-28b3-11e9-8d1f-5e319961b721
STEP: Creating secret with name s-test-opt-create-bb6cf96f-28b3-11e9-8d1f-5e319961b721
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:33:28.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b8l2j" for this suite.
Feb  4 19:33:50.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:33:50.455: INFO: namespace: e2e-tests-projected-b8l2j, resource: bindings, ignored listing per whitelist
Feb  4 19:33:50.474: INFO: namespace e2e-tests-projected-b8l2j deletion completed in 22.115794463s

• [SLOW TEST:28.637 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:33:50.474: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cc6ec23c-28b3-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:33:50.570: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc6f6327-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-9pkm4" to be "success or failure"
Feb  4 19:33:50.591: INFO: Pod "pod-configmaps-cc6f6327-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 21.168446ms
Feb  4 19:33:52.599: INFO: Pod "pod-configmaps-cc6f6327-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029232063s
Feb  4 19:33:54.611: INFO: Pod "pod-configmaps-cc6f6327-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040973176s
STEP: Saw pod success
Feb  4 19:33:54.611: INFO: Pod "pod-configmaps-cc6f6327-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:33:54.614: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-configmaps-cc6f6327-28b3-11e9-8d1f-5e319961b721 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:33:54.643: INFO: Waiting for pod pod-configmaps-cc6f6327-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:33:54.650: INFO: Pod pod-configmaps-cc6f6327-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:33:54.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9pkm4" for this suite.
Feb  4 19:34:00.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:34:00.798: INFO: namespace: e2e-tests-configmap-9pkm4, resource: bindings, ignored listing per whitelist
Feb  4 19:34:00.803: INFO: namespace e2e-tests-configmap-9pkm4 deletion completed in 6.146027222s

• [SLOW TEST:10.329 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:34:00.803: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d2942e45-28b3-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:34:00.880: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d2950aa8-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-f5b6m" to be "success or failure"
Feb  4 19:34:00.895: INFO: Pod "pod-projected-configmaps-d2950aa8-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 15.268377ms
Feb  4 19:34:02.897: INFO: Pod "pod-projected-configmaps-d2950aa8-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017406473s
Feb  4 19:34:04.909: INFO: Pod "pod-projected-configmaps-d2950aa8-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029637898s
STEP: Saw pod success
Feb  4 19:34:04.910: INFO: Pod "pod-projected-configmaps-d2950aa8-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:34:04.944: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-projected-configmaps-d2950aa8-28b3-11e9-8d1f-5e319961b721 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:34:04.991: INFO: Waiting for pod pod-projected-configmaps-d2950aa8-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:34:04.999: INFO: Pod pod-projected-configmaps-d2950aa8-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:34:04.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f5b6m" for this suite.
Feb  4 19:34:11.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:34:11.173: INFO: namespace: e2e-tests-projected-f5b6m, resource: bindings, ignored listing per whitelist
Feb  4 19:34:11.184: INFO: namespace e2e-tests-projected-f5b6m deletion completed in 6.183254226s

• [SLOW TEST:10.381 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:34:11.185: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:34:11.324: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8ca8848-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-zjsxr" to be "success or failure"
Feb  4 19:34:11.347: INFO: Pod "downwardapi-volume-d8ca8848-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 22.967584ms
Feb  4 19:34:13.358: INFO: Pod "downwardapi-volume-d8ca8848-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033574682s
Feb  4 19:34:15.364: INFO: Pod "downwardapi-volume-d8ca8848-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039927927s
STEP: Saw pod success
Feb  4 19:34:15.364: INFO: Pod "downwardapi-volume-d8ca8848-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:34:15.371: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod downwardapi-volume-d8ca8848-28b3-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:34:15.463: INFO: Waiting for pod downwardapi-volume-d8ca8848-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:34:15.489: INFO: Pod downwardapi-volume-d8ca8848-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:34:15.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zjsxr" for this suite.
Feb  4 19:34:21.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:34:21.619: INFO: namespace: e2e-tests-projected-zjsxr, resource: bindings, ignored listing per whitelist
Feb  4 19:34:21.641: INFO: namespace e2e-tests-projected-zjsxr deletion completed in 6.142309537s

• [SLOW TEST:10.457 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:34:21.641: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-df00fde2-28b3-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:34:21.725: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-df01c243-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-8r54f" to be "success or failure"
Feb  4 19:34:21.749: INFO: Pod "pod-projected-secrets-df01c243-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 23.467444ms
Feb  4 19:34:23.751: INFO: Pod "pod-projected-secrets-df01c243-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025535017s
STEP: Saw pod success
Feb  4 19:34:23.751: INFO: Pod "pod-projected-secrets-df01c243-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:34:23.754: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-projected-secrets-df01c243-28b3-11e9-8d1f-5e319961b721 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  4 19:34:23.781: INFO: Waiting for pod pod-projected-secrets-df01c243-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:34:23.790: INFO: Pod pod-projected-secrets-df01c243-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:34:23.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8r54f" for this suite.
Feb  4 19:34:29.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:34:29.968: INFO: namespace: e2e-tests-projected-8r54f, resource: bindings, ignored listing per whitelist
Feb  4 19:34:29.986: INFO: namespace e2e-tests-projected-8r54f deletion completed in 6.191770831s

• [SLOW TEST:8.344 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:34:29.986: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  4 19:34:30.135: INFO: Waiting up to 5m0s for pod "pod-e4027b29-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-ptmbp" to be "success or failure"
Feb  4 19:34:30.151: INFO: Pod "pod-e4027b29-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 16.350791ms
Feb  4 19:34:32.154: INFO: Pod "pod-e4027b29-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01932498s
STEP: Saw pod success
Feb  4 19:34:32.154: INFO: Pod "pod-e4027b29-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:34:32.157: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-e4027b29-28b3-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 19:34:32.182: INFO: Waiting for pod pod-e4027b29-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:34:32.187: INFO: Pod pod-e4027b29-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:34:32.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ptmbp" for this suite.
Feb  4 19:34:38.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:34:38.380: INFO: namespace: e2e-tests-emptydir-ptmbp, resource: bindings, ignored listing per whitelist
Feb  4 19:34:38.425: INFO: namespace e2e-tests-emptydir-ptmbp deletion completed in 6.235389527s

• [SLOW TEST:8.439 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:34:38.425: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e90804de-28b3-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:34:38.578: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e90a2fd1-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-dtrkv" to be "success or failure"
Feb  4 19:34:38.620: INFO: Pod "pod-projected-configmaps-e90a2fd1-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 40.696946ms
Feb  4 19:34:40.638: INFO: Pod "pod-projected-configmaps-e90a2fd1-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.058097336s
STEP: Saw pod success
Feb  4 19:34:40.638: INFO: Pod "pod-projected-configmaps-e90a2fd1-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:34:40.642: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-projected-configmaps-e90a2fd1-28b3-11e9-8d1f-5e319961b721 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:34:40.680: INFO: Waiting for pod pod-projected-configmaps-e90a2fd1-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:34:40.690: INFO: Pod pod-projected-configmaps-e90a2fd1-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:34:40.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dtrkv" for this suite.
Feb  4 19:34:46.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:34:46.874: INFO: namespace: e2e-tests-projected-dtrkv, resource: bindings, ignored listing per whitelist
Feb  4 19:34:46.902: INFO: namespace e2e-tests-projected-dtrkv deletion completed in 6.208886032s

• [SLOW TEST:8.477 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:34:46.902: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  4 19:34:47.083: INFO: Waiting up to 5m0s for pod "downward-api-ee1b0dc7-28b3-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-xlgkn" to be "success or failure"
Feb  4 19:34:47.094: INFO: Pod "downward-api-ee1b0dc7-28b3-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 10.37861ms
Feb  4 19:34:49.103: INFO: Pod "downward-api-ee1b0dc7-28b3-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019317934s
STEP: Saw pod success
Feb  4 19:34:49.106: INFO: Pod "downward-api-ee1b0dc7-28b3-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:34:49.119: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downward-api-ee1b0dc7-28b3-11e9-8d1f-5e319961b721 container dapi-container: <nil>
STEP: delete the pod
Feb  4 19:34:49.167: INFO: Waiting for pod downward-api-ee1b0dc7-28b3-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:34:49.176: INFO: Pod downward-api-ee1b0dc7-28b3-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:34:49.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xlgkn" for this suite.
Feb  4 19:34:55.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:34:55.403: INFO: namespace: e2e-tests-downward-api-xlgkn, resource: bindings, ignored listing per whitelist
Feb  4 19:34:55.418: INFO: namespace e2e-tests-downward-api-xlgkn deletion completed in 6.238368167s

• [SLOW TEST:8.516 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:34:55.418: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  4 19:34:59.634: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  4 19:34:59.653: INFO: Pod pod-with-poststart-http-hook still exists
Feb  4 19:35:01.653: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  4 19:35:01.667: INFO: Pod pod-with-poststart-http-hook still exists
Feb  4 19:35:03.653: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  4 19:35:03.660: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:35:03.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zsmmh" for this suite.
Feb  4 19:35:25.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:35:25.801: INFO: namespace: e2e-tests-container-lifecycle-hook-zsmmh, resource: bindings, ignored listing per whitelist
Feb  4 19:35:25.916: INFO: namespace e2e-tests-container-lifecycle-hook-zsmmh deletion completed in 22.242616989s

• [SLOW TEST:30.498 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:35:25.917: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:35:30.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-ffqpb" for this suite.
Feb  4 19:35:36.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:35:36.208: INFO: namespace: e2e-tests-kubelet-test-ffqpb, resource: bindings, ignored listing per whitelist
Feb  4 19:35:36.240: INFO: namespace e2e-tests-kubelet-test-ffqpb deletion completed in 6.205677542s

• [SLOW TEST:10.323 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:35:36.242: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb  4 19:35:36.332: INFO: Waiting up to 5m0s for pod "client-containers-0b799342-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-containers-q89fm" to be "success or failure"
Feb  4 19:35:36.338: INFO: Pod "client-containers-0b799342-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 6.081477ms
Feb  4 19:35:38.348: INFO: Pod "client-containers-0b799342-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015811592s
STEP: Saw pod success
Feb  4 19:35:38.348: INFO: Pod "client-containers-0b799342-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:35:38.361: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod client-containers-0b799342-28b4-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 19:35:38.425: INFO: Waiting for pod client-containers-0b799342-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:35:38.432: INFO: Pod client-containers-0b799342-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:35:38.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-q89fm" for this suite.
Feb  4 19:35:44.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:35:44.546: INFO: namespace: e2e-tests-containers-q89fm, resource: bindings, ignored listing per whitelist
Feb  4 19:35:44.668: INFO: namespace e2e-tests-containers-q89fm deletion completed in 6.232090214s

• [SLOW TEST:8.426 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:35:44.669: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0204 19:35:45.864038      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  4 19:35:45.864: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:35:45.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cdzpr" for this suite.
Feb  4 19:35:51.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:35:52.029: INFO: namespace: e2e-tests-gc-cdzpr, resource: bindings, ignored listing per whitelist
Feb  4 19:35:52.059: INFO: namespace e2e-tests-gc-cdzpr deletion completed in 6.192588437s

• [SLOW TEST:7.391 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:35:52.060: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  4 19:35:52.179: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-a,UID:14ebfaeb-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15232,Generation:0,CreationTimestamp:2019-02-04 19:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  4 19:35:52.179: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-a,UID:14ebfaeb-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15232,Generation:0,CreationTimestamp:2019-02-04 19:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  4 19:36:02.213: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-a,UID:14ebfaeb-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15248,Generation:0,CreationTimestamp:2019-02-04 19:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  4 19:36:02.219: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-a,UID:14ebfaeb-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15248,Generation:0,CreationTimestamp:2019-02-04 19:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  4 19:36:12.241: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-a,UID:14ebfaeb-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15263,Generation:0,CreationTimestamp:2019-02-04 19:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  4 19:36:12.241: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-a,UID:14ebfaeb-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15263,Generation:0,CreationTimestamp:2019-02-04 19:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  4 19:36:22.265: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-a,UID:14ebfaeb-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15278,Generation:0,CreationTimestamp:2019-02-04 19:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  4 19:36:22.266: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-a,UID:14ebfaeb-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15278,Generation:0,CreationTimestamp:2019-02-04 19:35:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  4 19:36:32.281: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-b,UID:2cd1e35e-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15293,Generation:0,CreationTimestamp:2019-02-04 19:36:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  4 19:36:32.282: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-b,UID:2cd1e35e-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15293,Generation:0,CreationTimestamp:2019-02-04 19:36:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  4 19:36:42.309: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-b,UID:2cd1e35e-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15308,Generation:0,CreationTimestamp:2019-02-04 19:36:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  4 19:36:42.310: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-v4hd8,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4hd8/configmaps/e2e-watch-test-configmap-b,UID:2cd1e35e-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15308,Generation:0,CreationTimestamp:2019-02-04 19:36:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:36:52.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-v4hd8" for this suite.
Feb  4 19:36:58.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:36:58.407: INFO: namespace: e2e-tests-watch-v4hd8, resource: bindings, ignored listing per whitelist
Feb  4 19:36:58.440: INFO: namespace e2e-tests-watch-v4hd8 deletion completed in 6.101068477s

• [SLOW TEST:66.379 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:36:58.440: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-3c77b05e-28b4-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:36:58.555: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c79af42-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-jljwh" to be "success or failure"
Feb  4 19:36:58.591: INFO: Pod "pod-configmaps-3c79af42-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 35.206181ms
Feb  4 19:37:00.610: INFO: Pod "pod-configmaps-3c79af42-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054027286s
Feb  4 19:37:02.616: INFO: Pod "pod-configmaps-3c79af42-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060517424s
STEP: Saw pod success
Feb  4 19:37:02.616: INFO: Pod "pod-configmaps-3c79af42-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:37:02.625: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-configmaps-3c79af42-28b4-11e9-8d1f-5e319961b721 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:37:02.769: INFO: Waiting for pod pod-configmaps-3c79af42-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:37:02.782: INFO: Pod pod-configmaps-3c79af42-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:37:02.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jljwh" for this suite.
Feb  4 19:37:08.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:37:08.992: INFO: namespace: e2e-tests-configmap-jljwh, resource: bindings, ignored listing per whitelist
Feb  4 19:37:09.009: INFO: namespace e2e-tests-configmap-jljwh deletion completed in 6.207874124s

• [SLOW TEST:10.569 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:37:09.009: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  4 19:37:09.107: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:37:13.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ckrjj" for this suite.
Feb  4 19:37:35.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:37:36.069: INFO: namespace: e2e-tests-init-container-ckrjj, resource: bindings, ignored listing per whitelist
Feb  4 19:37:36.104: INFO: namespace e2e-tests-init-container-ckrjj deletion completed in 22.243275869s

• [SLOW TEST:27.096 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:37:36.104: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb  4 19:37:36.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 api-versions'
Feb  4 19:37:36.311: INFO: stderr: ""
Feb  4 19:37:36.311: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:37:36.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wxn94" for this suite.
Feb  4 19:37:42.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:37:42.407: INFO: namespace: e2e-tests-kubectl-wxn94, resource: bindings, ignored listing per whitelist
Feb  4 19:37:42.542: INFO: namespace e2e-tests-kubectl-wxn94 deletion completed in 6.203058411s

• [SLOW TEST:6.437 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:37:42.542: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  4 19:37:42.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 create -f - --namespace=e2e-tests-kubectl-7w265'
Feb  4 19:37:43.399: INFO: stderr: ""
Feb  4 19:37:43.399: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  4 19:37:44.407: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 19:37:44.407: INFO: Found 0 / 1
Feb  4 19:37:45.411: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 19:37:45.411: INFO: Found 1 / 1
Feb  4 19:37:45.411: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  4 19:37:45.416: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 19:37:45.416: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  4 19:37:45.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 patch pod redis-master-vpkl8 --namespace=e2e-tests-kubectl-7w265 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  4 19:37:45.495: INFO: stderr: ""
Feb  4 19:37:45.495: INFO: stdout: "pod/redis-master-vpkl8 patched\n"
STEP: checking annotations
Feb  4 19:37:45.498: INFO: Selector matched 1 pods for map[app:redis]
Feb  4 19:37:45.498: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:37:45.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7w265" for this suite.
Feb  4 19:38:07.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:38:07.756: INFO: namespace: e2e-tests-kubectl-7w265, resource: bindings, ignored listing per whitelist
Feb  4 19:38:07.763: INFO: namespace e2e-tests-kubectl-7w265 deletion completed in 22.262656315s

• [SLOW TEST:25.220 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:38:07.764: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb  4 19:38:07.858: INFO: Waiting up to 5m0s for pod "var-expansion-65ca645a-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-var-expansion-6j6nz" to be "success or failure"
Feb  4 19:38:07.908: INFO: Pod "var-expansion-65ca645a-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 50.458281ms
Feb  4 19:38:09.924: INFO: Pod "var-expansion-65ca645a-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066439704s
Feb  4 19:38:11.935: INFO: Pod "var-expansion-65ca645a-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077011277s
STEP: Saw pod success
Feb  4 19:38:11.935: INFO: Pod "var-expansion-65ca645a-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:38:11.942: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod var-expansion-65ca645a-28b4-11e9-8d1f-5e319961b721 container dapi-container: <nil>
STEP: delete the pod
Feb  4 19:38:12.072: INFO: Waiting for pod var-expansion-65ca645a-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:38:12.085: INFO: Pod var-expansion-65ca645a-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:38:12.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6j6nz" for this suite.
Feb  4 19:38:18.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:38:18.187: INFO: namespace: e2e-tests-var-expansion-6j6nz, resource: bindings, ignored listing per whitelist
Feb  4 19:38:18.203: INFO: namespace e2e-tests-var-expansion-6j6nz deletion completed in 6.10763615s

• [SLOW TEST:10.439 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:38:18.203: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6c07e2aa-28b4-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:38:18.364: INFO: Waiting up to 5m0s for pod "pod-secrets-6c098a7b-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-22chk" to be "success or failure"
Feb  4 19:38:18.374: INFO: Pod "pod-secrets-6c098a7b-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 10.400313ms
Feb  4 19:38:20.378: INFO: Pod "pod-secrets-6c098a7b-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014442093s
STEP: Saw pod success
Feb  4 19:38:20.378: INFO: Pod "pod-secrets-6c098a7b-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:38:20.391: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-secrets-6c098a7b-28b4-11e9-8d1f-5e319961b721 container secret-env-test: <nil>
STEP: delete the pod
Feb  4 19:38:20.423: INFO: Waiting for pod pod-secrets-6c098a7b-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:38:20.434: INFO: Pod pod-secrets-6c098a7b-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:38:20.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-22chk" for this suite.
Feb  4 19:38:26.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:38:26.516: INFO: namespace: e2e-tests-secrets-22chk, resource: bindings, ignored listing per whitelist
Feb  4 19:38:26.744: INFO: namespace e2e-tests-secrets-22chk deletion completed in 6.307713218s

• [SLOW TEST:8.541 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:38:26.744: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-711d27c0-28b4-11e9-8d1f-5e319961b721
STEP: Creating configMap with name cm-test-opt-upd-711d27e9-28b4-11e9-8d1f-5e319961b721
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-711d27c0-28b4-11e9-8d1f-5e319961b721
STEP: Updating configmap cm-test-opt-upd-711d27e9-28b4-11e9-8d1f-5e319961b721
STEP: Creating configMap with name cm-test-opt-create-711d27f6-28b4-11e9-8d1f-5e319961b721
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:38:33.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-krpk6" for this suite.
Feb  4 19:38:55.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:38:55.221: INFO: namespace: e2e-tests-configmap-krpk6, resource: bindings, ignored listing per whitelist
Feb  4 19:38:55.257: INFO: namespace e2e-tests-configmap-krpk6 deletion completed in 22.149423842s

• [SLOW TEST:28.513 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:38:55.258: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  4 19:38:55.399: INFO: Waiting up to 5m0s for pod "pod-821e98f5-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-emptydir-pgt72" to be "success or failure"
Feb  4 19:38:55.426: INFO: Pod "pod-821e98f5-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 26.653576ms
Feb  4 19:38:57.433: INFO: Pod "pod-821e98f5-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034343359s
STEP: Saw pod success
Feb  4 19:38:57.434: INFO: Pod "pod-821e98f5-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:38:57.445: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod pod-821e98f5-28b4-11e9-8d1f-5e319961b721 container test-container: <nil>
STEP: delete the pod
Feb  4 19:38:57.534: INFO: Waiting for pod pod-821e98f5-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:38:57.538: INFO: Pod pod-821e98f5-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:38:57.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pgt72" for this suite.
Feb  4 19:39:03.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:39:03.698: INFO: namespace: e2e-tests-emptydir-pgt72, resource: bindings, ignored listing per whitelist
Feb  4 19:39:03.743: INFO: namespace e2e-tests-emptydir-pgt72 deletion completed in 6.199863486s

• [SLOW TEST:8.484 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:39:03.744: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-872895b2-28b4-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:39:03.856: INFO: Waiting up to 5m0s for pod "pod-secrets-8729cc41-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-v5qkh" to be "success or failure"
Feb  4 19:39:03.861: INFO: Pod "pod-secrets-8729cc41-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 5.320338ms
Feb  4 19:39:05.869: INFO: Pod "pod-secrets-8729cc41-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013410308s
Feb  4 19:39:07.878: INFO: Pod "pod-secrets-8729cc41-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022165056s
STEP: Saw pod success
Feb  4 19:39:07.879: INFO: Pod "pod-secrets-8729cc41-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:39:07.891: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-secrets-8729cc41-28b4-11e9-8d1f-5e319961b721 container secret-volume-test: <nil>
STEP: delete the pod
Feb  4 19:39:07.989: INFO: Waiting for pod pod-secrets-8729cc41-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:39:07.998: INFO: Pod pod-secrets-8729cc41-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:39:07.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-v5qkh" for this suite.
Feb  4 19:39:14.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:39:14.214: INFO: namespace: e2e-tests-secrets-v5qkh, resource: bindings, ignored listing per whitelist
Feb  4 19:39:14.224: INFO: namespace e2e-tests-secrets-v5qkh deletion completed in 6.216722608s

• [SLOW TEST:10.481 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:39:14.225: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:39:14.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-gfgd8" for this suite.
Feb  4 19:39:20.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:39:20.631: INFO: namespace: e2e-tests-kubelet-test-gfgd8, resource: bindings, ignored listing per whitelist
Feb  4 19:39:20.656: INFO: namespace e2e-tests-kubelet-test-gfgd8 deletion completed in 6.20128555s

• [SLOW TEST:6.431 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:39:20.659: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-9vcqg/secret-test-9136f7cb-28b4-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:39:20.722: INFO: Waiting up to 5m0s for pod "pod-configmaps-913892bd-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-secrets-9vcqg" to be "success or failure"
Feb  4 19:39:20.725: INFO: Pod "pod-configmaps-913892bd-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 3.834848ms
Feb  4 19:39:22.728: INFO: Pod "pod-configmaps-913892bd-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006116588s
STEP: Saw pod success
Feb  4 19:39:22.728: INFO: Pod "pod-configmaps-913892bd-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:39:22.731: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-configmaps-913892bd-28b4-11e9-8d1f-5e319961b721 container env-test: <nil>
STEP: delete the pod
Feb  4 19:39:22.766: INFO: Waiting for pod pod-configmaps-913892bd-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:39:22.776: INFO: Pod pod-configmaps-913892bd-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:39:22.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9vcqg" for this suite.
Feb  4 19:39:28.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:39:28.867: INFO: namespace: e2e-tests-secrets-9vcqg, resource: bindings, ignored listing per whitelist
Feb  4 19:39:28.879: INFO: namespace e2e-tests-secrets-9vcqg deletion completed in 6.099719087s

• [SLOW TEST:8.221 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:39:28.880: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:39:28.956: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9620397f-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-ht6nj" to be "success or failure"
Feb  4 19:39:28.963: INFO: Pod "downwardapi-volume-9620397f-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 7.227807ms
Feb  4 19:39:30.971: INFO: Pod "downwardapi-volume-9620397f-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015383614s
Feb  4 19:39:32.981: INFO: Pod "downwardapi-volume-9620397f-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025754514s
STEP: Saw pod success
Feb  4 19:39:32.982: INFO: Pod "downwardapi-volume-9620397f-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:39:32.995: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-9620397f-28b4-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:39:33.043: INFO: Waiting for pod downwardapi-volume-9620397f-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:39:33.054: INFO: Pod downwardapi-volume-9620397f-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:39:33.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ht6nj" for this suite.
Feb  4 19:39:39.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:39:39.190: INFO: namespace: e2e-tests-projected-ht6nj, resource: bindings, ignored listing per whitelist
Feb  4 19:39:39.218: INFO: namespace e2e-tests-projected-ht6nj deletion completed in 6.160210589s

• [SLOW TEST:10.338 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:39:39.218: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:39:39.347: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c4f08d9-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-w7x8w" to be "success or failure"
Feb  4 19:39:39.396: INFO: Pod "downwardapi-volume-9c4f08d9-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 49.320933ms
Feb  4 19:39:41.402: INFO: Pod "downwardapi-volume-9c4f08d9-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055764788s
Feb  4 19:39:43.409: INFO: Pod "downwardapi-volume-9c4f08d9-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062546971s
STEP: Saw pod success
Feb  4 19:39:43.409: INFO: Pod "downwardapi-volume-9c4f08d9-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:39:43.420: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-9c4f08d9-28b4-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:39:43.516: INFO: Waiting for pod downwardapi-volume-9c4f08d9-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:39:43.529: INFO: Pod downwardapi-volume-9c4f08d9-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:39:43.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w7x8w" for this suite.
Feb  4 19:39:49.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:39:49.591: INFO: namespace: e2e-tests-downward-api-w7x8w, resource: bindings, ignored listing per whitelist
Feb  4 19:39:49.683: INFO: namespace e2e-tests-downward-api-w7x8w deletion completed in 6.148813404s

• [SLOW TEST:10.464 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:39:49.683: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  4 19:39:49.875: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-n7wcm,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7wcm/configmaps/e2e-watch-test-resource-version,UID:a28ac22e-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15925,Generation:0,CreationTimestamp:2019-02-04 19:39:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  4 19:39:49.875: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-n7wcm,SelfLink:/api/v1/namespaces/e2e-tests-watch-n7wcm/configmaps/e2e-watch-test-resource-version,UID:a28ac22e-28b4-11e9-88b2-2600a3ceccc4,ResourceVersion:15926,Generation:0,CreationTimestamp:2019-02-04 19:39:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:39:49.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-n7wcm" for this suite.
Feb  4 19:39:55.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:39:55.980: INFO: namespace: e2e-tests-watch-n7wcm, resource: bindings, ignored listing per whitelist
Feb  4 19:39:56.010: INFO: namespace e2e-tests-watch-n7wcm deletion completed in 6.128616448s

• [SLOW TEST:6.327 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:39:56.010: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-bj5xs
I0204 19:39:56.069974      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-bj5xs, replica count: 1
I0204 19:39:57.121171      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0204 19:39:58.121341      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  4 19:39:58.268: INFO: Created: latency-svc-sfmsq
Feb  4 19:39:58.326: INFO: Got endpoints: latency-svc-sfmsq [104.202498ms]
Feb  4 19:39:58.359: INFO: Created: latency-svc-q75tt
Feb  4 19:39:58.365: INFO: Got endpoints: latency-svc-q75tt [39.415603ms]
Feb  4 19:39:58.386: INFO: Created: latency-svc-svtd6
Feb  4 19:39:58.402: INFO: Got endpoints: latency-svc-svtd6 [75.064223ms]
Feb  4 19:39:58.419: INFO: Created: latency-svc-2dqxz
Feb  4 19:39:58.421: INFO: Got endpoints: latency-svc-2dqxz [93.217153ms]
Feb  4 19:39:58.449: INFO: Created: latency-svc-rnj52
Feb  4 19:39:58.456: INFO: Got endpoints: latency-svc-rnj52 [124.280344ms]
Feb  4 19:39:58.493: INFO: Created: latency-svc-zgfbf
Feb  4 19:39:58.499: INFO: Got endpoints: latency-svc-zgfbf [168.449891ms]
Feb  4 19:39:58.525: INFO: Created: latency-svc-fpwld
Feb  4 19:39:58.530: INFO: Got endpoints: latency-svc-fpwld [198.126362ms]
Feb  4 19:39:58.595: INFO: Created: latency-svc-ccz66
Feb  4 19:39:58.600: INFO: Got endpoints: latency-svc-ccz66 [267.183651ms]
Feb  4 19:39:58.626: INFO: Created: latency-svc-qmbzg
Feb  4 19:39:58.634: INFO: Got endpoints: latency-svc-qmbzg [299.874716ms]
Feb  4 19:39:58.657: INFO: Created: latency-svc-jvrq2
Feb  4 19:39:58.662: INFO: Got endpoints: latency-svc-jvrq2 [328.598357ms]
Feb  4 19:39:58.749: INFO: Created: latency-svc-vgjd6
Feb  4 19:39:58.758: INFO: Got endpoints: latency-svc-vgjd6 [424.06272ms]
Feb  4 19:39:58.783: INFO: Created: latency-svc-rxtdn
Feb  4 19:39:58.795: INFO: Got endpoints: latency-svc-rxtdn [460.461881ms]
Feb  4 19:39:58.813: INFO: Created: latency-svc-gdpqg
Feb  4 19:39:58.814: INFO: Got endpoints: latency-svc-gdpqg [479.562331ms]
Feb  4 19:39:58.881: INFO: Created: latency-svc-lvvkf
Feb  4 19:39:58.912: INFO: Got endpoints: latency-svc-lvvkf [577.272545ms]
Feb  4 19:39:58.923: INFO: Created: latency-svc-c9lqc
Feb  4 19:39:58.923: INFO: Got endpoints: latency-svc-c9lqc [583.18524ms]
Feb  4 19:39:58.951: INFO: Created: latency-svc-2j4pf
Feb  4 19:39:58.958: INFO: Got endpoints: latency-svc-2j4pf [618.591251ms]
Feb  4 19:39:58.974: INFO: Created: latency-svc-8rf6h
Feb  4 19:39:59.006: INFO: Got endpoints: latency-svc-8rf6h [640.692782ms]
Feb  4 19:39:59.021: INFO: Created: latency-svc-frzzb
Feb  4 19:39:59.027: INFO: Got endpoints: latency-svc-frzzb [68.95089ms]
Feb  4 19:39:59.056: INFO: Created: latency-svc-8tk69
Feb  4 19:39:59.065: INFO: Got endpoints: latency-svc-8tk69 [663.356693ms]
Feb  4 19:39:59.084: INFO: Created: latency-svc-4pdkz
Feb  4 19:39:59.091: INFO: Got endpoints: latency-svc-4pdkz [669.870349ms]
Feb  4 19:39:59.142: INFO: Created: latency-svc-6k2hw
Feb  4 19:39:59.151: INFO: Got endpoints: latency-svc-6k2hw [695.453041ms]
Feb  4 19:39:59.184: INFO: Created: latency-svc-btkns
Feb  4 19:39:59.185: INFO: Got endpoints: latency-svc-btkns [685.985584ms]
Feb  4 19:39:59.213: INFO: Created: latency-svc-rzrjk
Feb  4 19:39:59.220: INFO: Got endpoints: latency-svc-rzrjk [689.971207ms]
Feb  4 19:39:59.282: INFO: Created: latency-svc-nkn5q
Feb  4 19:39:59.283: INFO: Got endpoints: latency-svc-nkn5q [682.179422ms]
Feb  4 19:39:59.306: INFO: Created: latency-svc-hvq5n
Feb  4 19:39:59.318: INFO: Got endpoints: latency-svc-hvq5n [683.614566ms]
Feb  4 19:39:59.344: INFO: Created: latency-svc-vb25l
Feb  4 19:39:59.349: INFO: Got endpoints: latency-svc-vb25l [686.544924ms]
Feb  4 19:39:59.421: INFO: Created: latency-svc-dhlkm
Feb  4 19:39:59.463: INFO: Got endpoints: latency-svc-dhlkm [704.176253ms]
Feb  4 19:39:59.513: INFO: Created: latency-svc-c59gp
Feb  4 19:39:59.537: INFO: Got endpoints: latency-svc-c59gp [742.343975ms]
Feb  4 19:39:59.543: INFO: Created: latency-svc-x7k5w
Feb  4 19:39:59.555: INFO: Got endpoints: latency-svc-x7k5w [740.619573ms]
Feb  4 19:39:59.581: INFO: Created: latency-svc-42pp2
Feb  4 19:39:59.591: INFO: Got endpoints: latency-svc-42pp2 [667.846076ms]
Feb  4 19:39:59.623: INFO: Created: latency-svc-vwcnr
Feb  4 19:39:59.671: INFO: Got endpoints: latency-svc-vwcnr [758.39451ms]
Feb  4 19:39:59.680: INFO: Created: latency-svc-zhqg6
Feb  4 19:39:59.689: INFO: Got endpoints: latency-svc-zhqg6 [682.579254ms]
Feb  4 19:39:59.714: INFO: Created: latency-svc-jvckw
Feb  4 19:39:59.720: INFO: Got endpoints: latency-svc-jvckw [692.568956ms]
Feb  4 19:39:59.749: INFO: Created: latency-svc-96w98
Feb  4 19:39:59.755: INFO: Got endpoints: latency-svc-96w98 [689.572929ms]
Feb  4 19:39:59.771: INFO: Created: latency-svc-s4ds8
Feb  4 19:39:59.799: INFO: Got endpoints: latency-svc-s4ds8 [707.987438ms]
Feb  4 19:39:59.803: INFO: Created: latency-svc-dmr66
Feb  4 19:39:59.814: INFO: Got endpoints: latency-svc-dmr66 [662.885436ms]
Feb  4 19:39:59.840: INFO: Created: latency-svc-425mv
Feb  4 19:39:59.845: INFO: Got endpoints: latency-svc-425mv [660.192596ms]
Feb  4 19:39:59.865: INFO: Created: latency-svc-pmmsw
Feb  4 19:39:59.872: INFO: Got endpoints: latency-svc-pmmsw [650.941265ms]
Feb  4 19:39:59.893: INFO: Created: latency-svc-f2wct
Feb  4 19:39:59.934: INFO: Got endpoints: latency-svc-f2wct [651.488453ms]
Feb  4 19:39:59.941: INFO: Created: latency-svc-q9ls6
Feb  4 19:39:59.944: INFO: Got endpoints: latency-svc-q9ls6 [626.449004ms]
Feb  4 19:39:59.968: INFO: Created: latency-svc-scm9n
Feb  4 19:39:59.973: INFO: Got endpoints: latency-svc-scm9n [623.830422ms]
Feb  4 19:39:59.995: INFO: Created: latency-svc-nmqpg
Feb  4 19:40:00.000: INFO: Got endpoints: latency-svc-nmqpg [536.958265ms]
Feb  4 19:40:00.023: INFO: Created: latency-svc-smwkx
Feb  4 19:40:00.070: INFO: Got endpoints: latency-svc-smwkx [532.663714ms]
Feb  4 19:40:00.074: INFO: Created: latency-svc-jjfn6
Feb  4 19:40:00.079: INFO: Got endpoints: latency-svc-jjfn6 [523.601075ms]
Feb  4 19:40:00.099: INFO: Created: latency-svc-fltfz
Feb  4 19:40:00.105: INFO: Got endpoints: latency-svc-fltfz [514.143919ms]
Feb  4 19:40:00.126: INFO: Created: latency-svc-tct2x
Feb  4 19:40:00.131: INFO: Got endpoints: latency-svc-tct2x [460.250831ms]
Feb  4 19:40:00.171: INFO: Created: latency-svc-7xzpl
Feb  4 19:40:00.221: INFO: Got endpoints: latency-svc-7xzpl [532.370134ms]
Feb  4 19:40:00.240: INFO: Created: latency-svc-6ntmw
Feb  4 19:40:00.248: INFO: Got endpoints: latency-svc-6ntmw [527.961076ms]
Feb  4 19:40:00.275: INFO: Created: latency-svc-4sflv
Feb  4 19:40:00.280: INFO: Got endpoints: latency-svc-4sflv [525.323563ms]
Feb  4 19:40:00.299: INFO: Created: latency-svc-k2pvk
Feb  4 19:40:00.306: INFO: Got endpoints: latency-svc-k2pvk [506.486132ms]
Feb  4 19:40:00.355: INFO: Created: latency-svc-l82zf
Feb  4 19:40:00.361: INFO: Got endpoints: latency-svc-l82zf [545.866809ms]
Feb  4 19:40:00.376: INFO: Created: latency-svc-dxwm6
Feb  4 19:40:00.384: INFO: Got endpoints: latency-svc-dxwm6 [538.415865ms]
Feb  4 19:40:00.400: INFO: Created: latency-svc-bfmj9
Feb  4 19:40:00.406: INFO: Got endpoints: latency-svc-bfmj9 [534.015901ms]
Feb  4 19:40:00.421: INFO: Created: latency-svc-8bp9v
Feb  4 19:40:00.426: INFO: Got endpoints: latency-svc-8bp9v [491.47479ms]
Feb  4 19:40:00.441: INFO: Created: latency-svc-f5cjg
Feb  4 19:40:00.446: INFO: Got endpoints: latency-svc-f5cjg [502.156631ms]
Feb  4 19:40:00.501: INFO: Created: latency-svc-pfsvf
Feb  4 19:40:00.504: INFO: Got endpoints: latency-svc-pfsvf [530.857935ms]
Feb  4 19:40:00.524: INFO: Created: latency-svc-m9j54
Feb  4 19:40:00.530: INFO: Got endpoints: latency-svc-m9j54 [529.365305ms]
Feb  4 19:40:00.553: INFO: Created: latency-svc-v6jng
Feb  4 19:40:00.558: INFO: Got endpoints: latency-svc-v6jng [484.647878ms]
Feb  4 19:40:00.587: INFO: Created: latency-svc-k82dw
Feb  4 19:40:00.587: INFO: Got endpoints: latency-svc-k82dw [508.521379ms]
Feb  4 19:40:00.637: INFO: Created: latency-svc-xsh9g
Feb  4 19:40:00.642: INFO: Got endpoints: latency-svc-xsh9g [537.104182ms]
Feb  4 19:40:00.664: INFO: Created: latency-svc-tbv5w
Feb  4 19:40:00.675: INFO: Got endpoints: latency-svc-tbv5w [543.460707ms]
Feb  4 19:40:00.691: INFO: Created: latency-svc-jsbvq
Feb  4 19:40:00.694: INFO: Got endpoints: latency-svc-jsbvq [472.902736ms]
Feb  4 19:40:00.716: INFO: Created: latency-svc-q7v29
Feb  4 19:40:00.723: INFO: Got endpoints: latency-svc-q7v29 [471.313076ms]
Feb  4 19:40:00.781: INFO: Created: latency-svc-8hvm5
Feb  4 19:40:00.799: INFO: Got endpoints: latency-svc-8hvm5 [519.11617ms]
Feb  4 19:40:00.805: INFO: Created: latency-svc-sbswd
Feb  4 19:40:00.808: INFO: Got endpoints: latency-svc-sbswd [502.364264ms]
Feb  4 19:40:00.833: INFO: Created: latency-svc-blnqb
Feb  4 19:40:00.833: INFO: Got endpoints: latency-svc-blnqb [472.876864ms]
Feb  4 19:40:00.862: INFO: Created: latency-svc-t95vq
Feb  4 19:40:00.911: INFO: Got endpoints: latency-svc-t95vq [526.866131ms]
Feb  4 19:40:00.919: INFO: Created: latency-svc-ch9vw
Feb  4 19:40:00.944: INFO: Got endpoints: latency-svc-ch9vw [537.593806ms]
Feb  4 19:40:00.969: INFO: Created: latency-svc-qkf22
Feb  4 19:40:00.976: INFO: Got endpoints: latency-svc-qkf22 [550.519456ms]
Feb  4 19:40:00.997: INFO: Created: latency-svc-h7jll
Feb  4 19:40:01.055: INFO: Got endpoints: latency-svc-h7jll [608.666387ms]
Feb  4 19:40:01.058: INFO: Created: latency-svc-6z27j
Feb  4 19:40:01.062: INFO: Got endpoints: latency-svc-6z27j [557.20874ms]
Feb  4 19:40:01.085: INFO: Created: latency-svc-zrfw9
Feb  4 19:40:01.089: INFO: Got endpoints: latency-svc-zrfw9 [559.078339ms]
Feb  4 19:40:01.114: INFO: Created: latency-svc-dhf4f
Feb  4 19:40:01.126: INFO: Got endpoints: latency-svc-dhf4f [568.323453ms]
Feb  4 19:40:01.144: INFO: Created: latency-svc-j2mml
Feb  4 19:40:01.148: INFO: Got endpoints: latency-svc-j2mml [560.551341ms]
Feb  4 19:40:01.179: INFO: Created: latency-svc-c6hvl
Feb  4 19:40:01.207: INFO: Got endpoints: latency-svc-c6hvl [564.961034ms]
Feb  4 19:40:01.221: INFO: Created: latency-svc-f6x4x
Feb  4 19:40:01.232: INFO: Got endpoints: latency-svc-f6x4x [557.74359ms]
Feb  4 19:40:01.252: INFO: Created: latency-svc-qb9b5
Feb  4 19:40:01.252: INFO: Got endpoints: latency-svc-qb9b5 [558.22147ms]
Feb  4 19:40:01.276: INFO: Created: latency-svc-8ljr5
Feb  4 19:40:01.315: INFO: Got endpoints: latency-svc-8ljr5 [591.904954ms]
Feb  4 19:40:01.322: INFO: Created: latency-svc-dmnkx
Feb  4 19:40:01.326: INFO: Got endpoints: latency-svc-dmnkx [526.64614ms]
Feb  4 19:40:01.354: INFO: Created: latency-svc-47q8v
Feb  4 19:40:01.360: INFO: Got endpoints: latency-svc-47q8v [552.067994ms]
Feb  4 19:40:01.373: INFO: Created: latency-svc-547xc
Feb  4 19:40:01.383: INFO: Got endpoints: latency-svc-547xc [549.446ms]
Feb  4 19:40:01.396: INFO: Created: latency-svc-gb8kn
Feb  4 19:40:01.404: INFO: Got endpoints: latency-svc-gb8kn [493.060527ms]
Feb  4 19:40:01.469: INFO: Created: latency-svc-cbhz9
Feb  4 19:40:01.472: INFO: Got endpoints: latency-svc-cbhz9 [527.926926ms]
Feb  4 19:40:01.524: INFO: Created: latency-svc-tcf24
Feb  4 19:40:01.528: INFO: Got endpoints: latency-svc-tcf24 [551.750633ms]
Feb  4 19:40:01.551: INFO: Created: latency-svc-wbsh2
Feb  4 19:40:01.555: INFO: Got endpoints: latency-svc-wbsh2 [499.910466ms]
Feb  4 19:40:01.613: INFO: Created: latency-svc-c5lpz
Feb  4 19:40:01.618: INFO: Got endpoints: latency-svc-c5lpz [556.419343ms]
Feb  4 19:40:01.637: INFO: Created: latency-svc-svz76
Feb  4 19:40:01.642: INFO: Got endpoints: latency-svc-svz76 [552.75181ms]
Feb  4 19:40:01.662: INFO: Created: latency-svc-8m8jn
Feb  4 19:40:01.668: INFO: Got endpoints: latency-svc-8m8jn [541.211033ms]
Feb  4 19:40:01.734: INFO: Created: latency-svc-b5bht
Feb  4 19:40:01.755: INFO: Got endpoints: latency-svc-b5bht [607.194046ms]
Feb  4 19:40:01.757: INFO: Created: latency-svc-9zpln
Feb  4 19:40:01.761: INFO: Got endpoints: latency-svc-9zpln [554.197941ms]
Feb  4 19:40:01.797: INFO: Created: latency-svc-z9rz6
Feb  4 19:40:01.802: INFO: Got endpoints: latency-svc-z9rz6 [569.102943ms]
Feb  4 19:40:01.826: INFO: Created: latency-svc-cdgnt
Feb  4 19:40:01.896: INFO: Got endpoints: latency-svc-cdgnt [643.533587ms]
Feb  4 19:40:01.906: INFO: Created: latency-svc-lnc2l
Feb  4 19:40:01.912: INFO: Got endpoints: latency-svc-lnc2l [597.221653ms]
Feb  4 19:40:01.938: INFO: Created: latency-svc-n6kk4
Feb  4 19:40:01.944: INFO: Got endpoints: latency-svc-n6kk4 [617.64056ms]
Feb  4 19:40:01.962: INFO: Created: latency-svc-d47w8
Feb  4 19:40:01.970: INFO: Got endpoints: latency-svc-d47w8 [609.694599ms]
Feb  4 19:40:01.989: INFO: Created: latency-svc-9pvtb
Feb  4 19:40:01.994: INFO: Got endpoints: latency-svc-9pvtb [610.612803ms]
Feb  4 19:40:02.028: INFO: Created: latency-svc-7h42z
Feb  4 19:40:02.033: INFO: Got endpoints: latency-svc-7h42z [628.233122ms]
Feb  4 19:40:02.050: INFO: Created: latency-svc-xh2km
Feb  4 19:40:02.060: INFO: Got endpoints: latency-svc-xh2km [587.00328ms]
Feb  4 19:40:02.074: INFO: Created: latency-svc-p2ptk
Feb  4 19:40:02.081: INFO: Got endpoints: latency-svc-p2ptk [552.686919ms]
Feb  4 19:40:02.104: INFO: Created: latency-svc-g5vbb
Feb  4 19:40:02.113: INFO: Got endpoints: latency-svc-g5vbb [557.102003ms]
Feb  4 19:40:02.178: INFO: Created: latency-svc-2hb5d
Feb  4 19:40:02.178: INFO: Got endpoints: latency-svc-2hb5d [557.877109ms]
Feb  4 19:40:02.206: INFO: Created: latency-svc-hqgsk
Feb  4 19:40:02.231: INFO: Got endpoints: latency-svc-hqgsk [589.160417ms]
Feb  4 19:40:02.241: INFO: Created: latency-svc-l5prf
Feb  4 19:40:02.324: INFO: Got endpoints: latency-svc-l5prf [655.737876ms]
Feb  4 19:40:02.340: INFO: Created: latency-svc-q6w6w
Feb  4 19:40:02.347: INFO: Got endpoints: latency-svc-q6w6w [591.407208ms]
Feb  4 19:40:02.366: INFO: Created: latency-svc-c768j
Feb  4 19:40:02.370: INFO: Got endpoints: latency-svc-c768j [608.384467ms]
Feb  4 19:40:02.398: INFO: Created: latency-svc-g7nf5
Feb  4 19:40:02.400: INFO: Got endpoints: latency-svc-g7nf5 [598.062745ms]
Feb  4 19:40:02.421: INFO: Created: latency-svc-45hrx
Feb  4 19:40:02.460: INFO: Got endpoints: latency-svc-45hrx [563.678512ms]
Feb  4 19:40:02.467: INFO: Created: latency-svc-q9ljk
Feb  4 19:40:02.476: INFO: Got endpoints: latency-svc-q9ljk [563.676076ms]
Feb  4 19:40:02.495: INFO: Created: latency-svc-hfwf5
Feb  4 19:40:02.501: INFO: Got endpoints: latency-svc-hfwf5 [557.019747ms]
Feb  4 19:40:02.527: INFO: Created: latency-svc-86w6b
Feb  4 19:40:02.534: INFO: Got endpoints: latency-svc-86w6b [563.418791ms]
Feb  4 19:40:02.556: INFO: Created: latency-svc-qg22r
Feb  4 19:40:02.560: INFO: Got endpoints: latency-svc-qg22r [564.630841ms]
Feb  4 19:40:02.628: INFO: Created: latency-svc-6kzbd
Feb  4 19:40:02.637: INFO: Got endpoints: latency-svc-6kzbd [604.260257ms]
Feb  4 19:40:02.660: INFO: Created: latency-svc-bn5lr
Feb  4 19:40:02.667: INFO: Got endpoints: latency-svc-bn5lr [607.212452ms]
Feb  4 19:40:02.683: INFO: Created: latency-svc-vq5j9
Feb  4 19:40:02.689: INFO: Got endpoints: latency-svc-vq5j9 [607.86689ms]
Feb  4 19:40:02.710: INFO: Created: latency-svc-nzbnh
Feb  4 19:40:02.713: INFO: Got endpoints: latency-svc-nzbnh [600.283155ms]
Feb  4 19:40:02.777: INFO: Created: latency-svc-x6cpg
Feb  4 19:40:02.780: INFO: Got endpoints: latency-svc-x6cpg [602.200177ms]
Feb  4 19:40:02.825: INFO: Created: latency-svc-njbgn
Feb  4 19:40:02.831: INFO: Got endpoints: latency-svc-njbgn [599.748854ms]
Feb  4 19:40:02.858: INFO: Created: latency-svc-bb7bj
Feb  4 19:40:02.864: INFO: Got endpoints: latency-svc-bb7bj [540.457736ms]
Feb  4 19:40:02.914: INFO: Created: latency-svc-xwwql
Feb  4 19:40:02.917: INFO: Got endpoints: latency-svc-xwwql [570.056614ms]
Feb  4 19:40:02.960: INFO: Created: latency-svc-ds84w
Feb  4 19:40:02.966: INFO: Got endpoints: latency-svc-ds84w [596.087742ms]
Feb  4 19:40:02.988: INFO: Created: latency-svc-f5lwz
Feb  4 19:40:03.002: INFO: Got endpoints: latency-svc-f5lwz [601.914407ms]
Feb  4 19:40:03.072: INFO: Created: latency-svc-vj9ck
Feb  4 19:40:03.081: INFO: Got endpoints: latency-svc-vj9ck [620.927034ms]
Feb  4 19:40:03.096: INFO: Created: latency-svc-nm9rx
Feb  4 19:40:03.102: INFO: Got endpoints: latency-svc-nm9rx [625.671055ms]
Feb  4 19:40:03.126: INFO: Created: latency-svc-pxfff
Feb  4 19:40:03.131: INFO: Got endpoints: latency-svc-pxfff [630.195527ms]
Feb  4 19:40:03.148: INFO: Created: latency-svc-bxl5s
Feb  4 19:40:03.154: INFO: Got endpoints: latency-svc-bxl5s [620.741329ms]
Feb  4 19:40:03.207: INFO: Created: latency-svc-bm6dv
Feb  4 19:40:03.211: INFO: Got endpoints: latency-svc-bm6dv [651.252054ms]
Feb  4 19:40:03.237: INFO: Created: latency-svc-bnvs2
Feb  4 19:40:03.258: INFO: Got endpoints: latency-svc-bnvs2 [620.137322ms]
Feb  4 19:40:03.261: INFO: Created: latency-svc-tktnz
Feb  4 19:40:03.267: INFO: Got endpoints: latency-svc-tktnz [600.146724ms]
Feb  4 19:40:03.302: INFO: Created: latency-svc-lstw8
Feb  4 19:40:03.305: INFO: Got endpoints: latency-svc-lstw8 [616.637567ms]
Feb  4 19:40:03.362: INFO: Created: latency-svc-tr2pj
Feb  4 19:40:03.381: INFO: Got endpoints: latency-svc-tr2pj [667.557456ms]
Feb  4 19:40:03.383: INFO: Created: latency-svc-cmkhk
Feb  4 19:40:03.389: INFO: Got endpoints: latency-svc-cmkhk [607.475575ms]
Feb  4 19:40:03.405: INFO: Created: latency-svc-bfpvr
Feb  4 19:40:03.430: INFO: Got endpoints: latency-svc-bfpvr [599.561948ms]
Feb  4 19:40:03.433: INFO: Created: latency-svc-rm867
Feb  4 19:40:03.451: INFO: Created: latency-svc-wd4st
Feb  4 19:40:03.505: INFO: Created: latency-svc-8mh48
Feb  4 19:40:03.505: INFO: Got endpoints: latency-svc-rm867 [640.924643ms]
Feb  4 19:40:03.541: INFO: Got endpoints: latency-svc-wd4st [623.105097ms]
Feb  4 19:40:03.541: INFO: Created: latency-svc-gv8vj
Feb  4 19:40:03.581: INFO: Got endpoints: latency-svc-8mh48 [615.089813ms]
Feb  4 19:40:03.584: INFO: Created: latency-svc-98pmf
Feb  4 19:40:03.678: INFO: Got endpoints: latency-svc-gv8vj [675.995231ms]
Feb  4 19:40:03.680: INFO: Got endpoints: latency-svc-98pmf [598.33124ms]
Feb  4 19:40:03.684: INFO: Created: latency-svc-sqgsc
Feb  4 19:40:03.708: INFO: Created: latency-svc-848dz
Feb  4 19:40:03.721: INFO: Got endpoints: latency-svc-sqgsc [619.20797ms]
Feb  4 19:40:03.738: INFO: Created: latency-svc-4bklt
Feb  4 19:40:03.757: INFO: Created: latency-svc-78vrt
Feb  4 19:40:03.772: INFO: Got endpoints: latency-svc-848dz [640.902926ms]
Feb  4 19:40:03.828: INFO: Created: latency-svc-xdpmr
Feb  4 19:40:03.828: INFO: Got endpoints: latency-svc-4bklt [674.033458ms]
Feb  4 19:40:03.857: INFO: Created: latency-svc-krp6v
Feb  4 19:40:03.867: INFO: Got endpoints: latency-svc-78vrt [652.510124ms]
Feb  4 19:40:03.889: INFO: Created: latency-svc-82hm8
Feb  4 19:40:03.914: INFO: Got endpoints: latency-svc-xdpmr [656.3774ms]
Feb  4 19:40:03.917: INFO: Created: latency-svc-xm2x8
Feb  4 19:40:03.971: INFO: Got endpoints: latency-svc-krp6v [703.86366ms]
Feb  4 19:40:03.978: INFO: Created: latency-svc-kz498
Feb  4 19:40:04.019: INFO: Created: latency-svc-q45lx
Feb  4 19:40:04.019: INFO: Got endpoints: latency-svc-82hm8 [713.531827ms]
Feb  4 19:40:04.050: INFO: Created: latency-svc-nq7rl
Feb  4 19:40:04.155: INFO: Created: latency-svc-986tk
Feb  4 19:40:04.158: INFO: Got endpoints: latency-svc-kz498 [769.209909ms]
Feb  4 19:40:04.158: INFO: Got endpoints: latency-svc-xm2x8 [777.458859ms]
Feb  4 19:40:04.188: INFO: Got endpoints: latency-svc-q45lx [757.994448ms]
Feb  4 19:40:04.189: INFO: Created: latency-svc-s8m7f
Feb  4 19:40:04.217: INFO: Got endpoints: latency-svc-nq7rl [711.520457ms]
Feb  4 19:40:04.220: INFO: Created: latency-svc-rj265
Feb  4 19:40:04.253: INFO: Created: latency-svc-gpm4p
Feb  4 19:40:04.286: INFO: Got endpoints: latency-svc-986tk [744.31384ms]
Feb  4 19:40:04.294: INFO: Created: latency-svc-xqtf8
Feb  4 19:40:04.330: INFO: Got endpoints: latency-svc-s8m7f [745.992714ms]
Feb  4 19:40:04.333: INFO: Created: latency-svc-4cnvx
Feb  4 19:40:04.359: INFO: Created: latency-svc-qbkgj
Feb  4 19:40:04.442: INFO: Created: latency-svc-dpdcp
Feb  4 19:40:04.449: INFO: Got endpoints: latency-svc-gpm4p [768.911306ms]
Feb  4 19:40:04.450: INFO: Got endpoints: latency-svc-rj265 [772.219154ms]
Feb  4 19:40:04.463: INFO: Created: latency-svc-cphq2
Feb  4 19:40:04.470: INFO: Got endpoints: latency-svc-xqtf8 [748.896859ms]
Feb  4 19:40:04.508: INFO: Created: latency-svc-xlwh6
Feb  4 19:40:04.521: INFO: Got endpoints: latency-svc-4cnvx [747.867506ms]
Feb  4 19:40:04.539: INFO: Created: latency-svc-bnxht
Feb  4 19:40:04.585: INFO: Got endpoints: latency-svc-qbkgj [756.183192ms]
Feb  4 19:40:04.590: INFO: Created: latency-svc-9jjpl
Feb  4 19:40:04.618: INFO: Got endpoints: latency-svc-dpdcp [750.891879ms]
Feb  4 19:40:04.620: INFO: Created: latency-svc-8xx2j
Feb  4 19:40:04.644: INFO: Created: latency-svc-n2btc
Feb  4 19:40:04.676: INFO: Got endpoints: latency-svc-cphq2 [758.732597ms]
Feb  4 19:40:04.679: INFO: Created: latency-svc-b48l4
Feb  4 19:40:04.712: INFO: Created: latency-svc-tmffg
Feb  4 19:40:04.726: INFO: Got endpoints: latency-svc-xlwh6 [755.348156ms]
Feb  4 19:40:04.750: INFO: Created: latency-svc-bl6qz
Feb  4 19:40:04.775: INFO: Got endpoints: latency-svc-bnxht [756.028356ms]
Feb  4 19:40:04.801: INFO: Created: latency-svc-gvcs4
Feb  4 19:40:04.872: INFO: Got endpoints: latency-svc-9jjpl [714.142069ms]
Feb  4 19:40:04.873: INFO: Got endpoints: latency-svc-8xx2j [714.979786ms]
Feb  4 19:40:04.902: INFO: Created: latency-svc-9rdm7
Feb  4 19:40:04.912: INFO: Got endpoints: latency-svc-n2btc [724.012265ms]
Feb  4 19:40:04.939: INFO: Created: latency-svc-vzffp
Feb  4 19:40:04.971: INFO: Created: latency-svc-72wpz
Feb  4 19:40:05.031: INFO: Got endpoints: latency-svc-tmffg [745.624926ms]
Feb  4 19:40:05.032: INFO: Got endpoints: latency-svc-b48l4 [815.089565ms]
Feb  4 19:40:05.040: INFO: Created: latency-svc-6j2v4
Feb  4 19:40:05.073: INFO: Got endpoints: latency-svc-bl6qz [742.706067ms]
Feb  4 19:40:05.073: INFO: Created: latency-svc-lxplg
Feb  4 19:40:05.098: INFO: Created: latency-svc-9mgp8
Feb  4 19:40:05.125: INFO: Got endpoints: latency-svc-gvcs4 [675.550502ms]
Feb  4 19:40:05.129: INFO: Created: latency-svc-g44m8
Feb  4 19:40:05.164: INFO: Got endpoints: latency-svc-9rdm7 [713.912634ms]
Feb  4 19:40:05.179: INFO: Created: latency-svc-5h7ll
Feb  4 19:40:05.212: INFO: Created: latency-svc-t6zjb
Feb  4 19:40:05.220: INFO: Got endpoints: latency-svc-vzffp [750.112676ms]
Feb  4 19:40:05.246: INFO: Created: latency-svc-gtnn8
Feb  4 19:40:05.310: INFO: Got endpoints: latency-svc-72wpz [788.94432ms]
Feb  4 19:40:05.317: INFO: Created: latency-svc-s4nd8
Feb  4 19:40:05.318: INFO: Got endpoints: latency-svc-6j2v4 [732.783863ms]
Feb  4 19:40:05.343: INFO: Created: latency-svc-87c62
Feb  4 19:40:05.371: INFO: Created: latency-svc-smgrp
Feb  4 19:40:05.372: INFO: Got endpoints: latency-svc-lxplg [751.648765ms]
Feb  4 19:40:05.404: INFO: Created: latency-svc-vvmwm
Feb  4 19:40:05.446: INFO: Got endpoints: latency-svc-9mgp8 [769.557283ms]
Feb  4 19:40:05.470: INFO: Got endpoints: latency-svc-g44m8 [743.952181ms]
Feb  4 19:40:05.473: INFO: Created: latency-svc-sxn2w
Feb  4 19:40:05.498: INFO: Created: latency-svc-qh6gr
Feb  4 19:40:05.523: INFO: Got endpoints: latency-svc-5h7ll [748.261215ms]
Feb  4 19:40:05.527: INFO: Created: latency-svc-986tv
Feb  4 19:40:05.581: INFO: Got endpoints: latency-svc-t6zjb [709.011477ms]
Feb  4 19:40:05.586: INFO: Created: latency-svc-xtpjv
Feb  4 19:40:05.614: INFO: Created: latency-svc-qbcrw
Feb  4 19:40:05.620: INFO: Got endpoints: latency-svc-gtnn8 [746.624844ms]
Feb  4 19:40:05.639: INFO: Created: latency-svc-xzw2m
Feb  4 19:40:05.663: INFO: Created: latency-svc-9tvrx
Feb  4 19:40:05.674: INFO: Got endpoints: latency-svc-s4nd8 [761.11282ms]
Feb  4 19:40:05.709: INFO: Created: latency-svc-pkghv
Feb  4 19:40:05.717: INFO: Got endpoints: latency-svc-87c62 [686.127891ms]
Feb  4 19:40:05.748: INFO: Created: latency-svc-8rkgn
Feb  4 19:40:05.770: INFO: Created: latency-svc-fhdf2
Feb  4 19:40:05.770: INFO: Got endpoints: latency-svc-smgrp [738.249267ms]
Feb  4 19:40:05.807: INFO: Created: latency-svc-j8vdm
Feb  4 19:40:05.883: INFO: Got endpoints: latency-svc-sxn2w [758.529176ms]
Feb  4 19:40:05.885: INFO: Got endpoints: latency-svc-vvmwm [812.560969ms]
Feb  4 19:40:05.890: INFO: Created: latency-svc-lzwpl
Feb  4 19:40:05.928: INFO: Got endpoints: latency-svc-qh6gr [762.997831ms]
Feb  4 19:40:05.931: INFO: Created: latency-svc-6dn64
Feb  4 19:40:05.958: INFO: Created: latency-svc-6zpt2
Feb  4 19:40:05.965: INFO: Got endpoints: latency-svc-986tv [745.012193ms]
Feb  4 19:40:06.056: INFO: Got endpoints: latency-svc-xtpjv [746.839666ms]
Feb  4 19:40:06.057: INFO: Created: latency-svc-pkqtf
Feb  4 19:40:06.080: INFO: Got endpoints: latency-svc-qbcrw [762.457293ms]
Feb  4 19:40:06.101: INFO: Created: latency-svc-dq6zn
Feb  4 19:40:06.123: INFO: Got endpoints: latency-svc-xzw2m [750.963738ms]
Feb  4 19:40:06.125: INFO: Created: latency-svc-qml4g
Feb  4 19:40:06.198: INFO: Got endpoints: latency-svc-9tvrx [751.736631ms]
Feb  4 19:40:06.207: INFO: Created: latency-svc-6m6nj
Feb  4 19:40:06.237: INFO: Got endpoints: latency-svc-pkghv [766.871346ms]
Feb  4 19:40:06.241: INFO: Created: latency-svc-xzqwt
Feb  4 19:40:06.270: INFO: Got endpoints: latency-svc-8rkgn [743.904762ms]
Feb  4 19:40:06.270: INFO: Created: latency-svc-8c5c7
Feb  4 19:40:06.337: INFO: Created: latency-svc-bblw6
Feb  4 19:40:06.337: INFO: Got endpoints: latency-svc-fhdf2 [755.432133ms]
Feb  4 19:40:06.363: INFO: Got endpoints: latency-svc-j8vdm [742.795838ms]
Feb  4 19:40:06.412: INFO: Got endpoints: latency-svc-lzwpl [738.850559ms]
Feb  4 19:40:06.471: INFO: Got endpoints: latency-svc-6dn64 [751.564748ms]
Feb  4 19:40:06.512: INFO: Got endpoints: latency-svc-6zpt2 [740.774419ms]
Feb  4 19:40:06.564: INFO: Got endpoints: latency-svc-pkqtf [679.672275ms]
Feb  4 19:40:06.613: INFO: Got endpoints: latency-svc-dq6zn [727.339999ms]
Feb  4 19:40:06.663: INFO: Got endpoints: latency-svc-qml4g [732.750605ms]
Feb  4 19:40:06.713: INFO: Got endpoints: latency-svc-6m6nj [747.882477ms]
Feb  4 19:40:06.763: INFO: Got endpoints: latency-svc-xzqwt [705.344517ms]
Feb  4 19:40:06.816: INFO: Got endpoints: latency-svc-8c5c7 [736.338658ms]
Feb  4 19:40:06.865: INFO: Got endpoints: latency-svc-bblw6 [740.364821ms]
Feb  4 19:40:06.865: INFO: Latencies: [39.415603ms 68.95089ms 75.064223ms 93.217153ms 124.280344ms 168.449891ms 198.126362ms 267.183651ms 299.874716ms 328.598357ms 424.06272ms 460.250831ms 460.461881ms 471.313076ms 472.876864ms 472.902736ms 479.562331ms 484.647878ms 491.47479ms 493.060527ms 499.910466ms 502.156631ms 502.364264ms 506.486132ms 508.521379ms 514.143919ms 519.11617ms 523.601075ms 525.323563ms 526.64614ms 526.866131ms 527.926926ms 527.961076ms 529.365305ms 530.857935ms 532.370134ms 532.663714ms 534.015901ms 536.958265ms 537.104182ms 537.593806ms 538.415865ms 540.457736ms 541.211033ms 543.460707ms 545.866809ms 549.446ms 550.519456ms 551.750633ms 552.067994ms 552.686919ms 552.75181ms 554.197941ms 556.419343ms 557.019747ms 557.102003ms 557.20874ms 557.74359ms 557.877109ms 558.22147ms 559.078339ms 560.551341ms 563.418791ms 563.676076ms 563.678512ms 564.630841ms 564.961034ms 568.323453ms 569.102943ms 570.056614ms 577.272545ms 583.18524ms 587.00328ms 589.160417ms 591.407208ms 591.904954ms 596.087742ms 597.221653ms 598.062745ms 598.33124ms 599.561948ms 599.748854ms 600.146724ms 600.283155ms 601.914407ms 602.200177ms 604.260257ms 607.194046ms 607.212452ms 607.475575ms 607.86689ms 608.384467ms 608.666387ms 609.694599ms 610.612803ms 615.089813ms 616.637567ms 617.64056ms 618.591251ms 619.20797ms 620.137322ms 620.741329ms 620.927034ms 623.105097ms 623.830422ms 625.671055ms 626.449004ms 628.233122ms 630.195527ms 640.692782ms 640.902926ms 640.924643ms 643.533587ms 650.941265ms 651.252054ms 651.488453ms 652.510124ms 655.737876ms 656.3774ms 660.192596ms 662.885436ms 663.356693ms 667.557456ms 667.846076ms 669.870349ms 674.033458ms 675.550502ms 675.995231ms 679.672275ms 682.179422ms 682.579254ms 683.614566ms 685.985584ms 686.127891ms 686.544924ms 689.572929ms 689.971207ms 692.568956ms 695.453041ms 703.86366ms 704.176253ms 705.344517ms 707.987438ms 709.011477ms 711.520457ms 713.531827ms 713.912634ms 714.142069ms 714.979786ms 724.012265ms 727.339999ms 732.750605ms 732.783863ms 736.338658ms 738.249267ms 738.850559ms 740.364821ms 740.619573ms 740.774419ms 742.343975ms 742.706067ms 742.795838ms 743.904762ms 743.952181ms 744.31384ms 745.012193ms 745.624926ms 745.992714ms 746.624844ms 746.839666ms 747.867506ms 747.882477ms 748.261215ms 748.896859ms 750.112676ms 750.891879ms 750.963738ms 751.564748ms 751.648765ms 751.736631ms 755.348156ms 755.432133ms 756.028356ms 756.183192ms 757.994448ms 758.39451ms 758.529176ms 758.732597ms 761.11282ms 762.457293ms 762.997831ms 766.871346ms 768.911306ms 769.209909ms 769.557283ms 772.219154ms 777.458859ms 788.94432ms 812.560969ms 815.089565ms]
Feb  4 19:40:06.865: INFO: 50 %ile: 620.137322ms
Feb  4 19:40:06.865: INFO: 90 %ile: 755.348156ms
Feb  4 19:40:06.865: INFO: 99 %ile: 812.560969ms
Feb  4 19:40:06.865: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:40:06.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-bj5xs" for this suite.
Feb  4 19:40:24.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:40:25.049: INFO: namespace: e2e-tests-svc-latency-bj5xs, resource: bindings, ignored listing per whitelist
Feb  4 19:40:25.088: INFO: namespace e2e-tests-svc-latency-bj5xs deletion completed in 18.207898748s

• [SLOW TEST:29.078 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:40:25.089: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b7a8fc32-28b4-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:40:25.217: INFO: Waiting up to 5m0s for pod "pod-configmaps-b7aa1d0d-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-configmap-xddz4" to be "success or failure"
Feb  4 19:40:25.222: INFO: Pod "pod-configmaps-b7aa1d0d-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 5.485639ms
Feb  4 19:40:27.233: INFO: Pod "pod-configmaps-b7aa1d0d-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016478979s
STEP: Saw pod success
Feb  4 19:40:27.233: INFO: Pod "pod-configmaps-b7aa1d0d-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:40:27.250: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-configmaps-b7aa1d0d-28b4-11e9-8d1f-5e319961b721 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:40:27.308: INFO: Waiting for pod pod-configmaps-b7aa1d0d-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:40:27.313: INFO: Pod pod-configmaps-b7aa1d0d-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:40:27.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xddz4" for this suite.
Feb  4 19:40:33.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:40:33.503: INFO: namespace: e2e-tests-configmap-xddz4, resource: bindings, ignored listing per whitelist
Feb  4 19:40:33.510: INFO: namespace e2e-tests-configmap-xddz4 deletion completed in 6.192952451s

• [SLOW TEST:8.421 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:40:33.510: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  4 19:40:33.640: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 19:40:33.645: INFO: Number of nodes with available pods: 0
Feb  4 19:40:33.645: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 19:40:34.652: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 19:40:34.677: INFO: Number of nodes with available pods: 0
Feb  4 19:40:34.677: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 19:40:35.656: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 19:40:35.679: INFO: Number of nodes with available pods: 1
Feb  4 19:40:35.679: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 19:40:36.657: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 19:40:36.668: INFO: Number of nodes with available pods: 2
Feb  4 19:40:36.669: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  4 19:40:36.781: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 19:40:36.800: INFO: Number of nodes with available pods: 1
Feb  4 19:40:36.800: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 19:40:37.808: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 19:40:37.818: INFO: Number of nodes with available pods: 1
Feb  4 19:40:37.818: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 19:40:38.809: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 19:40:38.817: INFO: Number of nodes with available pods: 1
Feb  4 19:40:38.817: INFO: Node kube-spawn-default-worker-iurq7e is running more than one daemon pod
Feb  4 19:40:39.808: INFO: DaemonSet pods can't tolerate node kube-spawn-default-master-ogc9eo with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Feb  4 19:40:39.820: INFO: Number of nodes with available pods: 2
Feb  4 19:40:39.820: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-psfcl, will wait for the garbage collector to delete the pods
Feb  4 19:40:39.915: INFO: Deleting DaemonSet.extensions daemon-set took: 18.235129ms
Feb  4 19:40:40.015: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.237614ms
Feb  4 19:41:13.726: INFO: Number of nodes with available pods: 0
Feb  4 19:41:13.726: INFO: Number of running nodes: 0, number of available pods: 0
Feb  4 19:41:13.733: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-psfcl/daemonsets","resourceVersion":"17437"},"items":null}

Feb  4 19:41:13.741: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-psfcl/pods","resourceVersion":"17437"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:41:13.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-psfcl" for this suite.
Feb  4 19:41:19.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:41:19.955: INFO: namespace: e2e-tests-daemonsets-psfcl, resource: bindings, ignored listing per whitelist
Feb  4 19:41:19.973: INFO: namespace e2e-tests-daemonsets-psfcl deletion completed in 6.192561218s

• [SLOW TEST:46.463 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:41:19.974: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  4 19:41:22.653: INFO: Successfully updated pod "labelsupdated85d076d-28b4-11e9-8d1f-5e319961b721"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:41:24.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dglcp" for this suite.
Feb  4 19:41:46.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:41:46.852: INFO: namespace: e2e-tests-downward-api-dglcp, resource: bindings, ignored listing per whitelist
Feb  4 19:41:46.956: INFO: namespace e2e-tests-downward-api-dglcp deletion completed in 22.206431053s

• [SLOW TEST:26.982 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:41:46.956: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:41:47.028: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e86d2201-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-ncxtx" to be "success or failure"
Feb  4 19:41:47.058: INFO: Pod "downwardapi-volume-e86d2201-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 29.678184ms
Feb  4 19:41:49.066: INFO: Pod "downwardapi-volume-e86d2201-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03789947s
STEP: Saw pod success
Feb  4 19:41:49.066: INFO: Pod "downwardapi-volume-e86d2201-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:41:49.079: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-e86d2201-28b4-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:41:49.175: INFO: Waiting for pod downwardapi-volume-e86d2201-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:41:49.186: INFO: Pod downwardapi-volume-e86d2201-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:41:49.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ncxtx" for this suite.
Feb  4 19:41:55.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:41:55.405: INFO: namespace: e2e-tests-downward-api-ncxtx, resource: bindings, ignored listing per whitelist
Feb  4 19:41:55.449: INFO: namespace e2e-tests-downward-api-ncxtx deletion completed in 6.25630557s

• [SLOW TEST:8.492 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:41:55.449: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  4 19:41:55.564: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:42:00.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6t8k4" for this suite.
Feb  4 19:42:06.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:42:06.271: INFO: namespace: e2e-tests-init-container-6t8k4, resource: bindings, ignored listing per whitelist
Feb  4 19:42:06.301: INFO: namespace e2e-tests-init-container-6t8k4 deletion completed in 6.174356623s

• [SLOW TEST:10.852 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:42:06.301: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-f3f4b245-28b4-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume configMaps
Feb  4 19:42:06.375: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f3f53530-28b4-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-sk5vp" to be "success or failure"
Feb  4 19:42:06.381: INFO: Pod "pod-projected-configmaps-f3f53530-28b4-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 6.21647ms
Feb  4 19:42:08.429: INFO: Pod "pod-projected-configmaps-f3f53530-28b4-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053810583s
STEP: Saw pod success
Feb  4 19:42:08.429: INFO: Pod "pod-projected-configmaps-f3f53530-28b4-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:42:08.439: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-projected-configmaps-f3f53530-28b4-11e9-8d1f-5e319961b721 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  4 19:42:08.472: INFO: Waiting for pod pod-projected-configmaps-f3f53530-28b4-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:42:08.478: INFO: Pod pod-projected-configmaps-f3f53530-28b4-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:42:08.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sk5vp" for this suite.
Feb  4 19:42:14.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:42:14.590: INFO: namespace: e2e-tests-projected-sk5vp, resource: bindings, ignored listing per whitelist
Feb  4 19:42:14.616: INFO: namespace e2e-tests-projected-sk5vp deletion completed in 6.134977778s

• [SLOW TEST:8.314 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:42:14.616: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-c2nx5
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb  4 19:42:14.687: INFO: Found 0 stateful pods, waiting for 3
Feb  4 19:42:24.694: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:42:24.694: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:42:24.694: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:42:24.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-c2nx5 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:42:24.947: INFO: stderr: ""
Feb  4 19:42:24.947: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:42:24.947: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  4 19:42:34.996: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  4 19:42:45.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-c2nx5 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:42:45.440: INFO: stderr: ""
Feb  4 19:42:45.440: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:42:45.440: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:42:55.488: INFO: Waiting for StatefulSet e2e-tests-statefulset-c2nx5/ss2 to complete update
Feb  4 19:42:55.488: INFO: Waiting for Pod e2e-tests-statefulset-c2nx5/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb  4 19:43:05.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-c2nx5 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:43:05.744: INFO: stderr: ""
Feb  4 19:43:05.744: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:43:05.744: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:43:15.836: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  4 19:43:25.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-c2nx5 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:43:26.141: INFO: stderr: ""
Feb  4 19:43:26.141: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:43:26.141: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:43:36.166: INFO: Waiting for StatefulSet e2e-tests-statefulset-c2nx5/ss2 to complete update
Feb  4 19:43:36.166: INFO: Waiting for Pod e2e-tests-statefulset-c2nx5/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  4 19:43:46.182: INFO: Deleting all statefulset in ns e2e-tests-statefulset-c2nx5
Feb  4 19:43:46.189: INFO: Scaling statefulset ss2 to 0
Feb  4 19:43:56.254: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:43:56.270: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:43:56.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-c2nx5" for this suite.
Feb  4 19:44:04.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:44:04.547: INFO: namespace: e2e-tests-statefulset-c2nx5, resource: bindings, ignored listing per whitelist
Feb  4 19:44:04.565: INFO: namespace e2e-tests-statefulset-c2nx5 deletion completed in 8.206360875s

• [SLOW TEST:109.949 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:44:04.565: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:44:04.683: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  4 19:44:09.691: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  4 19:44:09.691: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  4 19:44:09.796: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-7nrpv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7nrpv/deployments/test-cleanup-deployment,UID:3d7ba8f0-28b5-11e9-88b2-2600a3ceccc4,ResourceVersion:18179,Generation:1,CreationTimestamp:2019-02-04 19:44:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb  4 19:44:09.802: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:44:09.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7nrpv" for this suite.
Feb  4 19:44:15.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:44:15.986: INFO: namespace: e2e-tests-deployment-7nrpv, resource: bindings, ignored listing per whitelist
Feb  4 19:44:16.002: INFO: namespace e2e-tests-deployment-7nrpv deletion completed in 6.168966705s

• [SLOW TEST:11.436 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:44:16.002: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:44:16.068: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  4 19:44:16.077: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  4 19:44:21.088: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  4 19:44:21.088: INFO: Creating deployment "test-rolling-update-deployment"
Feb  4 19:44:21.099: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  4 19:44:21.122: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb  4 19:44:23.129: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  4 19:44:23.134: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684906261, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684906261, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63684906261, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63684906261, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  4 19:44:25.142: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  4 19:44:25.183: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-bf6fq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bf6fq/deployments/test-rolling-update-deployment,UID:444273f5-28b5-11e9-88b2-2600a3ceccc4,ResourceVersion:18319,Generation:1,CreationTimestamp:2019-02-04 19:44:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-04 19:44:21 +0000 UTC 2019-02-04 19:44:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-04 19:44:23 +0000 UTC 2019-02-04 19:44:21 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  4 19:44:25.198: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-bf6fq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bf6fq/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:444e49cd-28b5-11e9-88b2-2600a3ceccc4,ResourceVersion:18309,Generation:1,CreationTimestamp:2019-02-04 19:44:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 444273f5-28b5-11e9-88b2-2600a3ceccc4 0xc001bbbd47 0xc001bbbd48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  4 19:44:25.198: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  4 19:44:25.198: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-bf6fq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bf6fq/replicasets/test-rolling-update-controller,UID:414428d9-28b5-11e9-88b2-2600a3ceccc4,ResourceVersion:18318,Generation:2,CreationTimestamp:2019-02-04 19:44:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 444273f5-28b5-11e9-88b2-2600a3ceccc4 0xc001bbbbf7 0xc001bbbbf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  4 19:44:25.213: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-588hj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-588hj,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-bf6fq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bf6fq/pods/test-rolling-update-deployment-68b55d7bc6-588hj,UID:445162d3-28b5-11e9-88b2-2600a3ceccc4,ResourceVersion:18308,Generation:0,CreationTimestamp:2019-02-04 19:44:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 444e49cd-28b5-11e9-88b2-2600a3ceccc4 0xc0018ec737 0xc0018ec738}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nslpq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nslpq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nslpq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:kube-spawn-default-worker-iurq7e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ec7a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ec7c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:44:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:44:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:44:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-04 19:44:21 +0000 UTC  }],Message:,Reason:,HostIP:10.22.0.7,PodIP:10.46.0.2,StartTime:2019-02-04 19:44:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-04 19:44:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a71d9bfc508923f55e9f4af10806d04dd776e5930f57611fa6c935fb8a8ab8bb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:44:25.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bf6fq" for this suite.
Feb  4 19:44:31.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:44:31.347: INFO: namespace: e2e-tests-deployment-bf6fq, resource: bindings, ignored listing per whitelist
Feb  4 19:44:31.501: INFO: namespace e2e-tests-deployment-bf6fq deletion completed in 6.270805492s

• [SLOW TEST:15.500 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:44:31.502: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:44:35.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-sbqhv" for this suite.
Feb  4 19:45:13.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:45:13.759: INFO: namespace: e2e-tests-kubelet-test-sbqhv, resource: bindings, ignored listing per whitelist
Feb  4 19:45:13.793: INFO: namespace e2e-tests-kubelet-test-sbqhv deletion completed in 38.131897701s

• [SLOW TEST:42.292 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:45:13.794: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb  4 19:45:13.892: INFO: Waiting up to 5m0s for pod "var-expansion-63b8db8f-28b5-11e9-8d1f-5e319961b721" in namespace "e2e-tests-var-expansion-p8cnv" to be "success or failure"
Feb  4 19:45:13.900: INFO: Pod "var-expansion-63b8db8f-28b5-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 7.585337ms
Feb  4 19:45:15.914: INFO: Pod "var-expansion-63b8db8f-28b5-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021415174s
STEP: Saw pod success
Feb  4 19:45:15.914: INFO: Pod "var-expansion-63b8db8f-28b5-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:45:15.917: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod var-expansion-63b8db8f-28b5-11e9-8d1f-5e319961b721 container dapi-container: <nil>
STEP: delete the pod
Feb  4 19:45:15.940: INFO: Waiting for pod var-expansion-63b8db8f-28b5-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:45:15.945: INFO: Pod var-expansion-63b8db8f-28b5-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:45:15.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-p8cnv" for this suite.
Feb  4 19:45:21.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:45:22.054: INFO: namespace: e2e-tests-var-expansion-p8cnv, resource: bindings, ignored listing per whitelist
Feb  4 19:45:22.119: INFO: namespace e2e-tests-var-expansion-p8cnv deletion completed in 6.171382277s

• [SLOW TEST:8.326 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:45:22.120: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:45:22.211: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68af4845-28b5-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-gbh9k" to be "success or failure"
Feb  4 19:45:22.231: INFO: Pod "downwardapi-volume-68af4845-28b5-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 20.544126ms
Feb  4 19:45:24.239: INFO: Pod "downwardapi-volume-68af4845-28b5-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027842434s
STEP: Saw pod success
Feb  4 19:45:24.239: INFO: Pod "downwardapi-volume-68af4845-28b5-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:45:24.250: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-68af4845-28b5-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:45:24.274: INFO: Waiting for pod downwardapi-volume-68af4845-28b5-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:45:24.281: INFO: Pod downwardapi-volume-68af4845-28b5-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:45:24.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gbh9k" for this suite.
Feb  4 19:45:30.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:45:30.502: INFO: namespace: e2e-tests-projected-gbh9k, resource: bindings, ignored listing per whitelist
Feb  4 19:45:30.558: INFO: namespace e2e-tests-projected-gbh9k deletion completed in 6.269594993s

• [SLOW TEST:8.438 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:45:30.558: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  4 19:45:32.768: INFO: Waiting up to 5m0s for pod "client-envvars-6ef7c45f-28b5-11e9-8d1f-5e319961b721" in namespace "e2e-tests-pods-4cxqx" to be "success or failure"
Feb  4 19:45:32.817: INFO: Pod "client-envvars-6ef7c45f-28b5-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 48.332248ms
Feb  4 19:45:34.820: INFO: Pod "client-envvars-6ef7c45f-28b5-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051191996s
STEP: Saw pod success
Feb  4 19:45:34.820: INFO: Pod "client-envvars-6ef7c45f-28b5-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:45:34.822: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod client-envvars-6ef7c45f-28b5-11e9-8d1f-5e319961b721 container env3cont: <nil>
STEP: delete the pod
Feb  4 19:45:34.858: INFO: Waiting for pod client-envvars-6ef7c45f-28b5-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:45:34.870: INFO: Pod client-envvars-6ef7c45f-28b5-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:45:34.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4cxqx" for this suite.
Feb  4 19:46:12.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:46:12.980: INFO: namespace: e2e-tests-pods-4cxqx, resource: bindings, ignored listing per whitelist
Feb  4 19:46:13.026: INFO: namespace e2e-tests-pods-4cxqx deletion completed in 38.151712076s

• [SLOW TEST:42.468 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:46:13.026: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:46:13.098: INFO: Waiting up to 5m0s for pod "downwardapi-volume-87046c6e-28b5-11e9-8d1f-5e319961b721" in namespace "e2e-tests-downward-api-wzlkh" to be "success or failure"
Feb  4 19:46:13.104: INFO: Pod "downwardapi-volume-87046c6e-28b5-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 5.841432ms
Feb  4 19:46:15.110: INFO: Pod "downwardapi-volume-87046c6e-28b5-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011874064s
STEP: Saw pod success
Feb  4 19:46:15.110: INFO: Pod "downwardapi-volume-87046c6e-28b5-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:46:15.119: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-87046c6e-28b5-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:46:15.188: INFO: Waiting for pod downwardapi-volume-87046c6e-28b5-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:46:15.194: INFO: Pod downwardapi-volume-87046c6e-28b5-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:46:15.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wzlkh" for this suite.
Feb  4 19:46:21.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:46:21.286: INFO: namespace: e2e-tests-downward-api-wzlkh, resource: bindings, ignored listing per whitelist
Feb  4 19:46:21.421: INFO: namespace e2e-tests-downward-api-wzlkh deletion completed in 6.223803387s

• [SLOW TEST:8.396 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:46:21.422: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:46:21.515: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c08dce0-28b5-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-m242x" to be "success or failure"
Feb  4 19:46:21.529: INFO: Pod "downwardapi-volume-8c08dce0-28b5-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 12.510418ms
Feb  4 19:46:23.536: INFO: Pod "downwardapi-volume-8c08dce0-28b5-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019518903s
STEP: Saw pod success
Feb  4 19:46:23.536: INFO: Pod "downwardapi-volume-8c08dce0-28b5-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:46:23.542: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod downwardapi-volume-8c08dce0-28b5-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:46:23.604: INFO: Waiting for pod downwardapi-volume-8c08dce0-28b5-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:46:23.610: INFO: Pod downwardapi-volume-8c08dce0-28b5-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:46:23.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m242x" for this suite.
Feb  4 19:46:29.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:46:29.732: INFO: namespace: e2e-tests-projected-m242x, resource: bindings, ignored listing per whitelist
Feb  4 19:46:29.783: INFO: namespace e2e-tests-projected-m242x deletion completed in 6.170500565s

• [SLOW TEST:8.362 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:46:29.784: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-j9xls A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-j9xls;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-j9xls A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-j9xls;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-j9xls.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-j9xls.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-j9xls.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-j9xls.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-j9xls.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-j9xls.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-j9xls.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 75.231.106.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.106.231.75_udp@PTR;check="$$(dig +tcp +noall +answer +search 75.231.106.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.106.231.75_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-j9xls A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-j9xls;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-j9xls A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-j9xls;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-j9xls.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-j9xls.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-j9xls.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-j9xls.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-j9xls.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-j9xls.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-j9xls.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 75.231.106.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.106.231.75_udp@PTR;check="$$(dig +tcp +noall +answer +search 75.231.106.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.106.231.75_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  4 19:46:34.047: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.067: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.084: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-j9xls from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.096: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-j9xls from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.103: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.109: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.111: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.114: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.118: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.121: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.124: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.127: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.130: INFO: Unable to read 10.106.231.75_udp@PTR from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.132: INFO: Unable to read 10.106.231.75_tcp@PTR from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.135: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.139: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.141: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-j9xls from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.143: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-j9xls from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.145: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.147: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.150: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.153: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.155: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.158: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.160: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.162: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.165: INFO: Unable to read 10.106.231.75_udp@PTR from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.167: INFO: Unable to read 10.106.231.75_tcp@PTR from pod e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721: the server could not find the requested resource (get pods dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721)
Feb  4 19:46:34.167: INFO: Lookups using e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-j9xls wheezy_tcp@dns-test-service.e2e-tests-dns-j9xls wheezy_udp@dns-test-service.e2e-tests-dns-j9xls.svc wheezy_tcp@dns-test-service.e2e-tests-dns-j9xls.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.106.231.75_udp@PTR 10.106.231.75_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-j9xls jessie_tcp@dns-test-service.e2e-tests-dns-j9xls jessie_udp@dns-test-service.e2e-tests-dns-j9xls.svc jessie_tcp@dns-test-service.e2e-tests-dns-j9xls.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-j9xls.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-j9xls.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.106.231.75_udp@PTR 10.106.231.75_tcp@PTR]

Feb  4 19:46:39.297: INFO: DNS probes using e2e-tests-dns-j9xls/dns-test-910a9a51-28b5-11e9-8d1f-5e319961b721 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:46:39.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-j9xls" for this suite.
Feb  4 19:46:45.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:46:45.578: INFO: namespace: e2e-tests-dns-j9xls, resource: bindings, ignored listing per whitelist
Feb  4 19:46:45.687: INFO: namespace e2e-tests-dns-j9xls deletion completed in 6.235829389s

• [SLOW TEST:15.903 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:46:45.692: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-czzzh
Feb  4 19:46:51.862: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-czzzh
STEP: checking the pod's current state and verifying that restartCount is present
Feb  4 19:46:51.873: INFO: Initial restart count of pod liveness-http is 0
Feb  4 19:47:09.946: INFO: Restart count of pod e2e-tests-container-probe-czzzh/liveness-http is now 1 (18.073360477s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:47:09.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-czzzh" for this suite.
Feb  4 19:47:16.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:47:16.182: INFO: namespace: e2e-tests-container-probe-czzzh, resource: bindings, ignored listing per whitelist
Feb  4 19:47:16.210: INFO: namespace e2e-tests-container-probe-czzzh deletion completed in 6.179762482s

• [SLOW TEST:30.519 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:47:16.211: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  4 19:47:20.951: INFO: Successfully updated pod "labelsupdateacb2df6c-28b5-11e9-8d1f-5e319961b721"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:47:23.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9xbhl" for this suite.
Feb  4 19:47:45.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:47:45.247: INFO: namespace: e2e-tests-projected-9xbhl, resource: bindings, ignored listing per whitelist
Feb  4 19:47:45.274: INFO: namespace e2e-tests-projected-9xbhl deletion completed in 22.245216349s

• [SLOW TEST:29.063 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:47:45.274: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mwrqc
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mwrqc
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mwrqc
Feb  4 19:47:45.470: INFO: Found 0 stateful pods, waiting for 1
Feb  4 19:47:55.477: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  4 19:47:55.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-mwrqc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:47:55.876: INFO: stderr: ""
Feb  4 19:47:55.876: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:47:55.876: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:47:55.879: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  4 19:48:05.886: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  4 19:48:05.886: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:48:05.944: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999049s
Feb  4 19:48:06.951: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.975781138s
Feb  4 19:48:07.956: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.969182702s
Feb  4 19:48:08.963: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.963382157s
Feb  4 19:48:09.970: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.956569669s
Feb  4 19:48:11.016: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.947238526s
Feb  4 19:48:12.033: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.894017098s
Feb  4 19:48:13.043: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.887281288s
Feb  4 19:48:14.050: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.876219424s
Feb  4 19:48:15.057: INFO: Verifying statefulset ss doesn't scale past 1 for another 868.916987ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mwrqc
Feb  4 19:48:16.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-mwrqc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:48:16.311: INFO: stderr: ""
Feb  4 19:48:16.311: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:48:16.311: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:48:16.314: INFO: Found 1 stateful pods, waiting for 3
Feb  4 19:48:26.321: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:48:26.321: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  4 19:48:26.321: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  4 19:48:26.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-mwrqc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:48:26.669: INFO: stderr: ""
Feb  4 19:48:26.669: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:48:26.669: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:48:26.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-mwrqc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:48:26.883: INFO: stderr: ""
Feb  4 19:48:26.883: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:48:26.883: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:48:26.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-mwrqc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  4 19:48:27.040: INFO: stderr: ""
Feb  4 19:48:27.040: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  4 19:48:27.040: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  4 19:48:27.040: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:48:27.042: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb  4 19:48:37.054: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  4 19:48:37.054: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  4 19:48:37.054: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  4 19:48:37.091: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999895s
Feb  4 19:48:38.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.981987401s
Feb  4 19:48:39.110: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.974116542s
Feb  4 19:48:40.118: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962458817s
Feb  4 19:48:41.129: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.954804089s
Feb  4 19:48:42.140: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.94391721s
Feb  4 19:48:43.143: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.933119734s
Feb  4 19:48:44.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.92921994s
Feb  4 19:48:45.159: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.922222596s
Feb  4 19:48:46.167: INFO: Verifying statefulset ss doesn't scale past 3 for another 913.477067ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mwrqc
Feb  4 19:48:47.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-mwrqc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:48:47.459: INFO: stderr: ""
Feb  4 19:48:47.459: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:48:47.459: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:48:47.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-mwrqc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:48:47.626: INFO: stderr: ""
Feb  4 19:48:47.626: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:48:47.626: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:48:47.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-030580780 exec --namespace=e2e-tests-statefulset-mwrqc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  4 19:48:47.745: INFO: stderr: ""
Feb  4 19:48:47.745: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  4 19:48:47.745: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  4 19:48:47.745: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  4 19:49:07.800: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mwrqc
Feb  4 19:49:07.827: INFO: Scaling statefulset ss to 0
Feb  4 19:49:07.851: INFO: Waiting for statefulset status.replicas updated to 0
Feb  4 19:49:07.855: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:49:07.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mwrqc" for this suite.
Feb  4 19:49:13.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:49:14.050: INFO: namespace: e2e-tests-statefulset-mwrqc, resource: bindings, ignored listing per whitelist
Feb  4 19:49:14.082: INFO: namespace e2e-tests-statefulset-mwrqc deletion completed in 6.192249714s

• [SLOW TEST:88.808 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:49:14.082: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0204 19:49:24.352304      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  4 19:49:24.352: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:49:24.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xq9p6" for this suite.
Feb  4 19:49:32.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:49:32.597: INFO: namespace: e2e-tests-gc-xq9p6, resource: bindings, ignored listing per whitelist
Feb  4 19:49:32.618: INFO: namespace e2e-tests-gc-xq9p6 deletion completed in 8.243767716s

• [SLOW TEST:18.536 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:49:32.618: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  4 19:49:32.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe025eb2-28b5-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-mm9hr" to be "success or failure"
Feb  4 19:49:32.778: INFO: Pod "downwardapi-volume-fe025eb2-28b5-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 42.773287ms
Feb  4 19:49:34.792: INFO: Pod "downwardapi-volume-fe025eb2-28b5-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056497511s
Feb  4 19:49:36.797: INFO: Pod "downwardapi-volume-fe025eb2-28b5-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061830425s
STEP: Saw pod success
Feb  4 19:49:36.797: INFO: Pod "downwardapi-volume-fe025eb2-28b5-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:49:36.805: INFO: Trying to get logs from node kube-spawn-default-worker-iurq7e pod downwardapi-volume-fe025eb2-28b5-11e9-8d1f-5e319961b721 container client-container: <nil>
STEP: delete the pod
Feb  4 19:49:36.894: INFO: Waiting for pod downwardapi-volume-fe025eb2-28b5-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:49:36.911: INFO: Pod downwardapi-volume-fe025eb2-28b5-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:49:36.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mm9hr" for this suite.
Feb  4 19:49:42.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:49:42.996: INFO: namespace: e2e-tests-projected-mm9hr, resource: bindings, ignored listing per whitelist
Feb  4 19:49:43.042: INFO: namespace e2e-tests-projected-mm9hr deletion completed in 6.117319647s

• [SLOW TEST:10.424 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:49:43.042: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-04326440-28b6-11e9-8d1f-5e319961b721
STEP: Creating a pod to test consume secrets
Feb  4 19:49:43.120: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-04336fbc-28b6-11e9-8d1f-5e319961b721" in namespace "e2e-tests-projected-d57gb" to be "success or failure"
Feb  4 19:49:43.129: INFO: Pod "pod-projected-secrets-04336fbc-28b6-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 8.645667ms
Feb  4 19:49:45.133: INFO: Pod "pod-projected-secrets-04336fbc-28b6-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012961178s
STEP: Saw pod success
Feb  4 19:49:45.133: INFO: Pod "pod-projected-secrets-04336fbc-28b6-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:49:45.137: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod pod-projected-secrets-04336fbc-28b6-11e9-8d1f-5e319961b721 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  4 19:49:45.166: INFO: Waiting for pod pod-projected-secrets-04336fbc-28b6-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:49:45.179: INFO: Pod pod-projected-secrets-04336fbc-28b6-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:49:45.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d57gb" for this suite.
Feb  4 19:49:51.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:49:51.366: INFO: namespace: e2e-tests-projected-d57gb, resource: bindings, ignored listing per whitelist
Feb  4 19:49:51.476: INFO: namespace e2e-tests-projected-d57gb deletion completed in 6.29399001s

• [SLOW TEST:8.434 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:49:51.477: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-09483f34-28b6-11e9-8d1f-5e319961b721
Feb  4 19:49:51.671: INFO: Pod name my-hostname-basic-09483f34-28b6-11e9-8d1f-5e319961b721: Found 0 pods out of 1
Feb  4 19:49:56.673: INFO: Pod name my-hostname-basic-09483f34-28b6-11e9-8d1f-5e319961b721: Found 1 pods out of 1
Feb  4 19:49:56.673: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-09483f34-28b6-11e9-8d1f-5e319961b721" are running
Feb  4 19:49:56.676: INFO: Pod "my-hostname-basic-09483f34-28b6-11e9-8d1f-5e319961b721-2kblc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-04 19:49:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-04 19:49:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-04 19:49:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-04 19:49:51 +0000 UTC Reason: Message:}])
Feb  4 19:49:56.676: INFO: Trying to dial the pod
Feb  4 19:50:01.715: INFO: Controller my-hostname-basic-09483f34-28b6-11e9-8d1f-5e319961b721: Got expected result from replica 1 [my-hostname-basic-09483f34-28b6-11e9-8d1f-5e319961b721-2kblc]: "my-hostname-basic-09483f34-28b6-11e9-8d1f-5e319961b721-2kblc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:50:01.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-qx5cc" for this suite.
Feb  4 19:50:07.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:50:07.831: INFO: namespace: e2e-tests-replication-controller-qx5cc, resource: bindings, ignored listing per whitelist
Feb  4 19:50:07.977: INFO: namespace e2e-tests-replication-controller-qx5cc deletion completed in 6.247823455s

• [SLOW TEST:16.500 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  4 19:50:07.977: INFO: >>> kubeConfig: /tmp/kubeconfig-030580780
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb  4 19:50:08.052: INFO: Waiting up to 5m0s for pod "var-expansion-130eb4ca-28b6-11e9-8d1f-5e319961b721" in namespace "e2e-tests-var-expansion-xssq6" to be "success or failure"
Feb  4 19:50:08.063: INFO: Pod "var-expansion-130eb4ca-28b6-11e9-8d1f-5e319961b721": Phase="Pending", Reason="", readiness=false. Elapsed: 10.898428ms
Feb  4 19:50:10.065: INFO: Pod "var-expansion-130eb4ca-28b6-11e9-8d1f-5e319961b721": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013203553s
STEP: Saw pod success
Feb  4 19:50:10.065: INFO: Pod "var-expansion-130eb4ca-28b6-11e9-8d1f-5e319961b721" satisfied condition "success or failure"
Feb  4 19:50:10.068: INFO: Trying to get logs from node kube-spawn-default-worker-pqanhr pod var-expansion-130eb4ca-28b6-11e9-8d1f-5e319961b721 container dapi-container: <nil>
STEP: delete the pod
Feb  4 19:50:10.102: INFO: Waiting for pod var-expansion-130eb4ca-28b6-11e9-8d1f-5e319961b721 to disappear
Feb  4 19:50:10.107: INFO: Pod var-expansion-130eb4ca-28b6-11e9-8d1f-5e319961b721 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  4 19:50:10.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-xssq6" for this suite.
Feb  4 19:50:16.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  4 19:50:16.255: INFO: namespace: e2e-tests-var-expansion-xssq6, resource: bindings, ignored listing per whitelist
Feb  4 19:50:16.311: INFO: namespace e2e-tests-var-expansion-xssq6 deletion completed in 6.20112381s

• [SLOW TEST:8.334 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSFeb  4 19:50:16.319: INFO: Running AfterSuite actions on all nodes
Feb  4 19:50:16.320: INFO: Running AfterSuite actions on node 1
Feb  4 19:50:16.320: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5452.416 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h30m53.055402722s
Test Suite Passed
