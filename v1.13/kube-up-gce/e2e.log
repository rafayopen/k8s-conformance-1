bootstrap.py is deprecated!
Please migrate your job to podutils!
https://github.com/kubernetes/test-infra/blob/master/prow/pod-utilities.md
Args: --job=ci-kubernetes-gce-conformance-stable-1-13 --service-account=/etc/service-account/service-account.json --upload=gs://kubernetes-jenkins/logs --timeout=220 --bare --scenario=kubernetes_e2e -- --extract=release/stable-1.13 --gcp-master-image=gci --gcp-node-image=gci --gcp-zone=us-central1-f --provider=gce '--test_args=--ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\]' --timeout=200m
Bootstrap ci-kubernetes-gce-conformance-stable-1-13...
Builder: gke-prow-default-pool-3c8994a8-kfgr
Image: gcr.io/k8s-testimages/kubekins-e2e:v20181205-915278e90-1.13
Gubernator results at https://gubernator.k8s.io/build/kubernetes-jenkins/logs/ci-kubernetes-gce-conformance-stable-1-13/160
Call:  gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json
Activated service account credentials for: [pr-kubekins@kubernetes-jenkins-pull.iam.gserviceaccount.com]
process 34 exited with code 0 after 0.1m
Call:  gcloud config get-value account
process 47 exited with code 0 after 0.0m
Will upload results to gs://kubernetes-jenkins/logs using pr-kubekins@kubernetes-jenkins-pull.iam.gserviceaccount.com
Call:  kubectl get -oyaml pods/7e6545eb-0233-11e9-ade6-0a580a6c02f3
The connection to the server localhost:8080 was refused - did you specify the right host or port?
Command failed
process 60 exited with code 1 after 0.0m
unable to upload podspecs: Command '['kubectl', 'get', '-oyaml', 'pods/7e6545eb-0233-11e9-ade6-0a580a6c02f3']' returned non-zero exit status 1
Root: /workspace
cd to /workspace
Configure environment...
Call:  git show -s --format=format:%ct HEAD
fatal: Not a git repository (or any of the parent directories): .git
process 73 exited with code 128 after 0.0m
Unable to print commit date for HEAD
Call:  gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json
Activated service account credentials for: [pr-kubekins@kubernetes-jenkins-pull.iam.gserviceaccount.com]
process 74 exited with code 0 after 0.2m
Call:  gcloud config get-value account
process 87 exited with code 0 after 0.0m
Will upload results to gs://kubernetes-jenkins/logs using pr-kubekins@kubernetes-jenkins-pull.iam.gserviceaccount.com
Start 160 at ...
Call:  gsutil -q -h Content-Type:application/json cp /tmp/gsutil_9fbrZ8 gs://kubernetes-jenkins/logs/ci-kubernetes-gce-conformance-stable-1-13/160/started.json
process 100 exited with code 0 after 0.1m
Call:  /workspace/./test-infra/jenkins/../scenarios/kubernetes_e2e.py --extract=release/stable-1.13 --gcp-master-image=gci --gcp-node-image=gci --gcp-zone=us-central1-f --provider=gce '--test_args=--ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\]' --timeout=200m
starts with local mode
Environment:
ARTIFACTS=/workspace/_artifacts
BAZEL_REMOTE_CACHE_ENABLED=false
BAZEL_VERSION=0.18.1
BOOTSTRAP_MIGRATION=yes
BOSKOS_METRICS_PORT=tcp://10.63.249.148:80
BOSKOS_METRICS_PORT_80_TCP=tcp://10.63.249.148:80
BOSKOS_METRICS_PORT_80_TCP_ADDR=10.63.249.148
BOSKOS_METRICS_PORT_80_TCP_PORT=80
BOSKOS_METRICS_PORT_80_TCP_PROTO=tcp
BOSKOS_METRICS_SERVICE_HOST=10.63.249.148
BOSKOS_METRICS_SERVICE_PORT=80
BOSKOS_METRICS_SERVICE_PORT_DEFAULT=80
BOSKOS_PORT=tcp://10.63.250.132:80
BOSKOS_PORT_80_TCP=tcp://10.63.250.132:80
BOSKOS_PORT_80_TCP_ADDR=10.63.250.132
BOSKOS_PORT_80_TCP_PORT=80
BOSKOS_PORT_80_TCP_PROTO=tcp
BOSKOS_SERVICE_HOST=10.63.250.132
BOSKOS_SERVICE_PORT=80
BOSKOS_SERVICE_PORT_DEFAULT=80
BUILD_ID=160
BUILD_NUMBER=160
CLOUDSDK_COMPONENT_MANAGER_DISABLE_UPDATE_CHECK=true
CLOUDSDK_CONFIG=/workspace/.config/gcloud
CLOUDSDK_CORE_DISABLE_PROMPTS=1
CLOUDSDK_EXPERIMENTAL_FAST_COMPONENT_UPDATE=false
DOCKER_IN_DOCKER_ENABLED=false
E2E_GOOGLE_APPLICATION_CREDENTIALS=/etc/service-account/service-account.json
GCS_ARTIFACTS_DIR=gs://kubernetes-jenkins/logs/ci-kubernetes-gce-conformance-stable-1-13/160/artifacts
GOOGLE_APPLICATION_CREDENTIALS=/etc/service-account/service-account.json
GOPATH=/go
GO_TARBALL=go1.11.2.linux-amd64.tar.gz
HOME=/workspace
HOSTNAME=7e6545eb-0233-11e9-ade6-0a580a6c02f3
IMAGE=gcr.io/k8s-testimages/kubekins-e2e:v20181205-915278e90-1.13
INSTANCE_PREFIX=bootstrap-e2e
JENKINS_AWS_SSH_PRIVATE_KEY_FILE=/root/.ssh/kube_aws_rsa
JENKINS_AWS_SSH_PUBLIC_KEY_FILE=/root/.ssh/kube_aws_rsa.pub
JENKINS_GCE_SSH_PRIVATE_KEY_FILE=/workspace/.ssh/google_compute_engine
JENKINS_GCE_SSH_PUBLIC_KEY_FILE=/workspace/.ssh/google_compute_engine.pub
JOB_NAME=ci-kubernetes-gce-conformance-stable-1-13
JOB_SPEC={"type":"periodic","job":"ci-kubernetes-gce-conformance-stable-1-13","buildid":"160","prowjobid":"7e6545eb-0233-11e9-ade6-0a580a6c02f3"}
JOB_TYPE=periodic
KUBERNETES_PORT=tcp://10.63.240.1:443
KUBERNETES_PORT_443_TCP=tcp://10.63.240.1:443
KUBERNETES_PORT_443_TCP_ADDR=10.63.240.1
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_SERVICE_HOST=10.63.240.1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBETEST_IN_DOCKER=true
KUBETEST_MANUAL_DUMP=y
KUBE_AWS_INSTANCE_PREFIX=bootstrap-e2e
KUBE_GCE_INSTANCE_PREFIX=bootstrap-e2e
NODE_NAME=gke-prow-default-pool-3c8994a8-kfgr
PATH=/go/bin:/go/bin:/usr/local/go/bin:/google-cloud-sdk/bin:/workspace:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
POD_NAME=7e6545eb-0233-11e9-ade6-0a580a6c02f3
PROW_JOB_ID=7e6545eb-0233-11e9-ade6-0a580a6c02f3
PWD=/workspace
SHLVL=2
TERM=xterm
USER=prow
WORKSPACE=/workspace
_=./test-infra/jenkins/bootstrap.py
Run: ('kubetest', '--dump=/workspace/_artifacts', '--gcp-service-account=/etc/service-account/service-account.json', '--up', '--down', '--test', '--provider=gce', '--cluster=bootstrap-e2e', '--gcp-network=bootstrap-e2e', '--extract=release/stable-1.13', '--gcp-master-image=gci', '--gcp-node-image=gci', '--gcp-zone=us-central1-f', '--test_args=--ginkgo.focus=\\[Conformance\\] --ginkgo.skip=Alpha|\\[(Disruptive|Feature:[^\\]]+|Flaky)\\]', '--timeout=200m')
2018/12/17 19:41:26 main.go:326: Limiting testing to 3h20m0s
2018/12/17 19:41:26 main.go:761: --gcp-project is missing, trying to fetch a project from boskos.
(for local runs please set --gcp-project to your dev project)
2018/12/17 19:41:26 main.go:773: provider gce, will acquire project type gce-project from boskos
2018/12/17 19:41:32 process.go:153: Running: gcloud config set project k8s-boskos-gce-project-14
Updated property [core/project].
2018/12/17 19:41:32 process.go:155: Step 'gcloud config set project k8s-boskos-gce-project-14' finished in 288.866709ms
2018/12/17 19:41:32 process.go:153: Running: gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json
Activated service account credentials for: [pr-kubekins@kubernetes-jenkins-pull.iam.gserviceaccount.com]
2018/12/17 19:41:33 process.go:155: Step 'gcloud auth activate-service-account --key-file=/etc/service-account/service-account.json' finished in 606.063584ms
2018/12/17 19:41:33 main.go:814: Checking existing of GCP ssh keys...
2018/12/17 19:41:33 main.go:824: Checking presence of public key in k8s-boskos-gce-project-14
2018/12/17 19:41:33 process.go:153: Running: gcloud compute --project=k8s-boskos-gce-project-14 project-info describe
2018/12/17 19:41:33 process.go:155: Step 'gcloud compute --project=k8s-boskos-gce-project-14 project-info describe' finished in 813.803534ms
2018/12/17 19:41:33 extract_k8s.go:133: rm kubernetes
2018/12/17 19:41:33 process.go:153: Running: gsutil cat gs://kubernetes-release/release/stable-1.13.txt
2018/12/17 19:41:35 process.go:155: Step 'gsutil cat gs://kubernetes-release/release/stable-1.13.txt' finished in 2.023070323s
2018/12/17 19:41:35 extract_k8s.go:285: U=https://storage.googleapis.com/kubernetes-release/release R=v1.13.1 get-kube.sh
2018/12/17 19:41:35 process.go:153: Running: ./get-kube.sh
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100 1893k  100 1893k    0     0  11.9M      0 --:--:-- --:--:-- --:--:-- 12.0M
Downloading kubernetes release v1.13.1
  from https://storage.googleapis.com/kubernetes-release/release/v1.13.1/kubernetes.tar.gz
  to /workspace/kubernetes.tar.gz
Unpacking kubernetes release v1.13.1
Kubernetes release: v1.13.1
Server: linux/amd64  (to override, set KUBERNETES_SERVER_ARCH)
Client: linux/amd64  (autodetected)

Will download kubernetes-server-linux-amd64.tar.gz from https://storage.googleapis.com/kubernetes-release/release/v1.13.1
Will download and extract kubernetes-client-linux-amd64.tar.gz from https://storage.googleapis.com/kubernetes-release/release/v1.13.1
Will download and extract kubernetes-test.tar.gz from https://storage.googleapis.com/kubernetes-release/release/v1.13.1
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  1  398M    1 4096k    0     0  18.7M      0  0:00:21 --:--:--  0:00:21 18.6M 30  398M   30  122M    0     0   101M      0  0:00:03  0:00:01  0:00:02  101M 73  398M   73  292M    0     0   132M      0  0:00:02  0:00:02 --:--:--  132M100  398M  100  398M    0     0   136M      0  0:00:02  0:00:02 --:--:--  136M

md5sum(kubernetes-server-linux-amd64.tar.gz)=12a3dcacd6c1e4ce448187a091fc6d26
sha1sum(kubernetes-server-linux-amd64.tar.gz)=93bd08f4220ad26a6b38013f98b17cff9468da71

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 70 11.4M   70 8200k    0     0  28.9M      0 --:--:-- --:--:-- --:--:-- 28.9M100 11.4M  100 11.4M    0     0  38.9M      0 --:--:-- --:--:-- --:--:-- 38.8M

md5sum(kubernetes-client-linux-amd64.tar.gz)=aa8974dc6bff8c338d006c460e1b76a4
sha1sum(kubernetes-client-linux-amd64.tar.gz)=6586e64bf4aed6e0943590171c8e56d7f5715915

Extracting /workspace/kubernetes/client/kubernetes-client-linux-amd64.tar.gz into /workspace/kubernetes/platforms/linux/amd64
Add '/workspace/kubernetes/client/bin' to your PATH to use newly-installed binaries.
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  4 1175M    4 56.9M    0     0   111M      0  0:00:10 --:--:--  0:00:10  110M 21 1175M   21  252M    0     0   166M      0  0:00:07  0:00:01  0:00:06  166M 38 1175M   38  458M    0     0   182M      0  0:00:06  0:00:02  0:00:04  182M 55 1175M   55  655M    0     0   186M      0  0:00:06  0:00:03  0:00:03  186M 77 1175M   77  908M    0     0   201M      0  0:00:05  0:00:04  0:00:01  201M 96 1175M   96 1132M    0     0   205M      0  0:00:05  0:00:05 --:--:--  215M100 1175M  100 1175M    0     0   204M      0  0:00:05  0:00:05 --:--:--  218M

md5sum(kubernetes-test.tar.gz)=f50b579be06fac94e0f88e45d73e59c0
sha1sum(kubernetes-test.tar.gz)=04c2a9368bfdf8cb7096ba0fadf8f2b6b75ed4a2

Extracting kubernetes-test.tar.gz into /workspace/kubernetes
2018/12/17 19:42:37 process.go:155: Step './get-kube.sh' finished in 1m1.812047028s
2018/12/17 19:42:37 process.go:153: Running: ./hack/e2e-internal/e2e-down.sh
Project: k8s-boskos-gce-project-14
Network Project: k8s-boskos-gce-project-14
Zone: us-central1-f
Shutting down test cluster in background.
... calling verify-prereqs
Bringing down cluster using provider: gce
... calling verify-kube-binaries
... calling kube-down
Project: k8s-boskos-gce-project-14
Network Project: k8s-boskos-gce-project-14
Zone: us-central1-f
INSTANCE_GROUPS=
NODE_NAMES=
Bringing down cluster
Deleting firewall rules remaining in network bootstrap-e2e: 
Property "clusters.k8s-boskos-gce-project-14_bootstrap-e2e" unset.
Property "users.k8s-boskos-gce-project-14_bootstrap-e2e" unset.
Property "users.k8s-boskos-gce-project-14_bootstrap-e2e-basic-auth" unset.
Property "contexts.k8s-boskos-gce-project-14_bootstrap-e2e" unset.
Cleared config for k8s-boskos-gce-project-14_bootstrap-e2e from /workspace/.kube/config
Done
2018/12/17 19:43:13 process.go:155: Step './hack/e2e-internal/e2e-down.sh' finished in 35.330454055s
2018/12/17 19:43:13 process.go:153: Running: ./hack/e2e-internal/e2e-up.sh
Project: k8s-boskos-gce-project-14
Network Project: k8s-boskos-gce-project-14
Zone: us-central1-f
... Starting cluster in us-central1-f using provider gce
... calling verify-prereqs
... calling verify-kube-binaries
... calling verify-release-tars
... calling kube-up
Project: k8s-boskos-gce-project-14
Network Project: k8s-boskos-gce-project-14
Zone: us-central1-f
+++ Staging server tars to Google Storage: gs://kubernetes-staging-59320d12ef/bootstrap-e2e-devel
+++ kubernetes-server-linux-amd64.tar.gz uploaded (sha1 = 93bd08f4220ad26a6b38013f98b17cff9468da71)
+++ kubernetes-manifests.tar.gz uploaded (sha1 = 1f87def4698d40ef19c251876247b3854868f42e)
Creating new auto network: bootstrap-e2e
Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/networks/bootstrap-e2e].
NAME           SUBNET_MODE  BGP_ROUTING_MODE  IPV4_RANGE  GATEWAY_IPV4
bootstrap-e2e  AUTO         REGIONAL

Instances on this network will not be reachable until firewall rules
are created. As an example, you can allow all internal traffic between
instances as well as SSH, RDP, and ICMP by running:

$ gcloud compute firewall-rules create <FIREWALL_NAME> --network bootstrap-e2e --allow tcp,udp,icmp --source-ranges <IP_RANGE>
$ gcloud compute firewall-rules create <FIREWALL_NAME> --network bootstrap-e2e --allow tcp:22,tcp:3389,icmp

Creating firewall...
Creating firewall...
IP aliases are disabled.
.Creating firewall...
Found subnet for region us-central1 in network bootstrap-e2e: bootstrap-e2e
Starting master and configuring firewalls
..Creating firewall...
....................Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/zones/us-central1-f/disks/bootstrap-e2e-master-pd].
NAME                     ZONE           SIZE_GB  TYPE    STATUS
bootstrap-e2e-master-pd  us-central1-f  20       pd-ssd  READY

New disks are unformatted. You must format and mount a disk before it
can be used. You can find instructions on how to do this at:

https://cloud.google.com/compute/docs/disks/add-persistent-disk#formatting

.....Creating firewall...
.....................................Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/regions/us-central1/addresses/bootstrap-e2e-master-ip].
....Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/firewalls/bootstrap-e2e-default-internal-master].
done.
NAME                                   NETWORK        DIRECTION  PRIORITY  ALLOW                                       DENY  DISABLED
bootstrap-e2e-default-internal-master  bootstrap-e2e  INGRESS    1000      tcp:1-2379,tcp:2382-65535,udp:1-65535,icmp        False
............2018/12/17 19:45:02 [INFO] generating a new CA key and certificate from CSR
2018/12/17 19:45:02 [INFO] generate received request
2018/12/17 19:45:02 [INFO] received CSR
2018/12/17 19:45:02 [INFO] generating key: ecdsa-256
2018/12/17 19:45:02 [INFO] encoded CSR
2018/12/17 19:45:02 [INFO] signed certificate with serial number 711569740820920405688744888830624908185303080150
2018/12/17 19:45:02 [INFO] generate received request
2018/12/17 19:45:02 [INFO] received CSR
2018/12/17 19:45:02 [INFO] generating key: ecdsa-256
2018/12/17 19:45:02 [INFO] encoded CSR
2018/12/17 19:45:02 [INFO] signed certificate with serial number 351505281485345551463139679380147764605873638057
Generating certs for alternate-names: IP:35.225.177.164,IP:10.0.0.1,DNS:kubernetes,DNS:kubernetes.default,DNS:kubernetes.default.svc,DNS:kubernetes.default.svc.cluster.local,DNS:bootstrap-e2e-master
Generate peer certificates...
+++ Logging using Fluentd to gcp
.Creating firewall...
............Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/firewalls/bootstrap-e2e-default-internal-node].
.done.
....Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/firewalls/bootstrap-e2e-default-ssh].
NAME                                 NETWORK        DIRECTION  PRIORITY  ALLOW                         DENY  DISABLED
bootstrap-e2e-default-internal-node  bootstrap-e2e  INGRESS    1000      tcp:1-65535,udp:1-65535,icmp        False
done.
..Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/firewalls/bootstrap-e2e-master-https].
done.
...Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/firewalls/bootstrap-e2e-master-etcd].
NAME                       NETWORK        DIRECTION  PRIORITY  ALLOW   DENY  DISABLED
bootstrap-e2e-default-ssh  bootstrap-e2e  INGRESS    1000      tcp:22        False
NAME                        NETWORK        DIRECTION  PRIORITY  ALLOW    DENY  DISABLED
bootstrap-e2e-master-https  bootstrap-e2e  INGRESS    1000      tcp:443        False
done.
...........Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/firewalls/bootstrap-e2e-minion-all].
NAME                       NETWORK        DIRECTION  PRIORITY  ALLOW              DENY  DISABLED
bootstrap-e2e-master-etcd  bootstrap-e2e  INGRESS    1000      tcp:2380,tcp:2381        False
done.
NAME                      NETWORK        DIRECTION  PRIORITY  ALLOW                     DENY  DISABLED
bootstrap-e2e-minion-all  bootstrap-e2e  INGRESS    1000      tcp,udp,icmp,esp,ah,sctp        False
WARNING: You have selected a disk size of under [200GB]. This may result in poor I/O performance. For more information, see: https://developers.google.com/compute/docs/disks#performance.
Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/zones/us-central1-f/instances/bootstrap-e2e-master].
WARNING: Some requests generated warnings:
 - The resource 'projects/cos-cloud/global/images/cos-stable-65-10323-64-0' is deprecated. A suggested replacement is 'projects/cos-cloud/global/images/cos-stable-65-10323-69-0'.

NAME                  ZONE           MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP     STATUS
bootstrap-e2e-master  us-central1-f  n1-standard-1               10.128.0.2   35.225.177.164  RUNNING
Creating nodes.
Using subnet bootstrap-e2e
Attempt 1 to create bootstrap-e2e-minion-template
WARNING: You have selected a disk size of under [200GB]. This may result in poor I/O performance. For more information, see: https://developers.google.com/compute/docs/disks#performance.
Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/instanceTemplates/bootstrap-e2e-minion-template].
NAME                           MACHINE_TYPE   PREEMPTIBLE  CREATION_TIMESTAMP
bootstrap-e2e-minion-template  n1-standard-2               2018-12-17T11:45:41.611-08:00
Created [https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/zones/us-central1-f/instanceGroupManagers/bootstrap-e2e-minion-group].
NAME                        LOCATION       SCOPE  BASE_INSTANCE_NAME          SIZE  TARGET_SIZE  INSTANCE_TEMPLATE              AUTOSCALED
bootstrap-e2e-minion-group  us-central1-f  zone   bootstrap-e2e-minion-group  0     3            bootstrap-e2e-minion-template  no
Waiting for group to become stable, current operations: creating: 3
Waiting for group to become stable, current operations: creating: 3
Waiting for group to become stable, current operations: creating: 2
Waiting for group to become stable, current operations: creating: 2
Group is stable
INSTANCE_GROUPS=bootstrap-e2e-minion-group
NODE_NAMES=bootstrap-e2e-minion-group-6xhw bootstrap-e2e-minion-group-tnzf bootstrap-e2e-minion-group-wjp3
Trying to find master named 'bootstrap-e2e-master'
Looking for address 'bootstrap-e2e-master-ip'
Using master: bootstrap-e2e-master (external IP: 35.225.177.164)
Waiting up to 300 seconds for cluster initialization.

  This will continually check to see if the API for kubernetes is reachable.
  This may time out if there was some uncaught error during start up.

.....Kubernetes cluster created.
Cluster "k8s-boskos-gce-project-14_bootstrap-e2e" set.
User "k8s-boskos-gce-project-14_bootstrap-e2e" set.
Context "k8s-boskos-gce-project-14_bootstrap-e2e" created.
Switched to context "k8s-boskos-gce-project-14_bootstrap-e2e".
User "k8s-boskos-gce-project-14_bootstrap-e2e-basic-auth" set.
Wrote config for k8s-boskos-gce-project-14_bootstrap-e2e to /workspace/.kube/config

Kubernetes cluster is running.  The master is running at:

  https://35.225.177.164

The user name and password to use is located in /workspace/.kube/config.

Validating gce cluster, MULTIZONE=
... calling validate-cluster
Project: k8s-boskos-gce-project-14
Network Project: k8s-boskos-gce-project-14
Zone: us-central1-f
No resources found.
Waiting for 4 ready nodes. 0 ready nodes, 0 registered. Retrying.
No resources found.
Waiting for 4 ready nodes. 0 ready nodes, 0 registered. Retrying.
Waiting for 4 ready nodes. 3 ready nodes, 4 registered. Retrying.
Found 4 node(s).
NAME                              STATUS                     ROLES    AGE   VERSION
bootstrap-e2e-master              Ready,SchedulingDisabled   <none>   25s   v1.13.1
bootstrap-e2e-minion-group-6xhw   Ready                      <none>   17s   v1.13.1
bootstrap-e2e-minion-group-tnzf   Ready                      <none>   16s   v1.13.1
bootstrap-e2e-minion-group-wjp3   Ready                      <none>   16s   v1.13.1
Validate output:
NAME                 STATUS    MESSAGE              ERROR
scheduler            Healthy   ok                   
controller-manager   Healthy   ok                   
etcd-0               Healthy   {"health": "true"}   
etcd-1               Healthy   {"health": "true"}   
Cluster validation succeeded
Done, listing cluster services:

Kubernetes master is running at https://35.225.177.164
GLBCDefaultBackend is running at https://35.225.177.164/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy
Heapster is running at https://35.225.177.164/api/v1/namespaces/kube-system/services/heapster/proxy
CoreDNS is running at https://35.225.177.164/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
kubernetes-dashboard is running at https://35.225.177.164/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy
Metrics-server is running at https://35.225.177.164/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.

NAME                                         NETWORK        DIRECTION  PRIORITY  ALLOW            DENY  DISABLED
bootstrap-e2e-minion-bootstrap-e2e-http-alt  bootstrap-e2e  INGRESS    1000      tcp:80,tcp:8080        False
allowed:
- IPProtocol: tcp
  ports:
  - '80'
- IPProtocol: tcp
  ports:
  - '8080'
creationTimestamp: '2018-12-17T11:48:07.195-08:00'
description: ''
direction: INGRESS
disabled: false
id: '8301102329914606488'
kind: compute#firewall
name: bootstrap-e2e-minion-bootstrap-e2e-http-alt
network: https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/networks/bootstrap-e2e
priority: 1000
selfLink: https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/firewalls/bootstrap-e2e-minion-bootstrap-e2e-http-alt
sourceRanges:
- 0.0.0.0/0
targetTags:
- bootstrap-e2e-minion
NAME                                          NETWORK        DIRECTION  PRIORITY  ALLOW                            DENY  DISABLED
bootstrap-e2e-minion-bootstrap-e2e-nodeports  bootstrap-e2e  INGRESS    1000      tcp:30000-32767,udp:30000-32767        False
allowed:
- IPProtocol: tcp
  ports:
  - 30000-32767
- IPProtocol: udp
  ports:
  - 30000-32767
creationTimestamp: '2018-12-17T11:48:26.484-08:00'
description: ''
direction: INGRESS
disabled: false
id: '3378061118449271653'
kind: compute#firewall
name: bootstrap-e2e-minion-bootstrap-e2e-nodeports
network: https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/networks/bootstrap-e2e
priority: 1000
selfLink: https://www.googleapis.com/compute/v1/projects/k8s-boskos-gce-project-14/global/firewalls/bootstrap-e2e-minion-bootstrap-e2e-nodeports
sourceRanges:
- 0.0.0.0/0
targetTags:
- bootstrap-e2e-minion
2018/12/17 19:48:43 process.go:155: Step './hack/e2e-internal/e2e-up.sh' finished in 5m30.513662432s
2018/12/17 19:48:43 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false version
2018/12/17 19:48:44 process.go:155: Step './cluster/kubectl.sh --match-server-version=false version' finished in 245.483481ms
2018/12/17 19:48:44 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false get nodes -oyaml
2018/12/17 19:48:44 process.go:155: Step './cluster/kubectl.sh --match-server-version=false get nodes -oyaml' finished in 165.972528ms
2018/12/17 19:48:44 process.go:153: Running: ./hack/e2e-internal/e2e-status.sh
Project: k8s-boskos-gce-project-14
Network Project: k8s-boskos-gce-project-14
Zone: us-central1-f
Client Version: version.Info{Major:"1", Minor:"13", GitVersion:"v1.13.1", GitCommit:"eec55b9ba98609a46fee712359c7b5b365bdd920", GitTreeState:"clean", BuildDate:"2018-12-13T10:39:04Z", GoVersion:"go1.11.2", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"13", GitVersion:"v1.13.1", GitCommit:"eec55b9ba98609a46fee712359c7b5b365bdd920", GitTreeState:"clean", BuildDate:"2018-12-13T10:31:33Z", GoVersion:"go1.11.2", Compiler:"gc", Platform:"linux/amd64"}
2018/12/17 19:48:44 process.go:155: Step './hack/e2e-internal/e2e-status.sh' finished in 360.517907ms
2018/12/17 19:48:44 process.go:153: Running: ./cluster/kubectl.sh --match-server-version=false version
2018/12/17 19:48:44 process.go:155: Step './cluster/kubectl.sh --match-server-version=false version' finished in 232.077394ms
2018/12/17 19:48:44 process.go:153: Running: ./hack/ginkgo-e2e.sh --ginkgo.focus=\[Conformance\] --ginkgo.skip=Alpha|\[(Disruptive|Feature:[^\]]+|Flaky)\] --report-dir=/workspace/_artifacts --disable-log-dump=true
Setting up for KUBERNETES_PROVIDER="gce".
Project: k8s-boskos-gce-project-14
Network Project: k8s-boskos-gce-project-14
Zone: us-central1-f
Trying to find master named 'bootstrap-e2e-master'
Looking for address 'bootstrap-e2e-master-ip'
Using master: bootstrap-e2e-master (external IP: 35.225.177.164)
Dec 17 19:48:47.181: INFO: Fetching cloud provider for "gce"
I1217 19:48:47.181706    7194 gce.go:874] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc0000dc018), conf:(*jwt.Config)(0xc0016db500)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
I1217 19:48:47.303726    7194 gce.go:874] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc0000dc018), conf:(*jwt.Config)(0xc001800000)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
I1217 19:48:47.334777    7194 gce.go:874] Using DefaultTokenSource &oauth2.reuseTokenSource{new:jwt.jwtSource{ctx:(*context.emptyCtx)(0xc0000dc018), conf:(*jwt.Config)(0xc001800300)}, mu:sync.Mutex{state:0, sema:0x0}, t:(*oauth2.Token)(nil)}
W1217 19:48:47.362574    7194 gce.go:469] No network name or URL specified.
I1217 19:48:47.362752    7194 e2e.go:224] Starting e2e run "c44682f8-0234-11e9-9892-0a580a3c54b9" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1545076125 - Will randomize all specs
Will run 201 of 2118 specs

Dec 17 19:48:51.503: INFO: cluster-master-image: cos-stable-65-10323-64-0
Dec 17 19:48:51.503: INFO: cluster-node-image: cos-stable-65-10323-64-0
Dec 17 19:48:51.503: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 19:48:51.506: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 17 19:48:51.546: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 17 19:48:51.594: INFO: The status of Pod fluentd-gcp-v3.2.0-9nwks is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 17 19:48:51.594: INFO: The status of Pod fluentd-gcp-v3.2.0-dqnzd is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 17 19:48:51.594: INFO: The status of Pod fluentd-gcp-v3.2.0-txdr6 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 17 19:48:51.594: INFO: The status of Pod fluentd-gcp-v3.2.0-v2dvx is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Dec 17 19:48:51.594: INFO: 24 / 28 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 17 19:48:51.594: INFO: expected 9 pod replicas in namespace 'kube-system', 9 are Running and Ready.
Dec 17 19:48:51.594: INFO: POD                       NODE                             PHASE    GRACE  CONDITIONS
Dec 17 19:48:51.594: INFO: fluentd-gcp-v3.2.0-9nwks  bootstrap-e2e-master             Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC  }]
Dec 17 19:48:51.594: INFO: fluentd-gcp-v3.2.0-dqnzd  bootstrap-e2e-minion-group-tnzf  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC  }]
Dec 17 19:48:51.594: INFO: fluentd-gcp-v3.2.0-txdr6  bootstrap-e2e-minion-group-6xhw  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC  }]
Dec 17 19:48:51.594: INFO: fluentd-gcp-v3.2.0-v2dvx  bootstrap-e2e-minion-group-wjp3  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC ContainersNotReady containers with unready status: [fluentd-gcp prometheus-to-sd-exporter]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:48:50 +0000 UTC  }]
Dec 17 19:48:51.594: INFO: 
Dec 17 19:48:53.619: INFO: 28 / 28 pods in namespace 'kube-system' are running and ready (2 seconds elapsed)
Dec 17 19:48:53.619: INFO: expected 9 pod replicas in namespace 'kube-system', 9 are Running and Ready.
Dec 17 19:48:53.619: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 17 19:48:53.627: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'fluentd-gcp-v3.2.0' (0 seconds elapsed)
Dec 17 19:48:53.627: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'metadata-proxy-v0.1' (0 seconds elapsed)
Dec 17 19:48:53.627: INFO: e2e test version: v1.13.1
Dec 17 19:48:53.629: INFO: kube-apiserver version: v1.13.1
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:48:53.630: INFO: >>> kubeConfig: /workspace/.kube/config
E1217 19:48:53.690855    7194 memcache.go:135] couldn't get resource list for metrics.k8s.io/v1beta1: the server is currently unable to handle the request
STEP: Building a namespace api object, basename gc
Dec 17 19:48:53.731: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 17 19:49:33.807: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 7
	[quantile=0.99] = 7
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 49
	[quantile=0.9] = 115
	[quantile=0.99] = 115
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 4
	[quantile=0.99] = 4
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 164654
	[quantile=0.9] = 164654
	[quantile=0.99] = 164654
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 23
	[quantile=0.99] = 7777
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 12
	[quantile=0.9] = 31
	[quantile=0.99] = 73
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For namespace_queue_latency_sum:
	[] = 0
For namespace_queue_latency_count:
	[] = 0
For namespace_retries:
	[] = 0
For namespace_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For namespace_work_duration_sum:
	[] = 0
For namespace_work_duration_count:
	[] = 0
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:49:33.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-s985k" for this suite.
Dec 17 19:49:39.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:49:39.890: INFO: namespace: e2e-tests-gc-s985k, resource: bindings, ignored listing per whitelist
Dec 17 19:49:40.026: INFO: namespace e2e-tests-gc-s985k deletion completed in 6.21325877s

• [SLOW TEST:46.396 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:49:40.026: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 19:49:40.226: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e43acd98-0234-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-q6dxr" to be "success or failure"
Dec 17 19:49:40.235: INFO: Pod "downwardapi-volume-e43acd98-0234-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.373226ms
Dec 17 19:49:42.239: INFO: Pod "downwardapi-volume-e43acd98-0234-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013221648s
Dec 17 19:49:44.243: INFO: Pod "downwardapi-volume-e43acd98-0234-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016977719s
STEP: Saw pod success
Dec 17 19:49:44.243: INFO: Pod "downwardapi-volume-e43acd98-0234-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:49:44.246: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-e43acd98-0234-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 19:49:44.286: INFO: Waiting for pod downwardapi-volume-e43acd98-0234-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:49:44.290: INFO: Pod downwardapi-volume-e43acd98-0234-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:49:44.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q6dxr" for this suite.
Dec 17 19:49:50.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:49:50.421: INFO: namespace: e2e-tests-projected-q6dxr, resource: bindings, ignored listing per whitelist
Dec 17 19:49:50.469: INFO: namespace e2e-tests-projected-q6dxr deletion completed in 6.17486244s

• [SLOW TEST:10.443 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:49:50.469: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 19:49:50.580: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea66d100-0234-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-rzhw6" to be "success or failure"
Dec 17 19:49:50.591: INFO: Pod "downwardapi-volume-ea66d100-0234-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.65469ms
Dec 17 19:49:52.594: INFO: Pod "downwardapi-volume-ea66d100-0234-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014056209s
Dec 17 19:49:54.599: INFO: Pod "downwardapi-volume-ea66d100-0234-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018756263s
STEP: Saw pod success
Dec 17 19:49:54.599: INFO: Pod "downwardapi-volume-ea66d100-0234-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:49:54.602: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-ea66d100-0234-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 19:49:54.629: INFO: Waiting for pod downwardapi-volume-ea66d100-0234-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:49:54.635: INFO: Pod downwardapi-volume-ea66d100-0234-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:49:54.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rzhw6" for this suite.
Dec 17 19:50:00.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:50:00.687: INFO: namespace: e2e-tests-downward-api-rzhw6, resource: bindings, ignored listing per whitelist
Dec 17 19:50:00.773: INFO: namespace e2e-tests-downward-api-rzhw6 deletion completed in 6.135268827s

• [SLOW TEST:10.304 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:50:00.773: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec 17 19:50:04.918: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-f08b9c0f-0234-11e9-9892-0a580a3c54b9", GenerateName:"", Namespace:"e2e-tests-pods-24xb5", SelfLink:"/api/v1/namespaces/e2e-tests-pods-24xb5/pods/pod-submit-remove-f08b9c0f-0234-11e9-9892-0a580a3c54b9", UID:"f08bbdce-0234-11e9-b8bf-42010a800002", ResourceVersion:"1160", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63680673000, loc:(*time.Location)(0x7b3aba0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"874707520"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-mk8tq", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00218e100), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mk8tq", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002129988), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"bootstrap-e2e-minion-group-wjp3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0020b1980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0021299c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0021299e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0021299e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0021299ec)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680673000, loc:(*time.Location)(0x7b3aba0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680673003, loc:(*time.Location)(0x7b3aba0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680673003, loc:(*time.Location)(0x7b3aba0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680673000, loc:(*time.Location)(0x7b3aba0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.0.4", PodIP:"10.64.2.9", StartTime:(*v1.Time)(0xc000f10040), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000f10060), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df", ContainerID:"docker://8fbfac7e5a9a44046d1cbf3e72b36533cf80c4bbdcb6085fe9f8dff68f67d226"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 17 19:50:09.937: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:50:09.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-24xb5" for this suite.
Dec 17 19:50:15.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:50:16.109: INFO: namespace: e2e-tests-pods-24xb5, resource: bindings, ignored listing per whitelist
Dec 17 19:50:16.140: INFO: namespace e2e-tests-pods-24xb5 deletion completed in 6.191275529s

• [SLOW TEST:15.367 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:50:16.140: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 17 19:50:16.259: INFO: Waiting up to 5m0s for pod "pod-f9b5a02a-0234-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-fc88b" to be "success or failure"
Dec 17 19:50:16.270: INFO: Pod "pod-f9b5a02a-0234-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.142295ms
Dec 17 19:50:18.276: INFO: Pod "pod-f9b5a02a-0234-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01704274s
Dec 17 19:50:20.279: INFO: Pod "pod-f9b5a02a-0234-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020317248s
STEP: Saw pod success
Dec 17 19:50:20.279: INFO: Pod "pod-f9b5a02a-0234-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:50:20.282: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-f9b5a02a-0234-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 19:50:20.310: INFO: Waiting for pod pod-f9b5a02a-0234-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:50:20.314: INFO: Pod pod-f9b5a02a-0234-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:50:20.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fc88b" for this suite.
Dec 17 19:50:26.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:50:26.391: INFO: namespace: e2e-tests-emptydir-fc88b, resource: bindings, ignored listing per whitelist
Dec 17 19:50:26.454: INFO: namespace e2e-tests-emptydir-fc88b deletion completed in 6.137833368s

• [SLOW TEST:10.314 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:50:26.454: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 19:50:26.567: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffd9cf87-0234-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-xmccv" to be "success or failure"
Dec 17 19:50:26.573: INFO: Pod "downwardapi-volume-ffd9cf87-0234-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335689ms
Dec 17 19:50:28.577: INFO: Pod "downwardapi-volume-ffd9cf87-0234-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010701786s
Dec 17 19:50:30.582: INFO: Pod "downwardapi-volume-ffd9cf87-0234-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015119531s
STEP: Saw pod success
Dec 17 19:50:30.582: INFO: Pod "downwardapi-volume-ffd9cf87-0234-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:50:30.585: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-ffd9cf87-0234-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 19:50:30.611: INFO: Waiting for pod downwardapi-volume-ffd9cf87-0234-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:50:30.617: INFO: Pod downwardapi-volume-ffd9cf87-0234-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:50:30.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xmccv" for this suite.
Dec 17 19:50:36.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:50:36.687: INFO: namespace: e2e-tests-downward-api-xmccv, resource: bindings, ignored listing per whitelist
Dec 17 19:50:36.827: INFO: namespace e2e-tests-downward-api-xmccv deletion completed in 6.20688785s

• [SLOW TEST:10.373 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:50:36.827: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:50:39.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-drjwf" for this suite.
Dec 17 19:50:45.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:50:45.216: INFO: namespace: e2e-tests-emptydir-wrapper-drjwf, resource: bindings, ignored listing per whitelist
Dec 17 19:50:45.254: INFO: namespace e2e-tests-emptydir-wrapper-drjwf deletion completed in 6.135741802s

• [SLOW TEST:8.427 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:50:45.254: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0b149d8c-0235-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 19:50:45.410: INFO: Waiting up to 5m0s for pod "pod-configmaps-0b15426e-0235-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-dcngc" to be "success or failure"
Dec 17 19:50:45.424: INFO: Pod "pod-configmaps-0b15426e-0235-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019114ms
Dec 17 19:50:47.428: INFO: Pod "pod-configmaps-0b15426e-0235-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017888085s
Dec 17 19:50:49.431: INFO: Pod "pod-configmaps-0b15426e-0235-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021491178s
STEP: Saw pod success
Dec 17 19:50:49.431: INFO: Pod "pod-configmaps-0b15426e-0235-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:50:49.434: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-0b15426e-0235-11e9-9892-0a580a3c54b9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 19:50:49.459: INFO: Waiting for pod pod-configmaps-0b15426e-0235-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:50:49.468: INFO: Pod pod-configmaps-0b15426e-0235-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:50:49.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dcngc" for this suite.
Dec 17 19:50:55.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:50:55.543: INFO: namespace: e2e-tests-configmap-dcngc, resource: bindings, ignored listing per whitelist
Dec 17 19:50:55.602: INFO: namespace e2e-tests-configmap-dcngc deletion completed in 6.131797301s

• [SLOW TEST:10.349 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:50:55.603: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec 17 19:50:56.232: INFO: created pod pod-service-account-defaultsa
Dec 17 19:50:56.232: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 17 19:50:56.249: INFO: created pod pod-service-account-mountsa
Dec 17 19:50:56.249: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 17 19:50:56.261: INFO: created pod pod-service-account-nomountsa
Dec 17 19:50:56.261: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 17 19:50:56.288: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 17 19:50:56.288: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 17 19:50:56.326: INFO: created pod pod-service-account-mountsa-mountspec
Dec 17 19:50:56.326: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 17 19:50:56.361: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 17 19:50:56.361: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 17 19:50:56.384: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 17 19:50:56.384: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 17 19:50:56.416: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 17 19:50:56.416: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 17 19:50:56.442: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 17 19:50:56.442: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:50:56.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bctgt" for this suite.
Dec 17 19:51:02.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:51:02.724: INFO: namespace: e2e-tests-svcaccounts-bctgt, resource: bindings, ignored listing per whitelist
Dec 17 19:51:02.773: INFO: namespace e2e-tests-svcaccounts-bctgt deletion completed in 6.317573827s

• [SLOW TEST:7.170 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:51:02.773: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-1587b17a-0235-11e9-9892-0a580a3c54b9
STEP: Creating secret with name secret-projected-all-test-volume-1587b15e-0235-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 17 19:51:02.946: INFO: Waiting up to 5m0s for pod "projected-volume-1587b12d-0235-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-ww2v6" to be "success or failure"
Dec 17 19:51:02.955: INFO: Pod "projected-volume-1587b12d-0235-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.599473ms
Dec 17 19:51:04.958: INFO: Pod "projected-volume-1587b12d-0235-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012052307s
Dec 17 19:51:06.962: INFO: Pod "projected-volume-1587b12d-0235-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015779658s
STEP: Saw pod success
Dec 17 19:51:06.962: INFO: Pod "projected-volume-1587b12d-0235-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:51:06.965: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod projected-volume-1587b12d-0235-11e9-9892-0a580a3c54b9 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 17 19:51:06.989: INFO: Waiting for pod projected-volume-1587b12d-0235-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:51:06.993: INFO: Pod projected-volume-1587b12d-0235-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:51:06.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ww2v6" for this suite.
Dec 17 19:51:13.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:51:13.174: INFO: namespace: e2e-tests-projected-ww2v6, resource: bindings, ignored listing per whitelist
Dec 17 19:51:13.194: INFO: namespace e2e-tests-projected-ww2v6 deletion completed in 6.198138366s

• [SLOW TEST:10.421 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:51:13.194: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-9tsk
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 19:51:13.312: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9tsk" in namespace "e2e-tests-subpath-lzfpd" to be "success or failure"
Dec 17 19:51:13.317: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Pending", Reason="", readiness=false. Elapsed: 5.176612ms
Dec 17 19:51:15.321: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009234915s
Dec 17 19:51:17.326: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 4.014052534s
Dec 17 19:51:19.330: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 6.017988455s
Dec 17 19:51:21.334: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 8.021937083s
Dec 17 19:51:23.338: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 10.02607481s
Dec 17 19:51:25.342: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 12.030410325s
Dec 17 19:51:27.347: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 14.034633259s
Dec 17 19:51:29.351: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 16.039510402s
Dec 17 19:51:31.355: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 18.043460905s
Dec 17 19:51:33.362: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 20.049751001s
Dec 17 19:51:35.365: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Running", Reason="", readiness=false. Elapsed: 22.053559222s
Dec 17 19:51:37.369: INFO: Pod "pod-subpath-test-secret-9tsk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057391577s
STEP: Saw pod success
Dec 17 19:51:37.369: INFO: Pod "pod-subpath-test-secret-9tsk" satisfied condition "success or failure"
Dec 17 19:51:37.373: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-subpath-test-secret-9tsk container test-container-subpath-secret-9tsk: <nil>
STEP: delete the pod
Dec 17 19:51:37.401: INFO: Waiting for pod pod-subpath-test-secret-9tsk to disappear
Dec 17 19:51:37.405: INFO: Pod pod-subpath-test-secret-9tsk no longer exists
STEP: Deleting pod pod-subpath-test-secret-9tsk
Dec 17 19:51:37.405: INFO: Deleting pod "pod-subpath-test-secret-9tsk" in namespace "e2e-tests-subpath-lzfpd"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:51:37.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lzfpd" for this suite.
Dec 17 19:51:43.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:51:43.480: INFO: namespace: e2e-tests-subpath-lzfpd, resource: bindings, ignored listing per whitelist
Dec 17 19:51:43.612: INFO: namespace e2e-tests-subpath-lzfpd deletion completed in 6.201543428s

• [SLOW TEST:30.418 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:51:43.612: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-7h879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7h879 to expose endpoints map[]
Dec 17 19:51:43.725: INFO: Get endpoints failed (5.613495ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 17 19:51:44.729: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7h879 exposes endpoints map[] (1.009848422s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-7h879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7h879 to expose endpoints map[pod1:[80]]
Dec 17 19:51:47.778: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7h879 exposes endpoints map[pod1:[80]] (3.037283691s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-7h879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7h879 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 17 19:51:50.840: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7h879 exposes endpoints map[pod2:[80] pod1:[80]] (3.054037806s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-7h879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7h879 to expose endpoints map[pod2:[80]]
Dec 17 19:51:50.863: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7h879 exposes endpoints map[pod2:[80]] (14.642386ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-7h879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-7h879 to expose endpoints map[]
Dec 17 19:51:50.878: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-7h879 exposes endpoints map[] (9.783717ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:51:50.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7h879" for this suite.
Dec 17 19:52:12.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:52:13.822: INFO: namespace: e2e-tests-services-7h879, resource: bindings, ignored listing per whitelist
Dec 17 19:52:16.688: INFO: namespace e2e-tests-services-7h879 deletion completed in 25.781833891s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:33.076 seconds]
[sig-network] Services
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:52:16.689: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 19:52:17.669: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42136025-0235-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-jntjb" to be "success or failure"
Dec 17 19:52:17.677: INFO: Pod "downwardapi-volume-42136025-0235-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.53794ms
Dec 17 19:52:19.681: INFO: Pod "downwardapi-volume-42136025-0235-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012134276s
STEP: Saw pod success
Dec 17 19:52:19.681: INFO: Pod "downwardapi-volume-42136025-0235-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:52:19.684: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-42136025-0235-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 19:52:19.714: INFO: Waiting for pod downwardapi-volume-42136025-0235-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:52:19.717: INFO: Pod downwardapi-volume-42136025-0235-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:52:19.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jntjb" for this suite.
Dec 17 19:52:25.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:52:25.817: INFO: namespace: e2e-tests-projected-jntjb, resource: bindings, ignored listing per whitelist
Dec 17 19:52:25.878: INFO: namespace e2e-tests-projected-jntjb deletion completed in 6.157405452s

• [SLOW TEST:9.189 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:52:25.878: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 19:52:26.028: INFO: Number of nodes with available pods: 0
Dec 17 19:52:26.028: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 19:52:27.041: INFO: Number of nodes with available pods: 0
Dec 17 19:52:27.041: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 19:52:28.044: INFO: Number of nodes with available pods: 0
Dec 17 19:52:28.044: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 19:52:29.036: INFO: Number of nodes with available pods: 1
Dec 17 19:52:29.036: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 19:52:30.041: INFO: Number of nodes with available pods: 4
Dec 17 19:52:30.041: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 17 19:52:30.103: INFO: Number of nodes with available pods: 3
Dec 17 19:52:30.103: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 19:52:31.111: INFO: Number of nodes with available pods: 3
Dec 17 19:52:31.111: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 19:52:32.116: INFO: Number of nodes with available pods: 4
Dec 17 19:52:32.116: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-bxl8h, will wait for the garbage collector to delete the pods
Dec 17 19:52:32.235: INFO: Deleting DaemonSet.extensions daemon-set took: 47.864339ms
Dec 17 19:52:32.436: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.53401ms
Dec 17 19:53:09.441: INFO: Number of nodes with available pods: 0
Dec 17 19:53:09.441: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 19:53:09.446: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bxl8h/daemonsets","resourceVersion":"1845"},"items":null}

Dec 17 19:53:09.449: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bxl8h/pods","resourceVersion":"1845"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:53:09.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bxl8h" for this suite.
Dec 17 19:53:15.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:53:15.533: INFO: namespace: e2e-tests-daemonsets-bxl8h, resource: bindings, ignored listing per whitelist
Dec 17 19:53:15.602: INFO: namespace e2e-tests-daemonsets-bxl8h deletion completed in 6.138175044s

• [SLOW TEST:49.724 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:53:15.603: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 17 19:53:15.697: INFO: PodSpec: initContainers in spec.initContainers
Dec 17 19:53:57.420: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-64ab2fcf-0235-11e9-9892-0a580a3c54b9", GenerateName:"", Namespace:"e2e-tests-init-container-vmx67", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-vmx67/pods/pod-init-64ab2fcf-0235-11e9-9892-0a580a3c54b9", UID:"64a9755b-0235-11e9-b8bf-42010a800002", ResourceVersion:"1960", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63680673195, loc:(*time.Location)(0x7b3aba0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"697356435", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-rxgqd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0020cbc80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rxgqd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rxgqd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rxgqd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0022a2df8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"bootstrap-e2e-minion-group-wjp3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001d12600), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0022a2e70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0022a2e90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0022a2e98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0022a2e9c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680673195, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680673195, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680673195, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680673195, loc:(*time.Location)(0x7b3aba0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.0.4", PodIP:"10.64.2.25", StartTime:(*v1.Time)(0xc001498960), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0014989a0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00185c460)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:915f390a8912e16d4beb8689720a17348f3f6d1a7b659697df850ab625ea29d5", ContainerID:"docker://31ab9c0726a2341da2776db9619e3c3510929bf97fec0d20ab1f51250ea32c67"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0014989c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001498980), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:53:57.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vmx67" for this suite.
Dec 17 19:54:19.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:54:19.487: INFO: namespace: e2e-tests-init-container-vmx67, resource: bindings, ignored listing per whitelist
Dec 17 19:54:19.580: INFO: namespace e2e-tests-init-container-vmx67 deletion completed in 22.140634656s

• [SLOW TEST:63.977 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:54:19.580: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 17 19:54:19.673: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:54:24.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-26ndh" for this suite.
Dec 17 19:54:30.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:54:30.688: INFO: namespace: e2e-tests-init-container-26ndh, resource: bindings, ignored listing per whitelist
Dec 17 19:54:30.755: INFO: namespace e2e-tests-init-container-26ndh deletion completed in 6.115698056s

• [SLOW TEST:11.176 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:54:30.756: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 19:54:30.860: INFO: Waiting up to 5m0s for pod "downwardapi-volume-917677e4-0235-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-jstdk" to be "success or failure"
Dec 17 19:54:30.867: INFO: Pod "downwardapi-volume-917677e4-0235-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.305793ms
Dec 17 19:54:32.871: INFO: Pod "downwardapi-volume-917677e4-0235-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010936868s
STEP: Saw pod success
Dec 17 19:54:32.871: INFO: Pod "downwardapi-volume-917677e4-0235-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:54:32.874: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-917677e4-0235-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 19:54:32.896: INFO: Waiting for pod downwardapi-volume-917677e4-0235-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:54:32.904: INFO: Pod downwardapi-volume-917677e4-0235-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:54:32.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jstdk" for this suite.
Dec 17 19:54:38.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:54:38.988: INFO: namespace: e2e-tests-projected-jstdk, resource: bindings, ignored listing per whitelist
Dec 17 19:54:39.093: INFO: namespace e2e-tests-projected-jstdk deletion completed in 6.186144381s

• [SLOW TEST:8.338 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:54:39.093: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:54:45.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-thd9m" for this suite.
Dec 17 19:54:51.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:54:51.589: INFO: namespace: e2e-tests-namespaces-thd9m, resource: bindings, ignored listing per whitelist
Dec 17 19:54:51.594: INFO: namespace e2e-tests-namespaces-thd9m deletion completed in 6.219228002s
STEP: Destroying namespace "e2e-tests-nsdeletetest-ctbrq" for this suite.
Dec 17 19:54:51.597: INFO: Namespace e2e-tests-nsdeletetest-ctbrq was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-cbd88" for this suite.
Dec 17 19:54:57.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:54:57.654: INFO: namespace: e2e-tests-nsdeletetest-cbd88, resource: bindings, ignored listing per whitelist
Dec 17 19:54:57.724: INFO: namespace e2e-tests-nsdeletetest-cbd88 deletion completed in 6.126988296s

• [SLOW TEST:18.631 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:54:57.724: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 19:54:57.837: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a18a8faf-0235-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-wgjfd" to be "success or failure"
Dec 17 19:54:57.850: INFO: Pod "downwardapi-volume-a18a8faf-0235-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.155211ms
Dec 17 19:54:59.854: INFO: Pod "downwardapi-volume-a18a8faf-0235-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016963511s
Dec 17 19:55:01.864: INFO: Pod "downwardapi-volume-a18a8faf-0235-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027358213s
STEP: Saw pod success
Dec 17 19:55:01.864: INFO: Pod "downwardapi-volume-a18a8faf-0235-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:55:01.870: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-a18a8faf-0235-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 19:55:01.920: INFO: Waiting for pod downwardapi-volume-a18a8faf-0235-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:55:01.929: INFO: Pod downwardapi-volume-a18a8faf-0235-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:55:01.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wgjfd" for this suite.
Dec 17 19:55:07.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:55:08.130: INFO: namespace: e2e-tests-projected-wgjfd, resource: bindings, ignored listing per whitelist
Dec 17 19:55:08.167: INFO: namespace e2e-tests-projected-wgjfd deletion completed in 6.229790328s

• [SLOW TEST:10.443 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:55:08.167: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec 17 19:55:08.269: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 17 19:55:08.269: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:55:08.700: INFO: stderr: ""
Dec 17 19:55:08.700: INFO: stdout: "service/redis-slave created\n"
Dec 17 19:55:08.700: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 17 19:55:08.700: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:55:08.988: INFO: stderr: ""
Dec 17 19:55:08.988: INFO: stdout: "service/redis-master created\n"
Dec 17 19:55:08.988: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 17 19:55:08.988: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:55:09.280: INFO: stderr: ""
Dec 17 19:55:09.280: INFO: stdout: "service/frontend created\n"
Dec 17 19:55:09.280: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 17 19:55:09.280: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:55:09.618: INFO: stderr: ""
Dec 17 19:55:09.618: INFO: stdout: "deployment.extensions/frontend created\n"
Dec 17 19:55:09.618: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 17 19:55:09.618: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:55:09.943: INFO: stderr: ""
Dec 17 19:55:09.943: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec 17 19:55:09.944: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 17 19:55:09.944: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:55:10.243: INFO: stderr: ""
Dec 17 19:55:10.243: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec 17 19:55:10.243: INFO: Waiting for all frontend pods to be Running.
Dec 17 19:55:30.295: INFO: Waiting for frontend to serve content.
Dec 17 19:55:30.322: INFO: Trying to add a new entry to the guestbook.
Dec 17 19:55:30.340: INFO: Verifying that added entry can be retrieved.
Dec 17 19:55:30.356: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:55:35.369: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:55:40.385: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:55:45.397: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:55:50.421: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:55:55.440: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:56:00.456: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:56:05.471: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:56:10.488: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:56:15.501: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec 17 19:56:20.516: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Dec 17 19:56:25.534: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:56:25.642: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 19:56:25.642: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 19:56:25.643: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:56:25.745: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 19:56:25.746: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 19:56:25.746: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:56:25.848: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 19:56:25.848: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 19:56:25.848: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:56:25.946: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 19:56:25.946: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 19:56:25.947: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:56:26.043: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 19:56:26.043: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 19:56:26.044: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bhdh5'
Dec 17 19:56:26.146: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 19:56:26.147: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:56:26.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bhdh5" for this suite.
Dec 17 19:57:04.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:57:04.334: INFO: namespace: e2e-tests-kubectl-bhdh5, resource: bindings, ignored listing per whitelist
Dec 17 19:57:04.373: INFO: namespace e2e-tests-kubectl-bhdh5 deletion completed in 38.215582283s

• [SLOW TEST:116.206 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:57:04.373: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zb78q
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 19:57:04.471: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 19:57:26.599: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.64.1.14:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zb78q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 19:57:26.599: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 19:57:26.703: INFO: Found all expected endpoints: [netserver-0]
Dec 17 19:57:26.706: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.64.2.32:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zb78q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 19:57:26.706: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 19:57:26.791: INFO: Found all expected endpoints: [netserver-1]
Dec 17 19:57:26.795: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.64.3.15:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zb78q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 19:57:26.795: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 19:57:26.917: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:57:26.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zb78q" for this suite.
Dec 17 19:57:38.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:57:38.971: INFO: namespace: e2e-tests-pod-network-test-zb78q, resource: bindings, ignored listing per whitelist
Dec 17 19:57:39.050: INFO: namespace e2e-tests-pod-network-test-zb78q deletion completed in 12.128683333s

• [SLOW TEST:34.677 seconds]
[sig-network] Networking
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:57:39.051: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 19:57:39.222: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 17 19:57:44.226: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 19:57:44.226: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 17 19:57:44.253: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-qtv69,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qtv69/deployments/test-cleanup-deployment,UID:04b70d1e-0236-11e9-b8bf-42010a800002,ResourceVersion:2694,Generation:1,CreationTimestamp:2018-12-17 19:57:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec 17 19:57:44.262: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 17 19:57:44.262: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 17 19:57:44.262: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-qtv69,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qtv69/replicasets/test-cleanup-controller,UID:01b8a881-0236-11e9-b8bf-42010a800002,ResourceVersion:2695,Generation:1,CreationTimestamp:2018-12-17 19:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 04b70d1e-0236-11e9-b8bf-42010a800002 0xc0025958ff 0xc002595910}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 17 19:57:44.270: INFO: Pod "test-cleanup-controller-258gb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-258gb,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-qtv69,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qtv69/pods/test-cleanup-controller-258gb,UID:01baeb7c-0236-11e9-b8bf-42010a800002,ResourceVersion:2684,Generation:0,CreationTimestamp:2018-12-17 19:57:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 01b8a881-0236-11e9-b8bf-42010a800002 0xc002595ebf 0xc002595ed0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5kkdj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5kkdj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5kkdj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002595f30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002595f50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:57:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:57:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:57:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 19:57:39 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.64.2.34,StartTime:2018-12-17 19:57:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 19:57:40 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://ddee8a2bb9ab8c48001a8affae5397616031424a9f08dd45b64b566557353160}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:57:44.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qtv69" for this suite.
Dec 17 19:57:50.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:57:50.395: INFO: namespace: e2e-tests-deployment-qtv69, resource: bindings, ignored listing per whitelist
Dec 17 19:57:50.439: INFO: namespace e2e-tests-deployment-qtv69 deletion completed in 6.164852063s

• [SLOW TEST:11.388 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:57:50.439: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 17 19:57:50.547: INFO: Waiting up to 5m0s for pod "pod-087c77b0-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-2w5s6" to be "success or failure"
Dec 17 19:57:50.553: INFO: Pod "pod-087c77b0-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.92123ms
Dec 17 19:57:52.557: INFO: Pod "pod-087c77b0-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009863941s
STEP: Saw pod success
Dec 17 19:57:52.557: INFO: Pod "pod-087c77b0-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:57:52.560: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-087c77b0-0236-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 19:57:52.602: INFO: Waiting for pod pod-087c77b0-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:57:52.604: INFO: Pod pod-087c77b0-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:57:52.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2w5s6" for this suite.
Dec 17 19:57:58.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:57:58.703: INFO: namespace: e2e-tests-emptydir-2w5s6, resource: bindings, ignored listing per whitelist
Dec 17 19:57:58.737: INFO: namespace e2e-tests-emptydir-2w5s6 deletion completed in 6.130018786s

• [SLOW TEST:8.298 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:57:58.737: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 17 19:58:04.891: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:04.894: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 19:58:06.894: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:06.898: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 19:58:08.894: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:08.898: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 19:58:10.894: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:10.900: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 19:58:12.894: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:12.898: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 19:58:14.894: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:14.899: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 19:58:16.894: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:16.898: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 19:58:18.894: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:18.897: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 19:58:20.894: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 19:58:20.898: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:58:20.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-wlvtx" for this suite.
Dec 17 19:58:42.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:58:43.093: INFO: namespace: e2e-tests-container-lifecycle-hook-wlvtx, resource: bindings, ignored listing per whitelist
Dec 17 19:58:43.184: INFO: namespace e2e-tests-container-lifecycle-hook-wlvtx deletion completed in 22.271788887s

• [SLOW TEST:44.447 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:58:43.184: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 19:58:43.292: INFO: Waiting up to 5m0s for pod "downwardapi-volume-27ec8212-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-fsjjx" to be "success or failure"
Dec 17 19:58:43.303: INFO: Pod "downwardapi-volume-27ec8212-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.80157ms
Dec 17 19:58:45.306: INFO: Pod "downwardapi-volume-27ec8212-0236-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.01443382s
Dec 17 19:58:47.311: INFO: Pod "downwardapi-volume-27ec8212-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018985932s
STEP: Saw pod success
Dec 17 19:58:47.311: INFO: Pod "downwardapi-volume-27ec8212-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:58:47.315: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-27ec8212-0236-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 19:58:47.341: INFO: Waiting for pod downwardapi-volume-27ec8212-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:58:47.346: INFO: Pod downwardapi-volume-27ec8212-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:58:47.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fsjjx" for this suite.
Dec 17 19:58:53.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:58:53.428: INFO: namespace: e2e-tests-projected-fsjjx, resource: bindings, ignored listing per whitelist
Dec 17 19:58:53.589: INFO: namespace e2e-tests-projected-fsjjx deletion completed in 6.23987773s

• [SLOW TEST:10.405 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:58:53.589: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 17 19:58:53.697: INFO: Waiting up to 5m0s for pod "pod-2e1fec5d-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-txh4d" to be "success or failure"
Dec 17 19:58:53.708: INFO: Pod "pod-2e1fec5d-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.568749ms
Dec 17 19:58:55.713: INFO: Pod "pod-2e1fec5d-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016168586s
Dec 17 19:58:57.717: INFO: Pod "pod-2e1fec5d-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020565581s
STEP: Saw pod success
Dec 17 19:58:57.717: INFO: Pod "pod-2e1fec5d-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 19:58:57.722: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-2e1fec5d-0236-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 19:58:57.756: INFO: Waiting for pod pod-2e1fec5d-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 19:58:57.761: INFO: Pod pod-2e1fec5d-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:58:57.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-txh4d" for this suite.
Dec 17 19:59:03.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:59:03.818: INFO: namespace: e2e-tests-emptydir-txh4d, resource: bindings, ignored listing per whitelist
Dec 17 19:59:03.934: INFO: namespace e2e-tests-emptydir-txh4d deletion completed in 6.168505571s

• [SLOW TEST:10.345 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:59:03.934: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-28vlm A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-28vlm;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-28vlm A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-28vlm;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-28vlm.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-28vlm.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-28vlm.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-28vlm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-28vlm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-28vlm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-28vlm.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-28vlm.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-28vlm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 10.114.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.114.10_udp@PTR;check="$$(dig +tcp +noall +answer +search 10.114.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.114.10_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-28vlm A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-28vlm;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-28vlm A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-28vlm;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-28vlm.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-28vlm.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-28vlm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-28vlm.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-28vlm.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-28vlm.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-28vlm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 10.114.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.114.10_udp@PTR;check="$$(dig +tcp +noall +answer +search 10.114.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.114.10_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 19:59:14.119: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.123: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.167: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.171: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.175: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.177: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.180: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.183: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.187: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.190: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:14.213: INFO: Lookups using e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9 failed for: [wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-28vlm jessie_tcp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc]

Dec 17 19:59:19.223: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.227: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.275: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.279: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.284: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.288: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.292: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.296: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.300: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.304: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:19.325: INFO: Lookups using e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9 failed for: [wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-28vlm jessie_tcp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc]

Dec 17 19:59:24.223: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.227: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.272: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.275: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.278: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.281: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.284: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.288: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.291: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.294: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:24.317: INFO: Lookups using e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9 failed for: [wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-28vlm jessie_tcp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc]

Dec 17 19:59:29.222: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.226: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.306: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.310: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.315: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.319: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.323: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.326: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.332: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.336: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:29.361: INFO: Lookups using e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9 failed for: [wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-28vlm jessie_tcp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc]

Dec 17 19:59:34.222: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.226: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.279: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.283: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.287: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.291: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.296: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.299: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.303: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.307: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc from pod e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9: the server could not find the requested resource (get pods dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9)
Dec 17 19:59:34.331: INFO: Lookups using e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9 failed for: [wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-28vlm jessie_tcp@dns-test-service.e2e-tests-dns-28vlm jessie_udp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@dns-test-service.e2e-tests-dns-28vlm.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-28vlm.svc]

Dec 17 19:59:39.339: INFO: DNS probes using e2e-tests-dns-28vlm/dns-test-34522ec3-0236-11e9-9892-0a580a3c54b9 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:59:39.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-28vlm" for this suite.
Dec 17 19:59:45.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 19:59:45.604: INFO: namespace: e2e-tests-dns-28vlm, resource: bindings, ignored listing per whitelist
Dec 17 19:59:45.664: INFO: namespace e2e-tests-dns-28vlm deletion completed in 6.212865655s

• [SLOW TEST:41.730 seconds]
[sig-network] DNS
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 19:59:45.665: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 19:59:45.756: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config version --client'
Dec 17 19:59:45.818: INFO: stderr: ""
Dec 17 19:59:45.819: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.1\", GitCommit:\"eec55b9ba98609a46fee712359c7b5b365bdd920\", GitTreeState:\"clean\", BuildDate:\"2018-12-13T10:39:04Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec 17 19:59:45.821: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-h99n7'
Dec 17 19:59:48.575: INFO: stderr: ""
Dec 17 19:59:48.575: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 17 19:59:48.575: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-h99n7'
Dec 17 19:59:48.939: INFO: stderr: ""
Dec 17 19:59:48.939: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 19:59:49.944: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 19:59:49.945: INFO: Found 0 / 1
Dec 17 19:59:50.943: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 19:59:50.943: INFO: Found 1 / 1
Dec 17 19:59:50.943: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 17 19:59:50.947: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 19:59:50.947: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 19:59:50.947: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config describe pod redis-master-mswx6 --namespace=e2e-tests-kubectl-h99n7'
Dec 17 19:59:51.053: INFO: stderr: ""
Dec 17 19:59:51.053: INFO: stdout: "Name:               redis-master-mswx6\nNamespace:          e2e-tests-kubectl-h99n7\nPriority:           0\nPriorityClassName:  <none>\nNode:               bootstrap-e2e-minion-group-wjp3/10.128.0.4\nStart Time:         Mon, 17 Dec 2018 19:59:48 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.64.2.40\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://dba669ec40c7a16cd4bf89a0aea31464154724bde8b55b553d53e24edb1c537a\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 17 Dec 2018 19:59:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-tvgtl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-tvgtl:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-tvgtl\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                      Message\n  ----    ------     ----  ----                                      -------\n  Normal  Scheduled  3s    default-scheduler                         Successfully assigned e2e-tests-kubectl-h99n7/redis-master-mswx6 to bootstrap-e2e-minion-group-wjp3\n  Normal  Pulled     2s    kubelet, bootstrap-e2e-minion-group-wjp3  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, bootstrap-e2e-minion-group-wjp3  Created container\n  Normal  Started    2s    kubelet, bootstrap-e2e-minion-group-wjp3  Started container\n"
Dec 17 19:59:51.053: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config describe rc redis-master --namespace=e2e-tests-kubectl-h99n7'
Dec 17 19:59:51.173: INFO: stderr: ""
Dec 17 19:59:51.173: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-h99n7\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-mswx6\n"
Dec 17 19:59:51.174: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config describe service redis-master --namespace=e2e-tests-kubectl-h99n7'
Dec 17 19:59:51.281: INFO: stderr: ""
Dec 17 19:59:51.281: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-h99n7\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.70.99\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.64.2.40:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 17 19:59:51.285: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config describe node bootstrap-e2e-master'
Dec 17 19:59:51.401: INFO: stderr: ""
Dec 17 19:59:51.401: INFO: stdout: "Name:               bootstrap-e2e-master\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/fluentd-ds-ready=true\n                    beta.kubernetes.io/instance-type=n1-standard-1\n                    beta.kubernetes.io/metadata-proxy-ready=true\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-central1\n                    failure-domain.beta.kubernetes.io/zone=us-central1-f\n                    kubernetes.io/hostname=bootstrap-e2e-master\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 17 Dec 2018 19:47:40 +0000\nTaints:             node.kubernetes.io/unschedulable:NoSchedule\nUnschedulable:      true\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 17 Dec 2018 19:47:59 +0000   Mon, 17 Dec 2018 19:47:59 +0000   RouteCreated                 RouteController created a route\n  MemoryPressure       False   Mon, 17 Dec 2018 19:59:43 +0000   Mon, 17 Dec 2018 19:47:40 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 17 Dec 2018 19:59:43 +0000   Mon, 17 Dec 2018 19:47:40 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 17 Dec 2018 19:59:43 +0000   Mon, 17 Dec 2018 19:47:40 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 17 Dec 2018 19:59:43 +0000   Mon, 17 Dec 2018 19:47:41 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.128.0.2\n  ExternalIP:   35.225.177.164\n  InternalDNS:  bootstrap-e2e-master.c.k8s-boskos-gce-project-14.internal\n  Hostname:     bootstrap-e2e-master.c.k8s-boskos-gce-project-14.internal\nCapacity:\n attachable-volumes-gce-pd:  32\n cpu:                        1\n ephemeral-storage:          16293736Ki\n hugepages-2Mi:              0\n memory:                     3794344Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  32\n cpu:                        1\n ephemeral-storage:          15016307073\n hugepages-2Mi:              0\n memory:                     3538344Ki\n pods:                       110\nSystem Info:\n Machine ID:                 e9181820be176d684d4adf62cddec4a4\n System UUID:                E9181820-BE17-6D68-4D4A-DF62CDDEC4A4\n Boot ID:                    5cf74ff9-c912-49c5-a6c5-07565492929c\n Kernel Version:             4.4.111+\n OS Image:                   Container-Optimized OS from Google\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.13.1\n Kube-Proxy Version:         v1.13.1\nPodCIDR:                     10.64.0.0/24\nProviderID:                  gce://k8s-boskos-gce-project-14/us-central1-f/bootstrap-e2e-master\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                            CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                            ------------  ----------  ---------------  -------------  ---\n  kube-system                etcd-empty-dir-cleanup-bootstrap-e2e-master     0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                etcd-server-bootstrap-e2e-master                200m (20%)    0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                etcd-server-events-bootstrap-e2e-master         100m (10%)    0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                fluentd-gcp-v3.2.0-9nwks                        100m (10%)    1 (100%)    200Mi (5%)       500Mi (14%)    11m\n  kube-system                kube-addon-manager-bootstrap-e2e-master         5m (0%)       0 (0%)      50Mi (1%)        0 (0%)         11m\n  kube-system                kube-apiserver-bootstrap-e2e-master             250m (25%)    0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-controller-manager-bootstrap-e2e-master    200m (20%)    0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                kube-scheduler-bootstrap-e2e-master             75m (7%)      0 (0%)      0 (0%)           0 (0%)         11m\n  kube-system                l7-lb-controller-v1.2.3-bootstrap-e2e-master    10m (1%)      0 (0%)      50Mi (1%)        0 (0%)         11m\n  kube-system                metadata-proxy-v0.1-crftc                       32m (3%)      32m (3%)    45Mi (1%)        45Mi (1%)      12m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        972m (97%)  1032m (103%)\n  memory                     345Mi (9%)  545Mi (15%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-gce-pd  0           0\nEvents:                      <none>\n"
Dec 17 19:59:51.401: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config describe namespace e2e-tests-kubectl-h99n7'
Dec 17 19:59:51.507: INFO: stderr: ""
Dec 17 19:59:51.507: INFO: stdout: "Name:         e2e-tests-kubectl-h99n7\nLabels:       e2e-framework=kubectl\n              e2e-run=c44682f8-0234-11e9-9892-0a580a3c54b9\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 19:59:51.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h99n7" for this suite.
Dec 17 20:00:13.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:00:13.609: INFO: namespace: e2e-tests-kubectl-h99n7, resource: bindings, ignored listing per whitelist
Dec 17 20:00:13.674: INFO: namespace e2e-tests-kubectl-h99n7 deletion completed in 22.162893591s

• [SLOW TEST:28.009 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:00:13.674: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 17 20:00:16.337: INFO: Successfully updated pod "annotationupdate5ddf0385-0236-11e9-9892-0a580a3c54b9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:00:18.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cg7l2" for this suite.
Dec 17 20:00:40.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:00:40.429: INFO: namespace: e2e-tests-projected-cg7l2, resource: bindings, ignored listing per whitelist
Dec 17 20:00:40.489: INFO: namespace e2e-tests-projected-cg7l2 deletion completed in 22.128674905s

• [SLOW TEST:26.815 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:00:40.489: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:00:40.606: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6dd95776-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-f5rzg" to be "success or failure"
Dec 17 20:00:40.618: INFO: Pod "downwardapi-volume-6dd95776-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.232504ms
Dec 17 20:00:42.623: INFO: Pod "downwardapi-volume-6dd95776-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016673068s
STEP: Saw pod success
Dec 17 20:00:42.623: INFO: Pod "downwardapi-volume-6dd95776-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:00:42.626: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-6dd95776-0236-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:00:42.670: INFO: Waiting for pod downwardapi-volume-6dd95776-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:00:42.689: INFO: Pod downwardapi-volume-6dd95776-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:00:42.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f5rzg" for this suite.
Dec 17 20:00:48.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:00:48.849: INFO: namespace: e2e-tests-projected-f5rzg, resource: bindings, ignored listing per whitelist
Dec 17 20:00:48.880: INFO: namespace e2e-tests-projected-f5rzg deletion completed in 6.178135863s

• [SLOW TEST:8.391 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:00:48.881: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 17 20:00:48.981: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 20:00:48.990: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 20:00:48.995: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-6xhw before test
Dec 17 20:00:49.019: INFO: l7-default-backend-fd59995cd-bkm5h from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container default-http-backend ready: true, restart count 0
Dec 17 20:00:49.019: INFO: event-exporter-v0.2.3-fdd9d7c84-jh2xj from kube-system started at 2018-12-17 19:47:48 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container event-exporter ready: true, restart count 0
Dec 17 20:00:49.019: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:00:49.019: INFO: fluentd-gcp-scaler-68b55c6dc5-xnl65 from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
Dec 17 20:00:49.019: INFO: metadata-proxy-v0.1-gd7pr from kube-system started at 2018-12-17 19:47:48 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 20:00:49.019: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:00:49.019: INFO: kubernetes-dashboard-6bbb6846cd-8dqzv from kube-system started at 2018-12-17 19:48:38 +0000 UTC (1 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 17 20:00:49.019: INFO: coredns-fff89c9b9-dc8sd from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container coredns ready: true, restart count 0
Dec 17 20:00:49.019: INFO: kube-dns-autoscaler-545db58f6f-rjwmd from kube-system started at 2018-12-17 19:48:38 +0000 UTC (1 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container autoscaler ready: true, restart count 0
Dec 17 20:00:49.019: INFO: metrics-server-v0.3.1-58d65f8d6-pp669 from kube-system started at 2018-12-17 19:48:38 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container metrics-server ready: true, restart count 0
Dec 17 20:00:49.019: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec 17 20:00:49.019: INFO: heapster-v1.6.0-beta.1-5f77ccd9dd-zwfwt from kube-system started at 2018-12-17 19:48:38 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container heapster ready: true, restart count 0
Dec 17 20:00:49.019: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 17 20:00:49.019: INFO: kube-proxy-bootstrap-e2e-minion-group-6xhw from kube-system started at <nil> (0 container statuses recorded)
Dec 17 20:00:49.019: INFO: fluentd-gcp-v3.2.0-txdr6 from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.019: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 20:00:49.019: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:00:49.019: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-tnzf before test
Dec 17 20:00:49.041: INFO: kube-proxy-bootstrap-e2e-minion-group-tnzf from kube-system started at <nil> (0 container statuses recorded)
Dec 17 20:00:49.041: INFO: metadata-proxy-v0.1-lnjmm from kube-system started at 2018-12-17 19:47:49 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.041: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 20:00:49.041: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:00:49.041: INFO: coredns-fff89c9b9-s8fmm from kube-system started at 2018-12-17 19:48:45 +0000 UTC (1 container statuses recorded)
Dec 17 20:00:49.041: INFO: 	Container coredns ready: true, restart count 0
Dec 17 20:00:49.041: INFO: fluentd-gcp-v3.2.0-dqnzd from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.041: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 20:00:49.041: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:00:49.041: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-wjp3 before test
Dec 17 20:00:49.049: INFO: kube-proxy-bootstrap-e2e-minion-group-wjp3 from kube-system started at <nil> (0 container statuses recorded)
Dec 17 20:00:49.049: INFO: fluentd-gcp-v3.2.0-v2dvx from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.049: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 20:00:49.049: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:00:49.049: INFO: metadata-proxy-v0.1-727vr from kube-system started at 2018-12-17 19:47:49 +0000 UTC (2 container statuses recorded)
Dec 17 20:00:49.049: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 20:00:49.049: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node bootstrap-e2e-minion-group-6xhw
STEP: verifying the node has the label node bootstrap-e2e-minion-group-tnzf
STEP: verifying the node has the label node bootstrap-e2e-minion-group-wjp3
Dec 17 20:00:49.106: INFO: Pod coredns-fff89c9b9-dc8sd requesting resource cpu=100m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod coredns-fff89c9b9-s8fmm requesting resource cpu=100m on Node bootstrap-e2e-minion-group-tnzf
Dec 17 20:00:49.106: INFO: Pod event-exporter-v0.2.3-fdd9d7c84-jh2xj requesting resource cpu=0m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod fluentd-gcp-scaler-68b55c6dc5-xnl65 requesting resource cpu=0m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod fluentd-gcp-v3.2.0-dqnzd requesting resource cpu=100m on Node bootstrap-e2e-minion-group-tnzf
Dec 17 20:00:49.106: INFO: Pod fluentd-gcp-v3.2.0-txdr6 requesting resource cpu=100m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod fluentd-gcp-v3.2.0-v2dvx requesting resource cpu=100m on Node bootstrap-e2e-minion-group-wjp3
Dec 17 20:00:49.106: INFO: Pod heapster-v1.6.0-beta.1-5f77ccd9dd-zwfwt requesting resource cpu=138m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod kube-dns-autoscaler-545db58f6f-rjwmd requesting resource cpu=20m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod kube-proxy-bootstrap-e2e-minion-group-6xhw requesting resource cpu=100m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod kube-proxy-bootstrap-e2e-minion-group-tnzf requesting resource cpu=100m on Node bootstrap-e2e-minion-group-tnzf
Dec 17 20:00:49.106: INFO: Pod kube-proxy-bootstrap-e2e-minion-group-wjp3 requesting resource cpu=100m on Node bootstrap-e2e-minion-group-wjp3
Dec 17 20:00:49.106: INFO: Pod kubernetes-dashboard-6bbb6846cd-8dqzv requesting resource cpu=50m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod l7-default-backend-fd59995cd-bkm5h requesting resource cpu=10m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod metadata-proxy-v0.1-727vr requesting resource cpu=32m on Node bootstrap-e2e-minion-group-wjp3
Dec 17 20:00:49.106: INFO: Pod metadata-proxy-v0.1-gd7pr requesting resource cpu=32m on Node bootstrap-e2e-minion-group-6xhw
Dec 17 20:00:49.106: INFO: Pod metadata-proxy-v0.1-lnjmm requesting resource cpu=32m on Node bootstrap-e2e-minion-group-tnzf
Dec 17 20:00:49.106: INFO: Pod metrics-server-v0.3.1-58d65f8d6-pp669 requesting resource cpu=53m on Node bootstrap-e2e-minion-group-6xhw
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ebfb63-0236-11e9-9892-0a580a3c54b9.157137354579f585], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7xktw/filler-pod-72ebfb63-0236-11e9-9892-0a580a3c54b9 to bootstrap-e2e-minion-group-6xhw]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ebfb63-0236-11e9-9892-0a580a3c54b9.15713735b19ac981], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ebfb63-0236-11e9-9892-0a580a3c54b9.15713735b5551d61], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ebfb63-0236-11e9-9892-0a580a3c54b9.15713735bc9846b0], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ed8550-0236-11e9-9892-0a580a3c54b9.15713735483661a5], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7xktw/filler-pod-72ed8550-0236-11e9-9892-0a580a3c54b9 to bootstrap-e2e-minion-group-tnzf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ed8550-0236-11e9-9892-0a580a3c54b9.157137359b0efe2a], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ed8550-0236-11e9-9892-0a580a3c54b9.157137359dc36c26], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72ed8550-0236-11e9-9892-0a580a3c54b9.15713735a76adb35], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72f1b742-0236-11e9-9892-0a580a3c54b9.1571373549357bf8], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7xktw/filler-pod-72f1b742-0236-11e9-9892-0a580a3c54b9 to bootstrap-e2e-minion-group-wjp3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72f1b742-0236-11e9-9892-0a580a3c54b9.15713735b0a3a33b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72f1b742-0236-11e9-9892-0a580a3c54b9.15713735b4297428], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-72f1b742-0236-11e9-9892-0a580a3c54b9.15713735b99a37c6], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15713736380a729f], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) were unschedulable, 3 Insufficient cpu.]
STEP: removing the label node off the node bootstrap-e2e-minion-group-wjp3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node bootstrap-e2e-minion-group-6xhw
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node bootstrap-e2e-minion-group-tnzf
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:00:54.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-7xktw" for this suite.
Dec 17 20:01:00.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:01:00.458: INFO: namespace: e2e-tests-sched-pred-7xktw, resource: bindings, ignored listing per whitelist
Dec 17 20:01:00.473: INFO: namespace e2e-tests-sched-pred-7xktw deletion completed in 6.172475675s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.592 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:01:00.473: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-79c2add6-0236-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:01:00.596: INFO: Waiting up to 5m0s for pod "pod-configmaps-79c37c7d-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-nrwfd" to be "success or failure"
Dec 17 20:01:00.599: INFO: Pod "pod-configmaps-79c37c7d-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.467812ms
Dec 17 20:01:02.603: INFO: Pod "pod-configmaps-79c37c7d-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007273243s
Dec 17 20:01:04.607: INFO: Pod "pod-configmaps-79c37c7d-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011170484s
STEP: Saw pod success
Dec 17 20:01:04.607: INFO: Pod "pod-configmaps-79c37c7d-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:01:04.615: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-79c37c7d-0236-11e9-9892-0a580a3c54b9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:01:04.647: INFO: Waiting for pod pod-configmaps-79c37c7d-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:01:04.651: INFO: Pod pod-configmaps-79c37c7d-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:01:04.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nrwfd" for this suite.
Dec 17 20:01:10.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:01:10.762: INFO: namespace: e2e-tests-configmap-nrwfd, resource: bindings, ignored listing per whitelist
Dec 17 20:01:10.805: INFO: namespace e2e-tests-configmap-nrwfd deletion completed in 6.149975265s

• [SLOW TEST:10.332 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:01:10.805: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7feaeaae-0236-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:01:10.926: INFO: Waiting up to 5m0s for pod "pod-secrets-7febbe90-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-f742q" to be "success or failure"
Dec 17 20:01:10.938: INFO: Pod "pod-secrets-7febbe90-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.218274ms
Dec 17 20:01:12.941: INFO: Pod "pod-secrets-7febbe90-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015038188s
STEP: Saw pod success
Dec 17 20:01:12.942: INFO: Pod "pod-secrets-7febbe90-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:01:12.945: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-secrets-7febbe90-0236-11e9-9892-0a580a3c54b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:01:12.977: INFO: Waiting for pod pod-secrets-7febbe90-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:01:12.981: INFO: Pod pod-secrets-7febbe90-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:01:12.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-f742q" for this suite.
Dec 17 20:01:19.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:01:19.128: INFO: namespace: e2e-tests-secrets-f742q, resource: bindings, ignored listing per whitelist
Dec 17 20:01:19.209: INFO: namespace e2e-tests-secrets-f742q deletion completed in 6.223492736s

• [SLOW TEST:8.403 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:01:19.209: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:01:19.322: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84ec841b-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-j4ln9" to be "success or failure"
Dec 17 20:01:19.340: INFO: Pod "downwardapi-volume-84ec841b-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.358256ms
Dec 17 20:01:21.344: INFO: Pod "downwardapi-volume-84ec841b-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021263225s
Dec 17 20:01:23.347: INFO: Pod "downwardapi-volume-84ec841b-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02490246s
STEP: Saw pod success
Dec 17 20:01:23.347: INFO: Pod "downwardapi-volume-84ec841b-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:01:23.351: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-84ec841b-0236-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:01:23.375: INFO: Waiting for pod downwardapi-volume-84ec841b-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:01:23.381: INFO: Pod downwardapi-volume-84ec841b-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:01:23.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j4ln9" for this suite.
Dec 17 20:01:29.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:01:29.518: INFO: namespace: e2e-tests-downward-api-j4ln9, resource: bindings, ignored listing per whitelist
Dec 17 20:01:29.588: INFO: namespace e2e-tests-downward-api-j4ln9 deletion completed in 6.203526911s

• [SLOW TEST:10.379 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:01:29.588: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Dec 17 20:01:30.774: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 493
	[quantile=0.99] = 512
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 23048
	[quantile=0.9] = 36420
	[quantile=0.99] = 37964
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 5
	[quantile=0.99] = 24
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 13
	[quantile=0.9] = 28
	[quantile=0.99] = 62
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 14
	[quantile=0.9] = 25
	[quantile=0.99] = 30
For namespace_queue_latency_sum:
	[] = 1315
For namespace_queue_latency_count:
	[] = 79
For namespace_retries:
	[] = 81
For namespace_work_duration:
	[quantile=0.5] = 275657
	[quantile=0.9] = 452613
	[quantile=0.99] = 486541
For namespace_work_duration_sum:
	[] = 16990954
For namespace_work_duration_count:
	[] = 79
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:01:30.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-p98nm" for this suite.
Dec 17 20:01:36.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:01:36.902: INFO: namespace: e2e-tests-gc-p98nm, resource: bindings, ignored listing per whitelist
Dec 17 20:01:36.918: INFO: namespace e2e-tests-gc-p98nm deletion completed in 6.140009437s

• [SLOW TEST:7.330 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:01:36.918: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 17 20:01:37.083: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 17 20:01:42.087: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:01:42.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-24pd5" for this suite.
Dec 17 20:01:48.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:01:48.258: INFO: namespace: e2e-tests-replication-controller-24pd5, resource: bindings, ignored listing per whitelist
Dec 17 20:01:48.442: INFO: namespace e2e-tests-replication-controller-24pd5 deletion completed in 6.312614894s

• [SLOW TEST:11.523 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:01:48.442: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 17 20:01:48.548: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:48.885: INFO: stderr: ""
Dec 17 20:01:48.885: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 20:01:48.885: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:48.990: INFO: stderr: ""
Dec 17 20:01:48.990: INFO: stdout: "update-demo-nautilus-2v68b update-demo-nautilus-ggcz4 "
Dec 17 20:01:48.990: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-2v68b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:49.087: INFO: stderr: ""
Dec 17 20:01:49.087: INFO: stdout: ""
Dec 17 20:01:49.087: INFO: update-demo-nautilus-2v68b is created but not running
Dec 17 20:01:54.088: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:54.186: INFO: stderr: ""
Dec 17 20:01:54.186: INFO: stdout: "update-demo-nautilus-2v68b update-demo-nautilus-ggcz4 "
Dec 17 20:01:54.186: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-2v68b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:54.287: INFO: stderr: ""
Dec 17 20:01:54.287: INFO: stdout: "true"
Dec 17 20:01:54.288: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-2v68b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:54.402: INFO: stderr: ""
Dec 17 20:01:54.402: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 20:01:54.402: INFO: validating pod update-demo-nautilus-2v68b
Dec 17 20:01:54.411: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 20:01:54.411: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 20:01:54.411: INFO: update-demo-nautilus-2v68b is verified up and running
Dec 17 20:01:54.411: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-ggcz4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:54.504: INFO: stderr: ""
Dec 17 20:01:54.504: INFO: stdout: "true"
Dec 17 20:01:54.504: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-ggcz4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:54.592: INFO: stderr: ""
Dec 17 20:01:54.592: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 20:01:54.592: INFO: validating pod update-demo-nautilus-ggcz4
Dec 17 20:01:54.598: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 20:01:54.598: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 20:01:54.598: INFO: update-demo-nautilus-ggcz4 is verified up and running
STEP: using delete to clean up resources
Dec 17 20:01:54.599: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:54.699: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 20:01:54.699: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 17 20:01:54.699: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-qj8tm'
Dec 17 20:01:54.794: INFO: stderr: "No resources found.\n"
Dec 17 20:01:54.794: INFO: stdout: ""
Dec 17 20:01:54.794: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -l name=update-demo --namespace=e2e-tests-kubectl-qj8tm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 20:01:54.887: INFO: stderr: ""
Dec 17 20:01:54.888: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:01:54.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qj8tm" for this suite.
Dec 17 20:02:00.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:02:01.046: INFO: namespace: e2e-tests-kubectl-qj8tm, resource: bindings, ignored listing per whitelist
Dec 17 20:02:01.175: INFO: namespace e2e-tests-kubectl-qj8tm deletion completed in 6.28311064s

• [SLOW TEST:12.733 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:02:01.175: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 17 20:02:01.363: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-k57j6,SelfLink:/api/v1/namespaces/e2e-tests-watch-k57j6/configmaps/e2e-watch-test-label-changed,UID:9df58e42-0236-11e9-b8bf-42010a800002,ResourceVersion:3588,Generation:0,CreationTimestamp:2018-12-17 20:02:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 20:02:01.363: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-k57j6,SelfLink:/api/v1/namespaces/e2e-tests-watch-k57j6/configmaps/e2e-watch-test-label-changed,UID:9df58e42-0236-11e9-b8bf-42010a800002,ResourceVersion:3589,Generation:0,CreationTimestamp:2018-12-17 20:02:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 17 20:02:01.363: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-k57j6,SelfLink:/api/v1/namespaces/e2e-tests-watch-k57j6/configmaps/e2e-watch-test-label-changed,UID:9df58e42-0236-11e9-b8bf-42010a800002,ResourceVersion:3590,Generation:0,CreationTimestamp:2018-12-17 20:02:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 17 20:02:11.395: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-k57j6,SelfLink:/api/v1/namespaces/e2e-tests-watch-k57j6/configmaps/e2e-watch-test-label-changed,UID:9df58e42-0236-11e9-b8bf-42010a800002,ResourceVersion:3614,Generation:0,CreationTimestamp:2018-12-17 20:02:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 20:02:11.395: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-k57j6,SelfLink:/api/v1/namespaces/e2e-tests-watch-k57j6/configmaps/e2e-watch-test-label-changed,UID:9df58e42-0236-11e9-b8bf-42010a800002,ResourceVersion:3615,Generation:0,CreationTimestamp:2018-12-17 20:02:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 17 20:02:11.395: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-k57j6,SelfLink:/api/v1/namespaces/e2e-tests-watch-k57j6/configmaps/e2e-watch-test-label-changed,UID:9df58e42-0236-11e9-b8bf-42010a800002,ResourceVersion:3616,Generation:0,CreationTimestamp:2018-12-17 20:02:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:02:11.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-k57j6" for this suite.
Dec 17 20:02:19.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:02:19.497: INFO: namespace: e2e-tests-watch-k57j6, resource: bindings, ignored listing per whitelist
Dec 17 20:02:19.615: INFO: namespace e2e-tests-watch-k57j6 deletion completed in 8.215817922s

• [SLOW TEST:18.439 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:02:19.615: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a8edbb73-0236-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:02:19.730: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a8ee9469-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-d8jb2" to be "success or failure"
Dec 17 20:02:19.739: INFO: Pod "pod-projected-secrets-a8ee9469-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.210103ms
Dec 17 20:02:21.742: INFO: Pod "pod-projected-secrets-a8ee9469-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011552934s
STEP: Saw pod success
Dec 17 20:02:21.742: INFO: Pod "pod-projected-secrets-a8ee9469-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:02:21.745: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-secrets-a8ee9469-0236-11e9-9892-0a580a3c54b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:02:21.772: INFO: Waiting for pod pod-projected-secrets-a8ee9469-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:02:21.776: INFO: Pod pod-projected-secrets-a8ee9469-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:02:21.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d8jb2" for this suite.
Dec 17 20:02:27.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:02:27.930: INFO: namespace: e2e-tests-projected-d8jb2, resource: bindings, ignored listing per whitelist
Dec 17 20:02:27.937: INFO: namespace e2e-tests-projected-d8jb2 deletion completed in 6.156329232s

• [SLOW TEST:8.322 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:02:27.937: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:02:28.051: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 17 20:02:28.063: INFO: Number of nodes with available pods: 0
Dec 17 20:02:28.063: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 17 20:02:28.095: INFO: Number of nodes with available pods: 0
Dec 17 20:02:28.095: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:29.100: INFO: Number of nodes with available pods: 0
Dec 17 20:02:29.100: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:30.099: INFO: Number of nodes with available pods: 1
Dec 17 20:02:30.099: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 17 20:02:30.123: INFO: Number of nodes with available pods: 1
Dec 17 20:02:30.123: INFO: Number of running nodes: 0, number of available pods: 1
Dec 17 20:02:31.127: INFO: Number of nodes with available pods: 0
Dec 17 20:02:31.127: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 17 20:02:31.169: INFO: Number of nodes with available pods: 0
Dec 17 20:02:31.169: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:32.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:32.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:33.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:33.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:34.174: INFO: Number of nodes with available pods: 0
Dec 17 20:02:34.174: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:35.175: INFO: Number of nodes with available pods: 0
Dec 17 20:02:35.175: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:36.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:36.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:37.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:37.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:38.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:38.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:39.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:39.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:40.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:40.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:41.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:41.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:42.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:42.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:43.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:43.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:44.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:44.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:45.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:45.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:46.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:46.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:47.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:47.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:48.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:48.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:49.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:49.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:50.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:50.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:51.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:51.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:52.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:52.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:53.174: INFO: Number of nodes with available pods: 0
Dec 17 20:02:53.175: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:54.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:54.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:55.174: INFO: Number of nodes with available pods: 0
Dec 17 20:02:55.174: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:56.172: INFO: Number of nodes with available pods: 0
Dec 17 20:02:56.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:57.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:57.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:58.173: INFO: Number of nodes with available pods: 0
Dec 17 20:02:58.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:02:59.174: INFO: Number of nodes with available pods: 0
Dec 17 20:02:59.174: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:00.172: INFO: Number of nodes with available pods: 0
Dec 17 20:03:00.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:01.173: INFO: Number of nodes with available pods: 0
Dec 17 20:03:01.174: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:02.173: INFO: Number of nodes with available pods: 0
Dec 17 20:03:02.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:03.173: INFO: Number of nodes with available pods: 0
Dec 17 20:03:03.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:04.172: INFO: Number of nodes with available pods: 0
Dec 17 20:03:04.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:05.173: INFO: Number of nodes with available pods: 0
Dec 17 20:03:05.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:06.172: INFO: Number of nodes with available pods: 0
Dec 17 20:03:06.172: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:07.174: INFO: Number of nodes with available pods: 0
Dec 17 20:03:07.174: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:08.204: INFO: Number of nodes with available pods: 0
Dec 17 20:03:08.204: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:09.173: INFO: Number of nodes with available pods: 0
Dec 17 20:03:09.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:10.173: INFO: Number of nodes with available pods: 0
Dec 17 20:03:10.173: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:03:11.173: INFO: Number of nodes with available pods: 1
Dec 17 20:03:11.173: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-cdzkd, will wait for the garbage collector to delete the pods
Dec 17 20:03:11.247: INFO: Deleting DaemonSet.extensions daemon-set took: 15.268613ms
Dec 17 20:03:11.348: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.478613ms
Dec 17 20:03:48.253: INFO: Number of nodes with available pods: 0
Dec 17 20:03:48.253: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 20:03:48.256: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cdzkd/daemonsets","resourceVersion":"3876"},"items":null}

Dec 17 20:03:48.258: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cdzkd/pods","resourceVersion":"3876"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:03:48.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cdzkd" for this suite.
Dec 17 20:03:54.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:03:54.381: INFO: namespace: e2e-tests-daemonsets-cdzkd, resource: bindings, ignored listing per whitelist
Dec 17 20:03:54.468: INFO: namespace e2e-tests-daemonsets-cdzkd deletion completed in 6.182605489s

• [SLOW TEST:86.531 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:03:54.468: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e177210b-0236-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:03:54.583: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e1781310-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-rfxpc" to be "success or failure"
Dec 17 20:03:54.589: INFO: Pod "pod-projected-configmaps-e1781310-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.828529ms
Dec 17 20:03:56.594: INFO: Pod "pod-projected-configmaps-e1781310-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010521763s
STEP: Saw pod success
Dec 17 20:03:56.594: INFO: Pod "pod-projected-configmaps-e1781310-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:03:56.598: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-configmaps-e1781310-0236-11e9-9892-0a580a3c54b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:03:56.621: INFO: Waiting for pod pod-projected-configmaps-e1781310-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:03:56.627: INFO: Pod pod-projected-configmaps-e1781310-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:03:56.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rfxpc" for this suite.
Dec 17 20:04:02.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:04:02.680: INFO: namespace: e2e-tests-projected-rfxpc, resource: bindings, ignored listing per whitelist
Dec 17 20:04:02.783: INFO: namespace e2e-tests-projected-rfxpc deletion completed in 6.153096738s

• [SLOW TEST:8.315 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:04:02.784: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec 17 20:04:02.903: INFO: Waiting up to 5m0s for pod "client-containers-e66d617c-0236-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-containers-8h754" to be "success or failure"
Dec 17 20:04:02.914: INFO: Pod "client-containers-e66d617c-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.060527ms
Dec 17 20:04:04.918: INFO: Pod "client-containers-e66d617c-0236-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014058596s
Dec 17 20:04:06.921: INFO: Pod "client-containers-e66d617c-0236-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017489725s
STEP: Saw pod success
Dec 17 20:04:06.921: INFO: Pod "client-containers-e66d617c-0236-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:04:06.924: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod client-containers-e66d617c-0236-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:04:06.953: INFO: Waiting for pod client-containers-e66d617c-0236-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:04:06.956: INFO: Pod client-containers-e66d617c-0236-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:04:06.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8h754" for this suite.
Dec 17 20:04:12.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:04:13.120: INFO: namespace: e2e-tests-containers-8h754, resource: bindings, ignored listing per whitelist
Dec 17 20:04:13.193: INFO: namespace e2e-tests-containers-8h754 deletion completed in 6.232474153s

• [SLOW TEST:10.409 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:04:13.193: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vv6g2
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec 17 20:04:13.334: INFO: Found 0 stateful pods, waiting for 3
Dec 17 20:04:23.339: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:04:23.339: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:04:23.339: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 17 20:04:23.372: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 17 20:04:33.418: INFO: Updating stateful set ss2
Dec 17 20:04:33.428: INFO: Waiting for Pod e2e-tests-statefulset-vv6g2/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec 17 20:04:43.495: INFO: Found 1 stateful pods, waiting for 3
Dec 17 20:04:53.501: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:04:53.501: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:04:53.501: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 17 20:04:53.530: INFO: Updating stateful set ss2
Dec 17 20:04:53.542: INFO: Waiting for Pod e2e-tests-statefulset-vv6g2/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 17 20:05:03.577: INFO: Updating stateful set ss2
Dec 17 20:05:03.589: INFO: Waiting for StatefulSet e2e-tests-statefulset-vv6g2/ss2 to complete update
Dec 17 20:05:03.589: INFO: Waiting for Pod e2e-tests-statefulset-vv6g2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 17 20:05:13.599: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vv6g2
Dec 17 20:05:13.602: INFO: Scaling statefulset ss2 to 0
Dec 17 20:05:33.625: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:05:33.629: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:05:33.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vv6g2" for this suite.
Dec 17 20:05:39.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:05:39.858: INFO: namespace: e2e-tests-statefulset-vv6g2, resource: bindings, ignored listing per whitelist
Dec 17 20:05:39.910: INFO: namespace e2e-tests-statefulset-vv6g2 deletion completed in 6.246634488s

• [SLOW TEST:86.717 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:05:39.910: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:05:40.017: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:05:44.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zph5t" for this suite.
Dec 17 20:06:30.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:06:30.176: INFO: namespace: e2e-tests-pods-zph5t, resource: bindings, ignored listing per whitelist
Dec 17 20:06:30.325: INFO: namespace e2e-tests-pods-zph5t deletion completed in 46.197200417s

• [SLOW TEST:50.415 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:06:30.325: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-3e5de4a1-0237-11e9-9892-0a580a3c54b9
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3e5de4a1-0237-11e9-9892-0a580a3c54b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:06:34.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8rzxf" for this suite.
Dec 17 20:06:56.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:06:56.641: INFO: namespace: e2e-tests-configmap-8rzxf, resource: bindings, ignored listing per whitelist
Dec 17 20:06:56.698: INFO: namespace e2e-tests-configmap-8rzxf deletion completed in 22.180112202s

• [SLOW TEST:26.372 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:06:56.698: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 17 20:07:02.880: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 4838
	[quantile=0.9] = 65942
	[quantile=0.99] = 102157
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 32066
	[quantile=0.9] = 164456
	[quantile=0.99] = 197766
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 5
	[quantile=0.99] = 25
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 14
	[quantile=0.9] = 28
	[quantile=0.99] = 68
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 13
	[quantile=0.9] = 27
	[quantile=0.99] = 86
For namespace_queue_latency_sum:
	[] = 2005
For namespace_queue_latency_count:
	[] = 115
For namespace_retries:
	[] = 116
For namespace_work_duration:
	[quantile=0.5] = 278910
	[quantile=0.9] = 452613
	[quantile=0.99] = 657094
For namespace_work_duration_sum:
	[] = 26387640
For namespace_work_duration_count:
	[] = 115
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:07:02.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8hrpj" for this suite.
Dec 17 20:07:08.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:07:08.961: INFO: namespace: e2e-tests-gc-8hrpj, resource: bindings, ignored listing per whitelist
Dec 17 20:07:09.028: INFO: namespace e2e-tests-gc-8hrpj deletion completed in 6.144089179s

• [SLOW TEST:12.331 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:07:09.028: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:07:09.156: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 20:07:09.183: INFO: Number of nodes with available pods: 0
Dec 17 20:07:09.183: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 20:07:10.191: INFO: Number of nodes with available pods: 0
Dec 17 20:07:10.191: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 20:07:11.193: INFO: Number of nodes with available pods: 2
Dec 17 20:07:11.193: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 20:07:12.192: INFO: Number of nodes with available pods: 4
Dec 17 20:07:12.192: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 17 20:07:12.224: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:12.224: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:12.224: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:12.224: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:13.316: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:13.316: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:13.316: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:13.316: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:14.318: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:14.318: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:14.318: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:14.318: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:15.361: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:15.361: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:15.361: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:15.361: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:16.323: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:16.323: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:16.323: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:16.323: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:17.325: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:17.325: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:17.325: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:17.325: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:18.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:18.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:18.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:18.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:19.235: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:19.235: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:19.235: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:19.235: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:20.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:20.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:20.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:20.232: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:21.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:21.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:21.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:21.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:22.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:22.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:22.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:22.232: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:23.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:23.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:23.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:23.232: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:24.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:24.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:24.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:24.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:25.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:25.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:25.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:25.232: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:26.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:26.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:26.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:26.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:27.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:27.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:27.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:27.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:28.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:28.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:28.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:28.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:29.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:29.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:29.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:29.232: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:30.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:30.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:30.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:30.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:31.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:31.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:31.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:31.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:32.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:32.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:32.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:32.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:33.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:33.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:33.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:33.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:34.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:34.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:34.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:34.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:35.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:35.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:35.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:35.232: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:36.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:36.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:36.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:36.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:37.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:37.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:37.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:37.234: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:38.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:38.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:38.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:38.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:39.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:39.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:39.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:39.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:40.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:40.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:40.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:40.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:41.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:41.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:41.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:41.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:42.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:42.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:42.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:42.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:43.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:43.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:43.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:43.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:44.247: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:44.247: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:44.247: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:44.248: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:44.248: INFO: Pod daemon-set-wqcl8 is not available
Dec 17 20:07:45.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:45.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:45.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:45.232: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:45.232: INFO: Pod daemon-set-wqcl8 is not available
Dec 17 20:07:46.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:46.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:46.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:46.233: INFO: Wrong image for pod: daemon-set-wqcl8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:46.233: INFO: Pod daemon-set-wqcl8 is not available
Dec 17 20:07:47.261: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:47.261: INFO: Pod daemon-set-h4xhl is not available
Dec 17 20:07:47.261: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:47.261: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:48.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:48.234: INFO: Pod daemon-set-h4xhl is not available
Dec 17 20:07:48.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:48.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:49.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:49.233: INFO: Pod daemon-set-h4xhl is not available
Dec 17 20:07:49.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:49.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:50.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:50.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:50.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:51.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:51.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:51.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:52.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:52.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:52.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:53.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:53.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:53.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:54.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:54.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:54.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:55.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:55.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:55.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:56.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:56.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:56.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:57.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:57.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:57.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:58.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:58.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:58.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:59.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:59.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:07:59.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:00.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:00.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:00.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:01.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:01.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:01.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:02.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:02.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:02.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:03.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:03.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:03.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:04.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:04.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:04.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:05.245: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:05.245: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:05.245: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:06.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:06.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:06.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:07.235: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:07.235: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:07.235: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:08.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:08.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:08.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:09.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:09.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:09.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:10.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:10.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:10.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:11.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:11.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:11.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:12.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:12.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:12.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:13.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:13.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:13.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:14.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:14.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:14.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:15.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:15.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:15.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:16.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:16.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:16.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:17.235: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:17.235: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:17.235: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:18.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:18.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:18.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:19.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:19.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:19.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:20.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:20.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:20.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:21.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:21.234: INFO: Pod daemon-set-8hr77 is not available
Dec 17 20:08:21.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:21.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:22.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:22.234: INFO: Pod daemon-set-8hr77 is not available
Dec 17 20:08:22.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:22.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:23.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:23.233: INFO: Pod daemon-set-8hr77 is not available
Dec 17 20:08:23.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:23.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:24.232: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:24.232: INFO: Pod daemon-set-8hr77 is not available
Dec 17 20:08:24.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:24.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:25.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:25.233: INFO: Pod daemon-set-8hr77 is not available
Dec 17 20:08:25.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:25.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:26.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:26.233: INFO: Pod daemon-set-8hr77 is not available
Dec 17 20:08:26.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:26.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:27.234: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:27.234: INFO: Pod daemon-set-8hr77 is not available
Dec 17 20:08:27.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:27.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:28.233: INFO: Wrong image for pod: daemon-set-8hr77. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:28.233: INFO: Pod daemon-set-8hr77 is not available
Dec 17 20:08:28.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:28.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:29.240: INFO: Pod daemon-set-dqpm9 is not available
Dec 17 20:08:29.240: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:29.240: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:30.234: INFO: Pod daemon-set-dqpm9 is not available
Dec 17 20:08:30.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:30.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:31.233: INFO: Pod daemon-set-dqpm9 is not available
Dec 17 20:08:31.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:31.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:32.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:32.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:33.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:33.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:34.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:34.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:35.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:35.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:36.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:36.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:37.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:37.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:38.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:38.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:39.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:39.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:40.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:40.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:41.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:41.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:42.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:42.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:43.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:43.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:44.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:44.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:45.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:45.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:46.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:46.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:47.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:47.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:48.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:48.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:49.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:49.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:50.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:50.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:51.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:51.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:52.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:52.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:53.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:53.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:54.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:54.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:55.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:55.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:56.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:56.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:57.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:57.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:58.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:58.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:59.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:08:59.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:00.232: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:00.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:01.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:01.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:02.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:02.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:03.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:03.233: INFO: Pod daemon-set-hbxkq is not available
Dec 17 20:09:03.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:04.234: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:04.234: INFO: Pod daemon-set-hbxkq is not available
Dec 17 20:09:04.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:05.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:05.233: INFO: Pod daemon-set-hbxkq is not available
Dec 17 20:09:05.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:06.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:06.233: INFO: Pod daemon-set-hbxkq is not available
Dec 17 20:09:06.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:07.233: INFO: Wrong image for pod: daemon-set-hbxkq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:07.234: INFO: Pod daemon-set-hbxkq is not available
Dec 17 20:09:07.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:08.245: INFO: Pod daemon-set-krqsp is not available
Dec 17 20:09:08.245: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:09.233: INFO: Pod daemon-set-krqsp is not available
Dec 17 20:09:09.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:10.234: INFO: Pod daemon-set-krqsp is not available
Dec 17 20:09:10.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:11.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:12.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:13.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:14.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:15.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:16.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:17.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:18.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:19.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:20.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:21.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:22.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:23.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:24.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:25.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:26.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:27.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:28.234: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:29.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:30.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:31.235: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:32.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:33.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:34.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:35.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:36.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:37.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:38.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:39.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:40.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:41.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:42.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:42.232: INFO: Pod daemon-set-ntzsw is not available
Dec 17 20:09:43.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:43.233: INFO: Pod daemon-set-ntzsw is not available
Dec 17 20:09:44.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:44.232: INFO: Pod daemon-set-ntzsw is not available
Dec 17 20:09:45.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:45.233: INFO: Pod daemon-set-ntzsw is not available
Dec 17 20:09:46.232: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:46.232: INFO: Pod daemon-set-ntzsw is not available
Dec 17 20:09:47.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:47.233: INFO: Pod daemon-set-ntzsw is not available
Dec 17 20:09:48.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:48.233: INFO: Pod daemon-set-ntzsw is not available
Dec 17 20:09:49.233: INFO: Wrong image for pod: daemon-set-ntzsw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 17 20:09:49.233: INFO: Pod daemon-set-ntzsw is not available
Dec 17 20:09:50.233: INFO: Pod daemon-set-qsnzw is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 17 20:09:50.244: INFO: Number of nodes with available pods: 3
Dec 17 20:09:50.244: INFO: Node bootstrap-e2e-minion-group-tnzf is running more than one daemon pod
Dec 17 20:09:51.252: INFO: Number of nodes with available pods: 3
Dec 17 20:09:51.252: INFO: Node bootstrap-e2e-minion-group-tnzf is running more than one daemon pod
Dec 17 20:09:52.252: INFO: Number of nodes with available pods: 4
Dec 17 20:09:52.252: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-nvkwr, will wait for the garbage collector to delete the pods
Dec 17 20:09:52.330: INFO: Deleting DaemonSet.extensions daemon-set took: 7.86798ms
Dec 17 20:09:52.431: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.464355ms
Dec 17 20:09:59.237: INFO: Number of nodes with available pods: 0
Dec 17 20:09:59.237: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 20:09:59.242: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nvkwr/daemonsets","resourceVersion":"5042"},"items":null}

Dec 17 20:09:59.244: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nvkwr/pods","resourceVersion":"5042"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:09:59.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nvkwr" for this suite.
Dec 17 20:10:05.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:10:05.433: INFO: namespace: e2e-tests-daemonsets-nvkwr, resource: bindings, ignored listing per whitelist
Dec 17 20:10:05.454: INFO: namespace e2e-tests-daemonsets-nvkwr deletion completed in 6.192274598s

• [SLOW TEST:176.426 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:10:05.455: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-78gpx in namespace e2e-tests-proxy-cdrv9
I1217 20:10:05.647063    7194 runners.go:184] Created replication controller with name: proxy-service-78gpx, namespace: e2e-tests-proxy-cdrv9, replica count: 1
I1217 20:10:06.697707    7194 runners.go:184] proxy-service-78gpx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1217 20:10:07.698203    7194 runners.go:184] proxy-service-78gpx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1217 20:10:08.698596    7194 runners.go:184] proxy-service-78gpx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 20:10:09.699068    7194 runners.go:184] proxy-service-78gpx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 20:10:10.699482    7194 runners.go:184] proxy-service-78gpx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 20:10:11.699902    7194 runners.go:184] proxy-service-78gpx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 20:10:12.700248    7194 runners.go:184] proxy-service-78gpx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 20:10:13.700646    7194 runners.go:184] proxy-service-78gpx Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 20:10:13.705: INFO: setup took 8.107523949s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 17 20:10:13.724: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 18.751278ms)
Dec 17 20:10:13.724: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 18.842854ms)
Dec 17 20:10:13.724: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 18.767972ms)
Dec 17 20:10:13.730: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 24.906583ms)
Dec 17 20:10:13.731: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 25.312435ms)
Dec 17 20:10:13.732: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 26.73104ms)
Dec 17 20:10:13.737: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 31.411345ms)
Dec 17 20:10:13.737: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 32.039549ms)
Dec 17 20:10:13.737: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 32.097211ms)
Dec 17 20:10:13.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 36.393907ms)
Dec 17 20:10:13.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 36.98884ms)
Dec 17 20:10:13.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 36.959436ms)
Dec 17 20:10:13.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 36.880104ms)
Dec 17 20:10:13.742: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 36.933931ms)
Dec 17 20:10:13.743: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 38.130081ms)
Dec 17 20:10:13.744: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 38.779354ms)
Dec 17 20:10:13.761: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 16.527631ms)
Dec 17 20:10:13.765: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 20.375246ms)
Dec 17 20:10:13.765: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 20.665927ms)
Dec 17 20:10:13.765: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 21.100907ms)
Dec 17 20:10:13.766: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 21.365333ms)
Dec 17 20:10:13.766: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 21.751872ms)
Dec 17 20:10:13.767: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 22.636791ms)
Dec 17 20:10:13.767: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 22.897636ms)
Dec 17 20:10:13.767: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 22.974835ms)
Dec 17 20:10:13.767: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 22.944913ms)
Dec 17 20:10:13.767: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 23.015403ms)
Dec 17 20:10:13.767: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 23.148969ms)
Dec 17 20:10:13.768: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 23.982048ms)
Dec 17 20:10:13.770: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 25.856864ms)
Dec 17 20:10:13.770: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 25.921555ms)
Dec 17 20:10:13.770: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 25.993133ms)
Dec 17 20:10:13.795: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 24.369868ms)
Dec 17 20:10:13.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 25.650183ms)
Dec 17 20:10:13.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 25.531287ms)
Dec 17 20:10:13.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 25.974298ms)
Dec 17 20:10:13.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 26.261679ms)
Dec 17 20:10:13.799: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 28.299336ms)
Dec 17 20:10:13.800: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 29.417389ms)
Dec 17 20:10:13.800: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 30.000345ms)
Dec 17 20:10:13.800: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 30.193443ms)
Dec 17 20:10:13.801: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 30.301646ms)
Dec 17 20:10:13.801: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 30.074539ms)
Dec 17 20:10:13.801: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 30.156913ms)
Dec 17 20:10:13.802: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 31.586456ms)
Dec 17 20:10:13.803: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 32.444425ms)
Dec 17 20:10:13.804: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 33.685959ms)
Dec 17 20:10:13.808: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 37.395487ms)
Dec 17 20:10:13.830: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 22.420043ms)
Dec 17 20:10:13.831: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 22.6507ms)
Dec 17 20:10:13.835: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 27.268876ms)
Dec 17 20:10:13.835: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 27.572863ms)
Dec 17 20:10:13.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 27.700276ms)
Dec 17 20:10:13.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 27.783204ms)
Dec 17 20:10:13.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 27.60633ms)
Dec 17 20:10:13.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 27.589857ms)
Dec 17 20:10:13.836: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 27.603385ms)
Dec 17 20:10:13.839: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 30.719298ms)
Dec 17 20:10:13.846: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 38.1716ms)
Dec 17 20:10:13.847: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 38.763482ms)
Dec 17 20:10:13.848: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 40.024609ms)
Dec 17 20:10:13.849: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 40.757975ms)
Dec 17 20:10:13.849: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 41.351686ms)
Dec 17 20:10:13.849: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 41.363253ms)
Dec 17 20:10:13.863: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 13.931238ms)
Dec 17 20:10:13.867: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 17.229963ms)
Dec 17 20:10:13.867: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 17.517485ms)
Dec 17 20:10:13.867: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 17.516048ms)
Dec 17 20:10:13.870: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 20.881827ms)
Dec 17 20:10:13.871: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 21.172964ms)
Dec 17 20:10:13.871: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 21.315992ms)
Dec 17 20:10:13.871: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 21.674202ms)
Dec 17 20:10:13.875: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 25.132708ms)
Dec 17 20:10:13.875: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 25.150741ms)
Dec 17 20:10:13.875: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 25.076854ms)
Dec 17 20:10:13.875: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 25.19752ms)
Dec 17 20:10:13.876: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 26.416141ms)
Dec 17 20:10:13.876: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 26.56063ms)
Dec 17 20:10:13.876: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 26.582222ms)
Dec 17 20:10:13.876: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 26.60446ms)
Dec 17 20:10:13.890: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 13.671486ms)
Dec 17 20:10:13.894: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 17.598272ms)
Dec 17 20:10:13.894: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 17.858015ms)
Dec 17 20:10:13.900: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 24.02753ms)
Dec 17 20:10:13.901: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 24.227388ms)
Dec 17 20:10:13.901: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 24.375737ms)
Dec 17 20:10:13.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 25.532938ms)
Dec 17 20:10:13.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 25.486437ms)
Dec 17 20:10:13.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 25.67797ms)
Dec 17 20:10:13.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 25.626916ms)
Dec 17 20:10:13.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 25.510829ms)
Dec 17 20:10:13.902: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 25.854726ms)
Dec 17 20:10:13.905: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 28.257491ms)
Dec 17 20:10:13.905: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 28.548393ms)
Dec 17 20:10:13.905: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 28.711116ms)
Dec 17 20:10:13.905: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 28.774722ms)
Dec 17 20:10:13.923: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 17.490519ms)
Dec 17 20:10:13.923: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 17.787567ms)
Dec 17 20:10:13.923: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 17.919398ms)
Dec 17 20:10:13.923: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 18.190904ms)
Dec 17 20:10:13.924: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 18.273086ms)
Dec 17 20:10:13.925: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 19.809176ms)
Dec 17 20:10:13.929: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 23.594418ms)
Dec 17 20:10:13.930: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 24.71431ms)
Dec 17 20:10:13.930: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 25.081211ms)
Dec 17 20:10:13.931: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 25.364315ms)
Dec 17 20:10:13.933: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 27.529243ms)
Dec 17 20:10:13.933: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 27.777246ms)
Dec 17 20:10:13.933: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 27.858631ms)
Dec 17 20:10:13.933: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 27.963172ms)
Dec 17 20:10:13.933: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 28.020341ms)
Dec 17 20:10:13.936: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 30.305108ms)
Dec 17 20:10:13.965: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 28.873462ms)
Dec 17 20:10:13.965: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 28.890462ms)
Dec 17 20:10:13.965: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 29.060235ms)
Dec 17 20:10:13.965: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 29.482403ms)
Dec 17 20:10:13.966: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 29.944739ms)
Dec 17 20:10:13.966: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 30.000385ms)
Dec 17 20:10:13.966: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 30.453987ms)
Dec 17 20:10:13.966: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 30.593425ms)
Dec 17 20:10:13.966: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 30.522697ms)
Dec 17 20:10:13.966: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 30.779113ms)
Dec 17 20:10:13.966: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 30.569178ms)
Dec 17 20:10:13.966: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 30.602862ms)
Dec 17 20:10:13.968: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 32.372813ms)
Dec 17 20:10:13.969: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 33.498551ms)
Dec 17 20:10:13.969: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 33.586728ms)
Dec 17 20:10:13.969: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 33.624797ms)
Dec 17 20:10:13.990: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 19.91797ms)
Dec 17 20:10:13.991: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 21.527014ms)
Dec 17 20:10:13.991: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 21.436031ms)
Dec 17 20:10:13.991: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 21.708806ms)
Dec 17 20:10:13.991: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.891182ms)
Dec 17 20:10:13.996: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 25.906545ms)
Dec 17 20:10:13.996: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 26.603708ms)
Dec 17 20:10:13.997: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 27.377976ms)
Dec 17 20:10:13.999: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 29.789903ms)
Dec 17 20:10:14.000: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 30.486203ms)
Dec 17 20:10:14.000: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 30.400264ms)
Dec 17 20:10:14.001: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 30.891805ms)
Dec 17 20:10:14.001: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 31.384525ms)
Dec 17 20:10:14.001: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 31.458568ms)
Dec 17 20:10:14.001: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 31.508837ms)
Dec 17 20:10:14.001: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 31.436601ms)
Dec 17 20:10:14.016: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 14.360911ms)
Dec 17 20:10:14.020: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 19.056113ms)
Dec 17 20:10:14.021: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 19.154819ms)
Dec 17 20:10:14.022: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 20.252488ms)
Dec 17 20:10:14.022: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 20.948234ms)
Dec 17 20:10:14.022: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 20.969732ms)
Dec 17 20:10:14.023: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 21.262008ms)
Dec 17 20:10:14.023: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.262491ms)
Dec 17 20:10:14.023: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.369296ms)
Dec 17 20:10:14.023: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 21.361422ms)
Dec 17 20:10:14.024: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 22.643433ms)
Dec 17 20:10:14.024: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 23.16337ms)
Dec 17 20:10:14.025: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 23.17048ms)
Dec 17 20:10:14.026: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 25.064561ms)
Dec 17 20:10:14.027: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 25.319255ms)
Dec 17 20:10:14.027: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 25.754327ms)
Dec 17 20:10:14.038: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 10.39641ms)
Dec 17 20:10:14.042: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 14.427359ms)
Dec 17 20:10:14.044: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 17.131211ms)
Dec 17 20:10:14.045: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 17.283784ms)
Dec 17 20:10:14.045: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 17.223676ms)
Dec 17 20:10:14.046: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 18.340679ms)
Dec 17 20:10:14.049: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 21.221189ms)
Dec 17 20:10:14.049: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 21.431242ms)
Dec 17 20:10:14.049: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 21.672532ms)
Dec 17 20:10:14.049: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.781868ms)
Dec 17 20:10:14.052: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 24.148679ms)
Dec 17 20:10:14.052: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 25.099898ms)
Dec 17 20:10:14.053: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 25.334792ms)
Dec 17 20:10:14.054: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 26.508754ms)
Dec 17 20:10:14.054: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 26.854404ms)
Dec 17 20:10:14.054: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 26.851787ms)
Dec 17 20:10:14.069: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 14.301549ms)
Dec 17 20:10:14.069: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 14.981201ms)
Dec 17 20:10:14.070: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 15.17914ms)
Dec 17 20:10:14.070: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 15.199444ms)
Dec 17 20:10:14.075: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 20.587564ms)
Dec 17 20:10:14.075: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 20.568782ms)
Dec 17 20:10:14.075: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 20.907432ms)
Dec 17 20:10:14.075: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 21.001116ms)
Dec 17 20:10:14.075: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 20.935299ms)
Dec 17 20:10:14.076: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 20.947247ms)
Dec 17 20:10:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 22.69287ms)
Dec 17 20:10:14.077: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 22.928808ms)
Dec 17 20:10:14.080: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 25.863376ms)
Dec 17 20:10:14.080: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 25.869615ms)
Dec 17 20:10:14.080: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 25.826082ms)
Dec 17 20:10:14.080: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 25.742626ms)
Dec 17 20:10:14.095: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 14.136419ms)
Dec 17 20:10:14.100: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 19.180663ms)
Dec 17 20:10:14.101: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 20.477921ms)
Dec 17 20:10:14.102: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 21.96794ms)
Dec 17 20:10:14.103: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 22.106416ms)
Dec 17 20:10:14.103: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 22.209606ms)
Dec 17 20:10:14.103: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 22.021177ms)
Dec 17 20:10:14.103: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 22.053638ms)
Dec 17 20:10:14.103: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 22.545733ms)
Dec 17 20:10:14.106: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 25.217858ms)
Dec 17 20:10:14.106: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 25.323616ms)
Dec 17 20:10:14.107: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 26.003324ms)
Dec 17 20:10:14.107: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 26.09013ms)
Dec 17 20:10:14.107: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 26.1206ms)
Dec 17 20:10:14.107: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 26.024148ms)
Dec 17 20:10:14.108: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 27.374082ms)
Dec 17 20:10:14.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 16.502971ms)
Dec 17 20:10:14.125: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 16.879096ms)
Dec 17 20:10:14.129: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 20.626492ms)
Dec 17 20:10:14.129: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 20.564494ms)
Dec 17 20:10:14.129: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 21.017104ms)
Dec 17 20:10:14.133: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 25.037138ms)
Dec 17 20:10:14.134: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 25.293715ms)
Dec 17 20:10:14.134: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 25.302377ms)
Dec 17 20:10:14.134: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 26.062683ms)
Dec 17 20:10:14.134: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 26.111408ms)
Dec 17 20:10:14.134: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 26.337861ms)
Dec 17 20:10:14.134: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 26.286918ms)
Dec 17 20:10:14.134: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 26.435137ms)
Dec 17 20:10:14.135: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 26.239628ms)
Dec 17 20:10:14.135: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 26.342758ms)
Dec 17 20:10:14.136: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 27.886543ms)
Dec 17 20:10:14.153: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 16.425503ms)
Dec 17 20:10:14.154: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 17.880704ms)
Dec 17 20:10:14.154: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 17.967265ms)
Dec 17 20:10:14.157: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 20.858147ms)
Dec 17 20:10:14.157: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 21.146226ms)
Dec 17 20:10:14.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 22.309261ms)
Dec 17 20:10:14.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 22.470776ms)
Dec 17 20:10:14.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 23.049133ms)
Dec 17 20:10:14.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 23.120838ms)
Dec 17 20:10:14.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 23.143185ms)
Dec 17 20:10:14.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 23.166097ms)
Dec 17 20:10:14.159: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 23.161059ms)
Dec 17 20:10:14.160: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 23.525161ms)
Dec 17 20:10:14.162: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 25.577282ms)
Dec 17 20:10:14.162: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 25.613445ms)
Dec 17 20:10:14.162: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 25.823264ms)
Dec 17 20:10:14.177: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 14.944441ms)
Dec 17 20:10:14.177: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 15.059312ms)
Dec 17 20:10:14.182: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 20.252933ms)
Dec 17 20:10:14.183: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 20.869579ms)
Dec 17 20:10:14.184: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 21.417304ms)
Dec 17 20:10:14.184: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 21.481042ms)
Dec 17 20:10:14.184: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.433592ms)
Dec 17 20:10:14.184: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.441523ms)
Dec 17 20:10:14.184: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 21.487938ms)
Dec 17 20:10:14.184: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 21.435492ms)
Dec 17 20:10:14.184: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 21.487054ms)
Dec 17 20:10:14.185: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 22.223051ms)
Dec 17 20:10:14.187: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 24.343953ms)
Dec 17 20:10:14.187: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 24.382397ms)
Dec 17 20:10:14.187: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 25.156502ms)
Dec 17 20:10:14.188: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 26.031819ms)
Dec 17 20:10:14.204: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 15.786279ms)
Dec 17 20:10:14.209: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 20.248967ms)
Dec 17 20:10:14.209: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 20.133398ms)
Dec 17 20:10:14.210: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 21.370985ms)
Dec 17 20:10:14.210: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 21.560911ms)
Dec 17 20:10:14.210: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.823366ms)
Dec 17 20:10:14.210: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 21.72923ms)
Dec 17 20:10:14.210: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.968566ms)
Dec 17 20:10:14.210: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 21.766334ms)
Dec 17 20:10:14.219: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 30.307505ms)
Dec 17 20:10:14.219: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 30.268254ms)
Dec 17 20:10:14.221: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 32.583149ms)
Dec 17 20:10:14.222: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 33.171856ms)
Dec 17 20:10:14.222: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 33.093843ms)
Dec 17 20:10:14.222: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 33.121715ms)
Dec 17 20:10:14.222: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 33.228178ms)
Dec 17 20:10:14.235: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 13.42865ms)
Dec 17 20:10:14.242: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 19.92429ms)
Dec 17 20:10:14.242: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 20.025779ms)
Dec 17 20:10:14.242: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 20.149321ms)
Dec 17 20:10:14.242: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 20.044032ms)
Dec 17 20:10:14.242: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 20.30012ms)
Dec 17 20:10:14.246: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 24.191261ms)
Dec 17 20:10:14.246: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 24.216012ms)
Dec 17 20:10:14.246: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 24.417496ms)
Dec 17 20:10:14.248: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 25.974903ms)
Dec 17 20:10:14.248: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 25.883628ms)
Dec 17 20:10:14.248: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 25.920659ms)
Dec 17 20:10:14.248: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 25.993908ms)
Dec 17 20:10:14.248: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 25.993801ms)
Dec 17 20:10:14.248: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 26.224891ms)
Dec 17 20:10:14.249: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 27.419254ms)
Dec 17 20:10:14.267: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 17.808092ms)
Dec 17 20:10:14.267: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 17.688091ms)
Dec 17 20:10:14.267: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 17.747751ms)
Dec 17 20:10:14.267: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 17.822256ms)
Dec 17 20:10:14.267: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 17.793248ms)
Dec 17 20:10:14.268: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 18.084755ms)
Dec 17 20:10:14.268: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 17.934687ms)
Dec 17 20:10:14.271: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 20.990281ms)
Dec 17 20:10:14.271: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.701452ms)
Dec 17 20:10:14.272: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 21.927017ms)
Dec 17 20:10:14.272: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 22.784975ms)
Dec 17 20:10:14.274: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 24.41507ms)
Dec 17 20:10:14.274: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 24.468787ms)
Dec 17 20:10:14.274: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 24.437321ms)
Dec 17 20:10:14.274: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 24.733852ms)
Dec 17 20:10:14.276: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 25.956594ms)
Dec 17 20:10:14.292: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:1080/proxy/rewri... (200; 16.462883ms)
Dec 17 20:10:14.292: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:1080/proxy/... (200; 16.45372ms)
Dec 17 20:10:14.292: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn/proxy/rewriteme"... (200; 16.590469ms)
Dec 17 20:10:14.293: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:160/proxy/: foo (200; 17.592078ms)
Dec 17 20:10:14.297: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname1/proxy/: foo (200; 21.345508ms)
Dec 17 20:10:14.301: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:443/proxy/... (200; 25.596525ms)
Dec 17 20:10:14.302: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:462/proxy/: tls qux (200; 25.811911ms)
Dec 17 20:10:14.302: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/https:proxy-service-78gpx-229dn:460/proxy/: tls baz (200; 26.162595ms)
Dec 17 20:10:14.303: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:162/proxy/: bar (200; 27.70371ms)
Dec 17 20:10:14.303: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/proxy-service-78gpx-229dn:160/proxy/: foo (200; 27.666101ms)
Dec 17 20:10:14.304: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname1/proxy/: tls baz (200; 27.912408ms)
Dec 17 20:10:14.304: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/pods/http:proxy-service-78gpx-229dn:162/proxy/: bar (200; 27.687889ms)
Dec 17 20:10:14.305: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname2/proxy/: bar (200; 29.127213ms)
Dec 17 20:10:14.306: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/https:proxy-service-78gpx:tlsportname2/proxy/: tls qux (200; 29.804467ms)
Dec 17 20:10:14.307: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/proxy-service-78gpx:portname2/proxy/: bar (200; 31.047682ms)
Dec 17 20:10:14.307: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-cdrv9/services/http:proxy-service-78gpx:portname1/proxy/: foo (200; 31.162745ms)
STEP: deleting ReplicationController proxy-service-78gpx in namespace e2e-tests-proxy-cdrv9, will wait for the garbage collector to delete the pods
Dec 17 20:10:14.369: INFO: Deleting ReplicationController proxy-service-78gpx took: 8.390354ms
Dec 17 20:10:14.469: INFO: Terminating ReplicationController proxy-service-78gpx pods took: 100.374891ms
[AfterEach] version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:10:19.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-cdrv9" for this suite.
Dec 17 20:10:25.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:10:25.408: INFO: namespace: e2e-tests-proxy-cdrv9, resource: bindings, ignored listing per whitelist
Dec 17 20:10:25.419: INFO: namespace e2e-tests-proxy-cdrv9 deletion completed in 6.144452652s

• [SLOW TEST:19.965 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:10:25.420: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-ca7fc361-0237-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:10:25.551: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ca8093bd-0237-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-bkfvh" to be "success or failure"
Dec 17 20:10:25.560: INFO: Pod "pod-projected-secrets-ca8093bd-0237-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.979761ms
Dec 17 20:10:27.564: INFO: Pod "pod-projected-secrets-ca8093bd-0237-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012796842s
STEP: Saw pod success
Dec 17 20:10:27.564: INFO: Pod "pod-projected-secrets-ca8093bd-0237-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:10:27.567: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-secrets-ca8093bd-0237-11e9-9892-0a580a3c54b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:10:27.589: INFO: Waiting for pod pod-projected-secrets-ca8093bd-0237-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:10:27.594: INFO: Pod pod-projected-secrets-ca8093bd-0237-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:10:27.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bkfvh" for this suite.
Dec 17 20:10:33.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:10:33.776: INFO: namespace: e2e-tests-projected-bkfvh, resource: bindings, ignored listing per whitelist
Dec 17 20:10:33.776: INFO: namespace e2e-tests-projected-bkfvh deletion completed in 6.17809416s

• [SLOW TEST:8.356 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:10:33.776: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7szlq
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-7szlq
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-7szlq
Dec 17 20:10:33.953: INFO: Found 0 stateful pods, waiting for 1
Dec 17 20:10:43.958: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 17 20:10:43.962: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:10:44.142: INFO: stderr: ""
Dec 17 20:10:44.142: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:10:44.142: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:10:44.146: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 17 20:10:54.153: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 20:10:54.153: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:10:54.174: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:10:54.174: INFO: ss-0  bootstrap-e2e-minion-group-wjp3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  }]
Dec 17 20:10:54.174: INFO: 
Dec 17 20:10:54.174: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 17 20:10:55.178: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992782285s
Dec 17 20:10:56.182: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988752922s
Dec 17 20:10:57.188: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984457665s
Dec 17 20:10:58.193: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979030373s
Dec 17 20:10:59.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97387694s
Dec 17 20:11:00.203: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.967936371s
Dec 17 20:11:01.208: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96339763s
Dec 17 20:11:02.215: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.958439345s
Dec 17 20:11:03.218: INFO: Verifying statefulset ss doesn't scale past 3 for another 952.347816ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-7szlq
Dec 17 20:11:04.222: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:11:04.414: INFO: stderr: ""
Dec 17 20:11:04.414: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:11:04.414: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 17 20:11:04.414: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:11:04.600: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 17 20:11:04.600: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:11:04.600: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 17 20:11:04.600: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:11:04.798: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 17 20:11:04.798: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:11:04.798: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 17 20:11:04.804: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 17 20:11:14.817: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:11:14.817: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:11:14.817: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 17 20:11:14.820: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:11:15.003: INFO: stderr: ""
Dec 17 20:11:15.003: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:11:15.003: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:11:15.004: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:11:15.188: INFO: stderr: ""
Dec 17 20:11:15.188: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:11:15.188: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:11:15.188: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:11:15.368: INFO: stderr: ""
Dec 17 20:11:15.368: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:11:15.368: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:11:15.368: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:11:15.372: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 17 20:11:25.382: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 20:11:25.382: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 20:11:25.382: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 20:11:25.415: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:25.415: INFO: ss-0  bootstrap-e2e-minion-group-wjp3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  }]
Dec 17 20:11:25.415: INFO: ss-1  bootstrap-e2e-minion-group-tnzf  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:25.415: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:25.415: INFO: 
Dec 17 20:11:25.415: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 20:11:26.419: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:26.419: INFO: ss-0  bootstrap-e2e-minion-group-wjp3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  }]
Dec 17 20:11:26.419: INFO: ss-1  bootstrap-e2e-minion-group-tnzf  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:26.419: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:26.419: INFO: 
Dec 17 20:11:26.419: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 20:11:27.424: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:27.424: INFO: ss-0  bootstrap-e2e-minion-group-wjp3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  }]
Dec 17 20:11:27.424: INFO: ss-1  bootstrap-e2e-minion-group-tnzf  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:27.424: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:27.424: INFO: 
Dec 17 20:11:27.424: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 20:11:28.428: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:28.428: INFO: ss-0  bootstrap-e2e-minion-group-wjp3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:33 +0000 UTC  }]
Dec 17 20:11:28.428: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:28.428: INFO: 
Dec 17 20:11:28.428: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 17 20:11:29.432: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:29.432: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:29.432: INFO: 
Dec 17 20:11:29.432: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 17 20:11:30.436: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:30.436: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:30.436: INFO: 
Dec 17 20:11:30.436: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 17 20:11:31.440: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:31.440: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:31.440: INFO: 
Dec 17 20:11:31.440: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 17 20:11:32.444: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:32.444: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:32.444: INFO: 
Dec 17 20:11:32.444: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 17 20:11:33.447: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:33.448: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:33.448: INFO: 
Dec 17 20:11:33.448: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 17 20:11:34.452: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 17 20:11:34.452: INFO: ss-2  bootstrap-e2e-minion-group-6xhw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:11:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:10:54 +0000 UTC  }]
Dec 17 20:11:34.452: INFO: 
Dec 17 20:11:34.452: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-7szlq
Dec 17 20:11:35.456: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:11:35.592: INFO: rc: 1
Dec 17 20:11:35.593: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0017bd2f0 exit status 1 <nil> <nil> true [0xc0004b9c78 0xc0004b9ce0 0xc0004b9d20] [0xc0004b9c78 0xc0004b9ce0 0xc0004b9d20] [0xc0004b9cc0 0xc0004b9d00] [0x92f8e0 0x92f8e0] 0xc000fecfc0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec 17 20:11:45.593: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:11:45.674: INFO: rc: 1
Dec 17 20:11:45.674: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0017bdb60 exit status 1 <nil> <nil> true [0xc0004b9d40 0xc0004b9d88 0xc0004b9dd0] [0xc0004b9d40 0xc0004b9d88 0xc0004b9dd0] [0xc0004b9d70 0xc0004b9dc8] [0x92f8e0 0x92f8e0] 0xc000fed3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:11:55.674: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:11:55.759: INFO: rc: 1
Dec 17 20:11:55.759: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00096e540 exit status 1 <nil> <nil> true [0xc0000e1690 0xc0000e16b0 0xc0000e16e8] [0xc0000e1690 0xc0000e16b0 0xc0000e16e8] [0xc0000e16a8 0xc0000e16d8] [0x92f8e0 0x92f8e0] 0xc001306360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:12:05.759: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:12:05.850: INFO: rc: 1
Dec 17 20:12:05.851: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00162cfc0 exit status 1 <nil> <nil> true [0xc0020a2150 0xc0020a2168 0xc0020a2180] [0xc0020a2150 0xc0020a2168 0xc0020a2180] [0xc0020a2160 0xc0020a2178] [0x92f8e0 0x92f8e0] 0xc001dc8960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:12:15.851: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:12:16.088: INFO: rc: 1
Dec 17 20:12:16.088: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00096ec30 exit status 1 <nil> <nil> true [0xc0000e1708 0xc0000e1730 0xc0000e1748] [0xc0000e1708 0xc0000e1730 0xc0000e1748] [0xc0000e1728 0xc0000e1740] [0x92f8e0 0x92f8e0] 0xc001306660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:12:26.088: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:12:26.170: INFO: rc: 1
Dec 17 20:12:26.170: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00096f350 exit status 1 <nil> <nil> true [0xc0000e1760 0xc0000e1790 0xc0000e17b0] [0xc0000e1760 0xc0000e1790 0xc0000e17b0] [0xc0000e1780 0xc0000e17a8] [0x92f8e0 0x92f8e0] 0xc001307680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:12:36.171: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:12:36.262: INFO: rc: 1
Dec 17 20:12:36.262: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000c55020 exit status 1 <nil> <nil> true [0xc0000e1818 0xc0000e1850 0xc0000e1890] [0xc0000e1818 0xc0000e1850 0xc0000e1890] [0xc0000e1830 0xc0000e1880] [0x92f8e0 0x92f8e0] 0xc001554a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:12:46.263: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:12:46.347: INFO: rc: 1
Dec 17 20:12:46.347: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0003f9470 exit status 1 <nil> <nil> true [0xc00000e010 0xc000361348 0xc000361678] [0xc00000e010 0xc000361348 0xc000361678] [0xc000361310 0xc000361650] [0x92f8e0 0x92f8e0] 0xc00141e480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:12:56.348: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:12:56.430: INFO: rc: 1
Dec 17 20:12:56.430: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0011508a0 exit status 1 <nil> <nil> true [0xc0020a2000 0xc0020a2018 0xc0020a2030] [0xc0020a2000 0xc0020a2018 0xc0020a2030] [0xc0020a2010 0xc0020a2028] [0x92f8e0 0x92f8e0] 0xc0011d22a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:13:06.430: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:13:06.512: INFO: rc: 1
Dec 17 20:13:06.512: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019eed20 exit status 1 <nil> <nil> true [0xc0000e0090 0xc0000e0700 0xc0000e0938] [0xc0000e0090 0xc0000e0700 0xc0000e0938] [0xc0000e0698 0xc0000e08f8] [0x92f8e0 0x92f8e0] 0xc000e82420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:13:16.513: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:13:16.591: INFO: rc: 1
Dec 17 20:13:16.591: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b068d0 exit status 1 <nil> <nil> true [0xc00226c000 0xc00226c018 0xc00226c030] [0xc00226c000 0xc00226c018 0xc00226c030] [0xc00226c010 0xc00226c028] [0x92f8e0 0x92f8e0] 0xc0008fac60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:13:26.592: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:13:26.670: INFO: rc: 1
Dec 17 20:13:26.670: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019ef590 exit status 1 <nil> <nil> true [0xc0000e0968 0xc0000e09b0 0xc0000e0a68] [0xc0000e0968 0xc0000e09b0 0xc0000e0a68] [0xc0000e0990 0xc0000e0a20] [0x92f8e0 0x92f8e0] 0xc000e828a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:13:36.671: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:13:36.749: INFO: rc: 1
Dec 17 20:13:36.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019efce0 exit status 1 <nil> <nil> true [0xc0000e0aa0 0xc0000e0ae8 0xc0000e0b08] [0xc0000e0aa0 0xc0000e0ae8 0xc0000e0b08] [0xc0000e0ad8 0xc0000e0b00] [0x92f8e0 0x92f8e0] 0xc000e82ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:13:46.750: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:13:46.831: INFO: rc: 1
Dec 17 20:13:46.831: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001151050 exit status 1 <nil> <nil> true [0xc0020a2038 0xc0020a2050 0xc0020a2068] [0xc0020a2038 0xc0020a2050 0xc0020a2068] [0xc0020a2048 0xc0020a2060] [0x92f8e0 0x92f8e0] 0xc0011d26c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:13:56.831: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:13:56.913: INFO: rc: 1
Dec 17 20:13:56.913: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b07140 exit status 1 <nil> <nil> true [0xc00226c038 0xc00226c050 0xc00226c068] [0xc00226c038 0xc00226c050 0xc00226c068] [0xc00226c048 0xc00226c060] [0x92f8e0 0x92f8e0] 0xc0008fb320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:14:06.913: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:14:06.994: INFO: rc: 1
Dec 17 20:14:06.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b07920 exit status 1 <nil> <nil> true [0xc00226c070 0xc00226c098 0xc00226c0b0] [0xc00226c070 0xc00226c098 0xc00226c0b0] [0xc00226c090 0xc00226c0a8] [0x92f8e0 0x92f8e0] 0xc0008fb800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:14:16.994: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:14:17.078: INFO: rc: 1
Dec 17 20:14:17.078: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00196c600 exit status 1 <nil> <nil> true [0xc0000e0b58 0xc0000e0bd0 0xc0000e0bf8] [0xc0000e0b58 0xc0000e0bd0 0xc0000e0bf8] [0xc0000e0bc8 0xc0000e0be0] [0x92f8e0 0x92f8e0] 0xc000e83740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:14:27.078: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:14:27.190: INFO: rc: 1
Dec 17 20:14:27.190: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00090e090 exit status 1 <nil> <nil> true [0xc00226c0b8 0xc00226c0f0 0xc00226c148] [0xc00226c0b8 0xc00226c0f0 0xc00226c148] [0xc00226c0d8 0xc00226c138] [0x92f8e0 0x92f8e0] 0xc001bd06c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:14:37.191: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:14:37.272: INFO: rc: 1
Dec 17 20:14:37.272: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00196cdb0 exit status 1 <nil> <nil> true [0xc0000e0c58 0xc0000e0ca8 0xc0000e0d48] [0xc0000e0c58 0xc0000e0ca8 0xc0000e0d48] [0xc0000e0c90 0xc0000e0cf0] [0x92f8e0 0x92f8e0] 0xc000e83a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:14:47.272: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:14:47.355: INFO: rc: 1
Dec 17 20:14:47.355: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b068a0 exit status 1 <nil> <nil> true [0xc00000e010 0xc00226c010 0xc00226c028] [0xc00000e010 0xc00226c010 0xc00226c028] [0xc00226c008 0xc00226c020] [0x92f8e0 0x92f8e0] 0xc0008fac60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:14:57.356: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:14:57.433: INFO: rc: 1
Dec 17 20:14:57.433: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019ef2c0 exit status 1 <nil> <nil> true [0xc000361030 0xc000361648 0xc0003616a8] [0xc000361030 0xc000361648 0xc0003616a8] [0xc000361348 0xc000361678] [0x92f8e0 0x92f8e0] 0xc001bd06c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:15:07.433: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:15:07.518: INFO: rc: 1
Dec 17 20:15:07.518: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019efa70 exit status 1 <nil> <nil> true [0xc0003616d0 0xc000361708 0xc000361768] [0xc0003616d0 0xc000361708 0xc000361768] [0xc0003616f8 0xc000361760] [0x92f8e0 0x92f8e0] 0xc001bd0c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:15:17.518: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:15:17.609: INFO: rc: 1
Dec 17 20:15:17.609: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b07080 exit status 1 <nil> <nil> true [0xc00226c030 0xc00226c048 0xc00226c060] [0xc00226c030 0xc00226c048 0xc00226c060] [0xc00226c040 0xc00226c058] [0x92f8e0 0x92f8e0] 0xc0008fb320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:15:27.610: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:15:27.704: INFO: rc: 1
Dec 17 20:15:27.704: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b07860 exit status 1 <nil> <nil> true [0xc00226c068 0xc00226c090 0xc00226c0a8] [0xc00226c068 0xc00226c090 0xc00226c0a8] [0xc00226c078 0xc00226c0a0] [0x92f8e0 0x92f8e0] 0xc0008fb800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:15:37.705: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:15:37.791: INFO: rc: 1
Dec 17 20:15:37.792: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00090e4b0 exit status 1 <nil> <nil> true [0xc0000e0090 0xc0000e0700 0xc0000e0938] [0xc0000e0090 0xc0000e0700 0xc0000e0938] [0xc0000e0698 0xc0000e08f8] [0x92f8e0 0x92f8e0] 0xc00141e480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:15:47.792: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:15:47.872: INFO: rc: 1
Dec 17 20:15:47.872: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00196c060 exit status 1 <nil> <nil> true [0xc00226c0b0 0xc00226c0d8 0xc00226c138] [0xc00226c0b0 0xc00226c0d8 0xc00226c138] [0xc00226c0c8 0xc00226c118] [0x92f8e0 0x92f8e0] 0xc000e82420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:15:57.873: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:15:57.957: INFO: rc: 1
Dec 17 20:15:57.957: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00090ec60 exit status 1 <nil> <nil> true [0xc0000e0968 0xc0000e09b0 0xc0000e0a68] [0xc0000e0968 0xc0000e09b0 0xc0000e0a68] [0xc0000e0990 0xc0000e0a20] [0x92f8e0 0x92f8e0] 0xc00141e840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:16:07.957: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:16:08.042: INFO: rc: 1
Dec 17 20:16:08.042: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0003f9830 exit status 1 <nil> <nil> true [0xc0020a2000 0xc0020a2018 0xc0020a2030] [0xc0020a2000 0xc0020a2018 0xc0020a2030] [0xc0020a2010 0xc0020a2028] [0x92f8e0 0x92f8e0] 0xc0011d22a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:16:18.042: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:16:18.128: INFO: rc: 1
Dec 17 20:16:18.129: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00196d0b0 exit status 1 <nil> <nil> true [0xc00226c148 0xc00226c180 0xc00226c1c8] [0xc00226c148 0xc00226c180 0xc00226c1c8] [0xc00226c168 0xc00226c1b0] [0x92f8e0 0x92f8e0] 0xc000e828a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:16:28.129: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:16:28.208: INFO: rc: 1
Dec 17 20:16:28.208: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/workspace/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00090f4d0 exit status 1 <nil> <nil> true [0xc0000e0aa0 0xc0000e0ae8 0xc0000e0b08] [0xc0000e0aa0 0xc0000e0ae8 0xc0000e0b08] [0xc0000e0ad8 0xc0000e0b00] [0x92f8e0 0x92f8e0] 0xc00141eea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 17 20:16:38.208: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-7szlq ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:16:38.289: INFO: rc: 1
Dec 17 20:16:38.289: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Dec 17 20:16:38.289: INFO: Scaling statefulset ss to 0
Dec 17 20:16:38.307: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 17 20:16:38.310: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7szlq
Dec 17 20:16:38.313: INFO: Scaling statefulset ss to 0
Dec 17 20:16:38.323: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:16:38.326: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:16:38.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7szlq" for this suite.
Dec 17 20:16:44.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:16:44.453: INFO: namespace: e2e-tests-statefulset-7szlq, resource: bindings, ignored listing per whitelist
Dec 17 20:16:44.486: INFO: namespace e2e-tests-statefulset-7szlq deletion completed in 6.137577465s

• [SLOW TEST:370.710 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:16:44.487: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:16:44.593: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 17 20:16:49.598: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 20:16:49.598: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 17 20:16:51.602: INFO: Creating deployment "test-rollover-deployment"
Dec 17 20:16:51.614: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 17 20:16:53.622: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 17 20:16:53.628: INFO: Ensure that both replica sets have 1 created replica
Dec 17 20:16:53.640: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 17 20:16:53.656: INFO: Updating deployment test-rollover-deployment
Dec 17 20:16:53.656: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 17 20:16:55.670: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 17 20:16:55.685: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 17 20:16:55.694: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 20:16:55.694: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674615, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 20:16:57.702: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 20:16:57.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674615, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 20:16:59.702: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 20:16:59.702: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674615, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 20:17:01.701: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 20:17:01.701: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674615, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 20:17:03.703: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 20:17:03.703: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674615, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680674611, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 20:17:05.707: INFO: 
Dec 17 20:17:05.707: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 17 20:17:05.716: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-fjzkg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fjzkg/deployments/test-rollover-deployment,UID:b0988232-0238-11e9-b8bf-42010a800002,ResourceVersion:6101,Generation:2,CreationTimestamp:2018-12-17 20:16:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-17 20:16:51 +0000 UTC 2018-12-17 20:16:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-17 20:17:05 +0000 UTC 2018-12-17 20:16:51 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 17 20:17:05.719: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-fjzkg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fjzkg/replicasets/test-rollover-deployment-6b7f9d6597,UID:b1d25421-0238-11e9-b8bf-42010a800002,ResourceVersion:6094,Generation:2,CreationTimestamp:2018-12-17 20:16:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b0988232-0238-11e9-b8bf-42010a800002 0xc00182db77 0xc00182db78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 17 20:17:05.719: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 17 20:17:05.720: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-fjzkg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fjzkg/replicasets/test-rollover-controller,UID:ac690f51-0238-11e9-b8bf-42010a800002,ResourceVersion:6100,Generation:2,CreationTimestamp:2018-12-17 20:16:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b0988232-0238-11e9-b8bf-42010a800002 0xc00182d9ef 0xc00182da00}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 17 20:17:05.720: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-fjzkg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fjzkg/replicasets/test-rollover-deployment-6586df867b,UID:b09cd8aa-0238-11e9-b8bf-42010a800002,ResourceVersion:6063,Generation:2,CreationTimestamp:2018-12-17 20:16:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b0988232-0238-11e9-b8bf-42010a800002 0xc00182dab7 0xc00182dab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 17 20:17:05.723: INFO: Pod "test-rollover-deployment-6b7f9d6597-ff4hn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-ff4hn,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-fjzkg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fjzkg/pods/test-rollover-deployment-6b7f9d6597-ff4hn,UID:b1dac5ea-0238-11e9-b8bf-42010a800002,ResourceVersion:6070,Generation:0,CreationTimestamp:2018-12-17 20:16:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 b1d25421-0238-11e9-b8bf-42010a800002 0xc0019f3927 0xc0019f3928}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4pvzw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4pvzw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4pvzw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019f3a00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019f3a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:16:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:16:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:16:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:16:53 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:10.64.3.31,StartTime:2018-12-17 20:16:53 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-17 20:16:54 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b4790bf25dc2a51b22367dfa6d196208263de844ed6bfd360af0a0c176817a3b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:17:05.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fjzkg" for this suite.
Dec 17 20:17:11.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:17:11.787: INFO: namespace: e2e-tests-deployment-fjzkg, resource: bindings, ignored listing per whitelist
Dec 17 20:17:11.865: INFO: namespace e2e-tests-deployment-fjzkg deletion completed in 6.137079039s

• [SLOW TEST:27.378 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:17:11.865: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:17:14.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-7wx6d" for this suite.
Dec 17 20:18:00.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:18:00.824: INFO: namespace: e2e-tests-kubelet-test-7wx6d, resource: bindings, ignored listing per whitelist
Dec 17 20:18:00.852: INFO: namespace e2e-tests-kubelet-test-7wx6d deletion completed in 46.395083819s

• [SLOW TEST:48.987 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:18:00.853: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-d9f35d79-0238-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:18:00.969: INFO: Waiting up to 5m0s for pod "pod-secrets-d9f410cf-0238-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-t7l87" to be "success or failure"
Dec 17 20:18:00.983: INFO: Pod "pod-secrets-d9f410cf-0238-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.206487ms
Dec 17 20:18:02.987: INFO: Pod "pod-secrets-d9f410cf-0238-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017951888s
Dec 17 20:18:04.991: INFO: Pod "pod-secrets-d9f410cf-0238-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022251346s
STEP: Saw pod success
Dec 17 20:18:04.991: INFO: Pod "pod-secrets-d9f410cf-0238-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:18:04.994: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-secrets-d9f410cf-0238-11e9-9892-0a580a3c54b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:18:05.022: INFO: Waiting for pod pod-secrets-d9f410cf-0238-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:18:05.031: INFO: Pod pod-secrets-d9f410cf-0238-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:18:05.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t7l87" for this suite.
Dec 17 20:18:11.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:18:11.081: INFO: namespace: e2e-tests-secrets-t7l87, resource: bindings, ignored listing per whitelist
Dec 17 20:18:11.224: INFO: namespace e2e-tests-secrets-t7l87 deletion completed in 6.189369196s

• [SLOW TEST:10.372 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:18:11.224: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e0227e6e-0238-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:18:11.346: INFO: Waiting up to 5m0s for pod "pod-configmaps-e0236cc4-0238-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-rzxdg" to be "success or failure"
Dec 17 20:18:11.358: INFO: Pod "pod-configmaps-e0236cc4-0238-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.073212ms
Dec 17 20:18:13.363: INFO: Pod "pod-configmaps-e0236cc4-0238-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016536203s
STEP: Saw pod success
Dec 17 20:18:13.363: INFO: Pod "pod-configmaps-e0236cc4-0238-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:18:13.366: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-e0236cc4-0238-11e9-9892-0a580a3c54b9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:18:13.388: INFO: Waiting for pod pod-configmaps-e0236cc4-0238-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:18:13.393: INFO: Pod pod-configmaps-e0236cc4-0238-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:18:13.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rzxdg" for this suite.
Dec 17 20:18:19.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:18:19.558: INFO: namespace: e2e-tests-configmap-rzxdg, resource: bindings, ignored listing per whitelist
Dec 17 20:18:19.586: INFO: namespace e2e-tests-configmap-rzxdg deletion completed in 6.18850171s

• [SLOW TEST:8.361 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:18:19.586: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 17 20:18:27.798: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:27.806: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:29.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:29.809: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:31.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:31.810: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:33.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:33.810: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:35.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:35.810: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:37.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:37.810: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:39.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:39.810: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:41.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:41.809: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:43.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:43.810: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 20:18:45.806: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 20:18:45.810: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:18:45.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-56hpk" for this suite.
Dec 17 20:19:09.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:19:09.890: INFO: namespace: e2e-tests-container-lifecycle-hook-56hpk, resource: bindings, ignored listing per whitelist
Dec 17 20:19:09.963: INFO: namespace e2e-tests-container-lifecycle-hook-56hpk deletion completed in 24.135938696s

• [SLOW TEST:50.377 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:19:09.963: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 17 20:19:10.070: INFO: Waiting up to 5m0s for pod "pod-032406f0-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-vhl85" to be "success or failure"
Dec 17 20:19:10.083: INFO: Pod "pod-032406f0-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.851333ms
Dec 17 20:19:12.087: INFO: Pod "pod-032406f0-0239-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.01643935s
Dec 17 20:19:14.090: INFO: Pod "pod-032406f0-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019853147s
STEP: Saw pod success
Dec 17 20:19:14.090: INFO: Pod "pod-032406f0-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:19:14.093: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-032406f0-0239-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:19:14.120: INFO: Waiting for pod pod-032406f0-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:19:14.124: INFO: Pod pod-032406f0-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:19:14.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vhl85" for this suite.
Dec 17 20:19:20.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:19:20.248: INFO: namespace: e2e-tests-emptydir-vhl85, resource: bindings, ignored listing per whitelist
Dec 17 20:19:20.283: INFO: namespace e2e-tests-emptydir-vhl85 deletion completed in 6.154924246s

• [SLOW TEST:10.320 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:19:20.284: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 17 20:19:20.430: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kfcs8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kfcs8/configmaps/e2e-watch-test-watch-closed,UID:094b89a7-0239-11e9-b8bf-42010a800002,ResourceVersion:6491,Generation:0,CreationTimestamp:2018-12-17 20:19:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 20:19:20.430: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kfcs8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kfcs8/configmaps/e2e-watch-test-watch-closed,UID:094b89a7-0239-11e9-b8bf-42010a800002,ResourceVersion:6492,Generation:0,CreationTimestamp:2018-12-17 20:19:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 17 20:19:20.448: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kfcs8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kfcs8/configmaps/e2e-watch-test-watch-closed,UID:094b89a7-0239-11e9-b8bf-42010a800002,ResourceVersion:6493,Generation:0,CreationTimestamp:2018-12-17 20:19:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 20:19:20.448: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kfcs8,SelfLink:/api/v1/namespaces/e2e-tests-watch-kfcs8/configmaps/e2e-watch-test-watch-closed,UID:094b89a7-0239-11e9-b8bf-42010a800002,ResourceVersion:6494,Generation:0,CreationTimestamp:2018-12-17 20:19:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:19:20.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-kfcs8" for this suite.
Dec 17 20:19:26.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:19:26.541: INFO: namespace: e2e-tests-watch-kfcs8, resource: bindings, ignored listing per whitelist
Dec 17 20:19:26.587: INFO: namespace e2e-tests-watch-kfcs8 deletion completed in 6.133835604s

• [SLOW TEST:6.304 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:19:26.588: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-0d0c81f8-0239-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:19:26.698: INFO: Waiting up to 5m0s for pod "pod-configmaps-0d0d33e2-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-bwtw7" to be "success or failure"
Dec 17 20:19:26.704: INFO: Pod "pod-configmaps-0d0d33e2-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.70533ms
Dec 17 20:19:28.708: INFO: Pod "pod-configmaps-0d0d33e2-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010531615s
Dec 17 20:19:30.712: INFO: Pod "pod-configmaps-0d0d33e2-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013843366s
STEP: Saw pod success
Dec 17 20:19:30.712: INFO: Pod "pod-configmaps-0d0d33e2-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:19:30.714: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-0d0d33e2-0239-11e9-9892-0a580a3c54b9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:19:30.740: INFO: Waiting for pod pod-configmaps-0d0d33e2-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:19:30.744: INFO: Pod pod-configmaps-0d0d33e2-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:19:30.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bwtw7" for this suite.
Dec 17 20:19:36.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:19:36.910: INFO: namespace: e2e-tests-configmap-bwtw7, resource: bindings, ignored listing per whitelist
Dec 17 20:19:36.977: INFO: namespace e2e-tests-configmap-bwtw7 deletion completed in 6.22808934s

• [SLOW TEST:10.390 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:19:36.978: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-13435d0c-0239-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:19:37.128: INFO: Waiting up to 5m0s for pod "pod-secrets-13449000-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-9l6qp" to be "success or failure"
Dec 17 20:19:37.138: INFO: Pod "pod-secrets-13449000-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.126572ms
Dec 17 20:19:39.142: INFO: Pod "pod-secrets-13449000-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014398393s
STEP: Saw pod success
Dec 17 20:19:39.142: INFO: Pod "pod-secrets-13449000-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:19:39.149: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-secrets-13449000-0239-11e9-9892-0a580a3c54b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:19:39.178: INFO: Waiting for pod pod-secrets-13449000-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:19:39.183: INFO: Pod pod-secrets-13449000-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:19:39.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9l6qp" for this suite.
Dec 17 20:19:45.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:19:45.236: INFO: namespace: e2e-tests-secrets-9l6qp, resource: bindings, ignored listing per whitelist
Dec 17 20:19:45.342: INFO: namespace e2e-tests-secrets-9l6qp deletion completed in 6.153450368s

• [SLOW TEST:8.364 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:19:45.342: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Dec 17 20:19:45.447: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-qmw7m'
Dec 17 20:19:48.314: INFO: stderr: ""
Dec 17 20:19:48.314: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec 17 20:19:49.319: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 20:19:49.319: INFO: Found 0 / 1
Dec 17 20:19:50.319: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 20:19:50.319: INFO: Found 1 / 1
Dec 17 20:19:50.319: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 17 20:19:50.322: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 20:19:50.322: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 17 20:19:50.322: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config logs redis-master-6qvmg redis-master --namespace=e2e-tests-kubectl-qmw7m'
Dec 17 20:19:50.426: INFO: stderr: ""
Dec 17 20:19:50.426: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Dec 20:19:49.514 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Dec 20:19:49.514 # Server started, Redis version 3.2.12\n1:M 17 Dec 20:19:49.515 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Dec 20:19:49.515 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 17 20:19:50.426: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config log redis-master-6qvmg redis-master --namespace=e2e-tests-kubectl-qmw7m --tail=1'
Dec 17 20:19:50.529: INFO: stderr: ""
Dec 17 20:19:50.529: INFO: stdout: "1:M 17 Dec 20:19:49.515 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 17 20:19:50.529: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config log redis-master-6qvmg redis-master --namespace=e2e-tests-kubectl-qmw7m --limit-bytes=1'
Dec 17 20:19:50.631: INFO: stderr: ""
Dec 17 20:19:50.631: INFO: stdout: " "
STEP: exposing timestamps
Dec 17 20:19:50.631: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config log redis-master-6qvmg redis-master --namespace=e2e-tests-kubectl-qmw7m --tail=1 --timestamps'
Dec 17 20:19:50.734: INFO: stderr: ""
Dec 17 20:19:50.734: INFO: stdout: "2018-12-17T20:19:49.515267424Z 1:M 17 Dec 20:19:49.515 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 17 20:19:53.234: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config log redis-master-6qvmg redis-master --namespace=e2e-tests-kubectl-qmw7m --since=1s'
Dec 17 20:19:53.338: INFO: stderr: ""
Dec 17 20:19:53.338: INFO: stdout: ""
Dec 17 20:19:53.338: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config log redis-master-6qvmg redis-master --namespace=e2e-tests-kubectl-qmw7m --since=24h'
Dec 17 20:19:53.448: INFO: stderr: ""
Dec 17 20:19:53.448: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Dec 20:19:49.514 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Dec 20:19:49.514 # Server started, Redis version 3.2.12\n1:M 17 Dec 20:19:49.515 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Dec 20:19:49.515 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Dec 17 20:19:53.448: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qmw7m'
Dec 17 20:19:53.548: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 20:19:53.548: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 17 20:19:53.548: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-qmw7m'
Dec 17 20:19:53.649: INFO: stderr: "No resources found.\n"
Dec 17 20:19:53.649: INFO: stdout: ""
Dec 17 20:19:53.649: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -l name=nginx --namespace=e2e-tests-kubectl-qmw7m -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 20:19:53.735: INFO: stderr: ""
Dec 17 20:19:53.735: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:19:53.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qmw7m" for this suite.
Dec 17 20:20:15.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:20:15.795: INFO: namespace: e2e-tests-kubectl-qmw7m, resource: bindings, ignored listing per whitelist
Dec 17 20:20:15.877: INFO: namespace e2e-tests-kubectl-qmw7m deletion completed in 22.136701706s

• [SLOW TEST:30.535 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:20:15.877: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 17 20:20:16.004: INFO: Waiting up to 5m0s for pod "pod-2a70be2e-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-hdrgv" to be "success or failure"
Dec 17 20:20:16.013: INFO: Pod "pod-2a70be2e-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.716133ms
Dec 17 20:20:18.017: INFO: Pod "pod-2a70be2e-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012517454s
Dec 17 20:20:20.021: INFO: Pod "pod-2a70be2e-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016506622s
STEP: Saw pod success
Dec 17 20:20:20.021: INFO: Pod "pod-2a70be2e-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:20:20.024: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-2a70be2e-0239-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:20:20.050: INFO: Waiting for pod pod-2a70be2e-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:20:20.054: INFO: Pod pod-2a70be2e-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:20:20.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hdrgv" for this suite.
Dec 17 20:20:26.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:20:26.192: INFO: namespace: e2e-tests-emptydir-hdrgv, resource: bindings, ignored listing per whitelist
Dec 17 20:20:26.199: INFO: namespace e2e-tests-emptydir-hdrgv deletion completed in 6.139910853s

• [SLOW TEST:10.322 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:20:26.199: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-r7sj
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 20:20:26.348: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-r7sj" in namespace "e2e-tests-subpath-9h7qs" to be "success or failure"
Dec 17 20:20:26.355: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.658543ms
Dec 17 20:20:28.359: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 2.010585064s
Dec 17 20:20:30.363: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 4.014388575s
Dec 17 20:20:32.367: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 6.018274197s
Dec 17 20:20:34.371: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 8.022211738s
Dec 17 20:20:36.375: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 10.026317413s
Dec 17 20:20:38.379: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 12.030315533s
Dec 17 20:20:40.383: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 14.034087817s
Dec 17 20:20:42.387: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 16.038414358s
Dec 17 20:20:44.391: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 18.04257888s
Dec 17 20:20:46.395: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 20.046275848s
Dec 17 20:20:48.398: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Running", Reason="", readiness=false. Elapsed: 22.049891869s
Dec 17 20:20:50.402: INFO: Pod "pod-subpath-test-configmap-r7sj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.053663557s
STEP: Saw pod success
Dec 17 20:20:50.402: INFO: Pod "pod-subpath-test-configmap-r7sj" satisfied condition "success or failure"
Dec 17 20:20:50.405: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-subpath-test-configmap-r7sj container test-container-subpath-configmap-r7sj: <nil>
STEP: delete the pod
Dec 17 20:20:50.427: INFO: Waiting for pod pod-subpath-test-configmap-r7sj to disappear
Dec 17 20:20:50.430: INFO: Pod pod-subpath-test-configmap-r7sj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-r7sj
Dec 17 20:20:50.430: INFO: Deleting pod "pod-subpath-test-configmap-r7sj" in namespace "e2e-tests-subpath-9h7qs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:20:50.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9h7qs" for this suite.
Dec 17 20:20:56.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:20:56.524: INFO: namespace: e2e-tests-subpath-9h7qs, resource: bindings, ignored listing per whitelist
Dec 17 20:20:56.560: INFO: namespace e2e-tests-subpath-9h7qs deletion completed in 6.124576879s

• [SLOW TEST:30.361 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:20:56.560: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 17 20:20:56.687: INFO: Waiting up to 5m0s for pod "pod-42b0593a-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-4cpck" to be "success or failure"
Dec 17 20:20:56.717: INFO: Pod "pod-42b0593a-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 29.989121ms
Dec 17 20:20:58.721: INFO: Pod "pod-42b0593a-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033876351s
Dec 17 20:21:00.725: INFO: Pod "pod-42b0593a-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037469786s
STEP: Saw pod success
Dec 17 20:21:00.725: INFO: Pod "pod-42b0593a-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:21:00.727: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-42b0593a-0239-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:21:00.757: INFO: Waiting for pod pod-42b0593a-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:21:00.762: INFO: Pod pod-42b0593a-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:21:00.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4cpck" for this suite.
Dec 17 20:21:06.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:21:06.862: INFO: namespace: e2e-tests-emptydir-4cpck, resource: bindings, ignored listing per whitelist
Dec 17 20:21:06.904: INFO: namespace e2e-tests-emptydir-4cpck deletion completed in 6.138301649s

• [SLOW TEST:10.344 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:21:06.904: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 17 20:21:07.034: INFO: Waiting up to 5m0s for pod "downward-api-48db4d1c-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-4qr8j" to be "success or failure"
Dec 17 20:21:07.041: INFO: Pod "downward-api-48db4d1c-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.347983ms
Dec 17 20:21:09.047: INFO: Pod "downward-api-48db4d1c-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012071449s
Dec 17 20:21:11.050: INFO: Pod "downward-api-48db4d1c-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01537516s
STEP: Saw pod success
Dec 17 20:21:11.050: INFO: Pod "downward-api-48db4d1c-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:21:11.053: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downward-api-48db4d1c-0239-11e9-9892-0a580a3c54b9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 20:21:11.079: INFO: Waiting for pod downward-api-48db4d1c-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:21:11.084: INFO: Pod downward-api-48db4d1c-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:21:11.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4qr8j" for this suite.
Dec 17 20:21:17.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:21:17.176: INFO: namespace: e2e-tests-downward-api-4qr8j, resource: bindings, ignored listing per whitelist
Dec 17 20:21:17.266: INFO: namespace e2e-tests-downward-api-4qr8j deletion completed in 6.179598118s

• [SLOW TEST:10.362 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:21:17.267: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:21:17.366: INFO: Creating deployment "nginx-deployment"
Dec 17 20:21:17.373: INFO: Waiting for observed generation 1
Dec 17 20:21:19.383: INFO: Waiting for all required pods to come up
Dec 17 20:21:19.387: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 17 20:21:21.411: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 17 20:21:21.417: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 17 20:21:21.427: INFO: Updating deployment nginx-deployment
Dec 17 20:21:21.427: INFO: Waiting for observed generation 2
Dec 17 20:21:23.436: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 17 20:21:23.440: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 17 20:21:23.442: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 17 20:21:23.450: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 17 20:21:23.451: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 17 20:21:23.453: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 17 20:21:23.459: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 17 20:21:23.459: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 17 20:21:23.467: INFO: Updating deployment nginx-deployment
Dec 17 20:21:23.467: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 17 20:21:23.494: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 17 20:21:25.547: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 17 20:21:25.553: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-btj89,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-btj89/deployments/nginx-deployment,UID:4f007222-0239-11e9-b8bf-42010a800002,ResourceVersion:7059,Generation:3,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[{Available False 2018-12-17 20:21:23 +0000 UTC 2018-12-17 20:21:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-17 20:21:25 +0000 UTC 2018-12-17 20:21:17 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:9,CollisionCount:nil,},}

Dec 17 20:21:25.561: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-btj89,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-btj89/replicasets/nginx-deployment-65bbdb5f8,UID:516c4bbb-0239-11e9-b8bf-42010a800002,ResourceVersion:7036,Generation:3,CreationTimestamp:2018-12-17 20:21:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 4f007222-0239-11e9-b8bf-42010a800002 0xc0017e97d7 0xc0017e97d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 17 20:21:25.561: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 17 20:21:25.561: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-btj89,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-btj89/replicasets/nginx-deployment-555b55d965,UID:4f02b450-0239-11e9-b8bf-42010a800002,ResourceVersion:7058,Generation:3,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 4f007222-0239-11e9-b8bf-42010a800002 0xc0017e96d7 0xc0017e96d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:9,AvailableReplicas:9,Conditions:[],},}
Dec 17 20:21:25.569: INFO: Pod "nginx-deployment-555b55d965-2n98w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2n98w,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-2n98w,UID:52b61bc2-0239-11e9-b8bf-42010a800002,ResourceVersion:7047,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b4390 0xc0015b4391}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-6xhw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b4400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b4430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.5,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.569: INFO: Pod "nginx-deployment-555b55d965-4nc54" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4nc54,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-4nc54,UID:4f17523b-0239-11e9-b8bf-42010a800002,ResourceVersion:6935,Generation:0,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b4550 0xc0015b4551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b4750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b4770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:10.64.3.33,StartTime:2018-12-17 20:21:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://61b55c6625c22733e4ec388f738e2a4e5a526c2b11b3961a605db3cab786536e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.569: INFO: Pod "nginx-deployment-555b55d965-5kndw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5kndw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-5kndw,UID:4f0e72e2-0239-11e9-b8bf-42010a800002,ResourceVersion:6911,Generation:0,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b4850 0xc0015b4851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-6xhw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b49d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b49f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:19 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:19 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.5,PodIP:10.64.1.24,StartTime:2018-12-17 20:21:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://a28de6e55aa8eb1a6d762154a345f17dabb10491c008ee5aa8d66b6578004b6c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.569: INFO: Pod "nginx-deployment-555b55d965-694pp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-694pp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-694pp,UID:4f0852d5-0239-11e9-b8bf-42010a800002,ResourceVersion:6919,Generation:0,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b4b80 0xc0015b4b81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b4be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b4c00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.64.2.86,StartTime:2018-12-17 20:21:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://f6a5ae8ec58f56757ab2e81586d0dd746bf9bc6110db070a2d91056d7461346d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.569: INFO: Pod "nginx-deployment-555b55d965-8mnw8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8mnw8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-8mnw8,UID:52aee81f-0239-11e9-b8bf-42010a800002,ResourceVersion:7039,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b4ee0 0xc0015b4ee1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b4f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b4f80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-bmhll" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bmhll,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-bmhll,UID:52a758b0-0239-11e9-b8bf-42010a800002,ResourceVersion:7057,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b51a0 0xc0015b51a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-6xhw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b5250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b5270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:25 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:25 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.5,PodIP:10.64.1.26,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:25 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://4daea3c4f16167633c696b3896c6c017aaa7d2da1be2660e48fa1afebc90f726}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-chhfh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-chhfh,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-chhfh,UID:52b697e6-0239-11e9-b8bf-42010a800002,ResourceVersion:7041,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b5360 0xc0015b5361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b5460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b5480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-dclg7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dclg7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-dclg7,UID:52b69ef5-0239-11e9-b8bf-42010a800002,ResourceVersion:7050,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b5550 0xc0015b5551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b5690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b56b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-dgqtd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dgqtd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-dgqtd,UID:52b71320-0239-11e9-b8bf-42010a800002,ResourceVersion:7042,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b5760 0xc0015b5761}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b57f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b58b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-dztvd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-dztvd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-dztvd,UID:4f0f00d2-0239-11e9-b8bf-42010a800002,ResourceVersion:6916,Generation:0,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0015b59f0 0xc0015b59f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015b5a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015b5a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.64.2.88,StartTime:2018-12-17 20:21:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://ac822912f63bf218b5d885a4760b9b3ee6334cb1d6240c49c50a074610986f38}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-g5km8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g5km8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-g5km8,UID:52b674bf-0239-11e9-b8bf-42010a800002,ResourceVersion:7045,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc001980130 0xc001980131}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001980190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019801b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-jmz4h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jmz4h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-jmz4h,UID:4f0ac303-0239-11e9-b8bf-42010a800002,ResourceVersion:6938,Generation:0,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc001980440 0xc001980441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019804d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019804f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:10.64.3.32,StartTime:2018-12-17 20:21:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://411635e275cdc5dfb5ff6530b4e340ef9f2ae36379b27de1053af1ff5b877782}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-lxblp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lxblp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-lxblp,UID:4f17985e-0239-11e9-b8bf-42010a800002,ResourceVersion:6928,Generation:0,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0019805b0 0xc0019805b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001980660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001980680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.64.2.87,StartTime:2018-12-17 20:21:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://7efa2373a0ed457276bad8a05d65d769cf8c885dee13a502a7d3f71aa6ad737b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-nv67t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nv67t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-nv67t,UID:52a81bb6-0239-11e9-b8bf-42010a800002,ResourceVersion:7025,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0019807a0 0xc0019807a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001980a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001980a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.570: INFO: Pod "nginx-deployment-555b55d965-p8nxs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p8nxs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-p8nxs,UID:52aef84f-0239-11e9-b8bf-42010a800002,ResourceVersion:7032,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc001980cb0 0xc001980cb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-6xhw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001980d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001980d40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.5,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.571: INFO: Pod "nginx-deployment-555b55d965-pdk9g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pdk9g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-pdk9g,UID:52ad284b-0239-11e9-b8bf-42010a800002,ResourceVersion:7033,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0019810d0 0xc0019810d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001981130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001981150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.571: INFO: Pod "nginx-deployment-555b55d965-pmsfs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pmsfs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-pmsfs,UID:52a419f0-0239-11e9-b8bf-42010a800002,ResourceVersion:7008,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc001981370 0xc001981371}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019813e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001981400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.572: INFO: Pod "nginx-deployment-555b55d965-s2hdb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-s2hdb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-s2hdb,UID:52aeef5e-0239-11e9-b8bf-42010a800002,ResourceVersion:7035,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0019814c0 0xc0019814c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001981610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001981670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.574: INFO: Pod "nginx-deployment-555b55d965-z9rzm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-z9rzm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-z9rzm,UID:4f170bef-0239-11e9-b8bf-42010a800002,ResourceVersion:6925,Generation:0,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc001981720 0xc001981721}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001981780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019817a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.64.2.85,StartTime:2018-12-17 20:21:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:19 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://db6dc3c9af57791e0d1c934c4a185754cb465c2165b2661e75caf744717d8f37}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.577: INFO: Pod "nginx-deployment-555b55d965-zsgdd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zsgdd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-555b55d965-zsgdd,UID:4f0a4161-0239-11e9-b8bf-42010a800002,ResourceVersion:6922,Generation:0,CreationTimestamp:2018-12-17 20:21:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 4f02b450-0239-11e9-b8bf-42010a800002 0xc0019819e0 0xc0019819e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001981a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001981a90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:17 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.64.2.89,StartTime:2018-12-17 20:21:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-17 20:21:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df docker://e357f85a9b14064e923be84b1288783e96d119df875e9b550fde723127d4ee5d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.579: INFO: Pod "nginx-deployment-65bbdb5f8-5mmz9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5mmz9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-5mmz9,UID:52ae8100-0239-11e9-b8bf-42010a800002,ResourceVersion:7043,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc001981c50 0xc001981c51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001981f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001981f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.582: INFO: Pod "nginx-deployment-65bbdb5f8-72js7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-72js7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-72js7,UID:51704f42-0239-11e9-b8bf-42010a800002,ResourceVersion:7056,Generation:0,CreationTimestamp:2018-12-17 20:21:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc00150a240 0xc00150a241}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-6xhw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00150a2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00150a2f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.5,PodIP:,StartTime:2018-12-17 20:21:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.584: INFO: Pod "nginx-deployment-65bbdb5f8-97z4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-97z4v,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-97z4v,UID:52a92a3b-0239-11e9-b8bf-42010a800002,ResourceVersion:7021,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc00150a510 0xc00150a511}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00150a6f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00150a730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.586: INFO: Pod "nginx-deployment-65bbdb5f8-c9j55" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-c9j55,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-c9j55,UID:518d03a4-0239-11e9-b8bf-42010a800002,ResourceVersion:6975,Generation:0,CreationTimestamp:2018-12-17 20:21:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc00150a840 0xc00150a841}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00150baf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00150bb10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.589: INFO: Pod "nginx-deployment-65bbdb5f8-cqcqb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cqcqb,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-cqcqb,UID:52b68f8b-0239-11e9-b8bf-42010a800002,ResourceVersion:7046,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc00150bd80 0xc00150bd81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00150be00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00150be20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.591: INFO: Pod "nginx-deployment-65bbdb5f8-dz9pl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-dz9pl,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-dz9pl,UID:52b68806-0239-11e9-b8bf-42010a800002,ResourceVersion:7052,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc0011941c0 0xc0011941c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001194670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001194690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.593: INFO: Pod "nginx-deployment-65bbdb5f8-frwd4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-frwd4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-frwd4,UID:52aedd03-0239-11e9-b8bf-42010a800002,ResourceVersion:7037,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc0011947c0 0xc0011947c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-6xhw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001194830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001194850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.5,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.594: INFO: Pod "nginx-deployment-65bbdb5f8-hd6wk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hd6wk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-hd6wk,UID:51901dc8-0239-11e9-b8bf-42010a800002,ResourceVersion:6976,Generation:0,CreationTimestamp:2018-12-17 20:21:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc001194b00 0xc001194b01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001194d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001194d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.596: INFO: Pod "nginx-deployment-65bbdb5f8-kbz2s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-kbz2s,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-kbz2s,UID:51708392-0239-11e9-b8bf-42010a800002,ResourceVersion:6962,Generation:0,CreationTimestamp:2018-12-17 20:21:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc001194e20 0xc001194e21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001194ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001194ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.598: INFO: Pod "nginx-deployment-65bbdb5f8-mjn4c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mjn4c,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-mjn4c,UID:52c14968-0239-11e9-b8bf-42010a800002,ResourceVersion:7055,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc001194fc0 0xc001194fc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001195030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001195060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.599: INFO: Pod "nginx-deployment-65bbdb5f8-pxtrm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pxtrm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-pxtrm,UID:52b50634-0239-11e9-b8bf-42010a800002,ResourceVersion:7040,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc0011951c0 0xc0011951c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-6xhw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001195250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001195270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.5,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.601: INFO: Pod "nginx-deployment-65bbdb5f8-vvh4d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vvh4d,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-vvh4d,UID:516d7dbe-0239-11e9-b8bf-42010a800002,ResourceVersion:6960,Generation:0,CreationTimestamp:2018-12-17 20:21:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc001195350 0xc001195351}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0011953d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001195400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:21 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 17 20:21:25.603: INFO: Pod "nginx-deployment-65bbdb5f8-wfb55" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wfb55,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-btj89,SelfLink:/api/v1/namespaces/e2e-tests-deployment-btj89/pods/nginx-deployment-65bbdb5f8-wfb55,UID:52b68072-0239-11e9-b8bf-42010a800002,ResourceVersion:7053,Generation:0,CreationTimestamp:2018-12-17 20:21:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 516c4bbb-0239-11e9-b8bf-42010a800002 0xc001195500 0xc001195501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-twmtl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-twmtl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-twmtl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001195580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0011955c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:21:23 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:,StartTime:2018-12-17 20:21:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:21:25.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-btj89" for this suite.
Dec 17 20:21:33.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:21:33.708: INFO: namespace: e2e-tests-deployment-btj89, resource: bindings, ignored listing per whitelist
Dec 17 20:21:33.743: INFO: namespace e2e-tests-deployment-btj89 deletion completed in 8.134304338s

• [SLOW TEST:16.476 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:21:33.743: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 17 20:21:33.848: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-6cfcz'
Dec 17 20:21:33.945: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 20:21:33.945: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 17 20:21:33.981: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-jd69l]
Dec 17 20:21:33.981: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-jd69l" in namespace "e2e-tests-kubectl-6cfcz" to be "running and ready"
Dec 17 20:21:33.997: INFO: Pod "e2e-test-nginx-rc-jd69l": Phase="Pending", Reason="", readiness=false. Elapsed: 16.228329ms
Dec 17 20:21:36.001: INFO: Pod "e2e-test-nginx-rc-jd69l": Phase="Running", Reason="", readiness=true. Elapsed: 2.01996312s
Dec 17 20:21:36.001: INFO: Pod "e2e-test-nginx-rc-jd69l" satisfied condition "running and ready"
Dec 17 20:21:36.001: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-jd69l]
Dec 17 20:21:36.001: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6cfcz'
Dec 17 20:21:36.114: INFO: stderr: ""
Dec 17 20:21:36.114: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Dec 17 20:21:36.114: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6cfcz'
Dec 17 20:21:36.217: INFO: stderr: ""
Dec 17 20:21:36.217: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:21:36.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6cfcz" for this suite.
Dec 17 20:21:42.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:21:42.318: INFO: namespace: e2e-tests-kubectl-6cfcz, resource: bindings, ignored listing per whitelist
Dec 17 20:21:42.433: INFO: namespace e2e-tests-kubectl-6cfcz deletion completed in 6.210320658s

• [SLOW TEST:8.690 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:21:42.433: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:21:42.539: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e04ccd2-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-nwbtq" to be "success or failure"
Dec 17 20:21:42.547: INFO: Pod "downwardapi-volume-5e04ccd2-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00416ms
Dec 17 20:21:44.551: INFO: Pod "downwardapi-volume-5e04ccd2-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012653022s
STEP: Saw pod success
Dec 17 20:21:44.551: INFO: Pod "downwardapi-volume-5e04ccd2-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:21:44.554: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-5e04ccd2-0239-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:21:44.578: INFO: Waiting for pod downwardapi-volume-5e04ccd2-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:21:44.585: INFO: Pod downwardapi-volume-5e04ccd2-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:21:44.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nwbtq" for this suite.
Dec 17 20:21:50.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:21:50.967: INFO: namespace: e2e-tests-downward-api-nwbtq, resource: bindings, ignored listing per whitelist
Dec 17 20:21:50.987: INFO: namespace e2e-tests-downward-api-nwbtq deletion completed in 6.398112337s

• [SLOW TEST:8.553 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:21:50.987: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-632bbe90-0239-11e9-9892-0a580a3c54b9
Dec 17 20:21:51.185: INFO: Pod name my-hostname-basic-632bbe90-0239-11e9-9892-0a580a3c54b9: Found 0 pods out of 1
Dec 17 20:21:56.189: INFO: Pod name my-hostname-basic-632bbe90-0239-11e9-9892-0a580a3c54b9: Found 1 pods out of 1
Dec 17 20:21:56.189: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-632bbe90-0239-11e9-9892-0a580a3c54b9" are running
Dec 17 20:21:56.192: INFO: Pod "my-hostname-basic-632bbe90-0239-11e9-9892-0a580a3c54b9-zj864" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-17 20:21:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-17 20:21:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-17 20:21:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-17 20:21:51 +0000 UTC Reason: Message:}])
Dec 17 20:21:56.192: INFO: Trying to dial the pod
Dec 17 20:22:01.206: INFO: Controller my-hostname-basic-632bbe90-0239-11e9-9892-0a580a3c54b9: Got expected result from replica 1 [my-hostname-basic-632bbe90-0239-11e9-9892-0a580a3c54b9-zj864]: "my-hostname-basic-632bbe90-0239-11e9-9892-0a580a3c54b9-zj864", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:22:01.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-sb4dx" for this suite.
Dec 17 20:22:07.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:22:07.286: INFO: namespace: e2e-tests-replication-controller-sb4dx, resource: bindings, ignored listing per whitelist
Dec 17 20:22:07.334: INFO: namespace e2e-tests-replication-controller-sb4dx deletion completed in 6.124912328s

• [SLOW TEST:16.347 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:22:07.335: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec 17 20:22:07.433: INFO: Asynchronously running '/workspace/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config proxy --unix-socket=/tmp/kubectl-proxy-unix246390081/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:22:07.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wpqf8" for this suite.
Dec 17 20:22:13.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:22:14.387: INFO: namespace: e2e-tests-kubectl-wpqf8, resource: bindings, ignored listing per whitelist
Dec 17 20:22:17.478: INFO: namespace e2e-tests-kubectl-wpqf8 deletion completed in 9.978023955s

• [SLOW TEST:10.144 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:22:17.479: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 17 20:22:17.585: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-a,UID:72e40da3-0239-11e9-b8bf-42010a800002,ResourceVersion:7364,Generation:0,CreationTimestamp:2018-12-17 20:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 20:22:17.585: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-a,UID:72e40da3-0239-11e9-b8bf-42010a800002,ResourceVersion:7364,Generation:0,CreationTimestamp:2018-12-17 20:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 17 20:22:27.596: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-a,UID:72e40da3-0239-11e9-b8bf-42010a800002,ResourceVersion:7388,Generation:0,CreationTimestamp:2018-12-17 20:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 17 20:22:27.596: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-a,UID:72e40da3-0239-11e9-b8bf-42010a800002,ResourceVersion:7388,Generation:0,CreationTimestamp:2018-12-17 20:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 17 20:22:37.606: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-a,UID:72e40da3-0239-11e9-b8bf-42010a800002,ResourceVersion:7409,Generation:0,CreationTimestamp:2018-12-17 20:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 20:22:37.606: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-a,UID:72e40da3-0239-11e9-b8bf-42010a800002,ResourceVersion:7409,Generation:0,CreationTimestamp:2018-12-17 20:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 17 20:22:47.613: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-a,UID:72e40da3-0239-11e9-b8bf-42010a800002,ResourceVersion:7430,Generation:0,CreationTimestamp:2018-12-17 20:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 20:22:47.613: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-a,UID:72e40da3-0239-11e9-b8bf-42010a800002,ResourceVersion:7430,Generation:0,CreationTimestamp:2018-12-17 20:22:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 17 20:22:57.623: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-b,UID:8ac0cc5c-0239-11e9-b8bf-42010a800002,ResourceVersion:7451,Generation:0,CreationTimestamp:2018-12-17 20:22:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 20:22:57.623: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-b,UID:8ac0cc5c-0239-11e9-b8bf-42010a800002,ResourceVersion:7451,Generation:0,CreationTimestamp:2018-12-17 20:22:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 17 20:23:07.630: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-b,UID:8ac0cc5c-0239-11e9-b8bf-42010a800002,ResourceVersion:7472,Generation:0,CreationTimestamp:2018-12-17 20:22:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 20:23:07.630: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-lrr2f,SelfLink:/api/v1/namespaces/e2e-tests-watch-lrr2f/configmaps/e2e-watch-test-configmap-b,UID:8ac0cc5c-0239-11e9-b8bf-42010a800002,ResourceVersion:7472,Generation:0,CreationTimestamp:2018-12-17 20:22:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:23:17.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-lrr2f" for this suite.
Dec 17 20:23:23.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:23:23.724: INFO: namespace: e2e-tests-watch-lrr2f, resource: bindings, ignored listing per whitelist
Dec 17 20:23:23.777: INFO: namespace e2e-tests-watch-lrr2f deletion completed in 6.141359484s

• [SLOW TEST:66.298 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:23:23.777: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-cglv
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 20:23:23.893: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-cglv" in namespace "e2e-tests-subpath-8kv5t" to be "success or failure"
Dec 17 20:23:23.901: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Pending", Reason="", readiness=false. Elapsed: 7.21795ms
Dec 17 20:23:25.904: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011083054s
Dec 17 20:23:27.913: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 4.019420027s
Dec 17 20:23:29.917: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 6.023706772s
Dec 17 20:23:31.921: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 8.02732195s
Dec 17 20:23:33.924: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 10.030785309s
Dec 17 20:23:35.929: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 12.035308827s
Dec 17 20:23:37.934: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 14.040635262s
Dec 17 20:23:39.939: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 16.045483666s
Dec 17 20:23:41.946: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 18.053117559s
Dec 17 20:23:43.950: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 20.05687883s
Dec 17 20:23:45.954: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Running", Reason="", readiness=false. Elapsed: 22.060679583s
Dec 17 20:23:47.960: INFO: Pod "pod-subpath-test-projected-cglv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.066635515s
STEP: Saw pod success
Dec 17 20:23:47.960: INFO: Pod "pod-subpath-test-projected-cglv" satisfied condition "success or failure"
Dec 17 20:23:47.976: INFO: Trying to get logs from node bootstrap-e2e-minion-group-tnzf pod pod-subpath-test-projected-cglv container test-container-subpath-projected-cglv: <nil>
STEP: delete the pod
Dec 17 20:23:48.004: INFO: Waiting for pod pod-subpath-test-projected-cglv to disappear
Dec 17 20:23:48.007: INFO: Pod pod-subpath-test-projected-cglv no longer exists
STEP: Deleting pod pod-subpath-test-projected-cglv
Dec 17 20:23:48.007: INFO: Deleting pod "pod-subpath-test-projected-cglv" in namespace "e2e-tests-subpath-8kv5t"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:23:48.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8kv5t" for this suite.
Dec 17 20:23:54.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:23:54.109: INFO: namespace: e2e-tests-subpath-8kv5t, resource: bindings, ignored listing per whitelist
Dec 17 20:23:54.149: INFO: namespace e2e-tests-subpath-8kv5t deletion completed in 6.135565105s

• [SLOW TEST:30.372 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:23:54.149: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:23:58.295: INFO: Waiting up to 5m0s for pod "client-envvars-aeef9644-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-pods-qqb7d" to be "success or failure"
Dec 17 20:23:58.311: INFO: Pod "client-envvars-aeef9644-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.597283ms
Dec 17 20:24:00.314: INFO: Pod "client-envvars-aeef9644-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019003313s
STEP: Saw pod success
Dec 17 20:24:00.314: INFO: Pod "client-envvars-aeef9644-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:24:00.317: INFO: Trying to get logs from node bootstrap-e2e-minion-group-tnzf pod client-envvars-aeef9644-0239-11e9-9892-0a580a3c54b9 container env3cont: <nil>
STEP: delete the pod
Dec 17 20:24:00.342: INFO: Waiting for pod client-envvars-aeef9644-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:24:00.346: INFO: Pod client-envvars-aeef9644-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:24:00.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qqb7d" for this suite.
Dec 17 20:24:40.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:24:40.431: INFO: namespace: e2e-tests-pods-qqb7d, resource: bindings, ignored listing per whitelist
Dec 17 20:24:40.486: INFO: namespace e2e-tests-pods-qqb7d deletion completed in 40.135001186s

• [SLOW TEST:46.337 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:24:40.487: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec 17 20:24:40.587: INFO: Asynchronously running '/workspace/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:24:40.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-26qnc" for this suite.
Dec 17 20:24:46.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:24:46.840: INFO: namespace: e2e-tests-kubectl-26qnc, resource: bindings, ignored listing per whitelist
Dec 17 20:24:46.882: INFO: namespace e2e-tests-kubectl-26qnc deletion completed in 6.208692378s

• [SLOW TEST:6.395 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:24:46.882: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 17 20:24:47.005: INFO: Waiting up to 5m0s for pod "downward-api-cbf83faf-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-lswgc" to be "success or failure"
Dec 17 20:24:47.011: INFO: Pod "downward-api-cbf83faf-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.139781ms
Dec 17 20:24:49.015: INFO: Pod "downward-api-cbf83faf-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009358293s
Dec 17 20:24:51.019: INFO: Pod "downward-api-cbf83faf-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013122308s
STEP: Saw pod success
Dec 17 20:24:51.019: INFO: Pod "downward-api-cbf83faf-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:24:51.022: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downward-api-cbf83faf-0239-11e9-9892-0a580a3c54b9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 20:24:51.057: INFO: Waiting for pod downward-api-cbf83faf-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:24:51.061: INFO: Pod downward-api-cbf83faf-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:24:51.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lswgc" for this suite.
Dec 17 20:24:57.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:24:57.300: INFO: namespace: e2e-tests-downward-api-lswgc, resource: bindings, ignored listing per whitelist
Dec 17 20:24:57.315: INFO: namespace e2e-tests-downward-api-lswgc deletion completed in 6.250259359s

• [SLOW TEST:10.433 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:24:57.315: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 17 20:24:57.438: INFO: Waiting up to 5m0s for pod "pod-d2304f3c-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-tv7xl" to be "success or failure"
Dec 17 20:24:57.455: INFO: Pod "pod-d2304f3c-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.892315ms
Dec 17 20:24:59.459: INFO: Pod "pod-d2304f3c-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021394658s
STEP: Saw pod success
Dec 17 20:24:59.459: INFO: Pod "pod-d2304f3c-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:24:59.463: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-d2304f3c-0239-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:24:59.501: INFO: Waiting for pod pod-d2304f3c-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:24:59.511: INFO: Pod pod-d2304f3c-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:24:59.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tv7xl" for this suite.
Dec 17 20:25:05.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:25:05.706: INFO: namespace: e2e-tests-emptydir-tv7xl, resource: bindings, ignored listing per whitelist
Dec 17 20:25:05.789: INFO: namespace e2e-tests-emptydir-tv7xl deletion completed in 6.269681932s

• [SLOW TEST:8.474 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:25:05.789: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 17 20:25:05.950: INFO: Waiting up to 5m0s for pod "pod-d7426dd3-0239-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-vq5pb" to be "success or failure"
Dec 17 20:25:05.962: INFO: Pod "pod-d7426dd3-0239-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.487235ms
Dec 17 20:25:07.966: INFO: Pod "pod-d7426dd3-0239-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015970878s
STEP: Saw pod success
Dec 17 20:25:07.966: INFO: Pod "pod-d7426dd3-0239-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:25:07.968: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-d7426dd3-0239-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:25:07.996: INFO: Waiting for pod pod-d7426dd3-0239-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:25:08.000: INFO: Pod pod-d7426dd3-0239-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:25:08.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vq5pb" for this suite.
Dec 17 20:25:14.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:25:14.128: INFO: namespace: e2e-tests-emptydir-vq5pb, resource: bindings, ignored listing per whitelist
Dec 17 20:25:14.133: INFO: namespace e2e-tests-emptydir-vq5pb deletion completed in 6.128675987s

• [SLOW TEST:8.344 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:25:14.133: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-82s8s
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-82s8s
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-82s8s
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-82s8s
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-82s8s
Dec 17 20:25:18.296: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-82s8s, name: ss-0, uid: de5d6e17-0239-11e9-b8bf-42010a800002, status phase: Pending. Waiting for statefulset controller to delete.
Dec 17 20:25:18.469: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-82s8s, name: ss-0, uid: de5d6e17-0239-11e9-b8bf-42010a800002, status phase: Failed. Waiting for statefulset controller to delete.
Dec 17 20:25:18.479: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-82s8s, name: ss-0, uid: de5d6e17-0239-11e9-b8bf-42010a800002, status phase: Failed. Waiting for statefulset controller to delete.
Dec 17 20:25:18.484: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-82s8s
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-82s8s
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-82s8s and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 17 20:25:22.526: INFO: Deleting all statefulset in ns e2e-tests-statefulset-82s8s
Dec 17 20:25:22.534: INFO: Scaling statefulset ss to 0
Dec 17 20:25:32.556: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:25:32.559: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:25:32.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-82s8s" for this suite.
Dec 17 20:25:38.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:25:38.831: INFO: namespace: e2e-tests-statefulset-82s8s, resource: bindings, ignored listing per whitelist
Dec 17 20:25:38.840: INFO: namespace e2e-tests-statefulset-82s8s deletion completed in 6.259313218s

• [SLOW TEST:24.707 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:25:38.840: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:25:38.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-cqddx" for this suite.
Dec 17 20:26:01.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:26:01.087: INFO: namespace: e2e-tests-kubelet-test-cqddx, resource: bindings, ignored listing per whitelist
Dec 17 20:26:01.197: INFO: namespace e2e-tests-kubelet-test-cqddx deletion completed in 22.195448997s

• [SLOW TEST:22.357 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:26:01.197: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-f844dd07-0239-11e9-9892-0a580a3c54b9
STEP: Creating secret with name s-test-opt-upd-f844dd5f-0239-11e9-9892-0a580a3c54b9
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f844dd07-0239-11e9-9892-0a580a3c54b9
STEP: Updating secret s-test-opt-upd-f844dd5f-0239-11e9-9892-0a580a3c54b9
STEP: Creating secret with name s-test-opt-create-f844dd77-0239-11e9-9892-0a580a3c54b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:27:34.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-szm2t" for this suite.
Dec 17 20:27:56.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:27:56.467: INFO: namespace: e2e-tests-secrets-szm2t, resource: bindings, ignored listing per whitelist
Dec 17 20:27:56.475: INFO: namespace e2e-tests-secrets-szm2t deletion completed in 22.197099843s

• [SLOW TEST:115.278 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:27:56.475: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zq772
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 20:27:56.575: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 20:28:18.738: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.3.49:8080/dial?request=hostName&protocol=udp&host=10.64.2.114&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-zq772 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 20:28:18.738: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 20:28:18.826: INFO: Waiting for endpoints: map[]
Dec 17 20:28:18.829: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.3.49:8080/dial?request=hostName&protocol=udp&host=10.64.1.37&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-zq772 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 20:28:18.830: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 20:28:18.919: INFO: Waiting for endpoints: map[]
Dec 17 20:28:18.922: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.3.49:8080/dial?request=hostName&protocol=udp&host=10.64.3.48&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-zq772 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 20:28:18.922: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 20:28:19.014: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:28:19.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zq772" for this suite.
Dec 17 20:28:41.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:28:41.324: INFO: namespace: e2e-tests-pod-network-test-zq772, resource: bindings, ignored listing per whitelist
Dec 17 20:28:41.324: INFO: namespace e2e-tests-pod-network-test-zq772 deletion completed in 22.305503177s

• [SLOW TEST:44.849 seconds]
[sig-network] Networking
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:28:41.324: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 17 20:28:43.987: INFO: Successfully updated pod "pod-update-activedeadlineseconds-57b5b534-023a-11e9-9892-0a580a3c54b9"
Dec 17 20:28:43.987: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-57b5b534-023a-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-pods-xr2l9" to be "terminated due to deadline exceeded"
Dec 17 20:28:43.990: INFO: Pod "pod-update-activedeadlineseconds-57b5b534-023a-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.834874ms
Dec 17 20:28:45.995: INFO: Pod "pod-update-activedeadlineseconds-57b5b534-023a-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.007777711s
Dec 17 20:28:47.998: INFO: Pod "pod-update-activedeadlineseconds-57b5b534-023a-11e9-9892-0a580a3c54b9": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.01119872s
Dec 17 20:28:47.998: INFO: Pod "pod-update-activedeadlineseconds-57b5b534-023a-11e9-9892-0a580a3c54b9" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:28:47.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xr2l9" for this suite.
Dec 17 20:28:54.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:28:54.125: INFO: namespace: e2e-tests-pods-xr2l9, resource: bindings, ignored listing per whitelist
Dec 17 20:28:54.134: INFO: namespace e2e-tests-pods-xr2l9 deletion completed in 6.131217504s

• [SLOW TEST:12.809 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:28:54.134: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec 17 20:28:54.266: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config api-versions'
Dec 17 20:28:54.487: INFO: stderr: ""
Dec 17 20:28:54.487: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscalingpolicy.kope.io/v1alpha1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:28:54.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-csvh6" for this suite.
Dec 17 20:29:00.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:29:00.678: INFO: namespace: e2e-tests-kubectl-csvh6, resource: bindings, ignored listing per whitelist
Dec 17 20:29:00.681: INFO: namespace e2e-tests-kubectl-csvh6 deletion completed in 6.1893042s

• [SLOW TEST:6.547 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:29:00.681: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:29:00.777: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config version'
Dec 17 20:29:02.128: INFO: stderr: ""
Dec 17 20:29:02.128: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.1\", GitCommit:\"eec55b9ba98609a46fee712359c7b5b365bdd920\", GitTreeState:\"clean\", BuildDate:\"2018-12-13T10:39:04Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.1\", GitCommit:\"eec55b9ba98609a46fee712359c7b5b365bdd920\", GitTreeState:\"clean\", BuildDate:\"2018-12-13T10:31:33Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:29:02.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6zfkk" for this suite.
Dec 17 20:29:08.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:29:08.186: INFO: namespace: e2e-tests-kubectl-6zfkk, resource: bindings, ignored listing per whitelist
Dec 17 20:29:08.261: INFO: namespace e2e-tests-kubectl-6zfkk deletion completed in 6.129599898s

• [SLOW TEST:7.581 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:29:08.262: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 17 20:29:08.366: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:29:13.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-t6g4v" for this suite.
Dec 17 20:29:35.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:29:35.126: INFO: namespace: e2e-tests-init-container-t6g4v, resource: bindings, ignored listing per whitelist
Dec 17 20:29:35.245: INFO: namespace e2e-tests-init-container-t6g4v deletion completed in 22.232003542s

• [SLOW TEST:26.984 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:29:35.245: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 17 20:29:39.434: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 20:29:39.437: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 20:29:41.438: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 20:29:41.451: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 20:29:43.438: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 20:29:43.441: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:29:43.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jqjjf" for this suite.
Dec 17 20:30:05.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:30:05.640: INFO: namespace: e2e-tests-container-lifecycle-hook-jqjjf, resource: bindings, ignored listing per whitelist
Dec 17 20:30:05.667: INFO: namespace e2e-tests-container-lifecycle-hook-jqjjf deletion completed in 22.222113694s

• [SLOW TEST:30.422 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:30:05.667: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 17 20:30:08.850: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:30:09.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-wrjnt" for this suite.
Dec 17 20:30:31.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:30:32.016: INFO: namespace: e2e-tests-replicaset-wrjnt, resource: bindings, ignored listing per whitelist
Dec 17 20:30:32.039: INFO: namespace e2e-tests-replicaset-wrjnt deletion completed in 22.156818983s

• [SLOW TEST:26.372 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:30:32.040: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-99b5a44d-023a-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:30:32.188: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-99b67bcd-023a-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-b4krk" to be "success or failure"
Dec 17 20:30:32.193: INFO: Pod "pod-projected-configmaps-99b67bcd-023a-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.56205ms
Dec 17 20:30:34.200: INFO: Pod "pod-projected-configmaps-99b67bcd-023a-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011687262s
STEP: Saw pod success
Dec 17 20:30:34.200: INFO: Pod "pod-projected-configmaps-99b67bcd-023a-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:30:34.203: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-configmaps-99b67bcd-023a-11e9-9892-0a580a3c54b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:30:34.235: INFO: Waiting for pod pod-projected-configmaps-99b67bcd-023a-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:30:34.239: INFO: Pod pod-projected-configmaps-99b67bcd-023a-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:30:34.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b4krk" for this suite.
Dec 17 20:30:40.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:30:40.333: INFO: namespace: e2e-tests-projected-b4krk, resource: bindings, ignored listing per whitelist
Dec 17 20:30:40.369: INFO: namespace e2e-tests-projected-b4krk deletion completed in 6.126378506s

• [SLOW TEST:8.330 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:30:40.369: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:30:40.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-tgp2j" for this suite.
Dec 17 20:30:46.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:30:46.597: INFO: namespace: e2e-tests-services-tgp2j, resource: bindings, ignored listing per whitelist
Dec 17 20:30:46.635: INFO: namespace e2e-tests-services-tgp2j deletion completed in 6.118338446s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.265 seconds]
[sig-network] Services
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:30:46.635: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a272fcea-023a-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:30:46.849: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a273e86a-023a-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-xn7hr" to be "success or failure"
Dec 17 20:30:46.861: INFO: Pod "pod-projected-secrets-a273e86a-023a-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.349695ms
Dec 17 20:30:48.870: INFO: Pod "pod-projected-secrets-a273e86a-023a-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021009418s
STEP: Saw pod success
Dec 17 20:30:48.870: INFO: Pod "pod-projected-secrets-a273e86a-023a-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:30:48.875: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-secrets-a273e86a-023a-11e9-9892-0a580a3c54b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:30:48.912: INFO: Waiting for pod pod-projected-secrets-a273e86a-023a-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:30:48.917: INFO: Pod pod-projected-secrets-a273e86a-023a-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:30:48.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xn7hr" for this suite.
Dec 17 20:30:54.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:30:55.046: INFO: namespace: e2e-tests-projected-xn7hr, resource: bindings, ignored listing per whitelist
Dec 17 20:30:55.075: INFO: namespace e2e-tests-projected-xn7hr deletion completed in 6.154950962s

• [SLOW TEST:8.440 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:30:55.076: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-a7718b0d-023a-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:30:55.227: INFO: Waiting up to 5m0s for pod "pod-configmaps-a7727b34-023a-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-9zjf5" to be "success or failure"
Dec 17 20:30:55.238: INFO: Pod "pod-configmaps-a7727b34-023a-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.570234ms
Dec 17 20:30:57.242: INFO: Pod "pod-configmaps-a7727b34-023a-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015383019s
STEP: Saw pod success
Dec 17 20:30:57.242: INFO: Pod "pod-configmaps-a7727b34-023a-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:30:57.245: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-a7727b34-023a-11e9-9892-0a580a3c54b9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:30:57.281: INFO: Waiting for pod pod-configmaps-a7727b34-023a-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:30:57.286: INFO: Pod pod-configmaps-a7727b34-023a-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:30:57.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9zjf5" for this suite.
Dec 17 20:31:03.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:31:03.392: INFO: namespace: e2e-tests-configmap-9zjf5, resource: bindings, ignored listing per whitelist
Dec 17 20:31:03.446: INFO: namespace e2e-tests-configmap-9zjf5 deletion completed in 6.155302263s

• [SLOW TEST:8.370 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:31:03.446: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hrwb6
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-hrwb6
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-hrwb6
Dec 17 20:31:03.574: INFO: Found 0 stateful pods, waiting for 1
Dec 17 20:31:13.580: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 17 20:31:13.583: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-hrwb6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:31:13.758: INFO: stderr: ""
Dec 17 20:31:13.758: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:31:13.758: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:31:13.763: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 17 20:31:23.768: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 20:31:23.768: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:31:23.796: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999266s
Dec 17 20:31:24.800: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.987608587s
Dec 17 20:31:25.804: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.983560156s
Dec 17 20:31:26.807: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.979944769s
Dec 17 20:31:27.811: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.975828345s
Dec 17 20:31:28.815: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.972169485s
Dec 17 20:31:29.820: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.968186836s
Dec 17 20:31:30.825: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.963056173s
Dec 17 20:31:31.828: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959015263s
Dec 17 20:31:32.832: INFO: Verifying statefulset ss doesn't scale past 1 for another 955.215884ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-hrwb6
Dec 17 20:31:33.836: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-hrwb6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:31:34.008: INFO: stderr: ""
Dec 17 20:31:34.008: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:31:34.008: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 17 20:31:34.011: INFO: Found 1 stateful pods, waiting for 3
Dec 17 20:31:44.016: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:31:44.016: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:31:44.016: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 17 20:31:44.023: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-hrwb6 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:31:44.199: INFO: stderr: ""
Dec 17 20:31:44.199: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:31:44.199: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:31:44.199: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-hrwb6 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:31:44.365: INFO: stderr: ""
Dec 17 20:31:44.365: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:31:44.365: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:31:44.366: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-hrwb6 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:31:44.554: INFO: stderr: ""
Dec 17 20:31:44.554: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:31:44.554: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:31:44.554: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:31:44.557: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 17 20:31:54.566: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 20:31:54.566: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 20:31:54.566: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 20:31:54.581: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999478s
Dec 17 20:31:55.585: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994620982s
Dec 17 20:31:56.590: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990112098s
Dec 17 20:31:57.594: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985703006s
Dec 17 20:31:58.600: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981488545s
Dec 17 20:31:59.604: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975934141s
Dec 17 20:32:00.608: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971738467s
Dec 17 20:32:01.614: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967285762s
Dec 17 20:32:02.619: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961270934s
Dec 17 20:32:03.622: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.073217ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-hrwb6
Dec 17 20:32:04.626: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-hrwb6 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:32:04.791: INFO: stderr: ""
Dec 17 20:32:04.792: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:32:04.792: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 17 20:32:04.792: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-hrwb6 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:32:04.968: INFO: stderr: ""
Dec 17 20:32:04.968: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:32:04.968: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 17 20:32:04.968: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-hrwb6 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:32:05.166: INFO: stderr: ""
Dec 17 20:32:05.166: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:32:05.166: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 17 20:32:05.166: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 17 20:32:25.193: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hrwb6
Dec 17 20:32:25.197: INFO: Scaling statefulset ss to 0
Dec 17 20:32:25.208: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:32:25.211: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:32:25.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hrwb6" for this suite.
Dec 17 20:32:31.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:32:31.375: INFO: namespace: e2e-tests-statefulset-hrwb6, resource: bindings, ignored listing per whitelist
Dec 17 20:32:31.386: INFO: namespace e2e-tests-statefulset-hrwb6 deletion completed in 6.14740459s

• [SLOW TEST:87.941 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:32:31.387: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-5skq7/secret-test-e0d97984-023a-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:32:31.536: INFO: Waiting up to 5m0s for pod "pod-configmaps-e0da516a-023a-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-5skq7" to be "success or failure"
Dec 17 20:32:31.546: INFO: Pod "pod-configmaps-e0da516a-023a-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.983965ms
Dec 17 20:32:33.549: INFO: Pod "pod-configmaps-e0da516a-023a-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013267802s
Dec 17 20:32:35.552: INFO: Pod "pod-configmaps-e0da516a-023a-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016618934s
STEP: Saw pod success
Dec 17 20:32:35.552: INFO: Pod "pod-configmaps-e0da516a-023a-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:32:35.555: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-e0da516a-023a-11e9-9892-0a580a3c54b9 container env-test: <nil>
STEP: delete the pod
Dec 17 20:32:35.582: INFO: Waiting for pod pod-configmaps-e0da516a-023a-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:32:35.586: INFO: Pod pod-configmaps-e0da516a-023a-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:32:35.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5skq7" for this suite.
Dec 17 20:32:41.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:32:41.717: INFO: namespace: e2e-tests-secrets-5skq7, resource: bindings, ignored listing per whitelist
Dec 17 20:32:41.780: INFO: namespace e2e-tests-secrets-5skq7 deletion completed in 6.190891534s

• [SLOW TEST:10.393 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:32:41.780: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:32:41.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e705d7d9-023a-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-jglkr" to be "success or failure"
Dec 17 20:32:41.903: INFO: Pod "downwardapi-volume-e705d7d9-023a-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.632888ms
Dec 17 20:32:43.906: INFO: Pod "downwardapi-volume-e705d7d9-023a-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.015337733s
Dec 17 20:32:45.910: INFO: Pod "downwardapi-volume-e705d7d9-023a-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019507525s
STEP: Saw pod success
Dec 17 20:32:45.911: INFO: Pod "downwardapi-volume-e705d7d9-023a-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:32:45.913: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-e705d7d9-023a-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:32:45.939: INFO: Waiting for pod downwardapi-volume-e705d7d9-023a-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:32:45.944: INFO: Pod downwardapi-volume-e705d7d9-023a-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:32:45.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jglkr" for this suite.
Dec 17 20:32:51.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:32:51.987: INFO: namespace: e2e-tests-downward-api-jglkr, resource: bindings, ignored listing per whitelist
Dec 17 20:32:52.090: INFO: namespace e2e-tests-downward-api-jglkr deletion completed in 6.142499785s

• [SLOW TEST:10.309 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:32:52.090: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 17 20:32:52.197: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ht5rt'
Dec 17 20:32:54.923: INFO: stderr: ""
Dec 17 20:32:54.923: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Dec 17 20:32:54.931: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ht5rt'
Dec 17 20:32:59.173: INFO: stderr: ""
Dec 17 20:32:59.173: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:32:59.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ht5rt" for this suite.
Dec 17 20:33:05.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:33:05.373: INFO: namespace: e2e-tests-kubectl-ht5rt, resource: bindings, ignored listing per whitelist
Dec 17 20:33:05.403: INFO: namespace e2e-tests-kubectl-ht5rt deletion completed in 6.217225999s

• [SLOW TEST:13.314 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:33:05.404: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec 17 20:33:09.577: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:33:31.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-l5ngt" for this suite.
Dec 17 20:33:37.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:33:37.728: INFO: namespace: e2e-tests-namespaces-l5ngt, resource: bindings, ignored listing per whitelist
Dec 17 20:33:37.778: INFO: namespace e2e-tests-namespaces-l5ngt deletion completed in 6.134843433s
STEP: Destroying namespace "e2e-tests-nsdeletetest-4b4lr" for this suite.
Dec 17 20:33:37.781: INFO: Namespace e2e-tests-nsdeletetest-4b4lr was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-f2ktt" for this suite.
Dec 17 20:33:43.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:33:43.922: INFO: namespace: e2e-tests-nsdeletetest-f2ktt, resource: bindings, ignored listing per whitelist
Dec 17 20:33:44.040: INFO: namespace e2e-tests-nsdeletetest-f2ktt deletion completed in 6.259758538s

• [SLOW TEST:38.637 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:33:44.041: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec 17 20:33:44.150: INFO: Waiting up to 5m0s for pod "client-containers-0c22565e-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-containers-7ptk5" to be "success or failure"
Dec 17 20:33:44.160: INFO: Pod "client-containers-0c22565e-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.640601ms
Dec 17 20:33:46.168: INFO: Pod "client-containers-0c22565e-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018023213s
Dec 17 20:33:48.172: INFO: Pod "client-containers-0c22565e-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021951173s
STEP: Saw pod success
Dec 17 20:33:48.172: INFO: Pod "client-containers-0c22565e-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:33:48.176: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod client-containers-0c22565e-023b-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:33:48.196: INFO: Waiting for pod client-containers-0c22565e-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:33:48.204: INFO: Pod client-containers-0c22565e-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:33:48.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7ptk5" for this suite.
Dec 17 20:33:54.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:33:54.358: INFO: namespace: e2e-tests-containers-7ptk5, resource: bindings, ignored listing per whitelist
Dec 17 20:33:54.372: INFO: namespace e2e-tests-containers-7ptk5 deletion completed in 6.164234619s

• [SLOW TEST:10.331 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:33:54.372: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:33:54.487: INFO: Waiting up to 5m0s for pod "downwardapi-volume-124b1f9a-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-8n9rg" to be "success or failure"
Dec 17 20:33:54.491: INFO: Pod "downwardapi-volume-124b1f9a-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.790911ms
Dec 17 20:33:56.495: INFO: Pod "downwardapi-volume-124b1f9a-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00837471s
Dec 17 20:33:58.499: INFO: Pod "downwardapi-volume-124b1f9a-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012084519s
STEP: Saw pod success
Dec 17 20:33:58.499: INFO: Pod "downwardapi-volume-124b1f9a-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:33:58.502: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-124b1f9a-023b-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:33:58.535: INFO: Waiting for pod downwardapi-volume-124b1f9a-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:33:58.538: INFO: Pod downwardapi-volume-124b1f9a-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:33:58.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8n9rg" for this suite.
Dec 17 20:34:04.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:34:04.696: INFO: namespace: e2e-tests-downward-api-8n9rg, resource: bindings, ignored listing per whitelist
Dec 17 20:34:04.750: INFO: namespace e2e-tests-downward-api-8n9rg deletion completed in 6.208244254s

• [SLOW TEST:10.378 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:34:04.750: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1887954b-023b-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:34:04.992: INFO: Waiting up to 5m0s for pod "pod-secrets-188e407b-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-jzmgl" to be "success or failure"
Dec 17 20:34:05.005: INFO: Pod "pod-secrets-188e407b-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.292328ms
Dec 17 20:34:07.009: INFO: Pod "pod-secrets-188e407b-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016748554s
STEP: Saw pod success
Dec 17 20:34:07.009: INFO: Pod "pod-secrets-188e407b-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:34:07.012: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-secrets-188e407b-023b-11e9-9892-0a580a3c54b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:34:07.039: INFO: Waiting for pod pod-secrets-188e407b-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:34:07.044: INFO: Pod pod-secrets-188e407b-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:34:07.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jzmgl" for this suite.
Dec 17 20:34:13.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:34:13.201: INFO: namespace: e2e-tests-secrets-jzmgl, resource: bindings, ignored listing per whitelist
Dec 17 20:34:13.264: INFO: namespace e2e-tests-secrets-jzmgl deletion completed in 6.217257247s
STEP: Destroying namespace "e2e-tests-secret-namespace-xhzrz" for this suite.
Dec 17 20:34:19.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:34:19.348: INFO: namespace: e2e-tests-secret-namespace-xhzrz, resource: bindings, ignored listing per whitelist
Dec 17 20:34:19.391: INFO: namespace e2e-tests-secret-namespace-xhzrz deletion completed in 6.12672802s

• [SLOW TEST:14.641 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:34:19.391: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 17 20:34:19.499: INFO: Waiting up to 5m0s for pod "pod-2133e764-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-z9wxc" to be "success or failure"
Dec 17 20:34:19.512: INFO: Pod "pod-2133e764-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.255462ms
Dec 17 20:34:21.516: INFO: Pod "pod-2133e764-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016333419s
STEP: Saw pod success
Dec 17 20:34:21.516: INFO: Pod "pod-2133e764-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:34:21.522: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-2133e764-023b-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:34:21.551: INFO: Waiting for pod pod-2133e764-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:34:21.556: INFO: Pod pod-2133e764-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:34:21.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z9wxc" for this suite.
Dec 17 20:34:27.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:34:27.632: INFO: namespace: e2e-tests-emptydir-z9wxc, resource: bindings, ignored listing per whitelist
Dec 17 20:34:27.714: INFO: namespace e2e-tests-emptydir-z9wxc deletion completed in 6.150669575s

• [SLOW TEST:8.323 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:34:27.714: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:34:27.838: INFO: Waiting up to 5m0s for pod "downwardapi-volume-262be051-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-8wbsx" to be "success or failure"
Dec 17 20:34:27.852: INFO: Pod "downwardapi-volume-262be051-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.959785ms
Dec 17 20:34:29.856: INFO: Pod "downwardapi-volume-262be051-023b-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.017859859s
Dec 17 20:34:31.860: INFO: Pod "downwardapi-volume-262be051-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022134551s
STEP: Saw pod success
Dec 17 20:34:31.860: INFO: Pod "downwardapi-volume-262be051-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:34:31.863: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-262be051-023b-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:34:31.892: INFO: Waiting for pod downwardapi-volume-262be051-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:34:31.896: INFO: Pod downwardapi-volume-262be051-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:34:31.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8wbsx" for this suite.
Dec 17 20:34:37.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:34:37.949: INFO: namespace: e2e-tests-downward-api-8wbsx, resource: bindings, ignored listing per whitelist
Dec 17 20:34:38.120: INFO: namespace e2e-tests-downward-api-8wbsx deletion completed in 6.219469716s

• [SLOW TEST:10.406 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:34:38.120: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-2c62c4c1-023b-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:34:38.273: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2c63d755-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-lcm89" to be "success or failure"
Dec 17 20:34:38.277: INFO: Pod "pod-projected-secrets-2c63d755-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.589204ms
Dec 17 20:34:40.281: INFO: Pod "pod-projected-secrets-2c63d755-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00765061s
Dec 17 20:34:42.285: INFO: Pod "pod-projected-secrets-2c63d755-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011560442s
STEP: Saw pod success
Dec 17 20:34:42.285: INFO: Pod "pod-projected-secrets-2c63d755-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:34:42.289: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-secrets-2c63d755-023b-11e9-9892-0a580a3c54b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:34:42.316: INFO: Waiting for pod pod-projected-secrets-2c63d755-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:34:42.322: INFO: Pod pod-projected-secrets-2c63d755-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:34:42.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lcm89" for this suite.
Dec 17 20:34:48.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:34:48.485: INFO: namespace: e2e-tests-projected-lcm89, resource: bindings, ignored listing per whitelist
Dec 17 20:34:48.512: INFO: namespace e2e-tests-projected-lcm89 deletion completed in 6.185545575s

• [SLOW TEST:10.392 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:34:48.512: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3291a8b8-023b-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:34:48.640: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-32925ea2-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-6gf7s" to be "success or failure"
Dec 17 20:34:48.653: INFO: Pod "pod-projected-configmaps-32925ea2-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.811024ms
Dec 17 20:34:50.656: INFO: Pod "pod-projected-configmaps-32925ea2-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01595475s
Dec 17 20:34:52.661: INFO: Pod "pod-projected-configmaps-32925ea2-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021181582s
STEP: Saw pod success
Dec 17 20:34:52.661: INFO: Pod "pod-projected-configmaps-32925ea2-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:34:52.666: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-configmaps-32925ea2-023b-11e9-9892-0a580a3c54b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:34:52.697: INFO: Waiting for pod pod-projected-configmaps-32925ea2-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:34:52.707: INFO: Pod pod-projected-configmaps-32925ea2-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:34:52.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6gf7s" for this suite.
Dec 17 20:34:58.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:34:58.872: INFO: namespace: e2e-tests-projected-6gf7s, resource: bindings, ignored listing per whitelist
Dec 17 20:34:58.874: INFO: namespace e2e-tests-projected-6gf7s deletion completed in 6.162150361s

• [SLOW TEST:10.362 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:34:58.874: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:34:58.994: INFO: (0) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.546702ms)
Dec 17 20:34:58.999: INFO: (1) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.966493ms)
Dec 17 20:34:59.005: INFO: (2) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.728213ms)
Dec 17 20:34:59.010: INFO: (3) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.457999ms)
Dec 17 20:34:59.016: INFO: (4) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.371719ms)
Dec 17 20:34:59.021: INFO: (5) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.186711ms)
Dec 17 20:34:59.027: INFO: (6) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.08617ms)
Dec 17 20:34:59.033: INFO: (7) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.657868ms)
Dec 17 20:34:59.038: INFO: (8) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.185526ms)
Dec 17 20:34:59.043: INFO: (9) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.022634ms)
Dec 17 20:34:59.048: INFO: (10) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.172046ms)
Dec 17 20:34:59.054: INFO: (11) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.534627ms)
Dec 17 20:34:59.060: INFO: (12) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.538407ms)
Dec 17 20:34:59.067: INFO: (13) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.096295ms)
Dec 17 20:34:59.073: INFO: (14) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.92128ms)
Dec 17 20:34:59.079: INFO: (15) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.658268ms)
Dec 17 20:34:59.085: INFO: (16) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.796142ms)
Dec 17 20:34:59.091: INFO: (17) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.532635ms)
Dec 17 20:34:59.096: INFO: (18) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.962423ms)
Dec 17 20:34:59.101: INFO: (19) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.107637ms)
[AfterEach] version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:34:59.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-dkxfx" for this suite.
Dec 17 20:35:05.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:35:05.214: INFO: namespace: e2e-tests-proxy-dkxfx, resource: bindings, ignored listing per whitelist
Dec 17 20:35:05.282: INFO: namespace e2e-tests-proxy-dkxfx deletion completed in 6.174569194s

• [SLOW TEST:6.408 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:35:05.282: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:35:05.429: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3c93f23a-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-zkc78" to be "success or failure"
Dec 17 20:35:05.448: INFO: Pod "downwardapi-volume-3c93f23a-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 19.371279ms
Dec 17 20:35:07.454: INFO: Pod "downwardapi-volume-3c93f23a-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025244647s
Dec 17 20:35:09.457: INFO: Pod "downwardapi-volume-3c93f23a-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028677404s
STEP: Saw pod success
Dec 17 20:35:09.457: INFO: Pod "downwardapi-volume-3c93f23a-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:35:09.460: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-3c93f23a-023b-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:35:09.484: INFO: Waiting for pod downwardapi-volume-3c93f23a-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:35:09.488: INFO: Pod downwardapi-volume-3c93f23a-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:35:09.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zkc78" for this suite.
Dec 17 20:35:15.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:35:15.794: INFO: namespace: e2e-tests-downward-api-zkc78, resource: bindings, ignored listing per whitelist
Dec 17 20:35:15.804: INFO: namespace e2e-tests-downward-api-zkc78 deletion completed in 6.312325194s

• [SLOW TEST:10.521 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:35:15.804: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 17 20:35:16.266: INFO: Pod name wrapped-volume-race-43074d73-023b-11e9-9892-0a580a3c54b9: Found 0 pods out of 5
Dec 17 20:35:21.272: INFO: Pod name wrapped-volume-race-43074d73-023b-11e9-9892-0a580a3c54b9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-43074d73-023b-11e9-9892-0a580a3c54b9 in namespace e2e-tests-emptydir-wrapper-l6f54, will wait for the garbage collector to delete the pods
Dec 17 20:35:33.358: INFO: Deleting ReplicationController wrapped-volume-race-43074d73-023b-11e9-9892-0a580a3c54b9 took: 11.000938ms
Dec 17 20:35:33.458: INFO: Terminating ReplicationController wrapped-volume-race-43074d73-023b-11e9-9892-0a580a3c54b9 pods took: 100.325435ms
STEP: Creating RC which spawns configmap-volume pods
Dec 17 20:36:18.681: INFO: Pod name wrapped-volume-race-683bd18e-023b-11e9-9892-0a580a3c54b9: Found 0 pods out of 5
Dec 17 20:36:23.687: INFO: Pod name wrapped-volume-race-683bd18e-023b-11e9-9892-0a580a3c54b9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-683bd18e-023b-11e9-9892-0a580a3c54b9 in namespace e2e-tests-emptydir-wrapper-l6f54, will wait for the garbage collector to delete the pods
Dec 17 20:36:33.776: INFO: Deleting ReplicationController wrapped-volume-race-683bd18e-023b-11e9-9892-0a580a3c54b9 took: 13.348695ms
Dec 17 20:36:33.876: INFO: Terminating ReplicationController wrapped-volume-race-683bd18e-023b-11e9-9892-0a580a3c54b9 pods took: 100.382117ms
STEP: Creating RC which spawns configmap-volume pods
Dec 17 20:37:18.312: INFO: Pod name wrapped-volume-race-8bc4db17-023b-11e9-9892-0a580a3c54b9: Found 0 pods out of 5
Dec 17 20:37:23.318: INFO: Pod name wrapped-volume-race-8bc4db17-023b-11e9-9892-0a580a3c54b9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8bc4db17-023b-11e9-9892-0a580a3c54b9 in namespace e2e-tests-emptydir-wrapper-l6f54, will wait for the garbage collector to delete the pods
Dec 17 20:37:35.414: INFO: Deleting ReplicationController wrapped-volume-race-8bc4db17-023b-11e9-9892-0a580a3c54b9 took: 17.001536ms
Dec 17 20:37:35.514: INFO: Terminating ReplicationController wrapped-volume-race-8bc4db17-023b-11e9-9892-0a580a3c54b9 pods took: 100.331391ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:38:19.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-l6f54" for this suite.
Dec 17 20:38:27.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:38:27.605: INFO: namespace: e2e-tests-emptydir-wrapper-l6f54, resource: bindings, ignored listing per whitelist
Dec 17 20:38:27.699: INFO: namespace e2e-tests-emptydir-wrapper-l6f54 deletion completed in 8.146995126s

• [SLOW TEST:191.895 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:38:27.699: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:38:43.839: INFO: Container started at 2018-12-17 20:38:28 +0000 UTC, pod became ready at 2018-12-17 20:38:43 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:38:43.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4txbf" for this suite.
Dec 17 20:39:05.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:39:05.973: INFO: namespace: e2e-tests-container-probe-4txbf, resource: bindings, ignored listing per whitelist
Dec 17 20:39:05.978: INFO: namespace e2e-tests-container-probe-4txbf deletion completed in 22.134691742s

• [SLOW TEST:38.279 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:39:05.979: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 17 20:39:08.654: INFO: Successfully updated pod "labelsupdatecc09bb25-023b-11e9-9892-0a580a3c54b9"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:39:12.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rxm5c" for this suite.
Dec 17 20:39:34.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:39:34.833: INFO: namespace: e2e-tests-downward-api-rxm5c, resource: bindings, ignored listing per whitelist
Dec 17 20:39:34.878: INFO: namespace e2e-tests-downward-api-rxm5c deletion completed in 22.173948087s

• [SLOW TEST:28.899 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:39:34.878: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec 17 20:39:35.018: INFO: Waiting up to 5m0s for pod "client-containers-dd400dff-023b-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-containers-gv4xv" to be "success or failure"
Dec 17 20:39:35.022: INFO: Pod "client-containers-dd400dff-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021646ms
Dec 17 20:39:37.026: INFO: Pod "client-containers-dd400dff-023b-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007940041s
Dec 17 20:39:39.030: INFO: Pod "client-containers-dd400dff-023b-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012122692s
STEP: Saw pod success
Dec 17 20:39:39.030: INFO: Pod "client-containers-dd400dff-023b-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:39:39.034: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod client-containers-dd400dff-023b-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:39:39.060: INFO: Waiting for pod client-containers-dd400dff-023b-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:39:39.063: INFO: Pod client-containers-dd400dff-023b-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:39:39.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-gv4xv" for this suite.
Dec 17 20:39:45.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:39:45.235: INFO: namespace: e2e-tests-containers-gv4xv, resource: bindings, ignored listing per whitelist
Dec 17 20:39:45.262: INFO: namespace e2e-tests-containers-gv4xv deletion completed in 6.195722847s

• [SLOW TEST:10.384 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:39:45.262: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 17 20:39:45.385: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-btjf8'
Dec 17 20:39:45.674: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 20:39:45.674: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Dec 17 20:39:49.707: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-btjf8'
Dec 17 20:39:49.809: INFO: stderr: ""
Dec 17 20:39:49.809: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:39:49.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-btjf8" for this suite.
Dec 17 20:39:55.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:39:55.943: INFO: namespace: e2e-tests-kubectl-btjf8, resource: bindings, ignored listing per whitelist
Dec 17 20:39:55.960: INFO: namespace e2e-tests-kubectl-btjf8 deletion completed in 6.145048479s

• [SLOW TEST:10.698 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:39:55.960: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:39:58.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5qwqc" for this suite.
Dec 17 20:40:40.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:40:40.158: INFO: namespace: e2e-tests-kubelet-test-5qwqc, resource: bindings, ignored listing per whitelist
Dec 17 20:40:40.257: INFO: namespace e2e-tests-kubelet-test-5qwqc deletion completed in 42.149530242s

• [SLOW TEST:44.297 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:40:40.257: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-0442ec7a-023c-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:40:40.447: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0443b9b7-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-7cjxz" to be "success or failure"
Dec 17 20:40:40.456: INFO: Pod "pod-projected-secrets-0443b9b7-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.781856ms
Dec 17 20:40:42.460: INFO: Pod "pod-projected-secrets-0443b9b7-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012823631s
Dec 17 20:40:44.463: INFO: Pod "pod-projected-secrets-0443b9b7-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016507755s
STEP: Saw pod success
Dec 17 20:40:44.463: INFO: Pod "pod-projected-secrets-0443b9b7-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:40:44.466: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-secrets-0443b9b7-023c-11e9-9892-0a580a3c54b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:40:44.493: INFO: Waiting for pod pod-projected-secrets-0443b9b7-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:40:44.498: INFO: Pod pod-projected-secrets-0443b9b7-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:40:44.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7cjxz" for this suite.
Dec 17 20:40:50.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:40:50.638: INFO: namespace: e2e-tests-projected-7cjxz, resource: bindings, ignored listing per whitelist
Dec 17 20:40:50.683: INFO: namespace e2e-tests-projected-7cjxz deletion completed in 6.180880918s

• [SLOW TEST:10.426 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:40:50.683: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;check="$$(dig +notcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/wheezy_udp@google.com;check="$$(dig +tcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@google.com;check="$$(dig +notcp +noall +answer +search metadata A)" && test -n "$$check" && echo OK > /results/wheezy_udp@metadata;check="$$(dig +tcp +noall +answer +search metadata A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@metadata;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-8g285.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-8g285.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8g285.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;check="$$(dig +notcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/jessie_udp@google.com;check="$$(dig +tcp +noall +answer +search google.com A)" && test -n "$$check" && echo OK > /results/jessie_tcp@google.com;check="$$(dig +notcp +noall +answer +search metadata A)" && test -n "$$check" && echo OK > /results/jessie_udp@metadata;check="$$(dig +tcp +noall +answer +search metadata A)" && test -n "$$check" && echo OK > /results/jessie_tcp@metadata;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-8g285.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-8g285.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-8g285.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 20:40:55.088: INFO: DNS probes using e2e-tests-dns-8g285/dns-test-0a8138c0-023c-11e9-9892-0a580a3c54b9 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:40:55.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-8g285" for this suite.
Dec 17 20:41:01.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:41:01.267: INFO: namespace: e2e-tests-dns-8g285, resource: bindings, ignored listing per whitelist
Dec 17 20:41:01.269: INFO: namespace e2e-tests-dns-8g285 deletion completed in 6.158764459s

• [SLOW TEST:10.586 seconds]
[sig-network] DNS
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:41:01.269: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 17 20:41:01.432: INFO: Waiting up to 5m0s for pod "pod-10c5ebc5-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-j6szb" to be "success or failure"
Dec 17 20:41:01.438: INFO: Pod "pod-10c5ebc5-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.400632ms
Dec 17 20:41:03.442: INFO: Pod "pod-10c5ebc5-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009939057s
STEP: Saw pod success
Dec 17 20:41:03.442: INFO: Pod "pod-10c5ebc5-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:41:03.445: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-10c5ebc5-023c-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:41:03.472: INFO: Waiting for pod pod-10c5ebc5-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:41:03.476: INFO: Pod pod-10c5ebc5-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:41:03.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-j6szb" for this suite.
Dec 17 20:41:09.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:41:09.602: INFO: namespace: e2e-tests-emptydir-j6szb, resource: bindings, ignored listing per whitelist
Dec 17 20:41:09.678: INFO: namespace e2e-tests-emptydir-j6szb deletion completed in 6.198505151s

• [SLOW TEST:8.408 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:41:09.678: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-15c04580-023c-11e9-9892-0a580a3c54b9
STEP: Creating configMap with name cm-test-opt-upd-15c045bf-023c-11e9-9892-0a580a3c54b9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-15c04580-023c-11e9-9892-0a580a3c54b9
STEP: Updating configmap cm-test-opt-upd-15c045bf-023c-11e9-9892-0a580a3c54b9
STEP: Creating configMap with name cm-test-opt-create-15c045d8-023c-11e9-9892-0a580a3c54b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:41:13.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x4w82" for this suite.
Dec 17 20:41:35.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:41:36.059: INFO: namespace: e2e-tests-projected-x4w82, resource: bindings, ignored listing per whitelist
Dec 17 20:41:36.103: INFO: namespace e2e-tests-projected-x4w82 deletion completed in 22.182633s

• [SLOW TEST:26.425 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:41:36.103: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-s8rm8
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 20:41:36.203: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 20:41:54.350: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.64.1.53 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s8rm8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 20:41:54.350: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 20:41:55.432: INFO: Found all expected endpoints: [netserver-0]
Dec 17 20:41:55.436: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.64.2.146 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s8rm8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 20:41:55.436: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 20:41:56.514: INFO: Found all expected endpoints: [netserver-1]
Dec 17 20:41:56.519: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.64.3.52 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-s8rm8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 20:41:56.519: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 20:41:57.594: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:41:57.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-s8rm8" for this suite.
Dec 17 20:42:19.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:42:19.815: INFO: namespace: e2e-tests-pod-network-test-s8rm8, resource: bindings, ignored listing per whitelist
Dec 17 20:42:19.910: INFO: namespace e2e-tests-pod-network-test-s8rm8 deletion completed in 22.311044179s

• [SLOW TEST:43.806 seconds]
[sig-network] Networking
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:42:19.910: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 17 20:42:20.021: INFO: Waiting up to 5m0s for pod "pod-3f9dbb76-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-t55b6" to be "success or failure"
Dec 17 20:42:20.035: INFO: Pod "pod-3f9dbb76-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.814662ms
Dec 17 20:42:22.040: INFO: Pod "pod-3f9dbb76-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018981624s
STEP: Saw pod success
Dec 17 20:42:22.041: INFO: Pod "pod-3f9dbb76-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:42:22.044: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-3f9dbb76-023c-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:42:22.065: INFO: Waiting for pod pod-3f9dbb76-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:42:22.072: INFO: Pod pod-3f9dbb76-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:42:22.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t55b6" for this suite.
Dec 17 20:42:28.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:42:28.244: INFO: namespace: e2e-tests-emptydir-t55b6, resource: bindings, ignored listing per whitelist
Dec 17 20:42:28.249: INFO: namespace e2e-tests-emptydir-t55b6 deletion completed in 6.173821118s

• [SLOW TEST:8.339 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:42:28.249: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 17 20:42:28.471: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-5kqvs'
Dec 17 20:42:28.571: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 20:42:28.572: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec 17 20:42:28.590: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec 17 20:42:28.594: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 17 20:42:28.622: INFO: scanned /workspace for discovery docs: <nil>
Dec 17 20:42:28.622: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-5kqvs'
Dec 17 20:42:44.444: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 17 20:42:44.444: INFO: stdout: "Created e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107\nScaling up e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 17 20:42:44.444: INFO: stdout: "Created e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107\nScaling up e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 17 20:42:44.444: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5kqvs'
Dec 17 20:42:44.537: INFO: stderr: ""
Dec 17 20:42:44.537: INFO: stdout: "e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107-g7c7l "
Dec 17 20:42:44.537: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107-g7c7l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5kqvs'
Dec 17 20:42:44.628: INFO: stderr: ""
Dec 17 20:42:44.628: INFO: stdout: "true"
Dec 17 20:42:44.628: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107-g7c7l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5kqvs'
Dec 17 20:42:44.714: INFO: stderr: ""
Dec 17 20:42:44.714: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec 17 20:42:44.714: INFO: e2e-test-nginx-rc-3a7d69d06e79008ccdc8639110fc2107-g7c7l is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Dec 17 20:42:44.714: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5kqvs'
Dec 17 20:42:44.825: INFO: stderr: ""
Dec 17 20:42:44.825: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:42:44.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5kqvs" for this suite.
Dec 17 20:42:50.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:42:50.913: INFO: namespace: e2e-tests-kubectl-5kqvs, resource: bindings, ignored listing per whitelist
Dec 17 20:42:50.999: INFO: namespace e2e-tests-kubectl-5kqvs deletion completed in 6.147612748s

• [SLOW TEST:22.750 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:42:50.999: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5225f8e9-023c-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:42:51.119: INFO: Waiting up to 5m0s for pod "pod-configmaps-5226d7c5-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-c77j7" to be "success or failure"
Dec 17 20:42:51.129: INFO: Pod "pod-configmaps-5226d7c5-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.235899ms
Dec 17 20:42:53.132: INFO: Pod "pod-configmaps-5226d7c5-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013656015s
Dec 17 20:42:55.137: INFO: Pod "pod-configmaps-5226d7c5-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018114251s
STEP: Saw pod success
Dec 17 20:42:55.137: INFO: Pod "pod-configmaps-5226d7c5-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:42:55.141: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-5226d7c5-023c-11e9-9892-0a580a3c54b9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:42:55.172: INFO: Waiting for pod pod-configmaps-5226d7c5-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:42:55.184: INFO: Pod pod-configmaps-5226d7c5-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:42:55.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c77j7" for this suite.
Dec 17 20:43:01.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:43:01.314: INFO: namespace: e2e-tests-configmap-c77j7, resource: bindings, ignored listing per whitelist
Dec 17 20:43:01.340: INFO: namespace e2e-tests-configmap-c77j7 deletion completed in 6.146343707s

• [SLOW TEST:10.342 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:43:01.341: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-5856a5f1-023c-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:43:01.507: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-58576dca-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-wghvm" to be "success or failure"
Dec 17 20:43:01.516: INFO: Pod "pod-projected-secrets-58576dca-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.503824ms
Dec 17 20:43:03.519: INFO: Pod "pod-projected-secrets-58576dca-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011876675s
STEP: Saw pod success
Dec 17 20:43:03.519: INFO: Pod "pod-projected-secrets-58576dca-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:43:03.523: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-secrets-58576dca-023c-11e9-9892-0a580a3c54b9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:43:03.555: INFO: Waiting for pod pod-projected-secrets-58576dca-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:43:03.560: INFO: Pod pod-projected-secrets-58576dca-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:43:03.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wghvm" for this suite.
Dec 17 20:43:09.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:43:09.656: INFO: namespace: e2e-tests-projected-wghvm, resource: bindings, ignored listing per whitelist
Dec 17 20:43:09.697: INFO: namespace e2e-tests-projected-wghvm deletion completed in 6.133250039s

• [SLOW TEST:8.357 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:43:09.697: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:43:09.806: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d4a3099-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-7vwkl" to be "success or failure"
Dec 17 20:43:09.825: INFO: Pod "downwardapi-volume-5d4a3099-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.871325ms
Dec 17 20:43:11.828: INFO: Pod "downwardapi-volume-5d4a3099-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022165017s
STEP: Saw pod success
Dec 17 20:43:11.828: INFO: Pod "downwardapi-volume-5d4a3099-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:43:11.832: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-5d4a3099-023c-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:43:11.859: INFO: Waiting for pod downwardapi-volume-5d4a3099-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:43:11.864: INFO: Pod downwardapi-volume-5d4a3099-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:43:11.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7vwkl" for this suite.
Dec 17 20:43:17.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:43:18.031: INFO: namespace: e2e-tests-projected-7vwkl, resource: bindings, ignored listing per whitelist
Dec 17 20:43:18.069: INFO: namespace e2e-tests-projected-7vwkl deletion completed in 6.200290591s

• [SLOW TEST:8.372 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:43:18.069: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:43:18.158: INFO: Creating deployment "test-recreate-deployment"
Dec 17 20:43:18.165: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 17 20:43:18.176: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec 17 20:43:20.184: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 17 20:43:20.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680676198, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680676198, loc:(*time.Location)(0x7b3aba0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680676198, loc:(*time.Location)(0x7b3aba0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680676198, loc:(*time.Location)(0x7b3aba0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 20:43:22.191: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 17 20:43:22.200: INFO: Updating deployment test-recreate-deployment
Dec 17 20:43:22.200: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 17 20:43:22.374: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-k85k9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k85k9/deployments/test-recreate-deployment,UID:623b660d-023c-11e9-b8bf-42010a800002,ResourceVersion:11380,Generation:2,CreationTimestamp:2018-12-17 20:43:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-17 20:43:22 +0000 UTC 2018-12-17 20:43:22 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-17 20:43:22 +0000 UTC 2018-12-17 20:43:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 17 20:43:22.377: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-k85k9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k85k9/replicasets/test-recreate-deployment-697fbf54bf,UID:64aed810-023c-11e9-b8bf-42010a800002,ResourceVersion:11379,Generation:1,CreationTimestamp:2018-12-17 20:43:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 623b660d-023c-11e9-b8bf-42010a800002 0xc00258b237 0xc00258b238}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 17 20:43:22.377: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 17 20:43:22.377: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-k85k9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k85k9/replicasets/test-recreate-deployment-5dfdcc846d,UID:623e1c39-023c-11e9-b8bf-42010a800002,ResourceVersion:11372,Generation:2,CreationTimestamp:2018-12-17 20:43:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 623b660d-023c-11e9-b8bf-42010a800002 0xc00258b097 0xc00258b098}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 17 20:43:22.380: INFO: Pod "test-recreate-deployment-697fbf54bf-dn5sb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-dn5sb,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-k85k9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k85k9/pods/test-recreate-deployment-697fbf54bf-dn5sb,UID:64b0f10a-023c-11e9-b8bf-42010a800002,ResourceVersion:11381,Generation:0,CreationTimestamp:2018-12-17 20:43:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 64aed810-023c-11e9-b8bf-42010a800002 0xc0018ba8d7 0xc0018ba8d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-wbbsv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wbbsv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wbbsv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0018ba940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0018ba960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:43:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:43:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:43:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:43:22 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:,StartTime:2018-12-17 20:43:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:43:22.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-k85k9" for this suite.
Dec 17 20:43:28.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:43:28.513: INFO: namespace: e2e-tests-deployment-k85k9, resource: bindings, ignored listing per whitelist
Dec 17 20:43:28.519: INFO: namespace e2e-tests-deployment-k85k9 deletion completed in 6.136657176s

• [SLOW TEST:10.450 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:43:28.520: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 17 20:43:28.628: INFO: Waiting up to 5m0s for pod "downward-api-68826721-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-p6xmr" to be "success or failure"
Dec 17 20:43:28.640: INFO: Pod "downward-api-68826721-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.130869ms
Dec 17 20:43:30.644: INFO: Pod "downward-api-68826721-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015630453s
STEP: Saw pod success
Dec 17 20:43:30.644: INFO: Pod "downward-api-68826721-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:43:30.647: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downward-api-68826721-023c-11e9-9892-0a580a3c54b9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 20:43:30.672: INFO: Waiting for pod downward-api-68826721-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:43:30.677: INFO: Pod downward-api-68826721-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:43:30.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p6xmr" for this suite.
Dec 17 20:43:36.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:43:36.791: INFO: namespace: e2e-tests-downward-api-p6xmr, resource: bindings, ignored listing per whitelist
Dec 17 20:43:37.118: INFO: namespace e2e-tests-downward-api-p6xmr deletion completed in 6.436794189s

• [SLOW TEST:8.598 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:43:37.118: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 17 20:43:37.294: INFO: Waiting up to 5m0s for pod "downward-api-6dab82d4-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-8wzh8" to be "success or failure"
Dec 17 20:43:37.304: INFO: Pod "downward-api-6dab82d4-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.486808ms
Dec 17 20:43:39.308: INFO: Pod "downward-api-6dab82d4-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014443564s
STEP: Saw pod success
Dec 17 20:43:39.308: INFO: Pod "downward-api-6dab82d4-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:43:39.312: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downward-api-6dab82d4-023c-11e9-9892-0a580a3c54b9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 20:43:39.339: INFO: Waiting for pod downward-api-6dab82d4-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:43:39.345: INFO: Pod downward-api-6dab82d4-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:43:39.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8wzh8" for this suite.
Dec 17 20:43:45.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:43:45.514: INFO: namespace: e2e-tests-downward-api-8wzh8, resource: bindings, ignored listing per whitelist
Dec 17 20:43:45.521: INFO: namespace e2e-tests-downward-api-8wzh8 deletion completed in 6.171834445s

• [SLOW TEST:8.403 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:43:45.521: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-475g7
Dec 17 20:43:49.705: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-475g7
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 20:43:49.708: INFO: Initial restart count of pod liveness-exec is 0
Dec 17 20:44:35.825: INFO: Restart count of pod e2e-tests-container-probe-475g7/liveness-exec is now 1 (46.116995168s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:44:35.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-475g7" for this suite.
Dec 17 20:44:41.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:44:41.997: INFO: namespace: e2e-tests-container-probe-475g7, resource: bindings, ignored listing per whitelist
Dec 17 20:44:42.037: INFO: namespace e2e-tests-container-probe-475g7 deletion completed in 6.193173408s

• [SLOW TEST:56.517 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:44:42.038: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec 17 20:44:42.154: INFO: Waiting up to 5m0s for pod "var-expansion-94552e4d-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-var-expansion-mgftl" to be "success or failure"
Dec 17 20:44:42.159: INFO: Pod "var-expansion-94552e4d-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.563736ms
Dec 17 20:44:44.163: INFO: Pod "var-expansion-94552e4d-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009449247s
Dec 17 20:44:46.167: INFO: Pod "var-expansion-94552e4d-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013411194s
STEP: Saw pod success
Dec 17 20:44:46.167: INFO: Pod "var-expansion-94552e4d-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:44:46.170: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod var-expansion-94552e4d-023c-11e9-9892-0a580a3c54b9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 20:44:46.196: INFO: Waiting for pod var-expansion-94552e4d-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:44:46.200: INFO: Pod var-expansion-94552e4d-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:44:46.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mgftl" for this suite.
Dec 17 20:44:52.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:44:52.324: INFO: namespace: e2e-tests-var-expansion-mgftl, resource: bindings, ignored listing per whitelist
Dec 17 20:44:52.385: INFO: namespace e2e-tests-var-expansion-mgftl deletion completed in 6.181422246s

• [SLOW TEST:10.347 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:44:52.385: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-9a87f683-023c-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:44:52.561: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9a89314c-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-k6nts" to be "success or failure"
Dec 17 20:44:52.579: INFO: Pod "pod-projected-configmaps-9a89314c-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.930476ms
Dec 17 20:44:54.584: INFO: Pod "pod-projected-configmaps-9a89314c-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022928298s
Dec 17 20:44:56.588: INFO: Pod "pod-projected-configmaps-9a89314c-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026670486s
STEP: Saw pod success
Dec 17 20:44:56.588: INFO: Pod "pod-projected-configmaps-9a89314c-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:44:56.592: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-configmaps-9a89314c-023c-11e9-9892-0a580a3c54b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:44:56.621: INFO: Waiting for pod pod-projected-configmaps-9a89314c-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:44:56.626: INFO: Pod pod-projected-configmaps-9a89314c-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:44:56.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k6nts" for this suite.
Dec 17 20:45:02.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:45:02.739: INFO: namespace: e2e-tests-projected-k6nts, resource: bindings, ignored listing per whitelist
Dec 17 20:45:02.775: INFO: namespace e2e-tests-projected-k6nts deletion completed in 6.146077065s

• [SLOW TEST:10.390 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:45:02.776: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 17 20:45:02.884: INFO: Waiting up to 5m0s for pod "pod-a0b07847-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-2dsrl" to be "success or failure"
Dec 17 20:45:02.894: INFO: Pod "pod-a0b07847-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.826128ms
Dec 17 20:45:04.899: INFO: Pod "pod-a0b07847-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015466735s
STEP: Saw pod success
Dec 17 20:45:04.899: INFO: Pod "pod-a0b07847-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:45:04.902: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-a0b07847-023c-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 20:45:04.923: INFO: Waiting for pod pod-a0b07847-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:45:04.929: INFO: Pod pod-a0b07847-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:45:04.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-2dsrl" for this suite.
Dec 17 20:45:10.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:45:10.993: INFO: namespace: e2e-tests-emptydir-2dsrl, resource: bindings, ignored listing per whitelist
Dec 17 20:45:11.064: INFO: namespace e2e-tests-emptydir-2dsrl deletion completed in 6.130829665s

• [SLOW TEST:8.288 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:45:11.064: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a5aa2db2-023c-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:45:11.234: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a5aae54f-023c-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-zn7rz" to be "success or failure"
Dec 17 20:45:11.248: INFO: Pod "pod-projected-configmaps-a5aae54f-023c-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.192808ms
Dec 17 20:45:13.252: INFO: Pod "pod-projected-configmaps-a5aae54f-023c-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01820855s
STEP: Saw pod success
Dec 17 20:45:13.252: INFO: Pod "pod-projected-configmaps-a5aae54f-023c-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:45:13.255: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-configmaps-a5aae54f-023c-11e9-9892-0a580a3c54b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:45:13.281: INFO: Waiting for pod pod-projected-configmaps-a5aae54f-023c-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:45:13.286: INFO: Pod pod-projected-configmaps-a5aae54f-023c-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:45:13.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zn7rz" for this suite.
Dec 17 20:45:19.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:45:19.385: INFO: namespace: e2e-tests-projected-zn7rz, resource: bindings, ignored listing per whitelist
Dec 17 20:45:19.475: INFO: namespace e2e-tests-projected-zn7rz deletion completed in 6.185757652s

• [SLOW TEST:8.411 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:45:19.475: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:45:19.579: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:45:23.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ltrg4" for this suite.
Dec 17 20:46:11.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:46:11.729: INFO: namespace: e2e-tests-pods-ltrg4, resource: bindings, ignored listing per whitelist
Dec 17 20:46:11.801: INFO: namespace e2e-tests-pods-ltrg4 deletion completed in 48.1581197s

• [SLOW TEST:52.326 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:46:11.802: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:46:11.945: INFO: (0) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 9.538325ms)
Dec 17 20:46:11.949: INFO: (1) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.538514ms)
Dec 17 20:46:11.954: INFO: (2) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.84416ms)
Dec 17 20:46:11.960: INFO: (3) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.801094ms)
Dec 17 20:46:11.966: INFO: (4) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.050289ms)
Dec 17 20:46:11.972: INFO: (5) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.670504ms)
Dec 17 20:46:11.977: INFO: (6) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.809025ms)
Dec 17 20:46:11.982: INFO: (7) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.207337ms)
Dec 17 20:46:11.988: INFO: (8) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.686994ms)
Dec 17 20:46:11.993: INFO: (9) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.928426ms)
Dec 17 20:46:11.999: INFO: (10) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.024464ms)
Dec 17 20:46:12.006: INFO: (11) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.700712ms)
Dec 17 20:46:12.010: INFO: (12) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 3.992391ms)
Dec 17 20:46:12.015: INFO: (13) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.718158ms)
Dec 17 20:46:12.023: INFO: (14) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.207609ms)
Dec 17 20:46:12.028: INFO: (15) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.429235ms)
Dec 17 20:46:12.034: INFO: (16) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.379039ms)
Dec 17 20:46:12.040: INFO: (17) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.292319ms)
Dec 17 20:46:12.045: INFO: (18) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.040286ms)
Dec 17 20:46:12.049: INFO: (19) /api/v1/nodes/bootstrap-e2e-minion-group-6xhw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.247254ms)
[AfterEach] version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:46:12.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-b254m" for this suite.
Dec 17 20:46:18.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:46:18.116: INFO: namespace: e2e-tests-proxy-b254m, resource: bindings, ignored listing per whitelist
Dec 17 20:46:18.202: INFO: namespace e2e-tests-proxy-b254m deletion completed in 6.149209859s

• [SLOW TEST:6.401 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:46:18.203: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 17 20:46:22.910: INFO: Successfully updated pod "labelsupdatecdadb4d8-023c-11e9-9892-0a580a3c54b9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:46:24.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mnkvt" for this suite.
Dec 17 20:46:46.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:46:47.056: INFO: namespace: e2e-tests-projected-mnkvt, resource: bindings, ignored listing per whitelist
Dec 17 20:46:47.103: INFO: namespace e2e-tests-projected-mnkvt deletion completed in 22.151265121s

• [SLOW TEST:28.900 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:46:47.103: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 17 20:46:47.233: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 20:46:47.240: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 20:46:47.243: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-6xhw before test
Dec 17 20:46:47.257: INFO: kube-dns-autoscaler-545db58f6f-rjwmd from kube-system started at 2018-12-17 19:48:38 +0000 UTC (1 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container autoscaler ready: true, restart count 0
Dec 17 20:46:47.257: INFO: heapster-v1.6.0-beta.1-5f77ccd9dd-zwfwt from kube-system started at 2018-12-17 19:48:38 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container heapster ready: true, restart count 0
Dec 17 20:46:47.257: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 17 20:46:47.257: INFO: coredns-fff89c9b9-dc8sd from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container coredns ready: true, restart count 0
Dec 17 20:46:47.257: INFO: event-exporter-v0.2.3-fdd9d7c84-jh2xj from kube-system started at 2018-12-17 19:47:48 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container event-exporter ready: true, restart count 0
Dec 17 20:46:47.257: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:46:47.257: INFO: kubernetes-dashboard-6bbb6846cd-8dqzv from kube-system started at 2018-12-17 19:48:38 +0000 UTC (1 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 17 20:46:47.257: INFO: kube-proxy-bootstrap-e2e-minion-group-6xhw from kube-system started at <nil> (0 container statuses recorded)
Dec 17 20:46:47.257: INFO: fluentd-gcp-v3.2.0-txdr6 from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 20:46:47.257: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:46:47.257: INFO: metrics-server-v0.3.1-58d65f8d6-pp669 from kube-system started at 2018-12-17 19:48:38 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container metrics-server ready: true, restart count 0
Dec 17 20:46:47.257: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec 17 20:46:47.257: INFO: l7-default-backend-fd59995cd-bkm5h from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container default-http-backend ready: true, restart count 0
Dec 17 20:46:47.257: INFO: fluentd-gcp-scaler-68b55c6dc5-xnl65 from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
Dec 17 20:46:47.257: INFO: metadata-proxy-v0.1-gd7pr from kube-system started at 2018-12-17 19:47:48 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.257: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 20:46:47.257: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:46:47.257: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-tnzf before test
Dec 17 20:46:47.267: INFO: kube-proxy-bootstrap-e2e-minion-group-tnzf from kube-system started at <nil> (0 container statuses recorded)
Dec 17 20:46:47.267: INFO: fluentd-gcp-v3.2.0-dqnzd from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.267: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 20:46:47.267: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:46:47.267: INFO: metadata-proxy-v0.1-lnjmm from kube-system started at 2018-12-17 19:47:49 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.267: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 20:46:47.267: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:46:47.267: INFO: coredns-fff89c9b9-s8fmm from kube-system started at 2018-12-17 19:48:45 +0000 UTC (1 container statuses recorded)
Dec 17 20:46:47.267: INFO: 	Container coredns ready: true, restart count 0
Dec 17 20:46:47.267: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-wjp3 before test
Dec 17 20:46:47.274: INFO: fluentd-gcp-v3.2.0-v2dvx from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.274: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 20:46:47.274: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 20:46:47.274: INFO: kube-proxy-bootstrap-e2e-minion-group-wjp3 from kube-system started at <nil> (0 container statuses recorded)
Dec 17 20:46:47.274: INFO: metadata-proxy-v0.1-727vr from kube-system started at 2018-12-17 19:47:49 +0000 UTC (2 container statuses recorded)
Dec 17 20:46:47.274: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 20:46:47.274: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157139b773208a06], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) were unschedulable, 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:46:48.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-mtmwv" for this suite.
Dec 17 20:46:54.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:46:54.351: INFO: namespace: e2e-tests-sched-pred-mtmwv, resource: bindings, ignored listing per whitelist
Dec 17 20:46:54.451: INFO: namespace e2e-tests-sched-pred-mtmwv deletion completed in 6.143158407s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.348 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:46:54.451: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-tbpv
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 20:46:54.649: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-tbpv" in namespace "e2e-tests-subpath-h665m" to be "success or failure"
Dec 17 20:46:54.654: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.647622ms
Dec 17 20:46:56.658: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008491265s
Dec 17 20:46:58.662: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 4.012666758s
Dec 17 20:47:00.666: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 6.016821004s
Dec 17 20:47:02.671: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 8.021563789s
Dec 17 20:47:04.678: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 10.028304732s
Dec 17 20:47:06.685: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 12.03558098s
Dec 17 20:47:08.695: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 14.045741778s
Dec 17 20:47:10.702: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 16.05216794s
Dec 17 20:47:12.706: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 18.056905689s
Dec 17 20:47:14.809: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 20.159290726s
Dec 17 20:47:16.942: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Running", Reason="", readiness=false. Elapsed: 22.292127137s
Dec 17 20:47:18.945: INFO: Pod "pod-subpath-test-downwardapi-tbpv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.295386025s
STEP: Saw pod success
Dec 17 20:47:18.945: INFO: Pod "pod-subpath-test-downwardapi-tbpv" satisfied condition "success or failure"
Dec 17 20:47:18.947: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-subpath-test-downwardapi-tbpv container test-container-subpath-downwardapi-tbpv: <nil>
STEP: delete the pod
Dec 17 20:47:18.975: INFO: Waiting for pod pod-subpath-test-downwardapi-tbpv to disappear
Dec 17 20:47:18.979: INFO: Pod pod-subpath-test-downwardapi-tbpv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-tbpv
Dec 17 20:47:18.979: INFO: Deleting pod "pod-subpath-test-downwardapi-tbpv" in namespace "e2e-tests-subpath-h665m"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:47:18.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-h665m" for this suite.
Dec 17 20:47:24.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:47:25.069: INFO: namespace: e2e-tests-subpath-h665m, resource: bindings, ignored listing per whitelist
Dec 17 20:47:25.147: INFO: namespace e2e-tests-subpath-h665m deletion completed in 6.16253971s

• [SLOW TEST:30.696 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:47:25.147: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-pc94
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 20:47:25.286: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pc94" in namespace "e2e-tests-subpath-2ds8t" to be "success or failure"
Dec 17 20:47:25.300: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Pending", Reason="", readiness=false. Elapsed: 13.62718ms
Dec 17 20:47:27.304: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017815447s
Dec 17 20:47:29.310: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 4.023951176s
Dec 17 20:47:31.314: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 6.027928974s
Dec 17 20:47:33.328: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 8.041389688s
Dec 17 20:47:35.331: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 10.0449874s
Dec 17 20:47:37.335: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 12.048632597s
Dec 17 20:47:39.339: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 14.052492178s
Dec 17 20:47:41.344: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 16.057810553s
Dec 17 20:47:43.349: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 18.062477511s
Dec 17 20:47:45.353: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 20.066731981s
Dec 17 20:47:47.357: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Running", Reason="", readiness=false. Elapsed: 22.070529118s
Dec 17 20:47:49.361: INFO: Pod "pod-subpath-test-configmap-pc94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.074380567s
STEP: Saw pod success
Dec 17 20:47:49.361: INFO: Pod "pod-subpath-test-configmap-pc94" satisfied condition "success or failure"
Dec 17 20:47:49.364: INFO: Trying to get logs from node bootstrap-e2e-minion-group-tnzf pod pod-subpath-test-configmap-pc94 container test-container-subpath-configmap-pc94: <nil>
STEP: delete the pod
Dec 17 20:47:49.389: INFO: Waiting for pod pod-subpath-test-configmap-pc94 to disappear
Dec 17 20:47:49.392: INFO: Pod pod-subpath-test-configmap-pc94 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pc94
Dec 17 20:47:49.392: INFO: Deleting pod "pod-subpath-test-configmap-pc94" in namespace "e2e-tests-subpath-2ds8t"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:47:49.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2ds8t" for this suite.
Dec 17 20:47:55.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:47:55.560: INFO: namespace: e2e-tests-subpath-2ds8t, resource: bindings, ignored listing per whitelist
Dec 17 20:47:55.586: INFO: namespace e2e-tests-subpath-2ds8t deletion completed in 6.186538704s

• [SLOW TEST:30.439 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:47:55.586: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-kb2zf
Dec 17 20:47:59.756: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-kb2zf
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 20:47:59.759: INFO: Initial restart count of pod liveness-http is 0
Dec 17 20:48:15.792: INFO: Restart count of pod e2e-tests-container-probe-kb2zf/liveness-http is now 1 (16.032790601s elapsed)
Dec 17 20:48:35.829: INFO: Restart count of pod e2e-tests-container-probe-kb2zf/liveness-http is now 2 (36.070354222s elapsed)
Dec 17 20:48:55.870: INFO: Restart count of pod e2e-tests-container-probe-kb2zf/liveness-http is now 3 (56.110843979s elapsed)
Dec 17 20:49:15.910: INFO: Restart count of pod e2e-tests-container-probe-kb2zf/liveness-http is now 4 (1m16.151030634s elapsed)
Dec 17 20:50:16.073: INFO: Restart count of pod e2e-tests-container-probe-kb2zf/liveness-http is now 5 (2m16.314214886s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:50:16.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kb2zf" for this suite.
Dec 17 20:50:22.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:50:22.207: INFO: namespace: e2e-tests-container-probe-kb2zf, resource: bindings, ignored listing per whitelist
Dec 17 20:50:22.262: INFO: namespace e2e-tests-container-probe-kb2zf deletion completed in 6.167661172s

• [SLOW TEST:146.675 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:50:22.262: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-5f1f1cec-023d-11e9-9892-0a580a3c54b9
STEP: Creating configMap with name cm-test-opt-upd-5f1f1d47-023d-11e9-9892-0a580a3c54b9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5f1f1cec-023d-11e9-9892-0a580a3c54b9
STEP: Updating configmap cm-test-opt-upd-5f1f1d47-023d-11e9-9892-0a580a3c54b9
STEP: Creating configMap with name cm-test-opt-create-5f1f1d59-023d-11e9-9892-0a580a3c54b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:50:30.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-757sr" for this suite.
Dec 17 20:50:52.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:50:52.762: INFO: namespace: e2e-tests-configmap-757sr, resource: bindings, ignored listing per whitelist
Dec 17 20:50:52.837: INFO: namespace e2e-tests-configmap-757sr deletion completed in 22.339174777s

• [SLOW TEST:30.576 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:50:52.838: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec 17 20:50:53.038: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config cluster-info'
Dec 17 20:50:55.722: INFO: stderr: ""
Dec 17 20:50:55.722: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://35.225.177.164\x1b[0m\n\x1b[0;32mGLBCDefaultBackend\x1b[0m is running at \x1b[0;33mhttps://35.225.177.164/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://35.225.177.164/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://35.225.177.164/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://35.225.177.164/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://35.225.177.164/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:50:55.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7qnqd" for this suite.
Dec 17 20:51:01.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:51:01.789: INFO: namespace: e2e-tests-kubectl-7qnqd, resource: bindings, ignored listing per whitelist
Dec 17 20:51:01.931: INFO: namespace e2e-tests-kubectl-7qnqd deletion completed in 6.194464968s

• [SLOW TEST:9.093 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:51:01.931: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-swkpw
I1217 20:51:02.282487    7194 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-swkpw, replica count: 1
I1217 20:51:03.333132    7194 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1217 20:51:04.334061    7194 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1217 20:51:05.335098    7194 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 20:51:05.447: INFO: Created: latency-svc-m2j7d
Dec 17 20:51:05.457: INFO: Got endpoints: latency-svc-m2j7d [21.60083ms]
Dec 17 20:51:05.471: INFO: Created: latency-svc-pfl98
Dec 17 20:51:05.481: INFO: Got endpoints: latency-svc-pfl98 [23.536137ms]
Dec 17 20:51:05.489: INFO: Created: latency-svc-rjgxb
Dec 17 20:51:05.498: INFO: Created: latency-svc-tq2w2
Dec 17 20:51:05.504: INFO: Got endpoints: latency-svc-rjgxb [46.459438ms]
Dec 17 20:51:05.510: INFO: Got endpoints: latency-svc-tq2w2 [51.6008ms]
Dec 17 20:51:05.516: INFO: Created: latency-svc-cj9tb
Dec 17 20:51:05.523: INFO: Got endpoints: latency-svc-cj9tb [65.648444ms]
Dec 17 20:51:05.532: INFO: Created: latency-svc-d8l5w
Dec 17 20:51:05.538: INFO: Created: latency-svc-jxfkb
Dec 17 20:51:05.542: INFO: Got endpoints: latency-svc-d8l5w [84.130198ms]
Dec 17 20:51:05.548: INFO: Got endpoints: latency-svc-jxfkb [90.636655ms]
Dec 17 20:51:05.556: INFO: Created: latency-svc-6bshg
Dec 17 20:51:05.567: INFO: Created: latency-svc-pkxnq
Dec 17 20:51:05.570: INFO: Got endpoints: latency-svc-6bshg [112.299192ms]
Dec 17 20:51:05.581: INFO: Got endpoints: latency-svc-pkxnq [123.267781ms]
Dec 17 20:51:05.609: INFO: Created: latency-svc-49pwv
Dec 17 20:51:05.630: INFO: Created: latency-svc-xfqks
Dec 17 20:51:05.637: INFO: Got endpoints: latency-svc-49pwv [179.072405ms]
Dec 17 20:51:05.643: INFO: Got endpoints: latency-svc-xfqks [185.469367ms]
Dec 17 20:51:05.652: INFO: Created: latency-svc-nnhhq
Dec 17 20:51:05.658: INFO: Got endpoints: latency-svc-nnhhq [200.49788ms]
Dec 17 20:51:05.677: INFO: Created: latency-svc-h75lv
Dec 17 20:51:05.686: INFO: Created: latency-svc-jxw7b
Dec 17 20:51:05.688: INFO: Got endpoints: latency-svc-h75lv [229.760802ms]
Dec 17 20:51:05.696: INFO: Got endpoints: latency-svc-jxw7b [238.380343ms]
Dec 17 20:51:05.702: INFO: Created: latency-svc-g8dm6
Dec 17 20:51:05.710: INFO: Created: latency-svc-b5w5p
Dec 17 20:51:05.715: INFO: Got endpoints: latency-svc-g8dm6 [257.057941ms]
Dec 17 20:51:05.725: INFO: Got endpoints: latency-svc-b5w5p [267.528239ms]
Dec 17 20:51:05.730: INFO: Created: latency-svc-r68m8
Dec 17 20:51:05.740: INFO: Created: latency-svc-r4q8x
Dec 17 20:51:05.749: INFO: Created: latency-svc-wgc5w
Dec 17 20:51:05.750: INFO: Got endpoints: latency-svc-r68m8 [268.810276ms]
Dec 17 20:51:05.750: INFO: Got endpoints: latency-svc-r4q8x [245.695776ms]
Dec 17 20:51:05.764: INFO: Got endpoints: latency-svc-wgc5w [254.054466ms]
Dec 17 20:51:05.770: INFO: Created: latency-svc-z72mf
Dec 17 20:51:05.780: INFO: Created: latency-svc-x79k4
Dec 17 20:51:05.783: INFO: Got endpoints: latency-svc-z72mf [259.87575ms]
Dec 17 20:51:05.787: INFO: Got endpoints: latency-svc-x79k4 [244.888308ms]
Dec 17 20:51:05.797: INFO: Created: latency-svc-87bsc
Dec 17 20:51:05.801: INFO: Created: latency-svc-f2jrz
Dec 17 20:51:05.803: INFO: Got endpoints: latency-svc-87bsc [254.90678ms]
Dec 17 20:51:05.813: INFO: Got endpoints: latency-svc-f2jrz [29.304183ms]
Dec 17 20:51:05.825: INFO: Created: latency-svc-t98br
Dec 17 20:51:05.833: INFO: Created: latency-svc-sbl6z
Dec 17 20:51:05.838: INFO: Got endpoints: latency-svc-t98br [267.541956ms]
Dec 17 20:51:05.846: INFO: Created: latency-svc-5m9km
Dec 17 20:51:05.846: INFO: Got endpoints: latency-svc-sbl6z [264.590989ms]
Dec 17 20:51:05.860: INFO: Created: latency-svc-f7pr6
Dec 17 20:51:05.864: INFO: Got endpoints: latency-svc-5m9km [226.639196ms]
Dec 17 20:51:05.871: INFO: Got endpoints: latency-svc-f7pr6 [227.365376ms]
Dec 17 20:51:05.881: INFO: Created: latency-svc-b7x4b
Dec 17 20:51:05.881: INFO: Created: latency-svc-46gkq
Dec 17 20:51:05.892: INFO: Got endpoints: latency-svc-b7x4b [203.951681ms]
Dec 17 20:51:05.900: INFO: Got endpoints: latency-svc-46gkq [241.826188ms]
Dec 17 20:51:05.907: INFO: Created: latency-svc-c5sbm
Dec 17 20:51:05.916: INFO: Got endpoints: latency-svc-c5sbm [219.372201ms]
Dec 17 20:51:05.922: INFO: Created: latency-svc-7jqht
Dec 17 20:51:05.930: INFO: Got endpoints: latency-svc-7jqht [215.141961ms]
Dec 17 20:51:05.935: INFO: Created: latency-svc-h2j78
Dec 17 20:51:05.948: INFO: Created: latency-svc-7z8d2
Dec 17 20:51:05.951: INFO: Got endpoints: latency-svc-h2j78 [226.114981ms]
Dec 17 20:51:05.957: INFO: Got endpoints: latency-svc-7z8d2 [207.431247ms]
Dec 17 20:51:05.964: INFO: Created: latency-svc-zzw9w
Dec 17 20:51:05.970: INFO: Got endpoints: latency-svc-zzw9w [220.393792ms]
Dec 17 20:51:05.974: INFO: Created: latency-svc-rwls4
Dec 17 20:51:05.983: INFO: Got endpoints: latency-svc-rwls4 [219.259151ms]
Dec 17 20:51:05.991: INFO: Created: latency-svc-jcv5g
Dec 17 20:51:05.998: INFO: Got endpoints: latency-svc-jcv5g [210.8287ms]
Dec 17 20:51:06.004: INFO: Created: latency-svc-pbh89
Dec 17 20:51:06.011: INFO: Got endpoints: latency-svc-pbh89 [207.696524ms]
Dec 17 20:51:06.016: INFO: Created: latency-svc-f2hdg
Dec 17 20:51:06.023: INFO: Got endpoints: latency-svc-f2hdg [210.419753ms]
Dec 17 20:51:06.031: INFO: Created: latency-svc-6dgfj
Dec 17 20:51:06.040: INFO: Got endpoints: latency-svc-6dgfj [201.945609ms]
Dec 17 20:51:06.042: INFO: Created: latency-svc-d9g87
Dec 17 20:51:06.055: INFO: Created: latency-svc-rddxh
Dec 17 20:51:06.059: INFO: Got endpoints: latency-svc-d9g87 [213.488867ms]
Dec 17 20:51:06.065: INFO: Got endpoints: latency-svc-rddxh [201.036856ms]
Dec 17 20:51:06.072: INFO: Created: latency-svc-htkh6
Dec 17 20:51:06.078: INFO: Got endpoints: latency-svc-htkh6 [207.476873ms]
Dec 17 20:51:06.083: INFO: Created: latency-svc-txphc
Dec 17 20:51:06.093: INFO: Created: latency-svc-hhjg5
Dec 17 20:51:06.113: INFO: Created: latency-svc-4dbkm
Dec 17 20:51:06.113: INFO: Got endpoints: latency-svc-txphc [221.222499ms]
Dec 17 20:51:06.113: INFO: Created: latency-svc-lhsv4
Dec 17 20:51:06.122: INFO: Created: latency-svc-zx9lr
Dec 17 20:51:06.129: INFO: Created: latency-svc-4n7bc
Dec 17 20:51:06.137: INFO: Created: latency-svc-nr59b
Dec 17 20:51:06.150: INFO: Created: latency-svc-sww89
Dec 17 20:51:06.165: INFO: Created: latency-svc-m2kfz
Dec 17 20:51:06.168: INFO: Got endpoints: latency-svc-hhjg5 [267.334761ms]
Dec 17 20:51:06.177: INFO: Created: latency-svc-qr5v5
Dec 17 20:51:06.184: INFO: Created: latency-svc-26tbt
Dec 17 20:51:06.193: INFO: Created: latency-svc-4fn72
Dec 17 20:51:06.205: INFO: Created: latency-svc-n7d7g
Dec 17 20:51:06.210: INFO: Got endpoints: latency-svc-4dbkm [293.840975ms]
Dec 17 20:51:06.215: INFO: Created: latency-svc-tm46q
Dec 17 20:51:06.225: INFO: Created: latency-svc-7dbh8
Dec 17 20:51:06.234: INFO: Created: latency-svc-p9wrr
Dec 17 20:51:06.241: INFO: Created: latency-svc-gd2zx
Dec 17 20:51:06.248: INFO: Created: latency-svc-8nxbg
Dec 17 20:51:06.253: INFO: Got endpoints: latency-svc-lhsv4 [322.731949ms]
Dec 17 20:51:06.266: INFO: Created: latency-svc-2lvwx
Dec 17 20:51:06.301: INFO: Got endpoints: latency-svc-zx9lr [350.062999ms]
Dec 17 20:51:06.316: INFO: Created: latency-svc-jk8lj
Dec 17 20:51:06.351: INFO: Got endpoints: latency-svc-4n7bc [393.502737ms]
Dec 17 20:51:06.364: INFO: Created: latency-svc-qjqtr
Dec 17 20:51:06.400: INFO: Got endpoints: latency-svc-nr59b [428.999162ms]
Dec 17 20:51:06.413: INFO: Created: latency-svc-tl2sg
Dec 17 20:51:06.451: INFO: Got endpoints: latency-svc-sww89 [467.69715ms]
Dec 17 20:51:06.479: INFO: Created: latency-svc-nwjb9
Dec 17 20:51:06.511: INFO: Got endpoints: latency-svc-m2kfz [512.985603ms]
Dec 17 20:51:06.522: INFO: Created: latency-svc-pp668
Dec 17 20:51:06.550: INFO: Got endpoints: latency-svc-qr5v5 [538.892204ms]
Dec 17 20:51:06.564: INFO: Created: latency-svc-sgt84
Dec 17 20:51:06.602: INFO: Got endpoints: latency-svc-26tbt [579.031671ms]
Dec 17 20:51:06.614: INFO: Created: latency-svc-56lmg
Dec 17 20:51:06.650: INFO: Got endpoints: latency-svc-4fn72 [610.373662ms]
Dec 17 20:51:06.664: INFO: Created: latency-svc-wc2cm
Dec 17 20:51:06.702: INFO: Got endpoints: latency-svc-n7d7g [643.031878ms]
Dec 17 20:51:06.717: INFO: Created: latency-svc-2w5cb
Dec 17 20:51:06.753: INFO: Got endpoints: latency-svc-tm46q [687.84992ms]
Dec 17 20:51:06.768: INFO: Created: latency-svc-9jjwv
Dec 17 20:51:06.803: INFO: Got endpoints: latency-svc-7dbh8 [724.516287ms]
Dec 17 20:51:06.819: INFO: Created: latency-svc-jzlps
Dec 17 20:51:06.852: INFO: Got endpoints: latency-svc-p9wrr [738.728123ms]
Dec 17 20:51:06.864: INFO: Created: latency-svc-h6g6t
Dec 17 20:51:06.901: INFO: Got endpoints: latency-svc-gd2zx [733.258062ms]
Dec 17 20:51:06.914: INFO: Created: latency-svc-2pcbl
Dec 17 20:51:06.953: INFO: Got endpoints: latency-svc-8nxbg [743.263046ms]
Dec 17 20:51:06.965: INFO: Created: latency-svc-z22bn
Dec 17 20:51:07.002: INFO: Got endpoints: latency-svc-2lvwx [748.737224ms]
Dec 17 20:51:07.013: INFO: Created: latency-svc-zps5v
Dec 17 20:51:07.052: INFO: Got endpoints: latency-svc-jk8lj [750.336959ms]
Dec 17 20:51:07.063: INFO: Created: latency-svc-rsh4t
Dec 17 20:51:07.100: INFO: Got endpoints: latency-svc-qjqtr [748.78661ms]
Dec 17 20:51:07.117: INFO: Created: latency-svc-6slvl
Dec 17 20:51:07.157: INFO: Got endpoints: latency-svc-tl2sg [757.056603ms]
Dec 17 20:51:07.179: INFO: Created: latency-svc-zqldm
Dec 17 20:51:07.205: INFO: Got endpoints: latency-svc-nwjb9 [753.884616ms]
Dec 17 20:51:07.221: INFO: Created: latency-svc-fdrk6
Dec 17 20:51:07.252: INFO: Got endpoints: latency-svc-pp668 [740.992214ms]
Dec 17 20:51:07.263: INFO: Created: latency-svc-9f76l
Dec 17 20:51:07.302: INFO: Got endpoints: latency-svc-sgt84 [751.715768ms]
Dec 17 20:51:07.314: INFO: Created: latency-svc-g9cxn
Dec 17 20:51:07.350: INFO: Got endpoints: latency-svc-56lmg [747.916682ms]
Dec 17 20:51:07.365: INFO: Created: latency-svc-slzsl
Dec 17 20:51:07.402: INFO: Got endpoints: latency-svc-wc2cm [752.051854ms]
Dec 17 20:51:07.414: INFO: Created: latency-svc-jxdfz
Dec 17 20:51:07.453: INFO: Got endpoints: latency-svc-2w5cb [750.263943ms]
Dec 17 20:51:07.464: INFO: Created: latency-svc-cl7vw
Dec 17 20:51:07.503: INFO: Got endpoints: latency-svc-9jjwv [750.066146ms]
Dec 17 20:51:07.516: INFO: Created: latency-svc-qr9c6
Dec 17 20:51:07.552: INFO: Got endpoints: latency-svc-jzlps [748.789356ms]
Dec 17 20:51:07.562: INFO: Created: latency-svc-pxgrf
Dec 17 20:51:07.601: INFO: Got endpoints: latency-svc-h6g6t [748.753429ms]
Dec 17 20:51:07.614: INFO: Created: latency-svc-tc6tt
Dec 17 20:51:07.651: INFO: Got endpoints: latency-svc-2pcbl [749.613419ms]
Dec 17 20:51:07.666: INFO: Created: latency-svc-snsqc
Dec 17 20:51:07.706: INFO: Got endpoints: latency-svc-z22bn [752.76081ms]
Dec 17 20:51:07.729: INFO: Created: latency-svc-bwmth
Dec 17 20:51:07.753: INFO: Got endpoints: latency-svc-zps5v [750.804229ms]
Dec 17 20:51:07.766: INFO: Created: latency-svc-gbxwj
Dec 17 20:51:07.802: INFO: Got endpoints: latency-svc-rsh4t [749.947022ms]
Dec 17 20:51:07.815: INFO: Created: latency-svc-b8qk4
Dec 17 20:51:07.854: INFO: Got endpoints: latency-svc-6slvl [753.916735ms]
Dec 17 20:51:07.866: INFO: Created: latency-svc-2wgl9
Dec 17 20:51:07.901: INFO: Got endpoints: latency-svc-zqldm [744.647263ms]
Dec 17 20:51:07.913: INFO: Created: latency-svc-mtppt
Dec 17 20:51:07.951: INFO: Got endpoints: latency-svc-fdrk6 [745.966425ms]
Dec 17 20:51:07.964: INFO: Created: latency-svc-xt7vk
Dec 17 20:51:08.000: INFO: Got endpoints: latency-svc-9f76l [747.847163ms]
Dec 17 20:51:08.016: INFO: Created: latency-svc-w4rr9
Dec 17 20:51:08.053: INFO: Got endpoints: latency-svc-g9cxn [750.754715ms]
Dec 17 20:51:08.063: INFO: Created: latency-svc-2gbcx
Dec 17 20:51:08.104: INFO: Got endpoints: latency-svc-slzsl [753.482347ms]
Dec 17 20:51:08.117: INFO: Created: latency-svc-hrkz4
Dec 17 20:51:08.154: INFO: Got endpoints: latency-svc-jxdfz [751.49152ms]
Dec 17 20:51:08.165: INFO: Created: latency-svc-nqdv9
Dec 17 20:51:08.199: INFO: Got endpoints: latency-svc-cl7vw [746.700782ms]
Dec 17 20:51:08.214: INFO: Created: latency-svc-2zvwx
Dec 17 20:51:08.253: INFO: Got endpoints: latency-svc-qr9c6 [749.787174ms]
Dec 17 20:51:08.264: INFO: Created: latency-svc-w5mzk
Dec 17 20:51:08.300: INFO: Got endpoints: latency-svc-pxgrf [748.077334ms]
Dec 17 20:51:08.315: INFO: Created: latency-svc-7j8rr
Dec 17 20:51:08.353: INFO: Got endpoints: latency-svc-tc6tt [751.941104ms]
Dec 17 20:51:08.364: INFO: Created: latency-svc-4hm4m
Dec 17 20:51:08.404: INFO: Got endpoints: latency-svc-snsqc [753.282426ms]
Dec 17 20:51:08.419: INFO: Created: latency-svc-z4l28
Dec 17 20:51:08.452: INFO: Got endpoints: latency-svc-bwmth [746.013424ms]
Dec 17 20:51:08.464: INFO: Created: latency-svc-2qgvp
Dec 17 20:51:08.502: INFO: Got endpoints: latency-svc-gbxwj [749.555468ms]
Dec 17 20:51:08.515: INFO: Created: latency-svc-kddmf
Dec 17 20:51:08.550: INFO: Got endpoints: latency-svc-b8qk4 [747.94128ms]
Dec 17 20:51:08.565: INFO: Created: latency-svc-jxtl7
Dec 17 20:51:08.602: INFO: Got endpoints: latency-svc-2wgl9 [747.959547ms]
Dec 17 20:51:08.616: INFO: Created: latency-svc-gkp5w
Dec 17 20:51:08.651: INFO: Got endpoints: latency-svc-mtppt [749.898688ms]
Dec 17 20:51:08.667: INFO: Created: latency-svc-bq9ks
Dec 17 20:51:08.702: INFO: Got endpoints: latency-svc-xt7vk [750.9572ms]
Dec 17 20:51:08.714: INFO: Created: latency-svc-t99hc
Dec 17 20:51:08.751: INFO: Got endpoints: latency-svc-w4rr9 [751.71841ms]
Dec 17 20:51:08.766: INFO: Created: latency-svc-wm6mc
Dec 17 20:51:08.802: INFO: Got endpoints: latency-svc-2gbcx [749.451105ms]
Dec 17 20:51:08.814: INFO: Created: latency-svc-l6k7q
Dec 17 20:51:08.852: INFO: Got endpoints: latency-svc-hrkz4 [748.2755ms]
Dec 17 20:51:08.863: INFO: Created: latency-svc-srchg
Dec 17 20:51:08.902: INFO: Got endpoints: latency-svc-nqdv9 [747.915586ms]
Dec 17 20:51:08.917: INFO: Created: latency-svc-76gjr
Dec 17 20:51:08.949: INFO: Got endpoints: latency-svc-2zvwx [749.378204ms]
Dec 17 20:51:08.962: INFO: Created: latency-svc-qbwsc
Dec 17 20:51:08.999: INFO: Got endpoints: latency-svc-w5mzk [746.656923ms]
Dec 17 20:51:09.013: INFO: Created: latency-svc-jlxdp
Dec 17 20:51:09.050: INFO: Got endpoints: latency-svc-7j8rr [749.837871ms]
Dec 17 20:51:09.064: INFO: Created: latency-svc-lxcnb
Dec 17 20:51:09.105: INFO: Got endpoints: latency-svc-4hm4m [752.115246ms]
Dec 17 20:51:09.121: INFO: Created: latency-svc-d7x88
Dec 17 20:51:09.156: INFO: Got endpoints: latency-svc-z4l28 [751.621394ms]
Dec 17 20:51:09.177: INFO: Created: latency-svc-sssl5
Dec 17 20:51:09.203: INFO: Got endpoints: latency-svc-2qgvp [750.796654ms]
Dec 17 20:51:09.214: INFO: Created: latency-svc-l8wft
Dec 17 20:51:09.250: INFO: Got endpoints: latency-svc-kddmf [747.332934ms]
Dec 17 20:51:09.265: INFO: Created: latency-svc-42phz
Dec 17 20:51:09.300: INFO: Got endpoints: latency-svc-jxtl7 [749.961301ms]
Dec 17 20:51:09.313: INFO: Created: latency-svc-cbnzp
Dec 17 20:51:09.351: INFO: Got endpoints: latency-svc-gkp5w [748.981042ms]
Dec 17 20:51:09.365: INFO: Created: latency-svc-754vm
Dec 17 20:51:09.402: INFO: Got endpoints: latency-svc-bq9ks [750.295007ms]
Dec 17 20:51:09.413: INFO: Created: latency-svc-6jp7f
Dec 17 20:51:09.449: INFO: Got endpoints: latency-svc-t99hc [747.677347ms]
Dec 17 20:51:09.463: INFO: Created: latency-svc-l5qmb
Dec 17 20:51:09.503: INFO: Got endpoints: latency-svc-wm6mc [751.082949ms]
Dec 17 20:51:09.514: INFO: Created: latency-svc-zswwr
Dec 17 20:51:09.551: INFO: Got endpoints: latency-svc-l6k7q [748.642098ms]
Dec 17 20:51:09.563: INFO: Created: latency-svc-jfz98
Dec 17 20:51:09.600: INFO: Got endpoints: latency-svc-srchg [747.629581ms]
Dec 17 20:51:09.615: INFO: Created: latency-svc-nndq6
Dec 17 20:51:09.652: INFO: Got endpoints: latency-svc-76gjr [749.926857ms]
Dec 17 20:51:09.665: INFO: Created: latency-svc-5m7fg
Dec 17 20:51:09.702: INFO: Got endpoints: latency-svc-qbwsc [752.814485ms]
Dec 17 20:51:09.718: INFO: Created: latency-svc-hflq8
Dec 17 20:51:09.753: INFO: Got endpoints: latency-svc-jlxdp [753.335567ms]
Dec 17 20:51:09.766: INFO: Created: latency-svc-lqrw9
Dec 17 20:51:09.803: INFO: Got endpoints: latency-svc-lxcnb [752.95027ms]
Dec 17 20:51:09.817: INFO: Created: latency-svc-2jcsv
Dec 17 20:51:09.851: INFO: Got endpoints: latency-svc-d7x88 [745.963369ms]
Dec 17 20:51:09.863: INFO: Created: latency-svc-nhnqt
Dec 17 20:51:09.902: INFO: Got endpoints: latency-svc-sssl5 [745.990492ms]
Dec 17 20:51:09.913: INFO: Created: latency-svc-gfhlp
Dec 17 20:51:09.950: INFO: Got endpoints: latency-svc-l8wft [747.113422ms]
Dec 17 20:51:09.964: INFO: Created: latency-svc-cff6r
Dec 17 20:51:10.002: INFO: Got endpoints: latency-svc-42phz [751.830418ms]
Dec 17 20:51:10.015: INFO: Created: latency-svc-9jgw4
Dec 17 20:51:10.052: INFO: Got endpoints: latency-svc-cbnzp [752.071267ms]
Dec 17 20:51:10.068: INFO: Created: latency-svc-hxnvc
Dec 17 20:51:10.101: INFO: Got endpoints: latency-svc-754vm [749.924617ms]
Dec 17 20:51:10.115: INFO: Created: latency-svc-dql65
Dec 17 20:51:10.153: INFO: Got endpoints: latency-svc-6jp7f [750.948863ms]
Dec 17 20:51:10.166: INFO: Created: latency-svc-z5smn
Dec 17 20:51:10.202: INFO: Got endpoints: latency-svc-l5qmb [752.140456ms]
Dec 17 20:51:10.215: INFO: Created: latency-svc-tvdsb
Dec 17 20:51:10.252: INFO: Got endpoints: latency-svc-zswwr [748.814108ms]
Dec 17 20:51:10.265: INFO: Created: latency-svc-5t587
Dec 17 20:51:10.300: INFO: Got endpoints: latency-svc-jfz98 [748.61863ms]
Dec 17 20:51:10.315: INFO: Created: latency-svc-5dg5t
Dec 17 20:51:10.351: INFO: Got endpoints: latency-svc-nndq6 [751.091602ms]
Dec 17 20:51:10.364: INFO: Created: latency-svc-5nkfl
Dec 17 20:51:10.400: INFO: Got endpoints: latency-svc-5m7fg [748.193546ms]
Dec 17 20:51:10.418: INFO: Created: latency-svc-nz9mn
Dec 17 20:51:10.450: INFO: Got endpoints: latency-svc-hflq8 [747.978266ms]
Dec 17 20:51:10.464: INFO: Created: latency-svc-4pl4g
Dec 17 20:51:10.502: INFO: Got endpoints: latency-svc-lqrw9 [749.444946ms]
Dec 17 20:51:10.516: INFO: Created: latency-svc-4wxxk
Dec 17 20:51:10.551: INFO: Got endpoints: latency-svc-2jcsv [748.635007ms]
Dec 17 20:51:10.565: INFO: Created: latency-svc-fjnmr
Dec 17 20:51:10.600: INFO: Got endpoints: latency-svc-nhnqt [748.764282ms]
Dec 17 20:51:10.614: INFO: Created: latency-svc-pwvxf
Dec 17 20:51:10.652: INFO: Got endpoints: latency-svc-gfhlp [749.865719ms]
Dec 17 20:51:10.665: INFO: Created: latency-svc-4jmqj
Dec 17 20:51:10.701: INFO: Got endpoints: latency-svc-cff6r [750.921831ms]
Dec 17 20:51:10.712: INFO: Created: latency-svc-kjvn9
Dec 17 20:51:10.753: INFO: Got endpoints: latency-svc-9jgw4 [751.116702ms]
Dec 17 20:51:10.766: INFO: Created: latency-svc-sgpxp
Dec 17 20:51:10.800: INFO: Got endpoints: latency-svc-hxnvc [747.948363ms]
Dec 17 20:51:10.817: INFO: Created: latency-svc-pft2g
Dec 17 20:51:10.859: INFO: Got endpoints: latency-svc-dql65 [758.001825ms]
Dec 17 20:51:10.873: INFO: Created: latency-svc-xfc9c
Dec 17 20:51:10.901: INFO: Got endpoints: latency-svc-z5smn [747.977692ms]
Dec 17 20:51:10.919: INFO: Created: latency-svc-j6zv6
Dec 17 20:51:10.960: INFO: Got endpoints: latency-svc-tvdsb [758.130104ms]
Dec 17 20:51:10.975: INFO: Created: latency-svc-gvhvb
Dec 17 20:51:11.002: INFO: Got endpoints: latency-svc-5t587 [750.100554ms]
Dec 17 20:51:11.016: INFO: Created: latency-svc-bhm22
Dec 17 20:51:11.052: INFO: Got endpoints: latency-svc-5dg5t [752.087216ms]
Dec 17 20:51:11.065: INFO: Created: latency-svc-6rprw
Dec 17 20:51:11.101: INFO: Got endpoints: latency-svc-5nkfl [749.929379ms]
Dec 17 20:51:11.116: INFO: Created: latency-svc-sdptr
Dec 17 20:51:11.163: INFO: Got endpoints: latency-svc-nz9mn [762.87455ms]
Dec 17 20:51:11.179: INFO: Created: latency-svc-llpfh
Dec 17 20:51:11.201: INFO: Got endpoints: latency-svc-4pl4g [751.272169ms]
Dec 17 20:51:11.215: INFO: Created: latency-svc-lwskl
Dec 17 20:51:11.251: INFO: Got endpoints: latency-svc-4wxxk [748.454913ms]
Dec 17 20:51:11.264: INFO: Created: latency-svc-qvk4h
Dec 17 20:51:11.299: INFO: Got endpoints: latency-svc-fjnmr [747.630417ms]
Dec 17 20:51:11.316: INFO: Created: latency-svc-k5vg7
Dec 17 20:51:11.350: INFO: Got endpoints: latency-svc-pwvxf [750.509813ms]
Dec 17 20:51:11.365: INFO: Created: latency-svc-7ggvv
Dec 17 20:51:11.401: INFO: Got endpoints: latency-svc-4jmqj [748.915328ms]
Dec 17 20:51:11.416: INFO: Created: latency-svc-8bf9g
Dec 17 20:51:11.451: INFO: Got endpoints: latency-svc-kjvn9 [749.725095ms]
Dec 17 20:51:11.462: INFO: Created: latency-svc-k842q
Dec 17 20:51:11.500: INFO: Got endpoints: latency-svc-sgpxp [746.873376ms]
Dec 17 20:51:11.518: INFO: Created: latency-svc-2cvvz
Dec 17 20:51:11.552: INFO: Got endpoints: latency-svc-pft2g [751.693271ms]
Dec 17 20:51:11.565: INFO: Created: latency-svc-t5z9w
Dec 17 20:51:11.601: INFO: Got endpoints: latency-svc-xfc9c [742.31269ms]
Dec 17 20:51:11.614: INFO: Created: latency-svc-xm2pb
Dec 17 20:51:11.652: INFO: Got endpoints: latency-svc-j6zv6 [751.465591ms]
Dec 17 20:51:11.665: INFO: Created: latency-svc-68n2g
Dec 17 20:51:11.703: INFO: Got endpoints: latency-svc-gvhvb [742.646414ms]
Dec 17 20:51:11.715: INFO: Created: latency-svc-dbgfs
Dec 17 20:51:11.755: INFO: Got endpoints: latency-svc-bhm22 [753.050125ms]
Dec 17 20:51:11.771: INFO: Created: latency-svc-9j7xs
Dec 17 20:51:11.801: INFO: Got endpoints: latency-svc-6rprw [748.98266ms]
Dec 17 20:51:11.815: INFO: Created: latency-svc-grq87
Dec 17 20:51:11.851: INFO: Got endpoints: latency-svc-sdptr [749.827485ms]
Dec 17 20:51:11.866: INFO: Created: latency-svc-9gcxt
Dec 17 20:51:11.902: INFO: Got endpoints: latency-svc-llpfh [739.490757ms]
Dec 17 20:51:11.915: INFO: Created: latency-svc-btmdz
Dec 17 20:51:11.953: INFO: Got endpoints: latency-svc-lwskl [751.572038ms]
Dec 17 20:51:11.966: INFO: Created: latency-svc-5rqqb
Dec 17 20:51:11.999: INFO: Got endpoints: latency-svc-qvk4h [748.596187ms]
Dec 17 20:51:12.016: INFO: Created: latency-svc-mn9z7
Dec 17 20:51:12.050: INFO: Got endpoints: latency-svc-k5vg7 [751.300799ms]
Dec 17 20:51:12.065: INFO: Created: latency-svc-q2fxh
Dec 17 20:51:12.105: INFO: Got endpoints: latency-svc-7ggvv [754.566233ms]
Dec 17 20:51:12.123: INFO: Created: latency-svc-p5bfc
Dec 17 20:51:12.152: INFO: Got endpoints: latency-svc-8bf9g [751.020349ms]
Dec 17 20:51:12.164: INFO: Created: latency-svc-bt6gf
Dec 17 20:51:12.203: INFO: Got endpoints: latency-svc-k842q [752.027949ms]
Dec 17 20:51:12.215: INFO: Created: latency-svc-jlddw
Dec 17 20:51:12.252: INFO: Got endpoints: latency-svc-2cvvz [751.95675ms]
Dec 17 20:51:12.268: INFO: Created: latency-svc-xzlw6
Dec 17 20:51:12.301: INFO: Got endpoints: latency-svc-t5z9w [749.724805ms]
Dec 17 20:51:12.313: INFO: Created: latency-svc-66k6h
Dec 17 20:51:12.351: INFO: Got endpoints: latency-svc-xm2pb [749.640207ms]
Dec 17 20:51:12.363: INFO: Created: latency-svc-g4t4t
Dec 17 20:51:12.403: INFO: Got endpoints: latency-svc-68n2g [750.372522ms]
Dec 17 20:51:12.416: INFO: Created: latency-svc-lswpf
Dec 17 20:51:12.451: INFO: Got endpoints: latency-svc-dbgfs [748.146044ms]
Dec 17 20:51:12.464: INFO: Created: latency-svc-xblwf
Dec 17 20:51:12.503: INFO: Got endpoints: latency-svc-9j7xs [747.81413ms]
Dec 17 20:51:12.514: INFO: Created: latency-svc-vx8q8
Dec 17 20:51:12.550: INFO: Got endpoints: latency-svc-grq87 [748.979726ms]
Dec 17 20:51:12.566: INFO: Created: latency-svc-8sg2f
Dec 17 20:51:12.602: INFO: Got endpoints: latency-svc-9gcxt [750.947627ms]
Dec 17 20:51:12.615: INFO: Created: latency-svc-fcs5q
Dec 17 20:51:12.651: INFO: Got endpoints: latency-svc-btmdz [748.485896ms]
Dec 17 20:51:12.664: INFO: Created: latency-svc-zvdj7
Dec 17 20:51:12.701: INFO: Got endpoints: latency-svc-5rqqb [748.383706ms]
Dec 17 20:51:12.720: INFO: Created: latency-svc-6j55c
Dec 17 20:51:12.758: INFO: Got endpoints: latency-svc-mn9z7 [758.359042ms]
Dec 17 20:51:12.772: INFO: Created: latency-svc-t5t6h
Dec 17 20:51:12.802: INFO: Got endpoints: latency-svc-q2fxh [751.244179ms]
Dec 17 20:51:12.813: INFO: Created: latency-svc-s6k9q
Dec 17 20:51:12.851: INFO: Got endpoints: latency-svc-p5bfc [746.295559ms]
Dec 17 20:51:12.864: INFO: Created: latency-svc-fcqd4
Dec 17 20:51:12.900: INFO: Got endpoints: latency-svc-bt6gf [747.887843ms]
Dec 17 20:51:12.914: INFO: Created: latency-svc-44g2c
Dec 17 20:51:12.950: INFO: Got endpoints: latency-svc-jlddw [746.914521ms]
Dec 17 20:51:12.965: INFO: Created: latency-svc-ntmmp
Dec 17 20:51:13.005: INFO: Got endpoints: latency-svc-xzlw6 [753.030405ms]
Dec 17 20:51:13.019: INFO: Created: latency-svc-gqckl
Dec 17 20:51:13.054: INFO: Got endpoints: latency-svc-66k6h [752.359436ms]
Dec 17 20:51:13.066: INFO: Created: latency-svc-8hf2w
Dec 17 20:51:13.109: INFO: Got endpoints: latency-svc-g4t4t [757.975937ms]
Dec 17 20:51:13.123: INFO: Created: latency-svc-wftn9
Dec 17 20:51:13.156: INFO: Got endpoints: latency-svc-lswpf [753.208038ms]
Dec 17 20:51:13.192: INFO: Created: latency-svc-l92d2
Dec 17 20:51:13.205: INFO: Got endpoints: latency-svc-xblwf [754.135332ms]
Dec 17 20:51:13.217: INFO: Created: latency-svc-7pqgp
Dec 17 20:51:13.252: INFO: Got endpoints: latency-svc-vx8q8 [748.920299ms]
Dec 17 20:51:13.262: INFO: Created: latency-svc-shcpl
Dec 17 20:51:13.301: INFO: Got endpoints: latency-svc-8sg2f [750.924279ms]
Dec 17 20:51:13.353: INFO: Got endpoints: latency-svc-fcs5q [750.948008ms]
Dec 17 20:51:13.401: INFO: Got endpoints: latency-svc-zvdj7 [750.417359ms]
Dec 17 20:51:13.451: INFO: Got endpoints: latency-svc-6j55c [749.53834ms]
Dec 17 20:51:13.501: INFO: Got endpoints: latency-svc-t5t6h [742.928181ms]
Dec 17 20:51:13.551: INFO: Got endpoints: latency-svc-s6k9q [749.109515ms]
Dec 17 20:51:13.600: INFO: Got endpoints: latency-svc-fcqd4 [748.623009ms]
Dec 17 20:51:13.652: INFO: Got endpoints: latency-svc-44g2c [752.006657ms]
Dec 17 20:51:13.702: INFO: Got endpoints: latency-svc-ntmmp [751.981505ms]
Dec 17 20:51:13.750: INFO: Got endpoints: latency-svc-gqckl [744.893323ms]
Dec 17 20:51:13.800: INFO: Got endpoints: latency-svc-8hf2w [745.90819ms]
Dec 17 20:51:13.853: INFO: Got endpoints: latency-svc-wftn9 [743.771073ms]
Dec 17 20:51:13.901: INFO: Got endpoints: latency-svc-l92d2 [745.472697ms]
Dec 17 20:51:13.953: INFO: Got endpoints: latency-svc-7pqgp [747.533385ms]
Dec 17 20:51:14.002: INFO: Got endpoints: latency-svc-shcpl [750.042506ms]
Dec 17 20:51:14.002: INFO: Latencies: [23.536137ms 29.304183ms 46.459438ms 51.6008ms 65.648444ms 84.130198ms 90.636655ms 112.299192ms 123.267781ms 179.072405ms 185.469367ms 200.49788ms 201.036856ms 201.945609ms 203.951681ms 207.431247ms 207.476873ms 207.696524ms 210.419753ms 210.8287ms 213.488867ms 215.141961ms 219.259151ms 219.372201ms 220.393792ms 221.222499ms 226.114981ms 226.639196ms 227.365376ms 229.760802ms 238.380343ms 241.826188ms 244.888308ms 245.695776ms 254.054466ms 254.90678ms 257.057941ms 259.87575ms 264.590989ms 267.334761ms 267.528239ms 267.541956ms 268.810276ms 293.840975ms 322.731949ms 350.062999ms 393.502737ms 428.999162ms 467.69715ms 512.985603ms 538.892204ms 579.031671ms 610.373662ms 643.031878ms 687.84992ms 724.516287ms 733.258062ms 738.728123ms 739.490757ms 740.992214ms 742.31269ms 742.646414ms 742.928181ms 743.263046ms 743.771073ms 744.647263ms 744.893323ms 745.472697ms 745.90819ms 745.963369ms 745.966425ms 745.990492ms 746.013424ms 746.295559ms 746.656923ms 746.700782ms 746.873376ms 746.914521ms 747.113422ms 747.332934ms 747.533385ms 747.629581ms 747.630417ms 747.677347ms 747.81413ms 747.847163ms 747.887843ms 747.915586ms 747.916682ms 747.94128ms 747.948363ms 747.959547ms 747.977692ms 747.978266ms 748.077334ms 748.146044ms 748.193546ms 748.2755ms 748.383706ms 748.454913ms 748.485896ms 748.596187ms 748.61863ms 748.623009ms 748.635007ms 748.642098ms 748.737224ms 748.753429ms 748.764282ms 748.78661ms 748.789356ms 748.814108ms 748.915328ms 748.920299ms 748.979726ms 748.981042ms 748.98266ms 749.109515ms 749.378204ms 749.444946ms 749.451105ms 749.53834ms 749.555468ms 749.613419ms 749.640207ms 749.724805ms 749.725095ms 749.787174ms 749.827485ms 749.837871ms 749.865719ms 749.898688ms 749.924617ms 749.926857ms 749.929379ms 749.947022ms 749.961301ms 750.042506ms 750.066146ms 750.100554ms 750.263943ms 750.295007ms 750.336959ms 750.372522ms 750.417359ms 750.509813ms 750.754715ms 750.796654ms 750.804229ms 750.921831ms 750.924279ms 750.947627ms 750.948008ms 750.948863ms 750.9572ms 751.020349ms 751.082949ms 751.091602ms 751.116702ms 751.244179ms 751.272169ms 751.300799ms 751.465591ms 751.49152ms 751.572038ms 751.621394ms 751.693271ms 751.715768ms 751.71841ms 751.830418ms 751.941104ms 751.95675ms 751.981505ms 752.006657ms 752.027949ms 752.051854ms 752.071267ms 752.087216ms 752.115246ms 752.140456ms 752.359436ms 752.76081ms 752.814485ms 752.95027ms 753.030405ms 753.050125ms 753.208038ms 753.282426ms 753.335567ms 753.482347ms 753.884616ms 753.916735ms 754.135332ms 754.566233ms 757.056603ms 757.975937ms 758.001825ms 758.130104ms 758.359042ms 762.87455ms]
Dec 17 20:51:14.002: INFO: 50 %ile: 748.485896ms
Dec 17 20:51:14.002: INFO: 90 %ile: 752.359436ms
Dec 17 20:51:14.002: INFO: 99 %ile: 758.359042ms
Dec 17 20:51:14.002: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:51:14.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-swkpw" for this suite.
Dec 17 20:51:30.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:51:30.153: INFO: namespace: e2e-tests-svc-latency-swkpw, resource: bindings, ignored listing per whitelist
Dec 17 20:51:30.216: INFO: namespace e2e-tests-svc-latency-swkpw deletion completed in 16.208306203s

• [SLOW TEST:28.286 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:51:30.218: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 17 20:51:30.331: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:51:34.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ctqj2" for this suite.
Dec 17 20:51:40.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:51:40.752: INFO: namespace: e2e-tests-init-container-ctqj2, resource: bindings, ignored listing per whitelist
Dec 17 20:51:40.911: INFO: namespace e2e-tests-init-container-ctqj2 deletion completed in 6.244617708s

• [SLOW TEST:10.693 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:51:40.911: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 17 20:51:51.226: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 6171
	[quantile=0.9] = 176388
	[quantile=0.99] = 277659
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 83983
	[quantile=0.9] = 589573
	[quantile=0.99] = 595565
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 12
	[quantile=0.99] = 70
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 12
	[quantile=0.9] = 27
	[quantile=0.99] = 53
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 13
	[quantile=0.9] = 20
	[quantile=0.99] = 27
For namespace_queue_latency_sum:
	[] = 6235
For namespace_queue_latency_count:
	[] = 369
For namespace_retries:
	[] = 371
For namespace_work_duration:
	[quantile=0.5] = 284681
	[quantile=0.9] = 420771
	[quantile=0.99] = 711751
For namespace_work_duration_sum:
	[] = 92934603
For namespace_work_duration_count:
	[] = 369
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:51:51.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g4875" for this suite.
Dec 17 20:51:57.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:51:57.465: INFO: namespace: e2e-tests-gc-g4875, resource: bindings, ignored listing per whitelist
Dec 17 20:51:57.594: INFO: namespace e2e-tests-gc-g4875 deletion completed in 6.361420092s

• [SLOW TEST:16.683 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:51:57.595: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-98030d48-023d-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 20:51:57.841: INFO: Waiting up to 5m0s for pod "pod-secrets-9805fd1c-023d-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-sz4zw" to be "success or failure"
Dec 17 20:51:57.844: INFO: Pod "pod-secrets-9805fd1c-023d-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.256963ms
Dec 17 20:51:59.848: INFO: Pod "pod-secrets-9805fd1c-023d-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007308334s
Dec 17 20:52:01.856: INFO: Pod "pod-secrets-9805fd1c-023d-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015084823s
STEP: Saw pod success
Dec 17 20:52:01.856: INFO: Pod "pod-secrets-9805fd1c-023d-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:52:01.861: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-secrets-9805fd1c-023d-11e9-9892-0a580a3c54b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 20:52:01.895: INFO: Waiting for pod pod-secrets-9805fd1c-023d-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:52:01.900: INFO: Pod pod-secrets-9805fd1c-023d-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:52:01.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sz4zw" for this suite.
Dec 17 20:52:07.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:52:08.048: INFO: namespace: e2e-tests-secrets-sz4zw, resource: bindings, ignored listing per whitelist
Dec 17 20:52:08.073: INFO: namespace e2e-tests-secrets-sz4zw deletion completed in 6.168410448s

• [SLOW TEST:10.479 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:52:08.074: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 17 20:52:12.771: INFO: Successfully updated pod "annotationupdate9e3462ad-023d-11e9-9892-0a580a3c54b9"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:52:14.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wkhmb" for this suite.
Dec 17 20:52:39.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:52:39.369: INFO: namespace: e2e-tests-downward-api-wkhmb, resource: bindings, ignored listing per whitelist
Dec 17 20:52:39.443: INFO: namespace e2e-tests-downward-api-wkhmb deletion completed in 24.406731281s

• [SLOW TEST:31.369 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:52:39.443: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-k5gdp
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec 17 20:52:39.670: INFO: Found 0 stateful pods, waiting for 3
Dec 17 20:52:49.685: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:52:49.685: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:52:49.685: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 20:52:49.697: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-k5gdp ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:52:49.968: INFO: stderr: ""
Dec 17 20:52:49.968: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:52:49.968: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 17 20:53:00.010: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 17 20:53:10.042: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-k5gdp ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:53:10.330: INFO: stderr: ""
Dec 17 20:53:10.330: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:53:10.330: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 17 20:53:20.353: INFO: Waiting for StatefulSet e2e-tests-statefulset-k5gdp/ss2 to complete update
Dec 17 20:53:20.353: INFO: Waiting for Pod e2e-tests-statefulset-k5gdp/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 17 20:53:30.361: INFO: Waiting for StatefulSet e2e-tests-statefulset-k5gdp/ss2 to complete update
STEP: Rolling back to a previous revision
Dec 17 20:53:40.362: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-k5gdp ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 17 20:53:40.639: INFO: stderr: ""
Dec 17 20:53:40.639: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 17 20:53:40.639: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 17 20:53:50.677: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 17 20:54:00.711: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config exec --namespace=e2e-tests-statefulset-k5gdp ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 17 20:54:01.029: INFO: stderr: ""
Dec 17 20:54:01.029: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 17 20:54:01.029: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 17 20:54:31.054: INFO: Deleting all statefulset in ns e2e-tests-statefulset-k5gdp
Dec 17 20:54:31.058: INFO: Scaling statefulset ss2 to 0
Dec 17 20:54:51.081: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 20:54:51.084: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:54:51.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-k5gdp" for this suite.
Dec 17 20:54:57.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:54:57.254: INFO: namespace: e2e-tests-statefulset-k5gdp, resource: bindings, ignored listing per whitelist
Dec 17 20:54:57.281: INFO: namespace e2e-tests-statefulset-k5gdp deletion completed in 6.164162015s

• [SLOW TEST:137.838 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:54:57.281: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-030ba8fb-023e-11e9-9892-0a580a3c54b9
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:54:59.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hjkvx" for this suite.
Dec 17 20:55:21.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:55:21.511: INFO: namespace: e2e-tests-configmap-hjkvx, resource: bindings, ignored listing per whitelist
Dec 17 20:55:21.626: INFO: namespace e2e-tests-configmap-hjkvx deletion completed in 22.184192908s

• [SLOW TEST:24.345 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:55:21.627: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-119dc43b-023e-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:55:21.844: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-119e6aaf-023e-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-h5lvd" to be "success or failure"
Dec 17 20:55:21.855: INFO: Pod "pod-projected-configmaps-119e6aaf-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.657085ms
Dec 17 20:55:23.860: INFO: Pod "pod-projected-configmaps-119e6aaf-023e-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016027117s
STEP: Saw pod success
Dec 17 20:55:23.860: INFO: Pod "pod-projected-configmaps-119e6aaf-023e-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:55:23.864: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-configmaps-119e6aaf-023e-11e9-9892-0a580a3c54b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 20:55:23.890: INFO: Waiting for pod pod-projected-configmaps-119e6aaf-023e-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:55:23.897: INFO: Pod pod-projected-configmaps-119e6aaf-023e-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:55:23.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h5lvd" for this suite.
Dec 17 20:55:29.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:55:29.996: INFO: namespace: e2e-tests-projected-h5lvd, resource: bindings, ignored listing per whitelist
Dec 17 20:55:30.088: INFO: namespace e2e-tests-projected-h5lvd deletion completed in 6.186901984s

• [SLOW TEST:8.461 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:55:30.088: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:55:30.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-169e21ac-023e-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-bnt6v" to be "success or failure"
Dec 17 20:55:30.247: INFO: Pod "downwardapi-volume-169e21ac-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.119562ms
Dec 17 20:55:32.250: INFO: Pod "downwardapi-volume-169e21ac-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016490726s
Dec 17 20:55:34.254: INFO: Pod "downwardapi-volume-169e21ac-023e-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020367033s
STEP: Saw pod success
Dec 17 20:55:34.254: INFO: Pod "downwardapi-volume-169e21ac-023e-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:55:34.257: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-169e21ac-023e-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:55:34.283: INFO: Waiting for pod downwardapi-volume-169e21ac-023e-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:55:34.286: INFO: Pod downwardapi-volume-169e21ac-023e-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:55:34.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bnt6v" for this suite.
Dec 17 20:55:40.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:55:40.412: INFO: namespace: e2e-tests-projected-bnt6v, resource: bindings, ignored listing per whitelist
Dec 17 20:55:40.592: INFO: namespace e2e-tests-projected-bnt6v deletion completed in 6.303122359s

• [SLOW TEST:10.504 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:55:40.592: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-1ce960c8-023e-11e9-9892-0a580a3c54b9
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-1ce960c8-023e-11e9-9892-0a580a3c54b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:56:53.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l6hhx" for this suite.
Dec 17 20:57:19.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:57:19.373: INFO: namespace: e2e-tests-projected-l6hhx, resource: bindings, ignored listing per whitelist
Dec 17 20:57:19.375: INFO: namespace e2e-tests-projected-l6hhx deletion completed in 26.115012508s

• [SLOW TEST:98.782 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:57:19.375: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:57:19.488: INFO: Waiting up to 5m0s for pod "downwardapi-volume-57bc5899-023e-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-n2jpw" to be "success or failure"
Dec 17 20:57:19.497: INFO: Pod "downwardapi-volume-57bc5899-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.71349ms
Dec 17 20:57:21.500: INFO: Pod "downwardapi-volume-57bc5899-023e-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012389811s
STEP: Saw pod success
Dec 17 20:57:21.500: INFO: Pod "downwardapi-volume-57bc5899-023e-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:57:21.503: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-57bc5899-023e-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:57:21.535: INFO: Waiting for pod downwardapi-volume-57bc5899-023e-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:57:21.539: INFO: Pod downwardapi-volume-57bc5899-023e-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:57:21.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n2jpw" for this suite.
Dec 17 20:57:27.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:57:27.678: INFO: namespace: e2e-tests-projected-n2jpw, resource: bindings, ignored listing per whitelist
Dec 17 20:57:27.688: INFO: namespace e2e-tests-projected-n2jpw deletion completed in 6.145826106s

• [SLOW TEST:8.313 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:57:27.689: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 17 20:57:37.909: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 6171
	[quantile=0.9] = 176388
	[quantile=0.99] = 277659
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 83983
	[quantile=0.9] = 589573
	[quantile=0.99] = 595565
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 6
	[quantile=0.99] = 33
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 12
	[quantile=0.9] = 28
	[quantile=0.99] = 61
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 13
	[quantile=0.9] = 15
	[quantile=0.99] = 24
For namespace_queue_latency_sum:
	[] = 6523
For namespace_queue_latency_count:
	[] = 390
For namespace_retries:
	[] = 393
For namespace_work_duration:
	[quantile=0.5] = 279955
	[quantile=0.9] = 554977
	[quantile=0.99] = 3270127
For namespace_work_duration_sum:
	[] = 101670481
For namespace_work_duration_count:
	[] = 390
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:57:37.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gfw2l" for this suite.
Dec 17 20:57:43.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:57:44.052: INFO: namespace: e2e-tests-gc-gfw2l, resource: bindings, ignored listing per whitelist
Dec 17 20:57:44.125: INFO: namespace e2e-tests-gc-gfw2l deletion completed in 6.211629548s

• [SLOW TEST:16.436 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:57:44.125: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec 17 20:57:44.238: INFO: Waiting up to 5m0s for pod "var-expansion-667e212a-023e-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-var-expansion-dbrrm" to be "success or failure"
Dec 17 20:57:44.243: INFO: Pod "var-expansion-667e212a-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.475342ms
Dec 17 20:57:46.247: INFO: Pod "var-expansion-667e212a-023e-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.008228505s
Dec 17 20:57:48.252: INFO: Pod "var-expansion-667e212a-023e-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013539858s
STEP: Saw pod success
Dec 17 20:57:48.252: INFO: Pod "var-expansion-667e212a-023e-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:57:48.255: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod var-expansion-667e212a-023e-11e9-9892-0a580a3c54b9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 20:57:48.282: INFO: Waiting for pod var-expansion-667e212a-023e-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:57:48.285: INFO: Pod var-expansion-667e212a-023e-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:57:48.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-dbrrm" for this suite.
Dec 17 20:57:54.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:57:54.409: INFO: namespace: e2e-tests-var-expansion-dbrrm, resource: bindings, ignored listing per whitelist
Dec 17 20:57:54.413: INFO: namespace e2e-tests-var-expansion-dbrrm deletion completed in 6.12521771s

• [SLOW TEST:10.288 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:57:54.414: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-lxszw/configmap-test-6c9fce08-023e-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 20:57:54.530: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ca08f57-023e-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-lxszw" to be "success or failure"
Dec 17 20:57:54.548: INFO: Pod "pod-configmaps-6ca08f57-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 17.831882ms
Dec 17 20:57:56.552: INFO: Pod "pod-configmaps-6ca08f57-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021638513s
Dec 17 20:57:58.556: INFO: Pod "pod-configmaps-6ca08f57-023e-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025461035s
STEP: Saw pod success
Dec 17 20:57:58.556: INFO: Pod "pod-configmaps-6ca08f57-023e-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:57:58.559: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-6ca08f57-023e-11e9-9892-0a580a3c54b9 container env-test: <nil>
STEP: delete the pod
Dec 17 20:57:58.601: INFO: Waiting for pod pod-configmaps-6ca08f57-023e-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:57:58.605: INFO: Pod pod-configmaps-6ca08f57-023e-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:57:58.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lxszw" for this suite.
Dec 17 20:58:04.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:58:04.724: INFO: namespace: e2e-tests-configmap-lxszw, resource: bindings, ignored listing per whitelist
Dec 17 20:58:04.750: INFO: namespace e2e-tests-configmap-lxszw deletion completed in 6.142250706s

• [SLOW TEST:10.336 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:58:04.750: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-gxwf7
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-gxwf7
STEP: Deleting pre-stop pod
Dec 17 20:58:17.935: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:58:17.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-gxwf7" for this suite.
Dec 17 20:58:57.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:58:58.012: INFO: namespace: e2e-tests-prestop-gxwf7, resource: bindings, ignored listing per whitelist
Dec 17 20:58:58.171: INFO: namespace e2e-tests-prestop-gxwf7 deletion completed in 40.220310331s

• [SLOW TEST:53.421 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:58:58.171: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 17 20:58:58.293: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92a1acb3-023e-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-vc68n" to be "success or failure"
Dec 17 20:58:58.300: INFO: Pod "downwardapi-volume-92a1acb3-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.821649ms
Dec 17 20:59:00.305: INFO: Pod "downwardapi-volume-92a1acb3-023e-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011928197s
Dec 17 20:59:02.309: INFO: Pod "downwardapi-volume-92a1acb3-023e-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015897468s
STEP: Saw pod success
Dec 17 20:59:02.309: INFO: Pod "downwardapi-volume-92a1acb3-023e-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 20:59:02.312: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downwardapi-volume-92a1acb3-023e-11e9-9892-0a580a3c54b9 container client-container: <nil>
STEP: delete the pod
Dec 17 20:59:02.354: INFO: Waiting for pod downwardapi-volume-92a1acb3-023e-11e9-9892-0a580a3c54b9 to disappear
Dec 17 20:59:02.359: INFO: Pod downwardapi-volume-92a1acb3-023e-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:59:02.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vc68n" for this suite.
Dec 17 20:59:08.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:59:08.427: INFO: namespace: e2e-tests-downward-api-vc68n, resource: bindings, ignored listing per whitelist
Dec 17 20:59:08.545: INFO: namespace e2e-tests-downward-api-vc68n deletion completed in 6.182004022s

• [SLOW TEST:10.374 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:59:08.545: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec 17 20:59:12.672: INFO: Pod pod-hostip-98ce64da-023e-11e9-9892-0a580a3c54b9 has hostIP: 10.128.0.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:59:12.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-98zqr" for this suite.
Dec 17 20:59:34.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:59:34.722: INFO: namespace: e2e-tests-pods-98zqr, resource: bindings, ignored listing per whitelist
Dec 17 20:59:34.825: INFO: namespace e2e-tests-pods-98zqr deletion completed in 22.149356468s

• [SLOW TEST:26.280 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:59:34.825: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 20:59:34.931: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 17 20:59:34.943: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 17 20:59:39.947: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 20:59:39.947: INFO: Creating deployment "test-rolling-update-deployment"
Dec 17 20:59:39.954: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 17 20:59:39.969: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 17 20:59:41.977: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 17 20:59:41.980: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 17 20:59:41.989: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-dvvw9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dvvw9/deployments/test-rolling-update-deployment,UID:ab73573b-023e-11e9-b8bf-42010a800002,ResourceVersion:15513,Generation:1,CreationTimestamp:2018-12-17 20:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-17 20:59:40 +0000 UTC 2018-12-17 20:59:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-17 20:59:41 +0000 UTC 2018-12-17 20:59:39 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 17 20:59:41.993: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-dvvw9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dvvw9/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:ab79f652-023e-11e9-b8bf-42010a800002,ResourceVersion:15506,Generation:1,CreationTimestamp:2018-12-17 20:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ab73573b-023e-11e9-b8bf-42010a800002 0xc002aaa3b7 0xc002aaa3b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 17 20:59:41.993: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 17 20:59:41.993: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-dvvw9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dvvw9/replicasets/test-rolling-update-controller,UID:a875db76-023e-11e9-b8bf-42010a800002,ResourceVersion:15512,Generation:2,CreationTimestamp:2018-12-17 20:59:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ab73573b-023e-11e9-b8bf-42010a800002 0xc002aaa2f7 0xc002aaa2f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 17 20:59:41.997: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-kbr9n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-kbr9n,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-dvvw9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-dvvw9/pods/test-rolling-update-deployment-68b55d7bc6-kbr9n,UID:ab7b588c-023e-11e9-b8bf-42010a800002,ResourceVersion:15505,Generation:0,CreationTimestamp:2018-12-17 20:59:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 ab79f652-023e-11e9-b8bf-42010a800002 0xc002aaaf97 0xc002aaaf98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4drwh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4drwh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4drwh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-tnzf,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002aab000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002aab020}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:59:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:59:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:59:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 20:59:39 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.3,PodIP:10.64.3.67,StartTime:2018-12-17 20:59:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-17 20:59:41 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://5291c6803ef51d260862bc9178356f2650d18cba5d640a34e168d6ba13edce0a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 20:59:41.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-dvvw9" for this suite.
Dec 17 20:59:48.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 20:59:48.085: INFO: namespace: e2e-tests-deployment-dvvw9, resource: bindings, ignored listing per whitelist
Dec 17 20:59:48.213: INFO: namespace e2e-tests-deployment-dvvw9 deletion completed in 6.213405165s

• [SLOW TEST:13.388 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 20:59:48.214: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 20:59:48.360: INFO: Number of nodes with available pods: 0
Dec 17 20:59:48.360: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 20:59:49.373: INFO: Number of nodes with available pods: 0
Dec 17 20:59:49.373: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 20:59:50.372: INFO: Number of nodes with available pods: 0
Dec 17 20:59:50.372: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 20:59:51.369: INFO: Number of nodes with available pods: 4
Dec 17 20:59:51.369: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 17 20:59:51.398: INFO: Number of nodes with available pods: 3
Dec 17 20:59:51.399: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:59:52.406: INFO: Number of nodes with available pods: 3
Dec 17 20:59:52.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:59:53.407: INFO: Number of nodes with available pods: 3
Dec 17 20:59:53.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:59:54.407: INFO: Number of nodes with available pods: 3
Dec 17 20:59:54.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:59:55.406: INFO: Number of nodes with available pods: 3
Dec 17 20:59:55.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:59:56.405: INFO: Number of nodes with available pods: 3
Dec 17 20:59:56.405: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:59:57.415: INFO: Number of nodes with available pods: 3
Dec 17 20:59:57.415: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:59:58.407: INFO: Number of nodes with available pods: 3
Dec 17 20:59:58.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 20:59:59.407: INFO: Number of nodes with available pods: 3
Dec 17 20:59:59.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:00.406: INFO: Number of nodes with available pods: 3
Dec 17 21:00:00.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:01.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:01.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:02.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:02.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:03.406: INFO: Number of nodes with available pods: 3
Dec 17 21:00:03.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:04.408: INFO: Number of nodes with available pods: 3
Dec 17 21:00:04.408: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:05.406: INFO: Number of nodes with available pods: 3
Dec 17 21:00:05.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:06.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:06.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:07.406: INFO: Number of nodes with available pods: 3
Dec 17 21:00:07.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:08.408: INFO: Number of nodes with available pods: 3
Dec 17 21:00:08.408: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:09.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:09.408: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:10.409: INFO: Number of nodes with available pods: 3
Dec 17 21:00:10.409: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:11.409: INFO: Number of nodes with available pods: 3
Dec 17 21:00:11.409: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:12.408: INFO: Number of nodes with available pods: 3
Dec 17 21:00:12.408: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:13.408: INFO: Number of nodes with available pods: 3
Dec 17 21:00:13.408: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:14.406: INFO: Number of nodes with available pods: 3
Dec 17 21:00:14.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:15.406: INFO: Number of nodes with available pods: 3
Dec 17 21:00:15.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:16.406: INFO: Number of nodes with available pods: 3
Dec 17 21:00:16.406: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:17.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:17.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:18.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:18.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:19.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:19.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:20.411: INFO: Number of nodes with available pods: 3
Dec 17 21:00:20.412: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:21.408: INFO: Number of nodes with available pods: 3
Dec 17 21:00:21.408: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:22.408: INFO: Number of nodes with available pods: 3
Dec 17 21:00:22.408: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:24.098: INFO: Number of nodes with available pods: 3
Dec 17 21:00:24.098: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:24.410: INFO: Number of nodes with available pods: 3
Dec 17 21:00:24.410: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:25.417: INFO: Number of nodes with available pods: 3
Dec 17 21:00:25.417: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:26.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:26.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:27.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:27.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:28.407: INFO: Number of nodes with available pods: 3
Dec 17 21:00:28.407: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:00:29.410: INFO: Number of nodes with available pods: 4
Dec 17 21:00:29.410: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-86n6z, will wait for the garbage collector to delete the pods
Dec 17 21:00:29.478: INFO: Deleting DaemonSet.extensions daemon-set took: 11.254349ms
Dec 17 21:00:29.578: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.334253ms
Dec 17 21:01:09.384: INFO: Number of nodes with available pods: 0
Dec 17 21:01:09.384: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 21:01:09.387: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-86n6z/daemonsets","resourceVersion":"15760"},"items":null}

Dec 17 21:01:09.390: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-86n6z/pods","resourceVersion":"15760"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:01:09.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-86n6z" for this suite.
Dec 17 21:01:15.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:01:15.482: INFO: namespace: e2e-tests-daemonsets-86n6z, resource: bindings, ignored listing per whitelist
Dec 17 21:01:15.607: INFO: namespace e2e-tests-daemonsets-86n6z deletion completed in 6.197360097s

• [SLOW TEST:87.394 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:01:15.607: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 17 21:01:15.728: INFO: namespace e2e-tests-kubectl-k46v5
Dec 17 21:01:15.728: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-k46v5'
Dec 17 21:01:18.669: INFO: stderr: ""
Dec 17 21:01:18.669: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 21:01:19.674: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 21:01:19.674: INFO: Found 0 / 1
Dec 17 21:01:20.675: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 21:01:20.675: INFO: Found 1 / 1
Dec 17 21:01:20.675: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 17 21:01:20.679: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 21:01:20.679: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 21:01:20.679: INFO: wait on redis-master startup in e2e-tests-kubectl-k46v5 
Dec 17 21:01:20.679: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config logs redis-master-q6pzv redis-master --namespace=e2e-tests-kubectl-k46v5'
Dec 17 21:01:20.783: INFO: stderr: ""
Dec 17 21:01:20.783: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 17 Dec 21:01:20.054 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Dec 21:01:20.054 # Server started, Redis version 3.2.12\n1:M 17 Dec 21:01:20.054 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Dec 21:01:20.054 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 17 21:01:20.783: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-k46v5'
Dec 17 21:01:20.894: INFO: stderr: ""
Dec 17 21:01:20.894: INFO: stdout: "service/rm2 exposed\n"
Dec 17 21:01:20.899: INFO: Service rm2 in namespace e2e-tests-kubectl-k46v5 found.
STEP: exposing service
Dec 17 21:01:22.906: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-k46v5'
Dec 17 21:01:23.010: INFO: stderr: ""
Dec 17 21:01:23.010: INFO: stdout: "service/rm3 exposed\n"
Dec 17 21:01:23.018: INFO: Service rm3 in namespace e2e-tests-kubectl-k46v5 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:01:25.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k46v5" for this suite.
Dec 17 21:01:47.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:01:47.170: INFO: namespace: e2e-tests-kubectl-k46v5, resource: bindings, ignored listing per whitelist
Dec 17 21:01:47.192: INFO: namespace e2e-tests-kubectl-k46v5 deletion completed in 22.162796975s

• [SLOW TEST:31.585 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:01:47.192: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec 17 21:01:47.302: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:01:47.653: INFO: stderr: ""
Dec 17 21:01:47.653: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 21:01:47.653: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:01:47.772: INFO: stderr: ""
Dec 17 21:01:47.772: INFO: stdout: "update-demo-nautilus-4pxl5 update-demo-nautilus-g6h6b "
Dec 17 21:01:47.772: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-4pxl5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:01:47.863: INFO: stderr: ""
Dec 17 21:01:47.863: INFO: stdout: ""
Dec 17 21:01:47.863: INFO: update-demo-nautilus-4pxl5 is created but not running
Dec 17 21:01:52.863: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:01:52.955: INFO: stderr: ""
Dec 17 21:01:52.955: INFO: stdout: "update-demo-nautilus-4pxl5 update-demo-nautilus-g6h6b "
Dec 17 21:01:52.955: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-4pxl5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:01:53.038: INFO: stderr: ""
Dec 17 21:01:53.038: INFO: stdout: "true"
Dec 17 21:01:53.038: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-4pxl5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:01:53.122: INFO: stderr: ""
Dec 17 21:01:53.122: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 21:01:53.122: INFO: validating pod update-demo-nautilus-4pxl5
Dec 17 21:01:53.136: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 21:01:53.136: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 21:01:53.136: INFO: update-demo-nautilus-4pxl5 is verified up and running
Dec 17 21:01:53.136: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-g6h6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:01:53.223: INFO: stderr: ""
Dec 17 21:01:53.223: INFO: stdout: "true"
Dec 17 21:01:53.224: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-g6h6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:01:53.311: INFO: stderr: ""
Dec 17 21:01:53.311: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 21:01:53.311: INFO: validating pod update-demo-nautilus-g6h6b
Dec 17 21:01:53.318: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 21:01:53.318: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 21:01:53.318: INFO: update-demo-nautilus-g6h6b is verified up and running
STEP: rolling-update to new replication controller
Dec 17 21:01:53.320: INFO: scanned /workspace for discovery docs: <nil>
Dec 17 21:01:53.320: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:02:16.348: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 17 21:02:16.348: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 21:02:16.348: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:02:16.573: INFO: stderr: ""
Dec 17 21:02:16.573: INFO: stdout: "update-demo-kitten-j5lwg update-demo-kitten-zqfff "
Dec 17 21:02:16.573: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-kitten-j5lwg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:02:16.809: INFO: stderr: ""
Dec 17 21:02:16.809: INFO: stdout: "true"
Dec 17 21:02:16.809: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-kitten-j5lwg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:02:17.051: INFO: stderr: ""
Dec 17 21:02:17.051: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 17 21:02:17.051: INFO: validating pod update-demo-kitten-j5lwg
Dec 17 21:02:17.232: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 17 21:02:17.232: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 17 21:02:17.233: INFO: update-demo-kitten-j5lwg is verified up and running
Dec 17 21:02:17.233: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-kitten-zqfff -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:02:17.457: INFO: stderr: ""
Dec 17 21:02:17.457: INFO: stdout: "true"
Dec 17 21:02:17.457: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-kitten-zqfff -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gbftj'
Dec 17 21:02:17.666: INFO: stderr: ""
Dec 17 21:02:17.666: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 17 21:02:17.666: INFO: validating pod update-demo-kitten-zqfff
Dec 17 21:02:17.698: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 17 21:02:17.698: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 17 21:02:17.698: INFO: update-demo-kitten-zqfff is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:02:17.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gbftj" for this suite.
Dec 17 21:02:37.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:02:37.784: INFO: namespace: e2e-tests-kubectl-gbftj, resource: bindings, ignored listing per whitelist
Dec 17 21:02:37.921: INFO: namespace e2e-tests-kubectl-gbftj deletion completed in 20.21849877s

• [SLOW TEST:50.729 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:02:37.921: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-159e77ab-023f-11e9-9892-0a580a3c54b9
STEP: Creating secret with name s-test-opt-upd-159e781e-023f-11e9-9892-0a580a3c54b9
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-159e77ab-023f-11e9-9892-0a580a3c54b9
STEP: Updating secret s-test-opt-upd-159e781e-023f-11e9-9892-0a580a3c54b9
STEP: Creating secret with name s-test-opt-create-159e7839-023f-11e9-9892-0a580a3c54b9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:03:56.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dks6w" for this suite.
Dec 17 21:04:18.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:04:18.755: INFO: namespace: e2e-tests-projected-dks6w, resource: bindings, ignored listing per whitelist
Dec 17 21:04:18.773: INFO: namespace e2e-tests-projected-dks6w deletion completed in 22.164139145s

• [SLOW TEST:100.853 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:04:18.773: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 21:04:18.988: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"51c22d4c-023f-11e9-b8bf-42010a800002", Controller:(*bool)(0xc0018966f2), BlockOwnerDeletion:(*bool)(0xc0018966f3)}}
Dec 17 21:04:19.007: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"51be6067-023f-11e9-b8bf-42010a800002", Controller:(*bool)(0xc0022e5b1e), BlockOwnerDeletion:(*bool)(0xc0022e5b1f)}}
Dec 17 21:04:19.028: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"51c01a59-023f-11e9-b8bf-42010a800002", Controller:(*bool)(0xc0022e5d42), BlockOwnerDeletion:(*bool)(0xc0022e5d43)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:04:24.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-h5xkk" for this suite.
Dec 17 21:04:30.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:04:30.099: INFO: namespace: e2e-tests-gc-h5xkk, resource: bindings, ignored listing per whitelist
Dec 17 21:04:30.190: INFO: namespace e2e-tests-gc-h5xkk deletion completed in 6.14289984s

• [SLOW TEST:11.417 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:04:30.190: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec 17 21:04:30.298: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 21:04:30.307: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 21:04:30.310: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-6xhw before test
Dec 17 21:04:30.323: INFO: fluentd-gcp-scaler-68b55c6dc5-xnl65 from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
Dec 17 21:04:30.323: INFO: metadata-proxy-v0.1-gd7pr from kube-system started at 2018-12-17 19:47:48 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 21:04:30.323: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 21:04:30.323: INFO: l7-default-backend-fd59995cd-bkm5h from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container default-http-backend ready: true, restart count 0
Dec 17 21:04:30.323: INFO: heapster-v1.6.0-beta.1-5f77ccd9dd-zwfwt from kube-system started at 2018-12-17 19:48:38 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container heapster ready: true, restart count 0
Dec 17 21:04:30.323: INFO: 	Container heapster-nanny ready: true, restart count 0
Dec 17 21:04:30.323: INFO: kube-dns-autoscaler-545db58f6f-rjwmd from kube-system started at 2018-12-17 19:48:38 +0000 UTC (1 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container autoscaler ready: true, restart count 0
Dec 17 21:04:30.323: INFO: event-exporter-v0.2.3-fdd9d7c84-jh2xj from kube-system started at 2018-12-17 19:47:48 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container event-exporter ready: true, restart count 0
Dec 17 21:04:30.323: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 21:04:30.323: INFO: kubernetes-dashboard-6bbb6846cd-8dqzv from kube-system started at 2018-12-17 19:48:38 +0000 UTC (1 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 17 21:04:30.323: INFO: coredns-fff89c9b9-dc8sd from kube-system started at 2018-12-17 19:47:48 +0000 UTC (1 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container coredns ready: true, restart count 0
Dec 17 21:04:30.323: INFO: fluentd-gcp-v3.2.0-txdr6 from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 21:04:30.323: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 21:04:30.323: INFO: metrics-server-v0.3.1-58d65f8d6-pp669 from kube-system started at 2018-12-17 19:48:38 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.323: INFO: 	Container metrics-server ready: true, restart count 0
Dec 17 21:04:30.323: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Dec 17 21:04:30.323: INFO: kube-proxy-bootstrap-e2e-minion-group-6xhw from kube-system started at <nil> (0 container statuses recorded)
Dec 17 21:04:30.323: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-tnzf before test
Dec 17 21:04:30.330: INFO: metadata-proxy-v0.1-lnjmm from kube-system started at 2018-12-17 19:47:49 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.330: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 21:04:30.330: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 21:04:30.330: INFO: coredns-fff89c9b9-s8fmm from kube-system started at 2018-12-17 19:48:45 +0000 UTC (1 container statuses recorded)
Dec 17 21:04:30.330: INFO: 	Container coredns ready: true, restart count 0
Dec 17 21:04:30.330: INFO: fluentd-gcp-v3.2.0-dqnzd from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.330: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 21:04:30.330: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 21:04:30.330: INFO: kube-proxy-bootstrap-e2e-minion-group-tnzf from kube-system started at <nil> (0 container statuses recorded)
Dec 17 21:04:30.330: INFO: 
Logging pods the kubelet thinks is on node bootstrap-e2e-minion-group-wjp3 before test
Dec 17 21:04:30.349: INFO: kube-proxy-bootstrap-e2e-minion-group-wjp3 from kube-system started at <nil> (0 container statuses recorded)
Dec 17 21:04:30.349: INFO: fluentd-gcp-v3.2.0-v2dvx from kube-system started at 2018-12-17 19:48:50 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.349: INFO: 	Container fluentd-gcp ready: true, restart count 0
Dec 17 21:04:30.349: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Dec 17 21:04:30.349: INFO: metadata-proxy-v0.1-727vr from kube-system started at 2018-12-17 19:47:49 +0000 UTC (2 container statuses recorded)
Dec 17 21:04:30.349: INFO: 	Container metadata-proxy ready: true, restart count 0
Dec 17 21:04:30.349: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-59c914cf-023f-11e9-9892-0a580a3c54b9 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-59c914cf-023f-11e9-9892-0a580a3c54b9 off the node bootstrap-e2e-minion-group-wjp3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-59c914cf-023f-11e9-9892-0a580a3c54b9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:04:36.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-s8d8c" for this suite.
Dec 17 21:04:50.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:04:50.615: INFO: namespace: e2e-tests-sched-pred-s8d8c, resource: bindings, ignored listing per whitelist
Dec 17 21:04:50.625: INFO: namespace e2e-tests-sched-pred-s8d8c deletion completed in 14.144092635s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:20.435 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:04:50.625: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-rwx4t
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rwx4t to expose endpoints map[]
Dec 17 21:04:50.767: INFO: Get endpoints failed (15.493925ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 17 21:04:51.771: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rwx4t exposes endpoints map[] (1.019297615s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rwx4t
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rwx4t to expose endpoints map[pod1:[100]]
Dec 17 21:04:53.814: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rwx4t exposes endpoints map[pod1:[100]] (2.031430382s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rwx4t
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rwx4t to expose endpoints map[pod1:[100] pod2:[101]]
Dec 17 21:04:55.868: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rwx4t exposes endpoints map[pod2:[101] pod1:[100]] (2.047090549s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rwx4t
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rwx4t to expose endpoints map[pod2:[101]]
Dec 17 21:04:55.897: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rwx4t exposes endpoints map[pod2:[101]] (20.226629ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rwx4t
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-rwx4t to expose endpoints map[]
Dec 17 21:04:56.915: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-rwx4t exposes endpoints map[] (1.007956614s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:04:56.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rwx4t" for this suite.
Dec 17 21:05:20.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:05:20.999: INFO: namespace: e2e-tests-services-rwx4t, resource: bindings, ignored listing per whitelist
Dec 17 21:05:21.075: INFO: namespace e2e-tests-services-rwx4t deletion completed in 24.135284919s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.450 seconds]
[sig-network] Services
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:05:21.075: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:05:43.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-8vhzk" for this suite.
Dec 17 21:05:49.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:05:49.638: INFO: namespace: e2e-tests-container-runtime-8vhzk, resource: bindings, ignored listing per whitelist
Dec 17 21:05:49.670: INFO: namespace e2e-tests-container-runtime-8vhzk deletion completed in 6.207886087s

• [SLOW TEST:28.595 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:05:49.670: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec 17 21:05:49.781: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config --namespace=e2e-tests-kubectl-6wjlb run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 17 21:05:52.532: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 17 21:05:52.533: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:05:54.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6wjlb" for this suite.
Dec 17 21:06:00.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:06:00.644: INFO: namespace: e2e-tests-kubectl-6wjlb, resource: bindings, ignored listing per whitelist
Dec 17 21:06:00.711: INFO: namespace e2e-tests-kubectl-6wjlb deletion completed in 6.165969292s

• [SLOW TEST:11.040 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:06:00.711: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 17 21:06:06.895: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:06.900: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:08.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:08.904: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:10.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:10.903: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:12.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:12.906: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:14.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:14.904: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:16.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:16.904: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:18.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:18.904: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:20.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:20.903: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:22.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:22.904: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 21:06:24.900: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 21:06:24.905: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:06:24.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-ssw9d" for this suite.
Dec 17 21:06:46.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:06:47.020: INFO: namespace: e2e-tests-container-lifecycle-hook-ssw9d, resource: bindings, ignored listing per whitelist
Dec 17 21:06:47.084: INFO: namespace e2e-tests-container-lifecycle-hook-ssw9d deletion completed in 22.17412781s

• [SLOW TEST:46.374 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:06:47.085: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec 17 21:06:47.234: INFO: Waiting up to 5m0s for pod "client-containers-aa2461dd-023f-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-containers-vtlms" to be "success or failure"
Dec 17 21:06:47.244: INFO: Pod "client-containers-aa2461dd-023f-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.261822ms
Dec 17 21:06:49.247: INFO: Pod "client-containers-aa2461dd-023f-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012940606s
STEP: Saw pod success
Dec 17 21:06:49.247: INFO: Pod "client-containers-aa2461dd-023f-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:06:49.250: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod client-containers-aa2461dd-023f-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 21:06:49.273: INFO: Waiting for pod client-containers-aa2461dd-023f-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:06:49.278: INFO: Pod client-containers-aa2461dd-023f-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:06:49.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-vtlms" for this suite.
Dec 17 21:06:55.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:06:55.400: INFO: namespace: e2e-tests-containers-vtlms, resource: bindings, ignored listing per whitelist
Dec 17 21:06:55.428: INFO: namespace e2e-tests-containers-vtlms deletion completed in 6.146674747s

• [SLOW TEST:8.343 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:06:55.428: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 17 21:06:55.538: INFO: Waiting up to 5m0s for pod "pod-af1802df-023f-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-fz92s" to be "success or failure"
Dec 17 21:06:55.549: INFO: Pod "pod-af1802df-023f-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.6676ms
Dec 17 21:06:57.553: INFO: Pod "pod-af1802df-023f-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015617532s
Dec 17 21:06:59.558: INFO: Pod "pod-af1802df-023f-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019849515s
STEP: Saw pod success
Dec 17 21:06:59.558: INFO: Pod "pod-af1802df-023f-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:06:59.562: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-af1802df-023f-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 21:06:59.587: INFO: Waiting for pod pod-af1802df-023f-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:06:59.591: INFO: Pod pod-af1802df-023f-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:06:59.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fz92s" for this suite.
Dec 17 21:07:05.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:07:05.648: INFO: namespace: e2e-tests-emptydir-fz92s, resource: bindings, ignored listing per whitelist
Dec 17 21:07:05.746: INFO: namespace e2e-tests-emptydir-fz92s deletion completed in 6.15038929s

• [SLOW TEST:10.318 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:07:05.746: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b53f5ef6-023f-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 21:07:05.872: INFO: Waiting up to 5m0s for pod "pod-configmaps-b5405a31-023f-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-jqtkl" to be "success or failure"
Dec 17 21:07:05.882: INFO: Pod "pod-configmaps-b5405a31-023f-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.171157ms
Dec 17 21:07:07.885: INFO: Pod "pod-configmaps-b5405a31-023f-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012971797s
STEP: Saw pod success
Dec 17 21:07:07.886: INFO: Pod "pod-configmaps-b5405a31-023f-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:07:07.889: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-b5405a31-023f-11e9-9892-0a580a3c54b9 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 21:07:07.915: INFO: Waiting for pod pod-configmaps-b5405a31-023f-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:07:07.920: INFO: Pod pod-configmaps-b5405a31-023f-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:07:07.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jqtkl" for this suite.
Dec 17 21:07:17.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:07:18.014: INFO: namespace: e2e-tests-configmap-jqtkl, resource: bindings, ignored listing per whitelist
Dec 17 21:07:18.079: INFO: namespace e2e-tests-configmap-jqtkl deletion completed in 10.155630639s

• [SLOW TEST:12.333 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:07:18.079: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec 17 21:07:18.209: INFO: Waiting up to 5m0s for pod "var-expansion-bc9ad0a4-023f-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-var-expansion-n5j2n" to be "success or failure"
Dec 17 21:07:18.221: INFO: Pod "var-expansion-bc9ad0a4-023f-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 11.579879ms
Dec 17 21:07:20.226: INFO: Pod "var-expansion-bc9ad0a4-023f-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016622395s
Dec 17 21:07:22.229: INFO: Pod "var-expansion-bc9ad0a4-023f-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020144155s
STEP: Saw pod success
Dec 17 21:07:22.229: INFO: Pod "var-expansion-bc9ad0a4-023f-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:07:22.232: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod var-expansion-bc9ad0a4-023f-11e9-9892-0a580a3c54b9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 21:07:22.257: INFO: Waiting for pod var-expansion-bc9ad0a4-023f-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:07:22.260: INFO: Pod var-expansion-bc9ad0a4-023f-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:07:22.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-n5j2n" for this suite.
Dec 17 21:07:28.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:07:28.418: INFO: namespace: e2e-tests-var-expansion-n5j2n, resource: bindings, ignored listing per whitelist
Dec 17 21:07:28.462: INFO: namespace e2e-tests-var-expansion-n5j2n deletion completed in 6.197457744s

• [SLOW TEST:10.383 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:07:28.462: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 17 21:07:28.597: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-9gmtl,SelfLink:/api/v1/namespaces/e2e-tests-watch-9gmtl/configmaps/e2e-watch-test-resource-version,UID:c2c6ab5f-023f-11e9-b8bf-42010a800002,ResourceVersion:16926,Generation:0,CreationTimestamp:2018-12-17 21:07:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 21:07:28.597: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-9gmtl,SelfLink:/api/v1/namespaces/e2e-tests-watch-9gmtl/configmaps/e2e-watch-test-resource-version,UID:c2c6ab5f-023f-11e9-b8bf-42010a800002,ResourceVersion:16927,Generation:0,CreationTimestamp:2018-12-17 21:07:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:07:28.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9gmtl" for this suite.
Dec 17 21:07:34.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:07:34.707: INFO: namespace: e2e-tests-watch-9gmtl, resource: bindings, ignored listing per whitelist
Dec 17 21:07:34.751: INFO: namespace e2e-tests-watch-9gmtl deletion completed in 6.149460142s

• [SLOW TEST:6.289 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:07:34.751: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 17 21:07:34.914: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xkfwx'
Dec 17 21:07:35.010: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 21:07:35.010: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec 17 21:07:35.015: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-xkfwx'
Dec 17 21:07:35.113: INFO: stderr: ""
Dec 17 21:07:35.113: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:07:35.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xkfwx" for this suite.
Dec 17 21:07:41.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:07:41.232: INFO: namespace: e2e-tests-kubectl-xkfwx, resource: bindings, ignored listing per whitelist
Dec 17 21:07:41.289: INFO: namespace e2e-tests-kubectl-xkfwx deletion completed in 6.157664779s

• [SLOW TEST:6.538 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:07:41.289: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec 17 21:07:41.406: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-slw8p" to be "success or failure"
Dec 17 21:07:41.417: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.15843ms
Dec 17 21:07:43.421: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01536527s
Dec 17 21:07:45.425: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019186453s
STEP: Saw pod success
Dec 17 21:07:45.425: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 17 21:07:45.429: INFO: Trying to get logs from node bootstrap-e2e-minion-group-tnzf pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 17 21:07:45.455: INFO: Waiting for pod pod-host-path-test to disappear
Dec 17 21:07:45.460: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:07:45.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-slw8p" for this suite.
Dec 17 21:07:51.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:07:51.582: INFO: namespace: e2e-tests-hostpath-slw8p, resource: bindings, ignored listing per whitelist
Dec 17 21:07:51.601: INFO: namespace e2e-tests-hostpath-slw8p deletion completed in 6.136512625s

• [SLOW TEST:10.312 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:07:51.602: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 21:07:51.733: INFO: Create a RollingUpdate DaemonSet
Dec 17 21:07:51.741: INFO: Check that daemon pods launch on every node of the cluster
Dec 17 21:07:51.753: INFO: Number of nodes with available pods: 0
Dec 17 21:07:51.753: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 21:07:52.762: INFO: Number of nodes with available pods: 1
Dec 17 21:07:52.762: INFO: Node bootstrap-e2e-master is running more than one daemon pod
Dec 17 21:07:53.762: INFO: Number of nodes with available pods: 3
Dec 17 21:07:53.762: INFO: Node bootstrap-e2e-minion-group-6xhw is running more than one daemon pod
Dec 17 21:07:54.761: INFO: Number of nodes with available pods: 4
Dec 17 21:07:54.761: INFO: Number of running nodes: 4, number of available pods: 4
Dec 17 21:07:54.761: INFO: Update the DaemonSet to trigger a rollout
Dec 17 21:07:54.772: INFO: Updating DaemonSet daemon-set
Dec 17 21:08:37.799: INFO: Roll back the DaemonSet before rollout is complete
Dec 17 21:08:37.820: INFO: Updating DaemonSet daemon-set
Dec 17 21:08:37.820: INFO: Make sure DaemonSet rollback is complete
Dec 17 21:08:37.828: INFO: Wrong image for pod: daemon-set-pdxvk. Expected: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1, got: foo:non-existent.
Dec 17 21:08:37.828: INFO: Pod daemon-set-pdxvk is not available
Dec 17 21:08:38.843: INFO: Wrong image for pod: daemon-set-pdxvk. Expected: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1, got: foo:non-existent.
Dec 17 21:08:38.843: INFO: Pod daemon-set-pdxvk is not available
Dec 17 21:08:39.842: INFO: Wrong image for pod: daemon-set-pdxvk. Expected: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1, got: foo:non-existent.
Dec 17 21:08:39.842: INFO: Pod daemon-set-pdxvk is not available
Dec 17 21:08:40.843: INFO: Pod daemon-set-2jgfp is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-stvm7, will wait for the garbage collector to delete the pods
Dec 17 21:08:40.934: INFO: Deleting DaemonSet.extensions daemon-set took: 23.310518ms
Dec 17 21:08:41.034: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.373327ms
Dec 17 21:09:19.239: INFO: Number of nodes with available pods: 0
Dec 17 21:09:19.239: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 21:09:19.242: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-stvm7/daemonsets","resourceVersion":"17268"},"items":null}

Dec 17 21:09:19.245: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-stvm7/pods","resourceVersion":"17268"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:09:19.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-stvm7" for this suite.
Dec 17 21:09:25.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:09:25.320: INFO: namespace: e2e-tests-daemonsets-stvm7, resource: bindings, ignored listing per whitelist
Dec 17 21:09:25.561: INFO: namespace e2e-tests-daemonsets-stvm7 deletion completed in 6.298115454s

• [SLOW TEST:93.959 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:09:25.561: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-pwjj4/configmap-test-08963f51-0240-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 21:09:25.690: INFO: Waiting up to 5m0s for pod "pod-configmaps-08974f5a-0240-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-configmap-pwjj4" to be "success or failure"
Dec 17 21:09:25.700: INFO: Pod "pod-configmaps-08974f5a-0240-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.959237ms
Dec 17 21:09:27.704: INFO: Pod "pod-configmaps-08974f5a-0240-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013628019s
STEP: Saw pod success
Dec 17 21:09:27.704: INFO: Pod "pod-configmaps-08974f5a-0240-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:09:27.707: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-configmaps-08974f5a-0240-11e9-9892-0a580a3c54b9 container env-test: <nil>
STEP: delete the pod
Dec 17 21:09:27.737: INFO: Waiting for pod pod-configmaps-08974f5a-0240-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:09:27.741: INFO: Pod pod-configmaps-08974f5a-0240-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:09:27.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pwjj4" for this suite.
Dec 17 21:09:33.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:09:33.810: INFO: namespace: e2e-tests-configmap-pwjj4, resource: bindings, ignored listing per whitelist
Dec 17 21:09:33.885: INFO: namespace e2e-tests-configmap-pwjj4 deletion completed in 6.139052991s

• [SLOW TEST:8.324 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:09:33.886: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 17 21:09:34.044: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:34.457: INFO: stderr: ""
Dec 17 21:09:34.457: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 21:09:34.457: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:34.564: INFO: stderr: ""
Dec 17 21:09:34.564: INFO: stdout: "update-demo-nautilus-gjmsx update-demo-nautilus-t8285 "
Dec 17 21:09:34.564: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-gjmsx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:34.696: INFO: stderr: ""
Dec 17 21:09:34.696: INFO: stdout: ""
Dec 17 21:09:34.696: INFO: update-demo-nautilus-gjmsx is created but not running
Dec 17 21:09:39.696: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:39.798: INFO: stderr: ""
Dec 17 21:09:39.798: INFO: stdout: "update-demo-nautilus-gjmsx update-demo-nautilus-t8285 "
Dec 17 21:09:39.798: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-gjmsx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:39.899: INFO: stderr: ""
Dec 17 21:09:39.899: INFO: stdout: "true"
Dec 17 21:09:39.899: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-gjmsx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:40.001: INFO: stderr: ""
Dec 17 21:09:40.001: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 21:09:40.001: INFO: validating pod update-demo-nautilus-gjmsx
Dec 17 21:09:40.008: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 21:09:40.009: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 21:09:40.009: INFO: update-demo-nautilus-gjmsx is verified up and running
Dec 17 21:09:40.009: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-t8285 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:40.104: INFO: stderr: ""
Dec 17 21:09:40.104: INFO: stdout: "true"
Dec 17 21:09:40.104: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-t8285 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:40.198: INFO: stderr: ""
Dec 17 21:09:40.198: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 21:09:40.198: INFO: validating pod update-demo-nautilus-t8285
Dec 17 21:09:40.205: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 21:09:40.205: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 21:09:40.205: INFO: update-demo-nautilus-t8285 is verified up and running
STEP: scaling down the replication controller
Dec 17 21:09:40.207: INFO: scanned /workspace for discovery docs: <nil>
Dec 17 21:09:40.207: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:41.355: INFO: stderr: ""
Dec 17 21:09:41.355: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 21:09:41.355: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:41.457: INFO: stderr: ""
Dec 17 21:09:41.457: INFO: stdout: "update-demo-nautilus-gjmsx update-demo-nautilus-t8285 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 17 21:09:46.457: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:46.550: INFO: stderr: ""
Dec 17 21:09:46.550: INFO: stdout: "update-demo-nautilus-gjmsx update-demo-nautilus-t8285 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 17 21:09:51.550: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:51.641: INFO: stderr: ""
Dec 17 21:09:51.641: INFO: stdout: "update-demo-nautilus-t8285 "
Dec 17 21:09:51.641: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-t8285 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:51.731: INFO: stderr: ""
Dec 17 21:09:51.731: INFO: stdout: "true"
Dec 17 21:09:51.731: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-t8285 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:51.822: INFO: stderr: ""
Dec 17 21:09:51.822: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 21:09:51.822: INFO: validating pod update-demo-nautilus-t8285
Dec 17 21:09:51.831: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 21:09:51.831: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 21:09:51.831: INFO: update-demo-nautilus-t8285 is verified up and running
STEP: scaling up the replication controller
Dec 17 21:09:51.833: INFO: scanned /workspace for discovery docs: <nil>
Dec 17 21:09:51.833: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:52.962: INFO: stderr: ""
Dec 17 21:09:52.962: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 21:09:52.962: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:53.059: INFO: stderr: ""
Dec 17 21:09:53.059: INFO: stdout: "update-demo-nautilus-fhb5x update-demo-nautilus-t8285 "
Dec 17 21:09:53.059: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-fhb5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:53.149: INFO: stderr: ""
Dec 17 21:09:53.149: INFO: stdout: ""
Dec 17 21:09:53.149: INFO: update-demo-nautilus-fhb5x is created but not running
Dec 17 21:09:58.149: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:58.253: INFO: stderr: ""
Dec 17 21:09:58.253: INFO: stdout: "update-demo-nautilus-fhb5x update-demo-nautilus-t8285 "
Dec 17 21:09:58.253: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-fhb5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:58.344: INFO: stderr: ""
Dec 17 21:09:58.344: INFO: stdout: "true"
Dec 17 21:09:58.344: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-fhb5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:58.432: INFO: stderr: ""
Dec 17 21:09:58.432: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 21:09:58.432: INFO: validating pod update-demo-nautilus-fhb5x
Dec 17 21:09:58.439: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 21:09:58.439: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 21:09:58.439: INFO: update-demo-nautilus-fhb5x is verified up and running
Dec 17 21:09:58.439: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-t8285 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:58.526: INFO: stderr: ""
Dec 17 21:09:58.527: INFO: stdout: "true"
Dec 17 21:09:58.527: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods update-demo-nautilus-t8285 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:58.613: INFO: stderr: ""
Dec 17 21:09:58.613: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 21:09:58.613: INFO: validating pod update-demo-nautilus-t8285
Dec 17 21:09:58.619: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 21:09:58.619: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 21:09:58.619: INFO: update-demo-nautilus-t8285 is verified up and running
STEP: using delete to clean up resources
Dec 17 21:09:58.619: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:58.721: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 21:09:58.721: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 17 21:09:58.721: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-gpbfn'
Dec 17 21:09:58.820: INFO: stderr: "No resources found.\n"
Dec 17 21:09:58.820: INFO: stdout: ""
Dec 17 21:09:58.820: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -l name=update-demo --namespace=e2e-tests-kubectl-gpbfn -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 21:09:58.917: INFO: stderr: ""
Dec 17 21:09:58.917: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:09:58.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gpbfn" for this suite.
Dec 17 21:10:20.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:10:21.029: INFO: namespace: e2e-tests-kubectl-gpbfn, resource: bindings, ignored listing per whitelist
Dec 17 21:10:21.098: INFO: namespace e2e-tests-kubectl-gpbfn deletion completed in 22.174670453s

• [SLOW TEST:47.212 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:10:21.098: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-f2qzx
Dec 17 21:10:25.264: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-f2qzx
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 21:10:25.267: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:14:25.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-f2qzx" for this suite.
Dec 17 21:14:31.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:14:32.012: INFO: namespace: e2e-tests-container-probe-f2qzx, resource: bindings, ignored listing per whitelist
Dec 17 21:14:32.074: INFO: namespace e2e-tests-container-probe-f2qzx deletion completed in 6.144467889s

• [SLOW TEST:250.976 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:14:32.074: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-bf4e1c13-0240-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume configMaps
Dec 17 21:14:32.240: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bf4f01ab-0240-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-projected-vr24t" to be "success or failure"
Dec 17 21:14:32.250: INFO: Pod "pod-projected-configmaps-bf4f01ab-0240-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.774525ms
Dec 17 21:14:34.254: INFO: Pod "pod-projected-configmaps-bf4f01ab-0240-11e9-9892-0a580a3c54b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013956826s
Dec 17 21:14:36.259: INFO: Pod "pod-projected-configmaps-bf4f01ab-0240-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018001131s
STEP: Saw pod success
Dec 17 21:14:36.259: INFO: Pod "pod-projected-configmaps-bf4f01ab-0240-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:14:36.262: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-projected-configmaps-bf4f01ab-0240-11e9-9892-0a580a3c54b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 21:14:36.299: INFO: Waiting for pod pod-projected-configmaps-bf4f01ab-0240-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:14:36.306: INFO: Pod pod-projected-configmaps-bf4f01ab-0240-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:14:36.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vr24t" for this suite.
Dec 17 21:14:42.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:14:42.421: INFO: namespace: e2e-tests-projected-vr24t, resource: bindings, ignored listing per whitelist
Dec 17 21:14:42.471: INFO: namespace e2e-tests-projected-vr24t deletion completed in 6.161409676s

• [SLOW TEST:10.397 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:14:42.471: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 21:14:42.579: INFO: Creating ReplicaSet my-hostname-basic-c57a38f3-0240-11e9-9892-0a580a3c54b9
Dec 17 21:14:42.595: INFO: Pod name my-hostname-basic-c57a38f3-0240-11e9-9892-0a580a3c54b9: Found 0 pods out of 1
Dec 17 21:14:47.600: INFO: Pod name my-hostname-basic-c57a38f3-0240-11e9-9892-0a580a3c54b9: Found 1 pods out of 1
Dec 17 21:14:47.600: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c57a38f3-0240-11e9-9892-0a580a3c54b9" is running
Dec 17 21:14:47.603: INFO: Pod "my-hostname-basic-c57a38f3-0240-11e9-9892-0a580a3c54b9-kgp28" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-17 21:14:42 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-17 21:14:44 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-17 21:14:44 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-17 21:14:42 +0000 UTC Reason: Message:}])
Dec 17 21:14:47.603: INFO: Trying to dial the pod
Dec 17 21:14:52.617: INFO: Controller my-hostname-basic-c57a38f3-0240-11e9-9892-0a580a3c54b9: Got expected result from replica 1 [my-hostname-basic-c57a38f3-0240-11e9-9892-0a580a3c54b9-kgp28]: "my-hostname-basic-c57a38f3-0240-11e9-9892-0a580a3c54b9-kgp28", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:14:52.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mczvf" for this suite.
Dec 17 21:14:58.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:14:58.688: INFO: namespace: e2e-tests-replicaset-mczvf, resource: bindings, ignored listing per whitelist
Dec 17 21:14:58.775: INFO: namespace e2e-tests-replicaset-mczvf deletion completed in 6.153599958s

• [SLOW TEST:16.304 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:14:58.775: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:15:02.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qddq6" for this suite.
Dec 17 21:15:08.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:15:09.001: INFO: namespace: e2e-tests-kubelet-test-qddq6, resource: bindings, ignored listing per whitelist
Dec 17 21:15:09.074: INFO: namespace e2e-tests-kubelet-test-qddq6 deletion completed in 6.164438045s

• [SLOW TEST:10.299 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:15:09.074: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 17 21:15:09.228: INFO: >>> kubeConfig: /workspace/.kube/config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:15:10.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-zkcmk" for this suite.
Dec 17 21:15:16.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:15:16.386: INFO: namespace: e2e-tests-custom-resource-definition-zkcmk, resource: bindings, ignored listing per whitelist
Dec 17 21:15:16.487: INFO: namespace e2e-tests-custom-resource-definition-zkcmk deletion completed in 6.195791047s

• [SLOW TEST:7.413 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:15:16.487: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d9cb603b-0240-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 21:15:16.678: INFO: Waiting up to 5m0s for pod "pod-secrets-d9cc13ca-0240-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-9l5cp" to be "success or failure"
Dec 17 21:15:16.687: INFO: Pod "pod-secrets-d9cc13ca-0240-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.087218ms
Dec 17 21:15:18.695: INFO: Pod "pod-secrets-d9cc13ca-0240-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017243731s
STEP: Saw pod success
Dec 17 21:15:18.695: INFO: Pod "pod-secrets-d9cc13ca-0240-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:15:18.698: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-secrets-d9cc13ca-0240-11e9-9892-0a580a3c54b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 21:15:18.723: INFO: Waiting for pod pod-secrets-d9cc13ca-0240-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:15:18.732: INFO: Pod pod-secrets-d9cc13ca-0240-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:15:18.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9l5cp" for this suite.
Dec 17 21:15:24.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:15:24.839: INFO: namespace: e2e-tests-secrets-9l5cp, resource: bindings, ignored listing per whitelist
Dec 17 21:15:24.866: INFO: namespace e2e-tests-secrets-9l5cp deletion completed in 6.130562982s

• [SLOW TEST:8.379 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:15:24.867: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 17 21:15:27.522: INFO: Successfully updated pod "pod-update-debefb4d-0240-11e9-9892-0a580a3c54b9"
STEP: verifying the updated pod is in kubernetes
Dec 17 21:15:27.530: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:15:27.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f2szw" for this suite.
Dec 17 21:15:49.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:15:49.596: INFO: namespace: e2e-tests-pods-f2szw, resource: bindings, ignored listing per whitelist
Dec 17 21:15:49.675: INFO: namespace e2e-tests-pods-f2szw deletion completed in 22.140645546s

• [SLOW TEST:24.808 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:15:49.675: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:15:49.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wr55x" for this suite.
Dec 17 21:16:11.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:16:11.993: INFO: namespace: e2e-tests-pods-wr55x, resource: bindings, ignored listing per whitelist
Dec 17 21:16:12.008: INFO: namespace e2e-tests-pods-wr55x deletion completed in 22.18238832s

• [SLOW TEST:22.333 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:16:12.008: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-fadb34a9-0240-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 21:16:12.149: INFO: Waiting up to 5m0s for pod "pod-secrets-fadc1312-0240-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-2xcxk" to be "success or failure"
Dec 17 21:16:12.156: INFO: Pod "pod-secrets-fadc1312-0240-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.432018ms
Dec 17 21:16:14.161: INFO: Pod "pod-secrets-fadc1312-0240-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011683197s
STEP: Saw pod success
Dec 17 21:16:14.161: INFO: Pod "pod-secrets-fadc1312-0240-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:16:14.164: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-secrets-fadc1312-0240-11e9-9892-0a580a3c54b9 container secret-env-test: <nil>
STEP: delete the pod
Dec 17 21:16:14.194: INFO: Waiting for pod pod-secrets-fadc1312-0240-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:16:14.198: INFO: Pod pod-secrets-fadc1312-0240-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:16:14.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2xcxk" for this suite.
Dec 17 21:16:20.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:16:20.407: INFO: namespace: e2e-tests-secrets-2xcxk, resource: bindings, ignored listing per whitelist
Dec 17 21:16:20.414: INFO: namespace e2e-tests-secrets-2xcxk deletion completed in 6.210905948s

• [SLOW TEST:8.406 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:16:20.414: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-66854
Dec 17 21:16:24.555: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-66854
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 21:16:24.559: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:20:25.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-66854" for this suite.
Dec 17 21:20:31.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:20:31.438: INFO: namespace: e2e-tests-container-probe-66854, resource: bindings, ignored listing per whitelist
Dec 17 21:20:31.449: INFO: namespace e2e-tests-container-probe-66854 deletion completed in 6.153951337s

• [SLOW TEST:251.035 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:20:31.449: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-957bed5e-0241-11e9-9892-0a580a3c54b9
STEP: Creating a pod to test consume secrets
Dec 17 21:20:31.575: INFO: Waiting up to 5m0s for pod "pod-secrets-957cf3f7-0241-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-secrets-x667x" to be "success or failure"
Dec 17 21:20:31.581: INFO: Pod "pod-secrets-957cf3f7-0241-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.904672ms
Dec 17 21:20:33.586: INFO: Pod "pod-secrets-957cf3f7-0241-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010221965s
STEP: Saw pod success
Dec 17 21:20:33.586: INFO: Pod "pod-secrets-957cf3f7-0241-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:20:33.589: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-secrets-957cf3f7-0241-11e9-9892-0a580a3c54b9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 21:20:33.619: INFO: Waiting for pod pod-secrets-957cf3f7-0241-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:20:33.628: INFO: Pod pod-secrets-957cf3f7-0241-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:20:33.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x667x" for this suite.
Dec 17 21:20:39.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:20:39.689: INFO: namespace: e2e-tests-secrets-x667x, resource: bindings, ignored listing per whitelist
Dec 17 21:20:39.769: INFO: namespace e2e-tests-secrets-x667x deletion completed in 6.136170958s

• [SLOW TEST:8.320 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:20:39.769: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2ffns
Dec 17 21:20:41.938: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2ffns
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 21:20:41.949: INFO: Initial restart count of pod liveness-http is 0
Dec 17 21:20:57.996: INFO: Restart count of pod e2e-tests-container-probe-2ffns/liveness-http is now 1 (16.047119479s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:20:58.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2ffns" for this suite.
Dec 17 21:21:04.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:21:04.126: INFO: namespace: e2e-tests-container-probe-2ffns, resource: bindings, ignored listing per whitelist
Dec 17 21:21:04.182: INFO: namespace e2e-tests-container-probe-2ffns deletion completed in 6.162890849s

• [SLOW TEST:24.413 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:21:04.182: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 17 21:21:04.290: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-d68tk'
Dec 17 21:21:06.876: INFO: stderr: ""
Dec 17 21:21:06.876: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 21:21:07.881: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 21:21:07.881: INFO: Found 0 / 1
Dec 17 21:21:08.880: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 21:21:08.880: INFO: Found 1 / 1
Dec 17 21:21:08.880: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 17 21:21:08.884: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 21:21:08.884: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 21:21:08.884: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config patch pod redis-master-kbb46 --namespace=e2e-tests-kubectl-d68tk -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 17 21:21:08.984: INFO: stderr: ""
Dec 17 21:21:08.984: INFO: stdout: "pod/redis-master-kbb46 patched\n"
STEP: checking annotations
Dec 17 21:21:08.988: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 21:21:08.988: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:21:08.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d68tk" for this suite.
Dec 17 21:21:31.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:21:31.115: INFO: namespace: e2e-tests-kubectl-d68tk, resource: bindings, ignored listing per whitelist
Dec 17 21:21:31.206: INFO: namespace e2e-tests-kubectl-d68tk deletion completed in 22.213502986s

• [SLOW TEST:27.024 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:21:31.206: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 17 21:21:37.384: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:37.384: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:37.463: INFO: Exec stderr: ""
Dec 17 21:21:37.463: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:37.463: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:37.563: INFO: Exec stderr: ""
Dec 17 21:21:37.564: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:37.564: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:37.678: INFO: Exec stderr: ""
Dec 17 21:21:37.678: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:37.678: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:37.764: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 17 21:21:37.764: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:37.764: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:37.846: INFO: Exec stderr: ""
Dec 17 21:21:37.846: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:37.846: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:37.965: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 17 21:21:37.965: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:37.965: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:38.047: INFO: Exec stderr: ""
Dec 17 21:21:38.047: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:38.047: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:38.160: INFO: Exec stderr: ""
Dec 17 21:21:38.160: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:38.160: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:38.254: INFO: Exec stderr: ""
Dec 17 21:21:38.254: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-9lx7f PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:21:38.254: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:21:38.333: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:21:38.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-9lx7f" for this suite.
Dec 17 21:22:18.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:22:18.442: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-9lx7f, resource: bindings, ignored listing per whitelist
Dec 17 21:22:18.462: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-9lx7f deletion completed in 40.124563546s

• [SLOW TEST:47.256 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:22:18.463: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Dec 17 21:22:18.557: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config create -f - --namespace=e2e-tests-kubectl-qllkp'
Dec 17 21:22:18.934: INFO: stderr: ""
Dec 17 21:22:18.934: INFO: stdout: "pod/pause created\n"
Dec 17 21:22:18.934: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 17 21:22:18.934: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-qllkp" to be "running and ready"
Dec 17 21:22:18.947: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.651415ms
Dec 17 21:22:20.951: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.016338747s
Dec 17 21:22:20.951: INFO: Pod "pause" satisfied condition "running and ready"
Dec 17 21:22:20.951: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 17 21:22:20.951: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-qllkp'
Dec 17 21:22:21.050: INFO: stderr: ""
Dec 17 21:22:21.050: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 17 21:22:21.050: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pod pause -L testing-label --namespace=e2e-tests-kubectl-qllkp'
Dec 17 21:22:21.140: INFO: stderr: ""
Dec 17 21:22:21.140: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 17 21:22:21.140: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config label pods pause testing-label- --namespace=e2e-tests-kubectl-qllkp'
Dec 17 21:22:21.245: INFO: stderr: ""
Dec 17 21:22:21.245: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 17 21:22:21.245: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pod pause -L testing-label --namespace=e2e-tests-kubectl-qllkp'
Dec 17 21:22:21.333: INFO: stderr: ""
Dec 17 21:22:21.333: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Dec 17 21:22:21.333: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qllkp'
Dec 17 21:22:21.437: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 21:22:21.437: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 17 21:22:21.437: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-qllkp'
Dec 17 21:22:21.533: INFO: stderr: "No resources found.\n"
Dec 17 21:22:21.533: INFO: stdout: ""
Dec 17 21:22:21.533: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pods -l name=pause --namespace=e2e-tests-kubectl-qllkp -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 21:22:21.620: INFO: stderr: ""
Dec 17 21:22:21.620: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:22:21.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qllkp" for this suite.
Dec 17 21:22:27.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:22:27.757: INFO: namespace: e2e-tests-kubectl-qllkp, resource: bindings, ignored listing per whitelist
Dec 17 21:22:27.786: INFO: namespace e2e-tests-kubectl-qllkp deletion completed in 6.1608408s

• [SLOW TEST:9.323 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:22:27.786: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:22:30.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-v2j67" for this suite.
Dec 17 21:22:52.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:22:53.041: INFO: namespace: e2e-tests-replication-controller-v2j67, resource: bindings, ignored listing per whitelist
Dec 17 21:22:53.096: INFO: namespace e2e-tests-replication-controller-v2j67 deletion completed in 22.167093797s

• [SLOW TEST:25.310 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:22:53.096: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec 17 21:22:53.741: INFO: Waiting up to 5m0s for pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-p5tq5" in namespace "e2e-tests-svcaccounts-hxcln" to be "success or failure"
Dec 17 21:22:53.749: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-p5tq5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.222038ms
Dec 17 21:22:55.753: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-p5tq5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012300072s
Dec 17 21:22:57.759: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-p5tq5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018550252s
STEP: Saw pod success
Dec 17 21:22:57.759: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-p5tq5" satisfied condition "success or failure"
Dec 17 21:22:57.762: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-p5tq5 container token-test: <nil>
STEP: delete the pod
Dec 17 21:22:57.792: INFO: Waiting for pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-p5tq5 to disappear
Dec 17 21:22:57.797: INFO: Pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-p5tq5 no longer exists
STEP: Creating a pod to test consume service account root CA
Dec 17 21:22:57.804: INFO: Waiting up to 5m0s for pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-9plp5" in namespace "e2e-tests-svcaccounts-hxcln" to be "success or failure"
Dec 17 21:22:57.812: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-9plp5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.867584ms
Dec 17 21:22:59.815: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-9plp5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011593701s
Dec 17 21:23:01.820: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-9plp5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0158537s
STEP: Saw pod success
Dec 17 21:23:01.820: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-9plp5" satisfied condition "success or failure"
Dec 17 21:23:01.824: INFO: Trying to get logs from node bootstrap-e2e-minion-group-tnzf pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-9plp5 container root-ca-test: <nil>
STEP: delete the pod
Dec 17 21:23:01.857: INFO: Waiting for pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-9plp5 to disappear
Dec 17 21:23:01.861: INFO: Pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-9plp5 no longer exists
STEP: Creating a pod to test consume service account namespace
Dec 17 21:23:01.868: INFO: Waiting up to 5m0s for pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-25s6r" in namespace "e2e-tests-svcaccounts-hxcln" to be "success or failure"
Dec 17 21:23:01.875: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-25s6r": Phase="Pending", Reason="", readiness=false. Elapsed: 6.876217ms
Dec 17 21:23:03.879: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-25s6r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011183918s
Dec 17 21:23:05.883: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-25s6r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014798705s
STEP: Saw pod success
Dec 17 21:23:05.883: INFO: Pod "pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-25s6r" satisfied condition "success or failure"
Dec 17 21:23:05.887: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-25s6r container namespace-test: <nil>
STEP: delete the pod
Dec 17 21:23:05.913: INFO: Waiting for pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-25s6r to disappear
Dec 17 21:23:05.917: INFO: Pod pod-service-account-ea3a30bc-0241-11e9-9892-0a580a3c54b9-25s6r no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:23:05.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-hxcln" for this suite.
Dec 17 21:23:11.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:23:12.005: INFO: namespace: e2e-tests-svcaccounts-hxcln, resource: bindings, ignored listing per whitelist
Dec 17 21:23:12.088: INFO: namespace e2e-tests-svcaccounts-hxcln deletion completed in 6.167851187s

• [SLOW TEST:18.991 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:23:12.088: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:24:12.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-z7kkx" for this suite.
Dec 17 21:24:34.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:24:34.361: INFO: namespace: e2e-tests-container-probe-z7kkx, resource: bindings, ignored listing per whitelist
Dec 17 21:24:34.393: INFO: namespace e2e-tests-container-probe-z7kkx deletion completed in 22.179859962s

• [SLOW TEST:82.305 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:24:34.394: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:24:36.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-p2zwb" for this suite.
Dec 17 21:25:20.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:25:20.592: INFO: namespace: e2e-tests-kubelet-test-p2zwb, resource: bindings, ignored listing per whitelist
Dec 17 21:25:20.786: INFO: namespace e2e-tests-kubelet-test-p2zwb deletion completed in 44.23953382s

• [SLOW TEST:46.392 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:25:20.786: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 17 21:25:51.496: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 4
	[quantile=0.99] = 4
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 103
	[quantile=0.9] = 119
	[quantile=0.99] = 119
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 5
	[quantile=0.99] = 5
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 2993
	[quantile=0.9] = 2993
	[quantile=0.99] = 2993
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 4
	[quantile=0.9] = 5
	[quantile=0.99] = 23
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 13
	[quantile=0.9] = 23
	[quantile=0.99] = 62
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 13
	[quantile=0.9] = 16
	[quantile=0.99] = 57
For namespace_queue_latency_sum:
	[] = 8471
For namespace_queue_latency_count:
	[] = 519
For namespace_retries:
	[] = 525
For namespace_work_duration:
	[quantile=0.5] = 325314
	[quantile=0.9] = 454103
	[quantile=0.99] = 752524
For namespace_work_duration_sum:
	[] = 139744828
For namespace_work_duration_count:
	[] = 519
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:25:51.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hs9nf" for this suite.
Dec 17 21:25:57.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:25:57.630: INFO: namespace: e2e-tests-gc-hs9nf, resource: bindings, ignored listing per whitelist
Dec 17 21:25:57.661: INFO: namespace e2e-tests-gc-hs9nf deletion completed in 6.160534333s

• [SLOW TEST:36.875 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:25:57.662: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 17 21:25:57.934: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-f4cs4'
Dec 17 21:25:58.036: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 21:25:58.036: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Dec 17 21:26:00.054: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-f4cs4'
Dec 17 21:26:00.165: INFO: stderr: ""
Dec 17 21:26:00.166: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:26:00.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f4cs4" for this suite.
Dec 17 21:26:22.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:26:22.283: INFO: namespace: e2e-tests-kubectl-f4cs4, resource: bindings, ignored listing per whitelist
Dec 17 21:26:22.365: INFO: namespace e2e-tests-kubectl-f4cs4 deletion completed in 22.188504358s

• [SLOW TEST:24.704 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:26:22.366: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-chldx
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 21:26:22.545: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 21:26:40.701: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.2.233:8080/dial?request=hostName&protocol=http&host=10.64.1.61&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-chldx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:26:40.701: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:26:40.798: INFO: Waiting for endpoints: map[]
Dec 17 21:26:40.802: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.2.233:8080/dial?request=hostName&protocol=http&host=10.64.3.79&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-chldx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:26:40.802: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:26:40.892: INFO: Waiting for endpoints: map[]
Dec 17 21:26:40.896: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.64.2.233:8080/dial?request=hostName&protocol=http&host=10.64.2.232&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-chldx PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 21:26:40.896: INFO: >>> kubeConfig: /workspace/.kube/config
Dec 17 21:26:40.980: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:26:40.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-chldx" for this suite.
Dec 17 21:27:03.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:27:03.095: INFO: namespace: e2e-tests-pod-network-test-chldx, resource: bindings, ignored listing per whitelist
Dec 17 21:27:03.202: INFO: namespace e2e-tests-pod-network-test-chldx deletion completed in 22.218465172s

• [SLOW TEST:40.837 seconds]
[sig-network] Networking
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:27:03.203: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 17 21:27:03.340: INFO: Waiting up to 5m0s for pod "downward-api-7eff470e-0242-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-downward-api-rzqhv" to be "success or failure"
Dec 17 21:27:03.352: INFO: Pod "downward-api-7eff470e-0242-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.551741ms
Dec 17 21:27:05.358: INFO: Pod "downward-api-7eff470e-0242-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017795744s
STEP: Saw pod success
Dec 17 21:27:05.358: INFO: Pod "downward-api-7eff470e-0242-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:27:05.363: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod downward-api-7eff470e-0242-11e9-9892-0a580a3c54b9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 21:27:05.396: INFO: Waiting for pod downward-api-7eff470e-0242-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:27:05.403: INFO: Pod downward-api-7eff470e-0242-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:27:05.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rzqhv" for this suite.
Dec 17 21:27:11.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:27:11.534: INFO: namespace: e2e-tests-downward-api-rzqhv, resource: bindings, ignored listing per whitelist
Dec 17 21:27:11.580: INFO: namespace e2e-tests-downward-api-rzqhv deletion completed in 6.172021297s

• [SLOW TEST:8.377 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:27:11.580: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 17 21:27:11.736: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pmsnk'
Dec 17 21:27:11.839: INFO: stderr: ""
Dec 17 21:27:11.839: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 17 21:27:16.890: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pmsnk -o json'
Dec 17 21:27:17.094: INFO: stderr: ""
Dec 17 21:27:17.094: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-17T21:27:11Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-pmsnk\",\n        \"resourceVersion\": \"20029\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-pmsnk/pods/e2e-test-nginx-pod\",\n        \"uid\": \"840e0217-0242-11e9-b8bf-42010a800002\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-hhvdc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"bootstrap-e2e-minion-group-wjp3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-hhvdc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-hhvdc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-17T21:27:11Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-17T21:27:13Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-17T21:27:13Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-17T21:27:11Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://afb4f0f2ba58214e1f3c2f5f5afa702e01e9e56f7f9bf8243b7f2124e6f82861\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:84976903b80878eae69c59ccf58be6cc35afa5205888399c7244b014e87184df\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-17T21:27:12Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.128.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.64.2.235\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-17T21:27:11Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 17 21:27:17.094: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config replace -f - --namespace=e2e-tests-kubectl-pmsnk'
Dec 17 21:27:17.506: INFO: stderr: ""
Dec 17 21:27:17.506: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Dec 17 21:27:17.522: INFO: Running '/workspace/kubernetes/platforms/linux/amd64/kubectl --server=https://35.225.177.164 --kubeconfig=/workspace/.kube/config delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pmsnk'
Dec 17 21:27:29.176: INFO: stderr: ""
Dec 17 21:27:29.176: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:27:29.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pmsnk" for this suite.
Dec 17 21:27:35.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:27:35.277: INFO: namespace: e2e-tests-kubectl-pmsnk, resource: bindings, ignored listing per whitelist
Dec 17 21:27:35.360: INFO: namespace e2e-tests-kubectl-pmsnk deletion completed in 6.174539081s

• [SLOW TEST:23.780 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:27:35.360: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 17 21:27:37.525: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-9228dc07-0242-11e9-9892-0a580a3c54b9,GenerateName:,Namespace:e2e-tests-events-jgpgh,SelfLink:/api/v1/namespaces/e2e-tests-events-jgpgh/pods/send-events-9228dc07-0242-11e9-9892-0a580a3c54b9,UID:9227c88a-0242-11e9-b8bf-42010a800002,ResourceVersion:20097,Generation:0,CreationTimestamp:2018-12-17 21:27:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 475922565,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-nzjcn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nzjcn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-nzjcn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:bootstrap-e2e-minion-group-wjp3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ba5fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0025d6000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 21:27:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 21:27:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 21:27:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-17 21:27:35 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.4,PodIP:10.64.2.236,StartTime:2018-12-17 21:27:35 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-17 21:27:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://23118a7ae006510f18ae27f679da680aa17df96e619ba642eb2e40a3dd627b2d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 17 21:27:39.529: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 17 21:27:41.532: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:27:41.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-jgpgh" for this suite.
Dec 17 21:28:21.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:28:21.627: INFO: namespace: e2e-tests-events-jgpgh, resource: bindings, ignored listing per whitelist
Dec 17 21:28:21.705: INFO: namespace e2e-tests-events-jgpgh deletion completed in 40.159388925s

• [SLOW TEST:46.345 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec 17 21:28:21.705: INFO: >>> kubeConfig: /workspace/.kube/config
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 17 21:28:21.819: INFO: Waiting up to 5m0s for pod "pod-adc6abb1-0242-11e9-9892-0a580a3c54b9" in namespace "e2e-tests-emptydir-cmmsr" to be "success or failure"
Dec 17 21:28:21.827: INFO: Pod "pod-adc6abb1-0242-11e9-9892-0a580a3c54b9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.60692ms
Dec 17 21:28:23.831: INFO: Pod "pod-adc6abb1-0242-11e9-9892-0a580a3c54b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011696565s
STEP: Saw pod success
Dec 17 21:28:23.831: INFO: Pod "pod-adc6abb1-0242-11e9-9892-0a580a3c54b9" satisfied condition "success or failure"
Dec 17 21:28:23.835: INFO: Trying to get logs from node bootstrap-e2e-minion-group-wjp3 pod pod-adc6abb1-0242-11e9-9892-0a580a3c54b9 container test-container: <nil>
STEP: delete the pod
Dec 17 21:28:23.862: INFO: Waiting for pod pod-adc6abb1-0242-11e9-9892-0a580a3c54b9 to disappear
Dec 17 21:28:23.866: INFO: Pod pod-adc6abb1-0242-11e9-9892-0a580a3c54b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec 17 21:28:23.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cmmsr" for this suite.
Dec 17 21:28:29.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 21:28:29.967: INFO: namespace: e2e-tests-emptydir-cmmsr, resource: bindings, ignored listing per whitelist
Dec 17 21:28:30.040: INFO: namespace e2e-tests-emptydir-cmmsr deletion completed in 6.170959062s

• [SLOW TEST:8.335 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.1-beta.0.57+eec55b9ba98609/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSDec 17 21:28:30.040: INFO: Running AfterSuite actions on all nodes
Dec 17 21:28:30.040: INFO: Running AfterSuite actions on node 1
Dec 17 21:28:30.040: INFO: Skipping dumping logs from cluster

Ran 201 of 2118 Specs in 5982.521 seconds
SUCCESS! -- 201 Passed | 0 Failed | 0 Pending | 1917 Skipped PASS
