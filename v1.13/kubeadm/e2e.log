I1208 08:34:37.843964      20 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-866404302
I1208 08:34:37.844170      20 e2e.go:224] Starting e2e run "18ce0aa4-fac4-11e8-9888-1eca7d857bda" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544258077 - Will randomize all specs
Will run 201 of 1946 specs

Dec  8 08:34:38.061: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 08:34:38.068: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  8 08:34:39.100: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  8 08:34:39.130: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  8 08:34:39.130: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Dec  8 08:34:39.130: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  8 08:34:39.140: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  8 08:34:39.140: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Dec  8 08:34:39.140: INFO: e2e test version: v1.13.0
Dec  8 08:34:39.141: INFO: kube-apiserver version: v1.13.0
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:34:39.142: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename init-container
Dec  8 08:34:39.232: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 08:34:39.234: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:34:45.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bzjf7" for this suite.
Dec  8 08:34:51.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:34:51.447: INFO: namespace: e2e-tests-init-container-bzjf7, resource: bindings, ignored listing per whitelist
Dec  8 08:34:51.523: INFO: namespace e2e-tests-init-container-bzjf7 deletion completed in 6.099837174s

• [SLOW TEST:12.381 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:34:51.523: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-21695a43-fac4-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 08:34:51.597: INFO: Waiting up to 5m0s for pod "pod-configmaps-2169d9fe-fac4-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-fgtpc" to be "success or failure"
Dec  8 08:34:51.600: INFO: Pod "pod-configmaps-2169d9fe-fac4-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.668846ms
Dec  8 08:34:53.603: INFO: Pod "pod-configmaps-2169d9fe-fac4-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005947601s
Dec  8 08:34:55.607: INFO: Pod "pod-configmaps-2169d9fe-fac4-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009376381s
STEP: Saw pod success
Dec  8 08:34:55.607: INFO: Pod "pod-configmaps-2169d9fe-fac4-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:34:55.610: INFO: Trying to get logs from node conformance pod pod-configmaps-2169d9fe-fac4-11e8-9888-1eca7d857bda container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 08:34:55.628: INFO: Waiting for pod pod-configmaps-2169d9fe-fac4-11e8-9888-1eca7d857bda to disappear
Dec  8 08:34:55.630: INFO: Pod pod-configmaps-2169d9fe-fac4-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:34:55.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fgtpc" for this suite.
Dec  8 08:35:01.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:35:01.657: INFO: namespace: e2e-tests-configmap-fgtpc, resource: bindings, ignored listing per whitelist
Dec  8 08:35:01.725: INFO: namespace e2e-tests-configmap-fgtpc deletion completed in 6.092722858s

• [SLOW TEST:10.203 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:35:01.725: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 08:35:01.793: INFO: (0) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.709642ms)
Dec  8 08:35:01.800: INFO: (1) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 7.137038ms)
Dec  8 08:35:01.804: INFO: (2) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.886758ms)
Dec  8 08:35:01.808: INFO: (3) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.742031ms)
Dec  8 08:35:01.812: INFO: (4) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.063066ms)
Dec  8 08:35:01.816: INFO: (5) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.843175ms)
Dec  8 08:35:01.819: INFO: (6) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.316004ms)
Dec  8 08:35:01.823: INFO: (7) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.54222ms)
Dec  8 08:35:01.826: INFO: (8) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.400519ms)
Dec  8 08:35:01.830: INFO: (9) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.815388ms)
Dec  8 08:35:01.833: INFO: (10) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.267437ms)
Dec  8 08:35:01.837: INFO: (11) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.69715ms)
Dec  8 08:35:01.840: INFO: (12) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.108839ms)
Dec  8 08:35:01.843: INFO: (13) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.351034ms)
Dec  8 08:35:01.847: INFO: (14) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.279257ms)
Dec  8 08:35:01.850: INFO: (15) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.152529ms)
Dec  8 08:35:01.853: INFO: (16) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.0347ms)
Dec  8 08:35:01.857: INFO: (17) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.485736ms)
Dec  8 08:35:01.863: INFO: (18) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.925209ms)
Dec  8 08:35:01.867: INFO: (19) /api/v1/nodes/conformance/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.97628ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:35:01.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-24q2d" for this suite.
Dec  8 08:35:07.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:35:07.909: INFO: namespace: e2e-tests-proxy-24q2d, resource: bindings, ignored listing per whitelist
Dec  8 08:35:07.960: INFO: namespace e2e-tests-proxy-24q2d deletion completed in 6.090991234s

• [SLOW TEST:6.235 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:35:07.961: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  8 08:35:08.528: INFO: Waiting up to 5m0s for pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-5sh8q" in namespace "e2e-tests-svcaccounts-b5rz9" to be "success or failure"
Dec  8 08:35:08.530: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-5sh8q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.307986ms
Dec  8 08:35:10.535: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-5sh8q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0066044s
Dec  8 08:35:12.538: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-5sh8q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010032666s
STEP: Saw pod success
Dec  8 08:35:12.538: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-5sh8q" satisfied condition "success or failure"
Dec  8 08:35:12.541: INFO: Trying to get logs from node conformance pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-5sh8q container token-test: <nil>
STEP: delete the pod
Dec  8 08:35:12.558: INFO: Waiting for pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-5sh8q to disappear
Dec  8 08:35:12.561: INFO: Pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-5sh8q no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  8 08:35:12.564: INFO: Waiting up to 5m0s for pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-szhvn" in namespace "e2e-tests-svcaccounts-b5rz9" to be "success or failure"
Dec  8 08:35:12.567: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-szhvn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.50771ms
Dec  8 08:35:14.570: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-szhvn": Phase="Running", Reason="", readiness=false. Elapsed: 2.006057364s
Dec  8 08:35:16.574: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-szhvn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009774338s
STEP: Saw pod success
Dec  8 08:35:16.574: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-szhvn" satisfied condition "success or failure"
Dec  8 08:35:16.576: INFO: Trying to get logs from node conformance pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-szhvn container root-ca-test: <nil>
STEP: delete the pod
Dec  8 08:35:16.599: INFO: Waiting for pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-szhvn to disappear
Dec  8 08:35:16.601: INFO: Pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-szhvn no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  8 08:35:16.604: INFO: Waiting up to 5m0s for pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-sbz69" in namespace "e2e-tests-svcaccounts-b5rz9" to be "success or failure"
Dec  8 08:35:16.607: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-sbz69": Phase="Pending", Reason="", readiness=false. Elapsed: 3.233384ms
Dec  8 08:35:18.611: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-sbz69": Phase="Running", Reason="", readiness=false. Elapsed: 2.006922364s
Dec  8 08:35:20.614: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-sbz69": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010257804s
STEP: Saw pod success
Dec  8 08:35:20.614: INFO: Pod "pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-sbz69" satisfied condition "success or failure"
Dec  8 08:35:20.617: INFO: Trying to get logs from node conformance pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-sbz69 container namespace-test: <nil>
STEP: delete the pod
Dec  8 08:35:20.635: INFO: Waiting for pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-sbz69 to disappear
Dec  8 08:35:20.638: INFO: Pod pod-service-account-2b8135f3-fac4-11e8-9888-1eca7d857bda-sbz69 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:35:20.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-b5rz9" for this suite.
Dec  8 08:35:26.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:35:26.724: INFO: namespace: e2e-tests-svcaccounts-b5rz9, resource: bindings, ignored listing per whitelist
Dec  8 08:35:26.737: INFO: namespace e2e-tests-svcaccounts-b5rz9 deletion completed in 6.096873556s

• [SLOW TEST:18.777 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:35:26.738: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-36664226-fac4-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 08:35:26.810: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3666b1ef-fac4-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-nmhs8" to be "success or failure"
Dec  8 08:35:26.812: INFO: Pod "pod-projected-secrets-3666b1ef-fac4-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.71919ms
Dec  8 08:35:28.816: INFO: Pod "pod-projected-secrets-3666b1ef-fac4-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006795722s
STEP: Saw pod success
Dec  8 08:35:28.816: INFO: Pod "pod-projected-secrets-3666b1ef-fac4-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:35:28.819: INFO: Trying to get logs from node conformance pod pod-projected-secrets-3666b1ef-fac4-11e8-9888-1eca7d857bda container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 08:35:28.835: INFO: Waiting for pod pod-projected-secrets-3666b1ef-fac4-11e8-9888-1eca7d857bda to disappear
Dec  8 08:35:28.838: INFO: Pod pod-projected-secrets-3666b1ef-fac4-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:35:28.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nmhs8" for this suite.
Dec  8 08:35:34.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:35:34.905: INFO: namespace: e2e-tests-projected-nmhs8, resource: bindings, ignored listing per whitelist
Dec  8 08:35:34.961: INFO: namespace e2e-tests-projected-nmhs8 deletion completed in 6.120222363s

• [SLOW TEST:8.224 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:35:34.962: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  8 08:35:35.029: INFO: Waiting up to 5m0s for pod "pod-3b4c6005-fac4-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-gnhpx" to be "success or failure"
Dec  8 08:35:35.031: INFO: Pod "pod-3b4c6005-fac4-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.604553ms
Dec  8 08:35:37.034: INFO: Pod "pod-3b4c6005-fac4-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005835465s
Dec  8 08:35:39.038: INFO: Pod "pod-3b4c6005-fac4-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009677166s
STEP: Saw pod success
Dec  8 08:35:39.038: INFO: Pod "pod-3b4c6005-fac4-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:35:39.041: INFO: Trying to get logs from node conformance pod pod-3b4c6005-fac4-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 08:35:39.060: INFO: Waiting for pod pod-3b4c6005-fac4-11e8-9888-1eca7d857bda to disappear
Dec  8 08:35:39.063: INFO: Pod pod-3b4c6005-fac4-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:35:39.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gnhpx" for this suite.
Dec  8 08:35:45.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:35:45.107: INFO: namespace: e2e-tests-emptydir-gnhpx, resource: bindings, ignored listing per whitelist
Dec  8 08:35:45.172: INFO: namespace e2e-tests-emptydir-gnhpx deletion completed in 6.104849656s

• [SLOW TEST:10.210 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:35:45.172: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 08:35:45.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7t2xc'
Dec  8 08:35:45.569: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  8 08:35:45.569: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Dec  8 08:35:47.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-7t2xc'
Dec  8 08:35:47.671: INFO: stderr: ""
Dec  8 08:35:47.671: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:35:47.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7t2xc" for this suite.
Dec  8 08:35:53.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:35:53.730: INFO: namespace: e2e-tests-kubectl-7t2xc, resource: bindings, ignored listing per whitelist
Dec  8 08:35:53.774: INFO: namespace e2e-tests-kubectl-7t2xc deletion completed in 6.098531658s

• [SLOW TEST:8.602 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:35:53.775: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 08:35:57.867: INFO: Waiting up to 5m0s for pod "client-envvars-48e9b502-fac4-11e8-9888-1eca7d857bda" in namespace "e2e-tests-pods-mvpg4" to be "success or failure"
Dec  8 08:35:57.870: INFO: Pod "client-envvars-48e9b502-fac4-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.941446ms
Dec  8 08:35:59.873: INFO: Pod "client-envvars-48e9b502-fac4-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006262841s
STEP: Saw pod success
Dec  8 08:35:59.873: INFO: Pod "client-envvars-48e9b502-fac4-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:35:59.876: INFO: Trying to get logs from node conformance pod client-envvars-48e9b502-fac4-11e8-9888-1eca7d857bda container env3cont: <nil>
STEP: delete the pod
Dec  8 08:35:59.892: INFO: Waiting for pod client-envvars-48e9b502-fac4-11e8-9888-1eca7d857bda to disappear
Dec  8 08:35:59.894: INFO: Pod client-envvars-48e9b502-fac4-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:35:59.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mvpg4" for this suite.
Dec  8 08:36:41.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:36:41.943: INFO: namespace: e2e-tests-pods-mvpg4, resource: bindings, ignored listing per whitelist
Dec  8 08:36:41.990: INFO: namespace e2e-tests-pods-mvpg4 deletion completed in 42.093105834s

• [SLOW TEST:48.216 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:36:41.990: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-59pvk
I1208 08:36:42.058572      20 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-59pvk, replica count: 1
I1208 08:36:43.109237      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  8 08:36:43.224: INFO: Created: latency-svc-6562f
Dec  8 08:36:43.234: INFO: Got endpoints: latency-svc-6562f [24.842822ms]
Dec  8 08:36:43.251: INFO: Created: latency-svc-p9gv6
Dec  8 08:36:43.252: INFO: Got endpoints: latency-svc-p9gv6 [17.615522ms]
Dec  8 08:36:43.271: INFO: Created: latency-svc-rkq7b
Dec  8 08:36:43.292: INFO: Got endpoints: latency-svc-rkq7b [57.518994ms]
Dec  8 08:36:43.316: INFO: Created: latency-svc-w6bh6
Dec  8 08:36:43.322: INFO: Got endpoints: latency-svc-w6bh6 [88.371604ms]
Dec  8 08:36:43.326: INFO: Created: latency-svc-xt2w4
Dec  8 08:36:43.331: INFO: Got endpoints: latency-svc-xt2w4 [96.877933ms]
Dec  8 08:36:43.337: INFO: Created: latency-svc-h2hs5
Dec  8 08:36:43.341: INFO: Got endpoints: latency-svc-h2hs5 [106.90666ms]
Dec  8 08:36:43.347: INFO: Created: latency-svc-8whxx
Dec  8 08:36:43.350: INFO: Got endpoints: latency-svc-8whxx [115.699619ms]
Dec  8 08:36:43.357: INFO: Created: latency-svc-t7rzw
Dec  8 08:36:43.360: INFO: Got endpoints: latency-svc-t7rzw [126.159189ms]
Dec  8 08:36:43.371: INFO: Created: latency-svc-x4mhk
Dec  8 08:36:43.375: INFO: Got endpoints: latency-svc-x4mhk [141.088572ms]
Dec  8 08:36:43.380: INFO: Created: latency-svc-hvscn
Dec  8 08:36:43.384: INFO: Got endpoints: latency-svc-hvscn [149.179417ms]
Dec  8 08:36:43.393: INFO: Created: latency-svc-d6kxs
Dec  8 08:36:43.396: INFO: Got endpoints: latency-svc-d6kxs [162.010467ms]
Dec  8 08:36:43.414: INFO: Created: latency-svc-s76qf
Dec  8 08:36:43.419: INFO: Got endpoints: latency-svc-s76qf [185.145324ms]
Dec  8 08:36:43.424: INFO: Created: latency-svc-tswwc
Dec  8 08:36:43.427: INFO: Got endpoints: latency-svc-tswwc [192.460412ms]
Dec  8 08:36:43.435: INFO: Created: latency-svc-kzp2m
Dec  8 08:36:43.437: INFO: Got endpoints: latency-svc-kzp2m [202.955274ms]
Dec  8 08:36:43.445: INFO: Created: latency-svc-2dl9l
Dec  8 08:36:43.446: INFO: Got endpoints: latency-svc-2dl9l [211.309283ms]
Dec  8 08:36:43.454: INFO: Created: latency-svc-schjw
Dec  8 08:36:43.458: INFO: Got endpoints: latency-svc-schjw [20.407928ms]
Dec  8 08:36:43.467: INFO: Created: latency-svc-6vml6
Dec  8 08:36:43.471: INFO: Got endpoints: latency-svc-6vml6 [237.011048ms]
Dec  8 08:36:43.481: INFO: Created: latency-svc-qrj2l
Dec  8 08:36:43.485: INFO: Got endpoints: latency-svc-qrj2l [233.391368ms]
Dec  8 08:36:43.494: INFO: Created: latency-svc-tgc86
Dec  8 08:36:43.497: INFO: Got endpoints: latency-svc-tgc86 [205.043918ms]
Dec  8 08:36:43.504: INFO: Created: latency-svc-sl5xq
Dec  8 08:36:43.507: INFO: Got endpoints: latency-svc-sl5xq [184.821949ms]
Dec  8 08:36:43.525: INFO: Created: latency-svc-x22d9
Dec  8 08:36:43.529: INFO: Got endpoints: latency-svc-x22d9 [197.993894ms]
Dec  8 08:36:43.538: INFO: Created: latency-svc-45fmd
Dec  8 08:36:43.541: INFO: Got endpoints: latency-svc-45fmd [200.171951ms]
Dec  8 08:36:43.550: INFO: Created: latency-svc-bmz46
Dec  8 08:36:43.552: INFO: Got endpoints: latency-svc-bmz46 [202.16904ms]
Dec  8 08:36:43.562: INFO: Created: latency-svc-bbp2q
Dec  8 08:36:43.564: INFO: Got endpoints: latency-svc-bbp2q [203.607826ms]
Dec  8 08:36:43.575: INFO: Created: latency-svc-c8729
Dec  8 08:36:43.576: INFO: Got endpoints: latency-svc-c8729 [200.566009ms]
Dec  8 08:36:43.583: INFO: Created: latency-svc-xxn88
Dec  8 08:36:43.589: INFO: Got endpoints: latency-svc-xxn88 [205.028283ms]
Dec  8 08:36:43.597: INFO: Created: latency-svc-2b4lk
Dec  8 08:36:43.600: INFO: Got endpoints: latency-svc-2b4lk [203.309093ms]
Dec  8 08:36:43.607: INFO: Created: latency-svc-rr9lr
Dec  8 08:36:43.611: INFO: Got endpoints: latency-svc-rr9lr [191.002268ms]
Dec  8 08:36:43.616: INFO: Created: latency-svc-h9hbj
Dec  8 08:36:43.619: INFO: Got endpoints: latency-svc-h9hbj [192.306957ms]
Dec  8 08:36:43.640: INFO: Created: latency-svc-qr6hr
Dec  8 08:36:43.644: INFO: Got endpoints: latency-svc-qr6hr [197.935043ms]
Dec  8 08:36:43.650: INFO: Created: latency-svc-fzb96
Dec  8 08:36:43.653: INFO: Got endpoints: latency-svc-fzb96 [195.312902ms]
Dec  8 08:36:43.661: INFO: Created: latency-svc-rmjjc
Dec  8 08:36:43.664: INFO: Got endpoints: latency-svc-rmjjc [192.177586ms]
Dec  8 08:36:43.675: INFO: Created: latency-svc-f2w59
Dec  8 08:36:43.675: INFO: Got endpoints: latency-svc-f2w59 [189.4849ms]
Dec  8 08:36:43.682: INFO: Created: latency-svc-zq9h7
Dec  8 08:36:43.686: INFO: Got endpoints: latency-svc-zq9h7 [188.917446ms]
Dec  8 08:36:43.692: INFO: Created: latency-svc-m9v4p
Dec  8 08:36:43.695: INFO: Got endpoints: latency-svc-m9v4p [187.668892ms]
Dec  8 08:36:43.703: INFO: Created: latency-svc-knzkc
Dec  8 08:36:43.706: INFO: Got endpoints: latency-svc-knzkc [176.413946ms]
Dec  8 08:36:43.714: INFO: Created: latency-svc-vwrbf
Dec  8 08:36:43.718: INFO: Got endpoints: latency-svc-vwrbf [176.446096ms]
Dec  8 08:36:43.723: INFO: Created: latency-svc-65zln
Dec  8 08:36:43.727: INFO: Got endpoints: latency-svc-65zln [175.100173ms]
Dec  8 08:36:43.734: INFO: Created: latency-svc-fln6h
Dec  8 08:36:43.749: INFO: Got endpoints: latency-svc-fln6h [185.200153ms]
Dec  8 08:36:43.752: INFO: Created: latency-svc-rwpzs
Dec  8 08:36:43.755: INFO: Got endpoints: latency-svc-rwpzs [178.745911ms]
Dec  8 08:36:43.767: INFO: Created: latency-svc-d5hxd
Dec  8 08:36:43.779: INFO: Created: latency-svc-kfg26
Dec  8 08:36:43.779: INFO: Got endpoints: latency-svc-d5hxd [190.131581ms]
Dec  8 08:36:43.788: INFO: Created: latency-svc-9586n
Dec  8 08:36:43.798: INFO: Created: latency-svc-wbl9k
Dec  8 08:36:43.808: INFO: Created: latency-svc-mw2nq
Dec  8 08:36:43.817: INFO: Created: latency-svc-fn6n6
Dec  8 08:36:43.827: INFO: Created: latency-svc-k4gbj
Dec  8 08:36:43.828: INFO: Got endpoints: latency-svc-kfg26 [228.233592ms]
Dec  8 08:36:43.837: INFO: Created: latency-svc-5fhdx
Dec  8 08:36:43.847: INFO: Created: latency-svc-mlxnl
Dec  8 08:36:43.862: INFO: Created: latency-svc-r9kcl
Dec  8 08:36:43.873: INFO: Created: latency-svc-v76bv
Dec  8 08:36:43.877: INFO: Got endpoints: latency-svc-9586n [266.338267ms]
Dec  8 08:36:43.886: INFO: Created: latency-svc-pjg9w
Dec  8 08:36:43.894: INFO: Created: latency-svc-grjhv
Dec  8 08:36:43.909: INFO: Created: latency-svc-bbznl
Dec  8 08:36:43.923: INFO: Created: latency-svc-bkgr8
Dec  8 08:36:43.933: INFO: Got endpoints: latency-svc-wbl9k [313.501066ms]
Dec  8 08:36:43.935: INFO: Created: latency-svc-s4xc7
Dec  8 08:36:43.943: INFO: Created: latency-svc-d2spm
Dec  8 08:36:43.954: INFO: Created: latency-svc-s2xnc
Dec  8 08:36:43.974: INFO: Created: latency-svc-2pdpg
Dec  8 08:36:43.977: INFO: Got endpoints: latency-svc-mw2nq [333.285871ms]
Dec  8 08:36:43.990: INFO: Created: latency-svc-fh27l
Dec  8 08:36:44.028: INFO: Got endpoints: latency-svc-fn6n6 [374.336832ms]
Dec  8 08:36:44.041: INFO: Created: latency-svc-pv6l9
Dec  8 08:36:44.081: INFO: Got endpoints: latency-svc-k4gbj [416.704578ms]
Dec  8 08:36:44.117: INFO: Created: latency-svc-252jn
Dec  8 08:36:44.128: INFO: Got endpoints: latency-svc-5fhdx [453.514686ms]
Dec  8 08:36:44.142: INFO: Created: latency-svc-6w2fh
Dec  8 08:36:44.177: INFO: Got endpoints: latency-svc-mlxnl [491.419309ms]
Dec  8 08:36:44.196: INFO: Created: latency-svc-ffdjz
Dec  8 08:36:44.228: INFO: Got endpoints: latency-svc-r9kcl [532.566339ms]
Dec  8 08:36:44.239: INFO: Created: latency-svc-f8lsj
Dec  8 08:36:44.277: INFO: Got endpoints: latency-svc-v76bv [571.644776ms]
Dec  8 08:36:44.296: INFO: Created: latency-svc-t5dr4
Dec  8 08:36:44.328: INFO: Got endpoints: latency-svc-pjg9w [609.759397ms]
Dec  8 08:36:44.343: INFO: Created: latency-svc-hkcwz
Dec  8 08:36:44.377: INFO: Got endpoints: latency-svc-grjhv [649.74853ms]
Dec  8 08:36:44.389: INFO: Created: latency-svc-wqxbw
Dec  8 08:36:44.428: INFO: Got endpoints: latency-svc-bbznl [678.477532ms]
Dec  8 08:36:44.439: INFO: Created: latency-svc-bz7h4
Dec  8 08:36:44.479: INFO: Got endpoints: latency-svc-bkgr8 [723.586903ms]
Dec  8 08:36:44.492: INFO: Created: latency-svc-b2xwj
Dec  8 08:36:44.528: INFO: Got endpoints: latency-svc-s4xc7 [748.381332ms]
Dec  8 08:36:44.538: INFO: Created: latency-svc-7xljk
Dec  8 08:36:44.578: INFO: Got endpoints: latency-svc-d2spm [749.682702ms]
Dec  8 08:36:44.590: INFO: Created: latency-svc-5dznv
Dec  8 08:36:44.627: INFO: Got endpoints: latency-svc-s2xnc [750.301569ms]
Dec  8 08:36:44.639: INFO: Created: latency-svc-km4gt
Dec  8 08:36:44.678: INFO: Got endpoints: latency-svc-2pdpg [745.092534ms]
Dec  8 08:36:44.690: INFO: Created: latency-svc-k24hp
Dec  8 08:36:44.728: INFO: Got endpoints: latency-svc-fh27l [750.678554ms]
Dec  8 08:36:44.741: INFO: Created: latency-svc-mwhr5
Dec  8 08:36:44.778: INFO: Got endpoints: latency-svc-pv6l9 [749.839826ms]
Dec  8 08:36:44.791: INFO: Created: latency-svc-l5lf7
Dec  8 08:36:44.831: INFO: Got endpoints: latency-svc-252jn [750.31409ms]
Dec  8 08:36:44.844: INFO: Created: latency-svc-w8dnh
Dec  8 08:36:44.878: INFO: Got endpoints: latency-svc-6w2fh [749.556008ms]
Dec  8 08:36:44.893: INFO: Created: latency-svc-l7khx
Dec  8 08:36:44.928: INFO: Got endpoints: latency-svc-ffdjz [750.140277ms]
Dec  8 08:36:44.950: INFO: Created: latency-svc-dsszb
Dec  8 08:36:44.978: INFO: Got endpoints: latency-svc-f8lsj [750.257548ms]
Dec  8 08:36:44.993: INFO: Created: latency-svc-j9xp8
Dec  8 08:36:45.028: INFO: Got endpoints: latency-svc-t5dr4 [750.545853ms]
Dec  8 08:36:45.052: INFO: Created: latency-svc-nrq5c
Dec  8 08:36:45.078: INFO: Got endpoints: latency-svc-hkcwz [750.067932ms]
Dec  8 08:36:45.091: INFO: Created: latency-svc-knrl9
Dec  8 08:36:45.128: INFO: Got endpoints: latency-svc-wqxbw [750.677254ms]
Dec  8 08:36:45.141: INFO: Created: latency-svc-zhfcz
Dec  8 08:36:45.178: INFO: Got endpoints: latency-svc-bz7h4 [749.4321ms]
Dec  8 08:36:45.192: INFO: Created: latency-svc-x6n89
Dec  8 08:36:45.228: INFO: Got endpoints: latency-svc-b2xwj [749.420935ms]
Dec  8 08:36:45.245: INFO: Created: latency-svc-ls45b
Dec  8 08:36:45.279: INFO: Got endpoints: latency-svc-7xljk [751.066202ms]
Dec  8 08:36:45.293: INFO: Created: latency-svc-nqs52
Dec  8 08:36:45.328: INFO: Got endpoints: latency-svc-5dznv [749.996274ms]
Dec  8 08:36:45.344: INFO: Created: latency-svc-fj4pd
Dec  8 08:36:45.378: INFO: Got endpoints: latency-svc-km4gt [750.271011ms]
Dec  8 08:36:45.392: INFO: Created: latency-svc-qwvkp
Dec  8 08:36:45.428: INFO: Got endpoints: latency-svc-k24hp [749.82439ms]
Dec  8 08:36:45.441: INFO: Created: latency-svc-4g6hq
Dec  8 08:36:45.478: INFO: Got endpoints: latency-svc-mwhr5 [749.927881ms]
Dec  8 08:36:45.490: INFO: Created: latency-svc-vjlrz
Dec  8 08:36:45.527: INFO: Got endpoints: latency-svc-l5lf7 [749.675441ms]
Dec  8 08:36:45.540: INFO: Created: latency-svc-h84rz
Dec  8 08:36:45.578: INFO: Got endpoints: latency-svc-w8dnh [746.430141ms]
Dec  8 08:36:45.593: INFO: Created: latency-svc-2jfff
Dec  8 08:36:45.628: INFO: Got endpoints: latency-svc-l7khx [749.608594ms]
Dec  8 08:36:45.640: INFO: Created: latency-svc-jzx7d
Dec  8 08:36:45.678: INFO: Got endpoints: latency-svc-dsszb [749.975917ms]
Dec  8 08:36:45.694: INFO: Created: latency-svc-8k9c5
Dec  8 08:36:45.727: INFO: Got endpoints: latency-svc-j9xp8 [748.531516ms]
Dec  8 08:36:45.740: INFO: Created: latency-svc-k6hcq
Dec  8 08:36:45.778: INFO: Got endpoints: latency-svc-nrq5c [749.495415ms]
Dec  8 08:36:45.790: INFO: Created: latency-svc-5j2kn
Dec  8 08:36:45.828: INFO: Got endpoints: latency-svc-knrl9 [750.010524ms]
Dec  8 08:36:45.841: INFO: Created: latency-svc-g8rbx
Dec  8 08:36:45.877: INFO: Got endpoints: latency-svc-zhfcz [749.114561ms]
Dec  8 08:36:45.890: INFO: Created: latency-svc-hhp7w
Dec  8 08:36:45.927: INFO: Got endpoints: latency-svc-x6n89 [749.470319ms]
Dec  8 08:36:45.938: INFO: Created: latency-svc-qfvf8
Dec  8 08:36:45.978: INFO: Got endpoints: latency-svc-ls45b [749.438583ms]
Dec  8 08:36:45.989: INFO: Created: latency-svc-789dp
Dec  8 08:36:46.027: INFO: Got endpoints: latency-svc-nqs52 [748.495695ms]
Dec  8 08:36:46.038: INFO: Created: latency-svc-tc7p9
Dec  8 08:36:46.077: INFO: Got endpoints: latency-svc-fj4pd [749.057975ms]
Dec  8 08:36:46.088: INFO: Created: latency-svc-j5lnr
Dec  8 08:36:46.127: INFO: Got endpoints: latency-svc-qwvkp [749.307863ms]
Dec  8 08:36:46.139: INFO: Created: latency-svc-ml7qv
Dec  8 08:36:46.178: INFO: Got endpoints: latency-svc-4g6hq [749.464302ms]
Dec  8 08:36:46.189: INFO: Created: latency-svc-jcmll
Dec  8 08:36:46.228: INFO: Got endpoints: latency-svc-vjlrz [749.878553ms]
Dec  8 08:36:46.238: INFO: Created: latency-svc-flf4q
Dec  8 08:36:46.277: INFO: Got endpoints: latency-svc-h84rz [749.721033ms]
Dec  8 08:36:46.287: INFO: Created: latency-svc-ksjg8
Dec  8 08:36:46.328: INFO: Got endpoints: latency-svc-2jfff [750.156485ms]
Dec  8 08:36:46.343: INFO: Created: latency-svc-dn4m9
Dec  8 08:36:46.378: INFO: Got endpoints: latency-svc-jzx7d [749.798985ms]
Dec  8 08:36:46.388: INFO: Created: latency-svc-bdfkh
Dec  8 08:36:46.428: INFO: Got endpoints: latency-svc-8k9c5 [749.709945ms]
Dec  8 08:36:46.441: INFO: Created: latency-svc-45bgz
Dec  8 08:36:46.477: INFO: Got endpoints: latency-svc-k6hcq [750.271364ms]
Dec  8 08:36:46.489: INFO: Created: latency-svc-h6xb6
Dec  8 08:36:46.527: INFO: Got endpoints: latency-svc-5j2kn [749.59927ms]
Dec  8 08:36:46.538: INFO: Created: latency-svc-zvbk7
Dec  8 08:36:46.577: INFO: Got endpoints: latency-svc-g8rbx [749.257091ms]
Dec  8 08:36:46.592: INFO: Created: latency-svc-ccgxx
Dec  8 08:36:46.628: INFO: Got endpoints: latency-svc-hhp7w [750.333948ms]
Dec  8 08:36:46.639: INFO: Created: latency-svc-2shvf
Dec  8 08:36:46.677: INFO: Got endpoints: latency-svc-qfvf8 [750.294968ms]
Dec  8 08:36:46.690: INFO: Created: latency-svc-4gv2j
Dec  8 08:36:46.727: INFO: Got endpoints: latency-svc-789dp [749.82562ms]
Dec  8 08:36:46.738: INFO: Created: latency-svc-5sgv8
Dec  8 08:36:46.777: INFO: Got endpoints: latency-svc-tc7p9 [750.163643ms]
Dec  8 08:36:46.788: INFO: Created: latency-svc-tnxr9
Dec  8 08:36:46.827: INFO: Got endpoints: latency-svc-j5lnr [749.755557ms]
Dec  8 08:36:46.839: INFO: Created: latency-svc-n4cbc
Dec  8 08:36:46.878: INFO: Got endpoints: latency-svc-ml7qv [750.066047ms]
Dec  8 08:36:46.888: INFO: Created: latency-svc-58k9d
Dec  8 08:36:46.929: INFO: Got endpoints: latency-svc-jcmll [751.419462ms]
Dec  8 08:36:46.940: INFO: Created: latency-svc-w4b7m
Dec  8 08:36:46.978: INFO: Got endpoints: latency-svc-flf4q [749.646719ms]
Dec  8 08:36:47.007: INFO: Created: latency-svc-bhwb4
Dec  8 08:36:47.028: INFO: Got endpoints: latency-svc-ksjg8 [750.287621ms]
Dec  8 08:36:47.040: INFO: Created: latency-svc-59cp9
Dec  8 08:36:47.077: INFO: Got endpoints: latency-svc-dn4m9 [749.217345ms]
Dec  8 08:36:47.092: INFO: Created: latency-svc-6mjgk
Dec  8 08:36:47.127: INFO: Got endpoints: latency-svc-bdfkh [749.669332ms]
Dec  8 08:36:47.138: INFO: Created: latency-svc-hww9s
Dec  8 08:36:47.178: INFO: Got endpoints: latency-svc-45bgz [750.183873ms]
Dec  8 08:36:47.195: INFO: Created: latency-svc-wxbbg
Dec  8 08:36:47.239: INFO: Got endpoints: latency-svc-h6xb6 [761.530473ms]
Dec  8 08:36:47.250: INFO: Created: latency-svc-dzk9v
Dec  8 08:36:47.277: INFO: Got endpoints: latency-svc-zvbk7 [750.068766ms]
Dec  8 08:36:47.287: INFO: Created: latency-svc-x9g4p
Dec  8 08:36:47.328: INFO: Got endpoints: latency-svc-ccgxx [750.044557ms]
Dec  8 08:36:47.338: INFO: Created: latency-svc-rvdt9
Dec  8 08:36:47.382: INFO: Got endpoints: latency-svc-2shvf [754.003097ms]
Dec  8 08:36:47.396: INFO: Created: latency-svc-cxzqg
Dec  8 08:36:47.428: INFO: Got endpoints: latency-svc-4gv2j [750.48681ms]
Dec  8 08:36:47.441: INFO: Created: latency-svc-f2g2d
Dec  8 08:36:47.477: INFO: Got endpoints: latency-svc-5sgv8 [749.422986ms]
Dec  8 08:36:47.488: INFO: Created: latency-svc-2tf57
Dec  8 08:36:47.528: INFO: Got endpoints: latency-svc-tnxr9 [750.099928ms]
Dec  8 08:36:47.538: INFO: Created: latency-svc-zpqrh
Dec  8 08:36:47.577: INFO: Got endpoints: latency-svc-n4cbc [750.000261ms]
Dec  8 08:36:47.588: INFO: Created: latency-svc-t67gv
Dec  8 08:36:47.627: INFO: Got endpoints: latency-svc-58k9d [749.646123ms]
Dec  8 08:36:47.638: INFO: Created: latency-svc-wt4fx
Dec  8 08:36:47.677: INFO: Got endpoints: latency-svc-w4b7m [748.201467ms]
Dec  8 08:36:47.688: INFO: Created: latency-svc-c66f4
Dec  8 08:36:47.730: INFO: Got endpoints: latency-svc-bhwb4 [752.400718ms]
Dec  8 08:36:47.742: INFO: Created: latency-svc-4crbm
Dec  8 08:36:47.778: INFO: Got endpoints: latency-svc-59cp9 [750.386668ms]
Dec  8 08:36:47.791: INFO: Created: latency-svc-n9j2j
Dec  8 08:36:47.828: INFO: Got endpoints: latency-svc-6mjgk [750.591245ms]
Dec  8 08:36:47.844: INFO: Created: latency-svc-hlbkg
Dec  8 08:36:47.877: INFO: Got endpoints: latency-svc-hww9s [749.775197ms]
Dec  8 08:36:47.887: INFO: Created: latency-svc-7vtcx
Dec  8 08:36:47.927: INFO: Got endpoints: latency-svc-wxbbg [749.591059ms]
Dec  8 08:36:47.946: INFO: Created: latency-svc-jckgm
Dec  8 08:36:47.977: INFO: Got endpoints: latency-svc-dzk9v [738.309548ms]
Dec  8 08:36:47.989: INFO: Created: latency-svc-hnwcv
Dec  8 08:36:48.028: INFO: Got endpoints: latency-svc-x9g4p [750.06516ms]
Dec  8 08:36:48.039: INFO: Created: latency-svc-k8q8w
Dec  8 08:36:48.077: INFO: Got endpoints: latency-svc-rvdt9 [749.726385ms]
Dec  8 08:36:48.088: INFO: Created: latency-svc-f57l5
Dec  8 08:36:48.127: INFO: Got endpoints: latency-svc-cxzqg [745.709343ms]
Dec  8 08:36:48.139: INFO: Created: latency-svc-f8j59
Dec  8 08:36:48.178: INFO: Got endpoints: latency-svc-f2g2d [749.429075ms]
Dec  8 08:36:48.189: INFO: Created: latency-svc-262jv
Dec  8 08:36:48.228: INFO: Got endpoints: latency-svc-2tf57 [751.215184ms]
Dec  8 08:36:48.239: INFO: Created: latency-svc-56pbh
Dec  8 08:36:48.277: INFO: Got endpoints: latency-svc-zpqrh [749.232512ms]
Dec  8 08:36:48.288: INFO: Created: latency-svc-n7mkn
Dec  8 08:36:48.329: INFO: Got endpoints: latency-svc-t67gv [751.129558ms]
Dec  8 08:36:48.339: INFO: Created: latency-svc-5462f
Dec  8 08:36:48.378: INFO: Got endpoints: latency-svc-wt4fx [750.539615ms]
Dec  8 08:36:48.394: INFO: Created: latency-svc-ghstx
Dec  8 08:36:48.428: INFO: Got endpoints: latency-svc-c66f4 [750.70408ms]
Dec  8 08:36:48.440: INFO: Created: latency-svc-g75c6
Dec  8 08:36:48.481: INFO: Got endpoints: latency-svc-4crbm [750.992466ms]
Dec  8 08:36:48.492: INFO: Created: latency-svc-4mmlq
Dec  8 08:36:48.527: INFO: Got endpoints: latency-svc-n9j2j [749.089126ms]
Dec  8 08:36:48.538: INFO: Created: latency-svc-xn6lt
Dec  8 08:36:48.577: INFO: Got endpoints: latency-svc-hlbkg [749.641424ms]
Dec  8 08:36:48.590: INFO: Created: latency-svc-m59wn
Dec  8 08:36:48.628: INFO: Got endpoints: latency-svc-7vtcx [750.457537ms]
Dec  8 08:36:48.639: INFO: Created: latency-svc-sczdg
Dec  8 08:36:48.678: INFO: Got endpoints: latency-svc-jckgm [750.089748ms]
Dec  8 08:36:48.697: INFO: Created: latency-svc-hc7p4
Dec  8 08:36:48.727: INFO: Got endpoints: latency-svc-hnwcv [749.805999ms]
Dec  8 08:36:48.739: INFO: Created: latency-svc-xdl6v
Dec  8 08:36:48.778: INFO: Got endpoints: latency-svc-k8q8w [750.121607ms]
Dec  8 08:36:48.791: INFO: Created: latency-svc-dnwnm
Dec  8 08:36:48.828: INFO: Got endpoints: latency-svc-f57l5 [750.163882ms]
Dec  8 08:36:48.839: INFO: Created: latency-svc-fqsjb
Dec  8 08:36:48.877: INFO: Got endpoints: latency-svc-f8j59 [749.952951ms]
Dec  8 08:36:48.888: INFO: Created: latency-svc-tvm9x
Dec  8 08:36:48.927: INFO: Got endpoints: latency-svc-262jv [749.220511ms]
Dec  8 08:36:48.938: INFO: Created: latency-svc-hps8b
Dec  8 08:36:48.978: INFO: Got endpoints: latency-svc-56pbh [749.537257ms]
Dec  8 08:36:48.990: INFO: Created: latency-svc-pp4np
Dec  8 08:36:49.027: INFO: Got endpoints: latency-svc-n7mkn [750.286294ms]
Dec  8 08:36:49.038: INFO: Created: latency-svc-zjpps
Dec  8 08:36:49.077: INFO: Got endpoints: latency-svc-5462f [748.828399ms]
Dec  8 08:36:49.088: INFO: Created: latency-svc-tnndv
Dec  8 08:36:49.128: INFO: Got endpoints: latency-svc-ghstx [749.951854ms]
Dec  8 08:36:49.139: INFO: Created: latency-svc-tqh8x
Dec  8 08:36:49.178: INFO: Got endpoints: latency-svc-g75c6 [749.411134ms]
Dec  8 08:36:49.189: INFO: Created: latency-svc-5972p
Dec  8 08:36:49.227: INFO: Got endpoints: latency-svc-4mmlq [746.120505ms]
Dec  8 08:36:49.243: INFO: Created: latency-svc-fjqct
Dec  8 08:36:49.278: INFO: Got endpoints: latency-svc-xn6lt [750.647245ms]
Dec  8 08:36:49.289: INFO: Created: latency-svc-h8ns6
Dec  8 08:36:49.327: INFO: Got endpoints: latency-svc-m59wn [749.950389ms]
Dec  8 08:36:49.345: INFO: Created: latency-svc-xqnmp
Dec  8 08:36:49.379: INFO: Got endpoints: latency-svc-sczdg [750.745966ms]
Dec  8 08:36:49.397: INFO: Created: latency-svc-dsjtn
Dec  8 08:36:49.427: INFO: Got endpoints: latency-svc-hc7p4 [749.866233ms]
Dec  8 08:36:49.438: INFO: Created: latency-svc-6ms2f
Dec  8 08:36:49.478: INFO: Got endpoints: latency-svc-xdl6v [750.315578ms]
Dec  8 08:36:49.488: INFO: Created: latency-svc-pqqxt
Dec  8 08:36:49.526: INFO: Got endpoints: latency-svc-dnwnm [748.542263ms]
Dec  8 08:36:49.536: INFO: Created: latency-svc-pxs4s
Dec  8 08:36:49.577: INFO: Got endpoints: latency-svc-fqsjb [749.766255ms]
Dec  8 08:36:49.587: INFO: Created: latency-svc-flhdp
Dec  8 08:36:49.627: INFO: Got endpoints: latency-svc-tvm9x [749.826713ms]
Dec  8 08:36:49.637: INFO: Created: latency-svc-z6lhz
Dec  8 08:36:49.677: INFO: Got endpoints: latency-svc-hps8b [750.005756ms]
Dec  8 08:36:49.687: INFO: Created: latency-svc-pvnjf
Dec  8 08:36:49.727: INFO: Got endpoints: latency-svc-pp4np [749.443695ms]
Dec  8 08:36:49.737: INFO: Created: latency-svc-grfkg
Dec  8 08:36:49.777: INFO: Got endpoints: latency-svc-zjpps [750.125513ms]
Dec  8 08:36:49.788: INFO: Created: latency-svc-jkrf9
Dec  8 08:36:49.827: INFO: Got endpoints: latency-svc-tnndv [749.518426ms]
Dec  8 08:36:49.837: INFO: Created: latency-svc-9rn89
Dec  8 08:36:49.877: INFO: Got endpoints: latency-svc-tqh8x [749.508358ms]
Dec  8 08:36:49.909: INFO: Created: latency-svc-kzvvm
Dec  8 08:36:49.928: INFO: Got endpoints: latency-svc-5972p [750.159444ms]
Dec  8 08:36:49.939: INFO: Created: latency-svc-jww9w
Dec  8 08:36:49.984: INFO: Got endpoints: latency-svc-fjqct [756.15456ms]
Dec  8 08:36:49.995: INFO: Created: latency-svc-bt5wk
Dec  8 08:36:50.027: INFO: Got endpoints: latency-svc-h8ns6 [748.93029ms]
Dec  8 08:36:50.037: INFO: Created: latency-svc-7hzs9
Dec  8 08:36:50.077: INFO: Got endpoints: latency-svc-xqnmp [749.533338ms]
Dec  8 08:36:50.091: INFO: Created: latency-svc-9dwgm
Dec  8 08:36:50.128: INFO: Got endpoints: latency-svc-dsjtn [749.183533ms]
Dec  8 08:36:50.139: INFO: Created: latency-svc-t5jxd
Dec  8 08:36:50.178: INFO: Got endpoints: latency-svc-6ms2f [750.009199ms]
Dec  8 08:36:50.188: INFO: Created: latency-svc-476wc
Dec  8 08:36:50.228: INFO: Got endpoints: latency-svc-pqqxt [749.820444ms]
Dec  8 08:36:50.238: INFO: Created: latency-svc-lb8kb
Dec  8 08:36:50.277: INFO: Got endpoints: latency-svc-pxs4s [750.615355ms]
Dec  8 08:36:50.288: INFO: Created: latency-svc-n4752
Dec  8 08:36:50.328: INFO: Got endpoints: latency-svc-flhdp [750.623403ms]
Dec  8 08:36:50.339: INFO: Created: latency-svc-v7bpb
Dec  8 08:36:50.377: INFO: Got endpoints: latency-svc-z6lhz [750.024075ms]
Dec  8 08:36:50.388: INFO: Created: latency-svc-tgts4
Dec  8 08:36:50.428: INFO: Got endpoints: latency-svc-pvnjf [750.375507ms]
Dec  8 08:36:50.441: INFO: Created: latency-svc-59qtk
Dec  8 08:36:50.477: INFO: Got endpoints: latency-svc-grfkg [749.878764ms]
Dec  8 08:36:50.487: INFO: Created: latency-svc-8t9vw
Dec  8 08:36:50.527: INFO: Got endpoints: latency-svc-jkrf9 [749.866595ms]
Dec  8 08:36:50.537: INFO: Created: latency-svc-fz979
Dec  8 08:36:50.577: INFO: Got endpoints: latency-svc-9rn89 [750.039898ms]
Dec  8 08:36:50.587: INFO: Created: latency-svc-mjwrt
Dec  8 08:36:50.628: INFO: Got endpoints: latency-svc-kzvvm [750.312638ms]
Dec  8 08:36:50.638: INFO: Created: latency-svc-2f4mv
Dec  8 08:36:50.677: INFO: Got endpoints: latency-svc-jww9w [748.885122ms]
Dec  8 08:36:50.688: INFO: Created: latency-svc-9k5cg
Dec  8 08:36:50.734: INFO: Got endpoints: latency-svc-bt5wk [750.151767ms]
Dec  8 08:36:50.744: INFO: Created: latency-svc-rwhww
Dec  8 08:36:50.777: INFO: Got endpoints: latency-svc-7hzs9 [750.146118ms]
Dec  8 08:36:50.787: INFO: Created: latency-svc-fm6dc
Dec  8 08:36:50.827: INFO: Got endpoints: latency-svc-9dwgm [749.931099ms]
Dec  8 08:36:50.840: INFO: Created: latency-svc-ts4ws
Dec  8 08:36:50.877: INFO: Got endpoints: latency-svc-t5jxd [749.07194ms]
Dec  8 08:36:50.887: INFO: Created: latency-svc-djxxk
Dec  8 08:36:50.927: INFO: Got endpoints: latency-svc-476wc [749.752178ms]
Dec  8 08:36:50.938: INFO: Created: latency-svc-gj6qz
Dec  8 08:36:50.977: INFO: Got endpoints: latency-svc-lb8kb [749.555101ms]
Dec  8 08:36:50.987: INFO: Created: latency-svc-8hcbq
Dec  8 08:36:51.028: INFO: Got endpoints: latency-svc-n4752 [750.473063ms]
Dec  8 08:36:51.038: INFO: Created: latency-svc-8xtpn
Dec  8 08:36:51.078: INFO: Got endpoints: latency-svc-v7bpb [749.411036ms]
Dec  8 08:36:51.127: INFO: Got endpoints: latency-svc-tgts4 [749.580494ms]
Dec  8 08:36:51.177: INFO: Got endpoints: latency-svc-59qtk [749.567025ms]
Dec  8 08:36:51.230: INFO: Got endpoints: latency-svc-8t9vw [752.205313ms]
Dec  8 08:36:51.277: INFO: Got endpoints: latency-svc-fz979 [749.78501ms]
Dec  8 08:36:51.327: INFO: Got endpoints: latency-svc-mjwrt [750.102324ms]
Dec  8 08:36:51.378: INFO: Got endpoints: latency-svc-2f4mv [749.661489ms]
Dec  8 08:36:51.427: INFO: Got endpoints: latency-svc-9k5cg [750.492813ms]
Dec  8 08:36:51.477: INFO: Got endpoints: latency-svc-rwhww [743.359968ms]
Dec  8 08:36:51.527: INFO: Got endpoints: latency-svc-fm6dc [749.876516ms]
Dec  8 08:36:51.577: INFO: Got endpoints: latency-svc-ts4ws [750.405573ms]
Dec  8 08:36:51.628: INFO: Got endpoints: latency-svc-djxxk [750.693073ms]
Dec  8 08:36:51.677: INFO: Got endpoints: latency-svc-gj6qz [749.685742ms]
Dec  8 08:36:51.727: INFO: Got endpoints: latency-svc-8hcbq [749.812247ms]
Dec  8 08:36:51.777: INFO: Got endpoints: latency-svc-8xtpn [749.267137ms]
Dec  8 08:36:51.777: INFO: Latencies: [17.615522ms 20.407928ms 57.518994ms 88.371604ms 96.877933ms 106.90666ms 115.699619ms 126.159189ms 141.088572ms 149.179417ms 162.010467ms 175.100173ms 176.413946ms 176.446096ms 178.745911ms 184.821949ms 185.145324ms 185.200153ms 187.668892ms 188.917446ms 189.4849ms 190.131581ms 191.002268ms 192.177586ms 192.306957ms 192.460412ms 195.312902ms 197.935043ms 197.993894ms 200.171951ms 200.566009ms 202.16904ms 202.955274ms 203.309093ms 203.607826ms 205.028283ms 205.043918ms 211.309283ms 228.233592ms 233.391368ms 237.011048ms 266.338267ms 313.501066ms 333.285871ms 374.336832ms 416.704578ms 453.514686ms 491.419309ms 532.566339ms 571.644776ms 609.759397ms 649.74853ms 678.477532ms 723.586903ms 738.309548ms 743.359968ms 745.092534ms 745.709343ms 746.120505ms 746.430141ms 748.201467ms 748.381332ms 748.495695ms 748.531516ms 748.542263ms 748.828399ms 748.885122ms 748.93029ms 749.057975ms 749.07194ms 749.089126ms 749.114561ms 749.183533ms 749.217345ms 749.220511ms 749.232512ms 749.257091ms 749.267137ms 749.307863ms 749.411036ms 749.411134ms 749.420935ms 749.422986ms 749.429075ms 749.4321ms 749.438583ms 749.443695ms 749.464302ms 749.470319ms 749.495415ms 749.508358ms 749.518426ms 749.533338ms 749.537257ms 749.555101ms 749.556008ms 749.567025ms 749.580494ms 749.591059ms 749.59927ms 749.608594ms 749.641424ms 749.646123ms 749.646719ms 749.661489ms 749.669332ms 749.675441ms 749.682702ms 749.685742ms 749.709945ms 749.721033ms 749.726385ms 749.752178ms 749.755557ms 749.766255ms 749.775197ms 749.78501ms 749.798985ms 749.805999ms 749.812247ms 749.820444ms 749.82439ms 749.82562ms 749.826713ms 749.839826ms 749.866233ms 749.866595ms 749.876516ms 749.878553ms 749.878764ms 749.927881ms 749.931099ms 749.950389ms 749.951854ms 749.952951ms 749.975917ms 749.996274ms 750.000261ms 750.005756ms 750.009199ms 750.010524ms 750.024075ms 750.039898ms 750.044557ms 750.06516ms 750.066047ms 750.067932ms 750.068766ms 750.089748ms 750.099928ms 750.102324ms 750.121607ms 750.125513ms 750.140277ms 750.146118ms 750.151767ms 750.156485ms 750.159444ms 750.163643ms 750.163882ms 750.183873ms 750.257548ms 750.271011ms 750.271364ms 750.286294ms 750.287621ms 750.294968ms 750.301569ms 750.312638ms 750.31409ms 750.315578ms 750.333948ms 750.375507ms 750.386668ms 750.405573ms 750.457537ms 750.473063ms 750.48681ms 750.492813ms 750.539615ms 750.545853ms 750.591245ms 750.615355ms 750.623403ms 750.647245ms 750.677254ms 750.678554ms 750.693073ms 750.70408ms 750.745966ms 750.992466ms 751.066202ms 751.129558ms 751.215184ms 751.419462ms 752.205313ms 752.400718ms 754.003097ms 756.15456ms 761.530473ms]
Dec  8 08:36:51.777: INFO: 50 %ile: 749.608594ms
Dec  8 08:36:51.777: INFO: 90 %ile: 750.545853ms
Dec  8 08:36:51.777: INFO: 99 %ile: 756.15456ms
Dec  8 08:36:51.777: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:36:51.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-59pvk" for this suite.
Dec  8 08:37:13.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:37:13.818: INFO: namespace: e2e-tests-svc-latency-59pvk, resource: bindings, ignored listing per whitelist
Dec  8 08:37:13.877: INFO: namespace e2e-tests-svc-latency-59pvk deletion completed in 22.096995441s

• [SLOW TEST:31.887 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:37:13.877: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1208 08:37:23.962998      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 08:37:23.963: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:37:23.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hcwl4" for this suite.
Dec  8 08:37:29.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:37:29.988: INFO: namespace: e2e-tests-gc-hcwl4, resource: bindings, ignored listing per whitelist
Dec  8 08:37:30.063: INFO: namespace e2e-tests-gc-hcwl4 deletion completed in 6.097320417s

• [SLOW TEST:16.186 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:37:30.064: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  8 08:37:30.123: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 08:37:30.129: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 08:37:30.132: INFO: 
Logging pods the kubelet thinks is on node conformance before test
Dec  8 08:37:30.139: INFO: kube-apiserver-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 08:37:30.139: INFO: coredns-86c58d9df4-mz9q8 from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 08:37:30.139: INFO: 	Container coredns ready: true, restart count 0
Dec  8 08:37:30.139: INFO: kube-proxy-djdrm from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 08:37:30.139: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 08:37:30.139: INFO: weave-net-xxrrf from kube-system started at 2018-12-08 08:33:13 +0000 UTC (2 container statuses recorded)
Dec  8 08:37:30.139: INFO: 	Container weave ready: true, restart count 0
Dec  8 08:37:30.139: INFO: 	Container weave-npc ready: true, restart count 0
Dec  8 08:37:30.139: INFO: sonobuoy-systemd-logs-daemon-set-70deb288c1a64a95-8db2d from heptio-sonobuoy started at 2018-12-08 08:34:09 +0000 UTC (2 container statuses recorded)
Dec  8 08:37:30.139: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  8 08:37:30.139: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 08:37:30.139: INFO: etcd-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 08:37:30.139: INFO: kube-controller-manager-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 08:37:30.139: INFO: kube-scheduler-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 08:37:30.139: INFO: coredns-86c58d9df4-bph5g from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 08:37:30.139: INFO: 	Container coredns ready: true, restart count 0
Dec  8 08:37:30.139: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 08:34:04 +0000 UTC (1 container statuses recorded)
Dec  8 08:37:30.139: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  8 08:37:30.139: INFO: sonobuoy-e2e-job-ecc19fc5f3ae4f3f from heptio-sonobuoy started at 2018-12-08 08:34:09 +0000 UTC (2 container statuses recorded)
Dec  8 08:37:30.139: INFO: 	Container e2e ready: true, restart count 0
Dec  8 08:37:30.139: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-811f18b6-fac4-11e8-9888-1eca7d857bda 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-811f18b6-fac4-11e8-9888-1eca7d857bda off the node conformance
STEP: verifying the node doesn't have the label kubernetes.io/e2e-811f18b6-fac4-11e8-9888-1eca7d857bda
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:37:34.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wfvb5" for this suite.
Dec  8 08:37:42.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:37:42.263: INFO: namespace: e2e-tests-sched-pred-wfvb5, resource: bindings, ignored listing per whitelist
Dec  8 08:37:42.293: INFO: namespace e2e-tests-sched-pred-wfvb5 deletion completed in 8.092045084s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.229 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:37:42.293: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:38:03.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-9tpnx" for this suite.
Dec  8 08:38:09.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:38:09.638: INFO: namespace: e2e-tests-container-runtime-9tpnx, resource: bindings, ignored listing per whitelist
Dec  8 08:38:09.651: INFO: namespace e2e-tests-container-runtime-9tpnx deletion completed in 6.097802862s

• [SLOW TEST:27.358 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:38:09.651: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:38:09.723: INFO: Waiting up to 5m0s for pod "downwardapi-volume-978133f0-fac4-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-6vxsp" to be "success or failure"
Dec  8 08:38:09.726: INFO: Pod "downwardapi-volume-978133f0-fac4-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.578142ms
Dec  8 08:38:11.730: INFO: Pod "downwardapi-volume-978133f0-fac4-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006165895s
STEP: Saw pod success
Dec  8 08:38:11.730: INFO: Pod "downwardapi-volume-978133f0-fac4-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:38:11.733: INFO: Trying to get logs from node conformance pod downwardapi-volume-978133f0-fac4-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:38:11.749: INFO: Waiting for pod downwardapi-volume-978133f0-fac4-11e8-9888-1eca7d857bda to disappear
Dec  8 08:38:11.754: INFO: Pod downwardapi-volume-978133f0-fac4-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:38:11.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6vxsp" for this suite.
Dec  8 08:38:17.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:38:17.785: INFO: namespace: e2e-tests-projected-6vxsp, resource: bindings, ignored listing per whitelist
Dec  8 08:38:17.851: INFO: namespace e2e-tests-projected-6vxsp deletion completed in 6.094686538s

• [SLOW TEST:8.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:38:17.852: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Dec  8 08:38:17.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-bblds'
Dec  8 08:38:18.140: INFO: stderr: ""
Dec  8 08:38:18.140: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  8 08:38:19.144: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:38:19.145: INFO: Found 0 / 1
Dec  8 08:38:20.145: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:38:20.145: INFO: Found 0 / 1
Dec  8 08:38:21.144: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:38:21.144: INFO: Found 0 / 1
Dec  8 08:38:22.145: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:38:22.145: INFO: Found 1 / 1
Dec  8 08:38:22.145: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 08:38:22.148: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:38:22.148: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  8 08:38:22.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 logs redis-master-bzscp redis-master --namespace=e2e-tests-kubectl-bblds'
Dec  8 08:38:22.247: INFO: stderr: ""
Dec  8 08:38:22.247: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 08:38:20.583 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 08:38:20.583 # Server started, Redis version 3.2.12\n1:M 08 Dec 08:38:20.583 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 08:38:20.583 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  8 08:38:22.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 log redis-master-bzscp redis-master --namespace=e2e-tests-kubectl-bblds --tail=1'
Dec  8 08:38:22.348: INFO: stderr: ""
Dec  8 08:38:22.348: INFO: stdout: "1:M 08 Dec 08:38:20.583 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  8 08:38:22.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 log redis-master-bzscp redis-master --namespace=e2e-tests-kubectl-bblds --limit-bytes=1'
Dec  8 08:38:22.450: INFO: stderr: ""
Dec  8 08:38:22.450: INFO: stdout: " "
STEP: exposing timestamps
Dec  8 08:38:22.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 log redis-master-bzscp redis-master --namespace=e2e-tests-kubectl-bblds --tail=1 --timestamps'
Dec  8 08:38:22.551: INFO: stderr: ""
Dec  8 08:38:22.551: INFO: stdout: "2018-12-08T08:38:20.584864461Z 1:M 08 Dec 08:38:20.583 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  8 08:38:25.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 log redis-master-bzscp redis-master --namespace=e2e-tests-kubectl-bblds --since=1s'
Dec  8 08:38:25.154: INFO: stderr: ""
Dec  8 08:38:25.154: INFO: stdout: ""
Dec  8 08:38:25.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 log redis-master-bzscp redis-master --namespace=e2e-tests-kubectl-bblds --since=24h'
Dec  8 08:38:25.254: INFO: stderr: ""
Dec  8 08:38:25.254: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 08:38:20.583 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 08:38:20.583 # Server started, Redis version 3.2.12\n1:M 08 Dec 08:38:20.583 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 08:38:20.583 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Dec  8 08:38:25.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bblds'
Dec  8 08:38:25.346: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 08:38:25.346: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  8 08:38:25.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-bblds'
Dec  8 08:38:25.446: INFO: stderr: "No resources found.\n"
Dec  8 08:38:25.446: INFO: stdout: ""
Dec  8 08:38:25.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -l name=nginx --namespace=e2e-tests-kubectl-bblds -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 08:38:25.534: INFO: stderr: ""
Dec  8 08:38:25.534: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:38:25.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bblds" for this suite.
Dec  8 08:38:31.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:38:31.610: INFO: namespace: e2e-tests-kubectl-bblds, resource: bindings, ignored listing per whitelist
Dec  8 08:38:31.631: INFO: namespace e2e-tests-kubectl-bblds deletion completed in 6.093672176s

• [SLOW TEST:13.780 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:38:31.632: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-c52nd in namespace e2e-tests-proxy-6shhx
I1208 08:38:31.708654      20 runners.go:184] Created replication controller with name: proxy-service-c52nd, namespace: e2e-tests-proxy-6shhx, replica count: 1
I1208 08:38:32.759399      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 08:38:33.759744      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1208 08:38:34.760128      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:35.760440      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:36.760817      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:37.761133      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:38.761442      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:39.761722      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:40.762038      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:41.762341      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:42.762639      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:43.763076      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1208 08:38:44.763461      20 runners.go:184] proxy-service-c52nd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  8 08:38:44.766: INFO: setup took 13.072928233s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  8 08:38:44.774: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 7.588303ms)
Dec  8 08:38:44.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 7.784219ms)
Dec  8 08:38:44.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 7.727513ms)
Dec  8 08:38:44.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 7.78017ms)
Dec  8 08:38:44.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 7.923609ms)
Dec  8 08:38:44.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 7.944896ms)
Dec  8 08:38:44.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 7.892927ms)
Dec  8 08:38:44.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 8.297102ms)
Dec  8 08:38:44.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 8.689402ms)
Dec  8 08:38:44.779: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 12.474594ms)
Dec  8 08:38:44.779: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 12.573224ms)
Dec  8 08:38:44.782: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 15.911856ms)
Dec  8 08:38:44.783: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 15.751577ms)
Dec  8 08:38:44.783: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 15.830734ms)
Dec  8 08:38:44.784: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 17.274374ms)
Dec  8 08:38:44.785: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 18.114099ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 4.672791ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 4.76308ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 4.776317ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.94418ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.777447ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 4.718544ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.993938ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.090077ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 5.120619ms)
Dec  8 08:38:44.790: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 5.039476ms)
Dec  8 08:38:44.791: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 5.877948ms)
Dec  8 08:38:44.791: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 5.921917ms)
Dec  8 08:38:44.791: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 5.920921ms)
Dec  8 08:38:44.791: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 6.184924ms)
Dec  8 08:38:44.791: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.100612ms)
Dec  8 08:38:44.791: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 5.975151ms)
Dec  8 08:38:44.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 4.065423ms)
Dec  8 08:38:44.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 3.998393ms)
Dec  8 08:38:44.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 4.273314ms)
Dec  8 08:38:44.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 4.094286ms)
Dec  8 08:38:44.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.510102ms)
Dec  8 08:38:44.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 3.893877ms)
Dec  8 08:38:44.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 3.875324ms)
Dec  8 08:38:44.796: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 3.933154ms)
Dec  8 08:38:44.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.568971ms)
Dec  8 08:38:44.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.344322ms)
Dec  8 08:38:44.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 5.344176ms)
Dec  8 08:38:44.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 5.642692ms)
Dec  8 08:38:44.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 5.128263ms)
Dec  8 08:38:44.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 5.11509ms)
Dec  8 08:38:44.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 5.437073ms)
Dec  8 08:38:44.797: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 5.71666ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 4.126788ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.317419ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 4.364406ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.452783ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.42931ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 4.476538ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 4.435879ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 4.474305ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 4.634686ms)
Dec  8 08:38:44.802: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.601826ms)
Dec  8 08:38:44.803: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 5.242489ms)
Dec  8 08:38:44.803: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 5.315522ms)
Dec  8 08:38:44.803: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 5.275575ms)
Dec  8 08:38:44.803: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 5.26364ms)
Dec  8 08:38:44.803: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 5.264272ms)
Dec  8 08:38:44.803: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 5.866077ms)
Dec  8 08:38:44.808: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.381754ms)
Dec  8 08:38:44.810: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 6.619131ms)
Dec  8 08:38:44.810: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 6.710425ms)
Dec  8 08:38:44.810: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 6.809482ms)
Dec  8 08:38:44.810: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 7.134996ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 7.072455ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 7.245425ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 7.224457ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 7.727241ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 7.685122ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 7.80293ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 7.571082ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 7.70086ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 7.680394ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 7.825885ms)
Dec  8 08:38:44.811: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 7.803991ms)
Dec  8 08:38:44.815: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 3.345884ms)
Dec  8 08:38:44.816: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 4.418941ms)
Dec  8 08:38:44.816: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 4.60464ms)
Dec  8 08:38:44.816: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 4.995703ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 5.041281ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 5.026674ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 5.214832ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.974984ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 5.151475ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.977306ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.973784ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 5.061184ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 5.298327ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 5.194131ms)
Dec  8 08:38:44.817: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 5.340109ms)
Dec  8 08:38:44.818: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.187049ms)
Dec  8 08:38:44.822: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 3.858883ms)
Dec  8 08:38:44.822: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.074761ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 5.910155ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 5.936905ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 5.957812ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 5.950915ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 6.06452ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 5.947735ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.11911ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 6.180324ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 6.382589ms)
Dec  8 08:38:44.824: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 6.473123ms)
Dec  8 08:38:44.825: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 6.896556ms)
Dec  8 08:38:44.825: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 6.901143ms)
Dec  8 08:38:44.825: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.896182ms)
Dec  8 08:38:44.825: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 7.017524ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 4.626009ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.695153ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.573276ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.57414ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 4.580189ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 4.640717ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 4.671124ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.652907ms)
Dec  8 08:38:44.830: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 4.747122ms)
Dec  8 08:38:44.831: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 5.557022ms)
Dec  8 08:38:44.831: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.20212ms)
Dec  8 08:38:44.831: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 6.340595ms)
Dec  8 08:38:44.831: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 6.279918ms)
Dec  8 08:38:44.831: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.456555ms)
Dec  8 08:38:44.831: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 6.517877ms)
Dec  8 08:38:44.832: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 6.918166ms)
Dec  8 08:38:44.836: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 3.709321ms)
Dec  8 08:38:44.836: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.127924ms)
Dec  8 08:38:44.836: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.493427ms)
Dec  8 08:38:44.837: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 4.736038ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 5.375762ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 5.597613ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 5.337576ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 5.529132ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 5.424033ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 5.07891ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 5.502941ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 5.565818ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 5.393621ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 5.431307ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 5.384595ms)
Dec  8 08:38:44.838: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 5.694344ms)
Dec  8 08:38:44.841: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 2.975145ms)
Dec  8 08:38:44.842: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 3.465964ms)
Dec  8 08:38:44.842: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 3.641635ms)
Dec  8 08:38:44.842: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 3.575095ms)
Dec  8 08:38:44.842: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 3.579773ms)
Dec  8 08:38:44.842: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 3.731239ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 7.389834ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 7.679254ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 7.807376ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 7.577711ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 7.558639ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 7.471189ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 7.540666ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 7.812018ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 7.702969ms)
Dec  8 08:38:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 7.885349ms)
Dec  8 08:38:44.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.533871ms)
Dec  8 08:38:44.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.962604ms)
Dec  8 08:38:44.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 5.254671ms)
Dec  8 08:38:44.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 5.386393ms)
Dec  8 08:38:44.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 5.737608ms)
Dec  8 08:38:44.852: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 6.182804ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.415207ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 7.105789ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 6.716191ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 6.668009ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 6.661738ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 7.140825ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 7.41118ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 6.439051ms)
Dec  8 08:38:44.853: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 6.677893ms)
Dec  8 08:38:44.854: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 6.991752ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 5.185223ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 5.372757ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 5.230694ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 5.317489ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.406732ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 5.418394ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 5.597585ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 5.667523ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 5.790245ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.764379ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 5.759416ms)
Dec  8 08:38:44.859: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 5.726947ms)
Dec  8 08:38:44.860: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.310397ms)
Dec  8 08:38:44.860: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.60203ms)
Dec  8 08:38:44.860: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 6.628058ms)
Dec  8 08:38:44.860: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 6.775868ms)
Dec  8 08:38:44.864: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 3.340627ms)
Dec  8 08:38:44.864: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 3.144451ms)
Dec  8 08:38:44.866: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 5.559867ms)
Dec  8 08:38:44.866: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.655632ms)
Dec  8 08:38:44.866: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 5.81819ms)
Dec  8 08:38:44.866: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 5.864686ms)
Dec  8 08:38:44.866: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 5.823384ms)
Dec  8 08:38:44.866: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 5.941521ms)
Dec  8 08:38:44.866: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.735861ms)
Dec  8 08:38:44.866: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 5.82977ms)
Dec  8 08:38:44.867: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 6.718887ms)
Dec  8 08:38:44.867: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.705969ms)
Dec  8 08:38:44.867: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 6.708417ms)
Dec  8 08:38:44.867: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 6.779269ms)
Dec  8 08:38:44.867: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.738049ms)
Dec  8 08:38:44.868: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 6.85285ms)
Dec  8 08:38:44.871: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 3.246285ms)
Dec  8 08:38:44.871: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 3.157763ms)
Dec  8 08:38:44.873: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.801509ms)
Dec  8 08:38:44.873: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.963302ms)
Dec  8 08:38:44.873: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 5.256988ms)
Dec  8 08:38:44.873: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 5.338253ms)
Dec  8 08:38:44.873: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.322831ms)
Dec  8 08:38:44.873: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 5.483433ms)
Dec  8 08:38:44.874: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 6.26875ms)
Dec  8 08:38:44.874: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 6.183911ms)
Dec  8 08:38:44.874: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 6.466022ms)
Dec  8 08:38:44.874: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 6.348808ms)
Dec  8 08:38:44.874: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 6.219904ms)
Dec  8 08:38:44.874: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 6.203845ms)
Dec  8 08:38:44.874: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.579217ms)
Dec  8 08:38:44.875: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.740456ms)
Dec  8 08:38:44.880: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 4.658079ms)
Dec  8 08:38:44.880: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.642782ms)
Dec  8 08:38:44.880: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 4.738428ms)
Dec  8 08:38:44.880: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 4.708867ms)
Dec  8 08:38:44.880: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.753862ms)
Dec  8 08:38:44.880: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.877469ms)
Dec  8 08:38:44.880: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 4.71963ms)
Dec  8 08:38:44.882: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 7.026866ms)
Dec  8 08:38:44.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 7.861184ms)
Dec  8 08:38:44.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 7.852279ms)
Dec  8 08:38:44.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 8.166721ms)
Dec  8 08:38:44.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 8.562252ms)
Dec  8 08:38:44.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 8.68347ms)
Dec  8 08:38:44.884: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 8.579525ms)
Dec  8 08:38:44.884: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 8.590556ms)
Dec  8 08:38:44.884: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 8.857447ms)
Dec  8 08:38:44.886: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 2.534456ms)
Dec  8 08:38:44.886: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 2.807267ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 6.992645ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 7.176808ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 7.102496ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 7.225432ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 7.117146ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 7.19229ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 7.216955ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 7.313114ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 7.207576ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 7.569122ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 7.643394ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 7.644218ms)
Dec  8 08:38:44.891: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 7.758384ms)
Dec  8 08:38:44.892: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 8.032889ms)
Dec  8 08:38:44.895: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 2.891207ms)
Dec  8 08:38:44.895: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 3.319715ms)
Dec  8 08:38:44.896: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 4.206207ms)
Dec  8 08:38:44.896: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.112893ms)
Dec  8 08:38:44.896: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 4.142448ms)
Dec  8 08:38:44.896: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 4.276749ms)
Dec  8 08:38:44.896: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 4.159068ms)
Dec  8 08:38:44.896: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.141084ms)
Dec  8 08:38:44.896: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.230036ms)
Dec  8 08:38:44.896: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 4.425092ms)
Dec  8 08:38:44.899: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.575443ms)
Dec  8 08:38:44.899: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 6.750949ms)
Dec  8 08:38:44.899: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 6.761585ms)
Dec  8 08:38:44.899: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.73613ms)
Dec  8 08:38:44.899: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 6.794987ms)
Dec  8 08:38:44.899: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 6.714745ms)
Dec  8 08:38:44.905: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 6.136836ms)
Dec  8 08:38:44.905: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 6.012338ms)
Dec  8 08:38:44.905: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 5.904718ms)
Dec  8 08:38:44.906: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 6.544345ms)
Dec  8 08:38:44.907: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 8.023129ms)
Dec  8 08:38:44.907: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 8.208058ms)
Dec  8 08:38:44.907: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 8.362725ms)
Dec  8 08:38:44.907: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 8.157118ms)
Dec  8 08:38:44.908: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 8.233348ms)
Dec  8 08:38:44.908: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 8.322787ms)
Dec  8 08:38:44.908: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 8.360232ms)
Dec  8 08:38:44.908: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 8.229091ms)
Dec  8 08:38:44.908: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 8.90823ms)
Dec  8 08:38:44.909: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 10.021512ms)
Dec  8 08:38:44.909: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 9.889821ms)
Dec  8 08:38:44.909: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 10.066688ms)
Dec  8 08:38:44.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 5.718276ms)
Dec  8 08:38:44.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.709773ms)
Dec  8 08:38:44.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 5.629644ms)
Dec  8 08:38:44.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.95349ms)
Dec  8 08:38:44.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 5.84915ms)
Dec  8 08:38:44.915: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 5.809259ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 6.308876ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 6.149565ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 6.430112ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 6.224242ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 6.298701ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 6.628498ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.746652ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 6.808936ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 6.813412ms)
Dec  8 08:38:44.916: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 7.016176ms)
Dec  8 08:38:44.921: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 4.142446ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:162/proxy/: bar (200; 5.976242ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:443/proxy/... (200; 5.970078ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 6.231734ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:1080/proxy/... (200; 5.971982ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx/proxy/rewriteme"... (200; 6.036959ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:460/proxy/: tls baz (200; 6.010429ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/http:proxy-service-c52nd-xnqgx:160/proxy/: foo (200; 6.161502ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/https:proxy-service-c52nd-xnqgx:462/proxy/: tls qux (200; 6.011919ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname1/proxy/: tls baz (200; 6.263159ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname1/proxy/: foo (200; 6.312537ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-6shhx/pods/proxy-service-c52nd-xnqgx:1080/proxy/rewri... (200; 6.439941ms)
Dec  8 08:38:44.923: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname1/proxy/: foo (200; 6.531489ms)
Dec  8 08:38:44.924: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/proxy-service-c52nd:portname2/proxy/: bar (200; 6.876107ms)
Dec  8 08:38:44.924: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/http:proxy-service-c52nd:portname2/proxy/: bar (200; 7.053225ms)
Dec  8 08:38:44.925: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-6shhx/services/https:proxy-service-c52nd:tlsportname2/proxy/: tls qux (200; 8.823342ms)
STEP: deleting ReplicationController proxy-service-c52nd in namespace e2e-tests-proxy-6shhx, will wait for the garbage collector to delete the pods
Dec  8 08:38:44.984: INFO: Deleting ReplicationController proxy-service-c52nd took: 5.441953ms
Dec  8 08:38:45.084: INFO: Terminating ReplicationController proxy-service-c52nd pods took: 100.254326ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:38:51.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-6shhx" for this suite.
Dec  8 08:38:57.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:38:57.305: INFO: namespace: e2e-tests-proxy-6shhx, resource: bindings, ignored listing per whitelist
Dec  8 08:38:57.384: INFO: namespace e2e-tests-proxy-6shhx deletion completed in 6.096019232s

• [SLOW TEST:25.752 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:38:57.384: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:38:57.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b3f45122-fac4-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-48vrf" to be "success or failure"
Dec  8 08:38:57.455: INFO: Pod "downwardapi-volume-b3f45122-fac4-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.691701ms
Dec  8 08:38:59.459: INFO: Pod "downwardapi-volume-b3f45122-fac4-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00643341s
STEP: Saw pod success
Dec  8 08:38:59.459: INFO: Pod "downwardapi-volume-b3f45122-fac4-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:38:59.461: INFO: Trying to get logs from node conformance pod downwardapi-volume-b3f45122-fac4-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:38:59.477: INFO: Waiting for pod downwardapi-volume-b3f45122-fac4-11e8-9888-1eca7d857bda to disappear
Dec  8 08:38:59.482: INFO: Pod downwardapi-volume-b3f45122-fac4-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:38:59.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-48vrf" for this suite.
Dec  8 08:39:05.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:39:05.566: INFO: namespace: e2e-tests-projected-48vrf, resource: bindings, ignored listing per whitelist
Dec  8 08:39:05.588: INFO: namespace e2e-tests-projected-48vrf deletion completed in 6.103133972s

• [SLOW TEST:8.204 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:39:05.588: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:39:09.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-r4l59" for this suite.
Dec  8 08:39:15.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:39:15.733: INFO: namespace: e2e-tests-kubelet-test-r4l59, resource: bindings, ignored listing per whitelist
Dec  8 08:39:15.766: INFO: namespace e2e-tests-kubelet-test-r4l59 deletion completed in 6.092192848s

• [SLOW TEST:10.177 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:39:15.766: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-zjrq9
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-zjrq9
STEP: Deleting pre-stop pod
Dec  8 08:39:26.866: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:39:26.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-zjrq9" for this suite.
Dec  8 08:40:04.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:40:04.912: INFO: namespace: e2e-tests-prestop-zjrq9, resource: bindings, ignored listing per whitelist
Dec  8 08:40:04.972: INFO: namespace e2e-tests-prestop-zjrq9 deletion completed in 38.094090445s

• [SLOW TEST:49.206 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:40:04.972: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 08:40:05.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-v9z2s'
Dec  8 08:40:05.134: INFO: stderr: ""
Dec  8 08:40:05.134: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Dec  8 08:40:05.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-v9z2s'
Dec  8 08:40:11.271: INFO: stderr: ""
Dec  8 08:40:11.271: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:40:11.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v9z2s" for this suite.
Dec  8 08:40:17.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:40:17.331: INFO: namespace: e2e-tests-kubectl-v9z2s, resource: bindings, ignored listing per whitelist
Dec  8 08:40:17.371: INFO: namespace e2e-tests-kubectl-v9z2s deletion completed in 6.096169071s

• [SLOW TEST:12.399 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:40:17.371: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:40:19.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-59zhp" for this suite.
Dec  8 08:41:05.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:41:05.521: INFO: namespace: e2e-tests-kubelet-test-59zhp, resource: bindings, ignored listing per whitelist
Dec  8 08:41:05.558: INFO: namespace e2e-tests-kubelet-test-59zhp deletion completed in 46.097892067s

• [SLOW TEST:48.187 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:41:05.558: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  8 08:41:05.625: INFO: Waiting up to 5m0s for pod "pod-0059f40b-fac5-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-fkxgg" to be "success or failure"
Dec  8 08:41:05.627: INFO: Pod "pod-0059f40b-fac5-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.109471ms
Dec  8 08:41:07.630: INFO: Pod "pod-0059f40b-fac5-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005481208s
STEP: Saw pod success
Dec  8 08:41:07.630: INFO: Pod "pod-0059f40b-fac5-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:41:07.633: INFO: Trying to get logs from node conformance pod pod-0059f40b-fac5-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 08:41:07.651: INFO: Waiting for pod pod-0059f40b-fac5-11e8-9888-1eca7d857bda to disappear
Dec  8 08:41:07.653: INFO: Pod pod-0059f40b-fac5-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:41:07.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fkxgg" for this suite.
Dec  8 08:41:13.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:41:13.746: INFO: namespace: e2e-tests-emptydir-fkxgg, resource: bindings, ignored listing per whitelist
Dec  8 08:41:13.753: INFO: namespace e2e-tests-emptydir-fkxgg deletion completed in 6.097660304s

• [SLOW TEST:8.195 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:41:13.754: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 08:41:16.350: INFO: Successfully updated pod "labelsupdate053c5647-fac5-11e8-9888-1eca7d857bda"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:41:18.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rtwgb" for this suite.
Dec  8 08:41:40.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:41:40.411: INFO: namespace: e2e-tests-projected-rtwgb, resource: bindings, ignored listing per whitelist
Dec  8 08:41:40.464: INFO: namespace e2e-tests-projected-rtwgb deletion completed in 22.090424665s

• [SLOW TEST:26.710 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:41:40.464: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  8 08:41:40.531: INFO: Waiting up to 5m0s for pod "client-containers-15284bd4-fac5-11e8-9888-1eca7d857bda" in namespace "e2e-tests-containers-g754m" to be "success or failure"
Dec  8 08:41:40.534: INFO: Pod "client-containers-15284bd4-fac5-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.406932ms
Dec  8 08:41:42.538: INFO: Pod "client-containers-15284bd4-fac5-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006402138s
Dec  8 08:41:44.542: INFO: Pod "client-containers-15284bd4-fac5-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01021372s
STEP: Saw pod success
Dec  8 08:41:44.542: INFO: Pod "client-containers-15284bd4-fac5-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:41:44.547: INFO: Trying to get logs from node conformance pod client-containers-15284bd4-fac5-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 08:41:44.565: INFO: Waiting for pod client-containers-15284bd4-fac5-11e8-9888-1eca7d857bda to disappear
Dec  8 08:41:44.567: INFO: Pod client-containers-15284bd4-fac5-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:41:44.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-g754m" for this suite.
Dec  8 08:41:50.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:41:50.643: INFO: namespace: e2e-tests-containers-g754m, resource: bindings, ignored listing per whitelist
Dec  8 08:41:50.661: INFO: namespace e2e-tests-containers-g754m deletion completed in 6.091404012s

• [SLOW TEST:10.197 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:41:50.662: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:41:50.729: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b3c6d21-fac5-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-gwwd4" to be "success or failure"
Dec  8 08:41:50.732: INFO: Pod "downwardapi-volume-1b3c6d21-fac5-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.442667ms
Dec  8 08:41:52.736: INFO: Pod "downwardapi-volume-1b3c6d21-fac5-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006037617s
STEP: Saw pod success
Dec  8 08:41:52.736: INFO: Pod "downwardapi-volume-1b3c6d21-fac5-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:41:52.739: INFO: Trying to get logs from node conformance pod downwardapi-volume-1b3c6d21-fac5-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:41:52.754: INFO: Waiting for pod downwardapi-volume-1b3c6d21-fac5-11e8-9888-1eca7d857bda to disappear
Dec  8 08:41:52.758: INFO: Pod downwardapi-volume-1b3c6d21-fac5-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:41:52.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gwwd4" for this suite.
Dec  8 08:41:58.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:41:58.827: INFO: namespace: e2e-tests-downward-api-gwwd4, resource: bindings, ignored listing per whitelist
Dec  8 08:41:58.872: INFO: namespace e2e-tests-downward-api-gwwd4 deletion completed in 6.110339955s

• [SLOW TEST:8.211 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:41:58.873: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:42:00.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qpmms" for this suite.
Dec  8 08:42:42.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:42:42.990: INFO: namespace: e2e-tests-kubelet-test-qpmms, resource: bindings, ignored listing per whitelist
Dec  8 08:42:43.052: INFO: namespace e2e-tests-kubelet-test-qpmms deletion completed in 42.090549333s

• [SLOW TEST:44.179 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:42:43.052: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:42:43.124: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a772d17-fac5-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-wfmqk" to be "success or failure"
Dec  8 08:42:43.127: INFO: Pod "downwardapi-volume-3a772d17-fac5-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.861801ms
Dec  8 08:42:45.131: INFO: Pod "downwardapi-volume-3a772d17-fac5-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006546512s
STEP: Saw pod success
Dec  8 08:42:45.131: INFO: Pod "downwardapi-volume-3a772d17-fac5-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:42:45.133: INFO: Trying to get logs from node conformance pod downwardapi-volume-3a772d17-fac5-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:42:45.152: INFO: Waiting for pod downwardapi-volume-3a772d17-fac5-11e8-9888-1eca7d857bda to disappear
Dec  8 08:42:45.154: INFO: Pod downwardapi-volume-3a772d17-fac5-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:42:45.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wfmqk" for this suite.
Dec  8 08:42:51.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:42:51.219: INFO: namespace: e2e-tests-downward-api-wfmqk, resource: bindings, ignored listing per whitelist
Dec  8 08:42:51.263: INFO: namespace e2e-tests-downward-api-wfmqk deletion completed in 6.105891559s

• [SLOW TEST:8.211 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:42:51.263: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xmw9b
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  8 08:42:51.332: INFO: Found 0 stateful pods, waiting for 3
Dec  8 08:43:01.336: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:43:01.336: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:43:01.336: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:43:01.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-xmw9b ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 08:43:01.531: INFO: stderr: ""
Dec  8 08:43:01.531: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 08:43:01.531: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  8 08:43:11.564: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  8 08:43:21.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-xmw9b ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:43:21.738: INFO: stderr: ""
Dec  8 08:43:21.739: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 08:43:21.739: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 08:43:31.759: INFO: Waiting for StatefulSet e2e-tests-statefulset-xmw9b/ss2 to complete update
Dec  8 08:43:31.759: INFO: Waiting for Pod e2e-tests-statefulset-xmw9b/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 08:43:31.759: INFO: Waiting for Pod e2e-tests-statefulset-xmw9b/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 08:43:41.765: INFO: Waiting for StatefulSet e2e-tests-statefulset-xmw9b/ss2 to complete update
Dec  8 08:43:41.765: INFO: Waiting for Pod e2e-tests-statefulset-xmw9b/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 08:43:41.765: INFO: Waiting for Pod e2e-tests-statefulset-xmw9b/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 08:43:51.766: INFO: Waiting for StatefulSet e2e-tests-statefulset-xmw9b/ss2 to complete update
STEP: Rolling back to a previous revision
Dec  8 08:44:01.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-xmw9b ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 08:44:01.952: INFO: stderr: ""
Dec  8 08:44:01.952: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 08:44:01.952: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 08:44:11.982: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  8 08:44:21.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-xmw9b ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:44:22.161: INFO: stderr: ""
Dec  8 08:44:22.161: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 08:44:22.161: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 08:44:32.182: INFO: Waiting for StatefulSet e2e-tests-statefulset-xmw9b/ss2 to complete update
Dec  8 08:44:32.182: INFO: Waiting for Pod e2e-tests-statefulset-xmw9b/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  8 08:44:32.182: INFO: Waiting for Pod e2e-tests-statefulset-xmw9b/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  8 08:44:42.190: INFO: Waiting for StatefulSet e2e-tests-statefulset-xmw9b/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 08:44:52.190: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xmw9b
Dec  8 08:44:52.194: INFO: Scaling statefulset ss2 to 0
Dec  8 08:45:02.208: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 08:45:02.211: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:45:02.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xmw9b" for this suite.
Dec  8 08:45:08.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:45:08.308: INFO: namespace: e2e-tests-statefulset-xmw9b, resource: bindings, ignored listing per whitelist
Dec  8 08:45:08.315: INFO: namespace e2e-tests-statefulset-xmw9b deletion completed in 6.09091385s

• [SLOW TEST:137.051 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:45:08.315: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gv42q
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 08:45:08.379: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 08:45:26.431: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.7:8080/dial?request=hostName&protocol=http&host=10.32.0.6&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-gv42q PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 08:45:26.431: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 08:45:26.507: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:45:26.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gv42q" for this suite.
Dec  8 08:45:48.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:45:48.540: INFO: namespace: e2e-tests-pod-network-test-gv42q, resource: bindings, ignored listing per whitelist
Dec  8 08:45:48.599: INFO: namespace e2e-tests-pod-network-test-gv42q deletion completed in 22.089645939s

• [SLOW TEST:40.284 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:45:48.599: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vct74
Dec  8 08:45:52.675: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vct74
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 08:45:52.677: INFO: Initial restart count of pod liveness-http is 0
Dec  8 08:46:12.713: INFO: Restart count of pod e2e-tests-container-probe-vct74/liveness-http is now 1 (20.035940698s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:46:12.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vct74" for this suite.
Dec  8 08:46:18.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:46:18.813: INFO: namespace: e2e-tests-container-probe-vct74, resource: bindings, ignored listing per whitelist
Dec  8 08:46:18.826: INFO: namespace e2e-tests-container-probe-vct74 deletion completed in 6.101930534s

• [SLOW TEST:30.226 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:46:18.826: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:46:18.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb13ac32-fac5-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-gwrjg" to be "success or failure"
Dec  8 08:46:18.903: INFO: Pod "downwardapi-volume-bb13ac32-fac5-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05592ms
Dec  8 08:46:20.907: INFO: Pod "downwardapi-volume-bb13ac32-fac5-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007963837s
STEP: Saw pod success
Dec  8 08:46:20.907: INFO: Pod "downwardapi-volume-bb13ac32-fac5-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:46:20.910: INFO: Trying to get logs from node conformance pod downwardapi-volume-bb13ac32-fac5-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:46:20.931: INFO: Waiting for pod downwardapi-volume-bb13ac32-fac5-11e8-9888-1eca7d857bda to disappear
Dec  8 08:46:20.933: INFO: Pod downwardapi-volume-bb13ac32-fac5-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:46:20.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gwrjg" for this suite.
Dec  8 08:46:26.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:46:26.991: INFO: namespace: e2e-tests-downward-api-gwrjg, resource: bindings, ignored listing per whitelist
Dec  8 08:46:27.027: INFO: namespace e2e-tests-downward-api-gwrjg deletion completed in 6.091383589s

• [SLOW TEST:8.201 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:46:27.027: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 08:46:27.088: INFO: Waiting up to 5m0s for pod "downward-api-bff54c87-fac5-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-kh2pr" to be "success or failure"
Dec  8 08:46:27.092: INFO: Pod "downward-api-bff54c87-fac5-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.977354ms
Dec  8 08:46:29.096: INFO: Pod "downward-api-bff54c87-fac5-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007830056s
STEP: Saw pod success
Dec  8 08:46:29.096: INFO: Pod "downward-api-bff54c87-fac5-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:46:29.099: INFO: Trying to get logs from node conformance pod downward-api-bff54c87-fac5-11e8-9888-1eca7d857bda container dapi-container: <nil>
STEP: delete the pod
Dec  8 08:46:29.117: INFO: Waiting for pod downward-api-bff54c87-fac5-11e8-9888-1eca7d857bda to disappear
Dec  8 08:46:29.119: INFO: Pod downward-api-bff54c87-fac5-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:46:29.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kh2pr" for this suite.
Dec  8 08:46:35.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:46:35.174: INFO: namespace: e2e-tests-downward-api-kh2pr, resource: bindings, ignored listing per whitelist
Dec  8 08:46:35.223: INFO: namespace e2e-tests-downward-api-kh2pr deletion completed in 6.100970085s

• [SLOW TEST:8.196 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:46:35.224: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 08:46:35.300: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  8 08:46:35.306: INFO: Number of nodes with available pods: 0
Dec  8 08:46:35.306: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  8 08:46:35.318: INFO: Number of nodes with available pods: 0
Dec  8 08:46:35.318: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:36.322: INFO: Number of nodes with available pods: 1
Dec  8 08:46:36.322: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  8 08:46:36.335: INFO: Number of nodes with available pods: 1
Dec  8 08:46:36.336: INFO: Number of running nodes: 0, number of available pods: 1
Dec  8 08:46:37.339: INFO: Number of nodes with available pods: 0
Dec  8 08:46:37.339: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  8 08:46:37.349: INFO: Number of nodes with available pods: 0
Dec  8 08:46:37.349: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:38.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:38.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:39.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:39.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:40.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:40.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:41.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:41.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:42.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:42.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:43.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:43.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:44.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:44.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:45.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:45.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:46.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:46.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:47.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:47.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:48.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:48.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:49.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:49.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:50.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:50.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:51.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:51.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:52.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:52.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:53.354: INFO: Number of nodes with available pods: 0
Dec  8 08:46:53.354: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:54.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:54.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:55.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:55.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:56.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:56.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:57.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:57.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:58.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:58.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:46:59.353: INFO: Number of nodes with available pods: 0
Dec  8 08:46:59.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:00.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:00.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:01.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:01.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:02.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:02.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:03.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:03.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:04.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:04.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:05.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:05.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:06.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:06.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:07.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:07.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:08.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:08.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:09.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:09.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:10.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:10.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:11.354: INFO: Number of nodes with available pods: 0
Dec  8 08:47:11.354: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:12.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:12.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:13.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:13.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:14.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:14.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:15.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:15.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:16.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:16.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:17.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:17.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:18.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:18.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:19.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:19.354: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:20.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:20.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:21.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:21.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:22.353: INFO: Number of nodes with available pods: 0
Dec  8 08:47:22.353: INFO: Node conformance is running more than one daemon pod
Dec  8 08:47:23.354: INFO: Number of nodes with available pods: 1
Dec  8 08:47:23.354: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-s5htg, will wait for the garbage collector to delete the pods
Dec  8 08:47:23.418: INFO: Deleting DaemonSet.extensions daemon-set took: 5.077062ms
Dec  8 08:47:23.518: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.433686ms
Dec  8 08:48:01.322: INFO: Number of nodes with available pods: 0
Dec  8 08:48:01.322: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 08:48:01.325: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-s5htg/daemonsets","resourceVersion":"4251"},"items":null}

Dec  8 08:48:01.328: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-s5htg/pods","resourceVersion":"4251"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:48:01.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-s5htg" for this suite.
Dec  8 08:48:07.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:48:07.417: INFO: namespace: e2e-tests-daemonsets-s5htg, resource: bindings, ignored listing per whitelist
Dec  8 08:48:07.434: INFO: namespace e2e-tests-daemonsets-s5htg deletion completed in 6.094013766s

• [SLOW TEST:92.211 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:48:07.435: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-fbcf0812-fac5-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 08:48:07.504: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fbcf8970-fac5-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-fg58f" to be "success or failure"
Dec  8 08:48:07.506: INFO: Pod "pod-projected-secrets-fbcf8970-fac5-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.571886ms
Dec  8 08:48:09.511: INFO: Pod "pod-projected-secrets-fbcf8970-fac5-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006955917s
STEP: Saw pod success
Dec  8 08:48:09.511: INFO: Pod "pod-projected-secrets-fbcf8970-fac5-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:48:09.513: INFO: Trying to get logs from node conformance pod pod-projected-secrets-fbcf8970-fac5-11e8-9888-1eca7d857bda container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 08:48:09.531: INFO: Waiting for pod pod-projected-secrets-fbcf8970-fac5-11e8-9888-1eca7d857bda to disappear
Dec  8 08:48:09.533: INFO: Pod pod-projected-secrets-fbcf8970-fac5-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:48:09.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fg58f" for this suite.
Dec  8 08:48:15.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:48:15.607: INFO: namespace: e2e-tests-projected-fg58f, resource: bindings, ignored listing per whitelist
Dec  8 08:48:15.626: INFO: namespace e2e-tests-projected-fg58f deletion completed in 6.090490442s

• [SLOW TEST:8.191 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:48:15.626: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  8 08:48:15.695: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k4pv8,SelfLink:/api/v1/namespaces/e2e-tests-watch-k4pv8/configmaps/e2e-watch-test-watch-closed,UID:00b0fb64-fac6-11e8-93eb-42010a840002,ResourceVersion:4319,Generation:0,CreationTimestamp:2018-12-08 08:48:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 08:48:15.695: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k4pv8,SelfLink:/api/v1/namespaces/e2e-tests-watch-k4pv8/configmaps/e2e-watch-test-watch-closed,UID:00b0fb64-fac6-11e8-93eb-42010a840002,ResourceVersion:4320,Generation:0,CreationTimestamp:2018-12-08 08:48:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  8 08:48:15.707: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k4pv8,SelfLink:/api/v1/namespaces/e2e-tests-watch-k4pv8/configmaps/e2e-watch-test-watch-closed,UID:00b0fb64-fac6-11e8-93eb-42010a840002,ResourceVersion:4321,Generation:0,CreationTimestamp:2018-12-08 08:48:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 08:48:15.708: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-k4pv8,SelfLink:/api/v1/namespaces/e2e-tests-watch-k4pv8/configmaps/e2e-watch-test-watch-closed,UID:00b0fb64-fac6-11e8-93eb-42010a840002,ResourceVersion:4322,Generation:0,CreationTimestamp:2018-12-08 08:48:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:48:15.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-k4pv8" for this suite.
Dec  8 08:48:21.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:48:21.740: INFO: namespace: e2e-tests-watch-k4pv8, resource: bindings, ignored listing per whitelist
Dec  8 08:48:21.805: INFO: namespace e2e-tests-watch-k4pv8 deletion completed in 6.094254772s

• [SLOW TEST:6.179 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:48:21.805: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  8 08:48:24.393: INFO: Successfully updated pod "pod-update-activedeadlineseconds-045fc3ff-fac6-11e8-9888-1eca7d857bda"
Dec  8 08:48:24.393: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-045fc3ff-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-pods-45fc2" to be "terminated due to deadline exceeded"
Dec  8 08:48:24.396: INFO: Pod "pod-update-activedeadlineseconds-045fc3ff-fac6-11e8-9888-1eca7d857bda": Phase="Running", Reason="", readiness=true. Elapsed: 3.139804ms
Dec  8 08:48:26.400: INFO: Pod "pod-update-activedeadlineseconds-045fc3ff-fac6-11e8-9888-1eca7d857bda": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006695843s
Dec  8 08:48:26.400: INFO: Pod "pod-update-activedeadlineseconds-045fc3ff-fac6-11e8-9888-1eca7d857bda" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:48:26.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-45fc2" for this suite.
Dec  8 08:48:32.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:48:32.509: INFO: namespace: e2e-tests-pods-45fc2, resource: bindings, ignored listing per whitelist
Dec  8 08:48:32.509: INFO: namespace e2e-tests-pods-45fc2 deletion completed in 6.104916981s

• [SLOW TEST:10.704 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:48:32.509: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-n228t
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 08:48:32.585: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 08:48:48.634: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.32.0.6:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-n228t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 08:48:48.634: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 08:48:48.716: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:48:48.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-n228t" for this suite.
Dec  8 08:49:10.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:49:10.772: INFO: namespace: e2e-tests-pod-network-test-n228t, resource: bindings, ignored listing per whitelist
Dec  8 08:49:10.815: INFO: namespace e2e-tests-pod-network-test-n228t deletion completed in 22.095565751s

• [SLOW TEST:38.306 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:49:10.815: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  8 08:49:10.884: INFO: Waiting up to 5m0s for pod "pod-2196a690-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-sfz52" to be "success or failure"
Dec  8 08:49:10.887: INFO: Pod "pod-2196a690-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.081457ms
Dec  8 08:49:12.891: INFO: Pod "pod-2196a690-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006597072s
STEP: Saw pod success
Dec  8 08:49:12.891: INFO: Pod "pod-2196a690-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:49:12.894: INFO: Trying to get logs from node conformance pod pod-2196a690-fac6-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 08:49:12.913: INFO: Waiting for pod pod-2196a690-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:49:12.916: INFO: Pod pod-2196a690-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:49:12.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sfz52" for this suite.
Dec  8 08:49:18.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:49:18.996: INFO: namespace: e2e-tests-emptydir-sfz52, resource: bindings, ignored listing per whitelist
Dec  8 08:49:19.006: INFO: namespace e2e-tests-emptydir-sfz52 deletion completed in 6.08678321s

• [SLOW TEST:8.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:49:19.006: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-26779e68-fac6-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 08:49:19.073: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-26782f77-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-zrfb4" to be "success or failure"
Dec  8 08:49:19.076: INFO: Pod "pod-projected-secrets-26782f77-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.634183ms
Dec  8 08:49:21.079: INFO: Pod "pod-projected-secrets-26782f77-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005950978s
STEP: Saw pod success
Dec  8 08:49:21.079: INFO: Pod "pod-projected-secrets-26782f77-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:49:21.082: INFO: Trying to get logs from node conformance pod pod-projected-secrets-26782f77-fac6-11e8-9888-1eca7d857bda container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 08:49:21.100: INFO: Waiting for pod pod-projected-secrets-26782f77-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:49:21.102: INFO: Pod pod-projected-secrets-26782f77-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:49:21.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zrfb4" for this suite.
Dec  8 08:49:27.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:49:27.140: INFO: namespace: e2e-tests-projected-zrfb4, resource: bindings, ignored listing per whitelist
Dec  8 08:49:27.188: INFO: namespace e2e-tests-projected-zrfb4 deletion completed in 6.082691533s

• [SLOW TEST:8.182 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:49:27.188: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:49:27.259: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b592722-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-cdl22" to be "success or failure"
Dec  8 08:49:27.267: INFO: Pod "downwardapi-volume-2b592722-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 7.587646ms
Dec  8 08:49:29.270: INFO: Pod "downwardapi-volume-2b592722-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01106009s
STEP: Saw pod success
Dec  8 08:49:29.270: INFO: Pod "downwardapi-volume-2b592722-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:49:29.273: INFO: Trying to get logs from node conformance pod downwardapi-volume-2b592722-fac6-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:49:29.289: INFO: Waiting for pod downwardapi-volume-2b592722-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:49:29.291: INFO: Pod downwardapi-volume-2b592722-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:49:29.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cdl22" for this suite.
Dec  8 08:49:35.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:49:35.355: INFO: namespace: e2e-tests-projected-cdl22, resource: bindings, ignored listing per whitelist
Dec  8 08:49:35.393: INFO: namespace e2e-tests-projected-cdl22 deletion completed in 6.098914612s

• [SLOW TEST:8.205 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:49:35.393: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 08:49:35.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 version --client'
Dec  8 08:49:35.529: INFO: stderr: ""
Dec  8 08:49:35.529: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  8 08:49:35.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-8v9wz'
Dec  8 08:49:35.962: INFO: stderr: ""
Dec  8 08:49:35.962: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  8 08:49:35.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-8v9wz'
Dec  8 08:49:36.165: INFO: stderr: ""
Dec  8 08:49:36.165: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 08:49:37.169: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:49:37.169: INFO: Found 0 / 1
Dec  8 08:49:38.169: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:49:38.169: INFO: Found 1 / 1
Dec  8 08:49:38.169: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 08:49:38.172: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:49:38.172: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 08:49:38.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 describe pod redis-master-wwmc2 --namespace=e2e-tests-kubectl-8v9wz'
Dec  8 08:49:38.281: INFO: stderr: ""
Dec  8 08:49:38.281: INFO: stdout: "Name:               redis-master-wwmc2\nNamespace:          e2e-tests-kubectl-8v9wz\nPriority:           0\nPriorityClassName:  <none>\nNode:               conformance/10.132.0.2\nStart Time:         Sat, 08 Dec 2018 08:49:35 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.32.0.6\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://b0f0d827b09c71428eb33fed13baef4d48ae86e5336946085bebaaab353d3159\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 08 Dec 2018 08:49:36 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-s7xgw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-s7xgw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-s7xgw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                  Message\n  ----    ------     ----  ----                  -------\n  Normal  Scheduled  3s    default-scheduler     Successfully assigned e2e-tests-kubectl-8v9wz/redis-master-wwmc2 to conformance\n  Normal  Pulled     2s    kubelet, conformance  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, conformance  Created container\n  Normal  Started    2s    kubelet, conformance  Started container\n"
Dec  8 08:49:38.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 describe rc redis-master --namespace=e2e-tests-kubectl-8v9wz'
Dec  8 08:49:38.399: INFO: stderr: ""
Dec  8 08:49:38.399: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-8v9wz\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-wwmc2\n"
Dec  8 08:49:38.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 describe service redis-master --namespace=e2e-tests-kubectl-8v9wz'
Dec  8 08:49:38.498: INFO: stderr: ""
Dec  8 08:49:38.498: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-8v9wz\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.105.156.132\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.32.0.6:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  8 08:49:38.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 describe node conformance'
Dec  8 08:49:38.618: INFO: stderr: ""
Dec  8 08:49:38.618: INFO: stdout: "Name:               conformance\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=conformance\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 08 Dec 2018 08:33:02 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 08 Dec 2018 08:33:21 +0000   Sat, 08 Dec 2018 08:33:21 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Sat, 08 Dec 2018 08:49:34 +0000   Sat, 08 Dec 2018 08:32:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 08 Dec 2018 08:49:34 +0000   Sat, 08 Dec 2018 08:32:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 08 Dec 2018 08:49:34 +0000   Sat, 08 Dec 2018 08:32:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 08 Dec 2018 08:49:34 +0000   Sat, 08 Dec 2018 08:33:32 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.132.0.2\n  Hostname:    conformance\nCapacity:\n cpu:                8\n ephemeral-storage:  253882800Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             30875792Ki\n pods:               110\nAllocatable:\n cpu:                8\n ephemeral-storage:  233978388093\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             30773392Ki\n pods:               110\nSystem Info:\n Machine ID:                 17ea5641aba5744b704b93152662372e\n System UUID:                17EA5641-ABA5-744B-704B-93152662372E\n Boot ID:                    2543344f-f634-4c6a-8d37-0ce7fb8dac26\n Kernel Version:             4.13.0-37-generic\n OS Image:                   Ubuntu 17.10\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.13.0\n Kube-Proxy Version:         v1.13.0\nNon-terminated Pods:         (12 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-8v9wz    redis-master-wwmc2                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  heptio-sonobuoy            sonobuoy-e2e-job-ecc19fc5f3ae4f3f                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-70deb288c1a64a95-8db2d    0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  kube-system                coredns-86c58d9df4-bph5g                                   100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)     16m\n  kube-system                coredns-86c58d9df4-mz9q8                                   100m (1%)     0 (0%)      70Mi (0%)        170Mi (0%)     16m\n  kube-system                etcd-conformance                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m\n  kube-system                kube-apiserver-conformance                                 250m (3%)     0 (0%)      0 (0%)           0 (0%)         15m\n  kube-system                kube-controller-manager-conformance                        200m (2%)     0 (0%)      0 (0%)           0 (0%)         15m\n  kube-system                kube-proxy-djdrm                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         16m\n  kube-system                kube-scheduler-conformance                                 100m (1%)     0 (0%)      0 (0%)           0 (0%)         15m\n  kube-system                weave-net-xxrrf                                            20m (0%)      0 (0%)      0 (0%)           0 (0%)         16m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                770m (9%)   0 (0%)\n  memory             140Mi (0%)  340Mi (1%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                     Message\n  ----    ------                   ----               ----                     -------\n  Normal  Starting                 16m                kubelet, conformance     Starting kubelet.\n  Normal  NodeHasSufficientMemory  16m (x8 over 16m)  kubelet, conformance     Node conformance status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    16m (x8 over 16m)  kubelet, conformance     Node conformance status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     16m (x7 over 16m)  kubelet, conformance     Node conformance status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  16m                kubelet, conformance     Updated Node Allocatable limit across pods\n  Normal  Starting                 16m                kube-proxy, conformance  Starting kube-proxy.\n"
Dec  8 08:49:38.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 describe namespace e2e-tests-kubectl-8v9wz'
Dec  8 08:49:38.718: INFO: stderr: ""
Dec  8 08:49:38.718: INFO: stdout: "Name:         e2e-tests-kubectl-8v9wz\nLabels:       e2e-framework=kubectl\n              e2e-run=18ce0aa4-fac4-11e8-9888-1eca7d857bda\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:49:38.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8v9wz" for this suite.
Dec  8 08:50:00.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:50:00.766: INFO: namespace: e2e-tests-kubectl-8v9wz, resource: bindings, ignored listing per whitelist
Dec  8 08:50:00.815: INFO: namespace e2e-tests-kubectl-8v9wz deletion completed in 22.093872839s

• [SLOW TEST:25.422 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:50:00.816: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-nnmkc
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  8 08:50:00.890: INFO: Found 0 stateful pods, waiting for 3
Dec  8 08:50:10.894: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:50:10.894: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:50:10.894: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  8 08:50:10.921: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  8 08:50:20.951: INFO: Updating stateful set ss2
Dec  8 08:50:20.957: INFO: Waiting for Pod e2e-tests-statefulset-nnmkc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 08:50:30.964: INFO: Waiting for Pod e2e-tests-statefulset-nnmkc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  8 08:50:40.997: INFO: Found 2 stateful pods, waiting for 3
Dec  8 08:50:51.002: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:50:51.002: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:50:51.002: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  8 08:50:51.025: INFO: Updating stateful set ss2
Dec  8 08:50:51.031: INFO: Waiting for Pod e2e-tests-statefulset-nnmkc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 08:51:01.038: INFO: Waiting for Pod e2e-tests-statefulset-nnmkc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  8 08:51:11.054: INFO: Updating stateful set ss2
Dec  8 08:51:11.060: INFO: Waiting for StatefulSet e2e-tests-statefulset-nnmkc/ss2 to complete update
Dec  8 08:51:11.060: INFO: Waiting for Pod e2e-tests-statefulset-nnmkc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 08:51:21.067: INFO: Deleting all statefulset in ns e2e-tests-statefulset-nnmkc
Dec  8 08:51:21.070: INFO: Scaling statefulset ss2 to 0
Dec  8 08:51:41.083: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 08:51:41.086: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:51:41.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-nnmkc" for this suite.
Dec  8 08:51:47.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:51:47.123: INFO: namespace: e2e-tests-statefulset-nnmkc, resource: bindings, ignored listing per whitelist
Dec  8 08:51:47.185: INFO: namespace e2e-tests-statefulset-nnmkc deletion completed in 6.087734019s

• [SLOW TEST:106.370 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:51:47.185: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  8 08:51:47.243: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-866404302 proxy --unix-socket=/tmp/kubectl-proxy-unix774975701/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:51:47.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6zlkd" for this suite.
Dec  8 08:51:53.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:51:53.352: INFO: namespace: e2e-tests-kubectl-6zlkd, resource: bindings, ignored listing per whitelist
Dec  8 08:51:53.404: INFO: namespace e2e-tests-kubectl-6zlkd deletion completed in 6.089499848s

• [SLOW TEST:6.219 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:51:53.404: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:51:53.466: INFO: Waiting up to 5m0s for pod "downwardapi-volume-827eadd1-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-gwg5z" to be "success or failure"
Dec  8 08:51:53.469: INFO: Pod "downwardapi-volume-827eadd1-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.481296ms
Dec  8 08:51:55.473: INFO: Pod "downwardapi-volume-827eadd1-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006263403s
STEP: Saw pod success
Dec  8 08:51:55.473: INFO: Pod "downwardapi-volume-827eadd1-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:51:55.476: INFO: Trying to get logs from node conformance pod downwardapi-volume-827eadd1-fac6-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:51:55.495: INFO: Waiting for pod downwardapi-volume-827eadd1-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:51:55.497: INFO: Pod downwardapi-volume-827eadd1-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:51:55.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gwg5z" for this suite.
Dec  8 08:52:01.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:52:01.563: INFO: namespace: e2e-tests-projected-gwg5z, resource: bindings, ignored listing per whitelist
Dec  8 08:52:01.606: INFO: namespace e2e-tests-projected-gwg5z deletion completed in 6.106094372s

• [SLOW TEST:8.202 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:52:01.606: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-8dlmh/configmap-test-8766d7a2-fac6-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 08:52:01.702: INFO: Waiting up to 5m0s for pod "pod-configmaps-87675141-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-8dlmh" to be "success or failure"
Dec  8 08:52:01.706: INFO: Pod "pod-configmaps-87675141-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.763516ms
Dec  8 08:52:03.710: INFO: Pod "pod-configmaps-87675141-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007856862s
STEP: Saw pod success
Dec  8 08:52:03.710: INFO: Pod "pod-configmaps-87675141-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:52:03.713: INFO: Trying to get logs from node conformance pod pod-configmaps-87675141-fac6-11e8-9888-1eca7d857bda container env-test: <nil>
STEP: delete the pod
Dec  8 08:52:03.731: INFO: Waiting for pod pod-configmaps-87675141-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:52:03.733: INFO: Pod pod-configmaps-87675141-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:52:03.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8dlmh" for this suite.
Dec  8 08:52:09.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:52:09.794: INFO: namespace: e2e-tests-configmap-8dlmh, resource: bindings, ignored listing per whitelist
Dec  8 08:52:09.821: INFO: namespace e2e-tests-configmap-8dlmh deletion completed in 6.084743152s

• [SLOW TEST:8.214 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:52:09.821: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:52:09.877: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8c46c403-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-25z4x" to be "success or failure"
Dec  8 08:52:09.879: INFO: Pod "downwardapi-volume-8c46c403-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.244834ms
Dec  8 08:52:11.883: INFO: Pod "downwardapi-volume-8c46c403-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005609069s
STEP: Saw pod success
Dec  8 08:52:11.883: INFO: Pod "downwardapi-volume-8c46c403-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:52:11.885: INFO: Trying to get logs from node conformance pod downwardapi-volume-8c46c403-fac6-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:52:11.903: INFO: Waiting for pod downwardapi-volume-8c46c403-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:52:11.906: INFO: Pod downwardapi-volume-8c46c403-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:52:11.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-25z4x" for this suite.
Dec  8 08:52:17.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:52:17.966: INFO: namespace: e2e-tests-downward-api-25z4x, resource: bindings, ignored listing per whitelist
Dec  8 08:52:18.003: INFO: namespace e2e-tests-downward-api-25z4x deletion completed in 6.094215581s

• [SLOW TEST:8.182 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:52:18.003: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 08:52:18.062: INFO: Creating ReplicaSet my-hostname-basic-91289a21-fac6-11e8-9888-1eca7d857bda
Dec  8 08:52:18.069: INFO: Pod name my-hostname-basic-91289a21-fac6-11e8-9888-1eca7d857bda: Found 0 pods out of 1
Dec  8 08:52:23.073: INFO: Pod name my-hostname-basic-91289a21-fac6-11e8-9888-1eca7d857bda: Found 1 pods out of 1
Dec  8 08:52:23.073: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-91289a21-fac6-11e8-9888-1eca7d857bda" is running
Dec  8 08:52:23.076: INFO: Pod "my-hostname-basic-91289a21-fac6-11e8-9888-1eca7d857bda-vgxcz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 08:52:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 08:52:19 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 08:52:19 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 08:52:18 +0000 UTC Reason: Message:}])
Dec  8 08:52:23.076: INFO: Trying to dial the pod
Dec  8 08:52:28.086: INFO: Controller my-hostname-basic-91289a21-fac6-11e8-9888-1eca7d857bda: Got expected result from replica 1 [my-hostname-basic-91289a21-fac6-11e8-9888-1eca7d857bda-vgxcz]: "my-hostname-basic-91289a21-fac6-11e8-9888-1eca7d857bda-vgxcz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:52:28.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-4q67l" for this suite.
Dec  8 08:52:34.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:52:34.109: INFO: namespace: e2e-tests-replicaset-4q67l, resource: bindings, ignored listing per whitelist
Dec  8 08:52:34.184: INFO: namespace e2e-tests-replicaset-4q67l deletion completed in 6.094237992s

• [SLOW TEST:16.181 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:52:34.184: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-9acdb905-fac6-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 08:52:34.253: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9ace37a5-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-qmz52" to be "success or failure"
Dec  8 08:52:34.259: INFO: Pod "pod-projected-configmaps-9ace37a5-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 5.412665ms
Dec  8 08:52:36.263: INFO: Pod "pod-projected-configmaps-9ace37a5-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009398508s
STEP: Saw pod success
Dec  8 08:52:36.263: INFO: Pod "pod-projected-configmaps-9ace37a5-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:52:36.266: INFO: Trying to get logs from node conformance pod pod-projected-configmaps-9ace37a5-fac6-11e8-9888-1eca7d857bda container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 08:52:36.284: INFO: Waiting for pod pod-projected-configmaps-9ace37a5-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:52:36.287: INFO: Pod pod-projected-configmaps-9ace37a5-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:52:36.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qmz52" for this suite.
Dec  8 08:52:42.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:52:42.323: INFO: namespace: e2e-tests-projected-qmz52, resource: bindings, ignored listing per whitelist
Dec  8 08:52:42.384: INFO: namespace e2e-tests-projected-qmz52 deletion completed in 6.09365409s

• [SLOW TEST:8.200 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:52:42.384: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tn7lf
Dec  8 08:52:44.456: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tn7lf
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 08:52:44.459: INFO: Initial restart count of pod liveness-exec is 0
Dec  8 08:53:36.556: INFO: Restart count of pod e2e-tests-container-probe-tn7lf/liveness-exec is now 1 (52.097740879s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:53:36.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tn7lf" for this suite.
Dec  8 08:53:42.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:53:42.618: INFO: namespace: e2e-tests-container-probe-tn7lf, resource: bindings, ignored listing per whitelist
Dec  8 08:53:42.671: INFO: namespace e2e-tests-container-probe-tn7lf deletion completed in 6.103040822s

• [SLOW TEST:60.287 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:53:42.671: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c3a02ec8-fac6-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 08:53:42.742: INFO: Waiting up to 5m0s for pod "pod-secrets-c3a0c3b9-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-crk8v" to be "success or failure"
Dec  8 08:53:42.744: INFO: Pod "pod-secrets-c3a0c3b9-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.465282ms
Dec  8 08:53:44.748: INFO: Pod "pod-secrets-c3a0c3b9-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006225501s
STEP: Saw pod success
Dec  8 08:53:44.748: INFO: Pod "pod-secrets-c3a0c3b9-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:53:44.751: INFO: Trying to get logs from node conformance pod pod-secrets-c3a0c3b9-fac6-11e8-9888-1eca7d857bda container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 08:53:44.766: INFO: Waiting for pod pod-secrets-c3a0c3b9-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:53:44.768: INFO: Pod pod-secrets-c3a0c3b9-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:53:44.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-crk8v" for this suite.
Dec  8 08:53:50.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:53:50.862: INFO: namespace: e2e-tests-secrets-crk8v, resource: bindings, ignored listing per whitelist
Dec  8 08:53:50.866: INFO: namespace e2e-tests-secrets-crk8v deletion completed in 6.096069788s

• [SLOW TEST:8.195 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:53:50.866: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  8 08:53:54.969: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 08:53:54.973: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 08:53:56.973: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 08:53:56.977: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 08:53:58.974: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 08:53:58.977: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 08:54:00.974: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 08:54:00.978: INFO: Pod pod-with-poststart-http-hook still exists
Dec  8 08:54:02.974: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  8 08:54:02.978: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:54:02.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-x96bp" for this suite.
Dec  8 08:54:24.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:54:25.037: INFO: namespace: e2e-tests-container-lifecycle-hook-x96bp, resource: bindings, ignored listing per whitelist
Dec  8 08:54:25.073: INFO: namespace e2e-tests-container-lifecycle-hook-x96bp deletion completed in 22.091798831s

• [SLOW TEST:34.207 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:54:25.073: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 08:54:25.163: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"dce84321-fac6-11e8-93eb-42010a840002", Controller:(*bool)(0xc0005a38fe), BlockOwnerDeletion:(*bool)(0xc0005a38ff)}}
Dec  8 08:54:25.167: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"dce7306d-fac6-11e8-93eb-42010a840002", Controller:(*bool)(0xc000beeb0a), BlockOwnerDeletion:(*bool)(0xc000beeb0b)}}
Dec  8 08:54:25.173: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"dce7b3ff-fac6-11e8-93eb-42010a840002", Controller:(*bool)(0xc0005a3b66), BlockOwnerDeletion:(*bool)(0xc0005a3b67)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:54:30.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8qw2f" for this suite.
Dec  8 08:54:36.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:54:36.223: INFO: namespace: e2e-tests-gc-8qw2f, resource: bindings, ignored listing per whitelist
Dec  8 08:54:36.279: INFO: namespace e2e-tests-gc-8qw2f deletion completed in 6.092321789s

• [SLOW TEST:11.206 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:54:36.280: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  8 08:54:36.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-hdgs6'
Dec  8 08:54:36.525: INFO: stderr: ""
Dec  8 08:54:36.525: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 08:54:37.530: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:54:37.530: INFO: Found 1 / 1
Dec  8 08:54:37.530: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  8 08:54:37.533: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:54:37.533: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 08:54:37.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 patch pod redis-master-kdshf --namespace=e2e-tests-kubectl-hdgs6 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  8 08:54:37.623: INFO: stderr: ""
Dec  8 08:54:37.623: INFO: stdout: "pod/redis-master-kdshf patched\n"
STEP: checking annotations
Dec  8 08:54:37.626: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 08:54:37.626: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:54:37.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hdgs6" for this suite.
Dec  8 08:54:59.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:54:59.695: INFO: namespace: e2e-tests-kubectl-hdgs6, resource: bindings, ignored listing per whitelist
Dec  8 08:54:59.733: INFO: namespace e2e-tests-kubectl-hdgs6 deletion completed in 22.104195169s

• [SLOW TEST:23.454 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:54:59.734: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-f1920808-fac6-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 08:54:59.825: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f192a8b5-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-ggnrr" to be "success or failure"
Dec  8 08:54:59.831: INFO: Pod "pod-projected-configmaps-f192a8b5-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 6.418514ms
Dec  8 08:55:01.839: INFO: Pod "pod-projected-configmaps-f192a8b5-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014423446s
STEP: Saw pod success
Dec  8 08:55:01.839: INFO: Pod "pod-projected-configmaps-f192a8b5-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:55:01.845: INFO: Trying to get logs from node conformance pod pod-projected-configmaps-f192a8b5-fac6-11e8-9888-1eca7d857bda container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 08:55:01.903: INFO: Waiting for pod pod-projected-configmaps-f192a8b5-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:55:01.907: INFO: Pod pod-projected-configmaps-f192a8b5-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:55:01.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ggnrr" for this suite.
Dec  8 08:55:07.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:55:08.031: INFO: namespace: e2e-tests-projected-ggnrr, resource: bindings, ignored listing per whitelist
Dec  8 08:55:08.040: INFO: namespace e2e-tests-projected-ggnrr deletion completed in 6.127350375s

• [SLOW TEST:8.307 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:55:08.040: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 08:55:08.128: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f6855443-fac6-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-wx2lx" to be "success or failure"
Dec  8 08:55:08.134: INFO: Pod "downwardapi-volume-f6855443-fac6-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 5.730466ms
Dec  8 08:55:10.137: INFO: Pod "downwardapi-volume-f6855443-fac6-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009525713s
STEP: Saw pod success
Dec  8 08:55:10.138: INFO: Pod "downwardapi-volume-f6855443-fac6-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 08:55:10.141: INFO: Trying to get logs from node conformance pod downwardapi-volume-f6855443-fac6-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 08:55:10.160: INFO: Waiting for pod downwardapi-volume-f6855443-fac6-11e8-9888-1eca7d857bda to disappear
Dec  8 08:55:10.162: INFO: Pod downwardapi-volume-f6855443-fac6-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:55:10.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wx2lx" for this suite.
Dec  8 08:55:16.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:55:16.238: INFO: namespace: e2e-tests-projected-wx2lx, resource: bindings, ignored listing per whitelist
Dec  8 08:55:16.257: INFO: namespace e2e-tests-projected-wx2lx deletion completed in 6.091732747s

• [SLOW TEST:8.217 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:55:16.257: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  8 08:55:18.342: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-fb683bfd-fac6-11e8-9888-1eca7d857bda", GenerateName:"", Namespace:"e2e-tests-pods-dkhv2", SelfLink:"/api/v1/namespaces/e2e-tests-pods-dkhv2/pods/pod-submit-remove-fb683bfd-fac6-11e8-9888-1eca7d857bda", UID:"fb698c2b-fac6-11e8-93eb-42010a840002", ResourceVersion:"5649", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679856116, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"318112673"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-262sn", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001fd3e80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-262sn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001f9fe18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001906d20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f9fed0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001f9fef0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001f9fef8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001f9fefc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679856116, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679856117, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679856117, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679856116, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.132.0.2", PodIP:"10.32.0.6", StartTime:(*v1.Time)(0xc000856d00), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000856d20), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6", ContainerID:"docker://67e1d14ffe05754065284e11100a37517ae9b817e3261f271ab78a220ae6c029"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  8 08:55:23.354: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:55:23.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dkhv2" for this suite.
Dec  8 08:55:29.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:55:29.399: INFO: namespace: e2e-tests-pods-dkhv2, resource: bindings, ignored listing per whitelist
Dec  8 08:55:29.459: INFO: namespace e2e-tests-pods-dkhv2 deletion completed in 6.099016759s

• [SLOW TEST:13.202 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:55:29.460: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 08:55:29.532: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 08:55:29.540: INFO: Number of nodes with available pods: 0
Dec  8 08:55:29.540: INFO: Node conformance is running more than one daemon pod
Dec  8 08:55:30.547: INFO: Number of nodes with available pods: 0
Dec  8 08:55:30.547: INFO: Node conformance is running more than one daemon pod
Dec  8 08:55:31.547: INFO: Number of nodes with available pods: 1
Dec  8 08:55:31.547: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  8 08:55:31.564: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:32.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:33.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:34.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:35.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:36.570: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:37.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:38.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:39.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:40.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:41.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:42.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:43.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:44.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:45.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:46.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:47.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:48.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:49.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:50.570: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:51.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:52.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:53.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:54.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:55.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:56.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:57.570: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:58.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:55:59.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:56:00.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:56:01.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:56:02.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:56:03.571: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:56:04.570: INFO: Wrong image for pod: daemon-set-9whwl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  8 08:56:04.570: INFO: Pod daemon-set-9whwl is not available
Dec  8 08:56:05.571: INFO: Pod daemon-set-qqqdd is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  8 08:56:05.580: INFO: Number of nodes with available pods: 0
Dec  8 08:56:05.580: INFO: Node conformance is running more than one daemon pod
Dec  8 08:56:06.587: INFO: Number of nodes with available pods: 1
Dec  8 08:56:06.587: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qs7j2, will wait for the garbage collector to delete the pods
Dec  8 08:56:06.662: INFO: Deleting DaemonSet.extensions daemon-set took: 6.719277ms
Dec  8 08:56:06.762: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.302041ms
Dec  8 08:56:21.366: INFO: Number of nodes with available pods: 0
Dec  8 08:56:21.366: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 08:56:21.369: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qs7j2/daemonsets","resourceVersion":"5788"},"items":null}

Dec  8 08:56:21.371: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qs7j2/pods","resourceVersion":"5788"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 08:56:21.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qs7j2" for this suite.
Dec  8 08:56:27.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 08:56:27.428: INFO: namespace: e2e-tests-daemonsets-qs7j2, resource: bindings, ignored listing per whitelist
Dec  8 08:56:27.472: INFO: namespace e2e-tests-daemonsets-qs7j2 deletion completed in 6.090829775s

• [SLOW TEST:58.012 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 08:56:27.472: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rnlfg
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-rnlfg
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-rnlfg
Dec  8 08:56:27.539: INFO: Found 0 stateful pods, waiting for 1
Dec  8 08:56:37.543: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  8 08:56:37.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 08:56:37.716: INFO: stderr: ""
Dec  8 08:56:37.716: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 08:56:37.716: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 08:56:37.720: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  8 08:56:47.724: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 08:56:47.724: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 08:56:47.735: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:56:47.735: INFO: ss-0  conformance  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:37 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:56:47.735: INFO: 
Dec  8 08:56:47.735: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  8 08:56:48.738: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99705092s
Dec  8 08:56:49.742: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993381196s
Dec  8 08:56:50.746: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989886052s
Dec  8 08:56:51.750: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985733742s
Dec  8 08:56:52.754: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98145065s
Dec  8 08:56:53.758: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977462942s
Dec  8 08:56:54.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.973730113s
Dec  8 08:56:55.766: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.969883773s
Dec  8 08:56:56.770: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.680073ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-rnlfg
Dec  8 08:56:57.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:56:57.929: INFO: stderr: ""
Dec  8 08:56:57.929: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 08:56:57.929: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 08:56:57.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:56:58.088: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  8 08:56:58.088: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 08:56:58.088: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 08:56:58.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:56:58.245: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  8 08:56:58.245: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 08:56:58.245: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 08:56:58.248: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:56:58.248: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 08:56:58.248: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  8 08:56:58.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 08:56:58.405: INFO: stderr: ""
Dec  8 08:56:58.405: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 08:56:58.405: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 08:56:58.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 08:56:58.566: INFO: stderr: ""
Dec  8 08:56:58.566: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 08:56:58.566: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 08:56:58.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 08:56:58.732: INFO: stderr: ""
Dec  8 08:56:58.732: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 08:56:58.732: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 08:56:58.732: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 08:56:58.736: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  8 08:57:08.748: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 08:57:08.748: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 08:57:08.748: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 08:57:08.759: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:08.759: INFO: ss-0  conformance  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:08.759: INFO: ss-1  conformance  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:08.759: INFO: ss-2  conformance  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:08.759: INFO: 
Dec  8 08:57:08.759: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 08:57:09.764: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:09.764: INFO: ss-0  conformance  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:09.764: INFO: ss-1  conformance  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:09.764: INFO: ss-2  conformance  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:09.764: INFO: 
Dec  8 08:57:09.764: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 08:57:10.768: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:10.768: INFO: ss-0  conformance  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:10.768: INFO: ss-1  conformance  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:10.768: INFO: ss-2  conformance  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:10.768: INFO: 
Dec  8 08:57:10.768: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 08:57:11.773: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:11.773: INFO: ss-0  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:11.773: INFO: ss-1  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:11.773: INFO: ss-2  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:11.773: INFO: 
Dec  8 08:57:11.773: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  8 08:57:12.777: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:12.777: INFO: ss-0  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:12.777: INFO: ss-2  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:12.777: INFO: 
Dec  8 08:57:12.777: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 08:57:13.781: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:13.781: INFO: ss-0  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:13.781: INFO: ss-2  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:13.781: INFO: 
Dec  8 08:57:13.781: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 08:57:14.786: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:14.786: INFO: ss-0  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:14.786: INFO: ss-2  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:14.786: INFO: 
Dec  8 08:57:14.786: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 08:57:15.790: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:15.790: INFO: ss-0  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:15.790: INFO: ss-2  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:15.790: INFO: 
Dec  8 08:57:15.790: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 08:57:16.794: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:16.794: INFO: ss-0  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:16.794: INFO: ss-2  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:16.794: INFO: 
Dec  8 08:57:16.794: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  8 08:57:17.798: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Dec  8 08:57:17.798: INFO: ss-0  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:27 +0000 UTC  }]
Dec  8 08:57:17.798: INFO: ss-2  conformance  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 08:56:47 +0000 UTC  }]
Dec  8 08:57:17.798: INFO: 
Dec  8 08:57:17.798: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-rnlfg
Dec  8 08:57:18.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:57:18.911: INFO: rc: 1
Dec  8 08:57:18.911: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0023d6c60 exit status 1 <nil> <nil> true [0xc000674c80 0xc000674d70 0xc000674de0] [0xc000674c80 0xc000674d70 0xc000674de0] [0xc000674d58 0xc000674db8] [0x92f8e0 0x92f8e0] 0xc0024ad380 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec  8 08:57:28.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:57:28.991: INFO: rc: 1
Dec  8 08:57:28.991: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000a82390 exit status 1 <nil> <nil> true [0xc001dd4008 0xc001dd4020 0xc001dd4038] [0xc001dd4008 0xc001dd4020 0xc001dd4038] [0xc001dd4018 0xc001dd4030] [0x92f8e0 0x92f8e0] 0xc001c0e240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:57:38.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:57:39.071: INFO: rc: 1
Dec  8 08:57:39.071: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002525800 exit status 1 <nil> <nil> true [0xc0017b40c8 0xc0017b40e0 0xc0017b40f8] [0xc0017b40c8 0xc0017b40e0 0xc0017b40f8] [0xc0017b40d8 0xc0017b40f0] [0x92f8e0 0x92f8e0] 0xc00226a900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:57:49.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:57:49.147: INFO: rc: 1
Dec  8 08:57:49.147: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000a82750 exit status 1 <nil> <nil> true [0xc001dd4040 0xc001dd4058 0xc001dd4070] [0xc001dd4040 0xc001dd4058 0xc001dd4070] [0xc001dd4050 0xc001dd4068] [0x92f8e0 0x92f8e0] 0xc001c0e5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:57:59.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:57:59.230: INFO: rc: 1
Dec  8 08:57:59.230: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002525bc0 exit status 1 <nil> <nil> true [0xc0017b4100 0xc0017b4118 0xc0017b4130] [0xc0017b4100 0xc0017b4118 0xc0017b4130] [0xc0017b4110 0xc0017b4128] [0x92f8e0 0x92f8e0] 0xc00226ac00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:58:09.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:58:09.310: INFO: rc: 1
Dec  8 08:58:09.310: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002525f80 exit status 1 <nil> <nil> true [0xc0017b4138 0xc0017b4150 0xc0017b4168] [0xc0017b4138 0xc0017b4150 0xc0017b4168] [0xc0017b4148 0xc0017b4160] [0x92f8e0 0x92f8e0] 0xc00226af00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:58:19.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:58:19.388: INFO: rc: 1
Dec  8 08:58:19.388: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000a82ae0 exit status 1 <nil> <nil> true [0xc001dd4078 0xc001dd4090 0xc001dd40a8] [0xc001dd4078 0xc001dd4090 0xc001dd40a8] [0xc001dd4088 0xc001dd40a0] [0x92f8e0 0x92f8e0] 0xc001c0eae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:58:29.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:58:29.468: INFO: rc: 1
Dec  8 08:58:29.468: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000a82ea0 exit status 1 <nil> <nil> true [0xc001dd40b0 0xc001dd40c8 0xc001dd40e0] [0xc001dd40b0 0xc001dd40c8 0xc001dd40e0] [0xc001dd40c0 0xc001dd40d8] [0x92f8e0 0x92f8e0] 0xc001c0f0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:58:39.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:58:39.547: INFO: rc: 1
Dec  8 08:58:39.547: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00183ced0 exit status 1 <nil> <nil> true [0xc00030b500 0xc00030b668 0xc00030b820] [0xc00030b500 0xc00030b668 0xc00030b820] [0xc00030b5d8 0xc00030b710] [0x92f8e0 0x92f8e0] 0xc001cf48a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:58:49.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:58:49.631: INFO: rc: 1
Dec  8 08:58:49.631: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00183d380 exit status 1 <nil> <nil> true [0xc00030b840 0xc00030b990 0xc00030ba50] [0xc00030b840 0xc00030b990 0xc00030ba50] [0xc00030b940 0xc00030b9e0] [0x92f8e0 0x92f8e0] 0xc001cf4ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:58:59.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:58:59.710: INFO: rc: 1
Dec  8 08:58:59.710: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00183d740 exit status 1 <nil> <nil> true [0xc00030ba88 0xc00030bad8 0xc00030bb28] [0xc00030ba88 0xc00030bad8 0xc00030bb28] [0xc00030bad0 0xc00030bb10] [0x92f8e0 0x92f8e0] 0xc001cf5080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:59:09.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:59:09.790: INFO: rc: 1
Dec  8 08:59:09.790: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0019202d0 exit status 1 <nil> <nil> true [0xc00030bb40 0xc0017b4170 0xc0017b4188] [0xc00030bb40 0xc0017b4170 0xc0017b4188] [0xc00030bbd0 0xc0017b4180] [0x92f8e0 0x92f8e0] 0xc00226b0e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:59:19.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:59:19.868: INFO: rc: 1
Dec  8 08:59:19.868: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002272390 exit status 1 <nil> <nil> true [0xc00030a020 0xc00030b468 0xc00030b5d8] [0xc00030a020 0xc00030b468 0xc00030b5d8] [0xc00030b428 0xc00030b588] [0x92f8e0 0x92f8e0] 0xc001cf45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:59:29.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:59:29.945: INFO: rc: 1
Dec  8 08:59:29.945: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00183c3c0 exit status 1 <nil> <nil> true [0xc0017b4000 0xc0017b4018 0xc0017b4030] [0xc0017b4000 0xc0017b4018 0xc0017b4030] [0xc0017b4010 0xc0017b4028] [0x92f8e0 0x92f8e0] 0xc00226a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:59:39.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:59:40.023: INFO: rc: 1
Dec  8 08:59:40.023: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00183c8a0 exit status 1 <nil> <nil> true [0xc0017b4038 0xc0017b4050 0xc0017b4068] [0xc0017b4038 0xc0017b4050 0xc0017b4068] [0xc0017b4048 0xc0017b4060] [0x92f8e0 0x92f8e0] 0xc00226a5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 08:59:50.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 08:59:50.099: INFO: rc: 1
Dec  8 08:59:50.099: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002272990 exit status 1 <nil> <nil> true [0xc00030b668 0xc00030b820 0xc00030b940] [0xc00030b668 0xc00030b820 0xc00030b940] [0xc00030b710 0xc00030b8b8] [0x92f8e0 0x92f8e0] 0xc001cf4960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:00:00.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:00:00.177: INFO: rc: 1
Dec  8 09:00:00.177: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00183cc30 exit status 1 <nil> <nil> true [0xc0017b4070 0xc0017b4088 0xc0017b40a0] [0xc0017b4070 0xc0017b4088 0xc0017b40a0] [0xc0017b4080 0xc0017b4098] [0x92f8e0 0x92f8e0] 0xc00226a8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:00:10.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:00:10.314: INFO: rc: 1
Dec  8 09:00:10.314: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002524450 exit status 1 <nil> <nil> true [0xc000674088 0xc000674158 0xc0006741e0] [0xc000674088 0xc000674158 0xc0006741e0] [0xc0006740e0 0xc0006741d8] [0x92f8e0 0x92f8e0] 0xc0024ac480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:00:20.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:00:20.402: INFO: rc: 1
Dec  8 09:00:20.402: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00183d0b0 exit status 1 <nil> <nil> true [0xc0017b40a8 0xc0017b40c0 0xc0017b40d8] [0xc0017b40a8 0xc0017b40c0 0xc0017b40d8] [0xc0017b40b8 0xc0017b40d0] [0x92f8e0 0x92f8e0] 0xc00226aba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:00:30.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:00:30.480: INFO: rc: 1
Dec  8 09:00:30.480: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002272d50 exit status 1 <nil> <nil> true [0xc00030b990 0xc00030ba50 0xc00030bad0] [0xc00030b990 0xc00030ba50 0xc00030bad0] [0xc00030b9e0 0xc00030bab0] [0x92f8e0 0x92f8e0] 0xc001cf4cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:00:40.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:00:40.560: INFO: rc: 1
Dec  8 09:00:40.560: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002273110 exit status 1 <nil> <nil> true [0xc00030bad8 0xc00030bb28 0xc00030bc30] [0xc00030bad8 0xc00030bb28 0xc00030bc30] [0xc00030bb10 0xc00030bbf8] [0x92f8e0 0x92f8e0] 0xc001cf5140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:00:50.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:00:50.638: INFO: rc: 1
Dec  8 09:00:50.639: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0022734d0 exit status 1 <nil> <nil> true [0xc00030bc38 0xc00030bcb0 0xc00030bce8] [0xc00030bc38 0xc00030bcb0 0xc00030bce8] [0xc00030bc70 0xc00030bcd8] [0x92f8e0 0x92f8e0] 0xc001cf5740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:01:00.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:01:00.718: INFO: rc: 1
Dec  8 09:01:00.719: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002273860 exit status 1 <nil> <nil> true [0xc00030bd50 0xc00030bd98 0xc00030bf18] [0xc00030bd50 0xc00030bd98 0xc00030bf18] [0xc00030bd88 0xc00030bdb0] [0x92f8e0 0x92f8e0] 0xc001cf5b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:01:10.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:01:10.803: INFO: rc: 1
Dec  8 09:01:10.803: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001920780 exit status 1 <nil> <nil> true [0xc001dd4008 0xc001dd4020 0xc001dd4038] [0xc001dd4008 0xc001dd4020 0xc001dd4038] [0xc001dd4018 0xc001dd4030] [0x92f8e0 0x92f8e0] 0xc001c0e1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:01:20.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:01:20.880: INFO: rc: 1
Dec  8 09:01:20.880: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001920900 exit status 1 <nil> <nil> true [0xc000160000 0xc00030b428 0xc00030b588] [0xc000160000 0xc00030b428 0xc00030b588] [0xc00030b1b8 0xc00030b500] [0x92f8e0 0x92f8e0] 0xc001cf45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:01:30.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:01:30.955: INFO: rc: 1
Dec  8 09:01:30.955: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0022723c0 exit status 1 <nil> <nil> true [0xc001dd4040 0xc001dd4058 0xc001dd4070] [0xc001dd4040 0xc001dd4058 0xc001dd4070] [0xc001dd4050 0xc001dd4068] [0x92f8e0 0x92f8e0] 0xc001c0e540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:01:40.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:01:41.036: INFO: rc: 1
Dec  8 09:01:41.036: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002524420 exit status 1 <nil> <nil> true [0xc000674088 0xc000674158 0xc0006741e0] [0xc000674088 0xc000674158 0xc0006741e0] [0xc0006740e0 0xc0006741d8] [0x92f8e0 0x92f8e0] 0xc0024ac480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:01:51.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:01:51.114: INFO: rc: 1
Dec  8 09:01:51.114: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001920cc0 exit status 1 <nil> <nil> true [0xc00030b5d8 0xc00030b710 0xc00030b8b8] [0xc00030b5d8 0xc00030b710 0xc00030b8b8] [0xc00030b6e8 0xc00030b840] [0x92f8e0 0x92f8e0] 0xc001cf4960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:02:01.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:02:01.193: INFO: rc: 1
Dec  8 09:02:01.193: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001921050 exit status 1 <nil> <nil> true [0xc00030b940 0xc00030b9e0 0xc00030bab0] [0xc00030b940 0xc00030b9e0 0xc00030bab0] [0xc00030b998 0xc00030ba88] [0x92f8e0 0x92f8e0] 0xc001cf4cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:02:11.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:02:11.268: INFO: rc: 1
Dec  8 09:02:11.268: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00183c3f0 exit status 1 <nil> <nil> true [0xc0017b4000 0xc0017b4018 0xc0017b4030] [0xc0017b4000 0xc0017b4018 0xc0017b4030] [0xc0017b4010 0xc0017b4028] [0x92f8e0 0x92f8e0] 0xc00226a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  8 09:02:21.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-rnlfg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:02:21.351: INFO: rc: 1
Dec  8 09:02:21.351: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Dec  8 09:02:21.351: INFO: Scaling statefulset ss to 0
Dec  8 09:02:21.361: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 09:02:21.364: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rnlfg
Dec  8 09:02:21.366: INFO: Scaling statefulset ss to 0
Dec  8 09:02:21.380: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 09:02:21.382: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:02:21.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rnlfg" for this suite.
Dec  8 09:02:27.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:02:27.415: INFO: namespace: e2e-tests-statefulset-rnlfg, resource: bindings, ignored listing per whitelist
Dec  8 09:02:27.495: INFO: namespace e2e-tests-statefulset-rnlfg deletion completed in 6.099553394s

• [SLOW TEST:360.023 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:02:27.495: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-fc732d4f-fac7-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:02:27.572: INFO: Waiting up to 5m0s for pod "pod-configmaps-fc739b91-fac7-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-5pqst" to be "success or failure"
Dec  8 09:02:27.575: INFO: Pod "pod-configmaps-fc739b91-fac7-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.630601ms
Dec  8 09:02:29.580: INFO: Pod "pod-configmaps-fc739b91-fac7-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006896658s
STEP: Saw pod success
Dec  8 09:02:29.580: INFO: Pod "pod-configmaps-fc739b91-fac7-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:02:29.582: INFO: Trying to get logs from node conformance pod pod-configmaps-fc739b91-fac7-11e8-9888-1eca7d857bda container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:02:29.602: INFO: Waiting for pod pod-configmaps-fc739b91-fac7-11e8-9888-1eca7d857bda to disappear
Dec  8 09:02:29.604: INFO: Pod pod-configmaps-fc739b91-fac7-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:02:29.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-5pqst" for this suite.
Dec  8 09:02:35.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:02:35.652: INFO: namespace: e2e-tests-configmap-5pqst, resource: bindings, ignored listing per whitelist
Dec  8 09:02:35.700: INFO: namespace e2e-tests-configmap-5pqst deletion completed in 6.093615049s

• [SLOW TEST:8.205 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:02:35.700: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 09:02:35.764: INFO: (0) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.772257ms)
Dec  8 09:02:35.769: INFO: (1) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.810022ms)
Dec  8 09:02:35.772: INFO: (2) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.40875ms)
Dec  8 09:02:35.776: INFO: (3) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.324592ms)
Dec  8 09:02:35.780: INFO: (4) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.858039ms)
Dec  8 09:02:35.783: INFO: (5) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.416608ms)
Dec  8 09:02:35.788: INFO: (6) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.567182ms)
Dec  8 09:02:35.792: INFO: (7) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 4.074949ms)
Dec  8 09:02:35.796: INFO: (8) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.863782ms)
Dec  8 09:02:35.800: INFO: (9) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.955567ms)
Dec  8 09:02:35.803: INFO: (10) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.574723ms)
Dec  8 09:02:35.807: INFO: (11) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.452083ms)
Dec  8 09:02:35.810: INFO: (12) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.262482ms)
Dec  8 09:02:35.814: INFO: (13) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.53994ms)
Dec  8 09:02:35.817: INFO: (14) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.546609ms)
Dec  8 09:02:35.821: INFO: (15) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.198685ms)
Dec  8 09:02:35.824: INFO: (16) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.246004ms)
Dec  8 09:02:35.828: INFO: (17) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.479381ms)
Dec  8 09:02:35.831: INFO: (18) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 3.603017ms)
Dec  8 09:02:35.837: INFO: (19) /api/v1/nodes/conformance:10250/proxy/logs/: <pre>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a href="btmp">btmp</a>
<a href="cl... (200; 5.610508ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:02:35.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-nhfw9" for this suite.
Dec  8 09:02:41.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:02:41.880: INFO: namespace: e2e-tests-proxy-nhfw9, resource: bindings, ignored listing per whitelist
Dec  8 09:02:41.928: INFO: namespace e2e-tests-proxy-nhfw9 deletion completed in 6.08843167s

• [SLOW TEST:6.228 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:02:41.929: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:02:42.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-brp6x" for this suite.
Dec  8 09:03:04.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:03:04.057: INFO: namespace: e2e-tests-pods-brp6x, resource: bindings, ignored listing per whitelist
Dec  8 09:03:04.108: INFO: namespace e2e-tests-pods-brp6x deletion completed in 22.099105091s

• [SLOW TEST:22.180 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:03:04.109: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  8 09:03:04.175: INFO: Waiting up to 5m0s for pod "pod-1244d274-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-wx9bn" to be "success or failure"
Dec  8 09:03:04.178: INFO: Pod "pod-1244d274-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.03155ms
Dec  8 09:03:06.182: INFO: Pod "pod-1244d274-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006577019s
STEP: Saw pod success
Dec  8 09:03:06.182: INFO: Pod "pod-1244d274-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:03:06.184: INFO: Trying to get logs from node conformance pod pod-1244d274-fac8-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:03:06.201: INFO: Waiting for pod pod-1244d274-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:03:06.204: INFO: Pod pod-1244d274-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:03:06.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wx9bn" for this suite.
Dec  8 09:03:12.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:03:12.289: INFO: namespace: e2e-tests-emptydir-wx9bn, resource: bindings, ignored listing per whitelist
Dec  8 09:03:12.310: INFO: namespace e2e-tests-emptydir-wx9bn deletion completed in 6.103844161s

• [SLOW TEST:8.202 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:03:12.311: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-1728e439-fac8-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:03:12.385: INFO: Waiting up to 5m0s for pod "pod-secrets-17296237-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-ncz4d" to be "success or failure"
Dec  8 09:03:12.390: INFO: Pod "pod-secrets-17296237-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 5.412144ms
Dec  8 09:03:14.395: INFO: Pod "pod-secrets-17296237-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009481226s
STEP: Saw pod success
Dec  8 09:03:14.395: INFO: Pod "pod-secrets-17296237-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:03:14.398: INFO: Trying to get logs from node conformance pod pod-secrets-17296237-fac8-11e8-9888-1eca7d857bda container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:03:14.422: INFO: Waiting for pod pod-secrets-17296237-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:03:14.425: INFO: Pod pod-secrets-17296237-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:03:14.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ncz4d" for this suite.
Dec  8 09:03:20.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:03:20.487: INFO: namespace: e2e-tests-secrets-ncz4d, resource: bindings, ignored listing per whitelist
Dec  8 09:03:20.515: INFO: namespace e2e-tests-secrets-ncz4d deletion completed in 6.086657845s

• [SLOW TEST:8.205 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:03:20.515: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wrcsl
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-wrcsl
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-wrcsl
Dec  8 09:03:20.589: INFO: Found 0 stateful pods, waiting for 1
Dec  8 09:03:30.593: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  8 09:03:30.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-wrcsl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 09:03:30.756: INFO: stderr: ""
Dec  8 09:03:30.756: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 09:03:30.756: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 09:03:30.760: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  8 09:03:40.768: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 09:03:40.768: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 09:03:40.781: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999288s
Dec  8 09:03:41.786: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996182993s
Dec  8 09:03:42.790: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991761962s
Dec  8 09:03:43.795: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987298165s
Dec  8 09:03:44.799: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982939469s
Dec  8 09:03:45.803: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97887957s
Dec  8 09:03:46.807: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.974776545s
Dec  8 09:03:47.811: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970864419s
Dec  8 09:03:48.815: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.966570151s
Dec  8 09:03:49.819: INFO: Verifying statefulset ss doesn't scale past 1 for another 962.599358ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-wrcsl
Dec  8 09:03:50.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-wrcsl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:03:50.983: INFO: stderr: ""
Dec  8 09:03:50.984: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 09:03:50.984: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 09:03:50.987: INFO: Found 1 stateful pods, waiting for 3
Dec  8 09:04:00.991: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 09:04:00.991: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  8 09:04:00.991: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  8 09:04:00.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-wrcsl ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 09:04:01.157: INFO: stderr: ""
Dec  8 09:04:01.157: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 09:04:01.157: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 09:04:01.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-wrcsl ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 09:04:01.322: INFO: stderr: ""
Dec  8 09:04:01.322: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 09:04:01.322: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 09:04:01.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-wrcsl ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  8 09:04:01.500: INFO: stderr: ""
Dec  8 09:04:01.500: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  8 09:04:01.500: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  8 09:04:01.500: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 09:04:01.508: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  8 09:04:11.520: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 09:04:11.520: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 09:04:11.520: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  8 09:04:11.531: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999374s
Dec  8 09:04:12.534: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.9965257s
Dec  8 09:04:13.539: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992561469s
Dec  8 09:04:14.544: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987590714s
Dec  8 09:04:15.548: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983209505s
Dec  8 09:04:16.552: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979201177s
Dec  8 09:04:17.557: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.974666041s
Dec  8 09:04:18.560: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970321743s
Dec  8 09:04:19.564: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.966586544s
Dec  8 09:04:20.568: INFO: Verifying statefulset ss doesn't scale past 3 for another 962.944619ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-wrcsl
Dec  8 09:04:21.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-wrcsl ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:04:21.729: INFO: stderr: ""
Dec  8 09:04:21.729: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 09:04:21.729: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 09:04:21.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-wrcsl ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:04:21.891: INFO: stderr: ""
Dec  8 09:04:21.891: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 09:04:21.891: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 09:04:21.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 exec --namespace=e2e-tests-statefulset-wrcsl ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  8 09:04:22.053: INFO: stderr: ""
Dec  8 09:04:22.053: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  8 09:04:22.053: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  8 09:04:22.053: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 09:04:52.069: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wrcsl
Dec  8 09:04:52.072: INFO: Scaling statefulset ss to 0
Dec  8 09:04:52.081: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 09:04:52.083: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:04:52.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wrcsl" for this suite.
Dec  8 09:04:58.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:04:58.168: INFO: namespace: e2e-tests-statefulset-wrcsl, resource: bindings, ignored listing per whitelist
Dec  8 09:04:58.191: INFO: namespace e2e-tests-statefulset-wrcsl deletion completed in 6.09550848s

• [SLOW TEST:97.675 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:04:58.191: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9s9fk A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9s9fk;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9s9fk A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9s9fk;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9s9fk.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-9s9fk.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9s9fk.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-9s9fk.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9s9fk.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 40.243.102.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.102.243.40_udp@PTR;check="$$(dig +tcp +noall +answer +search 40.243.102.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.102.243.40_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9s9fk A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9s9fk;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9s9fk A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9s9fk;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-9s9fk.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-9s9fk.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-9s9fk.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-9s9fk.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-9s9fk.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 40.243.102.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.102.243.40_udp@PTR;check="$$(dig +tcp +noall +answer +search 40.243.102.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.102.243.40_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  8 09:05:12.296: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.299: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.303: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9s9fk from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.306: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9s9fk from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.310: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.313: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.316: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.319: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.322: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.325: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.328: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.331: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.334: INFO: Unable to read 10.102.243.40_udp@PTR from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.337: INFO: Unable to read 10.102.243.40_tcp@PTR from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.341: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.344: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.346: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9s9fk from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.349: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9s9fk from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.352: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.356: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.359: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.362: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.365: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.367: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.371: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.374: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.377: INFO: Unable to read 10.102.243.40_udp@PTR from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.380: INFO: Unable to read 10.102.243.40_tcp@PTR from pod e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-564693a7-fac8-11e8-9888-1eca7d857bda)
Dec  8 09:05:12.380: INFO: Lookups using e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-9s9fk wheezy_tcp@dns-test-service.e2e-tests-dns-9s9fk wheezy_udp@dns-test-service.e2e-tests-dns-9s9fk.svc wheezy_tcp@dns-test-service.e2e-tests-dns-9s9fk.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.102.243.40_udp@PTR 10.102.243.40_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-9s9fk jessie_tcp@dns-test-service.e2e-tests-dns-9s9fk jessie_udp@dns-test-service.e2e-tests-dns-9s9fk.svc jessie_tcp@dns-test-service.e2e-tests-dns-9s9fk.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-9s9fk.svc jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-9s9fk.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.102.243.40_udp@PTR 10.102.243.40_tcp@PTR]

Dec  8 09:05:17.500: INFO: DNS probes using e2e-tests-dns-9s9fk/dns-test-564693a7-fac8-11e8-9888-1eca7d857bda succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:05:17.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-9s9fk" for this suite.
Dec  8 09:05:23.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:05:23.588: INFO: namespace: e2e-tests-dns-9s9fk, resource: bindings, ignored listing per whitelist
Dec  8 09:05:23.682: INFO: namespace e2e-tests-dns-9s9fk deletion completed in 6.120026696s

• [SLOW TEST:25.491 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:05:23.682: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  8 09:05:23.782: INFO: Waiting up to 5m0s for pod "pod-657a9fc6-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-77nzz" to be "success or failure"
Dec  8 09:05:23.788: INFO: Pod "pod-657a9fc6-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 6.180104ms
Dec  8 09:05:25.792: INFO: Pod "pod-657a9fc6-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010109189s
STEP: Saw pod success
Dec  8 09:05:25.792: INFO: Pod "pod-657a9fc6-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:05:25.796: INFO: Trying to get logs from node conformance pod pod-657a9fc6-fac8-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:05:25.816: INFO: Waiting for pod pod-657a9fc6-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:05:25.820: INFO: Pod pod-657a9fc6-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:05:25.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-77nzz" for this suite.
Dec  8 09:05:31.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:05:31.880: INFO: namespace: e2e-tests-emptydir-77nzz, resource: bindings, ignored listing per whitelist
Dec  8 09:05:31.917: INFO: namespace e2e-tests-emptydir-77nzz deletion completed in 6.09357s

• [SLOW TEST:8.235 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:05:31.918: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  8 09:05:31.980: INFO: Waiting up to 5m0s for pod "pod-6a5df948-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-tzkbv" to be "success or failure"
Dec  8 09:05:31.983: INFO: Pod "pod-6a5df948-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.217985ms
Dec  8 09:05:33.988: INFO: Pod "pod-6a5df948-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00795912s
STEP: Saw pod success
Dec  8 09:05:33.988: INFO: Pod "pod-6a5df948-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:05:33.992: INFO: Trying to get logs from node conformance pod pod-6a5df948-fac8-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:05:34.010: INFO: Waiting for pod pod-6a5df948-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:05:34.012: INFO: Pod pod-6a5df948-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:05:34.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tzkbv" for this suite.
Dec  8 09:05:40.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:05:40.064: INFO: namespace: e2e-tests-emptydir-tzkbv, resource: bindings, ignored listing per whitelist
Dec  8 09:05:40.107: INFO: namespace e2e-tests-emptydir-tzkbv deletion completed in 6.091638298s

• [SLOW TEST:8.190 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:05:40.107: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 09:05:40.178: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f40d9fe-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-5gs7s" to be "success or failure"
Dec  8 09:05:40.181: INFO: Pod "downwardapi-volume-6f40d9fe-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.209778ms
Dec  8 09:05:42.185: INFO: Pod "downwardapi-volume-6f40d9fe-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007091556s
STEP: Saw pod success
Dec  8 09:05:42.185: INFO: Pod "downwardapi-volume-6f40d9fe-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:05:42.188: INFO: Trying to get logs from node conformance pod downwardapi-volume-6f40d9fe-fac8-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 09:05:42.206: INFO: Waiting for pod downwardapi-volume-6f40d9fe-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:05:42.208: INFO: Pod downwardapi-volume-6f40d9fe-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:05:42.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5gs7s" for this suite.
Dec  8 09:05:48.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:05:48.238: INFO: namespace: e2e-tests-projected-5gs7s, resource: bindings, ignored listing per whitelist
Dec  8 09:05:48.327: INFO: namespace e2e-tests-projected-5gs7s deletion completed in 6.115757697s

• [SLOW TEST:8.220 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:05:48.327: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 09:05:48.383: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:05:52.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-th8ln" for this suite.
Dec  8 09:06:14.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:06:14.247: INFO: namespace: e2e-tests-init-container-th8ln, resource: bindings, ignored listing per whitelist
Dec  8 09:06:14.270: INFO: namespace e2e-tests-init-container-th8ln deletion completed in 22.10060714s

• [SLOW TEST:25.943 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:06:14.271: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-839df784-fac8-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:06:14.347: INFO: Waiting up to 5m0s for pod "pod-configmaps-839e89b7-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-pk2zs" to be "success or failure"
Dec  8 09:06:14.351: INFO: Pod "pod-configmaps-839e89b7-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.845966ms
Dec  8 09:06:16.355: INFO: Pod "pod-configmaps-839e89b7-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007544871s
STEP: Saw pod success
Dec  8 09:06:16.355: INFO: Pod "pod-configmaps-839e89b7-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:06:16.358: INFO: Trying to get logs from node conformance pod pod-configmaps-839e89b7-fac8-11e8-9888-1eca7d857bda container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:06:16.376: INFO: Waiting for pod pod-configmaps-839e89b7-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:06:16.378: INFO: Pod pod-configmaps-839e89b7-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:06:16.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pk2zs" for this suite.
Dec  8 09:06:22.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:06:22.416: INFO: namespace: e2e-tests-configmap-pk2zs, resource: bindings, ignored listing per whitelist
Dec  8 09:06:22.484: INFO: namespace e2e-tests-configmap-pk2zs deletion completed in 6.100926197s

• [SLOW TEST:8.214 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:06:22.484: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-88831fe8-fac8-11e8-9888-1eca7d857bda
STEP: Creating secret with name s-test-opt-upd-88832065-fac8-11e8-9888-1eca7d857bda
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-88831fe8-fac8-11e8-9888-1eca7d857bda
STEP: Updating secret s-test-opt-upd-88832065-fac8-11e8-9888-1eca7d857bda
STEP: Creating secret with name s-test-opt-create-8883208f-fac8-11e8-9888-1eca7d857bda
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:06:26.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gpgr8" for this suite.
Dec  8 09:06:48.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:06:48.738: INFO: namespace: e2e-tests-secrets-gpgr8, resource: bindings, ignored listing per whitelist
Dec  8 09:06:48.748: INFO: namespace e2e-tests-secrets-gpgr8 deletion completed in 22.091386683s

• [SLOW TEST:26.264 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:06:48.748: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 09:06:48.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-smm5l'
Dec  8 09:06:49.169: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  8 09:06:49.169: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  8 09:06:49.177: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-j7lq9]
Dec  8 09:06:49.177: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-j7lq9" in namespace "e2e-tests-kubectl-smm5l" to be "running and ready"
Dec  8 09:06:49.179: INFO: Pod "e2e-test-nginx-rc-j7lq9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015266ms
Dec  8 09:06:51.183: INFO: Pod "e2e-test-nginx-rc-j7lq9": Phase="Running", Reason="", readiness=true. Elapsed: 2.005345936s
Dec  8 09:06:51.183: INFO: Pod "e2e-test-nginx-rc-j7lq9" satisfied condition "running and ready"
Dec  8 09:06:51.183: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-j7lq9]
Dec  8 09:06:51.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-smm5l'
Dec  8 09:06:51.290: INFO: stderr: ""
Dec  8 09:06:51.290: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Dec  8 09:06:51.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-smm5l'
Dec  8 09:06:51.380: INFO: stderr: ""
Dec  8 09:06:51.380: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:06:51.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-smm5l" for this suite.
Dec  8 09:07:13.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:07:13.468: INFO: namespace: e2e-tests-kubectl-smm5l, resource: bindings, ignored listing per whitelist
Dec  8 09:07:13.484: INFO: namespace e2e-tests-kubectl-smm5l deletion completed in 22.097885787s

• [SLOW TEST:24.735 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:07:13.484: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a6e8b422-fac8-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:07:13.555: INFO: Waiting up to 5m0s for pod "pod-secrets-a6e919aa-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-g9nlz" to be "success or failure"
Dec  8 09:07:13.563: INFO: Pod "pod-secrets-a6e919aa-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 7.523878ms
Dec  8 09:07:15.566: INFO: Pod "pod-secrets-a6e919aa-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011078099s
STEP: Saw pod success
Dec  8 09:07:15.566: INFO: Pod "pod-secrets-a6e919aa-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:07:15.569: INFO: Trying to get logs from node conformance pod pod-secrets-a6e919aa-fac8-11e8-9888-1eca7d857bda container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:07:15.585: INFO: Waiting for pod pod-secrets-a6e919aa-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:07:15.588: INFO: Pod pod-secrets-a6e919aa-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:07:15.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g9nlz" for this suite.
Dec  8 09:07:21.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:07:21.657: INFO: namespace: e2e-tests-secrets-g9nlz, resource: bindings, ignored listing per whitelist
Dec  8 09:07:21.691: INFO: namespace e2e-tests-secrets-g9nlz deletion completed in 6.099945767s

• [SLOW TEST:8.207 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:07:21.691: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:07:23.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-sgv8q" for this suite.
Dec  8 09:08:13.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:08:13.859: INFO: namespace: e2e-tests-kubelet-test-sgv8q, resource: bindings, ignored listing per whitelist
Dec  8 09:08:13.871: INFO: namespace e2e-tests-kubelet-test-sgv8q deletion completed in 50.092878825s

• [SLOW TEST:52.179 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:08:13.871: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  8 09:08:13.936: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-866404302 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:08:14.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wb297" for this suite.
Dec  8 09:08:20.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:08:20.036: INFO: namespace: e2e-tests-kubectl-wb297, resource: bindings, ignored listing per whitelist
Dec  8 09:08:20.106: INFO: namespace e2e-tests-kubectl-wb297 deletion completed in 6.088844532s

• [SLOW TEST:6.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:08:20.106: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  8 09:08:20.173: INFO: Waiting up to 5m0s for pod "pod-ce9e54c6-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-dfbcb" to be "success or failure"
Dec  8 09:08:20.176: INFO: Pod "pod-ce9e54c6-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.537025ms
Dec  8 09:08:22.179: INFO: Pod "pod-ce9e54c6-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005868297s
STEP: Saw pod success
Dec  8 09:08:22.179: INFO: Pod "pod-ce9e54c6-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:08:22.182: INFO: Trying to get logs from node conformance pod pod-ce9e54c6-fac8-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:08:22.200: INFO: Waiting for pod pod-ce9e54c6-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:08:22.202: INFO: Pod pod-ce9e54c6-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:08:22.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dfbcb" for this suite.
Dec  8 09:08:28.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:08:28.270: INFO: namespace: e2e-tests-emptydir-dfbcb, resource: bindings, ignored listing per whitelist
Dec  8 09:08:28.307: INFO: namespace e2e-tests-emptydir-dfbcb deletion completed in 6.102052883s

• [SLOW TEST:8.201 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:08:28.308: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  8 09:08:28.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 --namespace=e2e-tests-kubectl-jmpwv run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  8 09:08:29.766: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  8 09:08:29.766: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:08:31.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jmpwv" for this suite.
Dec  8 09:08:37.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:08:37.848: INFO: namespace: e2e-tests-kubectl-jmpwv, resource: bindings, ignored listing per whitelist
Dec  8 09:08:37.866: INFO: namespace e2e-tests-kubectl-jmpwv deletion completed in 6.090814274s

• [SLOW TEST:9.558 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:08:37.866: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 09:08:40.457: INFO: Successfully updated pod "annotationupdated93346fe-fac8-11e8-9888-1eca7d857bda"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:08:44.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cwdg6" for this suite.
Dec  8 09:09:06.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:09:06.573: INFO: namespace: e2e-tests-projected-cwdg6, resource: bindings, ignored listing per whitelist
Dec  8 09:09:06.577: INFO: namespace e2e-tests-projected-cwdg6 deletion completed in 22.087905067s

• [SLOW TEST:28.711 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:09:06.577: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  8 09:09:06.661: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-h7dzm,SelfLink:/api/v1/namespaces/e2e-tests-watch-h7dzm/configmaps/e2e-watch-test-resource-version,UID:ea5141dd-fac8-11e8-93eb-42010a840002,ResourceVersion:7615,Generation:0,CreationTimestamp:2018-12-08 09:09:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 09:09:06.661: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-h7dzm,SelfLink:/api/v1/namespaces/e2e-tests-watch-h7dzm/configmaps/e2e-watch-test-resource-version,UID:ea5141dd-fac8-11e8-93eb-42010a840002,ResourceVersion:7616,Generation:0,CreationTimestamp:2018-12-08 09:09:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:09:06.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-h7dzm" for this suite.
Dec  8 09:09:12.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:09:12.725: INFO: namespace: e2e-tests-watch-h7dzm, resource: bindings, ignored listing per whitelist
Dec  8 09:09:12.748: INFO: namespace e2e-tests-watch-h7dzm deletion completed in 6.084217826s

• [SLOW TEST:6.171 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:09:12.748: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  8 09:09:15.350: INFO: Successfully updated pod "pod-update-ee0117cc-fac8-11e8-9888-1eca7d857bda"
STEP: verifying the updated pod is in kubernetes
Dec  8 09:09:15.357: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:09:15.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nvsbs" for this suite.
Dec  8 09:09:37.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:09:37.382: INFO: namespace: e2e-tests-pods-nvsbs, resource: bindings, ignored listing per whitelist
Dec  8 09:09:37.455: INFO: namespace e2e-tests-pods-nvsbs deletion completed in 22.09557056s

• [SLOW TEST:24.707 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:09:37.456: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  8 09:09:37.520: INFO: Waiting up to 5m0s for pod "pod-fcb868aa-fac8-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-5tvwq" to be "success or failure"
Dec  8 09:09:37.522: INFO: Pod "pod-fcb868aa-fac8-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.789766ms
Dec  8 09:09:39.526: INFO: Pod "pod-fcb868aa-fac8-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006309416s
STEP: Saw pod success
Dec  8 09:09:39.526: INFO: Pod "pod-fcb868aa-fac8-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:09:39.529: INFO: Trying to get logs from node conformance pod pod-fcb868aa-fac8-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:09:39.546: INFO: Waiting for pod pod-fcb868aa-fac8-11e8-9888-1eca7d857bda to disappear
Dec  8 09:09:39.550: INFO: Pod pod-fcb868aa-fac8-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:09:39.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5tvwq" for this suite.
Dec  8 09:09:45.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:09:45.575: INFO: namespace: e2e-tests-emptydir-5tvwq, resource: bindings, ignored listing per whitelist
Dec  8 09:09:45.648: INFO: namespace e2e-tests-emptydir-5tvwq deletion completed in 6.094408335s

• [SLOW TEST:8.192 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:09:45.648: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-019af66d-fac9-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:09:45.719: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-019b7164-fac9-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-gv9v2" to be "success or failure"
Dec  8 09:09:45.722: INFO: Pod "pod-projected-secrets-019b7164-fac9-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.640998ms
Dec  8 09:09:47.725: INFO: Pod "pod-projected-secrets-019b7164-fac9-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006590647s
STEP: Saw pod success
Dec  8 09:09:47.726: INFO: Pod "pod-projected-secrets-019b7164-fac9-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:09:47.729: INFO: Trying to get logs from node conformance pod pod-projected-secrets-019b7164-fac9-11e8-9888-1eca7d857bda container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:09:47.746: INFO: Waiting for pod pod-projected-secrets-019b7164-fac9-11e8-9888-1eca7d857bda to disappear
Dec  8 09:09:47.749: INFO: Pod pod-projected-secrets-019b7164-fac9-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:09:47.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gv9v2" for this suite.
Dec  8 09:09:53.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:09:53.770: INFO: namespace: e2e-tests-projected-gv9v2, resource: bindings, ignored listing per whitelist
Dec  8 09:09:53.837: INFO: namespace e2e-tests-projected-gv9v2 deletion completed in 6.085420662s

• [SLOW TEST:8.190 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:09:53.838: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  8 09:09:53.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:54.096: INFO: stderr: ""
Dec  8 09:09:54.096: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 09:09:54.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:54.197: INFO: stderr: ""
Dec  8 09:09:54.197: INFO: stdout: "update-demo-nautilus-l7b4n update-demo-nautilus-s54m2 "
Dec  8 09:09:54.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-l7b4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:54.295: INFO: stderr: ""
Dec  8 09:09:54.296: INFO: stdout: ""
Dec  8 09:09:54.296: INFO: update-demo-nautilus-l7b4n is created but not running
Dec  8 09:09:59.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:59.383: INFO: stderr: ""
Dec  8 09:09:59.383: INFO: stdout: "update-demo-nautilus-l7b4n update-demo-nautilus-s54m2 "
Dec  8 09:09:59.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-l7b4n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:59.467: INFO: stderr: ""
Dec  8 09:09:59.467: INFO: stdout: "true"
Dec  8 09:09:59.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-l7b4n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:59.553: INFO: stderr: ""
Dec  8 09:09:59.553: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:09:59.553: INFO: validating pod update-demo-nautilus-l7b4n
Dec  8 09:09:59.557: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:09:59.557: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:09:59.557: INFO: update-demo-nautilus-l7b4n is verified up and running
Dec  8 09:09:59.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-s54m2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:59.648: INFO: stderr: ""
Dec  8 09:09:59.648: INFO: stdout: "true"
Dec  8 09:09:59.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-s54m2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:59.734: INFO: stderr: ""
Dec  8 09:09:59.734: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:09:59.734: INFO: validating pod update-demo-nautilus-s54m2
Dec  8 09:09:59.738: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:09:59.738: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:09:59.738: INFO: update-demo-nautilus-s54m2 is verified up and running
STEP: using delete to clean up resources
Dec  8 09:09:59.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:59.826: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 09:09:59.826: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  8 09:09:59.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-c875j'
Dec  8 09:09:59.934: INFO: stderr: "No resources found.\n"
Dec  8 09:09:59.934: INFO: stdout: ""
Dec  8 09:09:59.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -l name=update-demo --namespace=e2e-tests-kubectl-c875j -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 09:10:00.039: INFO: stderr: ""
Dec  8 09:10:00.039: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:10:00.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c875j" for this suite.
Dec  8 09:10:22.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:10:22.147: INFO: namespace: e2e-tests-kubectl-c875j, resource: bindings, ignored listing per whitelist
Dec  8 09:10:22.157: INFO: namespace e2e-tests-kubectl-c875j deletion completed in 22.114816391s

• [SLOW TEST:28.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:10:22.157: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1760ae8a-fac9-11e8-9888-1eca7d857bda
STEP: Creating secret with name s-test-opt-upd-1760aef6-fac9-11e8-9888-1eca7d857bda
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1760ae8a-fac9-11e8-9888-1eca7d857bda
STEP: Updating secret s-test-opt-upd-1760aef6-fac9-11e8-9888-1eca7d857bda
STEP: Creating secret with name s-test-opt-create-1760af12-fac9-11e8-9888-1eca7d857bda
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:10:26.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-89bxq" for this suite.
Dec  8 09:10:48.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:10:48.405: INFO: namespace: e2e-tests-projected-89bxq, resource: bindings, ignored listing per whitelist
Dec  8 09:10:48.447: INFO: namespace e2e-tests-projected-89bxq deletion completed in 22.085275967s

• [SLOW TEST:26.290 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:10:48.447: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-jkv28
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 09:10:48.506: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 09:11:08.552: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.32.0.6 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-jkv28 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:11:08.552: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:11:09.631: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:11:09.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-jkv28" for this suite.
Dec  8 09:11:31.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:11:31.694: INFO: namespace: e2e-tests-pod-network-test-jkv28, resource: bindings, ignored listing per whitelist
Dec  8 09:11:31.721: INFO: namespace e2e-tests-pod-network-test-jkv28 deletion completed in 22.086644614s

• [SLOW TEST:43.274 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:11:31.721: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-40d4300a-fac9-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:11:31.791: INFO: Waiting up to 5m0s for pod "pod-configmaps-40d4b5c2-fac9-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-vgx5n" to be "success or failure"
Dec  8 09:11:31.795: INFO: Pod "pod-configmaps-40d4b5c2-fac9-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 4.066116ms
Dec  8 09:11:33.798: INFO: Pod "pod-configmaps-40d4b5c2-fac9-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007454102s
STEP: Saw pod success
Dec  8 09:11:33.798: INFO: Pod "pod-configmaps-40d4b5c2-fac9-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:11:33.801: INFO: Trying to get logs from node conformance pod pod-configmaps-40d4b5c2-fac9-11e8-9888-1eca7d857bda container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:11:33.821: INFO: Waiting for pod pod-configmaps-40d4b5c2-fac9-11e8-9888-1eca7d857bda to disappear
Dec  8 09:11:33.827: INFO: Pod pod-configmaps-40d4b5c2-fac9-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:11:33.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vgx5n" for this suite.
Dec  8 09:11:39.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:11:39.892: INFO: namespace: e2e-tests-configmap-vgx5n, resource: bindings, ignored listing per whitelist
Dec  8 09:11:39.920: INFO: namespace e2e-tests-configmap-vgx5n deletion completed in 6.089396601s

• [SLOW TEST:8.198 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:11:39.920: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-6ng5p/configmap-test-45b67c1c-fac9-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:11:39.984: INFO: Waiting up to 5m0s for pod "pod-configmaps-45b6ea3b-fac9-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-6ng5p" to be "success or failure"
Dec  8 09:11:39.986: INFO: Pod "pod-configmaps-45b6ea3b-fac9-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.626179ms
Dec  8 09:11:41.990: INFO: Pod "pod-configmaps-45b6ea3b-fac9-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006153218s
STEP: Saw pod success
Dec  8 09:11:41.990: INFO: Pod "pod-configmaps-45b6ea3b-fac9-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:11:41.993: INFO: Trying to get logs from node conformance pod pod-configmaps-45b6ea3b-fac9-11e8-9888-1eca7d857bda container env-test: <nil>
STEP: delete the pod
Dec  8 09:11:42.009: INFO: Waiting for pod pod-configmaps-45b6ea3b-fac9-11e8-9888-1eca7d857bda to disappear
Dec  8 09:11:42.011: INFO: Pod pod-configmaps-45b6ea3b-fac9-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:11:42.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-6ng5p" for this suite.
Dec  8 09:11:48.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:11:48.102: INFO: namespace: e2e-tests-configmap-6ng5p, resource: bindings, ignored listing per whitelist
Dec  8 09:11:48.111: INFO: namespace e2e-tests-configmap-6ng5p deletion completed in 6.097198029s

• [SLOW TEST:8.191 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:11:48.111: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  8 09:11:48.349: INFO: Pod name wrapped-volume-race-4ab24489-fac9-11e8-9888-1eca7d857bda: Found 0 pods out of 5
Dec  8 09:11:53.355: INFO: Pod name wrapped-volume-race-4ab24489-fac9-11e8-9888-1eca7d857bda: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4ab24489-fac9-11e8-9888-1eca7d857bda in namespace e2e-tests-emptydir-wrapper-6bhdp, will wait for the garbage collector to delete the pods
Dec  8 09:12:03.441: INFO: Deleting ReplicationController wrapped-volume-race-4ab24489-fac9-11e8-9888-1eca7d857bda took: 16.219948ms
Dec  8 09:12:03.541: INFO: Terminating ReplicationController wrapped-volume-race-4ab24489-fac9-11e8-9888-1eca7d857bda pods took: 100.283977ms
STEP: Creating RC which spawns configmap-volume pods
Dec  8 09:12:42.356: INFO: Pod name wrapped-volume-race-6ae2e05a-fac9-11e8-9888-1eca7d857bda: Found 0 pods out of 5
Dec  8 09:12:47.361: INFO: Pod name wrapped-volume-race-6ae2e05a-fac9-11e8-9888-1eca7d857bda: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6ae2e05a-fac9-11e8-9888-1eca7d857bda in namespace e2e-tests-emptydir-wrapper-6bhdp, will wait for the garbage collector to delete the pods
Dec  8 09:12:57.444: INFO: Deleting ReplicationController wrapped-volume-race-6ae2e05a-fac9-11e8-9888-1eca7d857bda took: 7.180176ms
Dec  8 09:12:57.545: INFO: Terminating ReplicationController wrapped-volume-race-6ae2e05a-fac9-11e8-9888-1eca7d857bda pods took: 100.304516ms
STEP: Creating RC which spawns configmap-volume pods
Dec  8 09:13:41.361: INFO: Pod name wrapped-volume-race-8e0e0cce-fac9-11e8-9888-1eca7d857bda: Found 0 pods out of 5
Dec  8 09:13:46.366: INFO: Pod name wrapped-volume-race-8e0e0cce-fac9-11e8-9888-1eca7d857bda: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8e0e0cce-fac9-11e8-9888-1eca7d857bda in namespace e2e-tests-emptydir-wrapper-6bhdp, will wait for the garbage collector to delete the pods
Dec  8 09:13:58.452: INFO: Deleting ReplicationController wrapped-volume-race-8e0e0cce-fac9-11e8-9888-1eca7d857bda took: 6.618213ms
Dec  8 09:13:58.552: INFO: Terminating ReplicationController wrapped-volume-race-8e0e0cce-fac9-11e8-9888-1eca7d857bda pods took: 100.410361ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:14:41.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-6bhdp" for this suite.
Dec  8 09:14:47.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:14:47.655: INFO: namespace: e2e-tests-emptydir-wrapper-6bhdp, resource: bindings, ignored listing per whitelist
Dec  8 09:14:47.701: INFO: namespace e2e-tests-emptydir-wrapper-6bhdp deletion completed in 6.109134461s

• [SLOW TEST:179.590 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:14:47.701: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 09:14:47.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lkbc2'
Dec  8 09:14:47.869: INFO: stderr: ""
Dec  8 09:14:47.869: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  8 09:14:52.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lkbc2 -o json'
Dec  8 09:14:53.006: INFO: stderr: ""
Dec  8 09:14:53.006: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-08T09:14:47Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-lkbc2\",\n        \"resourceVersion\": \"9179\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-lkbc2/pods/e2e-test-nginx-pod\",\n        \"uid\": \"b5b34482-fac9-11e8-93eb-42010a840002\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-wcrmc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"conformance\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-wcrmc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-wcrmc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T09:14:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T09:14:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T09:14:49Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-08T09:14:47Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://0e7cab5e40770766dc7b7a782324740ac1604259c25c702e984a7be79f928256\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-08T09:14:48Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.132.0.2\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.32.0.6\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-08T09:14:47Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  8 09:14:53.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 replace -f - --namespace=e2e-tests-kubectl-lkbc2'
Dec  8 09:14:53.196: INFO: stderr: ""
Dec  8 09:14:53.197: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Dec  8 09:14:53.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-lkbc2'
Dec  8 09:14:56.302: INFO: stderr: ""
Dec  8 09:14:56.302: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:14:56.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lkbc2" for this suite.
Dec  8 09:15:02.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:15:02.405: INFO: namespace: e2e-tests-kubectl-lkbc2, resource: bindings, ignored listing per whitelist
Dec  8 09:15:02.411: INFO: namespace e2e-tests-kubectl-lkbc2 deletion completed in 6.105295321s

• [SLOW TEST:14.710 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:15:02.412: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-r96z
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 09:15:02.488: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-r96z" in namespace "e2e-tests-subpath-gn7bn" to be "success or failure"
Dec  8 09:15:02.491: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.865821ms
Dec  8 09:15:04.495: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006510737s
Dec  8 09:15:06.498: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 4.010245174s
Dec  8 09:15:08.502: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 6.013723789s
Dec  8 09:15:10.506: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 8.017314866s
Dec  8 09:15:12.509: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 10.020723619s
Dec  8 09:15:14.513: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 12.02449865s
Dec  8 09:15:16.516: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 14.027857279s
Dec  8 09:15:18.520: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 16.031540156s
Dec  8 09:15:20.523: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 18.034836988s
Dec  8 09:15:22.527: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 20.038336349s
Dec  8 09:15:24.530: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Running", Reason="", readiness=false. Elapsed: 22.042152064s
Dec  8 09:15:26.534: INFO: Pod "pod-subpath-test-downwardapi-r96z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046020945s
STEP: Saw pod success
Dec  8 09:15:26.534: INFO: Pod "pod-subpath-test-downwardapi-r96z" satisfied condition "success or failure"
Dec  8 09:15:26.538: INFO: Trying to get logs from node conformance pod pod-subpath-test-downwardapi-r96z container test-container-subpath-downwardapi-r96z: <nil>
STEP: delete the pod
Dec  8 09:15:26.563: INFO: Waiting for pod pod-subpath-test-downwardapi-r96z to disappear
Dec  8 09:15:26.571: INFO: Pod pod-subpath-test-downwardapi-r96z no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-r96z
Dec  8 09:15:26.571: INFO: Deleting pod "pod-subpath-test-downwardapi-r96z" in namespace "e2e-tests-subpath-gn7bn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:15:26.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gn7bn" for this suite.
Dec  8 09:15:32.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:15:32.680: INFO: namespace: e2e-tests-subpath-gn7bn, resource: bindings, ignored listing per whitelist
Dec  8 09:15:32.691: INFO: namespace e2e-tests-subpath-gn7bn deletion completed in 6.112061747s

• [SLOW TEST:30.279 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:15:32.691: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d075d0ba-fac9-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:15:32.765: INFO: Waiting up to 5m0s for pod "pod-secrets-d0766159-fac9-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-g6pxx" to be "success or failure"
Dec  8 09:15:32.767: INFO: Pod "pod-secrets-d0766159-fac9-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.383703ms
Dec  8 09:15:34.770: INFO: Pod "pod-secrets-d0766159-fac9-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005693353s
STEP: Saw pod success
Dec  8 09:15:34.770: INFO: Pod "pod-secrets-d0766159-fac9-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:15:34.773: INFO: Trying to get logs from node conformance pod pod-secrets-d0766159-fac9-11e8-9888-1eca7d857bda container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:15:34.790: INFO: Waiting for pod pod-secrets-d0766159-fac9-11e8-9888-1eca7d857bda to disappear
Dec  8 09:15:34.793: INFO: Pod pod-secrets-d0766159-fac9-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:15:34.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g6pxx" for this suite.
Dec  8 09:15:40.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:15:40.893: INFO: namespace: e2e-tests-secrets-g6pxx, resource: bindings, ignored listing per whitelist
Dec  8 09:15:40.893: INFO: namespace e2e-tests-secrets-g6pxx deletion completed in 6.096181782s

• [SLOW TEST:8.202 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:15:40.893: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 09:15:40.952: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:15:43.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-pr6n2" for this suite.
Dec  8 09:15:49.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:15:49.943: INFO: namespace: e2e-tests-init-container-pr6n2, resource: bindings, ignored listing per whitelist
Dec  8 09:15:49.997: INFO: namespace e2e-tests-init-container-pr6n2 deletion completed in 6.115734635s

• [SLOW TEST:9.104 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:15:49.997: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-h88sn
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-h88sn
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-h88sn
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-h88sn
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-h88sn
Dec  8 09:15:54.109: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-h88sn, name: ss-0, uid: dcd5a9ad-fac9-11e8-93eb-42010a840002, status phase: Failed. Waiting for statefulset controller to delete.
Dec  8 09:15:54.111: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-h88sn, name: ss-0, uid: dcd5a9ad-fac9-11e8-93eb-42010a840002, status phase: Failed. Waiting for statefulset controller to delete.
Dec  8 09:15:54.113: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-h88sn
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-h88sn
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-h88sn and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  8 09:15:56.129: INFO: Deleting all statefulset in ns e2e-tests-statefulset-h88sn
Dec  8 09:15:56.132: INFO: Scaling statefulset ss to 0
Dec  8 09:16:06.145: INFO: Waiting for statefulset status.replicas updated to 0
Dec  8 09:16:06.148: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:16:06.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-h88sn" for this suite.
Dec  8 09:16:12.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:16:12.202: INFO: namespace: e2e-tests-statefulset-h88sn, resource: bindings, ignored listing per whitelist
Dec  8 09:16:12.250: INFO: namespace e2e-tests-statefulset-h88sn deletion completed in 6.089305624s

• [SLOW TEST:22.253 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:16:12.251: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  8 09:16:16.338: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.338: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.411: INFO: Exec stderr: ""
Dec  8 09:16:16.411: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.411: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.482: INFO: Exec stderr: ""
Dec  8 09:16:16.482: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.482: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.553: INFO: Exec stderr: ""
Dec  8 09:16:16.554: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.554: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.624: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  8 09:16:16.625: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.625: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.697: INFO: Exec stderr: ""
Dec  8 09:16:16.697: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.697: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.768: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  8 09:16:16.768: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.768: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.842: INFO: Exec stderr: ""
Dec  8 09:16:16.842: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.842: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.922: INFO: Exec stderr: ""
Dec  8 09:16:16.922: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.922: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:16.992: INFO: Exec stderr: ""
Dec  8 09:16:16.992: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kfzpg PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:16:16.992: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:16:17.064: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:16:17.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-kfzpg" for this suite.
Dec  8 09:16:55.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:16:55.128: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-kfzpg, resource: bindings, ignored listing per whitelist
Dec  8 09:16:55.159: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-kfzpg deletion completed in 38.091375082s

• [SLOW TEST:42.908 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:16:55.159: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1208 09:17:01.240548      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 09:17:01.240: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:17:01.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qnwxr" for this suite.
Dec  8 09:17:07.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:17:07.286: INFO: namespace: e2e-tests-gc-qnwxr, resource: bindings, ignored listing per whitelist
Dec  8 09:17:07.312: INFO: namespace e2e-tests-gc-qnwxr deletion completed in 6.070092021s

• [SLOW TEST:12.153 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:17:07.313: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-08da2fc7-faca-11e8-9888-1eca7d857bda
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:17:09.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vbskm" for this suite.
Dec  8 09:17:31.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:17:31.425: INFO: namespace: e2e-tests-configmap-vbskm, resource: bindings, ignored listing per whitelist
Dec  8 09:17:31.495: INFO: namespace e2e-tests-configmap-vbskm deletion completed in 22.095272198s

• [SLOW TEST:24.183 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:17:31.496: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-17453314-faca-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:17:31.563: INFO: Waiting up to 5m0s for pod "pod-secrets-1745b125-faca-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-x2778" to be "success or failure"
Dec  8 09:17:31.566: INFO: Pod "pod-secrets-1745b125-faca-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.489762ms
Dec  8 09:17:33.570: INFO: Pod "pod-secrets-1745b125-faca-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006288277s
STEP: Saw pod success
Dec  8 09:17:33.570: INFO: Pod "pod-secrets-1745b125-faca-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:17:33.573: INFO: Trying to get logs from node conformance pod pod-secrets-1745b125-faca-11e8-9888-1eca7d857bda container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:17:33.591: INFO: Waiting for pod pod-secrets-1745b125-faca-11e8-9888-1eca7d857bda to disappear
Dec  8 09:17:33.593: INFO: Pod pod-secrets-1745b125-faca-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:17:33.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x2778" for this suite.
Dec  8 09:17:39.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:17:39.673: INFO: namespace: e2e-tests-secrets-x2778, resource: bindings, ignored listing per whitelist
Dec  8 09:17:39.694: INFO: namespace e2e-tests-secrets-x2778 deletion completed in 6.098852591s

• [SLOW TEST:8.199 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:17:39.694: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  8 09:17:48.780: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:17:49.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-wd8bb" for this suite.
Dec  8 09:18:11.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:18:11.879: INFO: namespace: e2e-tests-replicaset-wd8bb, resource: bindings, ignored listing per whitelist
Dec  8 09:18:11.885: INFO: namespace e2e-tests-replicaset-wd8bb deletion completed in 22.089098947s

• [SLOW TEST:32.191 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:18:11.885: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-lzccx
Dec  8 09:18:13.956: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-lzccx
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 09:18:13.959: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:22:14.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lzccx" for this suite.
Dec  8 09:22:20.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:22:20.461: INFO: namespace: e2e-tests-container-probe-lzccx, resource: bindings, ignored listing per whitelist
Dec  8 09:22:20.504: INFO: namespace e2e-tests-container-probe-lzccx deletion completed in 6.095775809s

• [SLOW TEST:248.619 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:22:20.504: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  8 09:22:20.572: INFO: Waiting up to 5m0s for pod "client-containers-c388de76-faca-11e8-9888-1eca7d857bda" in namespace "e2e-tests-containers-mfcjb" to be "success or failure"
Dec  8 09:22:20.575: INFO: Pod "client-containers-c388de76-faca-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.961523ms
Dec  8 09:22:22.578: INFO: Pod "client-containers-c388de76-faca-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006127689s
STEP: Saw pod success
Dec  8 09:22:22.578: INFO: Pod "client-containers-c388de76-faca-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:22:22.580: INFO: Trying to get logs from node conformance pod client-containers-c388de76-faca-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:22:22.605: INFO: Waiting for pod client-containers-c388de76-faca-11e8-9888-1eca7d857bda to disappear
Dec  8 09:22:22.607: INFO: Pod client-containers-c388de76-faca-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:22:22.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mfcjb" for this suite.
Dec  8 09:22:28.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:22:28.670: INFO: namespace: e2e-tests-containers-mfcjb, resource: bindings, ignored listing per whitelist
Dec  8 09:22:28.715: INFO: namespace e2e-tests-containers-mfcjb deletion completed in 6.104964995s

• [SLOW TEST:8.210 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:22:28.715: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  8 09:22:28.778: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 09:22:28.784: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 09:22:28.787: INFO: 
Logging pods the kubelet thinks is on node conformance before test
Dec  8 09:22:28.794: INFO: etcd-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 09:22:28.795: INFO: kube-scheduler-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 09:22:28.795: INFO: sonobuoy-e2e-job-ecc19fc5f3ae4f3f from heptio-sonobuoy started at 2018-12-08 08:34:09 +0000 UTC (2 container statuses recorded)
Dec  8 09:22:28.795: INFO: 	Container e2e ready: true, restart count 0
Dec  8 09:22:28.795: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 09:22:28.795: INFO: kube-apiserver-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 09:22:28.795: INFO: kube-proxy-djdrm from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 09:22:28.795: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 09:22:28.795: INFO: kube-controller-manager-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 09:22:28.795: INFO: coredns-86c58d9df4-bph5g from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 09:22:28.795: INFO: 	Container coredns ready: true, restart count 0
Dec  8 09:22:28.795: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 08:34:04 +0000 UTC (1 container statuses recorded)
Dec  8 09:22:28.795: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  8 09:22:28.795: INFO: coredns-86c58d9df4-mz9q8 from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 09:22:28.795: INFO: 	Container coredns ready: true, restart count 0
Dec  8 09:22:28.795: INFO: weave-net-xxrrf from kube-system started at 2018-12-08 08:33:13 +0000 UTC (2 container statuses recorded)
Dec  8 09:22:28.795: INFO: 	Container weave ready: true, restart count 0
Dec  8 09:22:28.795: INFO: 	Container weave-npc ready: true, restart count 0
Dec  8 09:22:28.795: INFO: sonobuoy-systemd-logs-daemon-set-70deb288c1a64a95-8db2d from heptio-sonobuoy started at 2018-12-08 08:34:09 +0000 UTC (2 container statuses recorded)
Dec  8 09:22:28.795: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  8 09:22:28.795: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node conformance
Dec  8 09:22:28.818: INFO: Pod sonobuoy requesting resource cpu=0m on Node conformance
Dec  8 09:22:28.818: INFO: Pod sonobuoy-e2e-job-ecc19fc5f3ae4f3f requesting resource cpu=0m on Node conformance
Dec  8 09:22:28.818: INFO: Pod sonobuoy-systemd-logs-daemon-set-70deb288c1a64a95-8db2d requesting resource cpu=0m on Node conformance
Dec  8 09:22:28.818: INFO: Pod coredns-86c58d9df4-bph5g requesting resource cpu=100m on Node conformance
Dec  8 09:22:28.818: INFO: Pod coredns-86c58d9df4-mz9q8 requesting resource cpu=100m on Node conformance
Dec  8 09:22:28.818: INFO: Pod etcd-conformance requesting resource cpu=0m on Node conformance
Dec  8 09:22:28.818: INFO: Pod kube-apiserver-conformance requesting resource cpu=250m on Node conformance
Dec  8 09:22:28.818: INFO: Pod kube-controller-manager-conformance requesting resource cpu=200m on Node conformance
Dec  8 09:22:28.818: INFO: Pod kube-proxy-djdrm requesting resource cpu=0m on Node conformance
Dec  8 09:22:28.818: INFO: Pod kube-scheduler-conformance requesting resource cpu=100m on Node conformance
Dec  8 09:22:28.818: INFO: Pod weave-net-xxrrf requesting resource cpu=20m on Node conformance
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c87416d3-faca-11e8-9888-1eca7d857bda.156e5126af7140e2], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-948fh/filler-pod-c87416d3-faca-11e8-9888-1eca7d857bda to conformance]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c87416d3-faca-11e8-9888-1eca7d857bda.156e5126dc7fff53], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c87416d3-faca-11e8-9888-1eca7d857bda.156e5126e2f9cd9b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c87416d3-faca-11e8-9888-1eca7d857bda.156e5126ea494c38], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156e51272761e693], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node conformance
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:22:31.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-948fh" for this suite.
Dec  8 09:22:37.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:22:37.882: INFO: namespace: e2e-tests-sched-pred-948fh, resource: bindings, ignored listing per whitelist
Dec  8 09:22:37.954: INFO: namespace e2e-tests-sched-pred-948fh deletion completed in 6.096467357s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.240 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:22:37.955: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  8 09:22:38.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:38.465: INFO: stderr: ""
Dec  8 09:22:38.465: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 09:22:38.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:38.565: INFO: stderr: ""
Dec  8 09:22:38.565: INFO: stdout: "update-demo-nautilus-cslfk update-demo-nautilus-xkmmn "
Dec  8 09:22:38.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-cslfk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:38.651: INFO: stderr: ""
Dec  8 09:22:38.651: INFO: stdout: ""
Dec  8 09:22:38.651: INFO: update-demo-nautilus-cslfk is created but not running
Dec  8 09:22:43.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:43.742: INFO: stderr: ""
Dec  8 09:22:43.742: INFO: stdout: "update-demo-nautilus-cslfk update-demo-nautilus-xkmmn "
Dec  8 09:22:43.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-cslfk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:43.828: INFO: stderr: ""
Dec  8 09:22:43.828: INFO: stdout: "true"
Dec  8 09:22:43.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-cslfk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:43.915: INFO: stderr: ""
Dec  8 09:22:43.915: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:22:43.915: INFO: validating pod update-demo-nautilus-cslfk
Dec  8 09:22:43.919: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:22:43.919: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:22:43.919: INFO: update-demo-nautilus-cslfk is verified up and running
Dec  8 09:22:43.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-xkmmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:44.004: INFO: stderr: ""
Dec  8 09:22:44.004: INFO: stdout: "true"
Dec  8 09:22:44.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-xkmmn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:44.090: INFO: stderr: ""
Dec  8 09:22:44.091: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:22:44.091: INFO: validating pod update-demo-nautilus-xkmmn
Dec  8 09:22:44.095: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:22:44.095: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:22:44.095: INFO: update-demo-nautilus-xkmmn is verified up and running
STEP: scaling down the replication controller
Dec  8 09:22:44.098: INFO: scanned /root for discovery docs: <nil>
Dec  8 09:22:44.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:45.225: INFO: stderr: ""
Dec  8 09:22:45.225: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 09:22:45.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:45.315: INFO: stderr: ""
Dec  8 09:22:45.315: INFO: stdout: "update-demo-nautilus-cslfk update-demo-nautilus-xkmmn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  8 09:22:50.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:50.404: INFO: stderr: ""
Dec  8 09:22:50.404: INFO: stdout: "update-demo-nautilus-xkmmn "
Dec  8 09:22:50.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-xkmmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:50.489: INFO: stderr: ""
Dec  8 09:22:50.489: INFO: stdout: "true"
Dec  8 09:22:50.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-xkmmn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:50.573: INFO: stderr: ""
Dec  8 09:22:50.573: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:22:50.573: INFO: validating pod update-demo-nautilus-xkmmn
Dec  8 09:22:50.576: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:22:50.576: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:22:50.576: INFO: update-demo-nautilus-xkmmn is verified up and running
STEP: scaling up the replication controller
Dec  8 09:22:50.579: INFO: scanned /root for discovery docs: <nil>
Dec  8 09:22:50.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:51.688: INFO: stderr: ""
Dec  8 09:22:51.688: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 09:22:51.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:51.779: INFO: stderr: ""
Dec  8 09:22:51.780: INFO: stdout: "update-demo-nautilus-6fmxx update-demo-nautilus-xkmmn "
Dec  8 09:22:51.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-6fmxx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:51.865: INFO: stderr: ""
Dec  8 09:22:51.865: INFO: stdout: "true"
Dec  8 09:22:51.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-6fmxx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:51.952: INFO: stderr: ""
Dec  8 09:22:51.952: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:22:51.952: INFO: validating pod update-demo-nautilus-6fmxx
Dec  8 09:22:51.957: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:22:51.957: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:22:51.957: INFO: update-demo-nautilus-6fmxx is verified up and running
Dec  8 09:22:51.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-xkmmn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:52.047: INFO: stderr: ""
Dec  8 09:22:52.047: INFO: stdout: "true"
Dec  8 09:22:52.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-xkmmn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:52.135: INFO: stderr: ""
Dec  8 09:22:52.135: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:22:52.135: INFO: validating pod update-demo-nautilus-xkmmn
Dec  8 09:22:52.139: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:22:52.139: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:22:52.139: INFO: update-demo-nautilus-xkmmn is verified up and running
STEP: using delete to clean up resources
Dec  8 09:22:52.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:52.225: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 09:22:52.225: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  8 09:22:52.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-dd7vs'
Dec  8 09:22:52.320: INFO: stderr: "No resources found.\n"
Dec  8 09:22:52.320: INFO: stdout: ""
Dec  8 09:22:52.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -l name=update-demo --namespace=e2e-tests-kubectl-dd7vs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 09:22:52.413: INFO: stderr: ""
Dec  8 09:22:52.413: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:22:52.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dd7vs" for this suite.
Dec  8 09:22:58.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:22:58.512: INFO: namespace: e2e-tests-kubectl-dd7vs, resource: bindings, ignored listing per whitelist
Dec  8 09:22:58.524: INFO: namespace e2e-tests-kubectl-dd7vs deletion completed in 6.106560917s

• [SLOW TEST:20.569 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:22:58.524: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  8 09:22:58.596: INFO: Waiting up to 5m0s for pod "pod-da32ed5e-faca-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-9lp98" to be "success or failure"
Dec  8 09:22:58.598: INFO: Pod "pod-da32ed5e-faca-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 1.980385ms
Dec  8 09:23:00.602: INFO: Pod "pod-da32ed5e-faca-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005723867s
STEP: Saw pod success
Dec  8 09:23:00.602: INFO: Pod "pod-da32ed5e-faca-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:23:00.605: INFO: Trying to get logs from node conformance pod pod-da32ed5e-faca-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:23:00.622: INFO: Waiting for pod pod-da32ed5e-faca-11e8-9888-1eca7d857bda to disappear
Dec  8 09:23:00.625: INFO: Pod pod-da32ed5e-faca-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:23:00.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9lp98" for this suite.
Dec  8 09:23:06.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:23:06.721: INFO: namespace: e2e-tests-emptydir-9lp98, resource: bindings, ignored listing per whitelist
Dec  8 09:23:06.721: INFO: namespace e2e-tests-emptydir-9lp98 deletion completed in 6.091805033s

• [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:23:06.721: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 09:23:06.795: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df15fe12-faca-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-nrdrx" to be "success or failure"
Dec  8 09:23:06.798: INFO: Pod "downwardapi-volume-df15fe12-faca-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.889692ms
Dec  8 09:23:08.802: INFO: Pod "downwardapi-volume-df15fe12-faca-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006475147s
STEP: Saw pod success
Dec  8 09:23:08.802: INFO: Pod "downwardapi-volume-df15fe12-faca-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:23:08.804: INFO: Trying to get logs from node conformance pod downwardapi-volume-df15fe12-faca-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 09:23:08.821: INFO: Waiting for pod downwardapi-volume-df15fe12-faca-11e8-9888-1eca7d857bda to disappear
Dec  8 09:23:08.823: INFO: Pod downwardapi-volume-df15fe12-faca-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:23:08.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nrdrx" for this suite.
Dec  8 09:23:14.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:23:14.863: INFO: namespace: e2e-tests-projected-nrdrx, resource: bindings, ignored listing per whitelist
Dec  8 09:23:14.921: INFO: namespace e2e-tests-projected-nrdrx deletion completed in 6.094939054s

• [SLOW TEST:8.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:23:14.921: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  8 09:23:14.984: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  8 09:23:19.988: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:23:21.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-fvk4g" for this suite.
Dec  8 09:23:27.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:23:27.085: INFO: namespace: e2e-tests-replication-controller-fvk4g, resource: bindings, ignored listing per whitelist
Dec  8 09:23:27.100: INFO: namespace e2e-tests-replication-controller-fvk4g deletion completed in 6.097233535s

• [SLOW TEST:12.179 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:23:27.101: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  8 09:23:27.163: INFO: PodSpec: initContainers in spec.initContainers
Dec  8 09:24:11.908: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-eb3ad01c-faca-11e8-9888-1eca7d857bda", GenerateName:"", Namespace:"e2e-tests-init-container-dcjcl", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-dcjcl/pods/pod-init-eb3ad01c-faca-11e8-9888-1eca7d857bda", UID:"eb3b56f1-faca-11e8-93eb-42010a840002", ResourceVersion:"10765", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679857807, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"163809796"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-tc4vg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0011db6c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tc4vg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tc4vg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-tc4vg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000a56228), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001865e60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000a562b0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000a562d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000a562d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000a562dc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679857807, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679857807, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679857807, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679857807, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.132.0.2", PodIP:"10.32.0.6", StartTime:(*v1.Time)(0xc000a92340), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00021e9a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00021eaf0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://69944bb873db5e0139cc0875f80c6d6d7b045deb77782069056b474d15645166"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000a92380), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000a92360), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:24:11.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dcjcl" for this suite.
Dec  8 09:24:33.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:24:34.012: INFO: namespace: e2e-tests-init-container-dcjcl, resource: bindings, ignored listing per whitelist
Dec  8 09:24:34.012: INFO: namespace e2e-tests-init-container-dcjcl deletion completed in 22.100438709s

• [SLOW TEST:66.911 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:24:34.012: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-gqp47
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gqp47 to expose endpoints map[]
Dec  8 09:24:34.092: INFO: Get endpoints failed (2.659069ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec  8 09:24:35.096: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gqp47 exposes endpoints map[] (1.005836027s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-gqp47
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gqp47 to expose endpoints map[pod1:[100]]
Dec  8 09:24:37.119: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gqp47 exposes endpoints map[pod1:[100]] (2.016811481s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-gqp47
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gqp47 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  8 09:24:39.147: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gqp47 exposes endpoints map[pod1:[100] pod2:[101]] (2.025025735s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-gqp47
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gqp47 to expose endpoints map[pod2:[101]]
Dec  8 09:24:40.163: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gqp47 exposes endpoints map[pod2:[101]] (1.01188117s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-gqp47
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-gqp47 to expose endpoints map[]
Dec  8 09:24:40.174: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-gqp47 exposes endpoints map[] (7.043348ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:24:40.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-gqp47" for this suite.
Dec  8 09:25:02.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:25:02.291: INFO: namespace: e2e-tests-services-gqp47, resource: bindings, ignored listing per whitelist
Dec  8 09:25:02.293: INFO: namespace e2e-tests-services-gqp47 deletion completed in 22.093906807s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:28.281 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:25:02.294: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  8 09:25:02.354: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  8 09:25:02.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:02.557: INFO: stderr: ""
Dec  8 09:25:02.557: INFO: stdout: "service/redis-slave created\n"
Dec  8 09:25:02.557: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  8 09:25:02.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:02.762: INFO: stderr: ""
Dec  8 09:25:02.762: INFO: stdout: "service/redis-master created\n"
Dec  8 09:25:02.762: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  8 09:25:02.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:02.965: INFO: stderr: ""
Dec  8 09:25:02.965: INFO: stdout: "service/frontend created\n"
Dec  8 09:25:02.966: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  8 09:25:02.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:03.164: INFO: stderr: ""
Dec  8 09:25:03.164: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  8 09:25:03.165: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  8 09:25:03.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:03.372: INFO: stderr: ""
Dec  8 09:25:03.372: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  8 09:25:03.372: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  8 09:25:03.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:03.604: INFO: stderr: ""
Dec  8 09:25:03.604: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  8 09:25:03.604: INFO: Waiting for all frontend pods to be Running.
Dec  8 09:25:23.656: INFO: Waiting for frontend to serve content.
Dec  8 09:25:28.677: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec  8 09:25:33.692: INFO: Trying to add a new entry to the guestbook.
Dec  8 09:25:33.707: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  8 09:25:33.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:33.812: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 09:25:33.812: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 09:25:33.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:33.913: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 09:25:33.913: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 09:25:33.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:34.018: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 09:25:34.018: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 09:25:34.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:34.118: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 09:25:34.118: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 09:25:34.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:34.243: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 09:25:34.243: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  8 09:25:34.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2vj9t'
Dec  8 09:25:34.349: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 09:25:34.349: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:25:34.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2vj9t" for this suite.
Dec  8 09:26:12.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:26:12.417: INFO: namespace: e2e-tests-kubectl-2vj9t, resource: bindings, ignored listing per whitelist
Dec  8 09:26:12.464: INFO: namespace e2e-tests-kubectl-2vj9t deletion completed in 38.110822777s

• [SLOW TEST:70.170 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:26:12.464: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-bl6x
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 09:26:12.559: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-bl6x" in namespace "e2e-tests-subpath-4cb87" to be "success or failure"
Dec  8 09:26:12.566: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Pending", Reason="", readiness=false. Elapsed: 7.234092ms
Dec  8 09:26:14.570: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010375267s
Dec  8 09:26:16.573: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 4.013756994s
Dec  8 09:26:18.577: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 6.017793439s
Dec  8 09:26:20.580: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 8.021260433s
Dec  8 09:26:22.584: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 10.02483628s
Dec  8 09:26:24.588: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 12.028822253s
Dec  8 09:26:26.592: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 14.032569198s
Dec  8 09:26:28.596: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 16.036391881s
Dec  8 09:26:30.599: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 18.039645516s
Dec  8 09:26:32.602: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 20.043167886s
Dec  8 09:26:34.606: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Running", Reason="", readiness=false. Elapsed: 22.047114615s
Dec  8 09:26:36.610: INFO: Pod "pod-subpath-test-secret-bl6x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.050777007s
STEP: Saw pod success
Dec  8 09:26:36.610: INFO: Pod "pod-subpath-test-secret-bl6x" satisfied condition "success or failure"
Dec  8 09:26:36.613: INFO: Trying to get logs from node conformance pod pod-subpath-test-secret-bl6x container test-container-subpath-secret-bl6x: <nil>
STEP: delete the pod
Dec  8 09:26:36.635: INFO: Waiting for pod pod-subpath-test-secret-bl6x to disappear
Dec  8 09:26:36.638: INFO: Pod pod-subpath-test-secret-bl6x no longer exists
STEP: Deleting pod pod-subpath-test-secret-bl6x
Dec  8 09:26:36.638: INFO: Deleting pod "pod-subpath-test-secret-bl6x" in namespace "e2e-tests-subpath-4cb87"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:26:36.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4cb87" for this suite.
Dec  8 09:26:42.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:26:42.711: INFO: namespace: e2e-tests-subpath-4cb87, resource: bindings, ignored listing per whitelist
Dec  8 09:26:42.743: INFO: namespace e2e-tests-subpath-4cb87 deletion completed in 6.098874521s

• [SLOW TEST:30.279 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:26:42.743: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-5fd828dd-facb-11e8-9888-1eca7d857bda
STEP: Creating configMap with name cm-test-opt-upd-5fd82930-facb-11e8-9888-1eca7d857bda
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-5fd828dd-facb-11e8-9888-1eca7d857bda
STEP: Updating configmap cm-test-opt-upd-5fd82930-facb-11e8-9888-1eca7d857bda
STEP: Creating configMap with name cm-test-opt-create-5fd82954-facb-11e8-9888-1eca7d857bda
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:26:46.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vnd6g" for this suite.
Dec  8 09:27:08.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:27:08.983: INFO: namespace: e2e-tests-configmap-vnd6g, resource: bindings, ignored listing per whitelist
Dec  8 09:27:08.992: INFO: namespace e2e-tests-configmap-vnd6g deletion completed in 22.086342103s

• [SLOW TEST:26.249 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:27:08.992: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  8 09:29:55.097: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:29:55.100: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:29:57.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:29:57.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:29:59.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:29:59.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:01.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:01.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:03.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:03.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:05.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:05.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:07.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:07.103: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:09.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:09.103: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:11.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:11.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:13.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:13.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:15.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:15.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:17.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:17.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:19.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:19.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:21.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:21.104: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  8 09:30:23.100: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  8 09:30:23.103: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:30:23.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6dq8m" for this suite.
Dec  8 09:30:45.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:30:45.178: INFO: namespace: e2e-tests-container-lifecycle-hook-6dq8m, resource: bindings, ignored listing per whitelist
Dec  8 09:30:45.228: INFO: namespace e2e-tests-container-lifecycle-hook-6dq8m deletion completed in 22.121728812s

• [SLOW TEST:216.236 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:30:45.228: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 09:30:45.317: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f062a361-facb-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-fgzzz" to be "success or failure"
Dec  8 09:30:45.320: INFO: Pod "downwardapi-volume-f062a361-facb-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.20295ms
Dec  8 09:30:47.324: INFO: Pod "downwardapi-volume-f062a361-facb-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007423003s
STEP: Saw pod success
Dec  8 09:30:47.324: INFO: Pod "downwardapi-volume-f062a361-facb-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:30:47.328: INFO: Trying to get logs from node conformance pod downwardapi-volume-f062a361-facb-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 09:30:47.349: INFO: Waiting for pod downwardapi-volume-f062a361-facb-11e8-9888-1eca7d857bda to disappear
Dec  8 09:30:47.354: INFO: Pod downwardapi-volume-f062a361-facb-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:30:47.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fgzzz" for this suite.
Dec  8 09:30:53.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:30:53.428: INFO: namespace: e2e-tests-downward-api-fgzzz, resource: bindings, ignored listing per whitelist
Dec  8 09:30:53.450: INFO: namespace e2e-tests-downward-api-fgzzz deletion completed in 6.091496977s

• [SLOW TEST:8.222 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:30:53.450: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-cncrg/secret-test-f5455221-facb-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:30:53.516: INFO: Waiting up to 5m0s for pod "pod-configmaps-f545cb5f-facb-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-cncrg" to be "success or failure"
Dec  8 09:30:53.518: INFO: Pod "pod-configmaps-f545cb5f-facb-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101116ms
Dec  8 09:30:55.521: INFO: Pod "pod-configmaps-f545cb5f-facb-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005684278s
STEP: Saw pod success
Dec  8 09:30:55.521: INFO: Pod "pod-configmaps-f545cb5f-facb-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:30:55.524: INFO: Trying to get logs from node conformance pod pod-configmaps-f545cb5f-facb-11e8-9888-1eca7d857bda container env-test: <nil>
STEP: delete the pod
Dec  8 09:30:55.540: INFO: Waiting for pod pod-configmaps-f545cb5f-facb-11e8-9888-1eca7d857bda to disappear
Dec  8 09:30:55.543: INFO: Pod pod-configmaps-f545cb5f-facb-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:30:55.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cncrg" for this suite.
Dec  8 09:31:01.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:31:01.573: INFO: namespace: e2e-tests-secrets-cncrg, resource: bindings, ignored listing per whitelist
Dec  8 09:31:01.632: INFO: namespace e2e-tests-secrets-cncrg deletion completed in 6.085808413s

• [SLOW TEST:8.182 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:31:01.633: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-sfgz
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 09:31:01.706: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sfgz" in namespace "e2e-tests-subpath-2t5cz" to be "success or failure"
Dec  8 09:31:01.709: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.489471ms
Dec  8 09:31:03.712: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006044481s
Dec  8 09:31:05.716: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 4.01011776s
Dec  8 09:31:07.720: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 6.013695408s
Dec  8 09:31:09.724: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 8.017424815s
Dec  8 09:31:11.727: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 10.02116516s
Dec  8 09:31:13.731: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 12.025038934s
Dec  8 09:31:15.735: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 14.029261097s
Dec  8 09:31:17.740: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 16.033620412s
Dec  8 09:31:19.744: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 18.03827275s
Dec  8 09:31:21.749: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 20.04242307s
Dec  8 09:31:23.753: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Running", Reason="", readiness=false. Elapsed: 22.046648825s
Dec  8 09:31:25.758: INFO: Pod "pod-subpath-test-configmap-sfgz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051466059s
STEP: Saw pod success
Dec  8 09:31:25.758: INFO: Pod "pod-subpath-test-configmap-sfgz" satisfied condition "success or failure"
Dec  8 09:31:25.761: INFO: Trying to get logs from node conformance pod pod-subpath-test-configmap-sfgz container test-container-subpath-configmap-sfgz: <nil>
STEP: delete the pod
Dec  8 09:31:25.793: INFO: Waiting for pod pod-subpath-test-configmap-sfgz to disappear
Dec  8 09:31:25.796: INFO: Pod pod-subpath-test-configmap-sfgz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-sfgz
Dec  8 09:31:25.796: INFO: Deleting pod "pod-subpath-test-configmap-sfgz" in namespace "e2e-tests-subpath-2t5cz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:31:25.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-2t5cz" for this suite.
Dec  8 09:31:31.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:31:31.845: INFO: namespace: e2e-tests-subpath-2t5cz, resource: bindings, ignored listing per whitelist
Dec  8 09:31:31.908: INFO: namespace e2e-tests-subpath-2t5cz deletion completed in 6.104473016s

• [SLOW TEST:30.275 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:31:31.908: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-0c33ea6d-facc-11e8-9888-1eca7d857bda
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-0c33ea6d-facc-11e8-9888-1eca7d857bda
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:31:36.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z8vb2" for this suite.
Dec  8 09:31:58.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:31:58.078: INFO: namespace: e2e-tests-configmap-z8vb2, resource: bindings, ignored listing per whitelist
Dec  8 09:31:58.133: INFO: namespace e2e-tests-configmap-z8vb2 deletion completed in 22.097948099s

• [SLOW TEST:26.225 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:31:58.133: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  8 09:32:00.222: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-1bd4f30d-facc-11e8-9888-1eca7d857bda,GenerateName:,Namespace:e2e-tests-events-zrftl,SelfLink:/api/v1/namespaces/e2e-tests-events-zrftl/pods/send-events-1bd4f30d-facc-11e8-9888-1eca7d857bda,UID:1bd57450-facc-11e8-93eb-42010a840002,ResourceVersion:11866,Generation:0,CreationTimestamp:2018-12-08 09:31:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 201326740,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mjdn7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mjdn7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-mjdn7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021eeba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021eebc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:31:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:31:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:31:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:31:58 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.6,StartTime:2018-12-08 09:31:58 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-08 09:31:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://aa1fe8d9a41cf277a48610630f1da7639f1d7354416dab1a1dfae96a05e66629}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  8 09:32:02.227: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  8 09:32:04.231: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:32:04.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-zrftl" for this suite.
Dec  8 09:32:42.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:32:42.292: INFO: namespace: e2e-tests-events-zrftl, resource: bindings, ignored listing per whitelist
Dec  8 09:32:42.344: INFO: namespace e2e-tests-events-zrftl deletion completed in 38.105307331s

• [SLOW TEST:44.211 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:32:42.344: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 09:32:42.411: INFO: Waiting up to 5m0s for pod "downwardapi-volume-362dfb6d-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-bdwnt" to be "success or failure"
Dec  8 09:32:42.413: INFO: Pod "downwardapi-volume-362dfb6d-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.169182ms
Dec  8 09:32:44.417: INFO: Pod "downwardapi-volume-362dfb6d-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00584976s
STEP: Saw pod success
Dec  8 09:32:44.417: INFO: Pod "downwardapi-volume-362dfb6d-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:32:44.420: INFO: Trying to get logs from node conformance pod downwardapi-volume-362dfb6d-facc-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 09:32:44.437: INFO: Waiting for pod downwardapi-volume-362dfb6d-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:32:44.439: INFO: Pod downwardapi-volume-362dfb6d-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:32:44.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bdwnt" for this suite.
Dec  8 09:32:50.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:32:50.520: INFO: namespace: e2e-tests-downward-api-bdwnt, resource: bindings, ignored listing per whitelist
Dec  8 09:32:50.536: INFO: namespace e2e-tests-downward-api-bdwnt deletion completed in 6.093973419s

• [SLOW TEST:8.192 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:32:50.537: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-3b0ff939-facc-11e8-9888-1eca7d857bda
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-3b0ff939-facc-11e8-9888-1eca7d857bda
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:32:54.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z8qbr" for this suite.
Dec  8 09:33:16.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:33:16.715: INFO: namespace: e2e-tests-projected-z8qbr, resource: bindings, ignored listing per whitelist
Dec  8 09:33:16.755: INFO: namespace e2e-tests-projected-z8qbr deletion completed in 22.10369987s

• [SLOW TEST:26.219 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:33:16.755: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-4ab21061-facc-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:33:16.837: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ab2be3f-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-v59cs" to be "success or failure"
Dec  8 09:33:16.841: INFO: Pod "pod-configmaps-4ab2be3f-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.784576ms
Dec  8 09:33:18.845: INFO: Pod "pod-configmaps-4ab2be3f-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007624855s
STEP: Saw pod success
Dec  8 09:33:18.845: INFO: Pod "pod-configmaps-4ab2be3f-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:33:18.848: INFO: Trying to get logs from node conformance pod pod-configmaps-4ab2be3f-facc-11e8-9888-1eca7d857bda container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:33:18.865: INFO: Waiting for pod pod-configmaps-4ab2be3f-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:33:18.867: INFO: Pod pod-configmaps-4ab2be3f-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:33:18.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v59cs" for this suite.
Dec  8 09:33:24.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:33:24.914: INFO: namespace: e2e-tests-configmap-v59cs, resource: bindings, ignored listing per whitelist
Dec  8 09:33:24.970: INFO: namespace e2e-tests-configmap-v59cs deletion completed in 6.100256951s

• [SLOW TEST:8.215 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:33:24.970: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 09:33:25.024: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  8 09:33:25.031: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  8 09:33:30.035: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 09:33:30.035: INFO: Creating deployment "test-rolling-update-deployment"
Dec  8 09:33:30.039: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  8 09:33:30.044: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  8 09:33:32.053: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  8 09:33:32.056: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 09:33:32.064: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-7vxk8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7vxk8/deployments/test-rolling-update-deployment,UID:5291f012-facc-11e8-93eb-42010a840002,ResourceVersion:12117,Generation:1,CreationTimestamp:2018-12-08 09:33:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-08 09:33:30 +0000 UTC 2018-12-08 09:33:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-08 09:33:31 +0000 UTC 2018-12-08 09:33:30 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  8 09:33:32.067: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-7vxk8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7vxk8/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:5294724f-facc-11e8-93eb-42010a840002,ResourceVersion:12108,Generation:1,CreationTimestamp:2018-12-08 09:33:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 5291f012-facc-11e8-93eb-42010a840002 0xc0005a3c87 0xc0005a3c88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  8 09:33:32.067: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  8 09:33:32.067: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-7vxk8,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7vxk8/replicasets/test-rolling-update-controller,UID:4f955b7f-facc-11e8-93eb-42010a840002,ResourceVersion:12116,Generation:2,CreationTimestamp:2018-12-08 09:33:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 5291f012-facc-11e8-93eb-42010a840002 0xc0005a3bc7 0xc0005a3bc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 09:33:32.071: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-n66qw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-n66qw,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-7vxk8,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7vxk8/pods/test-rolling-update-deployment-68b55d7bc6-n66qw,UID:529522b6-facc-11e8-93eb-42010a840002,ResourceVersion:12107,Generation:0,CreationTimestamp:2018-12-08 09:33:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 5294724f-facc-11e8-93eb-42010a840002 0xc000bef807 0xc000bef808}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-b2vmg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-b2vmg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-b2vmg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bef880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bef8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:33:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:33:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:33:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:33:30 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.7,StartTime:2018-12-08 09:33:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-08 09:33:30 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://802207e94267232da626dfd9feb8fe1df64c85ab0d7e0d0bf5d7b50505252a06}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:33:32.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7vxk8" for this suite.
Dec  8 09:33:38.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:33:38.170: INFO: namespace: e2e-tests-deployment-7vxk8, resource: bindings, ignored listing per whitelist
Dec  8 09:33:38.181: INFO: namespace e2e-tests-deployment-7vxk8 deletion completed in 6.107153316s

• [SLOW TEST:13.210 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:33:38.181: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-57768c51-facc-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:33:38.255: INFO: Waiting up to 5m0s for pod "pod-secrets-5777183d-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-6zcbp" to be "success or failure"
Dec  8 09:33:38.258: INFO: Pod "pod-secrets-5777183d-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.417396ms
Dec  8 09:33:40.261: INFO: Pod "pod-secrets-5777183d-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005870124s
STEP: Saw pod success
Dec  8 09:33:40.261: INFO: Pod "pod-secrets-5777183d-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:33:40.264: INFO: Trying to get logs from node conformance pod pod-secrets-5777183d-facc-11e8-9888-1eca7d857bda container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:33:40.281: INFO: Waiting for pod pod-secrets-5777183d-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:33:40.283: INFO: Pod pod-secrets-5777183d-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:33:40.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6zcbp" for this suite.
Dec  8 09:33:46.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:33:46.308: INFO: namespace: e2e-tests-secrets-6zcbp, resource: bindings, ignored listing per whitelist
Dec  8 09:33:46.379: INFO: namespace e2e-tests-secrets-6zcbp deletion completed in 6.093502472s

• [SLOW TEST:8.198 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:33:46.380: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5c58f4de-facc-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:33:46.451: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c597ad6-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-p75v9" to be "success or failure"
Dec  8 09:33:46.453: INFO: Pod "pod-projected-configmaps-5c597ad6-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.334445ms
Dec  8 09:33:48.456: INFO: Pod "pod-projected-configmaps-5c597ad6-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00566204s
STEP: Saw pod success
Dec  8 09:33:48.456: INFO: Pod "pod-projected-configmaps-5c597ad6-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:33:48.459: INFO: Trying to get logs from node conformance pod pod-projected-configmaps-5c597ad6-facc-11e8-9888-1eca7d857bda container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:33:48.477: INFO: Waiting for pod pod-projected-configmaps-5c597ad6-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:33:48.479: INFO: Pod pod-projected-configmaps-5c597ad6-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:33:48.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p75v9" for this suite.
Dec  8 09:33:54.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:33:54.531: INFO: namespace: e2e-tests-projected-p75v9, resource: bindings, ignored listing per whitelist
Dec  8 09:33:54.583: INFO: namespace e2e-tests-projected-p75v9 deletion completed in 6.10032985s

• [SLOW TEST:8.204 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:33:54.583: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  8 09:33:54.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 api-versions'
Dec  8 09:33:54.737: INFO: stderr: ""
Dec  8 09:33:54.737: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:33:54.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lfqgm" for this suite.
Dec  8 09:34:00.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:34:00.817: INFO: namespace: e2e-tests-kubectl-lfqgm, resource: bindings, ignored listing per whitelist
Dec  8 09:34:00.842: INFO: namespace e2e-tests-kubectl-lfqgm deletion completed in 6.101555151s

• [SLOW TEST:6.259 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:34:00.843: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 09:34:00.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64f8c7fd-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-54s2b" to be "success or failure"
Dec  8 09:34:00.920: INFO: Pod "downwardapi-volume-64f8c7fd-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1945ms
Dec  8 09:34:02.924: INFO: Pod "downwardapi-volume-64f8c7fd-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007634823s
STEP: Saw pod success
Dec  8 09:34:02.924: INFO: Pod "downwardapi-volume-64f8c7fd-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:34:02.928: INFO: Trying to get logs from node conformance pod downwardapi-volume-64f8c7fd-facc-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 09:34:02.948: INFO: Waiting for pod downwardapi-volume-64f8c7fd-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:34:02.951: INFO: Pod downwardapi-volume-64f8c7fd-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:34:02.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-54s2b" for this suite.
Dec  8 09:34:08.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:34:08.970: INFO: namespace: e2e-tests-downward-api-54s2b, resource: bindings, ignored listing per whitelist
Dec  8 09:34:09.052: INFO: namespace e2e-tests-downward-api-54s2b deletion completed in 6.097485918s

• [SLOW TEST:8.209 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:34:09.052: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:35:09.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-h6nxr" for this suite.
Dec  8 09:35:31.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:35:31.180: INFO: namespace: e2e-tests-container-probe-h6nxr, resource: bindings, ignored listing per whitelist
Dec  8 09:35:31.224: INFO: namespace e2e-tests-container-probe-h6nxr deletion completed in 22.09432116s

• [SLOW TEST:82.172 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:35:31.224: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 09:35:31.291: INFO: Waiting up to 5m0s for pod "downward-api-9ad708d0-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-qd75w" to be "success or failure"
Dec  8 09:35:31.294: INFO: Pod "downward-api-9ad708d0-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.680344ms
Dec  8 09:35:33.297: INFO: Pod "downward-api-9ad708d0-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006339521s
STEP: Saw pod success
Dec  8 09:35:33.297: INFO: Pod "downward-api-9ad708d0-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:35:33.301: INFO: Trying to get logs from node conformance pod downward-api-9ad708d0-facc-11e8-9888-1eca7d857bda container dapi-container: <nil>
STEP: delete the pod
Dec  8 09:35:33.320: INFO: Waiting for pod downward-api-9ad708d0-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:35:33.323: INFO: Pod downward-api-9ad708d0-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:35:33.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qd75w" for this suite.
Dec  8 09:35:39.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:35:39.384: INFO: namespace: e2e-tests-downward-api-qd75w, resource: bindings, ignored listing per whitelist
Dec  8 09:35:39.420: INFO: namespace e2e-tests-downward-api-qd75w deletion completed in 6.093720533s

• [SLOW TEST:8.196 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:35:39.420: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-9fb8d4ca-facc-11e8-9888-1eca7d857bda
Dec  8 09:35:39.482: INFO: Pod name my-hostname-basic-9fb8d4ca-facc-11e8-9888-1eca7d857bda: Found 0 pods out of 1
Dec  8 09:35:44.486: INFO: Pod name my-hostname-basic-9fb8d4ca-facc-11e8-9888-1eca7d857bda: Found 1 pods out of 1
Dec  8 09:35:44.486: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9fb8d4ca-facc-11e8-9888-1eca7d857bda" are running
Dec  8 09:35:44.488: INFO: Pod "my-hostname-basic-9fb8d4ca-facc-11e8-9888-1eca7d857bda-dc6xq" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 09:35:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 09:35:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 09:35:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-08 09:35:39 +0000 UTC Reason: Message:}])
Dec  8 09:35:44.489: INFO: Trying to dial the pod
Dec  8 09:35:49.498: INFO: Controller my-hostname-basic-9fb8d4ca-facc-11e8-9888-1eca7d857bda: Got expected result from replica 1 [my-hostname-basic-9fb8d4ca-facc-11e8-9888-1eca7d857bda-dc6xq]: "my-hostname-basic-9fb8d4ca-facc-11e8-9888-1eca7d857bda-dc6xq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:35:49.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-sx8bx" for this suite.
Dec  8 09:35:55.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:35:55.578: INFO: namespace: e2e-tests-replication-controller-sx8bx, resource: bindings, ignored listing per whitelist
Dec  8 09:35:55.615: INFO: namespace e2e-tests-replication-controller-sx8bx deletion completed in 6.113457066s

• [SLOW TEST:16.195 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:35:55.616: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  8 09:35:55.701: INFO: Waiting up to 5m0s for pod "var-expansion-a962ff61-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-var-expansion-fzkdf" to be "success or failure"
Dec  8 09:35:55.707: INFO: Pod "var-expansion-a962ff61-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 6.383028ms
Dec  8 09:35:57.710: INFO: Pod "var-expansion-a962ff61-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009813977s
STEP: Saw pod success
Dec  8 09:35:57.711: INFO: Pod "var-expansion-a962ff61-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:35:57.713: INFO: Trying to get logs from node conformance pod var-expansion-a962ff61-facc-11e8-9888-1eca7d857bda container dapi-container: <nil>
STEP: delete the pod
Dec  8 09:35:57.731: INFO: Waiting for pod var-expansion-a962ff61-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:35:57.734: INFO: Pod var-expansion-a962ff61-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:35:57.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-fzkdf" for this suite.
Dec  8 09:36:03.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:36:03.813: INFO: namespace: e2e-tests-var-expansion-fzkdf, resource: bindings, ignored listing per whitelist
Dec  8 09:36:03.828: INFO: namespace e2e-tests-var-expansion-fzkdf deletion completed in 6.091430288s

• [SLOW TEST:8.213 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:36:03.829: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  8 09:36:03.902: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fdzl4,SelfLink:/api/v1/namespaces/e2e-tests-watch-fdzl4/configmaps/e2e-watch-test-label-changed,UID:ae45db71-facc-11e8-93eb-42010a840002,ResourceVersion:12546,Generation:0,CreationTimestamp:2018-12-08 09:36:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 09:36:03.902: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fdzl4,SelfLink:/api/v1/namespaces/e2e-tests-watch-fdzl4/configmaps/e2e-watch-test-label-changed,UID:ae45db71-facc-11e8-93eb-42010a840002,ResourceVersion:12547,Generation:0,CreationTimestamp:2018-12-08 09:36:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  8 09:36:03.902: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fdzl4,SelfLink:/api/v1/namespaces/e2e-tests-watch-fdzl4/configmaps/e2e-watch-test-label-changed,UID:ae45db71-facc-11e8-93eb-42010a840002,ResourceVersion:12548,Generation:0,CreationTimestamp:2018-12-08 09:36:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  8 09:36:13.928: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fdzl4,SelfLink:/api/v1/namespaces/e2e-tests-watch-fdzl4/configmaps/e2e-watch-test-label-changed,UID:ae45db71-facc-11e8-93eb-42010a840002,ResourceVersion:12562,Generation:0,CreationTimestamp:2018-12-08 09:36:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 09:36:13.928: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fdzl4,SelfLink:/api/v1/namespaces/e2e-tests-watch-fdzl4/configmaps/e2e-watch-test-label-changed,UID:ae45db71-facc-11e8-93eb-42010a840002,ResourceVersion:12563,Generation:0,CreationTimestamp:2018-12-08 09:36:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  8 09:36:13.928: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-fdzl4,SelfLink:/api/v1/namespaces/e2e-tests-watch-fdzl4/configmaps/e2e-watch-test-label-changed,UID:ae45db71-facc-11e8-93eb-42010a840002,ResourceVersion:12564,Generation:0,CreationTimestamp:2018-12-08 09:36:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:36:13.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fdzl4" for this suite.
Dec  8 09:36:19.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:36:19.964: INFO: namespace: e2e-tests-watch-fdzl4, resource: bindings, ignored listing per whitelist
Dec  8 09:36:20.014: INFO: namespace e2e-tests-watch-fdzl4 deletion completed in 6.082930189s

• [SLOW TEST:16.185 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:36:20.014: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 09:36:20.080: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  8 09:36:25.084: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 09:36:25.084: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  8 09:36:27.088: INFO: Creating deployment "test-rollover-deployment"
Dec  8 09:36:27.097: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  8 09:36:29.103: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  8 09:36:29.109: INFO: Ensure that both replica sets have 1 created replica
Dec  8 09:36:29.116: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  8 09:36:29.124: INFO: Updating deployment test-rollover-deployment
Dec  8 09:36:29.124: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  8 09:36:31.132: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  8 09:36:31.139: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  8 09:36:31.144: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 09:36:31.144: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858590, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 09:36:33.153: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 09:36:33.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858590, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 09:36:35.152: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 09:36:35.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858590, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 09:36:37.152: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 09:36:37.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858590, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 09:36:39.151: INFO: all replica sets need to contain the pod-template-hash label
Dec  8 09:36:39.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858590, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679858587, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  8 09:36:41.151: INFO: 
Dec  8 09:36:41.151: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 09:36:41.161: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-qs5ql,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qs5ql/deployments/test-rollover-deployment,UID:bc1a1faa-facc-11e8-93eb-42010a840002,ResourceVersion:12676,Generation:2,CreationTimestamp:2018-12-08 09:36:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-08 09:36:27 +0000 UTC 2018-12-08 09:36:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-08 09:36:40 +0000 UTC 2018-12-08 09:36:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  8 09:36:41.165: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-qs5ql,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qs5ql/replicasets/test-rollover-deployment-6b7f9d6597,UID:bd50aa40-facc-11e8-93eb-42010a840002,ResourceVersion:12667,Generation:2,CreationTimestamp:2018-12-08 09:36:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bc1a1faa-facc-11e8-93eb-42010a840002 0xc000e91ff7 0xc000e91ff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  8 09:36:41.165: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  8 09:36:41.165: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-qs5ql,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qs5ql/replicasets/test-rollover-controller,UID:b7ebdb0d-facc-11e8-93eb-42010a840002,ResourceVersion:12675,Generation:2,CreationTimestamp:2018-12-08 09:36:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bc1a1faa-facc-11e8-93eb-42010a840002 0xc000e91e67 0xc000e91e68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 09:36:41.165: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-qs5ql,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qs5ql/replicasets/test-rollover-deployment-6586df867b,UID:bc1cd792-facc-11e8-93eb-42010a840002,ResourceVersion:12640,Generation:2,CreationTimestamp:2018-12-08 09:36:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment bc1a1faa-facc-11e8-93eb-42010a840002 0xc000e91f27 0xc000e91f28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 09:36:41.169: INFO: Pod "test-rollover-deployment-6b7f9d6597-ccnfz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-ccnfz,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-qs5ql,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qs5ql/pods/test-rollover-deployment-6b7f9d6597-ccnfz,UID:bd54b3ba-facc-11e8-93eb-42010a840002,ResourceVersion:12652,Generation:0,CreationTimestamp:2018-12-08 09:36:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 bd50aa40-facc-11e8-93eb-42010a840002 0xc001ad5f67 0xc001ad5f68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-xw9g6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xw9g6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-xw9g6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ad5fe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00158c070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:36:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:36:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:36:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:36:29 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.7,StartTime:2018-12-08 09:36:29 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-08 09:36:30 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://41858239d856d22f28cfd06bdcccb3889ec966ec4d294c7093c8bf27881f2892}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:36:41.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qs5ql" for this suite.
Dec  8 09:36:47.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:36:47.267: INFO: namespace: e2e-tests-deployment-qs5ql, resource: bindings, ignored listing per whitelist
Dec  8 09:36:47.270: INFO: namespace e2e-tests-deployment-qs5ql deletion completed in 6.097952585s

• [SLOW TEST:27.256 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:36:47.270: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c82b2563-facc-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:36:47.344: INFO: Waiting up to 5m0s for pod "pod-secrets-c82ba681-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-gvkmb" to be "success or failure"
Dec  8 09:36:47.346: INFO: Pod "pod-secrets-c82ba681-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.267739ms
Dec  8 09:36:49.350: INFO: Pod "pod-secrets-c82ba681-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005919886s
STEP: Saw pod success
Dec  8 09:36:49.350: INFO: Pod "pod-secrets-c82ba681-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:36:49.353: INFO: Trying to get logs from node conformance pod pod-secrets-c82ba681-facc-11e8-9888-1eca7d857bda container secret-env-test: <nil>
STEP: delete the pod
Dec  8 09:36:49.368: INFO: Waiting for pod pod-secrets-c82ba681-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:36:49.371: INFO: Pod pod-secrets-c82ba681-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:36:49.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gvkmb" for this suite.
Dec  8 09:36:55.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:36:55.455: INFO: namespace: e2e-tests-secrets-gvkmb, resource: bindings, ignored listing per whitelist
Dec  8 09:36:55.461: INFO: namespace e2e-tests-secrets-gvkmb deletion completed in 6.086909351s

• [SLOW TEST:8.191 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:36:55.461: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 09:36:55.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-r55vg'
Dec  8 09:36:55.866: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  8 09:36:55.866: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  8 09:36:55.875: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  8 09:36:55.879: INFO: scanned /root for discovery docs: <nil>
Dec  8 09:36:55.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-r55vg'
Dec  8 09:37:11.656: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  8 09:37:11.656: INFO: stdout: "Created e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8\nScaling up e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  8 09:37:11.656: INFO: stdout: "Created e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8\nScaling up e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  8 09:37:11.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-r55vg'
Dec  8 09:37:11.745: INFO: stderr: ""
Dec  8 09:37:11.745: INFO: stdout: "e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8-mwchk "
Dec  8 09:37:11.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8-mwchk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r55vg'
Dec  8 09:37:11.835: INFO: stderr: ""
Dec  8 09:37:11.836: INFO: stdout: "true"
Dec  8 09:37:11.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8-mwchk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r55vg'
Dec  8 09:37:11.923: INFO: stderr: ""
Dec  8 09:37:11.923: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec  8 09:37:11.923: INFO: e2e-test-nginx-rc-5d25bc3c4ab9e4e29a63605519ec94c8-mwchk is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Dec  8 09:37:11.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-r55vg'
Dec  8 09:37:12.018: INFO: stderr: ""
Dec  8 09:37:12.018: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:37:12.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r55vg" for this suite.
Dec  8 09:37:18.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:37:18.052: INFO: namespace: e2e-tests-kubectl-r55vg, resource: bindings, ignored listing per whitelist
Dec  8 09:37:18.122: INFO: namespace e2e-tests-kubectl-r55vg deletion completed in 6.101630858s

• [SLOW TEST:22.661 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:37:18.123: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 09:37:18.187: INFO: Creating deployment "test-recreate-deployment"
Dec  8 09:37:18.190: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  8 09:37:18.195: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec  8 09:37:20.201: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  8 09:37:20.204: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  8 09:37:20.209: INFO: Updating deployment test-recreate-deployment
Dec  8 09:37:20.209: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 09:37:20.255: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-llxz7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-llxz7/deployments/test-recreate-deployment,UID:da8f1899-facc-11e8-93eb-42010a840002,ResourceVersion:12912,Generation:2,CreationTimestamp:2018-12-08 09:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-08 09:37:20 +0000 UTC 2018-12-08 09:37:20 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-08 09:37:20 +0000 UTC 2018-12-08 09:37:18 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  8 09:37:20.257: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-llxz7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-llxz7/replicasets/test-recreate-deployment-697fbf54bf,UID:dbc75855-facc-11e8-93eb-42010a840002,ResourceVersion:12910,Generation:1,CreationTimestamp:2018-12-08 09:37:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment da8f1899-facc-11e8-93eb-42010a840002 0xc0028927a7 0xc0028927a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 09:37:20.257: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  8 09:37:20.257: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-llxz7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-llxz7/replicasets/test-recreate-deployment-5dfdcc846d,UID:da9051f0-facc-11e8-93eb-42010a840002,ResourceVersion:12901,Generation:2,CreationTimestamp:2018-12-08 09:37:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment da8f1899-facc-11e8-93eb-42010a840002 0xc0028926e7 0xc0028926e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 09:37:20.260: INFO: Pod "test-recreate-deployment-697fbf54bf-v48xd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-v48xd,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-llxz7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-llxz7/pods/test-recreate-deployment-697fbf54bf-v48xd,UID:dbc7bf8a-facc-11e8-93eb-42010a840002,ResourceVersion:12908,Generation:0,CreationTimestamp:2018-12-08 09:37:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf dbc75855-facc-11e8-93eb-42010a840002 0xc002600397 0xc002600398}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8rpt7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8rpt7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8rpt7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002600410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002600430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:37:20 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:37:20.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-llxz7" for this suite.
Dec  8 09:37:26.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:37:26.349: INFO: namespace: e2e-tests-deployment-llxz7, resource: bindings, ignored listing per whitelist
Dec  8 09:37:26.364: INFO: namespace e2e-tests-deployment-llxz7 deletion completed in 6.096958672s

• [SLOW TEST:8.241 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:37:26.364: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-df77af20-facc-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:37:26.433: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-df782c3f-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-nw8rt" to be "success or failure"
Dec  8 09:37:26.436: INFO: Pod "pod-projected-configmaps-df782c3f-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.519644ms
Dec  8 09:37:28.439: INFO: Pod "pod-projected-configmaps-df782c3f-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006458509s
STEP: Saw pod success
Dec  8 09:37:28.440: INFO: Pod "pod-projected-configmaps-df782c3f-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:37:28.442: INFO: Trying to get logs from node conformance pod pod-projected-configmaps-df782c3f-facc-11e8-9888-1eca7d857bda container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:37:28.465: INFO: Waiting for pod pod-projected-configmaps-df782c3f-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:37:28.469: INFO: Pod pod-projected-configmaps-df782c3f-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:37:28.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nw8rt" for this suite.
Dec  8 09:37:34.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:37:34.561: INFO: namespace: e2e-tests-projected-nw8rt, resource: bindings, ignored listing per whitelist
Dec  8 09:37:34.566: INFO: namespace e2e-tests-projected-nw8rt deletion completed in 6.092707289s

• [SLOW TEST:8.201 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:37:34.566: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-e45be4e4-facc-11e8-9888-1eca7d857bda
STEP: Creating configMap with name cm-test-opt-upd-e45be52b-facc-11e8-9888-1eca7d857bda
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e45be4e4-facc-11e8-9888-1eca7d857bda
STEP: Updating configmap cm-test-opt-upd-e45be52b-facc-11e8-9888-1eca7d857bda
STEP: Creating configMap with name cm-test-opt-create-e45be54a-facc-11e8-9888-1eca7d857bda
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:37:38.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6f99h" for this suite.
Dec  8 09:38:00.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:38:00.794: INFO: namespace: e2e-tests-projected-6f99h, resource: bindings, ignored listing per whitelist
Dec  8 09:38:00.816: INFO: namespace e2e-tests-projected-6f99h deletion completed in 22.089276349s

• [SLOW TEST:26.250 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:38:00.817: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 09:38:00.883: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f400e2f0-facc-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-m6ddk" to be "success or failure"
Dec  8 09:38:00.885: INFO: Pod "downwardapi-volume-f400e2f0-facc-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.428963ms
Dec  8 09:38:02.889: INFO: Pod "downwardapi-volume-f400e2f0-facc-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005822919s
STEP: Saw pod success
Dec  8 09:38:02.889: INFO: Pod "downwardapi-volume-f400e2f0-facc-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:38:02.892: INFO: Trying to get logs from node conformance pod downwardapi-volume-f400e2f0-facc-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 09:38:02.910: INFO: Waiting for pod downwardapi-volume-f400e2f0-facc-11e8-9888-1eca7d857bda to disappear
Dec  8 09:38:02.913: INFO: Pod downwardapi-volume-f400e2f0-facc-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:38:02.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m6ddk" for this suite.
Dec  8 09:38:08.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:38:08.940: INFO: namespace: e2e-tests-downward-api-m6ddk, resource: bindings, ignored listing per whitelist
Dec  8 09:38:09.011: INFO: namespace e2e-tests-downward-api-m6ddk deletion completed in 6.095243424s

• [SLOW TEST:8.195 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:38:09.012: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 09:38:09.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-95xhs'
Dec  8 09:38:09.164: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  8 09:38:09.164: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Dec  8 09:38:13.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-95xhs'
Dec  8 09:38:13.273: INFO: stderr: ""
Dec  8 09:38:13.273: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:38:13.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-95xhs" for this suite.
Dec  8 09:38:35.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:38:35.348: INFO: namespace: e2e-tests-kubectl-95xhs, resource: bindings, ignored listing per whitelist
Dec  8 09:38:35.369: INFO: namespace e2e-tests-kubectl-95xhs deletion completed in 22.092268698s

• [SLOW TEST:26.357 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:38:35.369: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  8 09:38:35.432: INFO: namespace e2e-tests-kubectl-crwng
Dec  8 09:38:35.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-crwng'
Dec  8 09:38:35.623: INFO: stderr: ""
Dec  8 09:38:35.623: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  8 09:38:36.627: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 09:38:36.627: INFO: Found 0 / 1
Dec  8 09:38:37.627: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 09:38:37.627: INFO: Found 1 / 1
Dec  8 09:38:37.627: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  8 09:38:37.630: INFO: Selector matched 1 pods for map[app:redis]
Dec  8 09:38:37.630: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  8 09:38:37.630: INFO: wait on redis-master startup in e2e-tests-kubectl-crwng 
Dec  8 09:38:37.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 logs redis-master-w5s2b redis-master --namespace=e2e-tests-kubectl-crwng'
Dec  8 09:38:37.727: INFO: stderr: ""
Dec  8 09:38:37.727: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Dec 09:38:36.516 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Dec 09:38:36.516 # Server started, Redis version 3.2.12\n1:M 08 Dec 09:38:36.516 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Dec 09:38:36.516 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  8 09:38:37.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-crwng'
Dec  8 09:38:37.833: INFO: stderr: ""
Dec  8 09:38:37.833: INFO: stdout: "service/rm2 exposed\n"
Dec  8 09:38:37.835: INFO: Service rm2 in namespace e2e-tests-kubectl-crwng found.
STEP: exposing service
Dec  8 09:38:39.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-crwng'
Dec  8 09:38:39.937: INFO: stderr: ""
Dec  8 09:38:39.938: INFO: stdout: "service/rm3 exposed\n"
Dec  8 09:38:39.940: INFO: Service rm3 in namespace e2e-tests-kubectl-crwng found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:38:41.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-crwng" for this suite.
Dec  8 09:39:03.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:39:04.027: INFO: namespace: e2e-tests-kubectl-crwng, resource: bindings, ignored listing per whitelist
Dec  8 09:39:04.047: INFO: namespace e2e-tests-kubectl-crwng deletion completed in 22.097915874s

• [SLOW TEST:28.678 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:39:04.047: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 09:39:04.118: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  8 09:39:09.121: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  8 09:39:09.122: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 09:39:09.137: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-gfgpr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gfgpr/deployments/test-cleanup-deployment,UID:1caf1991-facd-11e8-93eb-42010a840002,ResourceVersion:13267,Generation:1,CreationTimestamp:2018-12-08 09:39:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec  8 09:39:09.141: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec  8 09:39:09.141: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec  8 09:39:09.141: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-gfgpr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gfgpr/replicasets/test-cleanup-controller,UID:19b1d3c8-facd-11e8-93eb-42010a840002,ResourceVersion:13268,Generation:1,CreationTimestamp:2018-12-08 09:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 1caf1991-facd-11e8-93eb-42010a840002 0xc002598667 0xc002598668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  8 09:39:09.145: INFO: Pod "test-cleanup-controller-656k5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-656k5,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-gfgpr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gfgpr/pods/test-cleanup-controller-656k5,UID:19b39c6d-facd-11e8-93eb-42010a840002,ResourceVersion:13260,Generation:0,CreationTimestamp:2018-12-08 09:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 19b1d3c8-facd-11e8-93eb-42010a840002 0xc002598c47 0xc002598c48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9cq4d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9cq4d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9cq4d true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002598cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002598ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:39:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:39:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:39:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:39:04 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.6,StartTime:2018-12-08 09:39:04 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:39:05 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://0c7ca1419daac04deb06a40bfb7d4805e2e9f0c8ea58e57f9a86d7112a776179}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:39:09.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gfgpr" for this suite.
Dec  8 09:39:15.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:39:15.215: INFO: namespace: e2e-tests-deployment-gfgpr, resource: bindings, ignored listing per whitelist
Dec  8 09:39:15.241: INFO: namespace e2e-tests-deployment-gfgpr deletion completed in 6.093292795s

• [SLOW TEST:11.193 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:39:15.241: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:39:15.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-5qgqw" for this suite.
Dec  8 09:39:21.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:39:21.356: INFO: namespace: e2e-tests-kubelet-test-5qgqw, resource: bindings, ignored listing per whitelist
Dec  8 09:39:21.416: INFO: namespace e2e-tests-kubelet-test-5qgqw deletion completed in 6.086716414s

• [SLOW TEST:6.175 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:39:21.417: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 09:39:21.488: INFO: Number of nodes with available pods: 0
Dec  8 09:39:21.488: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:22.495: INFO: Number of nodes with available pods: 0
Dec  8 09:39:22.495: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:23.495: INFO: Number of nodes with available pods: 1
Dec  8 09:39:23.495: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  8 09:39:23.512: INFO: Number of nodes with available pods: 0
Dec  8 09:39:23.512: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:24.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:24.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:25.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:25.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:26.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:26.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:27.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:27.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:28.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:28.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:29.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:29.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:30.520: INFO: Number of nodes with available pods: 0
Dec  8 09:39:30.520: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:31.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:31.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:32.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:32.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:33.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:33.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:34.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:34.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:35.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:35.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:36.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:36.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:37.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:37.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:38.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:38.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:39.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:39.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:40.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:40.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:41.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:41.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:42.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:42.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:43.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:43.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:44.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:44.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:45.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:45.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:46.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:46.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:47.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:47.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:48.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:48.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:49.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:49.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:50.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:50.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:51.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:51.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:52.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:52.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:53.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:53.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:54.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:54.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:55.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:55.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:56.519: INFO: Number of nodes with available pods: 0
Dec  8 09:39:56.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:57.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:57.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:58.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:58.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:39:59.518: INFO: Number of nodes with available pods: 0
Dec  8 09:39:59.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:40:00.519: INFO: Number of nodes with available pods: 0
Dec  8 09:40:00.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:40:01.519: INFO: Number of nodes with available pods: 0
Dec  8 09:40:01.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:40:02.519: INFO: Number of nodes with available pods: 0
Dec  8 09:40:02.519: INFO: Node conformance is running more than one daemon pod
Dec  8 09:40:03.519: INFO: Number of nodes with available pods: 1
Dec  8 09:40:03.519: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-lndnr, will wait for the garbage collector to delete the pods
Dec  8 09:40:03.583: INFO: Deleting DaemonSet.extensions daemon-set took: 5.989367ms
Dec  8 09:40:03.683: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.456591ms
Dec  8 09:40:37.587: INFO: Number of nodes with available pods: 0
Dec  8 09:40:37.587: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 09:40:37.590: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-lndnr/daemonsets","resourceVersion":"13471"},"items":null}

Dec  8 09:40:37.593: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-lndnr/pods","resourceVersion":"13471"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:40:37.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-lndnr" for this suite.
Dec  8 09:40:43.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:40:43.666: INFO: namespace: e2e-tests-daemonsets-lndnr, resource: bindings, ignored listing per whitelist
Dec  8 09:40:43.692: INFO: namespace e2e-tests-daemonsets-lndnr deletion completed in 6.091110529s

• [SLOW TEST:82.275 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:40:43.692: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 09:40:46.289: INFO: Successfully updated pod "annotationupdate5515da2b-facd-11e8-9888-1eca7d857bda"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:40:50.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nm2s8" for this suite.
Dec  8 09:41:12.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:41:12.349: INFO: namespace: e2e-tests-downward-api-nm2s8, resource: bindings, ignored listing per whitelist
Dec  8 09:41:12.406: INFO: namespace e2e-tests-downward-api-nm2s8 deletion completed in 22.086758914s

• [SLOW TEST:28.714 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:41:12.407: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-4hwtm.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-4hwtm.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4hwtm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-4hwtm.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-4hwtm.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-4hwtm.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  8 09:41:14.486: INFO: Unable to read wheezy_udp@kubernetes.default from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.489: INFO: Unable to read wheezy_tcp@kubernetes.default from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.492: INFO: Unable to read wheezy_udp@kubernetes.default.svc from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.496: INFO: Unable to read wheezy_tcp@kubernetes.default.svc from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.499: INFO: Unable to read wheezy_udp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.502: INFO: Unable to read wheezy_tcp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.507: INFO: Unable to read wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-4hwtm.svc.cluster.local from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.510: INFO: Unable to read wheezy_hosts@dns-querier-1 from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.513: INFO: Unable to read wheezy_udp@PodARecord from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.516: INFO: Unable to read wheezy_tcp@PodARecord from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.519: INFO: Unable to read jessie_udp@kubernetes.default from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.522: INFO: Unable to read jessie_tcp@kubernetes.default from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.525: INFO: Unable to read jessie_udp@kubernetes.default.svc from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.528: INFO: Unable to read jessie_tcp@kubernetes.default.svc from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.530: INFO: Unable to read jessie_udp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.533: INFO: Unable to read jessie_tcp@kubernetes.default.svc.cluster.local from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.536: INFO: Unable to read jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-4hwtm.svc.cluster.local from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.539: INFO: Unable to read jessie_hosts@dns-querier-1 from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.542: INFO: Unable to read jessie_udp@PodARecord from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.544: INFO: Unable to read jessie_tcp@PodARecord from pod e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda: the server could not find the requested resource (get pods dns-test-663341f1-facd-11e8-9888-1eca7d857bda)
Dec  8 09:41:14.544: INFO: Lookups using e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda failed for: [wheezy_udp@kubernetes.default wheezy_tcp@kubernetes.default wheezy_udp@kubernetes.default.svc wheezy_tcp@kubernetes.default.svc wheezy_udp@kubernetes.default.svc.cluster.local wheezy_tcp@kubernetes.default.svc.cluster.local wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-4hwtm.svc.cluster.local wheezy_hosts@dns-querier-1 wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@kubernetes.default jessie_tcp@kubernetes.default jessie_udp@kubernetes.default.svc jessie_tcp@kubernetes.default.svc jessie_udp@kubernetes.default.svc.cluster.local jessie_tcp@kubernetes.default.svc.cluster.local jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-4hwtm.svc.cluster.local jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Dec  8 09:41:19.611: INFO: DNS probes using e2e-tests-dns-4hwtm/dns-test-663341f1-facd-11e8-9888-1eca7d857bda succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:41:19.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-4hwtm" for this suite.
Dec  8 09:41:25.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:41:25.688: INFO: namespace: e2e-tests-dns-4hwtm, resource: bindings, ignored listing per whitelist
Dec  8 09:41:25.713: INFO: namespace e2e-tests-dns-4hwtm deletion completed in 6.089328888s

• [SLOW TEST:13.307 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:41:25.714: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1208 09:41:56.303160      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 09:41:56.303: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:41:56.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jllq5" for this suite.
Dec  8 09:42:02.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:42:02.385: INFO: namespace: e2e-tests-gc-jllq5, resource: bindings, ignored listing per whitelist
Dec  8 09:42:02.411: INFO: namespace e2e-tests-gc-jllq5 deletion completed in 6.105020829s

• [SLOW TEST:36.697 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:42:02.411: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec  8 09:42:04.519: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:42:28.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-2d4ds" for this suite.
Dec  8 09:42:34.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:42:34.585: INFO: namespace: e2e-tests-namespaces-2d4ds, resource: bindings, ignored listing per whitelist
Dec  8 09:42:34.649: INFO: namespace e2e-tests-namespaces-2d4ds deletion completed in 6.088499692s
STEP: Destroying namespace "e2e-tests-nsdeletetest-xr5sd" for this suite.
Dec  8 09:42:34.652: INFO: Namespace e2e-tests-nsdeletetest-xr5sd was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-7g6qw" for this suite.
Dec  8 09:42:40.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:42:40.687: INFO: namespace: e2e-tests-nsdeletetest-7g6qw, resource: bindings, ignored listing per whitelist
Dec  8 09:42:40.742: INFO: namespace e2e-tests-nsdeletetest-7g6qw deletion completed in 6.089656655s

• [SLOW TEST:38.331 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:42:40.742: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  8 09:42:42.818: INFO: Pod pod-hostip-9ad9ffb1-facd-11e8-9888-1eca7d857bda has hostIP: 10.132.0.2
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:42:42.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-gjwdh" for this suite.
Dec  8 09:43:04.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:43:04.865: INFO: namespace: e2e-tests-pods-gjwdh, resource: bindings, ignored listing per whitelist
Dec  8 09:43:04.910: INFO: namespace e2e-tests-pods-gjwdh deletion completed in 22.088759915s

• [SLOW TEST:24.168 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:43:04.911: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a941dc76-facd-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:43:05.004: INFO: Waiting up to 5m0s for pod "pod-secrets-a946252c-facd-11e8-9888-1eca7d857bda" in namespace "e2e-tests-secrets-9j628" to be "success or failure"
Dec  8 09:43:05.008: INFO: Pod "pod-secrets-a946252c-facd-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.694152ms
Dec  8 09:43:07.011: INFO: Pod "pod-secrets-a946252c-facd-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007239853s
STEP: Saw pod success
Dec  8 09:43:07.011: INFO: Pod "pod-secrets-a946252c-facd-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:43:07.015: INFO: Trying to get logs from node conformance pod pod-secrets-a946252c-facd-11e8-9888-1eca7d857bda container secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:43:07.030: INFO: Waiting for pod pod-secrets-a946252c-facd-11e8-9888-1eca7d857bda to disappear
Dec  8 09:43:07.032: INFO: Pod pod-secrets-a946252c-facd-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:43:07.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9j628" for this suite.
Dec  8 09:43:13.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:43:13.072: INFO: namespace: e2e-tests-secrets-9j628, resource: bindings, ignored listing per whitelist
Dec  8 09:43:13.129: INFO: namespace e2e-tests-secrets-9j628 deletion completed in 6.094401016s
STEP: Destroying namespace "e2e-tests-secret-namespace-fctsn" for this suite.
Dec  8 09:43:19.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:43:19.203: INFO: namespace: e2e-tests-secret-namespace-fctsn, resource: bindings, ignored listing per whitelist
Dec  8 09:43:19.219: INFO: namespace e2e-tests-secret-namespace-fctsn deletion completed in 6.089707998s

• [SLOW TEST:14.309 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:43:19.219: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  8 09:43:19.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:19.459: INFO: stderr: ""
Dec  8 09:43:19.459: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 09:43:19.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:19.557: INFO: stderr: ""
Dec  8 09:43:19.557: INFO: stdout: "update-demo-nautilus-p8km4 update-demo-nautilus-rh9vm "
Dec  8 09:43:19.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-p8km4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:19.642: INFO: stderr: ""
Dec  8 09:43:19.642: INFO: stdout: ""
Dec  8 09:43:19.642: INFO: update-demo-nautilus-p8km4 is created but not running
Dec  8 09:43:24.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:24.729: INFO: stderr: ""
Dec  8 09:43:24.729: INFO: stdout: "update-demo-nautilus-p8km4 update-demo-nautilus-rh9vm "
Dec  8 09:43:24.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-p8km4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:24.814: INFO: stderr: ""
Dec  8 09:43:24.814: INFO: stdout: "true"
Dec  8 09:43:24.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-p8km4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:24.902: INFO: stderr: ""
Dec  8 09:43:24.902: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:43:24.902: INFO: validating pod update-demo-nautilus-p8km4
Dec  8 09:43:24.907: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:43:24.907: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:43:24.907: INFO: update-demo-nautilus-p8km4 is verified up and running
Dec  8 09:43:24.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-rh9vm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:24.995: INFO: stderr: ""
Dec  8 09:43:24.995: INFO: stdout: "true"
Dec  8 09:43:24.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-nautilus-rh9vm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:25.083: INFO: stderr: ""
Dec  8 09:43:25.083: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  8 09:43:25.083: INFO: validating pod update-demo-nautilus-rh9vm
Dec  8 09:43:25.088: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  8 09:43:25.088: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  8 09:43:25.088: INFO: update-demo-nautilus-rh9vm is verified up and running
STEP: rolling-update to new replication controller
Dec  8 09:43:25.090: INFO: scanned /root for discovery docs: <nil>
Dec  8 09:43:25.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:47.469: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  8 09:43:47.469: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  8 09:43:47.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:47.556: INFO: stderr: ""
Dec  8 09:43:47.556: INFO: stdout: "update-demo-kitten-crg24 update-demo-kitten-zqklq "
Dec  8 09:43:47.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-kitten-crg24 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:47.642: INFO: stderr: ""
Dec  8 09:43:47.642: INFO: stdout: "true"
Dec  8 09:43:47.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-kitten-crg24 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:47.728: INFO: stderr: ""
Dec  8 09:43:47.728: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  8 09:43:47.728: INFO: validating pod update-demo-kitten-crg24
Dec  8 09:43:47.733: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  8 09:43:47.733: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  8 09:43:47.734: INFO: update-demo-kitten-crg24 is verified up and running
Dec  8 09:43:47.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-kitten-zqklq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:47.821: INFO: stderr: ""
Dec  8 09:43:47.821: INFO: stdout: "true"
Dec  8 09:43:47.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods update-demo-kitten-zqklq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-cgqsb'
Dec  8 09:43:47.907: INFO: stderr: ""
Dec  8 09:43:47.907: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  8 09:43:47.907: INFO: validating pod update-demo-kitten-zqklq
Dec  8 09:43:47.912: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  8 09:43:47.912: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  8 09:43:47.913: INFO: update-demo-kitten-zqklq is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:43:47.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cgqsb" for this suite.
Dec  8 09:44:09.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:44:09.993: INFO: namespace: e2e-tests-kubectl-cgqsb, resource: bindings, ignored listing per whitelist
Dec  8 09:44:10.004: INFO: namespace e2e-tests-kubectl-cgqsb deletion completed in 22.088608997s

• [SLOW TEST:50.785 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:44:10.005: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-jk8rj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  8 09:44:10.066: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  8 09:44:28.113: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.32.0.7:8080/dial?request=hostName&protocol=udp&host=10.32.0.6&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-jk8rj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  8 09:44:28.113: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
Dec  8 09:44:28.196: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:44:28.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-jk8rj" for this suite.
Dec  8 09:44:50.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:44:50.225: INFO: namespace: e2e-tests-pod-network-test-jk8rj, resource: bindings, ignored listing per whitelist
Dec  8 09:44:50.285: INFO: namespace e2e-tests-pod-network-test-jk8rj deletion completed in 22.085496461s

• [SLOW TEST:40.281 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:44:50.286: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  8 09:44:50.353: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-a,UID:e81199ca-facd-11e8-93eb-42010a840002,ResourceVersion:14227,Generation:0,CreationTimestamp:2018-12-08 09:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 09:44:50.353: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-a,UID:e81199ca-facd-11e8-93eb-42010a840002,ResourceVersion:14227,Generation:0,CreationTimestamp:2018-12-08 09:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  8 09:45:00.359: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-a,UID:e81199ca-facd-11e8-93eb-42010a840002,ResourceVersion:14240,Generation:0,CreationTimestamp:2018-12-08 09:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  8 09:45:00.359: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-a,UID:e81199ca-facd-11e8-93eb-42010a840002,ResourceVersion:14240,Generation:0,CreationTimestamp:2018-12-08 09:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  8 09:45:10.366: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-a,UID:e81199ca-facd-11e8-93eb-42010a840002,ResourceVersion:14253,Generation:0,CreationTimestamp:2018-12-08 09:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 09:45:10.366: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-a,UID:e81199ca-facd-11e8-93eb-42010a840002,ResourceVersion:14253,Generation:0,CreationTimestamp:2018-12-08 09:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  8 09:45:20.372: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-a,UID:e81199ca-facd-11e8-93eb-42010a840002,ResourceVersion:14266,Generation:0,CreationTimestamp:2018-12-08 09:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  8 09:45:20.372: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-a,UID:e81199ca-facd-11e8-93eb-42010a840002,ResourceVersion:14266,Generation:0,CreationTimestamp:2018-12-08 09:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  8 09:45:30.379: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-b,UID:ffecabee-facd-11e8-93eb-42010a840002,ResourceVersion:14279,Generation:0,CreationTimestamp:2018-12-08 09:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 09:45:30.379: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-b,UID:ffecabee-facd-11e8-93eb-42010a840002,ResourceVersion:14279,Generation:0,CreationTimestamp:2018-12-08 09:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  8 09:45:40.385: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-b,UID:ffecabee-facd-11e8-93eb-42010a840002,ResourceVersion:14292,Generation:0,CreationTimestamp:2018-12-08 09:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  8 09:45:40.385: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-2fjr6,SelfLink:/api/v1/namespaces/e2e-tests-watch-2fjr6/configmaps/e2e-watch-test-configmap-b,UID:ffecabee-facd-11e8-93eb-42010a840002,ResourceVersion:14292,Generation:0,CreationTimestamp:2018-12-08 09:45:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:45:50.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-2fjr6" for this suite.
Dec  8 09:45:56.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:45:56.472: INFO: namespace: e2e-tests-watch-2fjr6, resource: bindings, ignored listing per whitelist
Dec  8 09:45:56.477: INFO: namespace e2e-tests-watch-2fjr6 deletion completed in 6.089172857s

• [SLOW TEST:66.192 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:45:56.478: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Dec  8 09:45:56.539: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  8 09:45:56.545: INFO: Waiting for terminating namespaces to be deleted...
Dec  8 09:45:56.548: INFO: 
Logging pods the kubelet thinks is on node conformance before test
Dec  8 09:45:56.556: INFO: coredns-86c58d9df4-mz9q8 from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 09:45:56.557: INFO: 	Container coredns ready: true, restart count 0
Dec  8 09:45:56.557: INFO: weave-net-xxrrf from kube-system started at 2018-12-08 08:33:13 +0000 UTC (2 container statuses recorded)
Dec  8 09:45:56.557: INFO: 	Container weave ready: true, restart count 0
Dec  8 09:45:56.557: INFO: 	Container weave-npc ready: true, restart count 0
Dec  8 09:45:56.557: INFO: sonobuoy-systemd-logs-daemon-set-70deb288c1a64a95-8db2d from heptio-sonobuoy started at 2018-12-08 08:34:09 +0000 UTC (2 container statuses recorded)
Dec  8 09:45:56.557: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  8 09:45:56.557: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  8 09:45:56.557: INFO: etcd-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 09:45:56.557: INFO: kube-scheduler-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 09:45:56.557: INFO: sonobuoy-e2e-job-ecc19fc5f3ae4f3f from heptio-sonobuoy started at 2018-12-08 08:34:09 +0000 UTC (2 container statuses recorded)
Dec  8 09:45:56.557: INFO: 	Container e2e ready: true, restart count 0
Dec  8 09:45:56.557: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  8 09:45:56.557: INFO: kube-apiserver-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 09:45:56.557: INFO: kube-proxy-djdrm from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 09:45:56.557: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  8 09:45:56.557: INFO: kube-controller-manager-conformance from kube-system started at <nil> (0 container statuses recorded)
Dec  8 09:45:56.557: INFO: coredns-86c58d9df4-bph5g from kube-system started at 2018-12-08 08:33:13 +0000 UTC (1 container statuses recorded)
Dec  8 09:45:56.557: INFO: 	Container coredns ready: true, restart count 0
Dec  8 09:45:56.557: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-08 08:34:04 +0000 UTC (1 container statuses recorded)
Dec  8 09:45:56.557: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156e526e7378e777], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:45:57.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-g28bh" for this suite.
Dec  8 09:46:03.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:46:03.663: INFO: namespace: e2e-tests-sched-pred-g28bh, resource: bindings, ignored listing per whitelist
Dec  8 09:46:03.689: INFO: namespace e2e-tests-sched-pred-g28bh deletion completed in 6.111627816s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.212 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:46:03.689: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-b972r
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-b972r to expose endpoints map[]
Dec  8 09:46:03.782: INFO: Get endpoints failed (2.957853ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec  8 09:46:04.786: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-b972r exposes endpoints map[] (1.007327927s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-b972r
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-b972r to expose endpoints map[pod1:[80]]
Dec  8 09:46:06.812: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-b972r exposes endpoints map[pod1:[80]] (2.018323259s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-b972r
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-b972r to expose endpoints map[pod1:[80] pod2:[80]]
Dec  8 09:46:08.852: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-b972r exposes endpoints map[pod1:[80] pod2:[80]] (2.036138185s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-b972r
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-b972r to expose endpoints map[pod2:[80]]
Dec  8 09:46:09.872: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-b972r exposes endpoints map[pod2:[80]] (1.015142181s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-b972r
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-b972r to expose endpoints map[]
Dec  8 09:46:10.885: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-b972r exposes endpoints map[] (1.005384357s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:46:10.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-b972r" for this suite.
Dec  8 09:46:32.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:46:32.987: INFO: namespace: e2e-tests-services-b972r, resource: bindings, ignored listing per whitelist
Dec  8 09:46:32.999: INFO: namespace e2e-tests-services-b972r deletion completed in 22.090215322s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.309 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:46:32.999: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  8 09:46:33.071: INFO: Waiting up to 5m0s for pod "var-expansion-254aa48f-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-var-expansion-4llzn" to be "success or failure"
Dec  8 09:46:33.073: INFO: Pod "var-expansion-254aa48f-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.130925ms
Dec  8 09:46:35.076: INFO: Pod "var-expansion-254aa48f-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0056657s
STEP: Saw pod success
Dec  8 09:46:35.076: INFO: Pod "var-expansion-254aa48f-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:46:35.079: INFO: Trying to get logs from node conformance pod var-expansion-254aa48f-face-11e8-9888-1eca7d857bda container dapi-container: <nil>
STEP: delete the pod
Dec  8 09:46:35.099: INFO: Waiting for pod var-expansion-254aa48f-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:46:35.101: INFO: Pod var-expansion-254aa48f-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:46:35.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4llzn" for this suite.
Dec  8 09:46:41.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:46:41.189: INFO: namespace: e2e-tests-var-expansion-4llzn, resource: bindings, ignored listing per whitelist
Dec  8 09:46:41.200: INFO: namespace e2e-tests-var-expansion-4llzn deletion completed in 6.096444266s

• [SLOW TEST:8.202 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:46:41.201: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-2a2c6f7a-face-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:46:41.266: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2a2cf26d-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-p6hcr" to be "success or failure"
Dec  8 09:46:41.268: INFO: Pod "pod-projected-secrets-2a2cf26d-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.414346ms
Dec  8 09:46:43.272: INFO: Pod "pod-projected-secrets-2a2cf26d-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006387234s
STEP: Saw pod success
Dec  8 09:46:43.272: INFO: Pod "pod-projected-secrets-2a2cf26d-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:46:43.275: INFO: Trying to get logs from node conformance pod pod-projected-secrets-2a2cf26d-face-11e8-9888-1eca7d857bda container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:46:43.291: INFO: Waiting for pod pod-projected-secrets-2a2cf26d-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:46:43.294: INFO: Pod pod-projected-secrets-2a2cf26d-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:46:43.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p6hcr" for this suite.
Dec  8 09:46:49.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:46:49.396: INFO: namespace: e2e-tests-projected-p6hcr, resource: bindings, ignored listing per whitelist
Dec  8 09:46:49.417: INFO: namespace e2e-tests-projected-p6hcr deletion completed in 6.12007372s

• [SLOW TEST:8.216 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:46:49.417: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1208 09:46:50.535126      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 09:46:50.535: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:46:50.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kgdbj" for this suite.
Dec  8 09:46:56.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:46:56.640: INFO: namespace: e2e-tests-gc-kgdbj, resource: bindings, ignored listing per whitelist
Dec  8 09:46:56.658: INFO: namespace e2e-tests-gc-kgdbj deletion completed in 6.114653467s

• [SLOW TEST:7.242 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:46:56.659: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  8 09:46:56.740: INFO: Waiting up to 5m0s for pod "client-containers-3366364c-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-containers-62pgm" to be "success or failure"
Dec  8 09:46:56.743: INFO: Pod "client-containers-3366364c-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.709802ms
Dec  8 09:46:58.746: INFO: Pod "client-containers-3366364c-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0066123s
STEP: Saw pod success
Dec  8 09:46:58.747: INFO: Pod "client-containers-3366364c-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:46:58.750: INFO: Trying to get logs from node conformance pod client-containers-3366364c-face-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:46:58.773: INFO: Waiting for pod client-containers-3366364c-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:46:58.777: INFO: Pod client-containers-3366364c-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:46:58.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-62pgm" for this suite.
Dec  8 09:47:04.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:47:04.815: INFO: namespace: e2e-tests-containers-62pgm, resource: bindings, ignored listing per whitelist
Dec  8 09:47:04.884: INFO: namespace e2e-tests-containers-62pgm deletion completed in 6.103575765s

• [SLOW TEST:8.225 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:47:04.884: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 09:47:04.956: INFO: Waiting up to 5m0s for pod "downwardapi-volume-384bd16c-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-4nc2z" to be "success or failure"
Dec  8 09:47:04.958: INFO: Pod "downwardapi-volume-384bd16c-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.316041ms
Dec  8 09:47:06.962: INFO: Pod "downwardapi-volume-384bd16c-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005807111s
STEP: Saw pod success
Dec  8 09:47:06.962: INFO: Pod "downwardapi-volume-384bd16c-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:47:06.965: INFO: Trying to get logs from node conformance pod downwardapi-volume-384bd16c-face-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 09:47:06.980: INFO: Waiting for pod downwardapi-volume-384bd16c-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:47:06.984: INFO: Pod downwardapi-volume-384bd16c-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:47:06.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4nc2z" for this suite.
Dec  8 09:47:12.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:47:13.032: INFO: namespace: e2e-tests-projected-4nc2z, resource: bindings, ignored listing per whitelist
Dec  8 09:47:13.070: INFO: namespace e2e-tests-projected-4nc2z deletion completed in 6.083270577s

• [SLOW TEST:8.186 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:47:13.071: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 09:47:13.126: INFO: Creating deployment "nginx-deployment"
Dec  8 09:47:13.130: INFO: Waiting for observed generation 1
Dec  8 09:47:15.136: INFO: Waiting for all required pods to come up
Dec  8 09:47:15.140: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  8 09:47:21.148: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  8 09:47:21.152: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  8 09:47:21.157: INFO: Updating deployment nginx-deployment
Dec  8 09:47:21.157: INFO: Waiting for observed generation 2
Dec  8 09:47:23.162: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  8 09:47:23.165: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  8 09:47:23.167: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  8 09:47:23.173: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  8 09:47:23.173: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  8 09:47:23.175: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  8 09:47:23.179: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  8 09:47:23.179: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  8 09:47:23.185: INFO: Updating deployment nginx-deployment
Dec  8 09:47:23.185: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  8 09:47:23.189: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  8 09:47:25.195: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  8 09:47:25.201: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7fhnj/deployments/nginx-deployment,UID:3d2bb019-face-11e8-93eb-42010a840002,ResourceVersion:14897,Generation:3,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-12-08 09:47:23 +0000 UTC 2018-12-08 09:47:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-08 09:47:23 +0000 UTC 2018-12-08 09:47:13 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  8 09:47:25.205: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7fhnj/replicasets/nginx-deployment-65bbdb5f8,UID:41f51cac-face-11e8-93eb-42010a840002,ResourceVersion:14895,Generation:3,CreationTimestamp:2018-12-08 09:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3d2bb019-face-11e8-93eb-42010a840002 0xc00180cb07 0xc00180cb08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  8 09:47:25.205: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  8 09:47:25.205: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7fhnj/replicasets/nginx-deployment-555b55d965,UID:3d2cf78e-face-11e8-93eb-42010a840002,ResourceVersion:14880,Generation:3,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3d2bb019-face-11e8-93eb-42010a840002 0xc00180c947 0xc00180c948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  8 09:47:25.213: INFO: Pod "nginx-deployment-555b55d965-627mg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-627mg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-627mg,UID:3d303512-face-11e8-93eb-42010a840002,ResourceVersion:14735,Generation:0,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc000b24647 0xc000b24648}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b24920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b249b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.11,StartTime:2018-12-08 09:47:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:47:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://c4fd2a49ffb1fa394818edd789717b4c15224f3fc2accd2b2d956f81428a9874}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.213: INFO: Pod "nginx-deployment-555b55d965-6mtd4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6mtd4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-6mtd4,UID:432dd72e-face-11e8-93eb-42010a840002,ResourceVersion:14852,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc000b24d30 0xc000b24d31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b25050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b25130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.214: INFO: Pod "nginx-deployment-555b55d965-6q5h9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6q5h9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-6q5h9,UID:432d1875-face-11e8-93eb-42010a840002,ResourceVersion:14899,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc000b252e0 0xc000b252e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b25520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b25540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.214: INFO: Pod "nginx-deployment-555b55d965-6xc9h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6xc9h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-6xc9h,UID:43305e5f-face-11e8-93eb-42010a840002,ResourceVersion:14856,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc000b25680 0xc000b25681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b256f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b25710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.214: INFO: Pod "nginx-deployment-555b55d965-bcv5v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bcv5v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-bcv5v,UID:43306c08-face-11e8-93eb-42010a840002,ResourceVersion:14863,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc000b25780 0xc000b25781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b257f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b25810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.215: INFO: Pod "nginx-deployment-555b55d965-brg8w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-brg8w,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-brg8w,UID:3d300106-face-11e8-93eb-42010a840002,ResourceVersion:14719,Generation:0,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc000b25980 0xc000b25981}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000b25d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000b25f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.8,StartTime:2018-12-08 09:47:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:47:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://f4e241444148115a8654e55e7fed8259bfe162e6f1d4e03b51c9b11ba1415865}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.215: INFO: Pod "nginx-deployment-555b55d965-g8p8r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g8p8r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-g8p8r,UID:3d304424-face-11e8-93eb-42010a840002,ResourceVersion:14714,Generation:0,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0005ba110 0xc0005ba111}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ba2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ba300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.10,StartTime:2018-12-08 09:47:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:47:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://b88b19b593826c3428dbd00fa6607140e135b256f4c6ff37f9220936b0fda302}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.215: INFO: Pod "nginx-deployment-555b55d965-gfz67" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gfz67,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-gfz67,UID:432c936f-face-11e8-93eb-42010a840002,ResourceVersion:14847,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0005ba4f0 0xc0005ba4f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005ba6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005ba700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.216: INFO: Pod "nginx-deployment-555b55d965-jllpc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jllpc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-jllpc,UID:433073b2-face-11e8-93eb-42010a840002,ResourceVersion:14866,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0005bb290 0xc0005bb291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005bb3c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005bb3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.216: INFO: Pod "nginx-deployment-555b55d965-kjzxr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kjzxr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-kjzxr,UID:3d31c45b-face-11e8-93eb-42010a840002,ResourceVersion:14741,Generation:0,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0005bb4f0 0xc0005bb4f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005bb640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005bb680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.14,StartTime:2018-12-08 09:47:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:47:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://b2fa6c8359bc5f2260bfd30b7029b548701c65219bfd1d584ed55e5847347225}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.216: INFO: Pod "nginx-deployment-555b55d965-nbjg7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nbjg7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-nbjg7,UID:432dded0-face-11e8-93eb-42010a840002,ResourceVersion:14927,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0005bb7d0 0xc0005bb7d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005bb990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005bb9d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.216: INFO: Pod "nginx-deployment-555b55d965-p4h7c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-p4h7c,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-p4h7c,UID:3d2f0ca3-face-11e8-93eb-42010a840002,ResourceVersion:14724,Generation:0,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0005bbbb0 0xc0005bbbb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0005bbc60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0005bbd30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.7,StartTime:2018-12-08 09:47:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:47:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://22888be14ccb8463ccec826c10ac3779fcac4b6708478e6620dec741c04c1776}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.216: INFO: Pod "nginx-deployment-555b55d965-pscww" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pscww,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-pscww,UID:3d2f2dc9-face-11e8-93eb-42010a840002,ResourceVersion:14708,Generation:0,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0005bbf40 0xc0005bbf41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.9,StartTime:2018-12-08 09:47:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:47:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://762c8985bd75db13e385ff4a8cf273398a68910d4b3c0a607e93ea13d4d8d11f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.216: INFO: Pod "nginx-deployment-555b55d965-pt76k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pt76k,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-pt76k,UID:432d0b16-face-11e8-93eb-42010a840002,ResourceVersion:14865,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0015f8700 0xc0015f8701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.217: INFO: Pod "nginx-deployment-555b55d965-q8mjm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q8mjm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-q8mjm,UID:43307bc0-face-11e8-93eb-42010a840002,ResourceVersion:14861,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0015f89b0 0xc0015f89b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.217: INFO: Pod "nginx-deployment-555b55d965-q9q7j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q9q7j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-q9q7j,UID:43303979-face-11e8-93eb-42010a840002,ResourceVersion:14860,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0015f8ac0 0xc0015f8ac1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.217: INFO: Pod "nginx-deployment-555b55d965-sw2sq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sw2sq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-sw2sq,UID:3d3104c9-face-11e8-93eb-42010a840002,ResourceVersion:14751,Generation:0,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0015f8c50 0xc0015f8c51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8de0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8e00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.12,StartTime:2018-12-08 09:47:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:47:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://241fb3efed866209ce2dc0b9f4898639bed25664ff3d1846d9b73d2a9ed7bb0e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.218: INFO: Pod "nginx-deployment-555b55d965-wsp44" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wsp44,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-wsp44,UID:3d31b852-face-11e8-93eb-42010a840002,ResourceVersion:14729,Generation:0,CreationTimestamp:2018-12-08 09:47:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0015f8ef0 0xc0015f8ef1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f8fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f8fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:13 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:10.32.0.15,StartTime:2018-12-08 09:47:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-08 09:47:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://8cd83f173f357243ccdfa8f4e5447853bc92f34764cecc28716d434766cf623f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.218: INFO: Pod "nginx-deployment-555b55d965-xxxk9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xxxk9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-xxxk9,UID:432dde51-face-11e8-93eb-42010a840002,ResourceVersion:14934,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0015f9290 0xc0015f9291}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f93d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f93f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.223: INFO: Pod "nginx-deployment-555b55d965-zj2jb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zj2jb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-555b55d965-zj2jb,UID:432dd9b5-face-11e8-93eb-42010a840002,ResourceVersion:14853,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 3d2cf78e-face-11e8-93eb-42010a840002 0xc0015f9670 0xc0015f9671}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f9c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015f9c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.224: INFO: Pod "nginx-deployment-65bbdb5f8-6dwdv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6dwdv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-6dwdv,UID:432d8400-face-11e8-93eb-42010a840002,ResourceVersion:14911,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc0015f9e10 0xc0015f9e11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015f9ee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00188e000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.224: INFO: Pod "nginx-deployment-65bbdb5f8-7g684" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7g684,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-7g684,UID:4336653c-face-11e8-93eb-42010a840002,ResourceVersion:14877,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc00188e150 0xc00188e151}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00188e200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00188e270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.224: INFO: Pod "nginx-deployment-65bbdb5f8-7zclm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7zclm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-7zclm,UID:4333b4ec-face-11e8-93eb-42010a840002,ResourceVersion:14870,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc00188e7d0 0xc00188e7d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00188e880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00188e8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.224: INFO: Pod "nginx-deployment-65bbdb5f8-c8m4c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-c8m4c,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-c8m4c,UID:41f62e54-face-11e8-93eb-42010a840002,ResourceVersion:14802,Generation:0,CreationTimestamp:2018-12-08 09:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc00188e950 0xc00188e951}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00188ea70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00188eaa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.224: INFO: Pod "nginx-deployment-65bbdb5f8-jkd8l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jkd8l,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-jkd8l,UID:41f620a1-face-11e8-93eb-42010a840002,ResourceVersion:14796,Generation:0,CreationTimestamp:2018-12-08 09:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc00188efb0 0xc00188efb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00188f030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00188f050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.224: INFO: Pod "nginx-deployment-65bbdb5f8-n4ld9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-n4ld9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-n4ld9,UID:432f289c-face-11e8-93eb-42010a840002,ResourceVersion:14922,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc00188f120 0xc00188f121}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00188f470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00188f490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.224: INFO: Pod "nginx-deployment-65bbdb5f8-nmp96" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nmp96,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-nmp96,UID:432f12db-face-11e8-93eb-42010a840002,ResourceVersion:14851,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc00188f6d0 0xc00188f6d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00188f7f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ada000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.224: INFO: Pod "nginx-deployment-65bbdb5f8-pvft5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pvft5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-pvft5,UID:4333a78f-face-11e8-93eb-42010a840002,ResourceVersion:14872,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc000ada1e0 0xc000ada1e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ada260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ada280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.225: INFO: Pod "nginx-deployment-65bbdb5f8-qgghm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-qgghm,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-qgghm,UID:41f58927-face-11e8-93eb-42010a840002,ResourceVersion:14786,Generation:0,CreationTimestamp:2018-12-08 09:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc000ada4c0 0xc000ada4c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ada630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ada6b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.225: INFO: Pod "nginx-deployment-65bbdb5f8-rkv6w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-rkv6w,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-rkv6w,UID:41fb14f6-face-11e8-93eb-42010a840002,ResourceVersion:14810,Generation:0,CreationTimestamp:2018-12-08 09:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc000ada800 0xc000ada801}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000ada8c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000ada8e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.225: INFO: Pod "nginx-deployment-65bbdb5f8-sz5z4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-sz5z4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-sz5z4,UID:41fa3ee0-face-11e8-93eb-42010a840002,ResourceVersion:14805,Generation:0,CreationTimestamp:2018-12-08 09:47:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc000ada9a0 0xc000ada9a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000adaa20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000adaa40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:21 +0000 UTC  }],Message:,Reason:,HostIP:10.132.0.2,PodIP:,StartTime:2018-12-08 09:47:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.225: INFO: Pod "nginx-deployment-65bbdb5f8-wwqbq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wwqbq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-wwqbq,UID:43337f2b-face-11e8-93eb-42010a840002,ResourceVersion:14871,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc000adae40 0xc000adae41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000adaf20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000adaf40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  8 09:47:25.225: INFO: Pod "nginx-deployment-65bbdb5f8-x9wf5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-x9wf5,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-7fhnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7fhnj/pods/nginx-deployment-65bbdb5f8-x9wf5,UID:4333a596-face-11e8-93eb-42010a840002,ResourceVersion:14867,Generation:0,CreationTimestamp:2018-12-08 09:47:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 41f51cac-face-11e8-93eb-42010a840002 0xc000adafe0 0xc000adafe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-sx27f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sx27f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sx27f true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000adb0e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000adb100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-08 09:47:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:47:25.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7fhnj" for this suite.
Dec  8 09:47:31.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:47:31.308: INFO: namespace: e2e-tests-deployment-7fhnj, resource: bindings, ignored listing per whitelist
Dec  8 09:47:31.314: INFO: namespace e2e-tests-deployment-7fhnj deletion completed in 6.084814041s

• [SLOW TEST:18.243 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:47:31.314: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-480b5f0e-face-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:47:31.379: INFO: Waiting up to 5m0s for pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-8fxnk" to be "success or failure"
Dec  8 09:47:31.382: INFO: Pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.388862ms
Dec  8 09:47:33.386: INFO: Pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006623372s
Dec  8 09:47:35.389: INFO: Pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009743902s
Dec  8 09:47:37.392: INFO: Pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012889938s
Dec  8 09:47:39.395: INFO: Pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01605536s
Dec  8 09:47:41.398: INFO: Pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01907884s
Dec  8 09:47:43.401: INFO: Pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.022139352s
STEP: Saw pod success
Dec  8 09:47:43.401: INFO: Pod "pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:47:43.404: INFO: Trying to get logs from node conformance pod pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:47:43.419: INFO: Waiting for pod pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:47:43.421: INFO: Pod pod-configmaps-480bdc9e-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:47:43.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8fxnk" for this suite.
Dec  8 09:47:49.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:47:49.445: INFO: namespace: e2e-tests-configmap-8fxnk, resource: bindings, ignored listing per whitelist
Dec  8 09:47:49.520: INFO: namespace e2e-tests-configmap-8fxnk deletion completed in 6.096565956s

• [SLOW TEST:18.206 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:47:49.520: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 09:47:49.581: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:47:50.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-tcv2j" for this suite.
Dec  8 09:47:56.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:47:56.654: INFO: namespace: e2e-tests-custom-resource-definition-tcv2j, resource: bindings, ignored listing per whitelist
Dec  8 09:47:56.723: INFO: namespace e2e-tests-custom-resource-definition-tcv2j deletion completed in 6.092177903s

• [SLOW TEST:7.203 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:47:56.723: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 09:47:56.792: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Dec  8 09:47:56.797: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dn7jn/daemonsets","resourceVersion":"15224"},"items":null}

Dec  8 09:47:56.799: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dn7jn/pods","resourceVersion":"15224"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:47:56.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dn7jn" for this suite.
Dec  8 09:48:02.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:48:02.876: INFO: namespace: e2e-tests-daemonsets-dn7jn, resource: bindings, ignored listing per whitelist
Dec  8 09:48:02.888: INFO: namespace e2e-tests-daemonsets-dn7jn deletion completed in 6.080284665s

S [SKIPPING] [6.165 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  8 09:47:56.792: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:48:02.888: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:48:09.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-zxwlp" for this suite.
Dec  8 09:48:15.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:48:15.106: INFO: namespace: e2e-tests-namespaces-zxwlp, resource: bindings, ignored listing per whitelist
Dec  8 09:48:15.121: INFO: namespace e2e-tests-namespaces-zxwlp deletion completed in 6.098950771s
STEP: Destroying namespace "e2e-tests-nsdeletetest-v876n" for this suite.
Dec  8 09:48:15.124: INFO: Namespace e2e-tests-nsdeletetest-v876n was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-2r8g5" for this suite.
Dec  8 09:48:21.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:48:21.197: INFO: namespace: e2e-tests-nsdeletetest-2r8g5, resource: bindings, ignored listing per whitelist
Dec  8 09:48:21.220: INFO: namespace e2e-tests-nsdeletetest-2r8g5 deletion completed in 6.096470813s

• [SLOW TEST:18.332 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:48:21.220: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:48:26.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-d9mzg" for this suite.
Dec  8 09:48:48.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:48:48.351: INFO: namespace: e2e-tests-replication-controller-d9mzg, resource: bindings, ignored listing per whitelist
Dec  8 09:48:48.407: INFO: namespace e2e-tests-replication-controller-d9mzg deletion completed in 22.092199728s

• [SLOW TEST:27.187 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:48:48.408: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  8 09:48:48.489: INFO: Number of nodes with available pods: 0
Dec  8 09:48:48.489: INFO: Node conformance is running more than one daemon pod
Dec  8 09:48:49.496: INFO: Number of nodes with available pods: 0
Dec  8 09:48:49.496: INFO: Node conformance is running more than one daemon pod
Dec  8 09:48:50.495: INFO: Number of nodes with available pods: 1
Dec  8 09:48:50.495: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  8 09:48:50.511: INFO: Number of nodes with available pods: 0
Dec  8 09:48:50.511: INFO: Node conformance is running more than one daemon pod
Dec  8 09:48:51.518: INFO: Number of nodes with available pods: 0
Dec  8 09:48:51.518: INFO: Node conformance is running more than one daemon pod
Dec  8 09:48:52.518: INFO: Number of nodes with available pods: 1
Dec  8 09:48:52.518: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-5vrm9, will wait for the garbage collector to delete the pods
Dec  8 09:48:52.582: INFO: Deleting DaemonSet.extensions daemon-set took: 6.231703ms
Dec  8 09:48:52.682: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.285568ms
Dec  8 09:49:26.085: INFO: Number of nodes with available pods: 0
Dec  8 09:49:26.085: INFO: Number of running nodes: 0, number of available pods: 0
Dec  8 09:49:26.088: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-5vrm9/daemonsets","resourceVersion":"15441"},"items":null}

Dec  8 09:49:26.091: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-5vrm9/pods","resourceVersion":"15441"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:49:26.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-5vrm9" for this suite.
Dec  8 09:49:32.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:49:32.180: INFO: namespace: e2e-tests-daemonsets-5vrm9, resource: bindings, ignored listing per whitelist
Dec  8 09:49:32.192: INFO: namespace e2e-tests-daemonsets-5vrm9 deletion completed in 6.09221338s

• [SLOW TEST:43.785 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:49:32.193: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 09:49:32.262: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9018edd3-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-z4s47" to be "success or failure"
Dec  8 09:49:32.265: INFO: Pod "downwardapi-volume-9018edd3-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.080135ms
Dec  8 09:49:34.268: INFO: Pod "downwardapi-volume-9018edd3-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006321741s
STEP: Saw pod success
Dec  8 09:49:34.268: INFO: Pod "downwardapi-volume-9018edd3-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:49:34.271: INFO: Trying to get logs from node conformance pod downwardapi-volume-9018edd3-face-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 09:49:34.289: INFO: Waiting for pod downwardapi-volume-9018edd3-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:49:34.291: INFO: Pod downwardapi-volume-9018edd3-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:49:34.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z4s47" for this suite.
Dec  8 09:49:40.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:49:40.389: INFO: namespace: e2e-tests-projected-z4s47, resource: bindings, ignored listing per whitelist
Dec  8 09:49:40.394: INFO: namespace e2e-tests-projected-z4s47 deletion completed in 6.097818344s

• [SLOW TEST:8.202 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:49:40.395: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  8 09:49:40.462: INFO: Waiting up to 5m0s for pod "pod-94fc5b94-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-4cnnl" to be "success or failure"
Dec  8 09:49:40.465: INFO: Pod "pod-94fc5b94-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.638598ms
Dec  8 09:49:42.469: INFO: Pod "pod-94fc5b94-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006327171s
STEP: Saw pod success
Dec  8 09:49:42.469: INFO: Pod "pod-94fc5b94-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:49:42.472: INFO: Trying to get logs from node conformance pod pod-94fc5b94-face-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:49:42.488: INFO: Waiting for pod pod-94fc5b94-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:49:42.490: INFO: Pod pod-94fc5b94-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:49:42.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4cnnl" for this suite.
Dec  8 09:49:48.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:49:48.554: INFO: namespace: e2e-tests-emptydir-4cnnl, resource: bindings, ignored listing per whitelist
Dec  8 09:49:48.582: INFO: namespace e2e-tests-emptydir-4cnnl deletion completed in 6.08799712s

• [SLOW TEST:8.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:49:48.582: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:49:48.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-c97db" for this suite.
Dec  8 09:49:54.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:49:54.721: INFO: namespace: e2e-tests-services-c97db, resource: bindings, ignored listing per whitelist
Dec  8 09:49:54.735: INFO: namespace e2e-tests-services-c97db deletion completed in 6.089704873s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.153 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:49:54.735: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 09:49:54.797: INFO: Waiting up to 5m0s for pod "downward-api-9d876ef2-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-d9hcd" to be "success or failure"
Dec  8 09:49:54.799: INFO: Pod "downward-api-9d876ef2-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.406348ms
Dec  8 09:49:56.803: INFO: Pod "downward-api-9d876ef2-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00592719s
STEP: Saw pod success
Dec  8 09:49:56.803: INFO: Pod "downward-api-9d876ef2-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:49:56.806: INFO: Trying to get logs from node conformance pod downward-api-9d876ef2-face-11e8-9888-1eca7d857bda container dapi-container: <nil>
STEP: delete the pod
Dec  8 09:49:56.824: INFO: Waiting for pod downward-api-9d876ef2-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:49:56.826: INFO: Pod downward-api-9d876ef2-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:49:56.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d9hcd" for this suite.
Dec  8 09:50:02.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:50:02.879: INFO: namespace: e2e-tests-downward-api-d9hcd, resource: bindings, ignored listing per whitelist
Dec  8 09:50:02.930: INFO: namespace e2e-tests-downward-api-d9hcd deletion completed in 6.100990648s

• [SLOW TEST:8.195 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:50:02.930: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 09:50:02.999: INFO: Waiting up to 5m0s for pod "downward-api-a26b22f7-face-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-5f56k" to be "success or failure"
Dec  8 09:50:03.003: INFO: Pod "downward-api-a26b22f7-face-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.367536ms
Dec  8 09:50:05.006: INFO: Pod "downward-api-a26b22f7-face-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006981475s
STEP: Saw pod success
Dec  8 09:50:05.006: INFO: Pod "downward-api-a26b22f7-face-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:50:05.009: INFO: Trying to get logs from node conformance pod downward-api-a26b22f7-face-11e8-9888-1eca7d857bda container dapi-container: <nil>
STEP: delete the pod
Dec  8 09:50:05.026: INFO: Waiting for pod downward-api-a26b22f7-face-11e8-9888-1eca7d857bda to disappear
Dec  8 09:50:05.028: INFO: Pod downward-api-a26b22f7-face-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:50:05.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5f56k" for this suite.
Dec  8 09:50:11.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:50:11.094: INFO: namespace: e2e-tests-downward-api-5f56k, resource: bindings, ignored listing per whitelist
Dec  8 09:50:11.131: INFO: namespace e2e-tests-downward-api-5f56k deletion completed in 6.100723207s

• [SLOW TEST:8.200 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:50:11.131: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  8 09:50:11.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 cluster-info'
Dec  8 09:50:11.491: INFO: stderr: ""
Dec  8 09:50:11.491: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:50:11.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-btdsn" for this suite.
Dec  8 09:50:17.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:50:17.527: INFO: namespace: e2e-tests-kubectl-btdsn, resource: bindings, ignored listing per whitelist
Dec  8 09:50:17.589: INFO: namespace e2e-tests-kubectl-btdsn deletion completed in 6.093662687s

• [SLOW TEST:6.457 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:50:17.589: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-jjm8
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 09:50:17.658: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-jjm8" in namespace "e2e-tests-subpath-smrlq" to be "success or failure"
Dec  8 09:50:17.661: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.057571ms
Dec  8 09:50:19.665: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007046963s
Dec  8 09:50:21.669: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 4.010737545s
Dec  8 09:50:23.672: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 6.014329985s
Dec  8 09:50:25.676: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 8.018191399s
Dec  8 09:50:27.680: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 10.021689164s
Dec  8 09:50:29.683: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 12.025040677s
Dec  8 09:50:31.686: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 14.028497792s
Dec  8 09:50:33.690: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 16.032426921s
Dec  8 09:50:35.694: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 18.035896476s
Dec  8 09:50:37.697: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 20.039135404s
Dec  8 09:50:39.701: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Running", Reason="", readiness=false. Elapsed: 22.042992008s
Dec  8 09:50:41.705: INFO: Pod "pod-subpath-test-projected-jjm8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046992313s
STEP: Saw pod success
Dec  8 09:50:41.705: INFO: Pod "pod-subpath-test-projected-jjm8" satisfied condition "success or failure"
Dec  8 09:50:41.707: INFO: Trying to get logs from node conformance pod pod-subpath-test-projected-jjm8 container test-container-subpath-projected-jjm8: <nil>
STEP: delete the pod
Dec  8 09:50:41.725: INFO: Waiting for pod pod-subpath-test-projected-jjm8 to disappear
Dec  8 09:50:41.729: INFO: Pod pod-subpath-test-projected-jjm8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-jjm8
Dec  8 09:50:41.729: INFO: Deleting pod "pod-subpath-test-projected-jjm8" in namespace "e2e-tests-subpath-smrlq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:50:41.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-smrlq" for this suite.
Dec  8 09:50:47.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:50:47.779: INFO: namespace: e2e-tests-subpath-smrlq, resource: bindings, ignored listing per whitelist
Dec  8 09:50:47.828: INFO: namespace e2e-tests-subpath-smrlq deletion completed in 6.093688093s

• [SLOW TEST:30.240 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:50:47.829: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-f287m
Dec  8 09:50:49.906: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-f287m
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 09:50:49.909: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:54:50.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-f287m" for this suite.
Dec  8 09:54:56.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:54:56.374: INFO: namespace: e2e-tests-container-probe-f287m, resource: bindings, ignored listing per whitelist
Dec  8 09:54:56.433: INFO: namespace e2e-tests-container-probe-f287m deletion completed in 6.085179005s

• [SLOW TEST:248.604 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:54:56.433: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  8 09:54:56.502: INFO: Waiting up to 5m0s for pod "client-containers-515c091b-facf-11e8-9888-1eca7d857bda" in namespace "e2e-tests-containers-8thmp" to be "success or failure"
Dec  8 09:54:56.506: INFO: Pod "client-containers-515c091b-facf-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 4.27398ms
Dec  8 09:54:58.510: INFO: Pod "client-containers-515c091b-facf-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007856786s
STEP: Saw pod success
Dec  8 09:54:58.510: INFO: Pod "client-containers-515c091b-facf-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:54:58.512: INFO: Trying to get logs from node conformance pod client-containers-515c091b-facf-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:54:58.530: INFO: Waiting for pod client-containers-515c091b-facf-11e8-9888-1eca7d857bda to disappear
Dec  8 09:54:58.533: INFO: Pod client-containers-515c091b-facf-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:54:58.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8thmp" for this suite.
Dec  8 09:55:04.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:55:04.607: INFO: namespace: e2e-tests-containers-8thmp, resource: bindings, ignored listing per whitelist
Dec  8 09:55:04.627: INFO: namespace e2e-tests-containers-8thmp deletion completed in 6.091667783s

• [SLOW TEST:8.194 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:55:04.628: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  8 09:55:05.200: INFO: created pod pod-service-account-defaultsa
Dec  8 09:55:05.200: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  8 09:55:05.205: INFO: created pod pod-service-account-mountsa
Dec  8 09:55:05.205: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  8 09:55:05.215: INFO: created pod pod-service-account-nomountsa
Dec  8 09:55:05.216: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  8 09:55:05.220: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  8 09:55:05.220: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  8 09:55:05.227: INFO: created pod pod-service-account-mountsa-mountspec
Dec  8 09:55:05.227: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  8 09:55:05.236: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  8 09:55:05.236: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  8 09:55:05.246: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  8 09:55:05.246: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  8 09:55:05.257: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  8 09:55:05.257: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  8 09:55:05.263: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  8 09:55:05.263: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:55:05.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-pwsjf" for this suite.
Dec  8 09:56:51.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:56:51.327: INFO: namespace: e2e-tests-svcaccounts-pwsjf, resource: bindings, ignored listing per whitelist
Dec  8 09:56:51.357: INFO: namespace e2e-tests-svcaccounts-pwsjf deletion completed in 1m46.089178237s

• [SLOW TEST:106.729 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:56:51.357: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-95dc16f0-facf-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume secrets
Dec  8 09:56:51.429: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-95dc8ad8-facf-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-27vj4" to be "success or failure"
Dec  8 09:56:51.431: INFO: Pod "pod-projected-secrets-95dc8ad8-facf-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.29562ms
Dec  8 09:56:53.435: INFO: Pod "pod-projected-secrets-95dc8ad8-facf-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005703046s
STEP: Saw pod success
Dec  8 09:56:53.435: INFO: Pod "pod-projected-secrets-95dc8ad8-facf-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:56:53.437: INFO: Trying to get logs from node conformance pod pod-projected-secrets-95dc8ad8-facf-11e8-9888-1eca7d857bda container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  8 09:56:53.453: INFO: Waiting for pod pod-projected-secrets-95dc8ad8-facf-11e8-9888-1eca7d857bda to disappear
Dec  8 09:56:53.455: INFO: Pod pod-projected-secrets-95dc8ad8-facf-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:56:53.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-27vj4" for this suite.
Dec  8 09:56:59.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:56:59.487: INFO: namespace: e2e-tests-projected-27vj4, resource: bindings, ignored listing per whitelist
Dec  8 09:56:59.543: INFO: namespace e2e-tests-projected-27vj4 deletion completed in 6.084928103s

• [SLOW TEST:8.185 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:56:59.543: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:57:01.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-rf757" for this suite.
Dec  8 09:57:07.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:57:07.691: INFO: namespace: e2e-tests-emptydir-wrapper-rf757, resource: bindings, ignored listing per whitelist
Dec  8 09:57:07.728: INFO: namespace e2e-tests-emptydir-wrapper-rf757 deletion completed in 6.089278499s

• [SLOW TEST:8.185 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:57:07.729: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  8 09:57:07.795: INFO: Waiting up to 5m0s for pod "var-expansion-9f9ddbb8-facf-11e8-9888-1eca7d857bda" in namespace "e2e-tests-var-expansion-kzblv" to be "success or failure"
Dec  8 09:57:07.798: INFO: Pod "var-expansion-9f9ddbb8-facf-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.639758ms
Dec  8 09:57:09.801: INFO: Pod "var-expansion-9f9ddbb8-facf-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006177111s
STEP: Saw pod success
Dec  8 09:57:09.801: INFO: Pod "var-expansion-9f9ddbb8-facf-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:57:09.804: INFO: Trying to get logs from node conformance pod var-expansion-9f9ddbb8-facf-11e8-9888-1eca7d857bda container dapi-container: <nil>
STEP: delete the pod
Dec  8 09:57:09.822: INFO: Waiting for pod var-expansion-9f9ddbb8-facf-11e8-9888-1eca7d857bda to disappear
Dec  8 09:57:09.826: INFO: Pod var-expansion-9f9ddbb8-facf-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:57:09.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kzblv" for this suite.
Dec  8 09:57:15.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:57:15.921: INFO: namespace: e2e-tests-var-expansion-kzblv, resource: bindings, ignored listing per whitelist
Dec  8 09:57:15.945: INFO: namespace e2e-tests-var-expansion-kzblv deletion completed in 6.115452561s

• [SLOW TEST:8.216 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:57:15.945: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1208 09:57:26.130571      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 09:57:26.130: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:57:26.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-z5rpt" for this suite.
Dec  8 09:57:32.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:57:32.152: INFO: namespace: e2e-tests-gc-z5rpt, resource: bindings, ignored listing per whitelist
Dec  8 09:57:32.230: INFO: namespace e2e-tests-gc-z5rpt deletion completed in 6.096822065s

• [SLOW TEST:16.285 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:57:32.230: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  8 09:57:32.298: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-tkh2d" to be "success or failure"
Dec  8 09:57:32.300: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015597ms
Dec  8 09:57:34.304: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005580166s
Dec  8 09:57:36.308: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009415289s
STEP: Saw pod success
Dec  8 09:57:36.308: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  8 09:57:36.310: INFO: Trying to get logs from node conformance pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  8 09:57:36.325: INFO: Waiting for pod pod-host-path-test to disappear
Dec  8 09:57:36.330: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:57:36.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-tkh2d" for this suite.
Dec  8 09:57:42.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:57:42.359: INFO: namespace: e2e-tests-hostpath-tkh2d, resource: bindings, ignored listing per whitelist
Dec  8 09:57:42.428: INFO: namespace e2e-tests-hostpath-tkh2d deletion completed in 6.09472621s

• [SLOW TEST:10.198 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:57:42.428: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b44d67fb-facf-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:57:42.504: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b44df0e6-facf-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-wzldg" to be "success or failure"
Dec  8 09:57:42.507: INFO: Pod "pod-projected-configmaps-b44df0e6-facf-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.506846ms
Dec  8 09:57:44.510: INFO: Pod "pod-projected-configmaps-b44df0e6-facf-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006130495s
STEP: Saw pod success
Dec  8 09:57:44.510: INFO: Pod "pod-projected-configmaps-b44df0e6-facf-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:57:44.514: INFO: Trying to get logs from node conformance pod pod-projected-configmaps-b44df0e6-facf-11e8-9888-1eca7d857bda container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:57:44.531: INFO: Waiting for pod pod-projected-configmaps-b44df0e6-facf-11e8-9888-1eca7d857bda to disappear
Dec  8 09:57:44.534: INFO: Pod pod-projected-configmaps-b44df0e6-facf-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:57:44.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wzldg" for this suite.
Dec  8 09:57:50.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:57:50.580: INFO: namespace: e2e-tests-projected-wzldg, resource: bindings, ignored listing per whitelist
Dec  8 09:57:50.640: INFO: namespace e2e-tests-projected-wzldg deletion completed in 6.103404368s

• [SLOW TEST:8.212 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:57:50.640: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-b9319d78-facf-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:57:50.741: INFO: Waiting up to 5m0s for pod "pod-configmaps-b936a7cc-facf-11e8-9888-1eca7d857bda" in namespace "e2e-tests-configmap-q9x4f" to be "success or failure"
Dec  8 09:57:50.743: INFO: Pod "pod-configmaps-b936a7cc-facf-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.239911ms
Dec  8 09:57:52.749: INFO: Pod "pod-configmaps-b936a7cc-facf-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007760509s
STEP: Saw pod success
Dec  8 09:57:52.749: INFO: Pod "pod-configmaps-b936a7cc-facf-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:57:52.751: INFO: Trying to get logs from node conformance pod pod-configmaps-b936a7cc-facf-11e8-9888-1eca7d857bda container configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:57:52.771: INFO: Waiting for pod pod-configmaps-b936a7cc-facf-11e8-9888-1eca7d857bda to disappear
Dec  8 09:57:52.774: INFO: Pod pod-configmaps-b936a7cc-facf-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:57:52.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-q9x4f" for this suite.
Dec  8 09:57:58.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:57:58.796: INFO: namespace: e2e-tests-configmap-q9x4f, resource: bindings, ignored listing per whitelist
Dec  8 09:57:58.866: INFO: namespace e2e-tests-configmap-q9x4f deletion completed in 6.089853243s

• [SLOW TEST:8.226 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:57:58.866: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-be190c82-facf-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:57:58.937: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-be197ca2-facf-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-bqdcb" to be "success or failure"
Dec  8 09:57:58.939: INFO: Pod "pod-projected-configmaps-be197ca2-facf-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.493717ms
Dec  8 09:58:00.943: INFO: Pod "pod-projected-configmaps-be197ca2-facf-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006128216s
STEP: Saw pod success
Dec  8 09:58:00.943: INFO: Pod "pod-projected-configmaps-be197ca2-facf-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:58:00.945: INFO: Trying to get logs from node conformance pod pod-projected-configmaps-be197ca2-facf-11e8-9888-1eca7d857bda container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 09:58:00.964: INFO: Waiting for pod pod-projected-configmaps-be197ca2-facf-11e8-9888-1eca7d857bda to disappear
Dec  8 09:58:00.966: INFO: Pod pod-projected-configmaps-be197ca2-facf-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:58:00.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bqdcb" for this suite.
Dec  8 09:58:06.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:58:06.984: INFO: namespace: e2e-tests-projected-bqdcb, resource: bindings, ignored listing per whitelist
Dec  8 09:58:07.049: INFO: namespace e2e-tests-projected-bqdcb deletion completed in 6.080192718s

• [SLOW TEST:8.183 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:58:07.050: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  8 09:58:11.134: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:11.138: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:13.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:13.142: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:15.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:15.142: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:17.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:17.142: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:19.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:19.142: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:21.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:21.142: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:23.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:23.142: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:25.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:25.142: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:27.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:27.142: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:29.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:29.143: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  8 09:58:31.139: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  8 09:58:31.142: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:58:31.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4676z" for this suite.
Dec  8 09:58:53.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:58:53.172: INFO: namespace: e2e-tests-container-lifecycle-hook-4676z, resource: bindings, ignored listing per whitelist
Dec  8 09:58:53.252: INFO: namespace e2e-tests-container-lifecycle-hook-4676z deletion completed in 22.097745978s

• [SLOW TEST:46.202 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:58:53.253: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  8 09:58:57.348: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 09:58:57.352: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 09:58:59.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 09:58:59.356: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 09:59:01.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 09:59:01.356: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 09:59:03.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 09:59:03.356: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 09:59:05.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 09:59:05.356: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 09:59:07.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 09:59:07.356: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 09:59:09.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 09:59:09.355: INFO: Pod pod-with-prestop-http-hook still exists
Dec  8 09:59:11.352: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  8 09:59:11.357: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:59:11.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-h49r6" for this suite.
Dec  8 09:59:33.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:59:33.388: INFO: namespace: e2e-tests-container-lifecycle-hook-h49r6, resource: bindings, ignored listing per whitelist
Dec  8 09:59:33.460: INFO: namespace e2e-tests-container-lifecycle-hook-h49r6 deletion completed in 22.090040497s

• [SLOW TEST:40.207 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:59:33.460: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  8 09:59:33.525: INFO: Waiting up to 5m0s for pod "pod-f67a8215-facf-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-r5xt5" to be "success or failure"
Dec  8 09:59:33.527: INFO: Pod "pod-f67a8215-facf-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.642177ms
Dec  8 09:59:35.531: INFO: Pod "pod-f67a8215-facf-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006416936s
STEP: Saw pod success
Dec  8 09:59:35.531: INFO: Pod "pod-f67a8215-facf-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:59:35.534: INFO: Trying to get logs from node conformance pod pod-f67a8215-facf-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:59:35.551: INFO: Waiting for pod pod-f67a8215-facf-11e8-9888-1eca7d857bda to disappear
Dec  8 09:59:35.554: INFO: Pod pod-f67a8215-facf-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:59:35.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r5xt5" for this suite.
Dec  8 09:59:41.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:59:41.581: INFO: namespace: e2e-tests-emptydir-r5xt5, resource: bindings, ignored listing per whitelist
Dec  8 09:59:41.644: INFO: namespace e2e-tests-emptydir-r5xt5 deletion completed in 6.087554595s

• [SLOW TEST:8.184 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:59:41.644: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-fb5a14ff-facf-11e8-9888-1eca7d857bda
STEP: Creating secret with name secret-projected-all-test-volume-fb5a14ed-facf-11e8-9888-1eca7d857bda
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  8 09:59:41.707: INFO: Waiting up to 5m0s for pod "projected-volume-fb5a149d-facf-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-gcvcp" to be "success or failure"
Dec  8 09:59:41.709: INFO: Pod "projected-volume-fb5a149d-facf-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.36922ms
Dec  8 09:59:43.712: INFO: Pod "projected-volume-fb5a149d-facf-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005744359s
STEP: Saw pod success
Dec  8 09:59:43.712: INFO: Pod "projected-volume-fb5a149d-facf-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:59:43.715: INFO: Trying to get logs from node conformance pod projected-volume-fb5a149d-facf-11e8-9888-1eca7d857bda container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  8 09:59:43.731: INFO: Waiting for pod projected-volume-fb5a149d-facf-11e8-9888-1eca7d857bda to disappear
Dec  8 09:59:43.732: INFO: Pod projected-volume-fb5a149d-facf-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:59:43.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gcvcp" for this suite.
Dec  8 09:59:49.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:59:49.782: INFO: namespace: e2e-tests-projected-gcvcp, resource: bindings, ignored listing per whitelist
Dec  8 09:59:49.818: INFO: namespace e2e-tests-projected-gcvcp deletion completed in 6.083031877s

• [SLOW TEST:8.174 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:59:49.818: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  8 09:59:49.883: INFO: Waiting up to 5m0s for pod "pod-003aa418-fad0-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-wxd6x" to be "success or failure"
Dec  8 09:59:49.886: INFO: Pod "pod-003aa418-fad0-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.562453ms
Dec  8 09:59:51.890: INFO: Pod "pod-003aa418-fad0-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00653134s
STEP: Saw pod success
Dec  8 09:59:51.890: INFO: Pod "pod-003aa418-fad0-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 09:59:51.893: INFO: Trying to get logs from node conformance pod pod-003aa418-fad0-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 09:59:51.912: INFO: Waiting for pod pod-003aa418-fad0-11e8-9888-1eca7d857bda to disappear
Dec  8 09:59:51.915: INFO: Pod pod-003aa418-fad0-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 09:59:51.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wxd6x" for this suite.
Dec  8 09:59:57.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 09:59:57.952: INFO: namespace: e2e-tests-emptydir-wxd6x, resource: bindings, ignored listing per whitelist
Dec  8 09:59:58.006: INFO: namespace e2e-tests-emptydir-wxd6x deletion completed in 6.087679286s

• [SLOW TEST:8.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 09:59:58.007: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-051b6dcb-fad0-11e8-9888-1eca7d857bda
STEP: Creating a pod to test consume configMaps
Dec  8 09:59:58.072: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-051beef4-fad0-11e8-9888-1eca7d857bda" in namespace "e2e-tests-projected-kgcrb" to be "success or failure"
Dec  8 09:59:58.075: INFO: Pod "pod-projected-configmaps-051beef4-fad0-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.924754ms
Dec  8 10:00:00.078: INFO: Pod "pod-projected-configmaps-051beef4-fad0-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006531803s
STEP: Saw pod success
Dec  8 10:00:00.079: INFO: Pod "pod-projected-configmaps-051beef4-fad0-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 10:00:00.081: INFO: Trying to get logs from node conformance pod pod-projected-configmaps-051beef4-fad0-11e8-9888-1eca7d857bda container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  8 10:00:00.101: INFO: Waiting for pod pod-projected-configmaps-051beef4-fad0-11e8-9888-1eca7d857bda to disappear
Dec  8 10:00:00.103: INFO: Pod pod-projected-configmaps-051beef4-fad0-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:00:00.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kgcrb" for this suite.
Dec  8 10:00:06.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:00:06.162: INFO: namespace: e2e-tests-projected-kgcrb, resource: bindings, ignored listing per whitelist
Dec  8 10:00:06.200: INFO: namespace e2e-tests-projected-kgcrb deletion completed in 6.093705735s

• [SLOW TEST:8.193 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:00:06.200: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 10:00:06.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 version'
Dec  8 10:00:06.350: INFO: stderr: ""
Dec  8 10:00:06.350: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T20:56:12Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:00:06.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b57rp" for this suite.
Dec  8 10:00:12.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:00:12.408: INFO: namespace: e2e-tests-kubectl-b57rp, resource: bindings, ignored listing per whitelist
Dec  8 10:00:12.436: INFO: namespace e2e-tests-kubectl-b57rp deletion completed in 6.082297331s

• [SLOW TEST:6.236 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:00:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  8 10:00:12.495: INFO: Waiting up to 5m0s for pod "downward-api-0db4c2f2-fad0-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-krpgc" to be "success or failure"
Dec  8 10:00:12.497: INFO: Pod "downward-api-0db4c2f2-fad0-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.729969ms
Dec  8 10:00:14.501: INFO: Pod "downward-api-0db4c2f2-fad0-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006218546s
STEP: Saw pod success
Dec  8 10:00:14.501: INFO: Pod "downward-api-0db4c2f2-fad0-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 10:00:14.504: INFO: Trying to get logs from node conformance pod downward-api-0db4c2f2-fad0-11e8-9888-1eca7d857bda container dapi-container: <nil>
STEP: delete the pod
Dec  8 10:00:14.521: INFO: Waiting for pod downward-api-0db4c2f2-fad0-11e8-9888-1eca7d857bda to disappear
Dec  8 10:00:14.524: INFO: Pod downward-api-0db4c2f2-fad0-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:00:14.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-krpgc" for this suite.
Dec  8 10:00:20.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:00:20.579: INFO: namespace: e2e-tests-downward-api-krpgc, resource: bindings, ignored listing per whitelist
Dec  8 10:00:20.631: INFO: namespace e2e-tests-downward-api-krpgc deletion completed in 6.103623206s

• [SLOW TEST:8.195 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:00:20.631: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1208 10:01:00.721565      20 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  8 10:01:00.721: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:01:00.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bcrsn" for this suite.
Dec  8 10:01:06.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:01:06.761: INFO: namespace: e2e-tests-gc-bcrsn, resource: bindings, ignored listing per whitelist
Dec  8 10:01:06.805: INFO: namespace e2e-tests-gc-bcrsn deletion completed in 6.081244294s

• [SLOW TEST:46.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:01:06.805: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  8 10:01:06.865: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2e1d14e2-fad0-11e8-9888-1eca7d857bda" in namespace "e2e-tests-downward-api-fvf7p" to be "success or failure"
Dec  8 10:01:06.868: INFO: Pod "downwardapi-volume-2e1d14e2-fad0-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.854093ms
Dec  8 10:01:08.871: INFO: Pod "downwardapi-volume-2e1d14e2-fad0-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005967315s
Dec  8 10:01:10.874: INFO: Pod "downwardapi-volume-2e1d14e2-fad0-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009005346s
STEP: Saw pod success
Dec  8 10:01:10.874: INFO: Pod "downwardapi-volume-2e1d14e2-fad0-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 10:01:10.876: INFO: Trying to get logs from node conformance pod downwardapi-volume-2e1d14e2-fad0-11e8-9888-1eca7d857bda container client-container: <nil>
STEP: delete the pod
Dec  8 10:01:10.891: INFO: Waiting for pod downwardapi-volume-2e1d14e2-fad0-11e8-9888-1eca7d857bda to disappear
Dec  8 10:01:10.893: INFO: Pod downwardapi-volume-2e1d14e2-fad0-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:01:10.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fvf7p" for this suite.
Dec  8 10:01:16.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:01:16.935: INFO: namespace: e2e-tests-downward-api-fvf7p, resource: bindings, ignored listing per whitelist
Dec  8 10:01:16.961: INFO: namespace e2e-tests-downward-api-fvf7p deletion completed in 6.065446107s

• [SLOW TEST:10.156 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:01:16.961: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  8 10:01:17.013: INFO: Waiting up to 5m0s for pod "pod-34299962-fad0-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-9fsmr" to be "success or failure"
Dec  8 10:01:17.015: INFO: Pod "pod-34299962-fad0-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.332202ms
Dec  8 10:01:19.018: INFO: Pod "pod-34299962-fad0-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005770606s
STEP: Saw pod success
Dec  8 10:01:19.018: INFO: Pod "pod-34299962-fad0-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 10:01:19.022: INFO: Trying to get logs from node conformance pod pod-34299962-fad0-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 10:01:19.037: INFO: Waiting for pod pod-34299962-fad0-11e8-9888-1eca7d857bda to disappear
Dec  8 10:01:19.039: INFO: Pod pod-34299962-fad0-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:01:19.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9fsmr" for this suite.
Dec  8 10:01:25.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:01:25.077: INFO: namespace: e2e-tests-emptydir-9fsmr, resource: bindings, ignored listing per whitelist
Dec  8 10:01:25.157: INFO: namespace e2e-tests-emptydir-9fsmr deletion completed in 6.114656726s

• [SLOW TEST:8.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:01:25.157: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Dec  8 10:01:25.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 create -f - --namespace=e2e-tests-kubectl-6jqtb'
Dec  8 10:01:25.789: INFO: stderr: ""
Dec  8 10:01:25.789: INFO: stdout: "pod/pause created\n"
Dec  8 10:01:25.789: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  8 10:01:25.789: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-6jqtb" to be "running and ready"
Dec  8 10:01:25.793: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.938623ms
Dec  8 10:01:27.797: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007458357s
Dec  8 10:01:27.797: INFO: Pod "pause" satisfied condition "running and ready"
Dec  8 10:01:27.797: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  8 10:01:27.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-6jqtb'
Dec  8 10:01:27.889: INFO: stderr: ""
Dec  8 10:01:27.889: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  8 10:01:27.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6jqtb'
Dec  8 10:01:27.976: INFO: stderr: ""
Dec  8 10:01:27.976: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  8 10:01:27.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 label pods pause testing-label- --namespace=e2e-tests-kubectl-6jqtb'
Dec  8 10:01:28.068: INFO: stderr: ""
Dec  8 10:01:28.068: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  8 10:01:28.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pod pause -L testing-label --namespace=e2e-tests-kubectl-6jqtb'
Dec  8 10:01:28.156: INFO: stderr: ""
Dec  8 10:01:28.156: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Dec  8 10:01:28.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-6jqtb'
Dec  8 10:01:28.251: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  8 10:01:28.251: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  8 10:01:28.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-6jqtb'
Dec  8 10:01:28.358: INFO: stderr: "No resources found.\n"
Dec  8 10:01:28.358: INFO: stdout: ""
Dec  8 10:01:28.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 get pods -l name=pause --namespace=e2e-tests-kubectl-6jqtb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  8 10:01:28.449: INFO: stderr: ""
Dec  8 10:01:28.449: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:01:28.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6jqtb" for this suite.
Dec  8 10:01:34.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:01:34.495: INFO: namespace: e2e-tests-kubectl-6jqtb, resource: bindings, ignored listing per whitelist
Dec  8 10:01:34.565: INFO: namespace e2e-tests-kubectl-6jqtb deletion completed in 6.112803221s

• [SLOW TEST:9.408 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:01:34.565: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  8 10:01:34.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xzhbg'
Dec  8 10:01:34.731: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  8 10:01:34.731: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Dec  8 10:01:34.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-866404302 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-xzhbg'
Dec  8 10:01:34.837: INFO: stderr: ""
Dec  8 10:01:34.837: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:01:34.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xzhbg" for this suite.
Dec  8 10:01:56.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:01:56.859: INFO: namespace: e2e-tests-kubectl-xzhbg, resource: bindings, ignored listing per whitelist
Dec  8 10:01:56.942: INFO: namespace e2e-tests-kubectl-xzhbg deletion completed in 22.102092711s

• [SLOW TEST:22.377 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:01:56.943: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-7vnn
STEP: Creating a pod to test atomic-volume-subpath
Dec  8 10:01:57.018: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7vnn" in namespace "e2e-tests-subpath-ch6tb" to be "success or failure"
Dec  8 10:01:57.021: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.87553ms
Dec  8 10:01:59.025: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006921177s
Dec  8 10:02:01.029: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 4.010767178s
Dec  8 10:02:03.032: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 6.014426762s
Dec  8 10:02:05.036: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 8.017854387s
Dec  8 10:02:07.039: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 10.021138911s
Dec  8 10:02:09.043: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 12.024646839s
Dec  8 10:02:11.046: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 14.028194862s
Dec  8 10:02:13.050: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 16.031696612s
Dec  8 10:02:15.053: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 18.035283563s
Dec  8 10:02:17.057: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 20.038856525s
Dec  8 10:02:19.060: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Running", Reason="", readiness=false. Elapsed: 22.042361213s
Dec  8 10:02:21.064: INFO: Pod "pod-subpath-test-configmap-7vnn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.046104447s
STEP: Saw pod success
Dec  8 10:02:21.064: INFO: Pod "pod-subpath-test-configmap-7vnn" satisfied condition "success or failure"
Dec  8 10:02:21.067: INFO: Trying to get logs from node conformance pod pod-subpath-test-configmap-7vnn container test-container-subpath-configmap-7vnn: <nil>
STEP: delete the pod
Dec  8 10:02:21.085: INFO: Waiting for pod pod-subpath-test-configmap-7vnn to disappear
Dec  8 10:02:21.088: INFO: Pod pod-subpath-test-configmap-7vnn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7vnn
Dec  8 10:02:21.088: INFO: Deleting pod "pod-subpath-test-configmap-7vnn" in namespace "e2e-tests-subpath-ch6tb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:02:21.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-ch6tb" for this suite.
Dec  8 10:02:27.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:02:27.197: INFO: namespace: e2e-tests-subpath-ch6tb, resource: bindings, ignored listing per whitelist
Dec  8 10:02:27.200: INFO: namespace e2e-tests-subpath-ch6tb deletion completed in 6.106821527s

• [SLOW TEST:30.257 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:02:27.200: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 10:02:27.278: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:02:29.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-zxcm9" for this suite.
Dec  8 10:03:07.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:03:07.412: INFO: namespace: e2e-tests-pods-zxcm9, resource: bindings, ignored listing per whitelist
Dec  8 10:03:07.479: INFO: namespace e2e-tests-pods-zxcm9 deletion completed in 38.092328384s

• [SLOW TEST:40.279 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:03:07.479: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  8 10:03:10.073: INFO: Successfully updated pod "labelsupdate760bed85-fad0-11e8-9888-1eca7d857bda"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:03:12.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-smr4j" for this suite.
Dec  8 10:03:34.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:03:34.140: INFO: namespace: e2e-tests-downward-api-smr4j, resource: bindings, ignored listing per whitelist
Dec  8 10:03:34.178: INFO: namespace e2e-tests-downward-api-smr4j deletion completed in 22.083473782s

• [SLOW TEST:26.699 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:03:34.178: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  8 10:03:34.245: INFO: Waiting up to 5m0s for pod "pod-85f563cb-fad0-11e8-9888-1eca7d857bda" in namespace "e2e-tests-emptydir-vmjvf" to be "success or failure"
Dec  8 10:03:34.247: INFO: Pod "pod-85f563cb-fad0-11e8-9888-1eca7d857bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.266681ms
Dec  8 10:03:36.251: INFO: Pod "pod-85f563cb-fad0-11e8-9888-1eca7d857bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005877314s
STEP: Saw pod success
Dec  8 10:03:36.251: INFO: Pod "pod-85f563cb-fad0-11e8-9888-1eca7d857bda" satisfied condition "success or failure"
Dec  8 10:03:36.253: INFO: Trying to get logs from node conformance pod pod-85f563cb-fad0-11e8-9888-1eca7d857bda container test-container: <nil>
STEP: delete the pod
Dec  8 10:03:36.273: INFO: Waiting for pod pod-85f563cb-fad0-11e8-9888-1eca7d857bda to disappear
Dec  8 10:03:36.276: INFO: Pod pod-85f563cb-fad0-11e8-9888-1eca7d857bda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:03:36.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vmjvf" for this suite.
Dec  8 10:03:42.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:03:42.348: INFO: namespace: e2e-tests-emptydir-vmjvf, resource: bindings, ignored listing per whitelist
Dec  8 10:03:42.380: INFO: namespace e2e-tests-emptydir-vmjvf deletion completed in 6.101283198s

• [SLOW TEST:8.202 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:03:42.380: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 10:03:42.433: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:03:44.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fcw6f" for this suite.
Dec  8 10:04:22.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:04:22.544: INFO: namespace: e2e-tests-pods-fcw6f, resource: bindings, ignored listing per whitelist
Dec  8 10:04:22.555: INFO: namespace e2e-tests-pods-fcw6f deletion completed in 38.088823576s

• [SLOW TEST:40.174 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:04:22.555: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-cmf99
Dec  8 10:04:24.635: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-cmf99
STEP: checking the pod's current state and verifying that restartCount is present
Dec  8 10:04:24.638: INFO: Initial restart count of pod liveness-http is 0
Dec  8 10:04:38.666: INFO: Restart count of pod e2e-tests-container-probe-cmf99/liveness-http is now 1 (14.027273855s elapsed)
Dec  8 10:04:58.701: INFO: Restart count of pod e2e-tests-container-probe-cmf99/liveness-http is now 2 (34.062794873s elapsed)
Dec  8 10:05:18.737: INFO: Restart count of pod e2e-tests-container-probe-cmf99/liveness-http is now 3 (54.098226349s elapsed)
Dec  8 10:05:38.774: INFO: Restart count of pod e2e-tests-container-probe-cmf99/liveness-http is now 4 (1m14.136087117s elapsed)
Dec  8 10:06:40.884: INFO: Restart count of pod e2e-tests-container-probe-cmf99/liveness-http is now 5 (2m16.245497178s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:06:40.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cmf99" for this suite.
Dec  8 10:06:46.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:06:46.934: INFO: namespace: e2e-tests-container-probe-cmf99, resource: bindings, ignored listing per whitelist
Dec  8 10:06:46.979: INFO: namespace e2e-tests-container-probe-cmf99 deletion completed in 6.084243607s

• [SLOW TEST:144.424 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Dec  8 10:06:46.979: INFO: >>> kubeConfig: /tmp/kubeconfig-866404302
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  8 10:07:11.062: INFO: Container started at 2018-12-08 10:06:47 +0000 UTC, pod became ready at 2018-12-08 10:07:10 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Dec  8 10:07:11.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-whpmg" for this suite.
Dec  8 10:07:33.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  8 10:07:33.157: INFO: namespace: e2e-tests-container-probe-whpmg, resource: bindings, ignored listing per whitelist
Dec  8 10:07:33.182: INFO: namespace e2e-tests-container-probe-whpmg deletion completed in 22.117724645s

• [SLOW TEST:46.204 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSDec  8 10:07:33.183: INFO: Running AfterSuite actions on all nodes
Dec  8 10:07:33.183: INFO: Running AfterSuite actions on node 1
Dec  8 10:07:33.183: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5575.122 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h32m56.149121289s
Test Suite Passed
