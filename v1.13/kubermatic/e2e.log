I0604 12:57:08.232272      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-063591806
I0604 12:57:08.232492      15 e2e.go:224] Starting e2e run "417a0c1b-86c8-11e9-8620-ba945f56578b" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1559653025 - Will randomize all specs
Will run 201 of 1946 specs

Jun  4 12:57:08.999: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 12:57:09.008: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jun  4 12:57:09.058: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun  4 12:57:09.164: INFO: 16 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun  4 12:57:09.164: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Jun  4 12:57:09.164: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jun  4 12:57:09.204: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'canal' (0 seconds elapsed)
Jun  4 12:57:09.204: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jun  4 12:57:09.204: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Jun  4 12:57:09.204: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Jun  4 12:57:09.204: INFO: e2e test version: v1.13.0
Jun  4 12:57:09.207: INFO: kube-apiserver version: v1.13.5
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 12:57:09.211: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
Jun  4 12:57:09.581: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jun  4 12:57:09.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-znbrd'
Jun  4 12:57:10.576: INFO: stderr: ""
Jun  4 12:57:10.576: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun  4 12:57:11.583: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 12:57:11.583: INFO: Found 0 / 1
Jun  4 12:57:12.582: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 12:57:12.582: INFO: Found 0 / 1
Jun  4 12:57:13.581: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 12:57:13.581: INFO: Found 0 / 1
Jun  4 12:57:14.583: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 12:57:14.584: INFO: Found 0 / 1
Jun  4 12:57:15.582: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 12:57:15.582: INFO: Found 0 / 1
Jun  4 12:57:16.584: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 12:57:16.584: INFO: Found 1 / 1
Jun  4 12:57:16.584: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jun  4 12:57:16.589: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 12:57:16.590: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun  4 12:57:16.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 patch pod redis-master-m5h8c --namespace=e2e-tests-kubectl-znbrd -p {"metadata":{"annotations":{"x":"y"}}}'
Jun  4 12:57:16.785: INFO: stderr: ""
Jun  4 12:57:16.785: INFO: stdout: "pod/redis-master-m5h8c patched\n"
STEP: checking annotations
Jun  4 12:57:16.846: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 12:57:16.846: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 12:57:16.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-znbrd" for this suite.
Jun  4 12:57:39.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 12:57:39.302: INFO: namespace: e2e-tests-kubectl-znbrd, resource: bindings, ignored listing per whitelist
Jun  4 12:57:39.659: INFO: namespace e2e-tests-kubectl-znbrd deletion completed in 22.807054661s

• [SLOW TEST:30.449 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 12:57:39.664: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0604 12:57:41.031344      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun  4 12:57:41.031: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 12:57:41.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-llh5w" for this suite.
Jun  4 12:57:47.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 12:57:47.503: INFO: namespace: e2e-tests-gc-llh5w, resource: bindings, ignored listing per whitelist
Jun  4 12:57:47.654: INFO: namespace e2e-tests-gc-llh5w deletion completed in 6.618662387s

• [SLOW TEST:7.992 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 12:57:47.659: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-x725q.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-x725q.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-x725q.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-x725q.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-x725q.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-x725q.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun  4 12:58:08.217: INFO: DNS probes using e2e-tests-dns-x725q/dns-test-5a65512e-86c8-11e9-8620-ba945f56578b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 12:58:08.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-x725q" for this suite.
Jun  4 12:58:14.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 12:58:14.891: INFO: namespace: e2e-tests-dns-x725q, resource: bindings, ignored listing per whitelist
Jun  4 12:58:14.894: INFO: namespace e2e-tests-dns-x725q deletion completed in 6.643236464s

• [SLOW TEST:27.235 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 12:58:14.897: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-7kg4l
Jun  4 12:58:21.246: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-7kg4l
STEP: checking the pod's current state and verifying that restartCount is present
Jun  4 12:58:21.251: INFO: Initial restart count of pod liveness-http is 0
Jun  4 12:58:37.368: INFO: Restart count of pod e2e-tests-container-probe-7kg4l/liveness-http is now 1 (16.116514772s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 12:58:37.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7kg4l" for this suite.
Jun  4 12:58:43.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 12:58:44.003: INFO: namespace: e2e-tests-container-probe-7kg4l, resource: bindings, ignored listing per whitelist
Jun  4 12:58:44.176: INFO: namespace e2e-tests-container-probe-7kg4l deletion completed in 6.75645937s

• [SLOW TEST:29.280 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 12:58:44.181: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun  4 12:58:44.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-jswdp'
Jun  4 12:58:44.742: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun  4 12:58:44.742: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jun  4 12:58:44.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-jswdp'
Jun  4 12:58:44.954: INFO: stderr: ""
Jun  4 12:58:44.955: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 12:58:44.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jswdp" for this suite.
Jun  4 12:58:51.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 12:58:51.357: INFO: namespace: e2e-tests-kubectl-jswdp, resource: bindings, ignored listing per whitelist
Jun  4 12:58:51.860: INFO: namespace e2e-tests-kubectl-jswdp deletion completed in 6.896490503s

• [SLOW TEST:7.679 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 12:58:51.865: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jun  4 12:59:00.365: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-80a1f6d0-86c8-11e9-8620-ba945f56578b", GenerateName:"", Namespace:"e2e-tests-pods-rlp8w", SelfLink:"/api/v1/namespaces/e2e-tests-pods-rlp8w/pods/pod-submit-remove-80a1f6d0-86c8-11e9-8620-ba945f56578b", UID:"80a35b4e-86c8-11e9-9957-a6a8fec88741", ResourceVersion:"8644", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63695249932, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"119017324"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8mwq2", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00050dfc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8mwq2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001cacfe8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-4jvsx-65d7bd6f69-45s5z", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0015b9da0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001cad020)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001cad040)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001cad048), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001cad04c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695249932, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695249940, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695249940, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695249932, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"138.68.109.151", PodIP:"172.25.1.5", StartTime:(*v1.Time)(0xc001a508c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001a508e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://b371acb0cad4ebd0faab22ed2a7d7051eb8a97c612169366e2f7ec17f841c06a"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jun  4 12:59:05.644: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 12:59:05.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rlp8w" for this suite.
Jun  4 12:59:11.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 12:59:12.159: INFO: namespace: e2e-tests-pods-rlp8w, resource: bindings, ignored listing per whitelist
Jun  4 12:59:12.287: INFO: namespace e2e-tests-pods-rlp8w deletion completed in 6.622305215s

• [SLOW TEST:20.423 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 12:59:12.291: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 12:59:19.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-br55p" for this suite.
Jun  4 13:00:03.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:00:03.580: INFO: namespace: e2e-tests-kubelet-test-br55p, resource: bindings, ignored listing per whitelist
Jun  4 13:00:03.779: INFO: namespace e2e-tests-kubelet-test-br55p deletion completed in 44.62659815s

• [SLOW TEST:51.489 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:00:03.783: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jun  4 13:00:04.271: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-063591806 proxy --unix-socket=/tmp/kubectl-proxy-unix695776453/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:00:04.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-95hmg" for this suite.
Jun  4 13:00:10.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:00:10.948: INFO: namespace: e2e-tests-kubectl-95hmg, resource: bindings, ignored listing per whitelist
Jun  4 13:00:11.253: INFO: namespace e2e-tests-kubectl-95hmg deletion completed in 6.79227522s

• [SLOW TEST:7.471 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:00:11.254: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:00:11.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-g2b6b" for this suite.
Jun  4 13:00:17.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:00:18.053: INFO: namespace: e2e-tests-services-g2b6b, resource: bindings, ignored listing per whitelist
Jun  4 13:00:18.289: INFO: namespace e2e-tests-services-g2b6b deletion completed in 6.644507283s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:7.035 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:00:18.294: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:00:51.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-6zlcw" for this suite.
Jun  4 13:00:58.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:00:58.552: INFO: namespace: e2e-tests-container-runtime-6zlcw, resource: bindings, ignored listing per whitelist
Jun  4 13:00:58.850: INFO: namespace e2e-tests-container-runtime-6zlcw deletion completed in 6.860471064s

• [SLOW TEST:40.557 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:00:58.851: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-cc5ff1fc-86c8-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 13:00:59.343: INFO: Waiting up to 5m0s for pod "pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-cssn7" to be "success or failure"
Jun  4 13:00:59.351: INFO: Pod "pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.794512ms
Jun  4 13:01:01.446: INFO: Pod "pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10353248s
Jun  4 13:01:03.451: INFO: Pod "pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.108540077s
Jun  4 13:01:05.546: INFO: Pod "pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.203121746s
STEP: Saw pod success
Jun  4 13:01:05.546: INFO: Pod "pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:01:05.550: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b container secret-volume-test: <nil>
STEP: delete the pod
Jun  4 13:01:05.661: INFO: Waiting for pod pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b to disappear
Jun  4 13:01:05.666: INFO: Pod pod-secrets-cc6aebbc-86c8-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:01:05.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cssn7" for this suite.
Jun  4 13:01:11.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:01:11.887: INFO: namespace: e2e-tests-secrets-cssn7, resource: bindings, ignored listing per whitelist
Jun  4 13:01:12.356: INFO: namespace e2e-tests-secrets-cssn7 deletion completed in 6.68043805s
STEP: Destroying namespace "e2e-tests-secret-namespace-8m5jn" for this suite.
Jun  4 13:01:18.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:01:18.776: INFO: namespace: e2e-tests-secret-namespace-8m5jn, resource: bindings, ignored listing per whitelist
Jun  4 13:01:18.802: INFO: namespace e2e-tests-secret-namespace-8m5jn deletion completed in 6.444546692s

• [SLOW TEST:19.950 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:01:18.803: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:01:38.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-vrx4n" for this suite.
Jun  4 13:02:00.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:02:00.586: INFO: namespace: e2e-tests-replication-controller-vrx4n, resource: bindings, ignored listing per whitelist
Jun  4 13:02:00.727: INFO: namespace e2e-tests-replication-controller-vrx4n deletion completed in 22.475768097s

• [SLOW TEST:41.925 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:02:00.732: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:02:05.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-sg28g" for this suite.
Jun  4 13:02:11.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:02:11.588: INFO: namespace: e2e-tests-kubelet-test-sg28g, resource: bindings, ignored listing per whitelist
Jun  4 13:02:11.858: INFO: namespace e2e-tests-kubelet-test-sg28g deletion completed in 6.601213129s

• [SLOW TEST:11.126 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:02:11.859: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun  4 13:02:12.274: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun  4 13:02:12.345: INFO: Waiting for terminating namespaces to be deleted...
Jun  4 13:02:12.359: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-45s5z before test
Jun  4 13:02:12.538: INFO: kube-proxy-nf7p7 from kube-system started at 2019-06-04 12:09:31 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.538: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:02:12.538: INFO: canal-76cwl from kube-system started at 2019-06-04 12:09:32 +0000 UTC (3 container statuses recorded)
Jun  4 13:02:12.539: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:02:12.539: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:02:12.539: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:02:12.539: INFO: node-exporter-w8mpm from kube-system started at 2019-06-04 12:09:32 +0000 UTC (2 container statuses recorded)
Jun  4 13:02:12.539: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:02:12.540: INFO: 	Container node-exporter ready: true, restart count 0
Jun  4 13:02:12.540: INFO: node-local-dns-j6q7n from kube-system started at 2019-06-04 12:10:12 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.540: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:02:12.540: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-04 12:56:20 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.540: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun  4 13:02:12.540: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-79nwm from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:02:12.541: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:02:12.541: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:02:12.541: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-4wzp4 before test
Jun  4 13:02:12.602: INFO: node-local-dns-cr5nd from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.602: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:02:12.602: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-bng6b from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:02:12.602: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:02:12.603: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:02:12.603: INFO: node-exporter-h5rs4 from kube-system started at 2019-06-04 12:09:29 +0000 UTC (2 container statuses recorded)
Jun  4 13:02:12.603: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:02:12.603: INFO: 	Container node-exporter ready: true, restart count 0
Jun  4 13:02:12.603: INFO: coredns-847fd8cc79-6tz5w from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.604: INFO: 	Container coredns ready: true, restart count 0
Jun  4 13:02:12.604: INFO: kubernetes-dashboard-69989d6597-ssww6 from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.604: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun  4 13:02:12.604: INFO: openvpn-client-cf455948c-2kz4k from kube-system started at 2019-06-04 12:10:09 +0000 UTC (2 container statuses recorded)
Jun  4 13:02:12.604: INFO: 	Container dnat-controller ready: true, restart count 0
Jun  4 13:02:12.604: INFO: 	Container openvpn-client ready: true, restart count 0
Jun  4 13:02:12.605: INFO: kube-proxy-j6nh9 from kube-system started at 2019-06-04 12:09:29 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.605: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:02:12.605: INFO: canal-pkkpj from kube-system started at 2019-06-04 12:09:29 +0000 UTC (3 container statuses recorded)
Jun  4 13:02:12.605: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:02:12.605: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:02:12.606: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:02:12.606: INFO: coredns-847fd8cc79-56mp9 from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.606: INFO: 	Container coredns ready: true, restart count 0
Jun  4 13:02:12.606: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-gv9cg before test
Jun  4 13:02:12.702: INFO: node-local-dns-v7xcp from kube-system started at 2019-06-04 12:10:35 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.703: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:02:12.703: INFO: sonobuoy-e2e-job-3ad4d89decb14678 from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:02:12.703: INFO: 	Container e2e ready: true, restart count 0
Jun  4 13:02:12.703: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:02:12.704: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-c7fnn from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:02:12.704: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:02:12.704: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:02:12.704: INFO: kube-proxy-j2gp8 from kube-system started at 2019-06-04 12:09:45 +0000 UTC (1 container statuses recorded)
Jun  4 13:02:12.704: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:02:12.705: INFO: canal-9xpkc from kube-system started at 2019-06-04 12:09:45 +0000 UTC (3 container statuses recorded)
Jun  4 13:02:12.705: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:02:12.705: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:02:12.705: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:02:12.705: INFO: node-exporter-k5l47 from kube-system started at 2019-06-04 12:09:45 +0000 UTC (2 container statuses recorded)
Jun  4 13:02:12.705: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:02:12.706: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node worker-4jvsx-65d7bd6f69-45s5z
STEP: verifying the node has the label node worker-4jvsx-65d7bd6f69-4wzp4
STEP: verifying the node has the label node worker-4jvsx-65d7bd6f69-gv9cg
Jun  4 13:02:12.813: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker-4jvsx-65d7bd6f69-45s5z
Jun  4 13:02:12.814: INFO: Pod sonobuoy-e2e-job-3ad4d89decb14678 requesting resource cpu=0m on Node worker-4jvsx-65d7bd6f69-gv9cg
Jun  4 13:02:12.814: INFO: Pod sonobuoy-systemd-logs-daemon-set-eac461d668c54200-79nwm requesting resource cpu=0m on Node worker-4jvsx-65d7bd6f69-45s5z
Jun  4 13:02:12.814: INFO: Pod sonobuoy-systemd-logs-daemon-set-eac461d668c54200-bng6b requesting resource cpu=0m on Node worker-4jvsx-65d7bd6f69-4wzp4
Jun  4 13:02:12.814: INFO: Pod sonobuoy-systemd-logs-daemon-set-eac461d668c54200-c7fnn requesting resource cpu=0m on Node worker-4jvsx-65d7bd6f69-gv9cg
Jun  4 13:02:12.814: INFO: Pod canal-76cwl requesting resource cpu=350m on Node worker-4jvsx-65d7bd6f69-45s5z
Jun  4 13:02:12.815: INFO: Pod canal-9xpkc requesting resource cpu=350m on Node worker-4jvsx-65d7bd6f69-gv9cg
Jun  4 13:02:12.815: INFO: Pod canal-pkkpj requesting resource cpu=350m on Node worker-4jvsx-65d7bd6f69-4wzp4
Jun  4 13:02:12.815: INFO: Pod coredns-847fd8cc79-56mp9 requesting resource cpu=100m on Node worker-4jvsx-65d7bd6f69-4wzp4
Jun  4 13:02:12.815: INFO: Pod coredns-847fd8cc79-6tz5w requesting resource cpu=100m on Node worker-4jvsx-65d7bd6f69-4wzp4
Jun  4 13:02:12.815: INFO: Pod kube-proxy-j2gp8 requesting resource cpu=75m on Node worker-4jvsx-65d7bd6f69-gv9cg
Jun  4 13:02:12.816: INFO: Pod kube-proxy-j6nh9 requesting resource cpu=75m on Node worker-4jvsx-65d7bd6f69-4wzp4
Jun  4 13:02:12.816: INFO: Pod kube-proxy-nf7p7 requesting resource cpu=75m on Node worker-4jvsx-65d7bd6f69-45s5z
Jun  4 13:02:12.816: INFO: Pod kubernetes-dashboard-69989d6597-ssww6 requesting resource cpu=75m on Node worker-4jvsx-65d7bd6f69-4wzp4
Jun  4 13:02:12.816: INFO: Pod node-exporter-h5rs4 requesting resource cpu=20m on Node worker-4jvsx-65d7bd6f69-4wzp4
Jun  4 13:02:12.817: INFO: Pod node-exporter-k5l47 requesting resource cpu=20m on Node worker-4jvsx-65d7bd6f69-gv9cg
Jun  4 13:02:12.817: INFO: Pod node-exporter-w8mpm requesting resource cpu=20m on Node worker-4jvsx-65d7bd6f69-45s5z
Jun  4 13:02:12.817: INFO: Pod node-local-dns-cr5nd requesting resource cpu=25m on Node worker-4jvsx-65d7bd6f69-4wzp4
Jun  4 13:02:12.817: INFO: Pod node-local-dns-j6q7n requesting resource cpu=25m on Node worker-4jvsx-65d7bd6f69-45s5z
Jun  4 13:02:12.818: INFO: Pod node-local-dns-v7xcp requesting resource cpu=25m on Node worker-4jvsx-65d7bd6f69-gv9cg
Jun  4 13:02:12.818: INFO: Pod openvpn-client-cf455948c-2kz4k requesting resource cpu=30m on Node worker-4jvsx-65d7bd6f69-4wzp4
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f8424d2e-86c8-11e9-8620-ba945f56578b.15a500715ce5a57c], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-xlf9z/filler-pod-f8424d2e-86c8-11e9-8620-ba945f56578b to worker-4jvsx-65d7bd6f69-45s5z]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f8424d2e-86c8-11e9-8620-ba945f56578b.15a50071dc03024c], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f8424d2e-86c8-11e9-8620-ba945f56578b.15a50071e07e9a83], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f8424d2e-86c8-11e9-8620-ba945f56578b.15a50072065b2f35], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f844aa11-86c8-11e9-8620-ba945f56578b.15a500715e03cd2a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-xlf9z/filler-pod-f844aa11-86c8-11e9-8620-ba945f56578b to worker-4jvsx-65d7bd6f69-4wzp4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f844aa11-86c8-11e9-8620-ba945f56578b.15a5007231f02730], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f844aa11-86c8-11e9-8620-ba945f56578b.15a500723498f333], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f844aa11-86c8-11e9-8620-ba945f56578b.15a50072ccd83132], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f847eb6c-86c8-11e9-8620-ba945f56578b.15a500715f5b1f0a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-xlf9z/filler-pod-f847eb6c-86c8-11e9-8620-ba945f56578b to worker-4jvsx-65d7bd6f69-gv9cg]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f847eb6c-86c8-11e9-8620-ba945f56578b.15a50071a579c062], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f847eb6c-86c8-11e9-8620-ba945f56578b.15a50071a8071a01], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f847eb6c-86c8-11e9-8620-ba945f56578b.15a50071be9d2293], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15a50073454bb664], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node worker-4jvsx-65d7bd6f69-45s5z
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker-4jvsx-65d7bd6f69-4wzp4
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker-4jvsx-65d7bd6f69-gv9cg
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:02:22.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-xlf9z" for this suite.
Jun  4 13:02:28.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:02:28.561: INFO: namespace: e2e-tests-sched-pred-xlf9z, resource: bindings, ignored listing per whitelist
Jun  4 13:02:28.760: INFO: namespace e2e-tests-sched-pred-xlf9z deletion completed in 6.494564142s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:16.902 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:02:28.765: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gb9lz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun  4 13:02:29.243: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun  4 13:02:53.467: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.25.1.14 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gb9lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:02:53.467: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:02:55.150: INFO: Found all expected endpoints: [netserver-0]
Jun  4 13:02:55.157: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.25.0.8 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gb9lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:02:55.157: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:02:56.842: INFO: Found all expected endpoints: [netserver-1]
Jun  4 13:02:56.941: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.25.2.4 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gb9lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:02:56.941: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:02:58.695: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:02:58.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gb9lz" for this suite.
Jun  4 13:03:20.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:03:20.986: INFO: namespace: e2e-tests-pod-network-test-gb9lz, resource: bindings, ignored listing per whitelist
Jun  4 13:03:21.084: INFO: namespace e2e-tests-pod-network-test-gb9lz deletion completed in 22.380532048s

• [SLOW TEST:52.319 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:03:21.089: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-sggkr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sggkr to expose endpoints map[]
Jun  4 13:03:21.427: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sggkr exposes endpoints map[] (22.597093ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-sggkr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sggkr to expose endpoints map[pod1:[100]]
Jun  4 13:03:24.661: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sggkr exposes endpoints map[pod1:[100]] (3.220208173s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-sggkr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sggkr to expose endpoints map[pod1:[100] pod2:[101]]
Jun  4 13:03:27.796: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sggkr exposes endpoints map[pod1:[100] pod2:[101]] (3.124851973s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-sggkr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sggkr to expose endpoints map[pod2:[101]]
Jun  4 13:03:27.823: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sggkr exposes endpoints map[pod2:[101]] (15.997476ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-sggkr
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-sggkr to expose endpoints map[]
Jun  4 13:03:27.843: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-sggkr exposes endpoints map[] (9.39119ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:03:27.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-sggkr" for this suite.
Jun  4 13:03:49.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:03:50.058: INFO: namespace: e2e-tests-services-sggkr, resource: bindings, ignored listing per whitelist
Jun  4 13:03:50.370: INFO: namespace e2e-tests-services-sggkr deletion completed in 22.486242097s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.282 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:03:50.380: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun  4 13:03:50.884: INFO: Waiting up to 5m0s for pod "pod-32b46281-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-dcv8q" to be "success or failure"
Jun  4 13:03:50.892: INFO: Pod "pod-32b46281-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.988166ms
Jun  4 13:03:52.945: INFO: Pod "pod-32b46281-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.060853668s
Jun  4 13:03:54.951: INFO: Pod "pod-32b46281-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067110146s
STEP: Saw pod success
Jun  4 13:03:54.952: INFO: Pod "pod-32b46281-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:03:54.957: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-32b46281-86c9-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:03:55.062: INFO: Waiting for pod pod-32b46281-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:03:55.148: INFO: Pod pod-32b46281-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:03:55.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dcv8q" for this suite.
Jun  4 13:04:01.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:04:01.730: INFO: namespace: e2e-tests-emptydir-dcv8q, resource: bindings, ignored listing per whitelist
Jun  4 13:04:01.743: INFO: namespace e2e-tests-emptydir-dcv8q deletion completed in 6.579695176s

• [SLOW TEST:11.364 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:04:01.751: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 13:04:01.953: INFO: Waiting up to 5m0s for pod "downwardapi-volume-394d68ea-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-djf8n" to be "success or failure"
Jun  4 13:04:01.959: INFO: Pod "downwardapi-volume-394d68ea-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.076464ms
Jun  4 13:04:03.968: INFO: Pod "downwardapi-volume-394d68ea-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014773877s
Jun  4 13:04:05.975: INFO: Pod "downwardapi-volume-394d68ea-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021696065s
STEP: Saw pod success
Jun  4 13:04:05.975: INFO: Pod "downwardapi-volume-394d68ea-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:04:05.979: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-394d68ea-86c9-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 13:04:06.140: INFO: Waiting for pod downwardapi-volume-394d68ea-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:04:06.145: INFO: Pod downwardapi-volume-394d68ea-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:04:06.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-djf8n" for this suite.
Jun  4 13:04:12.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:04:12.660: INFO: namespace: e2e-tests-downward-api-djf8n, resource: bindings, ignored listing per whitelist
Jun  4 13:04:12.801: INFO: namespace e2e-tests-downward-api-djf8n deletion completed in 6.650691582s

• [SLOW TEST:11.050 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:04:12.802: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 13:04:13.328: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40137850-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-wj7dx" to be "success or failure"
Jun  4 13:04:13.338: INFO: Pod "downwardapi-volume-40137850-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.573365ms
Jun  4 13:04:15.346: INFO: Pod "downwardapi-volume-40137850-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018050455s
Jun  4 13:04:17.351: INFO: Pod "downwardapi-volume-40137850-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023308505s
STEP: Saw pod success
Jun  4 13:04:17.351: INFO: Pod "downwardapi-volume-40137850-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:04:17.356: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-40137850-86c9-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 13:04:17.569: INFO: Waiting for pod downwardapi-volume-40137850-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:04:17.573: INFO: Pod downwardapi-volume-40137850-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:04:17.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wj7dx" for this suite.
Jun  4 13:04:23.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:04:24.183: INFO: namespace: e2e-tests-downward-api-wj7dx, resource: bindings, ignored listing per whitelist
Jun  4 13:04:24.183: INFO: namespace e2e-tests-downward-api-wj7dx deletion completed in 6.603194382s

• [SLOW TEST:11.382 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:04:24.190: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-5xl7
STEP: Creating a pod to test atomic-volume-subpath
Jun  4 13:04:24.631: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-5xl7" in namespace "e2e-tests-subpath-5dpn7" to be "success or failure"
Jun  4 13:04:24.648: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.514932ms
Jun  4 13:04:26.653: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022067143s
Jun  4 13:04:28.660: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028222362s
Jun  4 13:04:30.665: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033667688s
Jun  4 13:04:32.671: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 8.039624819s
Jun  4 13:04:34.677: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 10.046072318s
Jun  4 13:04:36.683: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 12.051948103s
Jun  4 13:04:38.690: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 14.058218204s
Jun  4 13:04:40.696: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 16.064970524s
Jun  4 13:04:42.750: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 18.118995336s
Jun  4 13:04:44.940: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 20.308241156s
Jun  4 13:04:46.945: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 22.313173182s
Jun  4 13:04:49.038: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 24.407009098s
Jun  4 13:04:51.060: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Running", Reason="", readiness=false. Elapsed: 26.428381078s
Jun  4 13:04:53.142: INFO: Pod "pod-subpath-test-downwardapi-5xl7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.511120372s
STEP: Saw pod success
Jun  4 13:04:53.143: INFO: Pod "pod-subpath-test-downwardapi-5xl7" satisfied condition "success or failure"
Jun  4 13:04:53.153: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-4wzp4 pod pod-subpath-test-downwardapi-5xl7 container test-container-subpath-downwardapi-5xl7: <nil>
STEP: delete the pod
Jun  4 13:04:53.341: INFO: Waiting for pod pod-subpath-test-downwardapi-5xl7 to disappear
Jun  4 13:04:53.348: INFO: Pod pod-subpath-test-downwardapi-5xl7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-5xl7
Jun  4 13:04:53.349: INFO: Deleting pod "pod-subpath-test-downwardapi-5xl7" in namespace "e2e-tests-subpath-5dpn7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:04:53.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5dpn7" for this suite.
Jun  4 13:04:59.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:04:59.895: INFO: namespace: e2e-tests-subpath-5dpn7, resource: bindings, ignored listing per whitelist
Jun  4 13:05:00.048: INFO: namespace e2e-tests-subpath-5dpn7 deletion completed in 6.607608164s

• [SLOW TEST:35.859 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:05:00.057: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jun  4 13:05:00.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 cluster-info'
Jun  4 13:05:00.557: INFO: stderr: ""
Jun  4 13:05:00.557: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.10.10.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.10.10.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:05:00.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d2q5d" for this suite.
Jun  4 13:05:06.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:05:06.935: INFO: namespace: e2e-tests-kubectl-d2q5d, resource: bindings, ignored listing per whitelist
Jun  4 13:05:07.065: INFO: namespace e2e-tests-kubectl-d2q5d deletion completed in 6.503063238s

• [SLOW TEST:7.009 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:05:07.070: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun  4 13:05:07.356: INFO: Waiting up to 5m0s for pod "pod-60491950-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-nsz2j" to be "success or failure"
Jun  4 13:05:07.361: INFO: Pod "pod-60491950-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.456705ms
Jun  4 13:05:09.368: INFO: Pod "pod-60491950-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011041074s
Jun  4 13:05:11.540: INFO: Pod "pod-60491950-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.183070961s
STEP: Saw pod success
Jun  4 13:05:11.540: INFO: Pod "pod-60491950-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:05:11.561: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-60491950-86c9-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:05:11.675: INFO: Waiting for pod pod-60491950-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:05:11.679: INFO: Pod pod-60491950-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:05:11.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nsz2j" for this suite.
Jun  4 13:05:17.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:05:18.155: INFO: namespace: e2e-tests-emptydir-nsz2j, resource: bindings, ignored listing per whitelist
Jun  4 13:05:18.524: INFO: namespace e2e-tests-emptydir-nsz2j deletion completed in 6.839131638s

• [SLOW TEST:11.455 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:05:18.525: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0604 13:05:29.154460      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun  4 13:05:29.154: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:05:29.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-dk6dv" for this suite.
Jun  4 13:05:35.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:05:35.460: INFO: namespace: e2e-tests-gc-dk6dv, resource: bindings, ignored listing per whitelist
Jun  4 13:05:35.845: INFO: namespace e2e-tests-gc-dk6dv deletion completed in 6.685768303s

• [SLOW TEST:17.320 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:05:35.851: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun  4 13:05:36.074: INFO: Waiting up to 5m0s for pod "pod-71673e24-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-w27xs" to be "success or failure"
Jun  4 13:05:36.081: INFO: Pod "pod-71673e24-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.322875ms
Jun  4 13:05:38.087: INFO: Pod "pod-71673e24-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012908417s
Jun  4 13:05:40.092: INFO: Pod "pod-71673e24-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018430593s
Jun  4 13:05:42.098: INFO: Pod "pod-71673e24-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023841803s
Jun  4 13:05:44.142: INFO: Pod "pod-71673e24-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.068505969s
STEP: Saw pod success
Jun  4 13:05:44.143: INFO: Pod "pod-71673e24-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:05:44.150: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-71673e24-86c9-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:05:44.258: INFO: Waiting for pod pod-71673e24-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:05:44.266: INFO: Pod pod-71673e24-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:05:44.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w27xs" for this suite.
Jun  4 13:05:50.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:05:50.565: INFO: namespace: e2e-tests-emptydir-w27xs, resource: bindings, ignored listing per whitelist
Jun  4 13:05:51.048: INFO: namespace e2e-tests-emptydir-w27xs deletion completed in 6.774315428s

• [SLOW TEST:15.197 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:05:51.050: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-7a87377a-86c9-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 13:05:51.388: INFO: Waiting up to 5m0s for pod "pod-secrets-7a881828-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-4ccxg" to be "success or failure"
Jun  4 13:05:51.393: INFO: Pod "pod-secrets-7a881828-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.986297ms
Jun  4 13:05:53.454: INFO: Pod "pod-secrets-7a881828-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065388406s
Jun  4 13:05:55.461: INFO: Pod "pod-secrets-7a881828-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.072208626s
STEP: Saw pod success
Jun  4 13:05:55.461: INFO: Pod "pod-secrets-7a881828-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:05:55.465: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-secrets-7a881828-86c9-11e9-8620-ba945f56578b container secret-volume-test: <nil>
STEP: delete the pod
Jun  4 13:05:55.565: INFO: Waiting for pod pod-secrets-7a881828-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:05:55.571: INFO: Pod pod-secrets-7a881828-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:05:55.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4ccxg" for this suite.
Jun  4 13:06:01.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:06:02.233: INFO: namespace: e2e-tests-secrets-4ccxg, resource: bindings, ignored listing per whitelist
Jun  4 13:06:02.455: INFO: namespace e2e-tests-secrets-4ccxg deletion completed in 6.87700631s

• [SLOW TEST:11.406 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:06:02.460: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jun  4 13:06:09.869: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:06:10.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7dbzw" for this suite.
Jun  4 13:06:33.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:06:33.345: INFO: namespace: e2e-tests-replicaset-7dbzw, resource: bindings, ignored listing per whitelist
Jun  4 13:06:33.852: INFO: namespace e2e-tests-replicaset-7dbzw deletion completed in 22.811365886s

• [SLOW TEST:31.393 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:06:33.857: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-94283c66-86c9-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:06:34.387: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9429313c-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-fw9t6" to be "success or failure"
Jun  4 13:06:34.392: INFO: Pod "pod-projected-configmaps-9429313c-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.303668ms
Jun  4 13:06:36.397: INFO: Pod "pod-projected-configmaps-9429313c-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009734832s
Jun  4 13:06:38.443: INFO: Pod "pod-projected-configmaps-9429313c-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055885829s
STEP: Saw pod success
Jun  4 13:06:38.443: INFO: Pod "pod-projected-configmaps-9429313c-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:06:38.448: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-configmaps-9429313c-86c9-11e9-8620-ba945f56578b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:06:38.558: INFO: Waiting for pod pod-projected-configmaps-9429313c-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:06:38.562: INFO: Pod pod-projected-configmaps-9429313c-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:06:38.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fw9t6" for this suite.
Jun  4 13:06:44.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:06:45.339: INFO: namespace: e2e-tests-projected-fw9t6, resource: bindings, ignored listing per whitelist
Jun  4 13:06:45.359: INFO: namespace e2e-tests-projected-fw9t6 deletion completed in 6.79004956s

• [SLOW TEST:11.504 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:06:45.364: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun  4 13:06:45.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-hnwff'
Jun  4 13:06:46.016: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun  4 13:06:46.016: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jun  4 13:06:46.039: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jun  4 13:06:46.046: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jun  4 13:06:46.057: INFO: scanned /root for discovery docs: <nil>
Jun  4 13:06:46.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-hnwff'
Jun  4 13:07:02.210: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun  4 13:07:02.210: INFO: stdout: "Created e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543\nScaling up e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jun  4 13:07:02.210: INFO: stdout: "Created e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543\nScaling up e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jun  4 13:07:02.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-hnwff'
Jun  4 13:07:02.433: INFO: stderr: ""
Jun  4 13:07:02.433: INFO: stdout: "e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543-czw9w "
Jun  4 13:07:02.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543-czw9w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hnwff'
Jun  4 13:07:02.646: INFO: stderr: ""
Jun  4 13:07:02.646: INFO: stdout: "true"
Jun  4 13:07:02.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543-czw9w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hnwff'
Jun  4 13:07:02.830: INFO: stderr: ""
Jun  4 13:07:02.830: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jun  4 13:07:02.830: INFO: e2e-test-nginx-rc-5b33ab37fd6396f5f80cb977ec8aa543-czw9w is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Jun  4 13:07:02.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-hnwff'
Jun  4 13:07:03.035: INFO: stderr: ""
Jun  4 13:07:03.035: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:07:03.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hnwff" for this suite.
Jun  4 13:07:09.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:07:09.469: INFO: namespace: e2e-tests-kubectl-hnwff, resource: bindings, ignored listing per whitelist
Jun  4 13:07:09.543: INFO: namespace e2e-tests-kubectl-hnwff deletion completed in 6.497741255s

• [SLOW TEST:24.179 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:07:09.544: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-nbxg
STEP: Creating a pod to test atomic-volume-subpath
Jun  4 13:07:09.987: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nbxg" in namespace "e2e-tests-subpath-gr4kq" to be "success or failure"
Jun  4 13:07:09.996: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Pending", Reason="", readiness=false. Elapsed: 8.139891ms
Jun  4 13:07:12.002: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014256109s
Jun  4 13:07:14.008: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02054256s
Jun  4 13:07:16.014: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 6.02629018s
Jun  4 13:07:18.045: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 8.057181626s
Jun  4 13:07:20.052: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 10.063872359s
Jun  4 13:07:22.059: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 12.070834261s
Jun  4 13:07:24.143: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 14.154935611s
Jun  4 13:07:26.150: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 16.162728332s
Jun  4 13:07:28.164: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 18.176789561s
Jun  4 13:07:30.343: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 20.355217919s
Jun  4 13:07:32.354: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Running", Reason="", readiness=false. Elapsed: 22.365873745s
Jun  4 13:07:34.361: INFO: Pod "pod-subpath-test-configmap-nbxg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.373367882s
STEP: Saw pod success
Jun  4 13:07:34.362: INFO: Pod "pod-subpath-test-configmap-nbxg" satisfied condition "success or failure"
Jun  4 13:07:34.367: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-subpath-test-configmap-nbxg container test-container-subpath-configmap-nbxg: <nil>
STEP: delete the pod
Jun  4 13:07:34.418: INFO: Waiting for pod pod-subpath-test-configmap-nbxg to disappear
Jun  4 13:07:34.425: INFO: Pod pod-subpath-test-configmap-nbxg no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nbxg
Jun  4 13:07:34.425: INFO: Deleting pod "pod-subpath-test-configmap-nbxg" in namespace "e2e-tests-subpath-gr4kq"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:07:34.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gr4kq" for this suite.
Jun  4 13:07:40.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:07:40.946: INFO: namespace: e2e-tests-subpath-gr4kq, resource: bindings, ignored listing per whitelist
Jun  4 13:07:40.972: INFO: namespace e2e-tests-subpath-gr4kq deletion completed in 6.531349753s

• [SLOW TEST:31.428 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:07:40.977: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bc346823-86c9-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 13:07:41.584: INFO: Waiting up to 5m0s for pod "pod-secrets-bc3640c2-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-4sddf" to be "success or failure"
Jun  4 13:07:41.588: INFO: Pod "pod-secrets-bc3640c2-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.043694ms
Jun  4 13:07:43.593: INFO: Pod "pod-secrets-bc3640c2-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00902106s
Jun  4 13:07:45.739: INFO: Pod "pod-secrets-bc3640c2-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.154791978s
STEP: Saw pod success
Jun  4 13:07:45.739: INFO: Pod "pod-secrets-bc3640c2-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:07:45.744: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-secrets-bc3640c2-86c9-11e9-8620-ba945f56578b container secret-env-test: <nil>
STEP: delete the pod
Jun  4 13:07:45.938: INFO: Waiting for pod pod-secrets-bc3640c2-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:07:46.043: INFO: Pod pod-secrets-bc3640c2-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:07:46.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4sddf" for this suite.
Jun  4 13:07:52.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:07:52.626: INFO: namespace: e2e-tests-secrets-4sddf, resource: bindings, ignored listing per whitelist
Jun  4 13:07:52.637: INFO: namespace e2e-tests-secrets-4sddf deletion completed in 6.587340625s

• [SLOW TEST:11.661 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:07:52.645: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c2f22f33-86c9-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:07:52.888: INFO: Waiting up to 5m0s for pod "pod-configmaps-c2f3092d-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-nbxd2" to be "success or failure"
Jun  4 13:07:52.896: INFO: Pod "pod-configmaps-c2f3092d-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.855089ms
Jun  4 13:07:54.944: INFO: Pod "pod-configmaps-c2f3092d-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055223358s
Jun  4 13:07:56.955: INFO: Pod "pod-configmaps-c2f3092d-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066447704s
STEP: Saw pod success
Jun  4 13:07:56.955: INFO: Pod "pod-configmaps-c2f3092d-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:07:57.038: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-c2f3092d-86c9-11e9-8620-ba945f56578b container configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:07:57.067: INFO: Waiting for pod pod-configmaps-c2f3092d-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:07:57.073: INFO: Pod pod-configmaps-c2f3092d-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:07:57.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nbxd2" for this suite.
Jun  4 13:08:03.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:08:03.772: INFO: namespace: e2e-tests-configmap-nbxd2, resource: bindings, ignored listing per whitelist
Jun  4 13:08:04.093: INFO: namespace e2e-tests-configmap-nbxd2 deletion completed in 6.953890402s

• [SLOW TEST:11.449 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:08:04.094: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c9d7fa43-86c9-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 13:08:04.462: INFO: Waiting up to 5m0s for pod "pod-secrets-c9d954bc-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-f4f77" to be "success or failure"
Jun  4 13:08:04.470: INFO: Pod "pod-secrets-c9d954bc-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.228606ms
Jun  4 13:08:06.547: INFO: Pod "pod-secrets-c9d954bc-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084431596s
Jun  4 13:08:08.643: INFO: Pod "pod-secrets-c9d954bc-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.180367479s
STEP: Saw pod success
Jun  4 13:08:08.643: INFO: Pod "pod-secrets-c9d954bc-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:08:08.647: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-secrets-c9d954bc-86c9-11e9-8620-ba945f56578b container secret-volume-test: <nil>
STEP: delete the pod
Jun  4 13:08:08.755: INFO: Waiting for pod pod-secrets-c9d954bc-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:08:08.760: INFO: Pod pod-secrets-c9d954bc-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:08:08.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-f4f77" for this suite.
Jun  4 13:08:14.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:08:15.132: INFO: namespace: e2e-tests-secrets-f4f77, resource: bindings, ignored listing per whitelist
Jun  4 13:08:15.345: INFO: namespace e2e-tests-secrets-f4f77 deletion completed in 6.577732441s

• [SLOW TEST:11.251 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:08:15.351: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun  4 13:08:15.700: INFO: Waiting up to 5m0s for pod "downward-api-d08ab6ab-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-xzs7t" to be "success or failure"
Jun  4 13:08:15.738: INFO: Pod "downward-api-d08ab6ab-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 37.493914ms
Jun  4 13:08:17.744: INFO: Pod "downward-api-d08ab6ab-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043470779s
Jun  4 13:08:19.751: INFO: Pod "downward-api-d08ab6ab-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049975217s
STEP: Saw pod success
Jun  4 13:08:19.751: INFO: Pod "downward-api-d08ab6ab-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:08:19.754: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downward-api-d08ab6ab-86c9-11e9-8620-ba945f56578b container dapi-container: <nil>
STEP: delete the pod
Jun  4 13:08:19.859: INFO: Waiting for pod downward-api-d08ab6ab-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:08:19.867: INFO: Pod downward-api-d08ab6ab-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:08:19.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xzs7t" for this suite.
Jun  4 13:08:25.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:08:26.213: INFO: namespace: e2e-tests-downward-api-xzs7t, resource: bindings, ignored listing per whitelist
Jun  4 13:08:26.263: INFO: namespace e2e-tests-downward-api-xzs7t deletion completed in 6.390012581s

• [SLOW TEST:10.913 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:08:26.268: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun  4 13:08:39.049: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:39.056: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:41.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:41.141: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:43.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:43.062: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:45.059: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:45.143: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:47.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:47.061: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:49.057: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:49.063: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:51.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:51.063: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:53.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:53.142: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:55.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:55.062: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:57.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:57.135: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:08:59.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:08:59.062: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:09:01.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:09:01.066: INFO: Pod pod-with-poststart-exec-hook still exists
Jun  4 13:09:03.056: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun  4 13:09:03.133: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:09:03.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-2452w" for this suite.
Jun  4 13:09:27.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:09:27.488: INFO: namespace: e2e-tests-container-lifecycle-hook-2452w, resource: bindings, ignored listing per whitelist
Jun  4 13:09:27.683: INFO: namespace e2e-tests-container-lifecycle-hook-2452w deletion completed in 24.539700929s

• [SLOW TEST:61.416 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:09:27.687: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-fbb4ab72-86c9-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:09:28.117: INFO: Waiting up to 5m0s for pod "pod-configmaps-fbb5c4a4-86c9-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-qcwz9" to be "success or failure"
Jun  4 13:09:28.123: INFO: Pod "pod-configmaps-fbb5c4a4-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.719313ms
Jun  4 13:09:30.130: INFO: Pod "pod-configmaps-fbb5c4a4-86c9-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012468641s
Jun  4 13:09:32.145: INFO: Pod "pod-configmaps-fbb5c4a4-86c9-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027668325s
STEP: Saw pod success
Jun  4 13:09:32.145: INFO: Pod "pod-configmaps-fbb5c4a4-86c9-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:09:32.151: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-fbb5c4a4-86c9-11e9-8620-ba945f56578b container configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:09:32.353: INFO: Waiting for pod pod-configmaps-fbb5c4a4-86c9-11e9-8620-ba945f56578b to disappear
Jun  4 13:09:32.366: INFO: Pod pod-configmaps-fbb5c4a4-86c9-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:09:32.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qcwz9" for this suite.
Jun  4 13:09:38.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:09:38.543: INFO: namespace: e2e-tests-configmap-qcwz9, resource: bindings, ignored listing per whitelist
Jun  4 13:09:38.759: INFO: namespace e2e-tests-configmap-qcwz9 deletion completed in 6.387857036s

• [SLOW TEST:11.073 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:09:38.763: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-028c8e56-86ca-11e9-8620-ba945f56578b
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-028c8e56-86ca-11e9-8620-ba945f56578b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:09:43.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fnx42" for this suite.
Jun  4 13:10:06.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:10:06.452: INFO: namespace: e2e-tests-configmap-fnx42, resource: bindings, ignored listing per whitelist
Jun  4 13:10:06.593: INFO: namespace e2e-tests-configmap-fnx42 deletion completed in 22.454293123s

• [SLOW TEST:27.831 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:10:06.594: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-kzvv7/secret-test-12f0d7ac-86ca-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 13:10:07.094: INFO: Waiting up to 5m0s for pod "pod-configmaps-12f1a2b3-86ca-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-kzvv7" to be "success or failure"
Jun  4 13:10:07.103: INFO: Pod "pod-configmaps-12f1a2b3-86ca-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.822887ms
Jun  4 13:10:09.109: INFO: Pod "pod-configmaps-12f1a2b3-86ca-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014801404s
Jun  4 13:10:11.115: INFO: Pod "pod-configmaps-12f1a2b3-86ca-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021277779s
STEP: Saw pod success
Jun  4 13:10:11.115: INFO: Pod "pod-configmaps-12f1a2b3-86ca-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:10:11.119: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-12f1a2b3-86ca-11e9-8620-ba945f56578b container env-test: <nil>
STEP: delete the pod
Jun  4 13:10:11.181: INFO: Waiting for pod pod-configmaps-12f1a2b3-86ca-11e9-8620-ba945f56578b to disappear
Jun  4 13:10:11.186: INFO: Pod pod-configmaps-12f1a2b3-86ca-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:10:11.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kzvv7" for this suite.
Jun  4 13:10:17.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:10:17.458: INFO: namespace: e2e-tests-secrets-kzvv7, resource: bindings, ignored listing per whitelist
Jun  4 13:10:17.556: INFO: namespace e2e-tests-secrets-kzvv7 deletion completed in 6.362883357s

• [SLOW TEST:10.963 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:10:17.568: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Jun  4 13:10:22.038: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:10:46.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-hl9ld" for this suite.
Jun  4 13:10:52.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:10:52.586: INFO: namespace: e2e-tests-namespaces-hl9ld, resource: bindings, ignored listing per whitelist
Jun  4 13:10:52.602: INFO: namespace e2e-tests-namespaces-hl9ld deletion completed in 6.439910278s
STEP: Destroying namespace "e2e-tests-nsdeletetest-bxw55" for this suite.
Jun  4 13:10:52.607: INFO: Namespace e2e-tests-nsdeletetest-bxw55 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-7mmgl" for this suite.
Jun  4 13:10:58.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:10:58.757: INFO: namespace: e2e-tests-nsdeletetest-7mmgl, resource: bindings, ignored listing per whitelist
Jun  4 13:10:59.161: INFO: namespace e2e-tests-nsdeletetest-7mmgl deletion completed in 6.554324957s

• [SLOW TEST:41.595 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:10:59.166: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jun  4 13:10:59.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:00.326: INFO: stderr: ""
Jun  4 13:11:00.326: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun  4 13:11:00.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:00.497: INFO: stderr: ""
Jun  4 13:11:00.497: INFO: stdout: "update-demo-nautilus-6mr7s update-demo-nautilus-d7v2z "
Jun  4 13:11:00.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-6mr7s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:00.626: INFO: stderr: ""
Jun  4 13:11:00.627: INFO: stdout: ""
Jun  4 13:11:00.627: INFO: update-demo-nautilus-6mr7s is created but not running
Jun  4 13:11:05.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:05.909: INFO: stderr: ""
Jun  4 13:11:05.909: INFO: stdout: "update-demo-nautilus-6mr7s update-demo-nautilus-d7v2z "
Jun  4 13:11:05.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-6mr7s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:06.100: INFO: stderr: ""
Jun  4 13:11:06.100: INFO: stdout: "true"
Jun  4 13:11:06.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-6mr7s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:06.259: INFO: stderr: ""
Jun  4 13:11:06.259: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 13:11:06.259: INFO: validating pod update-demo-nautilus-6mr7s
Jun  4 13:11:06.358: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 13:11:06.358: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 13:11:06.358: INFO: update-demo-nautilus-6mr7s is verified up and running
Jun  4 13:11:06.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-d7v2z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:06.502: INFO: stderr: ""
Jun  4 13:11:06.502: INFO: stdout: "true"
Jun  4 13:11:06.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-d7v2z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:06.693: INFO: stderr: ""
Jun  4 13:11:06.693: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 13:11:06.693: INFO: validating pod update-demo-nautilus-d7v2z
Jun  4 13:11:06.831: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 13:11:06.831: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 13:11:06.831: INFO: update-demo-nautilus-d7v2z is verified up and running
STEP: rolling-update to new replication controller
Jun  4 13:11:06.834: INFO: scanned /root for discovery docs: <nil>
Jun  4 13:11:06.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:31.354: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun  4 13:11:31.354: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun  4 13:11:31.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:31.545: INFO: stderr: ""
Jun  4 13:11:31.545: INFO: stdout: "update-demo-kitten-8jlhq update-demo-kitten-vj4mn "
Jun  4 13:11:31.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-kitten-8jlhq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:31.747: INFO: stderr: ""
Jun  4 13:11:31.747: INFO: stdout: "true"
Jun  4 13:11:31.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-kitten-8jlhq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:31.912: INFO: stderr: ""
Jun  4 13:11:31.912: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun  4 13:11:31.912: INFO: validating pod update-demo-kitten-8jlhq
Jun  4 13:11:32.047: INFO: got data: {
  "image": "kitten.jpg"
}

Jun  4 13:11:32.047: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun  4 13:11:32.047: INFO: update-demo-kitten-8jlhq is verified up and running
Jun  4 13:11:32.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-kitten-vj4mn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:32.219: INFO: stderr: ""
Jun  4 13:11:32.219: INFO: stdout: "true"
Jun  4 13:11:32.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-kitten-vj4mn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sptvv'
Jun  4 13:11:32.367: INFO: stderr: ""
Jun  4 13:11:32.367: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun  4 13:11:32.367: INFO: validating pod update-demo-kitten-vj4mn
Jun  4 13:11:32.538: INFO: got data: {
  "image": "kitten.jpg"
}

Jun  4 13:11:32.539: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun  4 13:11:32.539: INFO: update-demo-kitten-vj4mn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:11:32.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sptvv" for this suite.
Jun  4 13:11:56.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:11:56.741: INFO: namespace: e2e-tests-kubectl-sptvv, resource: bindings, ignored listing per whitelist
Jun  4 13:11:57.078: INFO: namespace e2e-tests-kubectl-sptvv deletion completed in 24.531749465s

• [SLOW TEST:57.913 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:11:57.083: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-54b14e06-86ca-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:11:57.413: INFO: Waiting up to 5m0s for pod "pod-configmaps-54b2b742-86ca-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-cwjs4" to be "success or failure"
Jun  4 13:11:57.418: INFO: Pod "pod-configmaps-54b2b742-86ca-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.022112ms
Jun  4 13:11:59.425: INFO: Pod "pod-configmaps-54b2b742-86ca-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012293147s
Jun  4 13:12:01.432: INFO: Pod "pod-configmaps-54b2b742-86ca-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019121942s
STEP: Saw pod success
Jun  4 13:12:01.432: INFO: Pod "pod-configmaps-54b2b742-86ca-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:12:01.438: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-54b2b742-86ca-11e9-8620-ba945f56578b container configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:12:01.613: INFO: Waiting for pod pod-configmaps-54b2b742-86ca-11e9-8620-ba945f56578b to disappear
Jun  4 13:12:01.623: INFO: Pod pod-configmaps-54b2b742-86ca-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:12:01.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cwjs4" for this suite.
Jun  4 13:12:07.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:12:08.109: INFO: namespace: e2e-tests-configmap-cwjs4, resource: bindings, ignored listing per whitelist
Jun  4 13:12:08.248: INFO: namespace e2e-tests-configmap-cwjs4 deletion completed in 6.610422908s

• [SLOW TEST:11.171 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:12:08.258: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0604 13:12:48.687085      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun  4 13:12:48.687: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:12:48.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qxmds" for this suite.
Jun  4 13:12:56.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:12:57.561: INFO: namespace: e2e-tests-gc-qxmds, resource: bindings, ignored listing per whitelist
Jun  4 13:12:57.665: INFO: namespace e2e-tests-gc-qxmds deletion completed in 8.972920517s

• [SLOW TEST:49.408 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:12:57.669: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mdcz6
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun  4 13:12:58.141: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun  4 13:13:18.348: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.0.23:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mdcz6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:13:18.348: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:13:19.137: INFO: Found all expected endpoints: [netserver-0]
Jun  4 13:13:19.143: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.1.45:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mdcz6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:13:19.143: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:13:20.037: INFO: Found all expected endpoints: [netserver-1]
Jun  4 13:13:20.044: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.25.2.13:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-mdcz6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:13:20.044: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:13:20.947: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:13:20.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mdcz6" for this suite.
Jun  4 13:13:45.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:13:45.153: INFO: namespace: e2e-tests-pod-network-test-mdcz6, resource: bindings, ignored listing per whitelist
Jun  4 13:13:45.454: INFO: namespace e2e-tests-pod-network-test-mdcz6 deletion completed in 24.41190028s

• [SLOW TEST:47.786 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:13:45.457: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jun  4 13:13:45.789: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-a,UID:954d28e8-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12594,Generation:0,CreationTimestamp:2019-06-04 13:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun  4 13:13:45.790: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-a,UID:954d28e8-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12594,Generation:0,CreationTimestamp:2019-06-04 13:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jun  4 13:13:55.847: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-a,UID:954d28e8-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12619,Generation:0,CreationTimestamp:2019-06-04 13:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun  4 13:13:55.848: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-a,UID:954d28e8-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12619,Generation:0,CreationTimestamp:2019-06-04 13:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jun  4 13:14:06.045: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-a,UID:954d28e8-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12644,Generation:0,CreationTimestamp:2019-06-04 13:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun  4 13:14:06.046: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-a,UID:954d28e8-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12644,Generation:0,CreationTimestamp:2019-06-04 13:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jun  4 13:14:16.237: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-a,UID:954d28e8-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12669,Generation:0,CreationTimestamp:2019-06-04 13:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun  4 13:14:16.237: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-a,UID:954d28e8-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12669,Generation:0,CreationTimestamp:2019-06-04 13:13:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jun  4 13:14:26.248: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-b,UID:ad6a3750-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12694,Generation:0,CreationTimestamp:2019-06-04 13:14:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun  4 13:14:26.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-b,UID:ad6a3750-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12694,Generation:0,CreationTimestamp:2019-06-04 13:14:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jun  4 13:14:36.260: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-b,UID:ad6a3750-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12719,Generation:0,CreationTimestamp:2019-06-04 13:14:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun  4 13:14:36.261: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-6sc6n,SelfLink:/api/v1/namespaces/e2e-tests-watch-6sc6n/configmaps/e2e-watch-test-configmap-b,UID:ad6a3750-86ca-11e9-9957-a6a8fec88741,ResourceVersion:12719,Generation:0,CreationTimestamp:2019-06-04 13:14:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:14:46.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6sc6n" for this suite.
Jun  4 13:14:52.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:14:52.685: INFO: namespace: e2e-tests-watch-6sc6n, resource: bindings, ignored listing per whitelist
Jun  4 13:14:52.763: INFO: namespace e2e-tests-watch-6sc6n deletion completed in 6.423383361s

• [SLOW TEST:67.307 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:14:52.769: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jun  4 13:14:53.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:14:53.446: INFO: stderr: ""
Jun  4 13:14:53.446: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun  4 13:14:53.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:14:53.673: INFO: stderr: ""
Jun  4 13:14:53.673: INFO: stdout: "update-demo-nautilus-9jstt update-demo-nautilus-tlm54 "
Jun  4 13:14:53.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-9jstt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:14:53.841: INFO: stderr: ""
Jun  4 13:14:53.841: INFO: stdout: ""
Jun  4 13:14:53.841: INFO: update-demo-nautilus-9jstt is created but not running
Jun  4 13:14:58.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:14:59.003: INFO: stderr: ""
Jun  4 13:14:59.003: INFO: stdout: "update-demo-nautilus-9jstt update-demo-nautilus-tlm54 "
Jun  4 13:14:59.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-9jstt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:14:59.139: INFO: stderr: ""
Jun  4 13:14:59.139: INFO: stdout: "true"
Jun  4 13:14:59.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-9jstt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:14:59.352: INFO: stderr: ""
Jun  4 13:14:59.352: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 13:14:59.352: INFO: validating pod update-demo-nautilus-9jstt
Jun  4 13:14:59.480: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 13:14:59.480: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 13:14:59.480: INFO: update-demo-nautilus-9jstt is verified up and running
Jun  4 13:14:59.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-tlm54 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:14:59.746: INFO: stderr: ""
Jun  4 13:14:59.746: INFO: stdout: "true"
Jun  4 13:14:59.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-tlm54 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:14:59.898: INFO: stderr: ""
Jun  4 13:14:59.899: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 13:14:59.899: INFO: validating pod update-demo-nautilus-tlm54
Jun  4 13:15:00.036: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 13:15:00.036: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 13:15:00.036: INFO: update-demo-nautilus-tlm54 is verified up and running
STEP: using delete to clean up resources
Jun  4 13:15:00.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:15:00.348: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:15:00.348: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun  4 13:15:00.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-vd68z'
Jun  4 13:15:00.648: INFO: stderr: "No resources found.\n"
Jun  4 13:15:00.648: INFO: stdout: ""
Jun  4 13:15:00.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -l name=update-demo --namespace=e2e-tests-kubectl-vd68z -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun  4 13:15:00.968: INFO: stderr: ""
Jun  4 13:15:00.968: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:15:00.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vd68z" for this suite.
Jun  4 13:15:23.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:15:23.458: INFO: namespace: e2e-tests-kubectl-vd68z, resource: bindings, ignored listing per whitelist
Jun  4 13:15:23.585: INFO: namespace e2e-tests-kubectl-vd68z deletion completed in 22.61113273s

• [SLOW TEST:30.817 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:15:23.590: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun  4 13:15:28.840: INFO: Successfully updated pod "labelsupdatecfd59292-86ca-11e9-8620-ba945f56578b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:15:31.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v7v9d" for this suite.
Jun  4 13:15:53.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:15:53.847: INFO: namespace: e2e-tests-projected-v7v9d, resource: bindings, ignored listing per whitelist
Jun  4 13:15:54.035: INFO: namespace e2e-tests-projected-v7v9d deletion completed in 22.89728271s

• [SLOW TEST:30.446 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:15:54.037: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e1dfde30-86ca-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 13:15:54.277: INFO: Waiting up to 5m0s for pod "pod-secrets-e1e110ec-86ca-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-2rvfx" to be "success or failure"
Jun  4 13:15:54.285: INFO: Pod "pod-secrets-e1e110ec-86ca-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.736612ms
Jun  4 13:15:56.291: INFO: Pod "pod-secrets-e1e110ec-86ca-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013277925s
Jun  4 13:15:58.296: INFO: Pod "pod-secrets-e1e110ec-86ca-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018644749s
STEP: Saw pod success
Jun  4 13:15:58.296: INFO: Pod "pod-secrets-e1e110ec-86ca-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:15:58.300: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-secrets-e1e110ec-86ca-11e9-8620-ba945f56578b container secret-volume-test: <nil>
STEP: delete the pod
Jun  4 13:15:58.367: INFO: Waiting for pod pod-secrets-e1e110ec-86ca-11e9-8620-ba945f56578b to disappear
Jun  4 13:15:58.442: INFO: Pod pod-secrets-e1e110ec-86ca-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:15:58.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2rvfx" for this suite.
Jun  4 13:16:04.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:16:04.972: INFO: namespace: e2e-tests-secrets-2rvfx, resource: bindings, ignored listing per whitelist
Jun  4 13:16:05.035: INFO: namespace e2e-tests-secrets-2rvfx deletion completed in 6.586244401s

• [SLOW TEST:10.998 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:16:05.041: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e8847996-86ca-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:16:05.450: INFO: Waiting up to 5m0s for pod "pod-configmaps-e88a6b2c-86ca-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-kp4nq" to be "success or failure"
Jun  4 13:16:05.457: INFO: Pod "pod-configmaps-e88a6b2c-86ca-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.612829ms
Jun  4 13:16:07.463: INFO: Pod "pod-configmaps-e88a6b2c-86ca-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011251821s
Jun  4 13:16:09.468: INFO: Pod "pod-configmaps-e88a6b2c-86ca-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016768943s
STEP: Saw pod success
Jun  4 13:16:09.468: INFO: Pod "pod-configmaps-e88a6b2c-86ca-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:16:09.472: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-e88a6b2c-86ca-11e9-8620-ba945f56578b container configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:16:09.611: INFO: Waiting for pod pod-configmaps-e88a6b2c-86ca-11e9-8620-ba945f56578b to disappear
Jun  4 13:16:09.617: INFO: Pod pod-configmaps-e88a6b2c-86ca-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:16:09.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kp4nq" for this suite.
Jun  4 13:16:15.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:16:15.782: INFO: namespace: e2e-tests-configmap-kp4nq, resource: bindings, ignored listing per whitelist
Jun  4 13:16:16.032: INFO: namespace e2e-tests-configmap-kp4nq deletion completed in 6.395300054s

• [SLOW TEST:10.993 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:16:16.036: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:16:16.439: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:16:21.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-nxmdl" for this suite.
Jun  4 13:17:03.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:17:03.871: INFO: namespace: e2e-tests-pods-nxmdl, resource: bindings, ignored listing per whitelist
Jun  4 13:17:04.122: INFO: namespace e2e-tests-pods-nxmdl deletion completed in 42.780326974s

• [SLOW TEST:48.087 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:17:04.127: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun  4 13:17:04.432: INFO: Waiting up to 5m0s for pod "pod-0bb2368d-86cb-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-4w5zm" to be "success or failure"
Jun  4 13:17:04.443: INFO: Pod "pod-0bb2368d-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.890009ms
Jun  4 13:17:06.450: INFO: Pod "pod-0bb2368d-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017902715s
Jun  4 13:17:08.456: INFO: Pod "pod-0bb2368d-86cb-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023723932s
STEP: Saw pod success
Jun  4 13:17:08.457: INFO: Pod "pod-0bb2368d-86cb-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:17:08.462: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-0bb2368d-86cb-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:17:08.537: INFO: Waiting for pod pod-0bb2368d-86cb-11e9-8620-ba945f56578b to disappear
Jun  4 13:17:08.542: INFO: Pod pod-0bb2368d-86cb-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:17:08.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4w5zm" for this suite.
Jun  4 13:17:14.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:17:15.254: INFO: namespace: e2e-tests-emptydir-4w5zm, resource: bindings, ignored listing per whitelist
Jun  4 13:17:15.272: INFO: namespace e2e-tests-emptydir-4w5zm deletion completed in 6.725687956s

• [SLOW TEST:11.147 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:17:15.279: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 13:17:15.693: INFO: Waiting up to 5m0s for pod "downwardapi-volume-126766e2-86cb-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-fd8ss" to be "success or failure"
Jun  4 13:17:15.699: INFO: Pod "downwardapi-volume-126766e2-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.614598ms
Jun  4 13:17:17.706: INFO: Pod "downwardapi-volume-126766e2-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013039305s
Jun  4 13:17:19.836: INFO: Pod "downwardapi-volume-126766e2-86cb-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.143448182s
STEP: Saw pod success
Jun  4 13:17:19.837: INFO: Pod "downwardapi-volume-126766e2-86cb-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:17:19.842: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-126766e2-86cb-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 13:17:19.956: INFO: Waiting for pod downwardapi-volume-126766e2-86cb-11e9-8620-ba945f56578b to disappear
Jun  4 13:17:19.963: INFO: Pod downwardapi-volume-126766e2-86cb-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:17:19.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fd8ss" for this suite.
Jun  4 13:17:26.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:17:26.398: INFO: namespace: e2e-tests-projected-fd8ss, resource: bindings, ignored listing per whitelist
Jun  4 13:17:26.482: INFO: namespace e2e-tests-projected-fd8ss deletion completed in 6.513442641s

• [SLOW TEST:11.203 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:17:26.486: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:17:33.077: INFO: Waiting up to 5m0s for pod "client-envvars-1cc0b1b9-86cb-11e9-8620-ba945f56578b" in namespace "e2e-tests-pods-xdh67" to be "success or failure"
Jun  4 13:17:33.093: INFO: Pod "client-envvars-1cc0b1b9-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.294066ms
Jun  4 13:17:35.099: INFO: Pod "client-envvars-1cc0b1b9-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022242861s
Jun  4 13:17:37.137: INFO: Pod "client-envvars-1cc0b1b9-86cb-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059794325s
STEP: Saw pod success
Jun  4 13:17:37.137: INFO: Pod "client-envvars-1cc0b1b9-86cb-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:17:37.152: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-4wzp4 pod client-envvars-1cc0b1b9-86cb-11e9-8620-ba945f56578b container env3cont: <nil>
STEP: delete the pod
Jun  4 13:17:37.336: INFO: Waiting for pod client-envvars-1cc0b1b9-86cb-11e9-8620-ba945f56578b to disappear
Jun  4 13:17:37.344: INFO: Pod client-envvars-1cc0b1b9-86cb-11e9-8620-ba945f56578b no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:17:37.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xdh67" for this suite.
Jun  4 13:18:25.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:18:25.551: INFO: namespace: e2e-tests-pods-xdh67, resource: bindings, ignored listing per whitelist
Jun  4 13:18:26.302: INFO: namespace e2e-tests-pods-xdh67 deletion completed in 48.952865258s

• [SLOW TEST:59.817 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:18:26.306: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun  4 13:18:26.673: INFO: Waiting up to 5m0s for pod "pod-3cb3dc7e-86cb-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-hckgc" to be "success or failure"
Jun  4 13:18:26.693: INFO: Pod "pod-3cb3dc7e-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.703685ms
Jun  4 13:18:28.697: INFO: Pod "pod-3cb3dc7e-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024236061s
Jun  4 13:18:30.710: INFO: Pod "pod-3cb3dc7e-86cb-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036686299s
STEP: Saw pod success
Jun  4 13:18:30.710: INFO: Pod "pod-3cb3dc7e-86cb-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:18:30.714: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-3cb3dc7e-86cb-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:18:30.973: INFO: Waiting for pod pod-3cb3dc7e-86cb-11e9-8620-ba945f56578b to disappear
Jun  4 13:18:30.988: INFO: Pod pod-3cb3dc7e-86cb-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:18:30.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hckgc" for this suite.
Jun  4 13:18:37.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:18:37.263: INFO: namespace: e2e-tests-emptydir-hckgc, resource: bindings, ignored listing per whitelist
Jun  4 13:18:37.428: INFO: namespace e2e-tests-emptydir-hckgc deletion completed in 6.433639044s

• [SLOW TEST:11.122 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:18:37.429: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jun  4 13:18:37.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 api-versions'
Jun  4 13:18:38.129: INFO: stderr: ""
Jun  4 13:18:38.129: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncluster.k8s.io/v1alpha1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:18:38.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pwfcn" for this suite.
Jun  4 13:18:44.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:18:44.534: INFO: namespace: e2e-tests-kubectl-pwfcn, resource: bindings, ignored listing per whitelist
Jun  4 13:18:44.651: INFO: namespace e2e-tests-kubectl-pwfcn deletion completed in 6.498754426s

• [SLOW TEST:7.222 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:18:44.659: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-crfb5
Jun  4 13:18:49.056: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-crfb5
STEP: checking the pod's current state and verifying that restartCount is present
Jun  4 13:18:49.134: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:22:51.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-crfb5" for this suite.
Jun  4 13:22:57.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:22:57.538: INFO: namespace: e2e-tests-container-probe-crfb5, resource: bindings, ignored listing per whitelist
Jun  4 13:22:57.856: INFO: namespace e2e-tests-container-probe-crfb5 deletion completed in 6.61214776s

• [SLOW TEST:253.197 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:22:57.860: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun  4 13:22:58.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ljmk9'
Jun  4 13:22:59.057: INFO: stderr: ""
Jun  4 13:22:59.057: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Jun  4 13:22:59.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-ljmk9'
Jun  4 13:23:01.630: INFO: stderr: ""
Jun  4 13:23:01.630: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:23:01.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ljmk9" for this suite.
Jun  4 13:23:07.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:23:08.192: INFO: namespace: e2e-tests-kubectl-ljmk9, resource: bindings, ignored listing per whitelist
Jun  4 13:23:08.460: INFO: namespace e2e-tests-kubectl-ljmk9 deletion completed in 6.821525435s

• [SLOW TEST:10.601 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:23:08.470: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun  4 13:23:08.936: INFO: Waiting up to 5m0s for pod "downward-api-e4eeaaed-86cb-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-2xnnp" to be "success or failure"
Jun  4 13:23:08.941: INFO: Pod "downward-api-e4eeaaed-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.537822ms
Jun  4 13:23:10.950: INFO: Pod "downward-api-e4eeaaed-86cb-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014164677s
Jun  4 13:23:12.955: INFO: Pod "downward-api-e4eeaaed-86cb-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019417138s
STEP: Saw pod success
Jun  4 13:23:12.955: INFO: Pod "downward-api-e4eeaaed-86cb-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:23:12.960: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downward-api-e4eeaaed-86cb-11e9-8620-ba945f56578b container dapi-container: <nil>
STEP: delete the pod
Jun  4 13:23:13.111: INFO: Waiting for pod downward-api-e4eeaaed-86cb-11e9-8620-ba945f56578b to disappear
Jun  4 13:23:13.116: INFO: Pod downward-api-e4eeaaed-86cb-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:23:13.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2xnnp" for this suite.
Jun  4 13:23:19.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:23:19.657: INFO: namespace: e2e-tests-downward-api-2xnnp, resource: bindings, ignored listing per whitelist
Jun  4 13:23:19.706: INFO: namespace e2e-tests-downward-api-2xnnp deletion completed in 6.581850228s

• [SLOW TEST:11.238 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:23:19.707: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jun  4 13:23:20.088: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-6g98p" to be "success or failure"
Jun  4 13:23:20.095: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.507247ms
Jun  4 13:23:22.101: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012480281s
Jun  4 13:23:24.106: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018342269s
Jun  4 13:23:26.115: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.026491088s
STEP: Saw pod success
Jun  4 13:23:26.115: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jun  4 13:23:26.119: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-gv9cg pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jun  4 13:23:26.211: INFO: Waiting for pod pod-host-path-test to disappear
Jun  4 13:23:26.217: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:23:26.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-6g98p" for this suite.
Jun  4 13:23:32.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:23:32.450: INFO: namespace: e2e-tests-hostpath-6g98p, resource: bindings, ignored listing per whitelist
Jun  4 13:23:32.578: INFO: namespace e2e-tests-hostpath-6g98p deletion completed in 6.354658137s

• [SLOW TEST:12.871 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:23:32.578: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-254zw in namespace e2e-tests-proxy-mxncx
I0604 13:23:33.020180      15 runners.go:184] Created replication controller with name: proxy-service-254zw, namespace: e2e-tests-proxy-mxncx, replica count: 1
I0604 13:23:34.076808      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 13:23:35.077084      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 13:23:36.077353      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 13:23:37.077651      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 13:23:38.077935      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 13:23:39.078280      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 13:23:40.078668      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0604 13:23:41.078937      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0604 13:23:42.079250      15 runners.go:184] proxy-service-254zw Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun  4 13:23:42.143: INFO: setup took 9.15140822s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jun  4 13:23:42.330: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 186.528133ms)
Jun  4 13:23:42.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 195.992307ms)
Jun  4 13:23:42.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 197.386138ms)
Jun  4 13:23:42.341: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 196.590868ms)
Jun  4 13:23:42.343: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 199.445322ms)
Jun  4 13:23:42.491: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 344.284966ms)
Jun  4 13:23:42.491: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 347.81803ms)
Jun  4 13:23:42.491: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 346.046565ms)
Jun  4 13:23:42.491: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 348.423425ms)
Jun  4 13:23:42.491: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 345.866049ms)
Jun  4 13:23:42.491: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 345.241404ms)
Jun  4 13:23:42.493: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 349.252565ms)
Jun  4 13:23:42.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 356.915712ms)
Jun  4 13:23:42.501: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 354.484421ms)
Jun  4 13:23:42.504: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 358.557264ms)
Jun  4 13:23:42.588: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 441.462974ms)
Jun  4 13:23:42.602: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 13.31779ms)
Jun  4 13:23:42.889: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 299.324238ms)
Jun  4 13:23:42.936: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 346.464256ms)
Jun  4 13:23:42.936: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 345.446451ms)
Jun  4 13:23:42.936: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 347.064711ms)
Jun  4 13:23:42.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 345.920275ms)
Jun  4 13:23:42.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 346.294011ms)
Jun  4 13:23:42.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 347.7846ms)
Jun  4 13:23:42.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 347.119879ms)
Jun  4 13:23:42.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 348.300905ms)
Jun  4 13:23:42.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 348.246621ms)
Jun  4 13:23:42.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 347.078008ms)
Jun  4 13:23:42.937: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 346.343593ms)
Jun  4 13:23:42.979: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 390.054886ms)
Jun  4 13:23:42.996: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 406.045344ms)
Jun  4 13:23:43.039: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 449.318003ms)
Jun  4 13:23:43.096: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 52.855438ms)
Jun  4 13:23:43.096: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 54.79704ms)
Jun  4 13:23:43.097: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 54.629319ms)
Jun  4 13:23:43.097: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 55.286839ms)
Jun  4 13:23:43.097: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 55.877099ms)
Jun  4 13:23:43.097: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 55.495326ms)
Jun  4 13:23:43.097: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 57.706417ms)
Jun  4 13:23:43.098: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 55.272657ms)
Jun  4 13:23:43.099: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 55.522489ms)
Jun  4 13:23:43.099: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 56.229115ms)
Jun  4 13:23:43.099: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 56.809987ms)
Jun  4 13:23:43.100: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 57.639908ms)
Jun  4 13:23:43.104: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 60.884492ms)
Jun  4 13:23:43.104: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 62.856778ms)
Jun  4 13:23:43.107: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 65.439336ms)
Jun  4 13:23:43.107: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 65.089798ms)
Jun  4 13:23:43.132: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 23.943589ms)
Jun  4 13:23:43.133: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 24.557914ms)
Jun  4 13:23:43.133: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 24.343521ms)
Jun  4 13:23:43.133: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 24.649361ms)
Jun  4 13:23:43.134: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 25.937209ms)
Jun  4 13:23:43.134: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 25.534972ms)
Jun  4 13:23:43.188: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 78.825522ms)
Jun  4 13:23:43.188: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 78.885468ms)
Jun  4 13:23:43.189: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 78.309797ms)
Jun  4 13:23:43.189: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 79.278103ms)
Jun  4 13:23:43.189: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 80.35591ms)
Jun  4 13:23:43.244: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 134.034988ms)
Jun  4 13:23:43.244: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 134.89906ms)
Jun  4 13:23:43.244: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 133.75509ms)
Jun  4 13:23:43.256: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 145.891955ms)
Jun  4 13:23:43.256: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 146.453196ms)
Jun  4 13:23:43.338: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 79.863122ms)
Jun  4 13:23:43.338: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 80.747987ms)
Jun  4 13:23:43.339: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 81.133885ms)
Jun  4 13:23:43.339: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 82.280742ms)
Jun  4 13:23:43.339: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 82.0655ms)
Jun  4 13:23:43.390: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 133.400709ms)
Jun  4 13:23:43.391: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 133.806066ms)
Jun  4 13:23:43.391: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 133.809296ms)
Jun  4 13:23:43.391: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 134.747144ms)
Jun  4 13:23:43.391: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 134.563085ms)
Jun  4 13:23:43.392: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 133.677726ms)
Jun  4 13:23:43.392: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 134.271266ms)
Jun  4 13:23:43.483: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 225.600065ms)
Jun  4 13:23:43.483: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 226.56503ms)
Jun  4 13:23:43.484: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 226.306791ms)
Jun  4 13:23:43.629: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 372.014524ms)
Jun  4 13:23:43.747: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 117.571966ms)
Jun  4 13:23:43.831: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 200.663881ms)
Jun  4 13:23:43.832: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 201.258037ms)
Jun  4 13:23:43.832: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 202.189545ms)
Jun  4 13:23:43.832: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 202.519324ms)
Jun  4 13:23:43.832: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 201.390512ms)
Jun  4 13:23:43.832: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 202.820231ms)
Jun  4 13:23:43.832: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 201.379203ms)
Jun  4 13:23:43.833: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 202.286831ms)
Jun  4 13:23:43.838: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 207.87442ms)
Jun  4 13:23:43.838: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 208.345572ms)
Jun  4 13:23:43.838: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 207.748681ms)
Jun  4 13:23:43.840: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 208.937724ms)
Jun  4 13:23:43.840: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 209.222758ms)
Jun  4 13:23:43.847: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 216.37995ms)
Jun  4 13:23:43.848: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 217.926222ms)
Jun  4 13:23:43.937: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 87.734031ms)
Jun  4 13:23:43.938: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 88.111141ms)
Jun  4 13:23:43.938: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 88.837417ms)
Jun  4 13:23:43.939: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 89.825185ms)
Jun  4 13:23:43.939: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 90.774502ms)
Jun  4 13:23:43.939: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 89.00216ms)
Jun  4 13:23:43.939: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 90.988579ms)
Jun  4 13:23:43.940: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 90.692422ms)
Jun  4 13:23:43.940: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 89.942769ms)
Jun  4 13:23:44.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 338.662658ms)
Jun  4 13:23:44.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 340.35792ms)
Jun  4 13:23:44.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 339.011951ms)
Jun  4 13:23:44.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 339.287147ms)
Jun  4 13:23:44.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 341.706411ms)
Jun  4 13:23:44.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 339.896809ms)
Jun  4 13:23:44.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 338.825923ms)
Jun  4 13:23:44.430: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 240.209412ms)
Jun  4 13:23:44.431: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 239.212349ms)
Jun  4 13:23:44.432: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 241.38201ms)
Jun  4 13:23:44.432: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 241.074566ms)
Jun  4 13:23:44.433: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 241.391786ms)
Jun  4 13:23:44.433: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 242.069606ms)
Jun  4 13:23:44.433: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 241.622647ms)
Jun  4 13:23:44.434: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 243.214317ms)
Jun  4 13:23:44.434: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 243.186255ms)
Jun  4 13:23:44.434: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 243.785703ms)
Jun  4 13:23:44.435: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 243.17205ms)
Jun  4 13:23:44.435: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 243.783889ms)
Jun  4 13:23:44.530: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 338.251806ms)
Jun  4 13:23:44.530: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 339.50689ms)
Jun  4 13:23:44.531: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 339.52065ms)
Jun  4 13:23:44.531: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 339.975439ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 104.959848ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 105.161017ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 103.026336ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 104.341938ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 104.020575ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 105.143693ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 103.660887ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 105.501494ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 104.644617ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 103.929099ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 104.310921ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 103.592621ms)
Jun  4 13:23:44.637: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 105.061349ms)
Jun  4 13:23:44.689: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 154.944537ms)
Jun  4 13:23:44.690: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 157.275249ms)
Jun  4 13:23:44.690: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 158.592564ms)
Jun  4 13:23:44.846: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 155.643776ms)
Jun  4 13:23:44.849: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 157.581984ms)
Jun  4 13:23:44.849: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 157.974829ms)
Jun  4 13:23:44.849: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 158.737352ms)
Jun  4 13:23:44.850: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 157.513227ms)
Jun  4 13:23:44.850: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 157.378323ms)
Jun  4 13:23:44.850: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 157.208643ms)
Jun  4 13:23:44.850: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 159.016218ms)
Jun  4 13:23:44.930: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 238.290036ms)
Jun  4 13:23:44.931: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 239.617798ms)
Jun  4 13:23:44.931: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 240.408348ms)
Jun  4 13:23:44.931: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 239.904163ms)
Jun  4 13:23:45.044: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 352.106228ms)
Jun  4 13:23:45.044: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 353.827339ms)
Jun  4 13:23:45.044: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 353.353086ms)
Jun  4 13:23:45.044: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 352.100927ms)
Jun  4 13:23:45.171: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 126.172036ms)
Jun  4 13:23:45.231: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 185.924135ms)
Jun  4 13:23:45.231: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 186.433902ms)
Jun  4 13:23:45.232: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 186.269147ms)
Jun  4 13:23:45.232: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 186.578184ms)
Jun  4 13:23:45.336: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 291.048432ms)
Jun  4 13:23:45.337: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 291.303803ms)
Jun  4 13:23:45.337: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 292.069679ms)
Jun  4 13:23:45.337: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 291.623984ms)
Jun  4 13:23:45.338: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 292.028695ms)
Jun  4 13:23:45.338: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 292.113004ms)
Jun  4 13:23:45.338: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 292.133877ms)
Jun  4 13:23:45.338: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 292.587034ms)
Jun  4 13:23:45.339: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 293.874949ms)
Jun  4 13:23:45.339: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 292.993494ms)
Jun  4 13:23:45.339: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 293.840932ms)
Jun  4 13:23:45.531: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 190.413329ms)
Jun  4 13:23:45.531: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 190.346997ms)
Jun  4 13:23:45.536: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 193.622897ms)
Jun  4 13:23:45.536: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 195.749025ms)
Jun  4 13:23:45.536: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 194.507082ms)
Jun  4 13:23:45.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 195.45488ms)
Jun  4 13:23:45.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 196.811183ms)
Jun  4 13:23:45.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 195.007861ms)
Jun  4 13:23:45.537: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 196.416994ms)
Jun  4 13:23:45.538: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 197.972997ms)
Jun  4 13:23:45.538: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 197.618575ms)
Jun  4 13:23:45.538: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 196.772744ms)
Jun  4 13:23:45.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 246.920875ms)
Jun  4 13:23:45.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 247.384929ms)
Jun  4 13:23:45.590: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 247.376848ms)
Jun  4 13:23:45.590: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 249.416474ms)
Jun  4 13:23:45.615: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 23.896934ms)
Jun  4 13:23:45.616: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 25.34642ms)
Jun  4 13:23:45.616: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 23.777502ms)
Jun  4 13:23:45.616: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 26.145471ms)
Jun  4 13:23:45.618: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 25.913073ms)
Jun  4 13:23:45.618: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 27.7416ms)
Jun  4 13:23:45.618: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 25.541036ms)
Jun  4 13:23:45.620: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 26.74906ms)
Jun  4 13:23:45.636: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 43.414462ms)
Jun  4 13:23:45.636: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 44.62495ms)
Jun  4 13:23:45.636: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 43.362454ms)
Jun  4 13:23:45.636: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 44.894157ms)
Jun  4 13:23:45.636: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 45.479895ms)
Jun  4 13:23:45.636: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 44.138958ms)
Jun  4 13:23:45.636: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 44.023687ms)
Jun  4 13:23:45.636: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 45.363212ms)
Jun  4 13:23:45.702: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 64.401287ms)
Jun  4 13:23:45.702: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 65.138503ms)
Jun  4 13:23:45.702: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 66.270976ms)
Jun  4 13:23:45.736: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 98.858453ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 99.644251ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 100.09709ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 98.932873ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 99.355567ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 100.206184ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 99.020235ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 99.647415ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 99.887349ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 100.680313ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 100.176986ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 99.980623ms)
Jun  4 13:23:45.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 100.52979ms)
Jun  4 13:23:45.893: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 155.201597ms)
Jun  4 13:23:45.893: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 155.038882ms)
Jun  4 13:23:45.893: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 153.675823ms)
Jun  4 13:23:45.893: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 152.65529ms)
Jun  4 13:23:45.893: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 154.817212ms)
Jun  4 13:23:45.893: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 155.133427ms)
Jun  4 13:23:45.894: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 155.834243ms)
Jun  4 13:23:45.894: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 153.187091ms)
Jun  4 13:23:45.894: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 155.641599ms)
Jun  4 13:23:45.894: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 155.312813ms)
Jun  4 13:23:45.894: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 156.610009ms)
Jun  4 13:23:45.894: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 154.245657ms)
Jun  4 13:23:45.937: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 198.317334ms)
Jun  4 13:23:45.937: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 198.975118ms)
Jun  4 13:23:45.937: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 198.354487ms)
Jun  4 13:23:45.937: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 197.070545ms)
Jun  4 13:23:45.977: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 38.585728ms)
Jun  4 13:23:45.977: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 39.403521ms)
Jun  4 13:23:45.983: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 45.023566ms)
Jun  4 13:23:45.983: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 44.521446ms)
Jun  4 13:23:45.985: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 47.666127ms)
Jun  4 13:23:45.986: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 48.020447ms)
Jun  4 13:23:45.991: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 52.413013ms)
Jun  4 13:23:45.991: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 51.87522ms)
Jun  4 13:23:45.992: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 52.473498ms)
Jun  4 13:23:45.992: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 54.176753ms)
Jun  4 13:23:45.992: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 53.193289ms)
Jun  4 13:23:45.994: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 55.628891ms)
Jun  4 13:23:45.995: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 55.191856ms)
Jun  4 13:23:45.995: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 55.618387ms)
Jun  4 13:23:46.042: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 103.098705ms)
Jun  4 13:23:46.043: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 103.607168ms)
Jun  4 13:23:46.068: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 24.35637ms)
Jun  4 13:23:46.069: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 23.605827ms)
Jun  4 13:23:46.069: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 23.665994ms)
Jun  4 13:23:46.137: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 93.74499ms)
Jun  4 13:23:46.138: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 94.550216ms)
Jun  4 13:23:46.138: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 93.613304ms)
Jun  4 13:23:46.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 94.33369ms)
Jun  4 13:23:46.139: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 93.828613ms)
Jun  4 13:23:46.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 95.660687ms)
Jun  4 13:23:46.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 94.39003ms)
Jun  4 13:23:46.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 96.779322ms)
Jun  4 13:23:46.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 95.163082ms)
Jun  4 13:23:46.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 96.475164ms)
Jun  4 13:23:46.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 95.886841ms)
Jun  4 13:23:46.140: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 96.028275ms)
Jun  4 13:23:46.231: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 186.635829ms)
Jun  4 13:23:46.393: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 161.765918ms)
Jun  4 13:23:46.394: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 160.58892ms)
Jun  4 13:23:46.394: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 160.445149ms)
Jun  4 13:23:46.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 162.106724ms)
Jun  4 13:23:46.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 161.728604ms)
Jun  4 13:23:46.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 162.170707ms)
Jun  4 13:23:46.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 164.120133ms)
Jun  4 13:23:46.396: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 162.680112ms)
Jun  4 13:23:46.397: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 165.181511ms)
Jun  4 13:23:46.397: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 164.743294ms)
Jun  4 13:23:46.398: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 163.706624ms)
Jun  4 13:23:46.398: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 163.576409ms)
Jun  4 13:23:46.401: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 168.129386ms)
Jun  4 13:23:46.403: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 170.695716ms)
Jun  4 13:23:46.404: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 171.422465ms)
Jun  4 13:23:46.406: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 174.34041ms)
Jun  4 13:23:46.460: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 53.161207ms)
Jun  4 13:23:46.460: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 53.516553ms)
Jun  4 13:23:46.461: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 53.100163ms)
Jun  4 13:23:46.461: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 53.895753ms)
Jun  4 13:23:46.461: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 54.928104ms)
Jun  4 13:23:46.463: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 54.621291ms)
Jun  4 13:23:46.463: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 56.663857ms)
Jun  4 13:23:46.464: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 55.408739ms)
Jun  4 13:23:46.464: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 56.560291ms)
Jun  4 13:23:46.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 57.298856ms)
Jun  4 13:23:46.465: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 57.396673ms)
Jun  4 13:23:46.468: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 59.602576ms)
Jun  4 13:23:46.468: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 61.523279ms)
Jun  4 13:23:46.469: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 61.535391ms)
Jun  4 13:23:46.469: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 61.738086ms)
Jun  4 13:23:46.469: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 61.497451ms)
Jun  4 13:23:46.494: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:460/proxy/: tls baz (200; 23.935734ms)
Jun  4 13:23:46.536: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname1/proxy/: foo (200; 66.368904ms)
Jun  4 13:23:46.536: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:1080/proxy/rewri... (200; 66.768278ms)
Jun  4 13:23:46.536: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:1080/proxy/... (200; 66.198681ms)
Jun  4 13:23:46.537: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:160/proxy/: foo (200; 66.077465ms)
Jun  4 13:23:46.537: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:160/proxy/: foo (200; 65.873954ms)
Jun  4 13:23:46.537: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/http:proxy-service-254zw-8zx7m:162/proxy/: bar (200; 65.734064ms)
Jun  4 13:23:46.537: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m:162/proxy/: bar (200; 65.181776ms)
Jun  4 13:23:46.537: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:462/proxy/: tls qux (200; 65.658556ms)
Jun  4 13:23:46.537: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/https:proxy-service-254zw-8zx7m:443/proxy/... (200; 65.053811ms)
Jun  4 13:23:46.537: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-mxncx/pods/proxy-service-254zw-8zx7m/proxy/rewriteme"... (200; 65.417849ms)
Jun  4 13:23:46.540: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname1/proxy/: foo (200; 68.540608ms)
Jun  4 13:23:46.542: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname1/proxy/: tls baz (200; 71.826931ms)
Jun  4 13:23:46.543: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/http:proxy-service-254zw:portname2/proxy/: bar (200; 71.464691ms)
Jun  4 13:23:46.543: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/https:proxy-service-254zw:tlsportname2/proxy/: tls qux (200; 70.954595ms)
Jun  4 13:23:46.543: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-mxncx/services/proxy-service-254zw:portname2/proxy/: bar (200; 72.816943ms)
STEP: deleting ReplicationController proxy-service-254zw in namespace e2e-tests-proxy-mxncx, will wait for the garbage collector to delete the pods
Jun  4 13:23:46.637: INFO: Deleting ReplicationController proxy-service-254zw took: 36.87881ms
Jun  4 13:23:46.737: INFO: Terminating ReplicationController proxy-service-254zw pods took: 100.279577ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:23:51.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-mxncx" for this suite.
Jun  4 13:23:57.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:23:58.007: INFO: namespace: e2e-tests-proxy-mxncx, resource: bindings, ignored listing per whitelist
Jun  4 13:23:58.359: INFO: namespace e2e-tests-proxy-mxncx deletion completed in 6.585867803s

• [SLOW TEST:25.781 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:23:58.364: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jun  4 13:23:59.039: INFO: namespace e2e-tests-kubectl-c968d
Jun  4 13:23:59.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-c968d'
Jun  4 13:23:59.644: INFO: stderr: ""
Jun  4 13:23:59.644: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun  4 13:24:00.654: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:24:00.654: INFO: Found 0 / 1
Jun  4 13:24:01.653: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:24:01.653: INFO: Found 0 / 1
Jun  4 13:24:02.653: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:24:02.653: INFO: Found 0 / 1
Jun  4 13:24:03.655: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:24:03.656: INFO: Found 1 / 1
Jun  4 13:24:03.656: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun  4 13:24:03.742: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:24:03.743: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun  4 13:24:03.743: INFO: wait on redis-master startup in e2e-tests-kubectl-c968d 
Jun  4 13:24:03.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 logs redis-master-87hp5 redis-master --namespace=e2e-tests-kubectl-c968d'
Jun  4 13:24:04.291: INFO: stderr: ""
Jun  4 13:24:04.291: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Jun 13:24:01.859 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Jun 13:24:01.859 # Server started, Redis version 3.2.12\n1:M 04 Jun 13:24:01.859 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Jun 13:24:01.859 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jun  4 13:24:04.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-c968d'
Jun  4 13:24:04.521: INFO: stderr: ""
Jun  4 13:24:04.521: INFO: stdout: "service/rm2 exposed\n"
Jun  4 13:24:04.526: INFO: Service rm2 in namespace e2e-tests-kubectl-c968d found.
STEP: exposing service
Jun  4 13:24:06.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-c968d'
Jun  4 13:24:07.230: INFO: stderr: ""
Jun  4 13:24:07.230: INFO: stdout: "service/rm3 exposed\n"
Jun  4 13:24:07.436: INFO: Service rm3 in namespace e2e-tests-kubectl-c968d found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:24:09.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c968d" for this suite.
Jun  4 13:24:33.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:24:34.618: INFO: namespace: e2e-tests-kubectl-c968d, resource: bindings, ignored listing per whitelist
Jun  4 13:24:34.667: INFO: namespace e2e-tests-kubectl-c968d deletion completed in 25.087541244s

• [SLOW TEST:36.304 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:24:34.678: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jun  4 13:24:35.153: INFO: Waiting up to 5m0s for pod "client-containers-18584d93-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-containers-bstvh" to be "success or failure"
Jun  4 13:24:35.162: INFO: Pod "client-containers-18584d93-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.567201ms
Jun  4 13:24:37.247: INFO: Pod "client-containers-18584d93-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.094326887s
Jun  4 13:24:39.253: INFO: Pod "client-containers-18584d93-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.100431844s
Jun  4 13:24:41.262: INFO: Pod "client-containers-18584d93-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.108925389s
STEP: Saw pod success
Jun  4 13:24:41.262: INFO: Pod "client-containers-18584d93-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:24:41.274: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod client-containers-18584d93-86cc-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:24:41.460: INFO: Waiting for pod client-containers-18584d93-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:24:41.466: INFO: Pod client-containers-18584d93-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:24:41.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bstvh" for this suite.
Jun  4 13:24:47.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:24:48.050: INFO: namespace: e2e-tests-containers-bstvh, resource: bindings, ignored listing per whitelist
Jun  4 13:24:48.110: INFO: namespace e2e-tests-containers-bstvh deletion completed in 6.637337838s

• [SLOW TEST:13.432 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:24:48.121: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jun  4 13:24:48.478: INFO: Waiting up to 5m0s for pod "pod-2049da97-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-zxsxn" to be "success or failure"
Jun  4 13:24:48.484: INFO: Pod "pod-2049da97-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.249423ms
Jun  4 13:24:50.603: INFO: Pod "pod-2049da97-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.124928535s
Jun  4 13:24:52.736: INFO: Pod "pod-2049da97-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.257272301s
STEP: Saw pod success
Jun  4 13:24:52.736: INFO: Pod "pod-2049da97-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:24:52.749: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-2049da97-86cc-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:24:53.199: INFO: Waiting for pod pod-2049da97-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:24:53.207: INFO: Pod pod-2049da97-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:24:53.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zxsxn" for this suite.
Jun  4 13:24:59.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:24:59.731: INFO: namespace: e2e-tests-emptydir-zxsxn, resource: bindings, ignored listing per whitelist
Jun  4 13:24:59.941: INFO: namespace e2e-tests-emptydir-zxsxn deletion completed in 6.727093203s

• [SLOW TEST:11.822 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:24:59.951: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:25:00.341: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jun  4 13:25:00.368: INFO: Pod name sample-pod: Found 0 pods out of 1
Jun  4 13:25:05.376: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun  4 13:25:05.377: INFO: Creating deployment "test-rolling-update-deployment"
Jun  4 13:25:05.384: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jun  4 13:25:05.398: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jun  4 13:25:07.413: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jun  4 13:25:07.421: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251505, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251505, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 13:25:09.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251505, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251505, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251505, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-68b55d7bc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 13:25:11.439: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun  4 13:25:11.463: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-gs2c4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gs2c4/deployments/test-rolling-update-deployment,UID:2a5f5ca5-86cc-11e9-9957-a6a8fec88741,ResourceVersion:14817,Generation:1,CreationTimestamp:2019-06-04 13:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-04 13:25:05 +0000 UTC 2019-06-04 13:25:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-04 13:25:09 +0000 UTC 2019-06-04 13:25:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun  4 13:25:11.520: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-gs2c4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gs2c4/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:2a62d3c7-86cc-11e9-9957-a6a8fec88741,ResourceVersion:14808,Generation:1,CreationTimestamp:2019-06-04 13:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 2a5f5ca5-86cc-11e9-9957-a6a8fec88741 0xc001584467 0xc001584468}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun  4 13:25:11.520: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jun  4 13:25:11.520: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-gs2c4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-gs2c4/replicasets/test-rolling-update-controller,UID:275eee21-86cc-11e9-9957-a6a8fec88741,ResourceVersion:14816,Generation:2,CreationTimestamp:2019-06-04 13:25:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 2a5f5ca5-86cc-11e9-9957-a6a8fec88741 0xc0015843a7 0xc0015843a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun  4 13:25:11.527: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-xgplx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-xgplx,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-gs2c4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-gs2c4/pods/test-rolling-update-deployment-68b55d7bc6-xgplx,UID:2a639b56-86cc-11e9-9957-a6a8fec88741,ResourceVersion:14807,Generation:0,CreationTimestamp:2019-06-04 13:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 2a62d3c7-86cc-11e9-9957-a6a8fec88741 0xc001584d37 0xc001584d38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-z4srh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z4srh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-z4srh true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001584da0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001584dc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:25:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:25:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:25:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:172.25.2.16,StartTime:2019-06-04 13:25:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-04 13:25:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://849da3b89d6d2f006b9270f4cd06100eb889639e8ae532f65a4adf167753030e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:25:11.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-gs2c4" for this suite.
Jun  4 13:25:17.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:25:18.097: INFO: namespace: e2e-tests-deployment-gs2c4, resource: bindings, ignored listing per whitelist
Jun  4 13:25:18.338: INFO: namespace e2e-tests-deployment-gs2c4 deletion completed in 6.799019886s

• [SLOW TEST:18.388 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:25:18.347: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun  4 13:25:18.926: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:25:24.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-lc8hf" for this suite.
Jun  4 13:25:30.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:25:30.781: INFO: namespace: e2e-tests-init-container-lc8hf, resource: bindings, ignored listing per whitelist
Jun  4 13:25:31.136: INFO: namespace e2e-tests-init-container-lc8hf deletion completed in 6.915102644s

• [SLOW TEST:12.789 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:25:31.142: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jun  4 13:25:31.745: INFO: Waiting up to 5m0s for pod "pod-3a122436-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-vcnbh" to be "success or failure"
Jun  4 13:25:31.763: INFO: Pod "pod-3a122436-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.709353ms
Jun  4 13:25:33.777: INFO: Pod "pod-3a122436-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03197292s
Jun  4 13:25:35.947: INFO: Pod "pod-3a122436-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.201867571s
STEP: Saw pod success
Jun  4 13:25:35.947: INFO: Pod "pod-3a122436-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:25:35.956: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-3a122436-86cc-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:25:36.274: INFO: Waiting for pod pod-3a122436-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:25:36.281: INFO: Pod pod-3a122436-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:25:36.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vcnbh" for this suite.
Jun  4 13:25:42.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:25:42.454: INFO: namespace: e2e-tests-emptydir-vcnbh, resource: bindings, ignored listing per whitelist
Jun  4 13:25:42.745: INFO: namespace e2e-tests-emptydir-vcnbh deletion completed in 6.457378289s

• [SLOW TEST:11.604 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:25:42.750: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 13:25:43.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40d126b8-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-jqn6x" to be "success or failure"
Jun  4 13:25:43.235: INFO: Pod "downwardapi-volume-40d126b8-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 98.518809ms
Jun  4 13:25:45.244: INFO: Pod "downwardapi-volume-40d126b8-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.106808849s
STEP: Saw pod success
Jun  4 13:25:45.244: INFO: Pod "downwardapi-volume-40d126b8-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:25:45.277: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-40d126b8-86cc-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 13:25:45.372: INFO: Waiting for pod downwardapi-volume-40d126b8-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:25:45.381: INFO: Pod downwardapi-volume-40d126b8-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:25:45.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jqn6x" for this suite.
Jun  4 13:25:51.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:25:51.723: INFO: namespace: e2e-tests-downward-api-jqn6x, resource: bindings, ignored listing per whitelist
Jun  4 13:25:52.342: INFO: namespace e2e-tests-downward-api-jqn6x deletion completed in 6.949743741s

• [SLOW TEST:9.593 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:25:52.343: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-46a86dc0-86cc-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:25:52.870: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-46a9f670-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-q5jt9" to be "success or failure"
Jun  4 13:25:52.877: INFO: Pod "pod-projected-configmaps-46a9f670-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.123342ms
Jun  4 13:25:54.941: INFO: Pod "pod-projected-configmaps-46a9f670-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071136132s
Jun  4 13:25:57.042: INFO: Pod "pod-projected-configmaps-46a9f670-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.171911817s
STEP: Saw pod success
Jun  4 13:25:57.042: INFO: Pod "pod-projected-configmaps-46a9f670-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:25:57.048: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-configmaps-46a9f670-86cc-11e9-8620-ba945f56578b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:25:57.157: INFO: Waiting for pod pod-projected-configmaps-46a9f670-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:25:57.235: INFO: Pod pod-projected-configmaps-46a9f670-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:25:57.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q5jt9" for this suite.
Jun  4 13:26:03.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:26:03.853: INFO: namespace: e2e-tests-projected-q5jt9, resource: bindings, ignored listing per whitelist
Jun  4 13:26:03.974: INFO: namespace e2e-tests-projected-q5jt9 deletion completed in 6.732230426s

• [SLOW TEST:11.632 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:26:03.980: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun  4 13:26:08.954: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4d8b292b-86cc-11e9-8620-ba945f56578b"
Jun  4 13:26:08.955: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4d8b292b-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-pods-5g8s6" to be "terminated due to deadline exceeded"
Jun  4 13:26:09.032: INFO: Pod "pod-update-activedeadlineseconds-4d8b292b-86cc-11e9-8620-ba945f56578b": Phase="Running", Reason="", readiness=true. Elapsed: 77.005479ms
Jun  4 13:26:11.135: INFO: Pod "pod-update-activedeadlineseconds-4d8b292b-86cc-11e9-8620-ba945f56578b": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.180721811s
Jun  4 13:26:11.135: INFO: Pod "pod-update-activedeadlineseconds-4d8b292b-86cc-11e9-8620-ba945f56578b" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:26:11.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5g8s6" for this suite.
Jun  4 13:26:17.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:26:17.395: INFO: namespace: e2e-tests-pods-5g8s6, resource: bindings, ignored listing per whitelist
Jun  4 13:26:17.578: INFO: namespace e2e-tests-pods-5g8s6 deletion completed in 6.435514354s

• [SLOW TEST:13.599 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:26:17.583: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-w4fzv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun  4 13:26:18.081: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun  4 13:26:36.232: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.2.18:8080/dial?request=hostName&protocol=udp&host=172.25.0.25&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-w4fzv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:26:36.232: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:26:37.099: INFO: Waiting for endpoints: map[]
Jun  4 13:26:37.106: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.2.18:8080/dial?request=hostName&protocol=udp&host=172.25.2.17&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-w4fzv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:26:37.106: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:26:37.875: INFO: Waiting for endpoints: map[]
Jun  4 13:26:37.881: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.2.18:8080/dial?request=hostName&protocol=udp&host=172.25.1.68&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-w4fzv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:26:37.881: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:26:38.588: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:26:38.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-w4fzv" for this suite.
Jun  4 13:27:00.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:27:00.902: INFO: namespace: e2e-tests-pod-network-test-w4fzv, resource: bindings, ignored listing per whitelist
Jun  4 13:27:01.148: INFO: namespace e2e-tests-pod-network-test-w4fzv deletion completed in 22.552313541s

• [SLOW TEST:43.566 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:27:01.155: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun  4 13:27:01.448: INFO: Waiting up to 5m0s for pod "downward-api-6f8bbc5c-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-8hn46" to be "success or failure"
Jun  4 13:27:01.458: INFO: Pod "downward-api-6f8bbc5c-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.032977ms
Jun  4 13:27:03.466: INFO: Pod "downward-api-6f8bbc5c-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017756136s
Jun  4 13:27:05.478: INFO: Pod "downward-api-6f8bbc5c-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029736834s
STEP: Saw pod success
Jun  4 13:27:05.478: INFO: Pod "downward-api-6f8bbc5c-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:27:05.537: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downward-api-6f8bbc5c-86cc-11e9-8620-ba945f56578b container dapi-container: <nil>
STEP: delete the pod
Jun  4 13:27:05.762: INFO: Waiting for pod downward-api-6f8bbc5c-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:27:05.767: INFO: Pod downward-api-6f8bbc5c-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:27:05.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8hn46" for this suite.
Jun  4 13:27:11.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:27:12.250: INFO: namespace: e2e-tests-downward-api-8hn46, resource: bindings, ignored listing per whitelist
Jun  4 13:27:12.370: INFO: namespace e2e-tests-downward-api-8hn46 deletion completed in 6.597515814s

• [SLOW TEST:11.216 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:27:12.373: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun  4 13:27:12.749: INFO: PodSpec: initContainers in spec.initContainers
Jun  4 13:28:01.595: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7649a0e1-86cc-11e9-8620-ba945f56578b", GenerateName:"", Namespace:"e2e-tests-init-container-c4thz", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-c4thz/pods/pod-init-7649a0e1-86cc-11e9-8620-ba945f56578b", UID:"764b81c7-86cc-11e9-9957-a6a8fec88741", ResourceVersion:"15540", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63695251632, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"749803330"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-slgkb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001c16380), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-slgkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-slgkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-slgkb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001a75548), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-4jvsx-65d7bd6f69-45s5z", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000f15860), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a755c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a755e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001a755e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001a755ec)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251632, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251632, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251632, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695251632, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"138.68.109.151", PodIP:"172.25.1.70", StartTime:(*v1.Time)(0xc0013f3160), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0013038f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001303960)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://23798db9b0edf941baf64d8ed97cf757c30d04755eca5c7ef15b30f64183ac18"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0013f31a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0013f3180), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:28:01.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-c4thz" for this suite.
Jun  4 13:28:23.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:28:24.090: INFO: namespace: e2e-tests-init-container-c4thz, resource: bindings, ignored listing per whitelist
Jun  4 13:28:24.135: INFO: namespace e2e-tests-init-container-c4thz deletion completed in 22.531281534s

• [SLOW TEST:71.762 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:28:24.141: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a10bdeba-86cc-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:28:24.555: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a1143e6f-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-vsg28" to be "success or failure"
Jun  4 13:28:24.560: INFO: Pod "pod-projected-configmaps-a1143e6f-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.872821ms
Jun  4 13:28:26.570: INFO: Pod "pod-projected-configmaps-a1143e6f-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014342654s
STEP: Saw pod success
Jun  4 13:28:26.570: INFO: Pod "pod-projected-configmaps-a1143e6f-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:28:26.579: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-configmaps-a1143e6f-86cc-11e9-8620-ba945f56578b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:28:26.706: INFO: Waiting for pod pod-projected-configmaps-a1143e6f-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:28:26.711: INFO: Pod pod-projected-configmaps-a1143e6f-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:28:26.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vsg28" for this suite.
Jun  4 13:28:32.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:28:33.245: INFO: namespace: e2e-tests-projected-vsg28, resource: bindings, ignored listing per whitelist
Jun  4 13:28:33.272: INFO: namespace e2e-tests-projected-vsg28 deletion completed in 6.553564886s

• [SLOW TEST:9.132 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:28:33.279: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun  4 13:28:33.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-fr46l'
Jun  4 13:28:34.044: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun  4 13:28:34.044: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jun  4 13:28:34.062: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-dzkpt]
Jun  4 13:28:34.062: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-dzkpt" in namespace "e2e-tests-kubectl-fr46l" to be "running and ready"
Jun  4 13:28:34.069: INFO: Pod "e2e-test-nginx-rc-dzkpt": Phase="Pending", Reason="", readiness=false. Elapsed: 6.83342ms
Jun  4 13:28:36.076: INFO: Pod "e2e-test-nginx-rc-dzkpt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013056356s
Jun  4 13:28:38.139: INFO: Pod "e2e-test-nginx-rc-dzkpt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.07631746s
Jun  4 13:28:40.144: INFO: Pod "e2e-test-nginx-rc-dzkpt": Phase="Running", Reason="", readiness=true. Elapsed: 6.081919436s
Jun  4 13:28:40.144: INFO: Pod "e2e-test-nginx-rc-dzkpt" satisfied condition "running and ready"
Jun  4 13:28:40.144: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-dzkpt]
Jun  4 13:28:40.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-fr46l'
Jun  4 13:28:40.489: INFO: stderr: ""
Jun  4 13:28:40.489: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Jun  4 13:28:40.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-fr46l'
Jun  4 13:28:40.640: INFO: stderr: ""
Jun  4 13:28:40.640: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:28:40.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fr46l" for this suite.
Jun  4 13:29:02.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:29:03.159: INFO: namespace: e2e-tests-kubectl-fr46l, resource: bindings, ignored listing per whitelist
Jun  4 13:29:03.539: INFO: namespace e2e-tests-kubectl-fr46l deletion completed in 22.890193935s

• [SLOW TEST:30.261 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:29:03.548: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:29:03.953: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Jun  4 13:29:04.042: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wn54v/daemonsets","resourceVersion":"15768"},"items":null}

Jun  4 13:29:04.056: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wn54v/pods","resourceVersion":"15768"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:29:04.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wn54v" for this suite.
Jun  4 13:29:10.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:29:10.542: INFO: namespace: e2e-tests-daemonsets-wn54v, resource: bindings, ignored listing per whitelist
Jun  4 13:29:10.649: INFO: namespace e2e-tests-daemonsets-wn54v deletion completed in 6.5641916s

S [SKIPPING] [7.102 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jun  4 13:29:03.953: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:29:10.655: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun  4 13:29:10.956: INFO: Waiting up to 5m0s for pod "pod-bcbc6f8b-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-8qvhf" to be "success or failure"
Jun  4 13:29:11.041: INFO: Pod "pod-bcbc6f8b-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 85.029322ms
Jun  4 13:29:13.052: INFO: Pod "pod-bcbc6f8b-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.096100936s
Jun  4 13:29:15.134: INFO: Pod "pod-bcbc6f8b-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.178530488s
STEP: Saw pod success
Jun  4 13:29:15.134: INFO: Pod "pod-bcbc6f8b-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:29:15.140: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-bcbc6f8b-86cc-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:29:15.305: INFO: Waiting for pod pod-bcbc6f8b-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:29:15.309: INFO: Pod pod-bcbc6f8b-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:29:15.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8qvhf" for this suite.
Jun  4 13:29:21.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:29:21.834: INFO: namespace: e2e-tests-emptydir-8qvhf, resource: bindings, ignored listing per whitelist
Jun  4 13:29:21.835: INFO: namespace e2e-tests-emptydir-8qvhf deletion completed in 6.518663291s

• [SLOW TEST:11.180 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:29:21.840: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 13:29:22.135: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c36312ad-86cc-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-dfk9b" to be "success or failure"
Jun  4 13:29:22.147: INFO: Pod "downwardapi-volume-c36312ad-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.90151ms
Jun  4 13:29:24.155: INFO: Pod "downwardapi-volume-c36312ad-86cc-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01925128s
Jun  4 13:29:26.160: INFO: Pod "downwardapi-volume-c36312ad-86cc-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024164294s
STEP: Saw pod success
Jun  4 13:29:26.160: INFO: Pod "downwardapi-volume-c36312ad-86cc-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:29:26.164: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-c36312ad-86cc-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 13:29:26.234: INFO: Waiting for pod downwardapi-volume-c36312ad-86cc-11e9-8620-ba945f56578b to disappear
Jun  4 13:29:26.242: INFO: Pod downwardapi-volume-c36312ad-86cc-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:29:26.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dfk9b" for this suite.
Jun  4 13:29:32.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:29:32.696: INFO: namespace: e2e-tests-downward-api-dfk9b, resource: bindings, ignored listing per whitelist
Jun  4 13:29:32.972: INFO: namespace e2e-tests-downward-api-dfk9b deletion completed in 6.722418126s

• [SLOW TEST:11.133 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:29:32.977: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-vgqc
STEP: Creating a pod to test atomic-volume-subpath
Jun  4 13:29:33.649: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-vgqc" in namespace "e2e-tests-subpath-fdvrt" to be "success or failure"
Jun  4 13:29:33.656: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.328682ms
Jun  4 13:29:35.661: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011225575s
Jun  4 13:29:37.666: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016551007s
Jun  4 13:29:39.672: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 6.022722118s
Jun  4 13:29:41.834: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 8.184674158s
Jun  4 13:29:43.842: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 10.192602901s
Jun  4 13:29:45.940: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 12.290320773s
Jun  4 13:29:47.948: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 14.298539341s
Jun  4 13:29:49.955: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 16.305534832s
Jun  4 13:29:51.961: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 18.311455616s
Jun  4 13:29:53.967: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 20.317214669s
Jun  4 13:29:55.973: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 22.323003393s
Jun  4 13:29:57.978: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Running", Reason="", readiness=false. Elapsed: 24.328586008s
Jun  4 13:30:00.039: INFO: Pod "pod-subpath-test-secret-vgqc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.389047616s
STEP: Saw pod success
Jun  4 13:30:00.039: INFO: Pod "pod-subpath-test-secret-vgqc" satisfied condition "success or failure"
Jun  4 13:30:00.046: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-subpath-test-secret-vgqc container test-container-subpath-secret-vgqc: <nil>
STEP: delete the pod
Jun  4 13:30:00.435: INFO: Waiting for pod pod-subpath-test-secret-vgqc to disappear
Jun  4 13:30:00.440: INFO: Pod pod-subpath-test-secret-vgqc no longer exists
STEP: Deleting pod pod-subpath-test-secret-vgqc
Jun  4 13:30:00.440: INFO: Deleting pod "pod-subpath-test-secret-vgqc" in namespace "e2e-tests-subpath-fdvrt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:30:00.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fdvrt" for this suite.
Jun  4 13:30:06.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:30:06.712: INFO: namespace: e2e-tests-subpath-fdvrt, resource: bindings, ignored listing per whitelist
Jun  4 13:30:06.809: INFO: namespace e2e-tests-subpath-fdvrt deletion completed in 6.357602347s

• [SLOW TEST:33.832 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:30:06.811: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:30:07.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 version'
Jun  4 13:30:07.588: INFO: stderr: ""
Jun  4 13:30:07.588: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.5\", GitCommit:\"2166946f41b36dea2c4626f90a77706f426cdea2\", GitTreeState:\"clean\", BuildDate:\"2019-03-25T15:19:22Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:30:07.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j8sz2" for this suite.
Jun  4 13:30:13.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:30:13.940: INFO: namespace: e2e-tests-kubectl-j8sz2, resource: bindings, ignored listing per whitelist
Jun  4 13:30:14.547: INFO: namespace e2e-tests-kubectl-j8sz2 deletion completed in 6.948984828s

• [SLOW TEST:7.736 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:30:14.553: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-89grc
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-89grc
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-89grc
Jun  4 13:30:14.891: INFO: Found 0 stateful pods, waiting for 1
Jun  4 13:30:24.940: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jun  4 13:30:24.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 13:30:26.219: INFO: stderr: ""
Jun  4 13:30:26.219: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 13:30:26.219: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 13:30:26.242: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun  4 13:30:36.248: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun  4 13:30:36.248: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 13:30:36.268: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:30:36.269: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:26 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:30:36.269: INFO: 
Jun  4 13:30:36.269: INFO: StatefulSet ss has not reached scale 3, at 1
Jun  4 13:30:37.282: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993901541s
Jun  4 13:30:38.340: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.981226266s
Jun  4 13:30:39.353: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.923270497s
Jun  4 13:30:40.434: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.909631381s
Jun  4 13:30:41.446: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.829372589s
Jun  4 13:30:42.454: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.817356128s
Jun  4 13:30:43.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.809021972s
Jun  4 13:30:44.468: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.802545002s
Jun  4 13:30:45.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 795.686846ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-89grc
Jun  4 13:30:46.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:30:47.589: INFO: stderr: ""
Jun  4 13:30:47.589: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun  4 13:30:47.589: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun  4 13:30:47.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:30:48.838: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jun  4 13:30:48.838: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun  4 13:30:48.838: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun  4 13:30:48.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:30:49.745: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jun  4 13:30:49.745: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun  4 13:30:49.745: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun  4 13:30:49.754: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 13:30:49.754: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 13:30:49.754: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jun  4 13:30:49.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 13:30:50.697: INFO: stderr: ""
Jun  4 13:30:50.697: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 13:30:50.697: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 13:30:50.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 13:30:51.542: INFO: stderr: ""
Jun  4 13:30:51.542: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 13:30:51.542: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 13:30:51.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 13:30:52.468: INFO: stderr: ""
Jun  4 13:30:52.468: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 13:30:52.468: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 13:30:52.468: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 13:30:52.474: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jun  4 13:31:02.484: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun  4 13:31:02.484: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun  4 13:31:02.484: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun  4 13:31:02.635: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:02.635: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:02.635: INFO: ss-1  worker-4jvsx-65d7bd6f69-4wzp4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:02.635: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:02.635: INFO: 
Jun  4 13:31:02.635: INFO: StatefulSet ss has not reached scale 0, at 3
Jun  4 13:31:03.642: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:03.642: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:03.642: INFO: ss-1  worker-4jvsx-65d7bd6f69-4wzp4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:03.642: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:03.642: INFO: 
Jun  4 13:31:03.642: INFO: StatefulSet ss has not reached scale 0, at 3
Jun  4 13:31:04.648: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:04.648: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:04.648: INFO: ss-1  worker-4jvsx-65d7bd6f69-4wzp4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:04.648: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:04.648: INFO: 
Jun  4 13:31:04.648: INFO: StatefulSet ss has not reached scale 0, at 3
Jun  4 13:31:05.662: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:05.662: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:05.662: INFO: ss-1  worker-4jvsx-65d7bd6f69-4wzp4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:05.662: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:05.662: INFO: 
Jun  4 13:31:05.662: INFO: StatefulSet ss has not reached scale 0, at 3
Jun  4 13:31:06.669: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:06.669: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:06.669: INFO: ss-1  worker-4jvsx-65d7bd6f69-4wzp4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:06.669: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:06.669: INFO: 
Jun  4 13:31:06.669: INFO: StatefulSet ss has not reached scale 0, at 3
Jun  4 13:31:07.677: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:07.678: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:07.678: INFO: ss-1  worker-4jvsx-65d7bd6f69-4wzp4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:07.678: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:07.678: INFO: 
Jun  4 13:31:07.678: INFO: StatefulSet ss has not reached scale 0, at 3
Jun  4 13:31:08.684: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:08.684: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:08.684: INFO: ss-1  worker-4jvsx-65d7bd6f69-4wzp4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:08.684: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:08.684: INFO: 
Jun  4 13:31:08.684: INFO: StatefulSet ss has not reached scale 0, at 3
Jun  4 13:31:09.742: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:09.742: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:09.742: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:09.742: INFO: 
Jun  4 13:31:09.742: INFO: StatefulSet ss has not reached scale 0, at 2
Jun  4 13:31:10.749: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:10.749: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:10.750: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:10.750: INFO: 
Jun  4 13:31:10.750: INFO: StatefulSet ss has not reached scale 0, at 2
Jun  4 13:31:11.764: INFO: POD   NODE                           PHASE    GRACE  CONDITIONS
Jun  4 13:31:11.764: INFO: ss-0  worker-4jvsx-65d7bd6f69-45s5z  Pending  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:14 +0000 UTC  }]
Jun  4 13:31:11.765: INFO: ss-2  worker-4jvsx-65d7bd6f69-gv9cg  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:30:36 +0000 UTC  }]
Jun  4 13:31:11.765: INFO: 
Jun  4 13:31:11.765: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-89grc
Jun  4 13:31:12.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:31:13.442: INFO: rc: 1
Jun  4 13:31:13.442: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001cc4ba0 exit status 1 <nil> <nil> true [0xc002f177b0 0xc002f177c8 0xc002f177e0] [0xc002f177b0 0xc002f177c8 0xc002f177e0] [0xc002f177c0 0xc002f177d8] [0x92f8e0 0x92f8e0] 0xc000a00f60 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Jun  4 13:31:23.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:31:23.573: INFO: rc: 1
Jun  4 13:31:23.573: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc51d0 exit status 1 <nil> <nil> true [0xc002f177e8 0xc002f17808 0xc002f17820] [0xc002f177e8 0xc002f17808 0xc002f17820] [0xc002f177f8 0xc002f17818] [0x92f8e0 0x92f8e0] 0xc000a012c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:31:33.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:31:33.695: INFO: rc: 1
Jun  4 13:31:33.695: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc56e0 exit status 1 <nil> <nil> true [0xc002f17828 0xc002f17840 0xc002f17858] [0xc002f17828 0xc002f17840 0xc002f17858] [0xc002f17838 0xc002f17850] [0x92f8e0 0x92f8e0] 0xc000a015c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:31:43.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:31:43.889: INFO: rc: 1
Jun  4 13:31:43.889: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc5c50 exit status 1 <nil> <nil> true [0xc002f17860 0xc002f17878 0xc002f17890] [0xc002f17860 0xc002f17878 0xc002f17890] [0xc002f17870 0xc002f17888] [0x92f8e0 0x92f8e0] 0xc000a018c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:31:53.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:31:54.012: INFO: rc: 1
Jun  4 13:31:54.012: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00184a0c0 exit status 1 <nil> <nil> true [0xc002f17898 0xc002f178b0 0xc002f178c8] [0xc002f17898 0xc002f178b0 0xc002f178c8] [0xc002f178a8 0xc002f178c0] [0x92f8e0 0x92f8e0] 0xc000a01f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:32:04.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:32:04.171: INFO: rc: 1
Jun  4 13:32:04.171: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00184a4b0 exit status 1 <nil> <nil> true [0xc002f178d0 0xc002f178e8 0xc002f17900] [0xc002f178d0 0xc002f178e8 0xc002f17900] [0xc002f178e0 0xc002f178f8] [0x92f8e0 0x92f8e0] 0xc000c08a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:32:14.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:32:14.330: INFO: rc: 1
Jun  4 13:32:14.330: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00184a8a0 exit status 1 <nil> <nil> true [0xc002f17908 0xc002f17920 0xc002f17950] [0xc002f17908 0xc002f17920 0xc002f17950] [0xc002f17918 0xc002f17948] [0x92f8e0 0x92f8e0] 0xc000c09140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:32:24.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:32:24.513: INFO: rc: 1
Jun  4 13:32:24.513: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc4420 exit status 1 <nil> <nil> true [0xc002f16028 0xc002f16068 0xc002f16090] [0xc002f16028 0xc002f16068 0xc002f16090] [0xc002f16048 0xc002f16088] [0x92f8e0 0x92f8e0] 0xc000a002a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:32:34.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:32:34.644: INFO: rc: 1
Jun  4 13:32:34.644: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc4cf0 exit status 1 <nil> <nil> true [0xc002f160c0 0xc002f160f0 0xc002f16108] [0xc002f160c0 0xc002f160f0 0xc002f16108] [0xc002f160e0 0xc002f16100] [0x92f8e0 0x92f8e0] 0xc000a005a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:32:44.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:32:44.837: INFO: rc: 1
Jun  4 13:32:44.837: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc5260 exit status 1 <nil> <nil> true [0xc002f16110 0xc002f16128 0xc002f16148] [0xc002f16110 0xc002f16128 0xc002f16148] [0xc002f16120 0xc002f16140] [0x92f8e0 0x92f8e0] 0xc000a008a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:32:54.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:32:55.051: INFO: rc: 1
Jun  4 13:32:55.051: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc5800 exit status 1 <nil> <nil> true [0xc002f16150 0xc002f16168 0xc002f16198] [0xc002f16150 0xc002f16168 0xc002f16198] [0xc002f16160 0xc002f16190] [0x92f8e0 0x92f8e0] 0xc000a00ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:33:05.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:33:05.181: INFO: rc: 1
Jun  4 13:33:05.181: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc5d70 exit status 1 <nil> <nil> true [0xc002f161a8 0xc002f161e8 0xc002f16228] [0xc002f161a8 0xc002f161e8 0xc002f16228] [0xc002f161d0 0xc002f16210] [0x92f8e0 0x92f8e0] 0xc000a00f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:33:15.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:33:15.437: INFO: rc: 1
Jun  4 13:33:15.437: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de0330 exit status 1 <nil> <nil> true [0xc002f16230 0xc002f16248 0xc002f16260] [0xc002f16230 0xc002f16248 0xc002f16260] [0xc002f16240 0xc002f16258] [0x92f8e0 0x92f8e0] 0xc000a012c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:33:25.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:33:25.659: INFO: rc: 1
Jun  4 13:33:25.659: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de0b70 exit status 1 <nil> <nil> true [0xc002f16268 0xc002f16280 0xc002f16298] [0xc002f16268 0xc002f16280 0xc002f16298] [0xc002f16278 0xc002f16290] [0x92f8e0 0x92f8e0] 0xc000a015c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:33:35.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:33:35.850: INFO: rc: 1
Jun  4 13:33:35.850: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de1080 exit status 1 <nil> <nil> true [0xc002f162a0 0xc002f162b8 0xc002f162d0] [0xc002f162a0 0xc002f162b8 0xc002f162d0] [0xc002f162b0 0xc002f162c8] [0x92f8e0 0x92f8e0] 0xc000a018c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:33:45.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:33:46.053: INFO: rc: 1
Jun  4 13:33:46.054: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de1530 exit status 1 <nil> <nil> true [0xc002f162e0 0xc002f162f8 0xc002f16310] [0xc002f162e0 0xc002f162f8 0xc002f16310] [0xc002f162f0 0xc002f16308] [0x92f8e0 0x92f8e0] 0xc000a01f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:33:56.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:33:56.182: INFO: rc: 1
Jun  4 13:33:56.183: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de1ce0 exit status 1 <nil> <nil> true [0xc002f16318 0xc002f16330 0xc002f16348] [0xc002f16318 0xc002f16330 0xc002f16348] [0xc002f16328 0xc002f16340] [0x92f8e0 0x92f8e0] 0xc0016f65a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:34:06.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:34:06.347: INFO: rc: 1
Jun  4 13:34:06.347: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dec0f0 exit status 1 <nil> <nil> true [0xc002f16350 0xc002f16368 0xc002f16380] [0xc002f16350 0xc002f16368 0xc002f16380] [0xc002f16360 0xc002f16378] [0x92f8e0 0x92f8e0] 0xc0016f6ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:34:16.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:34:16.542: INFO: rc: 1
Jun  4 13:34:16.542: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dec4e0 exit status 1 <nil> <nil> true [0xc002f16388 0xc002f163a0 0xc002f163b8] [0xc002f16388 0xc002f163a0 0xc002f163b8] [0xc002f16398 0xc002f163b0] [0x92f8e0 0x92f8e0] 0xc0016f6f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:34:26.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:34:26.678: INFO: rc: 1
Jun  4 13:34:26.679: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de06c0 exit status 1 <nil> <nil> true [0xc002f16028 0xc002f16068 0xc002f16090] [0xc002f16028 0xc002f16068 0xc002f16090] [0xc002f16048 0xc002f16088] [0x92f8e0 0x92f8e0] 0xc000a002a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:34:36.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:34:36.894: INFO: rc: 1
Jun  4 13:34:36.894: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de0e70 exit status 1 <nil> <nil> true [0xc002f160c0 0xc002f160f0 0xc002f16108] [0xc002f160c0 0xc002f160f0 0xc002f16108] [0xc002f160e0 0xc002f16100] [0x92f8e0 0x92f8e0] 0xc000a005a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:34:46.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:34:47.134: INFO: rc: 1
Jun  4 13:34:47.135: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de1380 exit status 1 <nil> <nil> true [0xc002f16110 0xc002f16128 0xc002f16148] [0xc002f16110 0xc002f16128 0xc002f16148] [0xc002f16120 0xc002f16140] [0x92f8e0 0x92f8e0] 0xc000a008a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:34:57.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:34:57.328: INFO: rc: 1
Jun  4 13:34:57.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000de1bc0 exit status 1 <nil> <nil> true [0xc002f16150 0xc002f16168 0xc002f16198] [0xc002f16150 0xc002f16168 0xc002f16198] [0xc002f16160 0xc002f16190] [0x92f8e0 0x92f8e0] 0xc000a00ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:35:07.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:35:07.520: INFO: rc: 1
Jun  4 13:35:07.520: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc4000 exit status 1 <nil> <nil> true [0xc002f161a8 0xc002f161e8 0xc002f16228] [0xc002f161a8 0xc002f161e8 0xc002f16228] [0xc002f161d0 0xc002f16210] [0x92f8e0 0x92f8e0] 0xc000a00f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:35:17.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:35:17.740: INFO: rc: 1
Jun  4 13:35:17.740: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc4630 exit status 1 <nil> <nil> true [0xc002f16230 0xc002f16248 0xc002f16260] [0xc002f16230 0xc002f16248 0xc002f16260] [0xc002f16240 0xc002f16258] [0x92f8e0 0x92f8e0] 0xc000a012c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:35:27.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:35:27.865: INFO: rc: 1
Jun  4 13:35:27.865: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc4d50 exit status 1 <nil> <nil> true [0xc002f16268 0xc002f16280 0xc002f16298] [0xc002f16268 0xc002f16280 0xc002f16298] [0xc002f16278 0xc002f16290] [0x92f8e0 0x92f8e0] 0xc000a015c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:35:37.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:35:38.034: INFO: rc: 1
Jun  4 13:35:38.034: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc5320 exit status 1 <nil> <nil> true [0xc002f162a0 0xc002f162b8 0xc002f162d0] [0xc002f162a0 0xc002f162b8 0xc002f162d0] [0xc002f162b0 0xc002f162c8] [0x92f8e0 0x92f8e0] 0xc000a018c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:35:48.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:35:48.163: INFO: rc: 1
Jun  4 13:35:48.163: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc58f0 exit status 1 <nil> <nil> true [0xc002f162e0 0xc002f162f8 0xc002f16310] [0xc002f162e0 0xc002f162f8 0xc002f16310] [0xc002f162f0 0xc002f16308] [0x92f8e0 0x92f8e0] 0xc000a01f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:35:58.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:35:58.334: INFO: rc: 1
Jun  4 13:35:58.335: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001cc5dd0 exit status 1 <nil> <nil> true [0xc002f16318 0xc002f16330 0xc002f16348] [0xc002f16318 0xc002f16330 0xc002f16348] [0xc002f16328 0xc002f16340] [0x92f8e0 0x92f8e0] 0xc0016f65a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:36:08.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:36:08.526: INFO: rc: 1
Jun  4 13:36:08.526: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001dec2a0 exit status 1 <nil> <nil> true [0xc002f16350 0xc002f16368 0xc002f16380] [0xc002f16350 0xc002f16368 0xc002f16380] [0xc002f16360 0xc002f16378] [0x92f8e0 0x92f8e0] 0xc0016f6ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 13:36:18.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-89grc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:36:18.660: INFO: rc: 1
Jun  4 13:36:18.660: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jun  4 13:36:18.660: INFO: Scaling statefulset ss to 0
Jun  4 13:36:18.680: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun  4 13:36:18.685: INFO: Deleting all statefulset in ns e2e-tests-statefulset-89grc
Jun  4 13:36:18.690: INFO: Scaling statefulset ss to 0
Jun  4 13:36:18.703: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 13:36:18.709: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:36:18.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-89grc" for this suite.
Jun  4 13:36:24.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:36:25.566: INFO: namespace: e2e-tests-statefulset-89grc, resource: bindings, ignored listing per whitelist
Jun  4 13:36:25.566: INFO: namespace e2e-tests-statefulset-89grc deletion completed in 6.827352105s

• [SLOW TEST:371.014 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:36:25.569: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c01815e2-86cd-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 13:36:26.091: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c0190371-86cd-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-6mhxx" to be "success or failure"
Jun  4 13:36:26.097: INFO: Pod "pod-projected-secrets-c0190371-86cd-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.193817ms
Jun  4 13:36:28.104: INFO: Pod "pod-projected-secrets-c0190371-86cd-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013236451s
Jun  4 13:36:30.132: INFO: Pod "pod-projected-secrets-c0190371-86cd-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041474645s
STEP: Saw pod success
Jun  4 13:36:30.132: INFO: Pod "pod-projected-secrets-c0190371-86cd-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:36:30.141: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-secrets-c0190371-86cd-11e9-8620-ba945f56578b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun  4 13:36:30.207: INFO: Waiting for pod pod-projected-secrets-c0190371-86cd-11e9-8620-ba945f56578b to disappear
Jun  4 13:36:30.211: INFO: Pod pod-projected-secrets-c0190371-86cd-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:36:30.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6mhxx" for this suite.
Jun  4 13:36:36.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:36:36.541: INFO: namespace: e2e-tests-projected-6mhxx, resource: bindings, ignored listing per whitelist
Jun  4 13:36:36.851: INFO: namespace e2e-tests-projected-6mhxx deletion completed in 6.633624413s

• [SLOW TEST:11.283 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:36:36.860: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:36:39.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-pg7bg" for this suite.
Jun  4 13:37:23.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:37:24.364: INFO: namespace: e2e-tests-kubelet-test-pg7bg, resource: bindings, ignored listing per whitelist
Jun  4 13:37:24.380: INFO: namespace e2e-tests-kubelet-test-pg7bg deletion completed in 44.886678734s

• [SLOW TEST:47.521 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:37:24.381: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun  4 13:37:29.734: INFO: Successfully updated pod "labelsupdatee337991f-86cd-11e9-8620-ba945f56578b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:37:32.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7vrjk" for this suite.
Jun  4 13:37:56.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:37:56.675: INFO: namespace: e2e-tests-downward-api-7vrjk, resource: bindings, ignored listing per whitelist
Jun  4 13:37:56.763: INFO: namespace e2e-tests-downward-api-7vrjk deletion completed in 24.627298887s

• [SLOW TEST:32.382 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:37:56.766: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0604 13:38:27.855950      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun  4 13:38:27.856: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:38:27.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l8f6d" for this suite.
Jun  4 13:38:33.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:38:34.057: INFO: namespace: e2e-tests-gc-l8f6d, resource: bindings, ignored listing per whitelist
Jun  4 13:38:34.361: INFO: namespace e2e-tests-gc-l8f6d deletion completed in 6.497544262s

• [SLOW TEST:37.596 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:38:34.368: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0cc0c9ee-86ce-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 13:38:34.705: INFO: Waiting up to 5m0s for pod "pod-secrets-0cc1cbd4-86ce-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-w4txn" to be "success or failure"
Jun  4 13:38:34.718: INFO: Pod "pod-secrets-0cc1cbd4-86ce-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.125165ms
Jun  4 13:38:36.744: INFO: Pod "pod-secrets-0cc1cbd4-86ce-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03941977s
Jun  4 13:38:38.751: INFO: Pod "pod-secrets-0cc1cbd4-86ce-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045551368s
STEP: Saw pod success
Jun  4 13:38:38.751: INFO: Pod "pod-secrets-0cc1cbd4-86ce-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:38:38.755: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-secrets-0cc1cbd4-86ce-11e9-8620-ba945f56578b container secret-volume-test: <nil>
STEP: delete the pod
Jun  4 13:38:39.034: INFO: Waiting for pod pod-secrets-0cc1cbd4-86ce-11e9-8620-ba945f56578b to disappear
Jun  4 13:38:39.042: INFO: Pod pod-secrets-0cc1cbd4-86ce-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:38:39.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-w4txn" for this suite.
Jun  4 13:38:45.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:38:45.545: INFO: namespace: e2e-tests-secrets-w4txn, resource: bindings, ignored listing per whitelist
Jun  4 13:38:45.563: INFO: namespace e2e-tests-secrets-w4txn deletion completed in 6.513598764s

• [SLOW TEST:11.196 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:38:45.567: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jun  4 13:38:46.869: INFO: Pod name wrapped-volume-race-13f23209-86ce-11e9-8620-ba945f56578b: Found 3 pods out of 5
Jun  4 13:38:51.938: INFO: Pod name wrapped-volume-race-13f23209-86ce-11e9-8620-ba945f56578b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-13f23209-86ce-11e9-8620-ba945f56578b in namespace e2e-tests-emptydir-wrapper-9sx69, will wait for the garbage collector to delete the pods
Jun  4 13:40:34.201: INFO: Deleting ReplicationController wrapped-volume-race-13f23209-86ce-11e9-8620-ba945f56578b took: 11.976477ms
Jun  4 13:40:34.501: INFO: Terminating ReplicationController wrapped-volume-race-13f23209-86ce-11e9-8620-ba945f56578b pods took: 300.647452ms
STEP: Creating RC which spawns configmap-volume pods
Jun  4 13:41:22.360: INFO: Pod name wrapped-volume-race-70a97109-86ce-11e9-8620-ba945f56578b: Found 0 pods out of 5
Jun  4 13:41:27.370: INFO: Pod name wrapped-volume-race-70a97109-86ce-11e9-8620-ba945f56578b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-70a97109-86ce-11e9-8620-ba945f56578b in namespace e2e-tests-emptydir-wrapper-9sx69, will wait for the garbage collector to delete the pods
Jun  4 13:43:33.707: INFO: Deleting ReplicationController wrapped-volume-race-70a97109-86ce-11e9-8620-ba945f56578b took: 12.534404ms
Jun  4 13:43:33.907: INFO: Terminating ReplicationController wrapped-volume-race-70a97109-86ce-11e9-8620-ba945f56578b pods took: 200.471815ms
STEP: Creating RC which spawns configmap-volume pods
Jun  4 13:44:22.045: INFO: Pod name wrapped-volume-race-dbc5fa49-86ce-11e9-8620-ba945f56578b: Found 0 pods out of 5
Jun  4 13:44:27.057: INFO: Pod name wrapped-volume-race-dbc5fa49-86ce-11e9-8620-ba945f56578b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dbc5fa49-86ce-11e9-8620-ba945f56578b in namespace e2e-tests-emptydir-wrapper-9sx69, will wait for the garbage collector to delete the pods
Jun  4 13:46:17.527: INFO: Deleting ReplicationController wrapped-volume-race-dbc5fa49-86ce-11e9-8620-ba945f56578b took: 11.764321ms
Jun  4 13:46:17.634: INFO: Terminating ReplicationController wrapped-volume-race-dbc5fa49-86ce-11e9-8620-ba945f56578b pods took: 106.991109ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:47:02.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-9sx69" for this suite.
Jun  4 13:47:10.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:47:11.607: INFO: namespace: e2e-tests-emptydir-wrapper-9sx69, resource: bindings, ignored listing per whitelist
Jun  4 13:47:11.737: INFO: namespace e2e-tests-emptydir-wrapper-9sx69 deletion completed in 8.973680818s

• [SLOW TEST:506.172 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:47:11.743: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jun  4 13:47:12.248: INFO: Waiting up to 5m0s for pod "client-containers-413a678c-86cf-11e9-8620-ba945f56578b" in namespace "e2e-tests-containers-j4x82" to be "success or failure"
Jun  4 13:47:12.257: INFO: Pod "client-containers-413a678c-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.256501ms
Jun  4 13:47:14.263: INFO: Pod "client-containers-413a678c-86cf-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014401355s
STEP: Saw pod success
Jun  4 13:47:14.263: INFO: Pod "client-containers-413a678c-86cf-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:47:14.268: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod client-containers-413a678c-86cf-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:47:14.507: INFO: Waiting for pod client-containers-413a678c-86cf-11e9-8620-ba945f56578b to disappear
Jun  4 13:47:14.511: INFO: Pod client-containers-413a678c-86cf-11e9-8620-ba945f56578b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:47:14.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-j4x82" for this suite.
Jun  4 13:47:20.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:47:20.693: INFO: namespace: e2e-tests-containers-j4x82, resource: bindings, ignored listing per whitelist
Jun  4 13:47:20.914: INFO: namespace e2e-tests-containers-j4x82 deletion completed in 6.397113636s

• [SLOW TEST:9.172 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:47:20.918: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun  4 13:47:21.623: INFO: Number of nodes with available pods: 0
Jun  4 13:47:21.623: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 13:47:22.637: INFO: Number of nodes with available pods: 0
Jun  4 13:47:22.637: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 13:47:23.644: INFO: Number of nodes with available pods: 1
Jun  4 13:47:23.644: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 13:47:24.636: INFO: Number of nodes with available pods: 1
Jun  4 13:47:24.636: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 13:47:26.135: INFO: Number of nodes with available pods: 1
Jun  4 13:47:26.136: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 13:47:26.648: INFO: Number of nodes with available pods: 3
Jun  4 13:47:26.648: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jun  4 13:47:26.758: INFO: Number of nodes with available pods: 2
Jun  4 13:47:26.758: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 13:47:27.768: INFO: Number of nodes with available pods: 2
Jun  4 13:47:27.768: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 13:47:28.846: INFO: Number of nodes with available pods: 2
Jun  4 13:47:28.846: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 13:47:29.835: INFO: Number of nodes with available pods: 3
Jun  4 13:47:29.835: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-vxwkg, will wait for the garbage collector to delete the pods
Jun  4 13:47:29.944: INFO: Deleting DaemonSet.extensions daemon-set took: 30.157596ms
Jun  4 13:47:30.045: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.849058ms
Jun  4 13:48:04.889: INFO: Number of nodes with available pods: 0
Jun  4 13:48:04.890: INFO: Number of running nodes: 0, number of available pods: 0
Jun  4 13:48:04.894: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vxwkg/daemonsets","resourceVersion":"19470"},"items":null}

Jun  4 13:48:04.899: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vxwkg/pods","resourceVersion":"19470"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:48:04.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vxwkg" for this suite.
Jun  4 13:48:11.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:48:11.140: INFO: namespace: e2e-tests-daemonsets-vxwkg, resource: bindings, ignored listing per whitelist
Jun  4 13:48:11.505: INFO: namespace e2e-tests-daemonsets-vxwkg deletion completed in 6.541642264s

• [SLOW TEST:50.588 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:48:11.513: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun  4 13:48:14.851: INFO: Successfully updated pod "annotationupdate64f2581e-86cf-11e9-8620-ba945f56578b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:48:17.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-km7pj" for this suite.
Jun  4 13:48:39.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:48:39.853: INFO: namespace: e2e-tests-downward-api-km7pj, resource: bindings, ignored listing per whitelist
Jun  4 13:48:39.973: INFO: namespace e2e-tests-downward-api-km7pj deletion completed in 22.838214727s

• [SLOW TEST:28.461 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:48:39.978: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-75eb8db3-86cf-11e9-8620-ba945f56578b
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:48:44.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-98dfz" for this suite.
Jun  4 13:49:08.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:49:09.288: INFO: namespace: e2e-tests-configmap-98dfz, resource: bindings, ignored listing per whitelist
Jun  4 13:49:09.303: INFO: namespace e2e-tests-configmap-98dfz deletion completed in 24.452680357s

• [SLOW TEST:29.327 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:49:09.317: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Jun  4 13:49:09.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-spqvh'
Jun  4 13:49:10.690: INFO: stderr: ""
Jun  4 13:49:10.690: INFO: stdout: "pod/pause created\n"
Jun  4 13:49:10.690: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jun  4 13:49:10.690: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-spqvh" to be "running and ready"
Jun  4 13:49:10.735: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 45.359074ms
Jun  4 13:49:12.744: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.053758336s
Jun  4 13:49:12.744: INFO: Pod "pause" satisfied condition "running and ready"
Jun  4 13:49:12.744: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jun  4 13:49:12.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-spqvh'
Jun  4 13:49:13.039: INFO: stderr: ""
Jun  4 13:49:13.039: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jun  4 13:49:13.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pod pause -L testing-label --namespace=e2e-tests-kubectl-spqvh'
Jun  4 13:49:13.244: INFO: stderr: ""
Jun  4 13:49:13.245: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jun  4 13:49:13.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 label pods pause testing-label- --namespace=e2e-tests-kubectl-spqvh'
Jun  4 13:49:13.492: INFO: stderr: ""
Jun  4 13:49:13.492: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jun  4 13:49:13.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pod pause -L testing-label --namespace=e2e-tests-kubectl-spqvh'
Jun  4 13:49:13.665: INFO: stderr: ""
Jun  4 13:49:13.665: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Jun  4 13:49:13.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-spqvh'
Jun  4 13:49:13.942: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:49:13.942: INFO: stdout: "pod \"pause\" force deleted\n"
Jun  4 13:49:13.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-spqvh'
Jun  4 13:49:14.144: INFO: stderr: "No resources found.\n"
Jun  4 13:49:14.145: INFO: stdout: ""
Jun  4 13:49:14.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -l name=pause --namespace=e2e-tests-kubectl-spqvh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun  4 13:49:14.297: INFO: stderr: ""
Jun  4 13:49:14.297: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:49:14.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-spqvh" for this suite.
Jun  4 13:49:20.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:49:20.840: INFO: namespace: e2e-tests-kubectl-spqvh, resource: bindings, ignored listing per whitelist
Jun  4 13:49:20.904: INFO: namespace e2e-tests-kubectl-spqvh deletion completed in 6.593631471s

• [SLOW TEST:11.588 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:49:20.906: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:49:21.404: INFO: (0) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.219739ms)
Jun  4 13:49:21.535: INFO: (1) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 130.647946ms)
Jun  4 13:49:21.555: INFO: (2) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.064922ms)
Jun  4 13:49:21.606: INFO: (3) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 50.681553ms)
Jun  4 13:49:21.699: INFO: (4) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 92.428616ms)
Jun  4 13:49:21.733: INFO: (5) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 34.606723ms)
Jun  4 13:49:21.755: INFO: (6) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.92171ms)
Jun  4 13:49:21.774: INFO: (7) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.957296ms)
Jun  4 13:49:21.802: INFO: (8) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.82407ms)
Jun  4 13:49:21.833: INFO: (9) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 30.765342ms)
Jun  4 13:49:21.894: INFO: (10) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 60.289922ms)
Jun  4 13:49:21.936: INFO: (11) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 40.977614ms)
Jun  4 13:49:22.047: INFO: (12) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 111.07746ms)
Jun  4 13:49:22.133: INFO: (13) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 85.297467ms)
Jun  4 13:49:22.141: INFO: (14) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.13237ms)
Jun  4 13:49:22.293: INFO: (15) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 151.966277ms)
Jun  4 13:49:22.436: INFO: (16) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 141.970884ms)
Jun  4 13:49:22.477: INFO: (17) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 41.440777ms)
Jun  4 13:49:22.591: INFO: (18) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 113.975093ms)
Jun  4 13:49:22.600: INFO: (19) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.039695ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:49:22.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5p78c" for this suite.
Jun  4 13:49:28.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:49:28.765: INFO: namespace: e2e-tests-proxy-5p78c, resource: bindings, ignored listing per whitelist
Jun  4 13:49:29.159: INFO: namespace e2e-tests-proxy-5p78c deletion completed in 6.551313588s

• [SLOW TEST:8.254 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:49:29.163: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-92f56368-86cf-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:49:29.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-92f6f04f-86cf-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-cmhf6" to be "success or failure"
Jun  4 13:49:29.370: INFO: Pod "pod-configmaps-92f6f04f-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.941525ms
Jun  4 13:49:31.376: INFO: Pod "pod-configmaps-92f6f04f-86cf-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010926079s
STEP: Saw pod success
Jun  4 13:49:31.376: INFO: Pod "pod-configmaps-92f6f04f-86cf-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:49:31.380: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-92f6f04f-86cf-11e9-8620-ba945f56578b container configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:49:31.574: INFO: Waiting for pod pod-configmaps-92f6f04f-86cf-11e9-8620-ba945f56578b to disappear
Jun  4 13:49:31.587: INFO: Pod pod-configmaps-92f6f04f-86cf-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:49:31.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cmhf6" for this suite.
Jun  4 13:49:37.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:49:38.140: INFO: namespace: e2e-tests-configmap-cmhf6, resource: bindings, ignored listing per whitelist
Jun  4 13:49:38.277: INFO: namespace e2e-tests-configmap-cmhf6 deletion completed in 6.678057795s

• [SLOW TEST:9.114 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:49:38.282: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Jun  4 13:49:38.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-ds5dt'
Jun  4 13:49:39.198: INFO: stderr: ""
Jun  4 13:49:39.198: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jun  4 13:49:40.203: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:49:40.203: INFO: Found 0 / 1
Jun  4 13:49:41.203: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:49:41.203: INFO: Found 0 / 1
Jun  4 13:49:42.208: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:49:42.208: INFO: Found 1 / 1
Jun  4 13:49:42.208: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun  4 13:49:42.218: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:49:42.218: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jun  4 13:49:42.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 logs redis-master-vtlqh redis-master --namespace=e2e-tests-kubectl-ds5dt'
Jun  4 13:49:42.537: INFO: stderr: ""
Jun  4 13:49:42.537: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Jun 13:49:40.799 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Jun 13:49:40.799 # Server started, Redis version 3.2.12\n1:M 04 Jun 13:49:40.799 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Jun 13:49:40.799 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jun  4 13:49:42.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 log redis-master-vtlqh redis-master --namespace=e2e-tests-kubectl-ds5dt --tail=1'
Jun  4 13:49:42.840: INFO: stderr: ""
Jun  4 13:49:42.840: INFO: stdout: "1:M 04 Jun 13:49:40.799 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jun  4 13:49:42.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 log redis-master-vtlqh redis-master --namespace=e2e-tests-kubectl-ds5dt --limit-bytes=1'
Jun  4 13:49:43.191: INFO: stderr: ""
Jun  4 13:49:43.191: INFO: stdout: " "
STEP: exposing timestamps
Jun  4 13:49:43.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 log redis-master-vtlqh redis-master --namespace=e2e-tests-kubectl-ds5dt --tail=1 --timestamps'
Jun  4 13:49:43.387: INFO: stderr: ""
Jun  4 13:49:43.387: INFO: stdout: "2019-06-04T13:49:40.800064215Z 1:M 04 Jun 13:49:40.799 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jun  4 13:49:45.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 log redis-master-vtlqh redis-master --namespace=e2e-tests-kubectl-ds5dt --since=1s'
Jun  4 13:49:46.198: INFO: stderr: ""
Jun  4 13:49:46.199: INFO: stdout: ""
Jun  4 13:49:46.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 log redis-master-vtlqh redis-master --namespace=e2e-tests-kubectl-ds5dt --since=24h'
Jun  4 13:49:46.636: INFO: stderr: ""
Jun  4 13:49:46.636: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 04 Jun 13:49:40.799 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Jun 13:49:40.799 # Server started, Redis version 3.2.12\n1:M 04 Jun 13:49:40.799 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Jun 13:49:40.799 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Jun  4 13:49:46.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ds5dt'
Jun  4 13:49:46.857: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:49:46.857: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jun  4 13:49:46.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-ds5dt'
Jun  4 13:49:47.061: INFO: stderr: "No resources found.\n"
Jun  4 13:49:47.061: INFO: stdout: ""
Jun  4 13:49:47.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -l name=nginx --namespace=e2e-tests-kubectl-ds5dt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun  4 13:49:47.219: INFO: stderr: ""
Jun  4 13:49:47.219: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:49:47.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ds5dt" for this suite.
Jun  4 13:49:53.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:49:53.853: INFO: namespace: e2e-tests-kubectl-ds5dt, resource: bindings, ignored listing per whitelist
Jun  4 13:49:54.156: INFO: namespace e2e-tests-kubectl-ds5dt deletion completed in 6.815490378s

• [SLOW TEST:15.876 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:49:54.162: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun  4 13:49:54.810: INFO: Waiting up to 5m0s for pod "pod-a2189d85-86cf-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-ts48k" to be "success or failure"
Jun  4 13:49:54.816: INFO: Pod "pod-a2189d85-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.355381ms
Jun  4 13:49:56.823: INFO: Pod "pod-a2189d85-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013184872s
Jun  4 13:49:58.839: INFO: Pod "pod-a2189d85-86cf-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029170547s
STEP: Saw pod success
Jun  4 13:49:58.839: INFO: Pod "pod-a2189d85-86cf-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:49:58.845: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-a2189d85-86cf-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:49:58.964: INFO: Waiting for pod pod-a2189d85-86cf-11e9-8620-ba945f56578b to disappear
Jun  4 13:49:58.970: INFO: Pod pod-a2189d85-86cf-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:49:58.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ts48k" for this suite.
Jun  4 13:50:05.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:50:05.259: INFO: namespace: e2e-tests-emptydir-ts48k, resource: bindings, ignored listing per whitelist
Jun  4 13:50:05.388: INFO: namespace e2e-tests-emptydir-ts48k deletion completed in 6.410378128s

• [SLOW TEST:11.227 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:50:05.393: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun  4 13:50:05.985: INFO: Waiting up to 5m0s for pod "pod-a8c9af5a-86cf-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-4w65q" to be "success or failure"
Jun  4 13:50:05.997: INFO: Pod "pod-a8c9af5a-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.993239ms
Jun  4 13:50:08.010: INFO: Pod "pod-a8c9af5a-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024981793s
Jun  4 13:50:10.042: INFO: Pod "pod-a8c9af5a-86cf-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057501114s
STEP: Saw pod success
Jun  4 13:50:10.043: INFO: Pod "pod-a8c9af5a-86cf-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:50:10.054: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-a8c9af5a-86cf-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 13:50:10.174: INFO: Waiting for pod pod-a8c9af5a-86cf-11e9-8620-ba945f56578b to disappear
Jun  4 13:50:10.179: INFO: Pod pod-a8c9af5a-86cf-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:50:10.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4w65q" for this suite.
Jun  4 13:50:16.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:50:16.840: INFO: namespace: e2e-tests-emptydir-4w65q, resource: bindings, ignored listing per whitelist
Jun  4 13:50:16.919: INFO: namespace e2e-tests-emptydir-4w65q deletion completed in 6.680617317s

• [SLOW TEST:11.527 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:50:16.926: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:50:17.340: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:50:18.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-v8dv5" for this suite.
Jun  4 13:50:24.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:50:25.152: INFO: namespace: e2e-tests-custom-resource-definition-v8dv5, resource: bindings, ignored listing per whitelist
Jun  4 13:50:25.438: INFO: namespace e2e-tests-custom-resource-definition-v8dv5 deletion completed in 6.810459881s

• [SLOW TEST:8.514 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:50:25.447: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 13:50:25.982: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4b651cb-86cf-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-5n9dj" to be "success or failure"
Jun  4 13:50:26.055: INFO: Pod "downwardapi-volume-b4b651cb-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 72.805439ms
Jun  4 13:50:28.236: INFO: Pod "downwardapi-volume-b4b651cb-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.253523385s
Jun  4 13:50:30.241: INFO: Pod "downwardapi-volume-b4b651cb-86cf-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.258692007s
STEP: Saw pod success
Jun  4 13:50:30.241: INFO: Pod "downwardapi-volume-b4b651cb-86cf-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:50:30.246: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-b4b651cb-86cf-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 13:50:30.337: INFO: Waiting for pod downwardapi-volume-b4b651cb-86cf-11e9-8620-ba945f56578b to disappear
Jun  4 13:50:30.343: INFO: Pod downwardapi-volume-b4b651cb-86cf-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:50:30.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5n9dj" for this suite.
Jun  4 13:50:36.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:50:36.602: INFO: namespace: e2e-tests-downward-api-5n9dj, resource: bindings, ignored listing per whitelist
Jun  4 13:50:36.784: INFO: namespace e2e-tests-downward-api-5n9dj deletion completed in 6.430388966s

• [SLOW TEST:11.337 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:50:36.785: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun  4 13:50:37.376: INFO: Waiting up to 5m0s for pod "downward-api-bb7d0bb2-86cf-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-zzpgx" to be "success or failure"
Jun  4 13:50:37.395: INFO: Pod "downward-api-bb7d0bb2-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.50535ms
Jun  4 13:50:39.405: INFO: Pod "downward-api-bb7d0bb2-86cf-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028978921s
STEP: Saw pod success
Jun  4 13:50:39.405: INFO: Pod "downward-api-bb7d0bb2-86cf-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:50:39.413: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downward-api-bb7d0bb2-86cf-11e9-8620-ba945f56578b container dapi-container: <nil>
STEP: delete the pod
Jun  4 13:50:39.653: INFO: Waiting for pod downward-api-bb7d0bb2-86cf-11e9-8620-ba945f56578b to disappear
Jun  4 13:50:39.666: INFO: Pod downward-api-bb7d0bb2-86cf-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:50:39.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zzpgx" for this suite.
Jun  4 13:50:45.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:50:45.940: INFO: namespace: e2e-tests-downward-api-zzpgx, resource: bindings, ignored listing per whitelist
Jun  4 13:50:46.245: INFO: namespace e2e-tests-downward-api-zzpgx deletion completed in 6.552036748s

• [SLOW TEST:9.460 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:50:46.254: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0604 13:50:52.782336      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun  4 13:50:52.782: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:50:52.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fcjdc" for this suite.
Jun  4 13:51:00.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:51:01.052: INFO: namespace: e2e-tests-gc-fcjdc, resource: bindings, ignored listing per whitelist
Jun  4 13:51:01.203: INFO: namespace e2e-tests-gc-fcjdc deletion completed in 8.414409497s

• [SLOW TEST:14.950 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:51:01.210: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun  4 13:51:01.605: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun  4 13:51:01.616: INFO: Waiting for terminating namespaces to be deleted...
Jun  4 13:51:01.620: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-45s5z before test
Jun  4 13:51:01.735: INFO: canal-76cwl from kube-system started at 2019-06-04 12:09:32 +0000 UTC (3 container statuses recorded)
Jun  4 13:51:01.735: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:51:01.735: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:51:01.736: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:51:01.736: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-04 12:56:20 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:01.736: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun  4 13:51:01.737: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-79nwm from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:01.737: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:51:01.737: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:51:01.737: INFO: kube-proxy-nf7p7 from kube-system started at 2019-06-04 12:09:31 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:01.738: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:51:01.738: INFO: node-exporter-w8mpm from kube-system started at 2019-06-04 12:09:32 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:01.738: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:51:01.738: INFO: 	Container node-exporter ready: true, restart count 0
Jun  4 13:51:01.739: INFO: node-local-dns-j6q7n from kube-system started at 2019-06-04 12:10:12 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:01.739: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:51:01.739: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-4wzp4 before test
Jun  4 13:51:01.995: INFO: kube-proxy-j6nh9 from kube-system started at 2019-06-04 12:09:29 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:01.995: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:51:01.996: INFO: canal-pkkpj from kube-system started at 2019-06-04 12:09:29 +0000 UTC (3 container statuses recorded)
Jun  4 13:51:01.996: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:51:01.996: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:51:01.996: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:51:01.997: INFO: coredns-847fd8cc79-56mp9 from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:01.997: INFO: 	Container coredns ready: true, restart count 0
Jun  4 13:51:01.997: INFO: node-exporter-h5rs4 from kube-system started at 2019-06-04 12:09:29 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:01.997: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:51:01.998: INFO: 	Container node-exporter ready: true, restart count 0
Jun  4 13:51:01.998: INFO: coredns-847fd8cc79-6tz5w from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:01.998: INFO: 	Container coredns ready: true, restart count 0
Jun  4 13:51:01.998: INFO: kubernetes-dashboard-69989d6597-ssww6 from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:01.999: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun  4 13:51:01.999: INFO: openvpn-client-cf455948c-2kz4k from kube-system started at 2019-06-04 12:10:09 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:01.999: INFO: 	Container dnat-controller ready: true, restart count 0
Jun  4 13:51:01.999: INFO: 	Container openvpn-client ready: true, restart count 0
Jun  4 13:51:02.000: INFO: node-local-dns-cr5nd from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:02.000: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:51:02.000: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-bng6b from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:02.000: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:51:02.000: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:51:02.001: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-gv9cg before test
Jun  4 13:51:02.292: INFO: node-local-dns-v7xcp from kube-system started at 2019-06-04 12:10:35 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:02.292: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:51:02.292: INFO: sonobuoy-e2e-job-3ad4d89decb14678 from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:02.292: INFO: 	Container e2e ready: true, restart count 0
Jun  4 13:51:02.292: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:51:02.292: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-c7fnn from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:02.292: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:51:02.292: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:51:02.292: INFO: kube-proxy-j2gp8 from kube-system started at 2019-06-04 12:09:45 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:02.292: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:51:02.292: INFO: canal-9xpkc from kube-system started at 2019-06-04 12:09:45 +0000 UTC (3 container statuses recorded)
Jun  4 13:51:02.292: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:51:02.292: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:51:02.292: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:51:02.292: INFO: node-exporter-k5l47 from kube-system started at 2019-06-04 12:09:45 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:02.292: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:51:02.292: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15a5031b72890755], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:51:03.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wdlhs" for this suite.
Jun  4 13:51:09.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:51:09.783: INFO: namespace: e2e-tests-sched-pred-wdlhs, resource: bindings, ignored listing per whitelist
Jun  4 13:51:09.936: INFO: namespace e2e-tests-sched-pred-wdlhs deletion completed in 6.48576472s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:8.728 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:51:09.945: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-cf37e306-86cf-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:51:10.458: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cf38cff6-86cf-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-vhbrv" to be "success or failure"
Jun  4 13:51:10.470: INFO: Pod "pod-projected-configmaps-cf38cff6-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.424461ms
Jun  4 13:51:12.476: INFO: Pod "pod-projected-configmaps-cf38cff6-86cf-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017735104s
STEP: Saw pod success
Jun  4 13:51:12.476: INFO: Pod "pod-projected-configmaps-cf38cff6-86cf-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:51:12.480: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-configmaps-cf38cff6-86cf-11e9-8620-ba945f56578b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 13:51:12.636: INFO: Waiting for pod pod-projected-configmaps-cf38cff6-86cf-11e9-8620-ba945f56578b to disappear
Jun  4 13:51:12.741: INFO: Pod pod-projected-configmaps-cf38cff6-86cf-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:51:12.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vhbrv" for this suite.
Jun  4 13:51:18.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:51:19.166: INFO: namespace: e2e-tests-projected-vhbrv, resource: bindings, ignored listing per whitelist
Jun  4 13:51:19.471: INFO: namespace e2e-tests-projected-vhbrv deletion completed in 6.634328848s

• [SLOW TEST:9.526 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:51:19.478: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 13:51:20.004: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4e931c6-86cf-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-8f42k" to be "success or failure"
Jun  4 13:51:20.012: INFO: Pod "downwardapi-volume-d4e931c6-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.843909ms
Jun  4 13:51:22.018: INFO: Pod "downwardapi-volume-d4e931c6-86cf-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014343886s
Jun  4 13:51:24.051: INFO: Pod "downwardapi-volume-d4e931c6-86cf-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046859445s
STEP: Saw pod success
Jun  4 13:51:24.051: INFO: Pod "downwardapi-volume-d4e931c6-86cf-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:51:24.056: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-d4e931c6-86cf-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 13:51:24.092: INFO: Waiting for pod downwardapi-volume-d4e931c6-86cf-11e9-8620-ba945f56578b to disappear
Jun  4 13:51:24.096: INFO: Pod downwardapi-volume-d4e931c6-86cf-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:51:24.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8f42k" for this suite.
Jun  4 13:51:30.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:51:30.764: INFO: namespace: e2e-tests-projected-8f42k, resource: bindings, ignored listing per whitelist
Jun  4 13:51:30.797: INFO: namespace e2e-tests-projected-8f42k deletion completed in 6.693773842s

• [SLOW TEST:11.319 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:51:30.797: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Jun  4 13:51:31.169: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun  4 13:51:31.344: INFO: Waiting for terminating namespaces to be deleted...
Jun  4 13:51:31.349: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-45s5z before test
Jun  4 13:51:31.498: INFO: sonobuoy from heptio-sonobuoy started at 2019-06-04 12:56:20 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.499: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun  4 13:51:31.499: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-79nwm from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:31.500: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:51:31.500: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:51:31.501: INFO: canal-76cwl from kube-system started at 2019-06-04 12:09:32 +0000 UTC (3 container statuses recorded)
Jun  4 13:51:31.501: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:51:31.501: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:51:31.501: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:51:31.501: INFO: node-exporter-w8mpm from kube-system started at 2019-06-04 12:09:32 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:31.502: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:51:31.502: INFO: 	Container node-exporter ready: true, restart count 0
Jun  4 13:51:31.502: INFO: node-local-dns-j6q7n from kube-system started at 2019-06-04 12:10:12 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.502: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:51:31.502: INFO: kube-proxy-nf7p7 from kube-system started at 2019-06-04 12:09:31 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.503: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:51:31.503: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-4wzp4 before test
Jun  4 13:51:31.553: INFO: kube-proxy-j6nh9 from kube-system started at 2019-06-04 12:09:29 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.554: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:51:31.554: INFO: canal-pkkpj from kube-system started at 2019-06-04 12:09:29 +0000 UTC (3 container statuses recorded)
Jun  4 13:51:31.554: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:51:31.554: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:51:31.555: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:51:31.555: INFO: coredns-847fd8cc79-56mp9 from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.555: INFO: 	Container coredns ready: true, restart count 0
Jun  4 13:51:31.555: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-bng6b from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:31.556: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:51:31.556: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:51:31.556: INFO: node-exporter-h5rs4 from kube-system started at 2019-06-04 12:09:29 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:31.556: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:51:31.557: INFO: 	Container node-exporter ready: true, restart count 0
Jun  4 13:51:31.557: INFO: coredns-847fd8cc79-6tz5w from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.557: INFO: 	Container coredns ready: true, restart count 0
Jun  4 13:51:31.557: INFO: kubernetes-dashboard-69989d6597-ssww6 from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.557: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun  4 13:51:31.558: INFO: openvpn-client-cf455948c-2kz4k from kube-system started at 2019-06-04 12:10:09 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:31.558: INFO: 	Container dnat-controller ready: true, restart count 0
Jun  4 13:51:31.558: INFO: 	Container openvpn-client ready: true, restart count 0
Jun  4 13:51:31.558: INFO: node-local-dns-cr5nd from kube-system started at 2019-06-04 12:10:09 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.558: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:51:31.558: INFO: 
Logging pods the kubelet thinks is on node worker-4jvsx-65d7bd6f69-gv9cg before test
Jun  4 13:51:31.653: INFO: node-local-dns-v7xcp from kube-system started at 2019-06-04 12:10:35 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.653: INFO: 	Container node-cache ready: true, restart count 0
Jun  4 13:51:31.653: INFO: sonobuoy-e2e-job-3ad4d89decb14678 from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:31.654: INFO: 	Container e2e ready: true, restart count 0
Jun  4 13:51:31.654: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:51:31.654: INFO: sonobuoy-systemd-logs-daemon-set-eac461d668c54200-c7fnn from heptio-sonobuoy started at 2019-06-04 12:56:30 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:31.654: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun  4 13:51:31.654: INFO: 	Container systemd-logs ready: true, restart count 0
Jun  4 13:51:31.655: INFO: kube-proxy-j2gp8 from kube-system started at 2019-06-04 12:09:45 +0000 UTC (1 container statuses recorded)
Jun  4 13:51:31.655: INFO: 	Container kube-proxy ready: true, restart count 0
Jun  4 13:51:31.655: INFO: canal-9xpkc from kube-system started at 2019-06-04 12:09:45 +0000 UTC (3 container statuses recorded)
Jun  4 13:51:31.655: INFO: 	Container calico-node ready: true, restart count 0
Jun  4 13:51:31.655: INFO: 	Container install-cni ready: true, restart count 0
Jun  4 13:51:31.656: INFO: 	Container kube-flannel ready: true, restart count 0
Jun  4 13:51:31.656: INFO: node-exporter-k5l47 from kube-system started at 2019-06-04 12:09:45 +0000 UTC (2 container statuses recorded)
Jun  4 13:51:31.656: INFO: 	Container kube-rbac-proxy ready: true, restart count 0
Jun  4 13:51:31.656: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dd1d865d-86cf-11e9-8620-ba945f56578b 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-dd1d865d-86cf-11e9-8620-ba945f56578b off the node worker-4jvsx-65d7bd6f69-45s5z
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dd1d865d-86cf-11e9-8620-ba945f56578b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:51:37.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-86fb9" for this suite.
Jun  4 13:51:48.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:51:48.273: INFO: namespace: e2e-tests-sched-pred-86fb9, resource: bindings, ignored listing per whitelist
Jun  4 13:51:48.656: INFO: namespace e2e-tests-sched-pred-86fb9 deletion completed in 10.705507514s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:17.860 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:51:48.665: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:51:49.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-9kfzh" for this suite.
Jun  4 13:51:55.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:51:55.843: INFO: namespace: e2e-tests-kubelet-test-9kfzh, resource: bindings, ignored listing per whitelist
Jun  4 13:51:56.294: INFO: namespace e2e-tests-kubelet-test-9kfzh deletion completed in 6.919689831s

• [SLOW TEST:7.630 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:51:56.298: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-fwt6d
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jun  4 13:51:56.674: INFO: Found 0 stateful pods, waiting for 3
Jun  4 13:52:06.681: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 13:52:06.681: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 13:52:06.681: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 13:52:06.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-fwt6d ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 13:52:07.846: INFO: stderr: ""
Jun  4 13:52:07.846: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 13:52:07.846: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jun  4 13:52:17.900: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jun  4 13:52:27.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-fwt6d ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:52:28.938: INFO: stderr: ""
Jun  4 13:52:28.938: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun  4 13:52:28.938: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun  4 13:52:39.063: INFO: Waiting for StatefulSet e2e-tests-statefulset-fwt6d/ss2 to complete update
Jun  4 13:52:39.063: INFO: Waiting for Pod e2e-tests-statefulset-fwt6d/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun  4 13:52:39.064: INFO: Waiting for Pod e2e-tests-statefulset-fwt6d/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun  4 13:52:49.086: INFO: Waiting for StatefulSet e2e-tests-statefulset-fwt6d/ss2 to complete update
Jun  4 13:52:49.086: INFO: Waiting for Pod e2e-tests-statefulset-fwt6d/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun  4 13:52:59.076: INFO: Waiting for StatefulSet e2e-tests-statefulset-fwt6d/ss2 to complete update
STEP: Rolling back to a previous revision
Jun  4 13:53:09.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-fwt6d ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 13:53:10.192: INFO: stderr: ""
Jun  4 13:53:10.192: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 13:53:10.192: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 13:53:20.247: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jun  4 13:53:30.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-fwt6d ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 13:53:31.297: INFO: stderr: ""
Jun  4 13:53:31.297: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun  4 13:53:31.297: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun  4 13:53:51.359: INFO: Waiting for StatefulSet e2e-tests-statefulset-fwt6d/ss2 to complete update
Jun  4 13:53:51.360: INFO: Waiting for Pod e2e-tests-statefulset-fwt6d/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun  4 13:54:01.542: INFO: Deleting all statefulset in ns e2e-tests-statefulset-fwt6d
Jun  4 13:54:01.550: INFO: Scaling statefulset ss2 to 0
Jun  4 13:54:31.611: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 13:54:31.640: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:54:31.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-fwt6d" for this suite.
Jun  4 13:54:37.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:54:37.869: INFO: namespace: e2e-tests-statefulset-fwt6d, resource: bindings, ignored listing per whitelist
Jun  4 13:54:37.983: INFO: namespace e2e-tests-statefulset-fwt6d deletion completed in 6.311742733s

• [SLOW TEST:161.686 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:54:37.989: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:54:38.390: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jun  4 13:54:43.397: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun  4 13:54:43.397: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun  4 13:54:47.580: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-nzg9q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nzg9q/deployments/test-cleanup-deployment,UID:4e31959e-86d0-11e9-9957-a6a8fec88741,ResourceVersion:21484,Generation:1,CreationTimestamp:2019-06-04 13:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-04 13:54:43 +0000 UTC 2019-06-04 13:54:43 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-04 13:54:46 +0000 UTC 2019-06-04 13:54:43 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-7dbbfcf846" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun  4 13:54:47.585: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-nzg9q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-nzg9q/replicasets/test-cleanup-deployment-7dbbfcf846,UID:4e3898c8-86d0-11e9-9957-a6a8fec88741,ResourceVersion:21475,Generation:1,CreationTimestamp:2019-06-04 13:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 4e31959e-86d0-11e9-9957-a6a8fec88741 0xc000216837 0xc000216838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun  4 13:54:47.590: INFO: Pod "test-cleanup-deployment-7dbbfcf846-g9tx5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846-g9tx5,GenerateName:test-cleanup-deployment-7dbbfcf846-,Namespace:e2e-tests-deployment-nzg9q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-nzg9q/pods/test-cleanup-deployment-7dbbfcf846-g9tx5,UID:4e3a3222-86d0-11e9-9957-a6a8fec88741,ResourceVersion:21474,Generation:0,CreationTimestamp:2019-06-04 13:54:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-7dbbfcf846 4e3898c8-86d0-11e9-9957-a6a8fec88741 0xc0016b4337 0xc0016b4338}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-p7h2v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p7h2v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-p7h2v true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016b43a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016b43c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:54:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:54:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:54:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 13:54:43 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:172.25.0.36,StartTime:2019-06-04 13:54:43 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-04 13:54:46 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://12db1df2743c8383409e704bf3dcd0755cd2ba8187e8244745c41414a64cc39c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:54:47.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-nzg9q" for this suite.
Jun  4 13:54:53.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:54:54.345: INFO: namespace: e2e-tests-deployment-nzg9q, resource: bindings, ignored listing per whitelist
Jun  4 13:54:54.667: INFO: namespace e2e-tests-deployment-nzg9q deletion completed in 7.030077777s

• [SLOW TEST:16.678 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:54:54.672: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:54:55.042: INFO: Creating ReplicaSet my-hostname-basic-55176c9e-86d0-11e9-8620-ba945f56578b
Jun  4 13:54:55.061: INFO: Pod name my-hostname-basic-55176c9e-86d0-11e9-8620-ba945f56578b: Found 0 pods out of 1
Jun  4 13:55:00.139: INFO: Pod name my-hostname-basic-55176c9e-86d0-11e9-8620-ba945f56578b: Found 1 pods out of 1
Jun  4 13:55:00.139: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-55176c9e-86d0-11e9-8620-ba945f56578b" is running
Jun  4 13:55:00.149: INFO: Pod "my-hostname-basic-55176c9e-86d0-11e9-8620-ba945f56578b-vth66" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-04 13:54:55 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-04 13:54:57 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-04 13:54:57 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-04 13:54:55 +0000 UTC Reason: Message:}])
Jun  4 13:55:00.150: INFO: Trying to dial the pod
Jun  4 13:55:05.258: INFO: Controller my-hostname-basic-55176c9e-86d0-11e9-8620-ba945f56578b: Got expected result from replica 1 [my-hostname-basic-55176c9e-86d0-11e9-8620-ba945f56578b-vth66]: "my-hostname-basic-55176c9e-86d0-11e9-8620-ba945f56578b-vth66", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:55:05.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-g5qjb" for this suite.
Jun  4 13:55:11.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:55:11.476: INFO: namespace: e2e-tests-replicaset-g5qjb, resource: bindings, ignored listing per whitelist
Jun  4 13:55:11.648: INFO: namespace e2e-tests-replicaset-g5qjb deletion completed in 6.384410498s

• [SLOW TEST:16.977 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:55:11.652: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-btj6c/configmap-test-5f29b94d-86d0-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:55:12.036: INFO: Waiting up to 5m0s for pod "pod-configmaps-5f2ac59e-86d0-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-btj6c" to be "success or failure"
Jun  4 13:55:12.042: INFO: Pod "pod-configmaps-5f2ac59e-86d0-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.741769ms
Jun  4 13:55:14.048: INFO: Pod "pod-configmaps-5f2ac59e-86d0-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011573038s
Jun  4 13:55:16.054: INFO: Pod "pod-configmaps-5f2ac59e-86d0-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017189435s
STEP: Saw pod success
Jun  4 13:55:16.054: INFO: Pod "pod-configmaps-5f2ac59e-86d0-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:55:16.058: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-5f2ac59e-86d0-11e9-8620-ba945f56578b container env-test: <nil>
STEP: delete the pod
Jun  4 13:55:16.134: INFO: Waiting for pod pod-configmaps-5f2ac59e-86d0-11e9-8620-ba945f56578b to disappear
Jun  4 13:55:16.140: INFO: Pod pod-configmaps-5f2ac59e-86d0-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:55:16.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-btj6c" for this suite.
Jun  4 13:55:22.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:55:22.758: INFO: namespace: e2e-tests-configmap-btj6c, resource: bindings, ignored listing per whitelist
Jun  4 13:55:22.933: INFO: namespace e2e-tests-configmap-btj6c deletion completed in 6.786803549s

• [SLOW TEST:11.282 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:55:22.933: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0604 13:55:33.678428      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun  4 13:55:33.678: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:55:33.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zrlkd" for this suite.
Jun  4 13:55:39.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:55:40.037: INFO: namespace: e2e-tests-gc-zrlkd, resource: bindings, ignored listing per whitelist
Jun  4 13:55:40.552: INFO: namespace e2e-tests-gc-zrlkd deletion completed in 6.811531735s

• [SLOW TEST:17.620 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:55:40.559: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-jwbmm
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun  4 13:55:40.836: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun  4 13:56:03.272: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.2.28:8080/dial?request=hostName&protocol=http&host=172.25.2.27&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-jwbmm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:56:03.272: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:56:03.990: INFO: Waiting for endpoints: map[]
Jun  4 13:56:04.000: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.2.28:8080/dial?request=hostName&protocol=http&host=172.25.0.38&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-jwbmm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:56:04.000: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:56:04.884: INFO: Waiting for endpoints: map[]
Jun  4 13:56:04.940: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.25.2.28:8080/dial?request=hostName&protocol=http&host=172.25.1.123&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-jwbmm PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 13:56:04.940: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 13:56:05.740: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:56:05.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-jwbmm" for this suite.
Jun  4 13:56:17.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:56:18.366: INFO: namespace: e2e-tests-pod-network-test-jwbmm, resource: bindings, ignored listing per whitelist
Jun  4 13:56:18.576: INFO: namespace e2e-tests-pod-network-test-jwbmm deletion completed in 12.829175484s

• [SLOW TEST:38.019 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:56:18.577: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jun  4 13:56:19.056: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-cjmvp,SelfLink:/api/v1/namespaces/e2e-tests-watch-cjmvp/configmaps/e2e-watch-test-resource-version,UID:871d2776-86d0-11e9-9957-a6a8fec88741,ResourceVersion:21940,Generation:0,CreationTimestamp:2019-06-04 13:56:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun  4 13:56:19.056: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-cjmvp,SelfLink:/api/v1/namespaces/e2e-tests-watch-cjmvp/configmaps/e2e-watch-test-resource-version,UID:871d2776-86d0-11e9-9957-a6a8fec88741,ResourceVersion:21941,Generation:0,CreationTimestamp:2019-06-04 13:56:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:56:19.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-cjmvp" for this suite.
Jun  4 13:56:25.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:56:25.448: INFO: namespace: e2e-tests-watch-cjmvp, resource: bindings, ignored listing per whitelist
Jun  4 13:56:25.799: INFO: namespace e2e-tests-watch-cjmvp deletion completed in 6.732028509s

• [SLOW TEST:7.222 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:56:25.803: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun  4 13:56:26.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-wq4nj'
Jun  4 13:56:26.318: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun  4 13:56:26.318: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Jun  4 13:56:30.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-wq4nj'
Jun  4 13:56:30.637: INFO: stderr: ""
Jun  4 13:56:30.637: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:56:30.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wq4nj" for this suite.
Jun  4 13:56:52.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:56:53.007: INFO: namespace: e2e-tests-kubectl-wq4nj, resource: bindings, ignored listing per whitelist
Jun  4 13:56:53.690: INFO: namespace e2e-tests-kubectl-wq4nj deletion completed in 23.043500096s

• [SLOW TEST:27.887 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:56:53.690: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 13:56:54.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 version --client'
Jun  4 13:56:54.143: INFO: stderr: ""
Jun  4 13:56:54.143: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jun  4 13:56:54.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-9fzdg'
Jun  4 13:56:54.585: INFO: stderr: ""
Jun  4 13:56:54.585: INFO: stdout: "replicationcontroller/redis-master created\n"
Jun  4 13:56:54.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-9fzdg'
Jun  4 13:56:55.068: INFO: stderr: ""
Jun  4 13:56:55.068: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun  4 13:56:56.075: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:56:56.075: INFO: Found 0 / 1
Jun  4 13:56:57.074: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:56:57.074: INFO: Found 0 / 1
Jun  4 13:56:58.238: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:56:58.238: INFO: Found 1 / 1
Jun  4 13:56:58.238: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun  4 13:56:58.245: INFO: Selector matched 1 pods for map[app:redis]
Jun  4 13:56:58.245: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun  4 13:56:58.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 describe pod redis-master-85fsx --namespace=e2e-tests-kubectl-9fzdg'
Jun  4 13:56:58.426: INFO: stderr: ""
Jun  4 13:56:58.426: INFO: stdout: "Name:               redis-master-85fsx\nNamespace:          e2e-tests-kubectl-9fzdg\nPriority:           0\nPriorityClassName:  <none>\nNode:               worker-4jvsx-65d7bd6f69-45s5z/138.68.109.151\nStart Time:         Tue, 04 Jun 2019 13:56:54 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 172.25.1.125\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6f7133a4cab61373594b52e80188c41ff6138866310232625c4d2c0556e15cd3\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 04 Jun 2019 13:56:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-47cwz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-47cwz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-47cwz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                    Message\n  ----    ------     ----  ----                                    -------\n  Normal  Scheduled  4s    default-scheduler                       Successfully assigned e2e-tests-kubectl-9fzdg/redis-master-85fsx to worker-4jvsx-65d7bd6f69-45s5z\n  Normal  Pulled     2s    kubelet, worker-4jvsx-65d7bd6f69-45s5z  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, worker-4jvsx-65d7bd6f69-45s5z  Created container\n  Normal  Started    2s    kubelet, worker-4jvsx-65d7bd6f69-45s5z  Started container\n"
Jun  4 13:56:58.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 describe rc redis-master --namespace=e2e-tests-kubectl-9fzdg'
Jun  4 13:56:58.712: INFO: stderr: ""
Jun  4 13:56:58.712: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-9fzdg\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-85fsx\n"
Jun  4 13:56:58.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 describe service redis-master --namespace=e2e-tests-kubectl-9fzdg'
Jun  4 13:56:59.170: INFO: stderr: ""
Jun  4 13:56:59.170: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-9fzdg\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.10.10.221\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.25.1.125:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jun  4 13:56:59.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 describe node worker-4jvsx-65d7bd6f69-45s5z'
Jun  4 13:56:59.363: INFO: stderr: ""
Jun  4 13:56:59.363: INFO: stdout: "Name:               worker-4jvsx-65d7bd6f69-45s5z\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=worker-4jvsx-65d7bd6f69-45s5z\n                    machine-controller/owned-by=40b1e9cc-86c1-11e9-9957-a6a8fec88741\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"7a:eb:a1:34:64:db\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 138.68.109.151\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 04 Jun 2019 12:09:31 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 04 Jun 2019 13:56:55 +0000   Tue, 04 Jun 2019 12:09:31 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 04 Jun 2019 13:56:55 +0000   Tue, 04 Jun 2019 12:09:31 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 04 Jun 2019 13:56:55 +0000   Tue, 04 Jun 2019 12:09:31 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 04 Jun 2019 13:56:55 +0000   Tue, 04 Jun 2019 12:10:12 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  138.68.109.151\n  Hostname:    worker-4jvsx-65d7bd6f69-45s5z\nCapacity:\n cpu:                1\n ephemeral-storage:  50633164Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2041320Ki\n pods:               110\nAllocatable:\n cpu:                800m\n ephemeral-storage:  44516040218\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1734120Ki\n pods:               110\nSystem Info:\n Machine ID:                 8b8d7572789240d59ef6495de3f62848\n System UUID:                8B8D7572-7892-40D5-9EF6-495DE3F62848\n Boot ID:                    4d15c7ab-912e-43b4-aca4-70b7a4ceca1c\n Kernel Version:             4.15.0-50-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.13.5\n Kube-Proxy Version:         v1.13.5\nPodCIDR:                     172.25.1.0/24\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-9fzdg    redis-master-85fsx                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         5s\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         60m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-eac461d668c54200-79nwm    0 (0%)        0 (0%)      0 (0%)           0 (0%)         60m\n  kube-system                canal-76cwl                                                350m (43%)    100m (12%)  50Mi (2%)        50Mi (2%)      107m\n  kube-system                kube-proxy-nf7p7                                           75m (9%)      250m (31%)  50Mi (2%)        250Mi (14%)    107m\n  kube-system                node-exporter-w8mpm                                        20m (2%)      45m (5%)    48Mi (2%)        96Mi (5%)      107m\n  kube-system                node-local-dns-j6q7n                                       25m (3%)      0 (0%)      5Mi (0%)         30Mi (1%)      106m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                470m (58%)  395m (49%)\n  memory             153Mi (9%)  426Mi (25%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Jun  4 13:56:59.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 describe namespace e2e-tests-kubectl-9fzdg'
Jun  4 13:56:59.524: INFO: stderr: ""
Jun  4 13:56:59.524: INFO: stdout: "Name:         e2e-tests-kubectl-9fzdg\nLabels:       e2e-framework=kubectl\n              e2e-run=417a0c1b-86c8-11e9-8620-ba945f56578b\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:56:59.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9fzdg" for this suite.
Jun  4 13:57:21.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:57:22.169: INFO: namespace: e2e-tests-kubectl-9fzdg, resource: bindings, ignored listing per whitelist
Jun  4 13:57:22.234: INFO: namespace e2e-tests-kubectl-9fzdg deletion completed in 22.704720909s

• [SLOW TEST:28.544 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:57:22.240: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jun  4 13:57:22.795: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jun  4 13:57:22.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:57:23.130: INFO: stderr: ""
Jun  4 13:57:23.130: INFO: stdout: "service/redis-slave created\n"
Jun  4 13:57:23.130: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jun  4 13:57:23.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:57:23.718: INFO: stderr: ""
Jun  4 13:57:23.718: INFO: stdout: "service/redis-master created\n"
Jun  4 13:57:23.718: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jun  4 13:57:23.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:57:24.136: INFO: stderr: ""
Jun  4 13:57:24.136: INFO: stdout: "service/frontend created\n"
Jun  4 13:57:24.137: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jun  4 13:57:24.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:57:24.686: INFO: stderr: ""
Jun  4 13:57:24.686: INFO: stdout: "deployment.extensions/frontend created\n"
Jun  4 13:57:24.686: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jun  4 13:57:24.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:57:25.379: INFO: stderr: ""
Jun  4 13:57:25.379: INFO: stdout: "deployment.extensions/redis-master created\n"
Jun  4 13:57:25.380: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jun  4 13:57:25.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:57:26.005: INFO: stderr: ""
Jun  4 13:57:26.005: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jun  4 13:57:26.005: INFO: Waiting for all frontend pods to be Running.
Jun  4 13:57:51.056: INFO: Waiting for frontend to serve content.
Jun  4 13:57:56.337: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Jun  4 13:58:01.537: INFO: Trying to add a new entry to the guestbook.
Jun  4 13:58:01.778: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jun  4 13:58:01.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:58:02.182: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:58:02.182: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jun  4 13:58:02.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:58:02.398: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:58:02.398: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun  4 13:58:02.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:58:02.828: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:58:02.828: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun  4 13:58:02.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:58:03.118: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:58:03.118: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun  4 13:58:03.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:58:03.376: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:58:03.376: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun  4 13:58:03.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s9wp5'
Jun  4 13:58:03.703: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 13:58:03.703: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:58:03.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s9wp5" for this suite.
Jun  4 13:58:43.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:58:43.988: INFO: namespace: e2e-tests-kubectl-s9wp5, resource: bindings, ignored listing per whitelist
Jun  4 13:58:44.243: INFO: namespace e2e-tests-kubectl-s9wp5 deletion completed in 40.5002313s

• [SLOW TEST:82.004 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:58:44.247: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-ddefddb1-86d0-11e9-8620-ba945f56578b
STEP: Creating secret with name secret-projected-all-test-volume-ddefdd98-86d0-11e9-8620-ba945f56578b
STEP: Creating a pod to test Check all projections for projected volume plugin
Jun  4 13:58:44.684: INFO: Waiting up to 5m0s for pod "projected-volume-ddefdd3e-86d0-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-t6s7p" to be "success or failure"
Jun  4 13:58:44.713: INFO: Pod "projected-volume-ddefdd3e-86d0-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 29.06949ms
Jun  4 13:58:46.719: INFO: Pod "projected-volume-ddefdd3e-86d0-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035041905s
Jun  4 13:58:48.726: INFO: Pod "projected-volume-ddefdd3e-86d0-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041936628s
STEP: Saw pod success
Jun  4 13:58:48.726: INFO: Pod "projected-volume-ddefdd3e-86d0-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 13:58:48.731: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod projected-volume-ddefdd3e-86d0-11e9-8620-ba945f56578b container projected-all-volume-test: <nil>
STEP: delete the pod
Jun  4 13:58:48.983: INFO: Waiting for pod projected-volume-ddefdd3e-86d0-11e9-8620-ba945f56578b to disappear
Jun  4 13:58:49.049: INFO: Pod projected-volume-ddefdd3e-86d0-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:58:49.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t6s7p" for this suite.
Jun  4 13:58:55.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:58:55.469: INFO: namespace: e2e-tests-projected-t6s7p, resource: bindings, ignored listing per whitelist
Jun  4 13:58:56.091: INFO: namespace e2e-tests-projected-t6s7p deletion completed in 7.029759956s

• [SLOW TEST:11.845 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:58:56.096: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun  4 13:59:04.937: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:04.959: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:06.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:07.037: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:08.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:08.973: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:10.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:11.049: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:12.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:12.976: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:14.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:15.037: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:16.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:16.973: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:18.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:19.066: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:20.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:20.993: INFO: Pod pod-with-prestop-exec-hook still exists
Jun  4 13:59:22.959: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun  4 13:59:22.970: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:59:23.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-kj5kq" for this suite.
Jun  4 13:59:47.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:59:47.271: INFO: namespace: e2e-tests-container-lifecycle-hook-kj5kq, resource: bindings, ignored listing per whitelist
Jun  4 13:59:47.905: INFO: namespace e2e-tests-container-lifecycle-hook-kj5kq deletion completed in 24.761434812s

• [SLOW TEST:51.811 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:59:47.913: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jun  4 13:59:49.068: INFO: created pod pod-service-account-defaultsa
Jun  4 13:59:49.068: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jun  4 13:59:49.084: INFO: created pod pod-service-account-mountsa
Jun  4 13:59:49.084: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jun  4 13:59:49.120: INFO: created pod pod-service-account-nomountsa
Jun  4 13:59:49.120: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jun  4 13:59:49.144: INFO: created pod pod-service-account-defaultsa-mountspec
Jun  4 13:59:49.145: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jun  4 13:59:49.167: INFO: created pod pod-service-account-mountsa-mountspec
Jun  4 13:59:49.167: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jun  4 13:59:49.197: INFO: created pod pod-service-account-nomountsa-mountspec
Jun  4 13:59:49.197: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jun  4 13:59:49.269: INFO: created pod pod-service-account-defaultsa-nomountspec
Jun  4 13:59:49.269: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jun  4 13:59:49.278: INFO: created pod pod-service-account-mountsa-nomountspec
Jun  4 13:59:49.279: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jun  4 13:59:49.336: INFO: created pod pod-service-account-nomountsa-nomountspec
Jun  4 13:59:49.336: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 13:59:49.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-jqgk9" for this suite.
Jun  4 13:59:57.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 13:59:57.939: INFO: namespace: e2e-tests-svcaccounts-jqgk9, resource: bindings, ignored listing per whitelist
Jun  4 13:59:58.360: INFO: namespace e2e-tests-svcaccounts-jqgk9 deletion completed in 9.009646558s

• [SLOW TEST:10.448 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 13:59:58.361: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0a32ded9-86d1-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 13:59:58.921: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0a347d91-86d1-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-746l4" to be "success or failure"
Jun  4 13:59:58.941: INFO: Pod "pod-projected-configmaps-0a347d91-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.856227ms
Jun  4 14:00:00.955: INFO: Pod "pod-projected-configmaps-0a347d91-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034184577s
Jun  4 14:00:03.039: INFO: Pod "pod-projected-configmaps-0a347d91-86d1-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117738659s
STEP: Saw pod success
Jun  4 14:00:03.039: INFO: Pod "pod-projected-configmaps-0a347d91-86d1-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:00:03.064: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-configmaps-0a347d91-86d1-11e9-8620-ba945f56578b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 14:00:03.375: INFO: Waiting for pod pod-projected-configmaps-0a347d91-86d1-11e9-8620-ba945f56578b to disappear
Jun  4 14:00:03.380: INFO: Pod pod-projected-configmaps-0a347d91-86d1-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:00:03.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-746l4" for this suite.
Jun  4 14:00:09.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:00:10.051: INFO: namespace: e2e-tests-projected-746l4, resource: bindings, ignored listing per whitelist
Jun  4 14:00:10.134: INFO: namespace e2e-tests-projected-746l4 deletion completed in 6.696260704s

• [SLOW TEST:11.774 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:00:10.135: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun  4 14:00:10.664: INFO: Number of nodes with available pods: 0
Jun  4 14:00:10.665: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:00:11.766: INFO: Number of nodes with available pods: 0
Jun  4 14:00:11.766: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:00:12.677: INFO: Number of nodes with available pods: 0
Jun  4 14:00:12.677: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:00:13.693: INFO: Number of nodes with available pods: 3
Jun  4 14:00:13.693: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jun  4 14:00:13.748: INFO: Number of nodes with available pods: 2
Jun  4 14:00:13.748: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:14.770: INFO: Number of nodes with available pods: 2
Jun  4 14:00:14.770: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:15.769: INFO: Number of nodes with available pods: 2
Jun  4 14:00:15.770: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:16.792: INFO: Number of nodes with available pods: 2
Jun  4 14:00:16.792: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:17.773: INFO: Number of nodes with available pods: 2
Jun  4 14:00:17.774: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:18.760: INFO: Number of nodes with available pods: 2
Jun  4 14:00:18.761: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:19.937: INFO: Number of nodes with available pods: 2
Jun  4 14:00:19.937: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:20.762: INFO: Number of nodes with available pods: 2
Jun  4 14:00:20.763: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:21.859: INFO: Number of nodes with available pods: 2
Jun  4 14:00:21.860: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:22.849: INFO: Number of nodes with available pods: 2
Jun  4 14:00:22.850: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:23.840: INFO: Number of nodes with available pods: 2
Jun  4 14:00:23.840: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:24.868: INFO: Number of nodes with available pods: 2
Jun  4 14:00:24.869: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:25.762: INFO: Number of nodes with available pods: 2
Jun  4 14:00:25.762: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:26.856: INFO: Number of nodes with available pods: 2
Jun  4 14:00:26.857: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:30.028: INFO: Number of nodes with available pods: 2
Jun  4 14:00:30.028: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:30.857: INFO: Number of nodes with available pods: 2
Jun  4 14:00:30.857: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:31.860: INFO: Number of nodes with available pods: 2
Jun  4 14:00:31.861: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:32.762: INFO: Number of nodes with available pods: 2
Jun  4 14:00:32.763: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:33.937: INFO: Number of nodes with available pods: 2
Jun  4 14:00:33.938: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:34.766: INFO: Number of nodes with available pods: 2
Jun  4 14:00:34.767: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:35.937: INFO: Number of nodes with available pods: 2
Jun  4 14:00:35.937: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:36.937: INFO: Number of nodes with available pods: 2
Jun  4 14:00:36.937: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:37.790: INFO: Number of nodes with available pods: 2
Jun  4 14:00:37.790: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:38.941: INFO: Number of nodes with available pods: 2
Jun  4 14:00:38.942: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:39.849: INFO: Number of nodes with available pods: 2
Jun  4 14:00:39.850: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:40.760: INFO: Number of nodes with available pods: 2
Jun  4 14:00:40.760: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:41.777: INFO: Number of nodes with available pods: 2
Jun  4 14:00:41.777: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:42.763: INFO: Number of nodes with available pods: 2
Jun  4 14:00:42.764: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:43.845: INFO: Number of nodes with available pods: 2
Jun  4 14:00:43.846: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:44.784: INFO: Number of nodes with available pods: 2
Jun  4 14:00:44.784: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:45.770: INFO: Number of nodes with available pods: 2
Jun  4 14:00:45.770: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:47.150: INFO: Number of nodes with available pods: 2
Jun  4 14:00:47.150: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:47.766: INFO: Number of nodes with available pods: 2
Jun  4 14:00:47.767: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:48.762: INFO: Number of nodes with available pods: 2
Jun  4 14:00:48.763: INFO: Node worker-4jvsx-65d7bd6f69-4wzp4 is running more than one daemon pod
Jun  4 14:00:49.839: INFO: Number of nodes with available pods: 3
Jun  4 14:00:49.840: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-s2sc9, will wait for the garbage collector to delete the pods
Jun  4 14:00:50.055: INFO: Deleting DaemonSet.extensions daemon-set took: 59.657995ms
Jun  4 14:00:50.156: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.619037ms
Jun  4 14:01:31.865: INFO: Number of nodes with available pods: 0
Jun  4 14:01:31.866: INFO: Number of running nodes: 0, number of available pods: 0
Jun  4 14:01:31.871: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-s2sc9/daemonsets","resourceVersion":"23321"},"items":null}

Jun  4 14:01:31.876: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-s2sc9/pods","resourceVersion":"23321"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:01:31.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-s2sc9" for this suite.
Jun  4 14:01:39.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:01:41.381: INFO: namespace: e2e-tests-daemonsets-s2sc9, resource: bindings, ignored listing per whitelist
Jun  4 14:01:41.626: INFO: namespace e2e-tests-daemonsets-s2sc9 deletion completed in 9.679721496s

• [SLOW TEST:91.491 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:01:41.633: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-47f7b550-86d1-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 14:01:42.624: INFO: Waiting up to 5m0s for pod "pod-secrets-47fa48dc-86d1-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-thj6g" to be "success or failure"
Jun  4 14:01:42.635: INFO: Pod "pod-secrets-47fa48dc-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.327594ms
Jun  4 14:01:44.647: INFO: Pod "pod-secrets-47fa48dc-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021891272s
Jun  4 14:01:46.661: INFO: Pod "pod-secrets-47fa48dc-86d1-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035933172s
STEP: Saw pod success
Jun  4 14:01:46.661: INFO: Pod "pod-secrets-47fa48dc-86d1-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:01:46.666: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-secrets-47fa48dc-86d1-11e9-8620-ba945f56578b container secret-volume-test: <nil>
STEP: delete the pod
Jun  4 14:01:46.991: INFO: Waiting for pod pod-secrets-47fa48dc-86d1-11e9-8620-ba945f56578b to disappear
Jun  4 14:01:47.026: INFO: Pod pod-secrets-47fa48dc-86d1-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:01:47.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-thj6g" for this suite.
Jun  4 14:01:55.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:01:55.715: INFO: namespace: e2e-tests-secrets-thj6g, resource: bindings, ignored listing per whitelist
Jun  4 14:01:55.834: INFO: namespace e2e-tests-secrets-thj6g deletion completed in 8.792774004s

• [SLOW TEST:14.203 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:01:55.838: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:01:56.145: INFO: Creating deployment "test-recreate-deployment"
Jun  4 14:01:56.237: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jun  4 14:01:56.254: INFO: Waiting deployment "test-recreate-deployment" to complete
Jun  4 14:01:56.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695253716, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695253716, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695253716, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695253716, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 14:01:58.266: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695253716, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695253716, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695253716, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695253716, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 14:02:00.340: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jun  4 14:02:00.445: INFO: Updating deployment test-recreate-deployment
Jun  4 14:02:00.445: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun  4 14:02:00.608: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-dtnl7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dtnl7/deployments/test-recreate-deployment,UID:50172241-86d1-11e9-9957-a6a8fec88741,ResourceVersion:23486,Generation:2,CreationTimestamp:2019-06-04 14:01:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-06-04 14:02:00 +0000 UTC 2019-06-04 14:02:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-06-04 14:02:00 +0000 UTC 2019-06-04 14:01:56 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jun  4 14:02:00.613: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-dtnl7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dtnl7/replicasets/test-recreate-deployment-697fbf54bf,UID:52b8ae2d-86d1-11e9-9957-a6a8fec88741,ResourceVersion:23483,Generation:1,CreationTimestamp:2019-06-04 14:02:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 50172241-86d1-11e9-9957-a6a8fec88741 0xc00329b447 0xc00329b448}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun  4 14:02:00.613: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jun  4 14:02:00.613: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-dtnl7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dtnl7/replicasets/test-recreate-deployment-5dfdcc846d,UID:5019c73a-86d1-11e9-9957-a6a8fec88741,ResourceVersion:23474,Generation:2,CreationTimestamp:2019-06-04 14:01:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 50172241-86d1-11e9-9957-a6a8fec88741 0xc00329b387 0xc00329b388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun  4 14:02:00.619: INFO: Pod "test-recreate-deployment-697fbf54bf-qqbzm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-qqbzm,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-dtnl7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-dtnl7/pods/test-recreate-deployment-697fbf54bf-qqbzm,UID:52b9809d-86d1-11e9-9957-a6a8fec88741,ResourceVersion:23482,Generation:0,CreationTimestamp:2019-06-04 14:02:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 52b8ae2d-86d1-11e9-9957-a6a8fec88741 0xc003914897 0xc003914898}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ljprj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ljprj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ljprj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003914950} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003914970}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:02:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:02:00.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-dtnl7" for this suite.
Jun  4 14:02:06.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:02:07.162: INFO: namespace: e2e-tests-deployment-dtnl7, resource: bindings, ignored listing per whitelist
Jun  4 14:02:07.765: INFO: namespace e2e-tests-deployment-dtnl7 deletion completed in 7.14107024s

• [SLOW TEST:11.928 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:02:07.769: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jun  4 14:02:08.270: INFO: Waiting up to 5m0s for pod "var-expansion-574d1e98-86d1-11e9-8620-ba945f56578b" in namespace "e2e-tests-var-expansion-bffbk" to be "success or failure"
Jun  4 14:02:08.279: INFO: Pod "var-expansion-574d1e98-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.870953ms
Jun  4 14:02:10.287: INFO: Pod "var-expansion-574d1e98-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016788856s
Jun  4 14:02:12.295: INFO: Pod "var-expansion-574d1e98-86d1-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024596305s
STEP: Saw pod success
Jun  4 14:02:12.296: INFO: Pod "var-expansion-574d1e98-86d1-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:02:12.300: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod var-expansion-574d1e98-86d1-11e9-8620-ba945f56578b container dapi-container: <nil>
STEP: delete the pod
Jun  4 14:02:12.565: INFO: Waiting for pod var-expansion-574d1e98-86d1-11e9-8620-ba945f56578b to disappear
Jun  4 14:02:12.574: INFO: Pod var-expansion-574d1e98-86d1-11e9-8620-ba945f56578b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:02:12.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-bffbk" for this suite.
Jun  4 14:02:18.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:02:19.337: INFO: namespace: e2e-tests-var-expansion-bffbk, resource: bindings, ignored listing per whitelist
Jun  4 14:02:19.412: INFO: namespace e2e-tests-var-expansion-bffbk deletion completed in 6.774024104s

• [SLOW TEST:11.644 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:02:19.418: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:02:19.847: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e33a47b-86d1-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-fpt74" to be "success or failure"
Jun  4 14:02:19.875: INFO: Pod "downwardapi-volume-5e33a47b-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 27.097971ms
Jun  4 14:02:21.891: INFO: Pod "downwardapi-volume-5e33a47b-86d1-11e9-8620-ba945f56578b": Phase="Running", Reason="", readiness=true. Elapsed: 2.043056127s
Jun  4 14:02:23.942: INFO: Pod "downwardapi-volume-5e33a47b-86d1-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.094166242s
STEP: Saw pod success
Jun  4 14:02:23.942: INFO: Pod "downwardapi-volume-5e33a47b-86d1-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:02:24.035: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-5e33a47b-86d1-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:02:24.237: INFO: Waiting for pod downwardapi-volume-5e33a47b-86d1-11e9-8620-ba945f56578b to disappear
Jun  4 14:02:24.244: INFO: Pod downwardapi-volume-5e33a47b-86d1-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:02:24.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fpt74" for this suite.
Jun  4 14:02:30.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:02:30.342: INFO: namespace: e2e-tests-downward-api-fpt74, resource: bindings, ignored listing per whitelist
Jun  4 14:02:30.749: INFO: namespace e2e-tests-downward-api-fpt74 deletion completed in 6.493842511s

• [SLOW TEST:11.332 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:02:30.754: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:03:31.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9nxnp" for this suite.
Jun  4 14:03:55.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:03:55.869: INFO: namespace: e2e-tests-container-probe-9nxnp, resource: bindings, ignored listing per whitelist
Jun  4 14:03:55.957: INFO: namespace e2e-tests-container-probe-9nxnp deletion completed in 24.501239214s

• [SLOW TEST:85.204 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:03:55.962: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-hhqrn
Jun  4 14:03:58.250: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-hhqrn
STEP: checking the pod's current state and verifying that restartCount is present
Jun  4 14:03:58.257: INFO: Initial restart count of pod liveness-exec is 0
Jun  4 14:04:48.841: INFO: Restart count of pod e2e-tests-container-probe-hhqrn/liveness-exec is now 1 (50.584619852s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:04:48.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hhqrn" for this suite.
Jun  4 14:04:54.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:04:55.152: INFO: namespace: e2e-tests-container-probe-hhqrn, resource: bindings, ignored listing per whitelist
Jun  4 14:04:55.585: INFO: namespace e2e-tests-container-probe-hhqrn deletion completed in 6.629113336s

• [SLOW TEST:59.624 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:04:55.590: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:05:00.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-plsb4" for this suite.
Jun  4 14:05:06.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:05:06.766: INFO: namespace: e2e-tests-emptydir-wrapper-plsb4, resource: bindings, ignored listing per whitelist
Jun  4 14:05:06.846: INFO: namespace e2e-tests-emptydir-wrapper-plsb4 deletion completed in 6.607271735s

• [SLOW TEST:11.256 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:05:06.847: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c210fc68-86d1-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 14:05:07.385: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c211e4d3-86d1-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-fd2fm" to be "success or failure"
Jun  4 14:05:07.390: INFO: Pod "pod-projected-configmaps-c211e4d3-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.217951ms
Jun  4 14:05:09.397: INFO: Pod "pod-projected-configmaps-c211e4d3-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01132793s
Jun  4 14:05:11.403: INFO: Pod "pod-projected-configmaps-c211e4d3-86d1-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017636045s
STEP: Saw pod success
Jun  4 14:05:11.403: INFO: Pod "pod-projected-configmaps-c211e4d3-86d1-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:05:11.409: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-configmaps-c211e4d3-86d1-11e9-8620-ba945f56578b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 14:05:11.537: INFO: Waiting for pod pod-projected-configmaps-c211e4d3-86d1-11e9-8620-ba945f56578b to disappear
Jun  4 14:05:11.543: INFO: Pod pod-projected-configmaps-c211e4d3-86d1-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:05:11.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fd2fm" for this suite.
Jun  4 14:05:17.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:05:18.547: INFO: namespace: e2e-tests-projected-fd2fm, resource: bindings, ignored listing per whitelist
Jun  4 14:05:18.737: INFO: namespace e2e-tests-projected-fd2fm deletion completed in 7.18458136s

• [SLOW TEST:11.891 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:05:18.745: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun  4 14:05:19.151: INFO: Waiting up to 5m0s for pod "pod-c914fd14-86d1-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-xptmf" to be "success or failure"
Jun  4 14:05:19.159: INFO: Pod "pod-c914fd14-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008502ms
Jun  4 14:05:21.165: INFO: Pod "pod-c914fd14-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013208486s
Jun  4 14:05:23.171: INFO: Pod "pod-c914fd14-86d1-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019550874s
STEP: Saw pod success
Jun  4 14:05:23.171: INFO: Pod "pod-c914fd14-86d1-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:05:23.176: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-c914fd14-86d1-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 14:05:23.310: INFO: Waiting for pod pod-c914fd14-86d1-11e9-8620-ba945f56578b to disappear
Jun  4 14:05:23.314: INFO: Pod pod-c914fd14-86d1-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:05:23.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xptmf" for this suite.
Jun  4 14:05:29.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:05:30.239: INFO: namespace: e2e-tests-emptydir-xptmf, resource: bindings, ignored listing per whitelist
Jun  4 14:05:30.288: INFO: namespace e2e-tests-emptydir-xptmf deletion completed in 6.946518035s

• [SLOW TEST:11.544 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:05:30.295: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:05:30.756: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d000237b-86d1-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-xktpn" to be "success or failure"
Jun  4 14:05:30.762: INFO: Pod "downwardapi-volume-d000237b-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.985896ms
Jun  4 14:05:32.841: INFO: Pod "downwardapi-volume-d000237b-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084070358s
Jun  4 14:05:34.849: INFO: Pod "downwardapi-volume-d000237b-86d1-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.091964975s
STEP: Saw pod success
Jun  4 14:05:34.849: INFO: Pod "downwardapi-volume-d000237b-86d1-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:05:34.938: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-d000237b-86d1-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:05:35.037: INFO: Waiting for pod downwardapi-volume-d000237b-86d1-11e9-8620-ba945f56578b to disappear
Jun  4 14:05:35.140: INFO: Pod downwardapi-volume-d000237b-86d1-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:05:35.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xktpn" for this suite.
Jun  4 14:05:41.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:05:41.578: INFO: namespace: e2e-tests-projected-xktpn, resource: bindings, ignored listing per whitelist
Jun  4 14:05:41.775: INFO: namespace e2e-tests-projected-xktpn deletion completed in 6.624864403s

• [SLOW TEST:11.481 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:05:41.783: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jun  4 14:05:42.107: INFO: Pod name pod-release: Found 0 pods out of 1
Jun  4 14:05:47.142: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:05:48.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-29jpv" for this suite.
Jun  4 14:05:54.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:05:54.837: INFO: namespace: e2e-tests-replication-controller-29jpv, resource: bindings, ignored listing per whitelist
Jun  4 14:05:54.846: INFO: namespace e2e-tests-replication-controller-29jpv deletion completed in 6.579146747s

• [SLOW TEST:13.064 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:05:54.847: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-dea06e39-86d1-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 14:05:55.347: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dea1b646-86d1-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-f6pz9" to be "success or failure"
Jun  4 14:05:55.359: INFO: Pod "pod-projected-secrets-dea1b646-86d1-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.566917ms
Jun  4 14:05:57.379: INFO: Pod "pod-projected-secrets-dea1b646-86d1-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027815002s
STEP: Saw pod success
Jun  4 14:05:57.379: INFO: Pod "pod-projected-secrets-dea1b646-86d1-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:05:57.385: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-secrets-dea1b646-86d1-11e9-8620-ba945f56578b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun  4 14:05:57.638: INFO: Waiting for pod pod-projected-secrets-dea1b646-86d1-11e9-8620-ba945f56578b to disappear
Jun  4 14:05:57.671: INFO: Pod pod-projected-secrets-dea1b646-86d1-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:05:57.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f6pz9" for this suite.
Jun  4 14:06:03.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:06:04.050: INFO: namespace: e2e-tests-projected-f6pz9, resource: bindings, ignored listing per whitelist
Jun  4 14:06:04.346: INFO: namespace e2e-tests-projected-f6pz9 deletion completed in 6.668772912s

• [SLOW TEST:9.500 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:06:04.354: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:06:04.765: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jun  4 14:06:04.790: INFO: Number of nodes with available pods: 0
Jun  4 14:06:04.791: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:06:05.846: INFO: Number of nodes with available pods: 0
Jun  4 14:06:05.846: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:06:06.801: INFO: Number of nodes with available pods: 2
Jun  4 14:06:06.802: INFO: Node worker-4jvsx-65d7bd6f69-gv9cg is running more than one daemon pod
Jun  4 14:06:07.849: INFO: Number of nodes with available pods: 3
Jun  4 14:06:07.849: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jun  4 14:06:07.972: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:07.972: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:07.973: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:08.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:08.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:08.988: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:09.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:09.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:09.988: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:11.038: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:11.038: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:11.038: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:11.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:11.987: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:11.987: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:12.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:12.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:12.989: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:13.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:13.987: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:13.987: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:14.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:14.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:14.990: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:16.041: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:16.041: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:16.041: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:17.037: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:17.038: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:17.038: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:18.039: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:18.039: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:18.039: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:19.049: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:19.049: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:19.049: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:19.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:19.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:19.988: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:21.040: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:21.040: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:21.040: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:21.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:21.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:21.988: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:22.993: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:22.993: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:22.993: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:24.142: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:24.142: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:24.142: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:25.038: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:25.038: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:25.038: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:26.041: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:26.041: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:26.041: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:27.141: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:27.142: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:27.142: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:27.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:27.990: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:27.990: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:29.037: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:29.037: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:29.037: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:29.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:29.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:29.989: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:30.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:30.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:30.990: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:31.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:31.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:31.988: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:33.138: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:33.138: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:33.138: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:33.990: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:33.990: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:33.990: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:34.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:34.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:34.988: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:36.043: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:36.044: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:36.044: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:36.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:36.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:36.989: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:37.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:37.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:37.989: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:39.044: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:39.044: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:39.044: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:39.995: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:39.996: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:39.996: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:41.046: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:41.046: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:41.046: INFO: Wrong image for pod: daemon-set-r5n76. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:41.046: INFO: Pod daemon-set-r5n76 is not available
Jun  4 14:06:41.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:41.987: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:41.987: INFO: Pod daemon-set-k4n2z is not available
Jun  4 14:06:42.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:42.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:42.988: INFO: Pod daemon-set-k4n2z is not available
Jun  4 14:06:43.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:43.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:44.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:44.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:45.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:45.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:46.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:46.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:47.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:47.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:48.991: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:48.991: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:49.992: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:49.992: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:51.038: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:51.038: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:51.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:51.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:53.004: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:53.004: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:54.140: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:54.140: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:54.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:54.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:55.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:55.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:57.037: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:57.038: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:58.037: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:58.037: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:58.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:06:58.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:00.004: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:00.004: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:00.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:00.987: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:02.042: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:02.042: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:03.046: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:03.046: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:04.038: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:04.038: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:05.042: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:05.043: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:05.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:05.987: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:07.038: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:07.039: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:07.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:07.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:08.994: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:08.995: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:10.014: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:10.014: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:11.139: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:11.140: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:12.137: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:12.138: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:12.992: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:12.992: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:14.009: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:14.009: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:15.042: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:15.042: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:16.137: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:16.137: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:16.137: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:17.037: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:17.037: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:17.037: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:17.990: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:17.990: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:17.990: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:18.992: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:18.992: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:18.992: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:20.041: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:20.042: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:20.042: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:20.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:20.989: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:20.989: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:22.045: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:22.045: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:22.045: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:22.990: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:22.990: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:22.990: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:23.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:23.988: INFO: Wrong image for pod: daemon-set-fppkf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:23.988: INFO: Pod daemon-set-fppkf is not available
Jun  4 14:07:24.990: INFO: Pod daemon-set-6xgwg is not available
Jun  4 14:07:24.990: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:25.987: INFO: Pod daemon-set-6xgwg is not available
Jun  4 14:07:25.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:26.987: INFO: Pod daemon-set-6xgwg is not available
Jun  4 14:07:26.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:27.990: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:29.038: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:29.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:30.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:32.042: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:33.038: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:33.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:34.994: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:36.051: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:36.992: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:38.055: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:38.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:40.000: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:41.042: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:42.039: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:42.992: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:44.137: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:45.035: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:46.048: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:47.037: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:47.991: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:48.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:49.991: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:51.041: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:51.988: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:53.048: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:53.989: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:54.991: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:55.987: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:57.042: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:58.041: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:59.037: INFO: Wrong image for pod: daemon-set-dvqhx. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jun  4 14:07:59.038: INFO: Pod daemon-set-dvqhx is not available
Jun  4 14:07:59.992: INFO: Pod daemon-set-hcgwb is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jun  4 14:08:00.022: INFO: Number of nodes with available pods: 2
Jun  4 14:08:00.023: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:08:01.037: INFO: Number of nodes with available pods: 2
Jun  4 14:08:01.037: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:08:02.051: INFO: Number of nodes with available pods: 3
Jun  4 14:08:02.051: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-wbk5g, will wait for the garbage collector to delete the pods
Jun  4 14:08:02.330: INFO: Deleting DaemonSet.extensions daemon-set took: 12.255176ms
Jun  4 14:08:02.630: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.704663ms
Jun  4 14:08:09.140: INFO: Number of nodes with available pods: 0
Jun  4 14:08:09.140: INFO: Number of running nodes: 0, number of available pods: 0
Jun  4 14:08:09.154: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-wbk5g/daemonsets","resourceVersion":"24798"},"items":null}

Jun  4 14:08:09.167: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-wbk5g/pods","resourceVersion":"24799"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:08:09.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-wbk5g" for this suite.
Jun  4 14:08:17.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:08:17.398: INFO: namespace: e2e-tests-daemonsets-wbk5g, resource: bindings, ignored listing per whitelist
Jun  4 14:08:17.665: INFO: namespace e2e-tests-daemonsets-wbk5g deletion completed in 8.454531705s

• [SLOW TEST:133.312 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:08:17.671: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jun  4 14:08:26.446: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:26.446: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:27.337: INFO: Exec stderr: ""
Jun  4 14:08:27.338: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:27.338: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:28.100: INFO: Exec stderr: ""
Jun  4 14:08:28.100: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:28.100: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:28.997: INFO: Exec stderr: ""
Jun  4 14:08:28.997: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:28.997: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:29.965: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jun  4 14:08:29.965: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:29.965: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:30.765: INFO: Exec stderr: ""
Jun  4 14:08:30.765: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:30.765: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:31.422: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jun  4 14:08:31.422: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:31.422: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:32.178: INFO: Exec stderr: ""
Jun  4 14:08:32.178: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:32.178: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:32.838: INFO: Exec stderr: ""
Jun  4 14:08:32.838: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:32.838: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:33.719: INFO: Exec stderr: ""
Jun  4 14:08:33.720: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-kdpjc PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun  4 14:08:33.720: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
Jun  4 14:08:34.477: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:08:34.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-kdpjc" for this suite.
Jun  4 14:09:26.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:09:27.373: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-kdpjc, resource: bindings, ignored listing per whitelist
Jun  4 14:09:27.940: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-kdpjc deletion completed in 53.385668139s

• [SLOW TEST:70.269 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:09:27.942: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:09:28.672: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5dcc207b-86d2-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-6kxkv" to be "success or failure"
Jun  4 14:09:28.706: INFO: Pod "downwardapi-volume-5dcc207b-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 33.482205ms
Jun  4 14:09:31.138: INFO: Pod "downwardapi-volume-5dcc207b-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.465519141s
Jun  4 14:09:33.248: INFO: Pod "downwardapi-volume-5dcc207b-86d2-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.576083096s
STEP: Saw pod success
Jun  4 14:09:33.248: INFO: Pod "downwardapi-volume-5dcc207b-86d2-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:09:33.255: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-5dcc207b-86d2-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:09:33.323: INFO: Waiting for pod downwardapi-volume-5dcc207b-86d2-11e9-8620-ba945f56578b to disappear
Jun  4 14:09:33.330: INFO: Pod downwardapi-volume-5dcc207b-86d2-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:09:33.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6kxkv" for this suite.
Jun  4 14:09:39.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:09:39.721: INFO: namespace: e2e-tests-projected-6kxkv, resource: bindings, ignored listing per whitelist
Jun  4 14:09:39.869: INFO: namespace e2e-tests-projected-6kxkv deletion completed in 6.525176486s

• [SLOW TEST:11.928 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:09:39.873: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2lvlw A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-2lvlw;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2lvlw A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-2lvlw;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2lvlw.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-2lvlw.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2lvlw.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-2lvlw.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2lvlw.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-2lvlw.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2lvlw.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-2lvlw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2lvlw.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 109.10.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.10.109_udp@PTR;check="$$(dig +tcp +noall +answer +search 109.10.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.10.109_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2lvlw A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-2lvlw;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2lvlw A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-2lvlw;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-2lvlw.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-2lvlw.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-2lvlw.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-2lvlw.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2lvlw.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-2lvlw.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-2lvlw.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-2lvlw.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-2lvlw.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 109.10.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.10.109_udp@PTR;check="$$(dig +tcp +noall +answer +search 109.10.10.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.10.10.109_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun  4 14:10:00.698: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-2lvlw/dns-test-64cac343-86d2-11e9-8620-ba945f56578b: the server could not find the requested resource (get pods dns-test-64cac343-86d2-11e9-8620-ba945f56578b)
Jun  4 14:10:00.939: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-2lvlw from pod e2e-tests-dns-2lvlw/dns-test-64cac343-86d2-11e9-8620-ba945f56578b: the server could not find the requested resource (get pods dns-test-64cac343-86d2-11e9-8620-ba945f56578b)
Jun  4 14:10:01.138: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-2lvlw.svc from pod e2e-tests-dns-2lvlw/dns-test-64cac343-86d2-11e9-8620-ba945f56578b: the server could not find the requested resource (get pods dns-test-64cac343-86d2-11e9-8620-ba945f56578b)
Jun  4 14:10:01.234: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc from pod e2e-tests-dns-2lvlw/dns-test-64cac343-86d2-11e9-8620-ba945f56578b: the server could not find the requested resource (get pods dns-test-64cac343-86d2-11e9-8620-ba945f56578b)
Jun  4 14:10:03.335: INFO: Lookups using e2e-tests-dns-2lvlw/dns-test-64cac343-86d2-11e9-8620-ba945f56578b failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-2lvlw wheezy_tcp@dns-test-service.e2e-tests-dns-2lvlw.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-2lvlw.svc]

Jun  4 14:10:11.606: INFO: DNS probes using e2e-tests-dns-2lvlw/dns-test-64cac343-86d2-11e9-8620-ba945f56578b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:10:12.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-2lvlw" for this suite.
Jun  4 14:10:18.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:10:18.687: INFO: namespace: e2e-tests-dns-2lvlw, resource: bindings, ignored listing per whitelist
Jun  4 14:10:18.837: INFO: namespace e2e-tests-dns-2lvlw deletion completed in 6.627189034s

• [SLOW TEST:38.965 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:10:18.839: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:10:19.337: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7bf019c4-86d2-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-v7cv5" to be "success or failure"
Jun  4 14:10:19.439: INFO: Pod "downwardapi-volume-7bf019c4-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 101.2364ms
Jun  4 14:10:21.446: INFO: Pod "downwardapi-volume-7bf019c4-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.108598009s
Jun  4 14:10:23.454: INFO: Pod "downwardapi-volume-7bf019c4-86d2-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.116395893s
STEP: Saw pod success
Jun  4 14:10:23.454: INFO: Pod "downwardapi-volume-7bf019c4-86d2-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:10:23.637: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-7bf019c4-86d2-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:10:23.902: INFO: Waiting for pod downwardapi-volume-7bf019c4-86d2-11e9-8620-ba945f56578b to disappear
Jun  4 14:10:23.910: INFO: Pod downwardapi-volume-7bf019c4-86d2-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:10:23.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-v7cv5" for this suite.
Jun  4 14:10:29.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:10:30.750: INFO: namespace: e2e-tests-projected-v7cv5, resource: bindings, ignored listing per whitelist
Jun  4 14:10:30.861: INFO: namespace e2e-tests-projected-v7cv5 deletion completed in 6.923011501s

• [SLOW TEST:12.022 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:10:30.862: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:10:31.353: INFO: Waiting up to 5m0s for pod "downwardapi-volume-832aa0f4-86d2-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-gcvf2" to be "success or failure"
Jun  4 14:10:31.398: INFO: Pod "downwardapi-volume-832aa0f4-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 45.151811ms
Jun  4 14:10:33.671: INFO: Pod "downwardapi-volume-832aa0f4-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.317625905s
Jun  4 14:10:35.681: INFO: Pod "downwardapi-volume-832aa0f4-86d2-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.327547928s
STEP: Saw pod success
Jun  4 14:10:35.681: INFO: Pod "downwardapi-volume-832aa0f4-86d2-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:10:35.695: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-832aa0f4-86d2-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:10:35.783: INFO: Waiting for pod downwardapi-volume-832aa0f4-86d2-11e9-8620-ba945f56578b to disappear
Jun  4 14:10:35.839: INFO: Pod downwardapi-volume-832aa0f4-86d2-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:10:35.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gcvf2" for this suite.
Jun  4 14:10:42.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:10:42.396: INFO: namespace: e2e-tests-projected-gcvf2, resource: bindings, ignored listing per whitelist
Jun  4 14:10:42.574: INFO: namespace e2e-tests-projected-gcvf2 deletion completed in 6.724886977s

• [SLOW TEST:11.713 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:10:42.580: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jun  4 14:10:42.988: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-063591806 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:10:43.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l9bbm" for this suite.
Jun  4 14:10:49.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:10:49.450: INFO: namespace: e2e-tests-kubectl-l9bbm, resource: bindings, ignored listing per whitelist
Jun  4 14:10:49.888: INFO: namespace e2e-tests-kubectl-l9bbm deletion completed in 6.723379872s

• [SLOW TEST:7.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:10:49.896: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:10:50.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xnnff" for this suite.
Jun  4 14:11:14.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:11:14.743: INFO: namespace: e2e-tests-pods-xnnff, resource: bindings, ignored listing per whitelist
Jun  4 14:11:15.141: INFO: namespace e2e-tests-pods-xnnff deletion completed in 24.803159163s

• [SLOW TEST:25.246 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:11:15.146: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun  4 14:11:19.811: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun  4 14:11:19.822: INFO: Pod pod-with-poststart-http-hook still exists
Jun  4 14:11:21.822: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun  4 14:11:21.892: INFO: Pod pod-with-poststart-http-hook still exists
Jun  4 14:11:23.822: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun  4 14:11:23.835: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:11:23.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4rslk" for this suite.
Jun  4 14:11:50.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:11:50.153: INFO: namespace: e2e-tests-container-lifecycle-hook-4rslk, resource: bindings, ignored listing per whitelist
Jun  4 14:11:50.621: INFO: namespace e2e-tests-container-lifecycle-hook-4rslk deletion completed in 26.773020582s

• [SLOW TEST:35.475 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:11:50.626: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b2b7a554-86d2-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 14:11:51.133: INFO: Waiting up to 5m0s for pod "pod-secrets-b2b8d5bc-86d2-11e9-8620-ba945f56578b" in namespace "e2e-tests-secrets-tl9jr" to be "success or failure"
Jun  4 14:11:51.141: INFO: Pod "pod-secrets-b2b8d5bc-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.798209ms
Jun  4 14:11:53.154: INFO: Pod "pod-secrets-b2b8d5bc-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020599273s
Jun  4 14:11:55.247: INFO: Pod "pod-secrets-b2b8d5bc-86d2-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113805943s
STEP: Saw pod success
Jun  4 14:11:55.247: INFO: Pod "pod-secrets-b2b8d5bc-86d2-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:11:55.259: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-secrets-b2b8d5bc-86d2-11e9-8620-ba945f56578b container secret-volume-test: <nil>
STEP: delete the pod
Jun  4 14:11:55.421: INFO: Waiting for pod pod-secrets-b2b8d5bc-86d2-11e9-8620-ba945f56578b to disappear
Jun  4 14:11:55.426: INFO: Pod pod-secrets-b2b8d5bc-86d2-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:11:55.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tl9jr" for this suite.
Jun  4 14:12:01.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:12:01.737: INFO: namespace: e2e-tests-secrets-tl9jr, resource: bindings, ignored listing per whitelist
Jun  4 14:12:02.243: INFO: namespace e2e-tests-secrets-tl9jr deletion completed in 6.810022771s

• [SLOW TEST:11.618 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:12:02.248: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:12:02.625: INFO: (0) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 43.453236ms)
Jun  4 14:12:02.671: INFO: (1) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 45.462894ms)
Jun  4 14:12:02.680: INFO: (2) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.938025ms)
Jun  4 14:12:02.697: INFO: (3) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.115649ms)
Jun  4 14:12:02.707: INFO: (4) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.003154ms)
Jun  4 14:12:02.738: INFO: (5) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 31.457859ms)
Jun  4 14:12:02.838: INFO: (6) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 99.642219ms)
Jun  4 14:12:02.937: INFO: (7) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 99.319521ms)
Jun  4 14:12:02.997: INFO: (8) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 59.726191ms)
Jun  4 14:12:03.040: INFO: (9) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 43.087311ms)
Jun  4 14:12:03.137: INFO: (10) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 96.959266ms)
Jun  4 14:12:03.176: INFO: (11) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 38.736493ms)
Jun  4 14:12:03.237: INFO: (12) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 60.60679ms)
Jun  4 14:12:03.298: INFO: (13) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 60.480813ms)
Jun  4 14:12:03.339: INFO: (14) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 40.71588ms)
Jun  4 14:12:03.355: INFO: (15) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.659206ms)
Jun  4 14:12:03.370: INFO: (16) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.005937ms)
Jun  4 14:12:03.398: INFO: (17) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.889849ms)
Jun  4 14:12:03.413: INFO: (18) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.972967ms)
Jun  4 14:12:03.425: INFO: (19) /api/v1/nodes/worker-4jvsx-65d7bd6f69-45s5z/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.952129ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:12:03.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-phgsc" for this suite.
Jun  4 14:12:09.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:12:10.235: INFO: namespace: e2e-tests-proxy-phgsc, resource: bindings, ignored listing per whitelist
Jun  4 14:12:10.256: INFO: namespace e2e-tests-proxy-phgsc deletion completed in 6.816377165s

• [SLOW TEST:8.009 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:12:10.262: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:12:11.135: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be8ffd1e-86d2-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-8knrm" to be "success or failure"
Jun  4 14:12:11.141: INFO: Pod "downwardapi-volume-be8ffd1e-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.73354ms
Jun  4 14:12:13.163: INFO: Pod "downwardapi-volume-be8ffd1e-86d2-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027427757s
STEP: Saw pod success
Jun  4 14:12:13.163: INFO: Pod "downwardapi-volume-be8ffd1e-86d2-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:12:13.172: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-be8ffd1e-86d2-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:12:13.261: INFO: Waiting for pod downwardapi-volume-be8ffd1e-86d2-11e9-8620-ba945f56578b to disappear
Jun  4 14:12:13.266: INFO: Pod downwardapi-volume-be8ffd1e-86d2-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:12:13.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8knrm" for this suite.
Jun  4 14:12:19.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:12:19.561: INFO: namespace: e2e-tests-downward-api-8knrm, resource: bindings, ignored listing per whitelist
Jun  4 14:12:20.018: INFO: namespace e2e-tests-downward-api-8knrm deletion completed in 6.743327628s

• [SLOW TEST:9.756 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:12:20.022: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c448171e-86d2-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 14:12:20.775: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c45186e8-86d2-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-mzpmr" to be "success or failure"
Jun  4 14:12:20.816: INFO: Pod "pod-projected-configmaps-c45186e8-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 41.558359ms
Jun  4 14:12:22.826: INFO: Pod "pod-projected-configmaps-c45186e8-86d2-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050928727s
STEP: Saw pod success
Jun  4 14:12:22.826: INFO: Pod "pod-projected-configmaps-c45186e8-86d2-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:12:22.843: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-configmaps-c45186e8-86d2-11e9-8620-ba945f56578b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 14:12:23.041: INFO: Waiting for pod pod-projected-configmaps-c45186e8-86d2-11e9-8620-ba945f56578b to disappear
Jun  4 14:12:23.048: INFO: Pod pod-projected-configmaps-c45186e8-86d2-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:12:23.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mzpmr" for this suite.
Jun  4 14:12:29.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:12:29.483: INFO: namespace: e2e-tests-projected-mzpmr, resource: bindings, ignored listing per whitelist
Jun  4 14:12:29.599: INFO: namespace e2e-tests-projected-mzpmr deletion completed in 6.527954057s

• [SLOW TEST:9.578 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:12:29.605: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-kbfn8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kbfn8 to expose endpoints map[]
Jun  4 14:12:30.170: INFO: Get endpoints failed (9.377671ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jun  4 14:12:31.179: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kbfn8 exposes endpoints map[] (1.01788608s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-kbfn8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kbfn8 to expose endpoints map[pod1:[80]]
Jun  4 14:12:34.475: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kbfn8 exposes endpoints map[pod1:[80]] (3.274768736s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-kbfn8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kbfn8 to expose endpoints map[pod1:[80] pod2:[80]]
Jun  4 14:12:37.707: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kbfn8 exposes endpoints map[pod1:[80] pod2:[80]] (3.167952138s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-kbfn8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kbfn8 to expose endpoints map[pod2:[80]]
Jun  4 14:12:37.743: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kbfn8 exposes endpoints map[pod2:[80]] (22.83686ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-kbfn8
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kbfn8 to expose endpoints map[]
Jun  4 14:12:38.840: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kbfn8 exposes endpoints map[] (1.051609048s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:12:38.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kbfn8" for this suite.
Jun  4 14:13:03.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:13:03.466: INFO: namespace: e2e-tests-services-kbfn8, resource: bindings, ignored listing per whitelist
Jun  4 14:13:03.759: INFO: namespace e2e-tests-services-kbfn8 deletion completed in 24.811859179s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:34.155 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:13:03.764: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun  4 14:13:04.304: INFO: Waiting up to 5m0s for pod "pod-de5556e2-86d2-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-p47tl" to be "success or failure"
Jun  4 14:13:04.314: INFO: Pod "pod-de5556e2-86d2-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.603719ms
Jun  4 14:13:06.321: INFO: Pod "pod-de5556e2-86d2-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015581705s
STEP: Saw pod success
Jun  4 14:13:06.321: INFO: Pod "pod-de5556e2-86d2-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:13:06.325: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-de5556e2-86d2-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 14:13:06.537: INFO: Waiting for pod pod-de5556e2-86d2-11e9-8620-ba945f56578b to disappear
Jun  4 14:13:06.546: INFO: Pod pod-de5556e2-86d2-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:13:06.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-p47tl" for this suite.
Jun  4 14:13:12.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:13:12.827: INFO: namespace: e2e-tests-emptydir-p47tl, resource: bindings, ignored listing per whitelist
Jun  4 14:13:12.986: INFO: namespace e2e-tests-emptydir-p47tl deletion completed in 6.433351799s

• [SLOW TEST:9.224 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:13:12.993: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jun  4 14:13:14.062: INFO: Waiting up to 5m0s for pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-27r8z" in namespace "e2e-tests-svcaccounts-m4s64" to be "success or failure"
Jun  4 14:13:14.069: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-27r8z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.585135ms
Jun  4 14:13:16.082: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-27r8z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019683576s
Jun  4 14:13:18.090: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-27r8z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027270955s
STEP: Saw pod success
Jun  4 14:13:18.090: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-27r8z" satisfied condition "success or failure"
Jun  4 14:13:18.148: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-gv9cg pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-27r8z container token-test: <nil>
STEP: delete the pod
Jun  4 14:13:18.311: INFO: Waiting for pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-27r8z to disappear
Jun  4 14:13:18.315: INFO: Pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-27r8z no longer exists
STEP: Creating a pod to test consume service account root CA
Jun  4 14:13:18.345: INFO: Waiting up to 5m0s for pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-4vs2j" in namespace "e2e-tests-svcaccounts-m4s64" to be "success or failure"
Jun  4 14:13:18.837: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-4vs2j": Phase="Pending", Reason="", readiness=false. Elapsed: 492.108308ms
Jun  4 14:13:20.937: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-4vs2j": Phase="Pending", Reason="", readiness=false. Elapsed: 2.591990535s
Jun  4 14:13:23.037: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-4vs2j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.691663753s
STEP: Saw pod success
Jun  4 14:13:23.037: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-4vs2j" satisfied condition "success or failure"
Jun  4 14:13:23.048: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-4vs2j container root-ca-test: <nil>
STEP: delete the pod
Jun  4 14:13:23.247: INFO: Waiting for pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-4vs2j to disappear
Jun  4 14:13:23.336: INFO: Pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-4vs2j no longer exists
STEP: Creating a pod to test consume service account namespace
Jun  4 14:13:23.350: INFO: Waiting up to 5m0s for pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-th9lj" in namespace "e2e-tests-svcaccounts-m4s64" to be "success or failure"
Jun  4 14:13:23.395: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-th9lj": Phase="Pending", Reason="", readiness=false. Elapsed: 44.629647ms
Jun  4 14:13:25.404: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-th9lj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053403567s
Jun  4 14:13:27.441: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-th9lj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.091128911s
STEP: Saw pod success
Jun  4 14:13:27.441: INFO: Pod "pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-th9lj" satisfied condition "success or failure"
Jun  4 14:13:27.447: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-th9lj container namespace-test: <nil>
STEP: delete the pod
Jun  4 14:13:27.555: INFO: Waiting for pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-th9lj to disappear
Jun  4 14:13:27.562: INFO: Pod pod-service-account-e4247447-86d2-11e9-8620-ba945f56578b-th9lj no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:13:27.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-m4s64" for this suite.
Jun  4 14:13:33.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:13:33.939: INFO: namespace: e2e-tests-svcaccounts-m4s64, resource: bindings, ignored listing per whitelist
Jun  4 14:13:34.203: INFO: namespace e2e-tests-svcaccounts-m4s64 deletion completed in 6.565432774s

• [SLOW TEST:21.211 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:13:34.203: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:13:41.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-thgn5" for this suite.
Jun  4 14:13:47.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:13:47.634: INFO: namespace: e2e-tests-namespaces-thgn5, resource: bindings, ignored listing per whitelist
Jun  4 14:13:47.705: INFO: namespace e2e-tests-namespaces-thgn5 deletion completed in 6.50222907s
STEP: Destroying namespace "e2e-tests-nsdeletetest-2tvdz" for this suite.
Jun  4 14:13:47.711: INFO: Namespace e2e-tests-nsdeletetest-2tvdz was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-lcvdj" for this suite.
Jun  4 14:13:53.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:13:54.523: INFO: namespace: e2e-tests-nsdeletetest-lcvdj, resource: bindings, ignored listing per whitelist
Jun  4 14:13:54.535: INFO: namespace e2e-tests-nsdeletetest-lcvdj deletion completed in 6.823593422s

• [SLOW TEST:20.332 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:13:54.544: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun  4 14:13:54.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-29jkj'
Jun  4 14:13:55.790: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun  4 14:13:55.790: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Jun  4 14:13:57.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-29jkj'
Jun  4 14:13:58.293: INFO: stderr: ""
Jun  4 14:13:58.293: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:13:58.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-29jkj" for this suite.
Jun  4 14:14:06.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:14:07.203: INFO: namespace: e2e-tests-kubectl-29jkj, resource: bindings, ignored listing per whitelist
Jun  4 14:14:07.795: INFO: namespace e2e-tests-kubectl-29jkj deletion completed in 9.224668467s

• [SLOW TEST:13.252 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:14:07.802: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-5xslk
Jun  4 14:14:14.915: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-5xslk
STEP: checking the pod's current state and verifying that restartCount is present
Jun  4 14:14:14.923: INFO: Initial restart count of pod liveness-http is 0
Jun  4 14:14:27.143: INFO: Restart count of pod e2e-tests-container-probe-5xslk/liveness-http is now 1 (12.220424028s elapsed)
Jun  4 14:14:47.374: INFO: Restart count of pod e2e-tests-container-probe-5xslk/liveness-http is now 2 (32.45097077s elapsed)
Jun  4 14:15:07.937: INFO: Restart count of pod e2e-tests-container-probe-5xslk/liveness-http is now 3 (53.014762527s elapsed)
Jun  4 14:15:28.684: INFO: Restart count of pod e2e-tests-container-probe-5xslk/liveness-http is now 4 (1m13.761469811s elapsed)
Jun  4 14:16:38.063: INFO: Restart count of pod e2e-tests-container-probe-5xslk/liveness-http is now 5 (2m23.140639783s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:16:38.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5xslk" for this suite.
Jun  4 14:16:44.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:16:44.637: INFO: namespace: e2e-tests-container-probe-5xslk, resource: bindings, ignored listing per whitelist
Jun  4 14:16:44.715: INFO: namespace e2e-tests-container-probe-5xslk deletion completed in 6.593856114s

• [SLOW TEST:156.914 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:16:44.721: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:16:45.040: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:16:49.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-n6c9p" for this suite.
Jun  4 14:17:33.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:17:34.151: INFO: namespace: e2e-tests-pods-n6c9p, resource: bindings, ignored listing per whitelist
Jun  4 14:17:34.341: INFO: namespace e2e-tests-pods-n6c9p deletion completed in 44.886752497s

• [SLOW TEST:49.623 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:17:34.346: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jun  4 14:17:35.200: INFO: Waiting up to 5m0s for pod "client-containers-7fcd724a-86d3-11e9-8620-ba945f56578b" in namespace "e2e-tests-containers-tz2f7" to be "success or failure"
Jun  4 14:17:35.213: INFO: Pod "client-containers-7fcd724a-86d3-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.460107ms
Jun  4 14:17:37.231: INFO: Pod "client-containers-7fcd724a-86d3-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030654745s
Jun  4 14:17:39.337: INFO: Pod "client-containers-7fcd724a-86d3-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.136461803s
STEP: Saw pod success
Jun  4 14:17:39.337: INFO: Pod "client-containers-7fcd724a-86d3-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:17:39.344: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod client-containers-7fcd724a-86d3-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 14:17:39.454: INFO: Waiting for pod client-containers-7fcd724a-86d3-11e9-8620-ba945f56578b to disappear
Jun  4 14:17:39.549: INFO: Pod client-containers-7fcd724a-86d3-11e9-8620-ba945f56578b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:17:39.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-tz2f7" for this suite.
Jun  4 14:17:45.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:17:46.056: INFO: namespace: e2e-tests-containers-tz2f7, resource: bindings, ignored listing per whitelist
Jun  4 14:17:46.191: INFO: namespace e2e-tests-containers-tz2f7 deletion completed in 6.62170368s

• [SLOW TEST:11.846 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:17:46.195: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-6xx8d
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-6xx8d
STEP: Deleting pre-stop pod
Jun  4 14:18:00.337: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:18:00.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-6xx8d" for this suite.
Jun  4 14:18:40.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:18:40.729: INFO: namespace: e2e-tests-prestop-6xx8d, resource: bindings, ignored listing per whitelist
Jun  4 14:18:40.921: INFO: namespace e2e-tests-prestop-6xx8d deletion completed in 40.55891982s

• [SLOW TEST:54.727 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:18:40.926: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a76e8a59-86d3-11e9-8620-ba945f56578b
STEP: Creating secret with name s-test-opt-upd-a76e8ab3-86d3-11e9-8620-ba945f56578b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a76e8a59-86d3-11e9-8620-ba945f56578b
STEP: Updating secret s-test-opt-upd-a76e8ab3-86d3-11e9-8620-ba945f56578b
STEP: Creating secret with name s-test-opt-create-a76e8ad2-86d3-11e9-8620-ba945f56578b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:20:16.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wfbq6" for this suite.
Jun  4 14:20:38.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:20:39.281: INFO: namespace: e2e-tests-secrets-wfbq6, resource: bindings, ignored listing per whitelist
Jun  4 14:20:39.561: INFO: namespace e2e-tests-secrets-wfbq6 deletion completed in 22.741192944s

• [SLOW TEST:118.636 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:20:39.564: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jun  4 14:20:42.374: INFO: Pod pod-hostip-ee11fae8-86d3-11e9-8620-ba945f56578b has hostIP: 138.68.109.151
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:20:42.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8lcj7" for this suite.
Jun  4 14:21:04.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:21:04.601: INFO: namespace: e2e-tests-pods-8lcj7, resource: bindings, ignored listing per whitelist
Jun  4 14:21:04.951: INFO: namespace e2e-tests-pods-8lcj7 deletion completed in 22.567252719s

• [SLOW TEST:25.387 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:21:04.954: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-fd353917-86d3-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 14:21:05.607: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fd36ba33-86d3-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-qfd2t" to be "success or failure"
Jun  4 14:21:05.610: INFO: Pod "pod-projected-secrets-fd36ba33-86d3-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.658857ms
Jun  4 14:21:07.616: INFO: Pod "pod-projected-secrets-fd36ba33-86d3-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009574799s
Jun  4 14:21:09.626: INFO: Pod "pod-projected-secrets-fd36ba33-86d3-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019499613s
STEP: Saw pod success
Jun  4 14:21:09.626: INFO: Pod "pod-projected-secrets-fd36ba33-86d3-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:21:09.633: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-secrets-fd36ba33-86d3-11e9-8620-ba945f56578b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun  4 14:21:09.753: INFO: Waiting for pod pod-projected-secrets-fd36ba33-86d3-11e9-8620-ba945f56578b to disappear
Jun  4 14:21:09.765: INFO: Pod pod-projected-secrets-fd36ba33-86d3-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:21:09.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qfd2t" for this suite.
Jun  4 14:21:15.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:21:16.540: INFO: namespace: e2e-tests-projected-qfd2t, resource: bindings, ignored listing per whitelist
Jun  4 14:21:16.573: INFO: namespace e2e-tests-projected-qfd2t deletion completed in 6.801797646s

• [SLOW TEST:11.620 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:21:16.577: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-03eb2822-86d4-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 14:21:16.891: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-03ee35a4-86d4-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-g5qqx" to be "success or failure"
Jun  4 14:21:16.971: INFO: Pod "pod-projected-secrets-03ee35a4-86d4-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 79.129222ms
Jun  4 14:21:18.979: INFO: Pod "pod-projected-secrets-03ee35a4-86d4-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.087044698s
STEP: Saw pod success
Jun  4 14:21:18.979: INFO: Pod "pod-projected-secrets-03ee35a4-86d4-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:21:18.994: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-secrets-03ee35a4-86d4-11e9-8620-ba945f56578b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun  4 14:21:19.244: INFO: Waiting for pod pod-projected-secrets-03ee35a4-86d4-11e9-8620-ba945f56578b to disappear
Jun  4 14:21:19.252: INFO: Pod pod-projected-secrets-03ee35a4-86d4-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:21:19.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g5qqx" for this suite.
Jun  4 14:21:25.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:21:25.742: INFO: namespace: e2e-tests-projected-g5qqx, resource: bindings, ignored listing per whitelist
Jun  4 14:21:25.928: INFO: namespace e2e-tests-projected-g5qqx deletion completed in 6.662567848s

• [SLOW TEST:9.351 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:21:25.933: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-74n9n
I0604 14:21:26.236960      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-74n9n, replica count: 1
I0604 14:21:27.287436      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 14:21:28.287822      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 14:21:29.288112      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0604 14:21:30.288405      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun  4 14:21:30.472: INFO: Created: latency-svc-qjtp5
Jun  4 14:21:30.537: INFO: Got endpoints: latency-svc-qjtp5 [149.061932ms]
Jun  4 14:21:30.574: INFO: Created: latency-svc-k4ktn
Jun  4 14:21:30.640: INFO: Created: latency-svc-rb48b
Jun  4 14:21:30.641: INFO: Created: latency-svc-ctm4j
Jun  4 14:21:30.641: INFO: Got endpoints: latency-svc-ctm4j [102.66612ms]
Jun  4 14:21:30.641: INFO: Created: latency-svc-qzs4j
Jun  4 14:21:30.643: INFO: Got endpoints: latency-svc-qzs4j [103.342691ms]
Jun  4 14:21:30.641: INFO: Created: latency-svc-877zb
Jun  4 14:21:30.643: INFO: Got endpoints: latency-svc-877zb [103.779965ms]
Jun  4 14:21:30.641: INFO: Created: latency-svc-smwj2
Jun  4 14:21:30.644: INFO: Got endpoints: latency-svc-smwj2 [104.359321ms]
Jun  4 14:21:30.641: INFO: Got endpoints: latency-svc-k4ktn [102.658623ms]
Jun  4 14:21:30.676: INFO: Created: latency-svc-4sh6n
Jun  4 14:21:30.677: INFO: Created: latency-svc-cpzzv
Jun  4 14:21:30.678: INFO: Got endpoints: latency-svc-cpzzv [137.427798ms]
Jun  4 14:21:30.677: INFO: Created: latency-svc-q4ddl
Jun  4 14:21:30.677: INFO: Got endpoints: latency-svc-rb48b [139.233815ms]
Jun  4 14:21:30.679: INFO: Got endpoints: latency-svc-q4ddl [138.405718ms]
Jun  4 14:21:30.681: INFO: Got endpoints: latency-svc-4sh6n [139.304423ms]
Jun  4 14:21:30.737: INFO: Created: latency-svc-njh88
Jun  4 14:21:30.737: INFO: Created: latency-svc-tkdzn
Jun  4 14:21:30.738: INFO: Created: latency-svc-cdgst
Jun  4 14:21:30.738: INFO: Created: latency-svc-4s7z4
Jun  4 14:21:30.738: INFO: Created: latency-svc-4zntk
Jun  4 14:21:30.739: INFO: Got endpoints: latency-svc-4zntk [195.891502ms]
Jun  4 14:21:30.739: INFO: Got endpoints: latency-svc-tkdzn [197.322486ms]
Jun  4 14:21:30.740: INFO: Got endpoints: latency-svc-cdgst [197.746706ms]
Jun  4 14:21:30.740: INFO: Got endpoints: latency-svc-4s7z4 [198.062288ms]
Jun  4 14:21:30.785: INFO: Created: latency-svc-m7qq2
Jun  4 14:21:30.785: INFO: Got endpoints: latency-svc-m7qq2 [242.538615ms]
Jun  4 14:21:30.786: INFO: Got endpoints: latency-svc-njh88 [242.639834ms]
Jun  4 14:21:30.837: INFO: Created: latency-svc-9h5cf
Jun  4 14:21:30.837: INFO: Created: latency-svc-mffwd
Jun  4 14:21:30.838: INFO: Created: latency-svc-bvn92
Jun  4 14:21:30.838: INFO: Created: latency-svc-v7xsc
Jun  4 14:21:30.838: INFO: Created: latency-svc-z7rtw
Jun  4 14:21:30.838: INFO: Got endpoints: latency-svc-z7rtw [192.338338ms]
Jun  4 14:21:30.838: INFO: Got endpoints: latency-svc-mffwd [195.591201ms]
Jun  4 14:21:30.839: INFO: Got endpoints: latency-svc-bvn92 [195.078199ms]
Jun  4 14:21:30.839: INFO: Got endpoints: latency-svc-v7xsc [194.624343ms]
Jun  4 14:21:30.975: INFO: Created: latency-svc-kkrr6
Jun  4 14:21:30.976: INFO: Created: latency-svc-q6448
Jun  4 14:21:30.976: INFO: Got endpoints: latency-svc-q6448 [297.719171ms]
Jun  4 14:21:30.977: INFO: Got endpoints: latency-svc-9h5cf [335.530722ms]
Jun  4 14:21:31.038: INFO: Created: latency-svc-bwk2c
Jun  4 14:21:31.039: INFO: Created: latency-svc-mrsz9
Jun  4 14:21:31.039: INFO: Got endpoints: latency-svc-mrsz9 [358.566653ms]
Jun  4 14:21:31.039: INFO: Created: latency-svc-rbwwm
Jun  4 14:21:31.040: INFO: Got endpoints: latency-svc-rbwwm [360.726929ms]
Jun  4 14:21:31.039: INFO: Created: latency-svc-7s84d
Jun  4 14:21:31.040: INFO: Got endpoints: latency-svc-7s84d [301.846843ms]
Jun  4 14:21:31.039: INFO: Created: latency-svc-ks92c
Jun  4 14:21:31.041: INFO: Got endpoints: latency-svc-ks92c [300.664558ms]
Jun  4 14:21:31.039: INFO: Got endpoints: latency-svc-bwk2c [298.927788ms]
Jun  4 14:21:31.039: INFO: Got endpoints: latency-svc-kkrr6 [360.015603ms]
Jun  4 14:21:31.046: INFO: Created: latency-svc-gbx22
Jun  4 14:21:31.083: INFO: Got endpoints: latency-svc-gbx22 [344.537395ms]
Jun  4 14:21:31.175: INFO: Created: latency-svc-7wcbc
Jun  4 14:21:31.177: INFO: Got endpoints: latency-svc-7wcbc [392.221808ms]
Jun  4 14:21:31.205: INFO: Created: latency-svc-tnch9
Jun  4 14:21:31.211: INFO: Got endpoints: latency-svc-tnch9 [425.016907ms]
Jun  4 14:21:31.229: INFO: Created: latency-svc-gp7fp
Jun  4 14:21:31.235: INFO: Got endpoints: latency-svc-gp7fp [396.817621ms]
Jun  4 14:21:31.338: INFO: Created: latency-svc-znwgk
Jun  4 14:21:31.338: INFO: Got endpoints: latency-svc-znwgk [499.776116ms]
Jun  4 14:21:31.385: INFO: Created: latency-svc-fz5br
Jun  4 14:21:31.392: INFO: Got endpoints: latency-svc-fz5br [553.562797ms]
Jun  4 14:21:31.439: INFO: Created: latency-svc-zrtfg
Jun  4 14:21:31.439: INFO: Got endpoints: latency-svc-zrtfg [599.316811ms]
Jun  4 14:21:31.574: INFO: Created: latency-svc-tfp7v
Jun  4 14:21:31.575: INFO: Created: latency-svc-6s2sb
Jun  4 14:21:31.575: INFO: Got endpoints: latency-svc-6s2sb [598.888487ms]
Jun  4 14:21:31.577: INFO: Got endpoints: latency-svc-tfp7v [599.929724ms]
Jun  4 14:21:31.582: INFO: Created: latency-svc-rbgnn
Jun  4 14:21:31.594: INFO: Got endpoints: latency-svc-rbgnn [552.902464ms]
Jun  4 14:21:31.642: INFO: Created: latency-svc-tdpz4
Jun  4 14:21:31.642: INFO: Created: latency-svc-rszw9
Jun  4 14:21:31.643: INFO: Created: latency-svc-zt7gf
Jun  4 14:21:31.643: INFO: Got endpoints: latency-svc-zt7gf [603.587074ms]
Jun  4 14:21:31.643: INFO: Got endpoints: latency-svc-tdpz4 [603.017408ms]
Jun  4 14:21:31.643: INFO: Got endpoints: latency-svc-rszw9 [602.716334ms]
Jun  4 14:21:31.738: INFO: Created: latency-svc-b6n7t
Jun  4 14:21:31.738: INFO: Created: latency-svc-95brs
Jun  4 14:21:31.739: INFO: Created: latency-svc-dwjsq
Jun  4 14:21:31.739: INFO: Created: latency-svc-dpwcz
Jun  4 14:21:31.740: INFO: Created: latency-svc-9gl2b
Jun  4 14:21:31.740: INFO: Got endpoints: latency-svc-9gl2b [562.437218ms]
Jun  4 14:21:31.741: INFO: Got endpoints: latency-svc-95brs [700.271869ms]
Jun  4 14:21:31.741: INFO: Got endpoints: latency-svc-dwjsq [700.542552ms]
Jun  4 14:21:31.742: INFO: Got endpoints: latency-svc-dpwcz [658.008281ms]
Jun  4 14:21:31.747: INFO: Got endpoints: latency-svc-b6n7t [535.961923ms]
Jun  4 14:21:31.769: INFO: Created: latency-svc-wsh4c
Jun  4 14:21:31.776: INFO: Got endpoints: latency-svc-wsh4c [540.886442ms]
Jun  4 14:21:31.790: INFO: Created: latency-svc-rxhnl
Jun  4 14:21:31.798: INFO: Got endpoints: latency-svc-rxhnl [459.33542ms]
Jun  4 14:21:31.839: INFO: Created: latency-svc-dlbpz
Jun  4 14:21:31.840: INFO: Got endpoints: latency-svc-dlbpz [447.073991ms]
Jun  4 14:21:31.876: INFO: Created: latency-svc-hvhxt
Jun  4 14:21:31.880: INFO: Got endpoints: latency-svc-hvhxt [440.596843ms]
Jun  4 14:21:31.891: INFO: Created: latency-svc-fq2mg
Jun  4 14:21:31.898: INFO: Got endpoints: latency-svc-fq2mg [323.005229ms]
Jun  4 14:21:31.916: INFO: Created: latency-svc-2w8m7
Jun  4 14:21:31.923: INFO: Got endpoints: latency-svc-2w8m7 [345.171045ms]
Jun  4 14:21:31.989: INFO: Created: latency-svc-tdljn
Jun  4 14:21:31.998: INFO: Got endpoints: latency-svc-tdljn [404.561717ms]
Jun  4 14:21:32.006: INFO: Created: latency-svc-vzln4
Jun  4 14:21:32.023: INFO: Got endpoints: latency-svc-vzln4 [379.565378ms]
Jun  4 14:21:32.025: INFO: Created: latency-svc-54xs4
Jun  4 14:21:32.080: INFO: Got endpoints: latency-svc-54xs4 [435.291342ms]
Jun  4 14:21:32.089: INFO: Created: latency-svc-6gzbb
Jun  4 14:21:32.098: INFO: Got endpoints: latency-svc-6gzbb [452.740914ms]
Jun  4 14:21:32.143: INFO: Created: latency-svc-8cxn4
Jun  4 14:21:32.143: INFO: Got endpoints: latency-svc-8cxn4 [402.963648ms]
Jun  4 14:21:32.174: INFO: Created: latency-svc-dsgnm
Jun  4 14:21:32.174: INFO: Got endpoints: latency-svc-dsgnm [433.601641ms]
Jun  4 14:21:32.175: INFO: Created: latency-svc-2sslg
Jun  4 14:21:32.180: INFO: Got endpoints: latency-svc-2sslg [437.507812ms]
Jun  4 14:21:32.192: INFO: Created: latency-svc-tlj7f
Jun  4 14:21:32.206: INFO: Got endpoints: latency-svc-tlj7f [464.387787ms]
Jun  4 14:21:32.212: INFO: Created: latency-svc-7fjwk
Jun  4 14:21:32.220: INFO: Got endpoints: latency-svc-7fjwk [472.957795ms]
Jun  4 14:21:32.237: INFO: Created: latency-svc-8gdr7
Jun  4 14:21:32.244: INFO: Created: latency-svc-l8zmh
Jun  4 14:21:32.245: INFO: Got endpoints: latency-svc-8gdr7 [468.789831ms]
Jun  4 14:21:32.278: INFO: Created: latency-svc-xpfvn
Jun  4 14:21:32.278: INFO: Got endpoints: latency-svc-xpfvn [58.185719ms]
Jun  4 14:21:32.279: INFO: Got endpoints: latency-svc-l8zmh [480.516734ms]
Jun  4 14:21:32.338: INFO: Created: latency-svc-m9fb7
Jun  4 14:21:32.338: INFO: Created: latency-svc-4rxp2
Jun  4 14:21:32.339: INFO: Got endpoints: latency-svc-4rxp2 [499.104029ms]
Jun  4 14:21:32.339: INFO: Created: latency-svc-m9vck
Jun  4 14:21:32.340: INFO: Got endpoints: latency-svc-m9vck [460.093553ms]
Jun  4 14:21:32.339: INFO: Created: latency-svc-xkjqf
Jun  4 14:21:32.339: INFO: Created: latency-svc-62jc6
Jun  4 14:21:32.341: INFO: Created: latency-svc-gqvwl
Jun  4 14:21:32.374: INFO: Created: latency-svc-58m9g
Jun  4 14:21:32.374: INFO: Created: latency-svc-d65ml
Jun  4 14:21:32.375: INFO: Created: latency-svc-2gllh
Jun  4 14:21:32.438: INFO: Created: latency-svc-7vt9f
Jun  4 14:21:32.439: INFO: Created: latency-svc-qvzxm
Jun  4 14:21:32.439: INFO: Created: latency-svc-wrdlt
Jun  4 14:21:32.439: INFO: Created: latency-svc-hlldc
Jun  4 14:21:32.440: INFO: Created: latency-svc-2xlbk
Jun  4 14:21:32.440: INFO: Created: latency-svc-fnwbv
Jun  4 14:21:32.440: INFO: Got endpoints: latency-svc-62jc6 [517.470808ms]
Jun  4 14:21:32.441: INFO: Got endpoints: latency-svc-xkjqf [541.981427ms]
Jun  4 14:21:32.477: INFO: Got endpoints: latency-svc-m9fb7 [477.916701ms]
Jun  4 14:21:32.478: INFO: Created: latency-svc-r4949
Jun  4 14:21:32.482: INFO: Created: latency-svc-ljjck
Jun  4 14:21:32.488: INFO: Created: latency-svc-xkj6t
Jun  4 14:21:32.496: INFO: Created: latency-svc-d4kgn
Jun  4 14:21:32.542: INFO: Created: latency-svc-k2lrk
Jun  4 14:21:32.578: INFO: Got endpoints: latency-svc-d65ml [497.688341ms]
Jun  4 14:21:32.579: INFO: Got endpoints: latency-svc-gqvwl [554.96031ms]
Jun  4 14:21:32.589: INFO: Created: latency-svc-qmvr9
Jun  4 14:21:32.597: INFO: Created: latency-svc-mztrb
Jun  4 14:21:32.621: INFO: Got endpoints: latency-svc-2gllh [522.792865ms]
Jun  4 14:21:32.634: INFO: Created: latency-svc-tvdcp
Jun  4 14:21:32.782: INFO: Got endpoints: latency-svc-qvzxm [607.584656ms]
Jun  4 14:21:32.783: INFO: Got endpoints: latency-svc-58m9g [639.672372ms]
Jun  4 14:21:32.838: INFO: Got endpoints: latency-svc-hlldc [631.370339ms]
Jun  4 14:21:32.838: INFO: Got endpoints: latency-svc-wrdlt [658.222798ms]
Jun  4 14:21:32.874: INFO: Got endpoints: latency-svc-2xlbk [629.32475ms]
Jun  4 14:21:32.876: INFO: Created: latency-svc-2vnpj
Jun  4 14:21:32.876: INFO: Created: latency-svc-cb9bp
Jun  4 14:21:32.881: INFO: Created: latency-svc-wwzr8
Jun  4 14:21:32.889: INFO: Created: latency-svc-r566r
Jun  4 14:21:32.895: INFO: Created: latency-svc-t2d46
Jun  4 14:21:32.919: INFO: Got endpoints: latency-svc-fnwbv [640.7991ms]
Jun  4 14:21:32.977: INFO: Got endpoints: latency-svc-7vt9f [697.751793ms]
Jun  4 14:21:32.981: INFO: Created: latency-svc-5wp5c
Jun  4 14:21:32.995: INFO: Created: latency-svc-ff5hk
Jun  4 14:21:33.019: INFO: Got endpoints: latency-svc-r4949 [679.753472ms]
Jun  4 14:21:33.095: INFO: Got endpoints: latency-svc-ljjck [754.976159ms]
Jun  4 14:21:33.097: INFO: Created: latency-svc-2q6lv
Jun  4 14:21:33.145: INFO: Got endpoints: latency-svc-xkj6t [704.18532ms]
Jun  4 14:21:33.185: INFO: Got endpoints: latency-svc-d4kgn [744.24527ms]
Jun  4 14:21:33.191: INFO: Created: latency-svc-4br5g
Jun  4 14:21:33.198: INFO: Created: latency-svc-t8428
Jun  4 14:21:33.278: INFO: Got endpoints: latency-svc-qmvr9 [700.174615ms]
Jun  4 14:21:33.279: INFO: Got endpoints: latency-svc-k2lrk [802.301539ms]
Jun  4 14:21:33.284: INFO: Created: latency-svc-tp4jx
Jun  4 14:21:33.291: INFO: Created: latency-svc-kvkkh
Jun  4 14:21:33.296: INFO: Created: latency-svc-kgtdh
Jun  4 14:21:33.324: INFO: Got endpoints: latency-svc-mztrb [744.843137ms]
Jun  4 14:21:33.375: INFO: Got endpoints: latency-svc-tvdcp [754.244399ms]
Jun  4 14:21:33.376: INFO: Created: latency-svc-mj5zh
Jun  4 14:21:33.387: INFO: Created: latency-svc-mn5sm
Jun  4 14:21:33.418: INFO: Got endpoints: latency-svc-2vnpj [635.950278ms]
Jun  4 14:21:33.430: INFO: Created: latency-svc-xllxb
Jun  4 14:21:33.474: INFO: Got endpoints: latency-svc-cb9bp [690.974336ms]
Jun  4 14:21:33.592: INFO: Created: latency-svc-225dz
Jun  4 14:21:33.593: INFO: Got endpoints: latency-svc-r566r [754.261547ms]
Jun  4 14:21:33.594: INFO: Got endpoints: latency-svc-wwzr8 [755.802793ms]
Jun  4 14:21:33.625: INFO: Got endpoints: latency-svc-t2d46 [749.865928ms]
Jun  4 14:21:33.628: INFO: Created: latency-svc-wv9nn
Jun  4 14:21:33.637: INFO: Created: latency-svc-wlh57
Jun  4 14:21:33.673: INFO: Created: latency-svc-x55t2
Jun  4 14:21:33.738: INFO: Got endpoints: latency-svc-ff5hk [760.264132ms]
Jun  4 14:21:33.738: INFO: Got endpoints: latency-svc-5wp5c [819.186801ms]
Jun  4 14:21:33.777: INFO: Got endpoints: latency-svc-2q6lv [757.237873ms]
Jun  4 14:21:33.778: INFO: Created: latency-svc-57db4
Jun  4 14:21:33.778: INFO: Created: latency-svc-t44wf
Jun  4 14:21:33.837: INFO: Got endpoints: latency-svc-4br5g [741.363175ms]
Jun  4 14:21:33.875: INFO: Created: latency-svc-zlpf8
Jun  4 14:21:33.875: INFO: Created: latency-svc-44px8
Jun  4 14:21:33.878: INFO: Got endpoints: latency-svc-t8428 [732.765816ms]
Jun  4 14:21:33.900: INFO: Created: latency-svc-jc5d2
Jun  4 14:21:33.925: INFO: Got endpoints: latency-svc-tp4jx [739.886511ms]
Jun  4 14:21:33.973: INFO: Created: latency-svc-xlsrr
Jun  4 14:21:33.975: INFO: Got endpoints: latency-svc-kvkkh [696.698358ms]
Jun  4 14:21:34.037: INFO: Got endpoints: latency-svc-kgtdh [757.8794ms]
Jun  4 14:21:34.038: INFO: Created: latency-svc-sw5dh
Jun  4 14:21:34.206: INFO: Got endpoints: latency-svc-xllxb [786.942316ms]
Jun  4 14:21:34.209: INFO: Got endpoints: latency-svc-mj5zh [884.933902ms]
Jun  4 14:21:34.210: INFO: Got endpoints: latency-svc-mn5sm [834.052474ms]
Jun  4 14:21:34.210: INFO: Created: latency-svc-2nk58
Jun  4 14:21:34.219: INFO: Got endpoints: latency-svc-225dz [744.159452ms]
Jun  4 14:21:34.296: INFO: Got endpoints: latency-svc-wv9nn [703.170632ms]
Jun  4 14:21:34.303: INFO: Created: latency-svc-vszdn
Jun  4 14:21:34.437: INFO: Created: latency-svc-rxg7s
Jun  4 14:21:34.438: INFO: Created: latency-svc-2ww29
Jun  4 14:21:34.438: INFO: Got endpoints: latency-svc-57db4 [699.822946ms]
Jun  4 14:21:34.438: INFO: Got endpoints: latency-svc-wlh57 [844.339098ms]
Jun  4 14:21:34.439: INFO: Got endpoints: latency-svc-x55t2 [813.835733ms]
Jun  4 14:21:34.484: INFO: Created: latency-svc-c6t4f
Jun  4 14:21:34.539: INFO: Created: latency-svc-hqgk2
Jun  4 14:21:34.539: INFO: Created: latency-svc-cwcg2
Jun  4 14:21:34.540: INFO: Created: latency-svc-dgdrt
Jun  4 14:21:34.540: INFO: Created: latency-svc-grkxk
Jun  4 14:21:34.540: INFO: Got endpoints: latency-svc-44px8 [762.480818ms]
Jun  4 14:21:34.540: INFO: Got endpoints: latency-svc-t44wf [801.087915ms]
Jun  4 14:21:34.576: INFO: Got endpoints: latency-svc-zlpf8 [738.686544ms]
Jun  4 14:21:34.577: INFO: Created: latency-svc-9jlbn
Jun  4 14:21:34.637: INFO: Got endpoints: latency-svc-jc5d2 [758.347935ms]
Jun  4 14:21:34.638: INFO: Created: latency-svc-jkz6g
Jun  4 14:21:34.672: INFO: Got endpoints: latency-svc-xlsrr [747.498877ms]
Jun  4 14:21:34.683: INFO: Created: latency-svc-fch78
Jun  4 14:21:34.691: INFO: Created: latency-svc-2hcpc
Jun  4 14:21:34.703: INFO: Created: latency-svc-84qxr
Jun  4 14:21:34.721: INFO: Got endpoints: latency-svc-sw5dh [744.871893ms]
Jun  4 14:21:35.111: INFO: Created: latency-svc-98wrq
Jun  4 14:21:35.139: INFO: Got endpoints: latency-svc-grkxk [700.21261ms]
Jun  4 14:21:35.140: INFO: Got endpoints: latency-svc-2nk58 [1.10166616s]
Jun  4 14:21:35.140: INFO: Got endpoints: latency-svc-vszdn [934.212755ms]
Jun  4 14:21:35.141: INFO: Got endpoints: latency-svc-2ww29 [930.929837ms]
Jun  4 14:21:35.141: INFO: Got endpoints: latency-svc-rxg7s [931.013242ms]
Jun  4 14:21:35.142: INFO: Got endpoints: latency-svc-c6t4f [922.992841ms]
Jun  4 14:21:35.142: INFO: Got endpoints: latency-svc-cwcg2 [845.037346ms]
Jun  4 14:21:35.142: INFO: Got endpoints: latency-svc-dgdrt [703.814651ms]
Jun  4 14:21:35.173: INFO: Created: latency-svc-hkvhz
Jun  4 14:21:35.173: INFO: Created: latency-svc-hrvp8
Jun  4 14:21:35.286: INFO: Got endpoints: latency-svc-hqgk2 [847.199257ms]
Jun  4 14:21:35.289: INFO: Got endpoints: latency-svc-jkz6g [747.958371ms]
Jun  4 14:21:35.290: INFO: Got endpoints: latency-svc-9jlbn [749.395959ms]
Jun  4 14:21:35.293: INFO: Created: latency-svc-vpms2
Jun  4 14:21:35.300: INFO: Created: latency-svc-b8jql
Jun  4 14:21:35.308: INFO: Created: latency-svc-pk4ls
Jun  4 14:21:35.313: INFO: Created: latency-svc-j4nfw
Jun  4 14:21:35.323: INFO: Got endpoints: latency-svc-fch78 [746.111386ms]
Jun  4 14:21:35.326: INFO: Created: latency-svc-5sdj5
Jun  4 14:21:35.337: INFO: Created: latency-svc-zks6m
Jun  4 14:21:35.365: INFO: Created: latency-svc-mk8l8
Jun  4 14:21:35.378: INFO: Got endpoints: latency-svc-2hcpc [740.610766ms]
Jun  4 14:21:35.379: INFO: Created: latency-svc-n5svc
Jun  4 14:21:35.419: INFO: Got endpoints: latency-svc-84qxr [746.439341ms]
Jun  4 14:21:35.421: INFO: Created: latency-svc-lf4bp
Jun  4 14:21:35.426: INFO: Created: latency-svc-ppz2s
Jun  4 14:21:35.433: INFO: Created: latency-svc-978ks
Jun  4 14:21:35.444: INFO: Created: latency-svc-xgtzt
Jun  4 14:21:35.475: INFO: Got endpoints: latency-svc-98wrq [754.316258ms]
Jun  4 14:21:35.503: INFO: Created: latency-svc-k7qsr
Jun  4 14:21:35.520: INFO: Got endpoints: latency-svc-hkvhz [380.923425ms]
Jun  4 14:21:35.546: INFO: Created: latency-svc-c57br
Jun  4 14:21:35.574: INFO: Got endpoints: latency-svc-hrvp8 [434.414237ms]
Jun  4 14:21:35.630: INFO: Got endpoints: latency-svc-vpms2 [486.405115ms]
Jun  4 14:21:35.637: INFO: Created: latency-svc-rdk2x
Jun  4 14:21:35.679: INFO: Got endpoints: latency-svc-b8jql [537.568979ms]
Jun  4 14:21:35.731: INFO: Created: latency-svc-wtqqq
Jun  4 14:21:35.731: INFO: Got endpoints: latency-svc-pk4ls [588.24634ms]
Jun  4 14:21:35.864: INFO: Got endpoints: latency-svc-5sdj5 [723.92403ms]
Jun  4 14:21:35.877: INFO: Got endpoints: latency-svc-j4nfw [734.241593ms]
Jun  4 14:21:35.877: INFO: Created: latency-svc-5nkm6
Jun  4 14:21:35.878: INFO: Created: latency-svc-rkm95
Jun  4 14:21:35.878: INFO: Got endpoints: latency-svc-zks6m [736.244307ms]
Jun  4 14:21:35.887: INFO: Created: latency-svc-pnx6w
Jun  4 14:21:35.896: INFO: Created: latency-svc-66wwr
Jun  4 14:21:35.902: INFO: Created: latency-svc-gj8hr
Jun  4 14:21:35.918: INFO: Got endpoints: latency-svc-mk8l8 [631.769522ms]
Jun  4 14:21:35.976: INFO: Got endpoints: latency-svc-n5svc [685.893738ms]
Jun  4 14:21:35.978: INFO: Created: latency-svc-rjb8l
Jun  4 14:21:36.007: INFO: Created: latency-svc-cnfhc
Jun  4 14:21:36.026: INFO: Got endpoints: latency-svc-lf4bp [736.03942ms]
Jun  4 14:21:36.076: INFO: Got endpoints: latency-svc-ppz2s [752.725251ms]
Jun  4 14:21:36.077: INFO: Created: latency-svc-rh99f
Jun  4 14:21:36.089: INFO: Created: latency-svc-xhfjv
Jun  4 14:21:36.123: INFO: Got endpoints: latency-svc-978ks [744.752186ms]
Jun  4 14:21:36.175: INFO: Created: latency-svc-q889b
Jun  4 14:21:36.195: INFO: Got endpoints: latency-svc-xgtzt [775.136738ms]
Jun  4 14:21:36.207: INFO: Created: latency-svc-74xzw
Jun  4 14:21:36.219: INFO: Got endpoints: latency-svc-k7qsr [743.485778ms]
Jun  4 14:21:36.276: INFO: Got endpoints: latency-svc-c57br [755.561132ms]
Jun  4 14:21:36.277: INFO: Created: latency-svc-lnkxb
Jun  4 14:21:36.289: INFO: Created: latency-svc-ztpml
Jun  4 14:21:36.320: INFO: Got endpoints: latency-svc-rdk2x [745.727718ms]
Jun  4 14:21:36.331: INFO: Created: latency-svc-kxq9g
Jun  4 14:21:36.377: INFO: Got endpoints: latency-svc-wtqqq [746.821895ms]
Jun  4 14:21:36.387: INFO: Created: latency-svc-nhdb8
Jun  4 14:21:36.419: INFO: Got endpoints: latency-svc-rkm95 [740.102863ms]
Jun  4 14:21:36.431: INFO: Created: latency-svc-szq8r
Jun  4 14:21:36.471: INFO: Got endpoints: latency-svc-5nkm6 [740.10152ms]
Jun  4 14:21:36.515: INFO: Created: latency-svc-t5ddg
Jun  4 14:21:36.520: INFO: Got endpoints: latency-svc-pnx6w [643.873109ms]
Jun  4 14:21:36.575: INFO: Got endpoints: latency-svc-66wwr [697.93283ms]
Jun  4 14:21:36.576: INFO: Created: latency-svc-wjmpv
Jun  4 14:21:36.738: INFO: Created: latency-svc-js9sp
Jun  4 14:21:36.738: INFO: Got endpoints: latency-svc-cnfhc [760.251006ms]
Jun  4 14:21:36.739: INFO: Got endpoints: latency-svc-gj8hr [860.184944ms]
Jun  4 14:21:36.739: INFO: Got endpoints: latency-svc-rjb8l [820.735692ms]
Jun  4 14:21:36.777: INFO: Got endpoints: latency-svc-rh99f [750.866934ms]
Jun  4 14:21:36.783: INFO: Created: latency-svc-pl2qj
Jun  4 14:21:36.795: INFO: Created: latency-svc-l626b
Jun  4 14:21:36.804: INFO: Created: latency-svc-j5rrm
Jun  4 14:21:36.881: INFO: Got endpoints: latency-svc-q889b [757.566998ms]
Jun  4 14:21:36.882: INFO: Got endpoints: latency-svc-xhfjv [805.679247ms]
Jun  4 14:21:36.886: INFO: Created: latency-svc-zmvx9
Jun  4 14:21:36.893: INFO: Created: latency-svc-4prjz
Jun  4 14:21:36.898: INFO: Created: latency-svc-5b6s9
Jun  4 14:21:36.937: INFO: Got endpoints: latency-svc-74xzw [741.412583ms]
Jun  4 14:21:36.974: INFO: Got endpoints: latency-svc-lnkxb [754.677211ms]
Jun  4 14:21:36.975: INFO: Created: latency-svc-nvpbs
Jun  4 14:21:37.001: INFO: Created: latency-svc-g8p2x
Jun  4 14:21:37.025: INFO: Got endpoints: latency-svc-ztpml [748.431173ms]
Jun  4 14:21:37.038: INFO: Created: latency-svc-twfwc
Jun  4 14:21:37.079: INFO: Got endpoints: latency-svc-kxq9g [758.657341ms]
Jun  4 14:21:37.093: INFO: Created: latency-svc-2gpjp
Jun  4 14:21:37.120: INFO: Got endpoints: latency-svc-nhdb8 [742.592931ms]
Jun  4 14:21:37.137: INFO: Created: latency-svc-7fkdz
Jun  4 14:21:37.186: INFO: Got endpoints: latency-svc-szq8r [766.026156ms]
Jun  4 14:21:37.298: INFO: Got endpoints: latency-svc-wjmpv [778.42199ms]
Jun  4 14:21:37.300: INFO: Got endpoints: latency-svc-t5ddg [828.27375ms]
Jun  4 14:21:37.337: INFO: Created: latency-svc-vmgj9
Jun  4 14:21:37.337: INFO: Created: latency-svc-smxl7
Jun  4 14:21:37.338: INFO: Got endpoints: latency-svc-js9sp [762.44408ms]
Jun  4 14:21:37.375: INFO: Created: latency-svc-qndvh
Jun  4 14:21:37.376: INFO: Created: latency-svc-zhvbl
Jun  4 14:21:37.379: INFO: Got endpoints: latency-svc-pl2qj [640.338278ms]
Jun  4 14:21:37.482: INFO: Created: latency-svc-qrhfn
Jun  4 14:21:37.484: INFO: Got endpoints: latency-svc-l626b [745.158019ms]
Jun  4 14:21:37.485: INFO: Got endpoints: latency-svc-j5rrm [745.214996ms]
Jun  4 14:21:37.516: INFO: Created: latency-svc-h8f59
Jun  4 14:21:37.520: INFO: Got endpoints: latency-svc-zmvx9 [742.891845ms]
Jun  4 14:21:37.531: INFO: Created: latency-svc-mcj2f
Jun  4 14:21:37.540: INFO: Created: latency-svc-s7bpj
Jun  4 14:21:37.574: INFO: Got endpoints: latency-svc-4prjz [693.257125ms]
Jun  4 14:21:37.675: INFO: Got endpoints: latency-svc-5b6s9 [792.699309ms]
Jun  4 14:21:37.675: INFO: Got endpoints: latency-svc-nvpbs [738.10661ms]
Jun  4 14:21:37.677: INFO: Created: latency-svc-fvd9q
Jun  4 14:21:37.691: INFO: Created: latency-svc-vns9c
Jun  4 14:21:37.694: INFO: Created: latency-svc-w4nxx
Jun  4 14:21:37.721: INFO: Got endpoints: latency-svc-g8p2x [745.974213ms]
Jun  4 14:21:37.733: INFO: Created: latency-svc-r9k9j
Jun  4 14:21:37.776: INFO: Got endpoints: latency-svc-twfwc [751.570808ms]
Jun  4 14:21:37.789: INFO: Created: latency-svc-67pkd
Jun  4 14:21:37.819: INFO: Got endpoints: latency-svc-2gpjp [739.435523ms]
Jun  4 14:21:37.831: INFO: Created: latency-svc-5dh5r
Jun  4 14:21:37.874: INFO: Got endpoints: latency-svc-7fkdz [753.308542ms]
Jun  4 14:21:37.889: INFO: Created: latency-svc-mql8l
Jun  4 14:21:37.920: INFO: Got endpoints: latency-svc-smxl7 [733.464185ms]
Jun  4 14:21:37.935: INFO: Created: latency-svc-gr2nw
Jun  4 14:21:38.038: INFO: Got endpoints: latency-svc-zhvbl [737.427944ms]
Jun  4 14:21:38.039: INFO: Got endpoints: latency-svc-vmgj9 [739.677043ms]
Jun  4 14:21:38.080: INFO: Created: latency-svc-9bp2f
Jun  4 14:21:38.081: INFO: Created: latency-svc-9zm2r
Jun  4 14:21:38.081: INFO: Got endpoints: latency-svc-qndvh [743.278212ms]
Jun  4 14:21:38.278: INFO: Got endpoints: latency-svc-mcj2f [792.59588ms]
Jun  4 14:21:38.279: INFO: Got endpoints: latency-svc-qrhfn [900.025081ms]
Jun  4 14:21:38.279: INFO: Got endpoints: latency-svc-h8f59 [795.03997ms]
Jun  4 14:21:38.286: INFO: Got endpoints: latency-svc-s7bpj [764.89707ms]
Jun  4 14:21:38.304: INFO: Created: latency-svc-xjr9r
Jun  4 14:21:38.410: INFO: Got endpoints: latency-svc-vns9c [734.952144ms]
Jun  4 14:21:38.411: INFO: Got endpoints: latency-svc-fvd9q [836.245205ms]
Jun  4 14:21:38.416: INFO: Created: latency-svc-z4t4l
Jun  4 14:21:38.513: INFO: Got endpoints: latency-svc-r9k9j [791.980561ms]
Jun  4 14:21:38.513: INFO: Got endpoints: latency-svc-w4nxx [837.362014ms]
Jun  4 14:21:38.518: INFO: Got endpoints: latency-svc-67pkd [741.589966ms]
Jun  4 14:21:38.522: INFO: Created: latency-svc-ghtmh
Jun  4 14:21:38.528: INFO: Created: latency-svc-6w5bx
Jun  4 14:21:38.534: INFO: Created: latency-svc-5d29h
Jun  4 14:21:38.569: INFO: Got endpoints: latency-svc-5dh5r [748.700799ms]
Jun  4 14:21:38.569: INFO: Created: latency-svc-zpvpf
Jun  4 14:21:38.622: INFO: Got endpoints: latency-svc-mql8l [748.378616ms]
Jun  4 14:21:38.695: INFO: Got endpoints: latency-svc-gr2nw [775.390641ms]
Jun  4 14:21:38.718: INFO: Got endpoints: latency-svc-9zm2r [679.85666ms]
Jun  4 14:21:38.784: INFO: Got endpoints: latency-svc-9bp2f [744.692659ms]
Jun  4 14:21:38.822: INFO: Got endpoints: latency-svc-xjr9r [740.611717ms]
Jun  4 14:21:38.938: INFO: Got endpoints: latency-svc-ghtmh [658.644864ms]
Jun  4 14:21:38.938: INFO: Got endpoints: latency-svc-z4t4l [659.784068ms]
Jun  4 14:21:39.038: INFO: Got endpoints: latency-svc-6w5bx [757.960179ms]
Jun  4 14:21:39.039: INFO: Got endpoints: latency-svc-5d29h [753.494093ms]
Jun  4 14:21:39.072: INFO: Got endpoints: latency-svc-zpvpf [661.678694ms]
Jun  4 14:21:39.072: INFO: Latencies: [58.185719ms 102.658623ms 102.66612ms 103.342691ms 103.779965ms 104.359321ms 137.427798ms 138.405718ms 139.233815ms 139.304423ms 192.338338ms 194.624343ms 195.078199ms 195.591201ms 195.891502ms 197.322486ms 197.746706ms 198.062288ms 242.538615ms 242.639834ms 297.719171ms 298.927788ms 300.664558ms 301.846843ms 323.005229ms 335.530722ms 344.537395ms 345.171045ms 358.566653ms 360.015603ms 360.726929ms 379.565378ms 380.923425ms 392.221808ms 396.817621ms 402.963648ms 404.561717ms 425.016907ms 433.601641ms 434.414237ms 435.291342ms 437.507812ms 440.596843ms 447.073991ms 452.740914ms 459.33542ms 460.093553ms 464.387787ms 468.789831ms 472.957795ms 477.916701ms 480.516734ms 486.405115ms 497.688341ms 499.104029ms 499.776116ms 517.470808ms 522.792865ms 535.961923ms 537.568979ms 540.886442ms 541.981427ms 552.902464ms 553.562797ms 554.96031ms 562.437218ms 588.24634ms 598.888487ms 599.316811ms 599.929724ms 602.716334ms 603.017408ms 603.587074ms 607.584656ms 629.32475ms 631.370339ms 631.769522ms 635.950278ms 639.672372ms 640.338278ms 640.7991ms 643.873109ms 658.008281ms 658.222798ms 658.644864ms 659.784068ms 661.678694ms 679.753472ms 679.85666ms 685.893738ms 690.974336ms 693.257125ms 696.698358ms 697.751793ms 697.93283ms 699.822946ms 700.174615ms 700.21261ms 700.271869ms 700.542552ms 703.170632ms 703.814651ms 704.18532ms 723.92403ms 732.765816ms 733.464185ms 734.241593ms 734.952144ms 736.03942ms 736.244307ms 737.427944ms 738.10661ms 738.686544ms 739.435523ms 739.677043ms 739.886511ms 740.10152ms 740.102863ms 740.610766ms 740.611717ms 741.363175ms 741.412583ms 741.589966ms 742.592931ms 742.891845ms 743.278212ms 743.485778ms 744.159452ms 744.24527ms 744.692659ms 744.752186ms 744.843137ms 744.871893ms 745.158019ms 745.214996ms 745.727718ms 745.974213ms 746.111386ms 746.439341ms 746.821895ms 747.498877ms 747.958371ms 748.378616ms 748.431173ms 748.700799ms 749.395959ms 749.865928ms 750.866934ms 751.570808ms 752.725251ms 753.308542ms 753.494093ms 754.244399ms 754.261547ms 754.316258ms 754.677211ms 754.976159ms 755.561132ms 755.802793ms 757.237873ms 757.566998ms 757.8794ms 757.960179ms 758.347935ms 758.657341ms 760.251006ms 760.264132ms 762.44408ms 762.480818ms 764.89707ms 766.026156ms 775.136738ms 775.390641ms 778.42199ms 786.942316ms 791.980561ms 792.59588ms 792.699309ms 795.03997ms 801.087915ms 802.301539ms 805.679247ms 813.835733ms 819.186801ms 820.735692ms 828.27375ms 834.052474ms 836.245205ms 837.362014ms 844.339098ms 845.037346ms 847.199257ms 860.184944ms 884.933902ms 900.025081ms 922.992841ms 930.929837ms 931.013242ms 934.212755ms 1.10166616s]
Jun  4 14:21:39.073: INFO: 50 %ile: 703.170632ms
Jun  4 14:21:39.073: INFO: 90 %ile: 802.301539ms
Jun  4 14:21:39.073: INFO: 99 %ile: 934.212755ms
Jun  4 14:21:39.073: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:21:39.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-74n9n" for this suite.
Jun  4 14:22:09.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:22:09.353: INFO: namespace: e2e-tests-svc-latency-74n9n, resource: bindings, ignored listing per whitelist
Jun  4 14:22:09.552: INFO: namespace e2e-tests-svc-latency-74n9n deletion completed in 30.472808946s

• [SLOW TEST:43.620 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:22:09.559: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jun  4 14:22:10.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 --namespace=e2e-tests-kubectl-cz5r9 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jun  4 14:22:13.842: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jun  4 14:22:13.842: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:22:15.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cz5r9" for this suite.
Jun  4 14:22:21.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:22:22.085: INFO: namespace: e2e-tests-kubectl-cz5r9, resource: bindings, ignored listing per whitelist
Jun  4 14:22:22.383: INFO: namespace e2e-tests-kubectl-cz5r9 deletion completed in 6.420810948s

• [SLOW TEST:12.825 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:22:22.384: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-2b325a6a-86d4-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 14:22:22.765: INFO: Waiting up to 5m0s for pod "pod-configmaps-2b3476a7-86d4-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-rp6gh" to be "success or failure"
Jun  4 14:22:22.770: INFO: Pod "pod-configmaps-2b3476a7-86d4-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.415656ms
Jun  4 14:22:24.783: INFO: Pod "pod-configmaps-2b3476a7-86d4-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017616259s
Jun  4 14:22:26.846: INFO: Pod "pod-configmaps-2b3476a7-86d4-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.081040939s
STEP: Saw pod success
Jun  4 14:22:26.846: INFO: Pod "pod-configmaps-2b3476a7-86d4-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:22:26.865: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-2b3476a7-86d4-11e9-8620-ba945f56578b container configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 14:22:27.192: INFO: Waiting for pod pod-configmaps-2b3476a7-86d4-11e9-8620-ba945f56578b to disappear
Jun  4 14:22:27.200: INFO: Pod pod-configmaps-2b3476a7-86d4-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:22:27.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rp6gh" for this suite.
Jun  4 14:22:33.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:22:33.897: INFO: namespace: e2e-tests-configmap-rp6gh, resource: bindings, ignored listing per whitelist
Jun  4 14:22:33.912: INFO: namespace e2e-tests-configmap-rp6gh deletion completed in 6.704124995s

• [SLOW TEST:11.528 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:22:33.915: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun  4 14:22:36.916: INFO: Successfully updated pod "pod-update-321bdf1a-86d4-11e9-8620-ba945f56578b"
STEP: verifying the updated pod is in kubernetes
Jun  4 14:22:36.940: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:22:36.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-bxzkf" for this suite.
Jun  4 14:23:01.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:23:01.337: INFO: namespace: e2e-tests-pods-bxzkf, resource: bindings, ignored listing per whitelist
Jun  4 14:23:01.422: INFO: namespace e2e-tests-pods-bxzkf deletion completed in 24.431973437s

• [SLOW TEST:27.509 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:23:01.430: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-q6x68
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-q6x68
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-q6x68
Jun  4 14:23:02.146: INFO: Found 0 stateful pods, waiting for 1
Jun  4 14:23:12.156: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jun  4 14:23:12.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 14:23:12.964: INFO: stderr: ""
Jun  4 14:23:12.964: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 14:23:12.964: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 14:23:13.044: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun  4 14:23:23.064: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun  4 14:23:23.064: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 14:23:23.179: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999277s
Jun  4 14:23:24.186: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99090914s
Jun  4 14:23:25.193: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.983945793s
Jun  4 14:23:26.246: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.977594768s
Jun  4 14:23:27.265: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.924824525s
Jun  4 14:23:28.271: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.905321819s
Jun  4 14:23:29.345: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.899177979s
Jun  4 14:23:30.353: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.825039092s
Jun  4 14:23:31.447: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.817434113s
Jun  4 14:23:32.550: INFO: Verifying statefulset ss doesn't scale past 1 for another 723.264123ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-q6x68
Jun  4 14:23:33.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:23:34.529: INFO: stderr: ""
Jun  4 14:23:34.529: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun  4 14:23:34.529: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun  4 14:23:34.536: INFO: Found 1 stateful pods, waiting for 3
Jun  4 14:23:44.559: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 14:23:44.559: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 14:23:44.560: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jun  4 14:23:44.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 14:23:45.679: INFO: stderr: ""
Jun  4 14:23:45.679: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 14:23:45.679: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 14:23:45.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 14:23:46.795: INFO: stderr: ""
Jun  4 14:23:46.795: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 14:23:46.795: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 14:23:46.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jun  4 14:23:47.697: INFO: stderr: ""
Jun  4 14:23:47.697: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jun  4 14:23:47.697: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jun  4 14:23:47.697: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 14:23:47.702: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jun  4 14:23:57.719: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun  4 14:23:57.720: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun  4 14:23:57.720: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun  4 14:23:57.741: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999583s
Jun  4 14:23:58.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994283884s
Jun  4 14:23:59.768: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97590265s
Jun  4 14:24:00.776: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.967265637s
Jun  4 14:24:01.786: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.958941908s
Jun  4 14:24:02.808: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.948993681s
Jun  4 14:24:03.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.927140172s
Jun  4 14:24:04.825: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.917009239s
Jun  4 14:24:05.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.910630293s
Jun  4 14:24:06.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 903.371857ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-q6x68
Jun  4 14:24:07.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:24:08.794: INFO: stderr: ""
Jun  4 14:24:08.794: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun  4 14:24:08.794: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun  4 14:24:08.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:24:10.146: INFO: stderr: ""
Jun  4 14:24:10.146: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jun  4 14:24:10.146: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jun  4 14:24:10.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:24:11.101: INFO: rc: 1
Jun  4 14:24:11.101: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server: 
 [] <nil> 0xc000b38570 exit status 1 <nil> <nil> true [0xc001730200 0xc001730218 0xc001730230] [0xc001730200 0xc001730218 0xc001730230] [0xc001730210 0xc001730228] [0x92f8e0 0x92f8e0] 0xc003145320 <nil>}:
Command stdout:

stderr:
Error from server: 

error:
exit status 1

Jun  4 14:24:21.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:24:21.264: INFO: rc: 1
Jun  4 14:24:21.264: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b38ba0 exit status 1 <nil> <nil> true [0xc001730238 0xc001730250 0xc001730268] [0xc001730238 0xc001730250 0xc001730268] [0xc001730248 0xc001730260] [0x92f8e0 0x92f8e0] 0xc003145620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:24:31.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:24:31.393: INFO: rc: 1
Jun  4 14:24:31.393: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b38ff0 exit status 1 <nil> <nil> true [0xc001730270 0xc001730288 0xc0017302a0] [0xc001730270 0xc001730288 0xc0017302a0] [0xc001730280 0xc001730298] [0x92f8e0 0x92f8e0] 0xc003145920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:24:41.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:24:41.650: INFO: rc: 1
Jun  4 14:24:41.650: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b39740 exit status 1 <nil> <nil> true [0xc0017302a8 0xc0017302c0 0xc0017302e0] [0xc0017302a8 0xc0017302c0 0xc0017302e0] [0xc0017302b8 0xc0017302d0] [0x92f8e0 0x92f8e0] 0xc003145c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:24:51.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:24:52.037: INFO: rc: 1
Jun  4 14:24:52.037: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b39cb0 exit status 1 <nil> <nil> true [0xc0017302f0 0xc001730308 0xc001730320] [0xc0017302f0 0xc001730308 0xc001730320] [0xc001730300 0xc001730318] [0x92f8e0 0x92f8e0] 0xc003145f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:25:02.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:25:02.174: INFO: rc: 1
Jun  4 14:25:02.174: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019202d0 exit status 1 <nil> <nil> true [0xc001730328 0xc001730340 0xc001730370] [0xc001730328 0xc001730340 0xc001730370] [0xc001730338 0xc001730368] [0x92f8e0 0x92f8e0] 0xc0035362a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:25:12.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:25:12.465: INFO: rc: 1
Jun  4 14:25:12.465: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001920810 exit status 1 <nil> <nil> true [0xc001730378 0xc001730398 0xc0017303b0] [0xc001730378 0xc001730398 0xc0017303b0] [0xc001730388 0xc0017303a8] [0x92f8e0 0x92f8e0] 0xc0035365a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:25:22.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:25:22.651: INFO: rc: 1
Jun  4 14:25:22.651: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001920e40 exit status 1 <nil> <nil> true [0xc0017303c0 0xc0017303e0 0xc0017303f8] [0xc0017303c0 0xc0017303e0 0xc0017303f8] [0xc0017303d8 0xc0017303f0] [0x92f8e0 0x92f8e0] 0xc0035368a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:25:32.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:25:32.776: INFO: rc: 1
Jun  4 14:25:32.776: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001921290 exit status 1 <nil> <nil> true [0xc001730400 0xc001730418 0xc001730430] [0xc001730400 0xc001730418 0xc001730430] [0xc001730410 0xc001730428] [0x92f8e0 0x92f8e0] 0xc003536ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:25:42.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:25:42.944: INFO: rc: 1
Jun  4 14:25:42.944: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001921680 exit status 1 <nil> <nil> true [0xc001730438 0xc001730450 0xc001730468] [0xc001730438 0xc001730450 0xc001730468] [0xc001730448 0xc001730460] [0x92f8e0 0x92f8e0] 0xc003536f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:25:52.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:25:53.069: INFO: rc: 1
Jun  4 14:25:53.069: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001921a70 exit status 1 <nil> <nil> true [0xc001730470 0xc001730488 0xc0017304a0] [0xc001730470 0xc001730488 0xc0017304a0] [0xc001730480 0xc001730498] [0x92f8e0 0x92f8e0] 0xc0035374a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:26:03.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:26:03.238: INFO: rc: 1
Jun  4 14:26:03.238: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b38690 exit status 1 <nil> <nil> true [0xc001730008 0xc001730020 0xc001730038] [0xc001730008 0xc001730020 0xc001730038] [0xc001730018 0xc001730030] [0x92f8e0 0x92f8e0] 0xc0031442a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:26:13.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:26:13.425: INFO: rc: 1
Jun  4 14:26:13.425: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b38cf0 exit status 1 <nil> <nil> true [0xc001730040 0xc001730058 0xc001730070] [0xc001730040 0xc001730058 0xc001730070] [0xc001730050 0xc001730068] [0x92f8e0 0x92f8e0] 0xc003144660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:26:23.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:26:23.553: INFO: rc: 1
Jun  4 14:26:23.553: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b39290 exit status 1 <nil> <nil> true [0xc001730078 0xc001730090 0xc0017300a8] [0xc001730078 0xc001730090 0xc0017300a8] [0xc001730088 0xc0017300a0] [0x92f8e0 0x92f8e0] 0xc003144960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:26:33.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:26:33.829: INFO: rc: 1
Jun  4 14:26:33.829: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b39a40 exit status 1 <nil> <nil> true [0xc0017300b0 0xc0017300c8 0xc0017300e0] [0xc0017300b0 0xc0017300c8 0xc0017300e0] [0xc0017300c0 0xc0017300d8] [0x92f8e0 0x92f8e0] 0xc003144d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:26:43.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:26:44.007: INFO: rc: 1
Jun  4 14:26:44.007: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b39f80 exit status 1 <nil> <nil> true [0xc0017300e8 0xc001730100 0xc001730118] [0xc0017300e8 0xc001730100 0xc001730118] [0xc0017300f8 0xc001730110] [0x92f8e0 0x92f8e0] 0xc003145080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:26:54.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:26:54.208: INFO: rc: 1
Jun  4 14:26:54.208: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4a480 exit status 1 <nil> <nil> true [0xc001730120 0xc001730138 0xc001730150] [0xc001730120 0xc001730138 0xc001730150] [0xc001730130 0xc001730148] [0x92f8e0 0x92f8e0] 0xc003145380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:27:04.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:27:04.443: INFO: rc: 1
Jun  4 14:27:04.443: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4aba0 exit status 1 <nil> <nil> true [0xc001730158 0xc001730170 0xc001730188] [0xc001730158 0xc001730170 0xc001730188] [0xc001730168 0xc001730180] [0x92f8e0 0x92f8e0] 0xc003145680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:27:14.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:27:14.565: INFO: rc: 1
Jun  4 14:27:14.565: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4b680 exit status 1 <nil> <nil> true [0xc001730190 0xc0017301a8 0xc0017301c0] [0xc001730190 0xc0017301a8 0xc0017301c0] [0xc0017301a0 0xc0017301b8] [0x92f8e0 0x92f8e0] 0xc003145980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:27:24.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:27:24.853: INFO: rc: 1
Jun  4 14:27:24.853: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4bb90 exit status 1 <nil> <nil> true [0xc0017301c8 0xc0017301e0 0xc0017301f8] [0xc0017301c8 0xc0017301e0 0xc0017301f8] [0xc0017301d8 0xc0017301f0] [0x92f8e0 0x92f8e0] 0xc003145c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:27:34.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:27:35.006: INFO: rc: 1
Jun  4 14:27:35.006: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4bfb0 exit status 1 <nil> <nil> true [0xc001730200 0xc001730218 0xc001730230] [0xc001730200 0xc001730218 0xc001730230] [0xc001730210 0xc001730228] [0x92f8e0 0x92f8e0] 0xc003145f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:27:45.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:27:45.225: INFO: rc: 1
Jun  4 14:27:45.226: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014b23c0 exit status 1 <nil> <nil> true [0xc001730238 0xc001730250 0xc001730268] [0xc001730238 0xc001730250 0xc001730268] [0xc001730248 0xc001730260] [0x92f8e0 0x92f8e0] 0xc001334840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:27:55.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:27:55.425: INFO: rc: 1
Jun  4 14:27:55.425: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0014b2900 exit status 1 <nil> <nil> true [0xc001730270 0xc001730288 0xc0017302a0] [0xc001730270 0xc001730288 0xc0017302a0] [0xc001730280 0xc001730298] [0x92f8e0 0x92f8e0] 0xc001335200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:28:05.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:28:05.551: INFO: rc: 1
Jun  4 14:28:05.551: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4a510 exit status 1 <nil> <nil> true [0xc001730008 0xc001730020 0xc001730038] [0xc001730008 0xc001730020 0xc001730038] [0xc001730018 0xc001730030] [0x92f8e0 0x92f8e0] 0xc0031442a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:28:15.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:28:15.759: INFO: rc: 1
Jun  4 14:28:15.759: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4ae10 exit status 1 <nil> <nil> true [0xc001730040 0xc001730058 0xc001730070] [0xc001730040 0xc001730058 0xc001730070] [0xc001730050 0xc001730068] [0x92f8e0 0x92f8e0] 0xc003144660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:28:25.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:28:25.888: INFO: rc: 1
Jun  4 14:28:25.888: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4b740 exit status 1 <nil> <nil> true [0xc001730078 0xc001730090 0xc0017300a8] [0xc001730078 0xc001730090 0xc0017300a8] [0xc001730088 0xc0017300a0] [0x92f8e0 0x92f8e0] 0xc003144960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:28:35.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:28:36.023: INFO: rc: 1
Jun  4 14:28:36.023: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001a4bc50 exit status 1 <nil> <nil> true [0xc0017300b0 0xc0017300c8 0xc0017300e0] [0xc0017300b0 0xc0017300c8 0xc0017300e0] [0xc0017300c0 0xc0017300d8] [0x92f8e0 0x92f8e0] 0xc003144d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:28:46.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:28:46.193: INFO: rc: 1
Jun  4 14:28:46.193: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b38090 exit status 1 <nil> <nil> true [0xc0017300e8 0xc001730100 0xc001730118] [0xc0017300e8 0xc001730100 0xc001730118] [0xc0017300f8 0xc001730110] [0x92f8e0 0x92f8e0] 0xc003145080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:28:56.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:28:56.318: INFO: rc: 1
Jun  4 14:28:56.318: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b38750 exit status 1 <nil> <nil> true [0xc001730120 0xc001730138 0xc001730150] [0xc001730120 0xc001730138 0xc001730150] [0xc001730130 0xc001730148] [0x92f8e0 0x92f8e0] 0xc003145380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:29:06.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:29:06.452: INFO: rc: 1
Jun  4 14:29:06.452: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000b38db0 exit status 1 <nil> <nil> true [0xc001730158 0xc001730170 0xc001730188] [0xc001730158 0xc001730170 0xc001730188] [0xc001730168 0xc001730180] [0x92f8e0 0x92f8e0] 0xc003145680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Jun  4 14:29:16.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 exec --namespace=e2e-tests-statefulset-q6x68 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jun  4 14:29:16.887: INFO: rc: 1
Jun  4 14:29:16.887: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Jun  4 14:29:16.887: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun  4 14:29:16.940: INFO: Deleting all statefulset in ns e2e-tests-statefulset-q6x68
Jun  4 14:29:17.038: INFO: Scaling statefulset ss to 0
Jun  4 14:29:17.059: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 14:29:17.064: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:29:17.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-q6x68" for this suite.
Jun  4 14:29:25.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:29:25.484: INFO: namespace: e2e-tests-statefulset-q6x68, resource: bindings, ignored listing per whitelist
Jun  4 14:29:25.851: INFO: namespace e2e-tests-statefulset-q6x68 deletion completed in 8.513528642s

• [SLOW TEST:384.422 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:29:25.857: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-bmxn7
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jun  4 14:29:26.487: INFO: Found 0 stateful pods, waiting for 3
Jun  4 14:29:36.514: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 14:29:36.514: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 14:29:36.514: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jun  4 14:29:36.606: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jun  4 14:29:36.996: INFO: Updating stateful set ss2
Jun  4 14:29:37.050: INFO: Waiting for Pod e2e-tests-statefulset-bmxn7/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jun  4 14:29:47.688: INFO: Found 2 stateful pods, waiting for 3
Jun  4 14:29:57.742: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 14:29:57.742: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun  4 14:29:57.742: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jun  4 14:29:57.862: INFO: Updating stateful set ss2
Jun  4 14:29:57.879: INFO: Waiting for Pod e2e-tests-statefulset-bmxn7/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jun  4 14:30:07.957: INFO: Updating stateful set ss2
Jun  4 14:30:07.973: INFO: Waiting for StatefulSet e2e-tests-statefulset-bmxn7/ss2 to complete update
Jun  4 14:30:07.973: INFO: Waiting for Pod e2e-tests-statefulset-bmxn7/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun  4 14:30:18.023: INFO: Deleting all statefulset in ns e2e-tests-statefulset-bmxn7
Jun  4 14:30:18.031: INFO: Scaling statefulset ss2 to 0
Jun  4 14:30:48.341: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 14:30:48.347: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:30:48.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-bmxn7" for this suite.
Jun  4 14:30:56.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:30:57.055: INFO: namespace: e2e-tests-statefulset-bmxn7, resource: bindings, ignored listing per whitelist
Jun  4 14:30:57.089: INFO: namespace e2e-tests-statefulset-bmxn7 deletion completed in 8.641301151s

• [SLOW TEST:91.233 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:30:57.097: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:30:57.442: INFO: Creating deployment "nginx-deployment"
Jun  4 14:30:57.450: INFO: Waiting for observed generation 1
Jun  4 14:30:59.461: INFO: Waiting for all required pods to come up
Jun  4 14:30:59.470: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jun  4 14:31:03.739: INFO: Waiting for deployment "nginx-deployment" to complete
Jun  4 14:31:03.750: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jun  4 14:31:03.769: INFO: Updating deployment nginx-deployment
Jun  4 14:31:03.769: INFO: Waiting for observed generation 2
Jun  4 14:31:05.781: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jun  4 14:31:05.836: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jun  4 14:31:05.841: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jun  4 14:31:05.856: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jun  4 14:31:05.857: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jun  4 14:31:05.861: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jun  4 14:31:05.869: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jun  4 14:31:05.870: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jun  4 14:31:05.881: INFO: Updating deployment nginx-deployment
Jun  4 14:31:05.881: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jun  4 14:31:05.898: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jun  4 14:31:07.937: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun  4 14:31:07.953: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wwpjq/deployments/nginx-deployment,UID:5dfbef5e-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31171,Generation:3,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-06-04 14:31:05 +0000 UTC 2019-06-04 14:31:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-06-04 14:31:05 +0000 UTC 2019-06-04 14:30:57 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Jun  4 14:31:08.043: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wwpjq/replicasets/nginx-deployment-65bbdb5f8,UID:61c12bfb-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31166,Generation:3,CreationTimestamp:2019-06-04 14:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 5dfbef5e-86d5-11e9-9957-a6a8fec88741 0xc003e51d97 0xc003e51d98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun  4 14:31:08.043: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jun  4 14:31:08.043: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wwpjq/replicasets/nginx-deployment-555b55d965,UID:5dfe592d-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31144,Generation:3,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 5dfbef5e-86d5-11e9-9957-a6a8fec88741 0xc003e51cd7 0xc003e51cd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Jun  4 14:31:08.058: INFO: Pod "nginx-deployment-555b55d965-cps4r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cps4r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-cps4r,UID:5e045974-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31025,Generation:0,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc000bbb2d7 0xc000bbb2d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bbb340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bbb360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:172.25.1.184,StartTime:2019-06-04 14:30:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-04 14:31:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://890cd2442da53c496bede618654e1796843919e7b9f75ebed6049ca9d1562819}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.064: INFO: Pod "nginx-deployment-555b55d965-d29ms" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-d29ms,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-d29ms,UID:630550d0-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31220,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc000bbb4f7 0xc000bbb4f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bbb750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bbb770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.065: INFO: Pod "nginx-deployment-555b55d965-fdcqm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-fdcqm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-fdcqm,UID:5e044a0b-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31034,Generation:0,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc000bbb827 0xc000bbb828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bbb890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bbb910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:172.25.2.47,StartTime:2019-06-04 14:30:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-04 14:31:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://20ed237c38a054e0799da64fef12553d6a052fe2919ef9e40f3418fc206ce13e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.065: INFO: Pod "nginx-deployment-555b55d965-g4mnj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g4mnj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-g4mnj,UID:5e05f24d-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31005,Generation:0,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc000bbb9d0 0xc000bbb9d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bbba30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bbba50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:172.25.2.46,StartTime:2019-06-04 14:30:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-04 14:31:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://18f0a3b9d23c5ee10dd972abeb8fd0dce6aa0033b64cf619ecc361c9bfa6c61d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.067: INFO: Pod "nginx-deployment-555b55d965-gv8rv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gv8rv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-gv8rv,UID:63046069-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31198,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc000bbbb50 0xc000bbbb51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bbbbb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bbbbd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:,StartTime:2019-06-04 14:31:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.068: INFO: Pod "nginx-deployment-555b55d965-hnp9s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hnp9s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-hnp9s,UID:6306d215-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31225,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc000bbbcc7 0xc000bbbcc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bbbd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bbbd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.068: INFO: Pod "nginx-deployment-555b55d965-k7qn2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k7qn2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-k7qn2,UID:6309bc25-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31178,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc000bbbe07 0xc000bbbe08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000bbbec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000bbbef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:,StartTime:2019-06-04 14:31:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.072: INFO: Pod "nginx-deployment-555b55d965-kbj57" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kbj57,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-kbj57,UID:63071116-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31222,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc000bbbfa7 0xc000bbbfa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b96030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b96060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.072: INFO: Pod "nginx-deployment-555b55d965-ksxcr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-ksxcr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-ksxcr,UID:6306c133-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31159,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001b96117 0xc001b96118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b961a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b961c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.072: INFO: Pod "nginx-deployment-555b55d965-l4d8p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-l4d8p,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-l4d8p,UID:6305833a-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31197,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001b96260 0xc001b96261}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b962e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b96300}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.072: INFO: Pod "nginx-deployment-555b55d965-lxjt9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-lxjt9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-lxjt9,UID:5e0212d2-86d5-11e9-9957-a6a8fec88741,ResourceVersion:30998,Generation:0,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001b963f7 0xc001b963f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b96460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b96480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:172.25.1.182,StartTime:2019-06-04 14:30:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-04 14:31:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b673345406284f1f7924fd885c0e079ce571b27839cef4fbd0afc72f004e1742}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.073: INFO: Pod "nginx-deployment-555b55d965-nv9st" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nv9st,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-nv9st,UID:63093b6a-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31234,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001b96557 0xc001b96558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b965d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b965f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.076: INFO: Pod "nginx-deployment-555b55d965-q95vl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q95vl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-q95vl,UID:5e02d509-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31042,Generation:0,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001b96af7 0xc001b96af8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b96b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b96b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:172.25.0.55,StartTime:2019-06-04 14:30:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-04 14:31:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://894a60095e918152de07493eda3c18e5bc7f56981f8feb98b9308bb2ebd2f0a2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.079: INFO: Pod "nginx-deployment-555b55d965-qfmsl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qfmsl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-qfmsl,UID:630970c0-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31208,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001b96ee0 0xc001b96ee1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001236270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001236290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.082: INFO: Pod "nginx-deployment-555b55d965-sj8kf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-sj8kf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-sj8kf,UID:5e02be37-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31001,Generation:0,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001236347 0xc001236348}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012363b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001236410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:172.25.2.45,StartTime:2019-06-04 14:30:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-04 14:31:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3a42dd309ad3fbe7b256199107f04355cadcc395ba573a67e4ddf85c902d129b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.082: INFO: Pod "nginx-deployment-555b55d965-tlqq6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tlqq6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-tlqq6,UID:63096345-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31192,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001236550 0xc001236551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012365b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0012365d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.082: INFO: Pod "nginx-deployment-555b55d965-tmc4t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tmc4t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-tmc4t,UID:5e064676-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31015,Generation:0,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001236707 0xc001236708}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001236770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001236790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:172.25.0.52,StartTime:2019-06-04 14:30:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-04 14:31:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9f8592a4a90eaa8a3cd8c0ae28603c01af312f11d8e724ca9b96fa2a324cd1a9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.082: INFO: Pod "nginx-deployment-555b55d965-vgrrf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-vgrrf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-vgrrf,UID:5e047398-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31039,Generation:0,CreationTimestamp:2019-06-04 14:30:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001236850 0xc001236851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001236bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001236bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:30:57 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:172.25.0.54,StartTime:2019-06-04 14:30:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-06-04 14:31:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2ee0b05f503611317e7c1ad6e613750eb9948cff0db46864e167b55acdc938b1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.083: INFO: Pod "nginx-deployment-555b55d965-wd68b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wd68b,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-wd68b,UID:63094cc2-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31201,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001236c90 0xc001236c91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001236cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001236d10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.083: INFO: Pod "nginx-deployment-555b55d965-wqhtt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wqhtt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-555b55d965-wqhtt,UID:6306df5f-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31218,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 5dfe592d-86d5-11e9-9957-a6a8fec88741 0xc001237387 0xc001237388}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0012373f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001237410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.083: INFO: Pod "nginx-deployment-65bbdb5f8-2v4jz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2v4jz,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-2v4jz,UID:63097fb5-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31228,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0012378f7 0xc0012378f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001237960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001237980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.083: INFO: Pod "nginx-deployment-65bbdb5f8-5sms6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5sms6,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-5sms6,UID:63099f39-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31174,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc001237a40 0xc001237a41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001237d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001237d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:,StartTime:2019-06-04 14:31:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.091: INFO: Pod "nginx-deployment-65bbdb5f8-6lvtj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6lvtj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-6lvtj,UID:61ca822f-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31224,Generation:0,CreationTimestamp:2019-06-04 14:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc001237e30 0xc001237e31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001237f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001237fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:172.25.1.185,StartTime:2019-06-04 14:31:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.091: INFO: Pod "nginx-deployment-65bbdb5f8-7bdbg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7bdbg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-7bdbg,UID:61c385db-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31206,Generation:0,CreationTimestamp:2019-06-04 14:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e40b0 0xc0014e40b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:172.25.0.56,StartTime:2019-06-04 14:31:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.091: INFO: Pod "nginx-deployment-65bbdb5f8-cpktv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-cpktv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-cpktv,UID:61cc6c5a-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31221,Generation:0,CreationTimestamp:2019-06-04 14:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e4250 0xc0014e4251}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e43a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:172.25.0.57,StartTime:2019-06-04 14:31:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.091: INFO: Pod "nginx-deployment-65bbdb5f8-hz7rk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hz7rk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-hz7rk,UID:63060a30-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31233,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e4580 0xc0014e4581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-4wzp4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e45f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.138.54,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.092: INFO: Pod "nginx-deployment-65bbdb5f8-j8jdq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j8jdq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-j8jdq,UID:61c35220-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31105,Generation:0,CreationTimestamp:2019-06-04 14:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e4700 0xc0014e4701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:172.25.2.48,StartTime:2019-06-04 14:31:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.092: INFO: Pod "nginx-deployment-65bbdb5f8-pd7m9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-pd7m9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-pd7m9,UID:630d79df-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31162,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e4890 0xc0014e4891}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.092: INFO: Pod "nginx-deployment-65bbdb5f8-q7l78" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-q7l78,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-q7l78,UID:63073435-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31195,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e4b10 0xc0014e4b11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.096: INFO: Pod "nginx-deployment-65bbdb5f8-shfhh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-shfhh,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-shfhh,UID:630a0651-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31169,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e4ce0 0xc0014e4ce1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e4d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:,StartTime:2019-06-04 14:31:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.096: INFO: Pod "nginx-deployment-65bbdb5f8-ssdsj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ssdsj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-ssdsj,UID:630722e9-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31157,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e4f00 0xc0014e4f01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e4fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e50a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.096: INFO: Pod "nginx-deployment-65bbdb5f8-xtp6k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xtp6k,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-xtp6k,UID:6309ab8c-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31188,Generation:0,CreationTimestamp:2019-06-04 14:31:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e51b0 0xc0014e51b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e5260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e5280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:05 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:,StartTime:2019-06-04 14:31:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jun  4 14:31:08.097: INFO: Pod "nginx-deployment-65bbdb5f8-zb845" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zb845,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-wwpjq,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wwpjq/pods/nginx-deployment-65bbdb5f8-zb845,UID:61c200d5-86d5-11e9-9957-a6a8fec88741,ResourceVersion:31226,Generation:0,CreationTimestamp:2019-06-04 14:31:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 61c12bfb-86d5-11e9-9957-a6a8fec88741 0xc0014e5360 0xc0014e5361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vpq47 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vpq47,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vpq47 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0014e5400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0014e5550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:31:03 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:172.25.1.186,StartTime:2019-06-04 14:31:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:31:08.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-wwpjq" for this suite.
Jun  4 14:31:16.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:31:16.246: INFO: namespace: e2e-tests-deployment-wwpjq, resource: bindings, ignored listing per whitelist
Jun  4 14:31:16.945: INFO: namespace e2e-tests-deployment-wwpjq deletion completed in 8.800267206s

• [SLOW TEST:19.849 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:31:16.946: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:31:39.653: INFO: Container started at 2019-06-04 14:31:23 +0000 UTC, pod became ready at 2019-06-04 14:31:38 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:31:39.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-85l46" for this suite.
Jun  4 14:32:01.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:32:02.709: INFO: namespace: e2e-tests-container-probe-85l46, resource: bindings, ignored listing per whitelist
Jun  4 14:32:02.714: INFO: namespace e2e-tests-container-probe-85l46 deletion completed in 23.055611319s

• [SLOW TEST:45.768 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:32:02.714: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-g9qzj
Jun  4 14:32:07.140: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-g9qzj
STEP: checking the pod's current state and verifying that restartCount is present
Jun  4 14:32:07.337: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:36:07.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-g9qzj" for this suite.
Jun  4 14:36:13.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:36:14.541: INFO: namespace: e2e-tests-container-probe-g9qzj, resource: bindings, ignored listing per whitelist
Jun  4 14:36:14.681: INFO: namespace e2e-tests-container-probe-g9qzj deletion completed in 6.995580872s

• [SLOW TEST:251.967 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:36:14.686: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1b58275b-86d6-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 14:36:15.154: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1b590f73-86d6-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-mrl46" to be "success or failure"
Jun  4 14:36:15.163: INFO: Pod "pod-projected-secrets-1b590f73-86d6-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.881432ms
Jun  4 14:36:17.343: INFO: Pod "pod-projected-secrets-1b590f73-86d6-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.188425335s
Jun  4 14:36:19.350: INFO: Pod "pod-projected-secrets-1b590f73-86d6-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.195593075s
STEP: Saw pod success
Jun  4 14:36:19.350: INFO: Pod "pod-projected-secrets-1b590f73-86d6-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:36:19.355: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-secrets-1b590f73-86d6-11e9-8620-ba945f56578b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun  4 14:36:19.510: INFO: Waiting for pod pod-projected-secrets-1b590f73-86d6-11e9-8620-ba945f56578b to disappear
Jun  4 14:36:19.515: INFO: Pod pod-projected-secrets-1b590f73-86d6-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:36:19.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mrl46" for this suite.
Jun  4 14:36:25.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:36:25.899: INFO: namespace: e2e-tests-projected-mrl46, resource: bindings, ignored listing per whitelist
Jun  4 14:36:26.041: INFO: namespace e2e-tests-projected-mrl46 deletion completed in 6.518589586s

• [SLOW TEST:11.356 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:36:26.046: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jw7dv
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-jw7dv
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-jw7dv
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-jw7dv
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-jw7dv
Jun  4 14:36:30.739: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-jw7dv, name: ss-0, uid: 24301fec-86d6-11e9-9957-a6a8fec88741, status phase: Pending. Waiting for statefulset controller to delete.
Jun  4 14:36:31.668: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-jw7dv, name: ss-0, uid: 24301fec-86d6-11e9-9957-a6a8fec88741, status phase: Failed. Waiting for statefulset controller to delete.
Jun  4 14:36:31.680: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-jw7dv, name: ss-0, uid: 24301fec-86d6-11e9-9957-a6a8fec88741, status phase: Failed. Waiting for statefulset controller to delete.
Jun  4 14:36:31.686: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-jw7dv
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-jw7dv
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-jw7dv and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jun  4 14:36:35.746: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jw7dv
Jun  4 14:36:35.751: INFO: Scaling statefulset ss to 0
Jun  4 14:36:45.774: INFO: Waiting for statefulset status.replicas updated to 0
Jun  4 14:36:45.842: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:36:45.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jw7dv" for this suite.
Jun  4 14:36:51.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:36:52.176: INFO: namespace: e2e-tests-statefulset-jw7dv, resource: bindings, ignored listing per whitelist
Jun  4 14:36:52.387: INFO: namespace e2e-tests-statefulset-jw7dv deletion completed in 6.515404864s

• [SLOW TEST:26.341 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:36:52.393: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-31d1fc3d-86d6-11e9-8620-ba945f56578b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-31d1fc3d-86d6-11e9-8620-ba945f56578b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:38:24.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4t6dx" for this suite.
Jun  4 14:38:46.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:38:47.121: INFO: namespace: e2e-tests-projected-4t6dx, resource: bindings, ignored listing per whitelist
Jun  4 14:38:47.342: INFO: namespace e2e-tests-projected-4t6dx deletion completed in 22.796834705s

• [SLOW TEST:114.949 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:38:47.342: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun  4 14:38:47.577: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:38:51.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-gvx7s" for this suite.
Jun  4 14:38:57.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:38:58.134: INFO: namespace: e2e-tests-init-container-gvx7s, resource: bindings, ignored listing per whitelist
Jun  4 14:38:58.645: INFO: namespace e2e-tests-init-container-gvx7s deletion completed in 6.801788974s

• [SLOW TEST:11.303 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:38:58.649: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jun  4 14:38:59.015: INFO: Waiting up to 5m0s for pod "client-containers-7d036d6d-86d6-11e9-8620-ba945f56578b" in namespace "e2e-tests-containers-4stv2" to be "success or failure"
Jun  4 14:38:59.037: INFO: Pod "client-containers-7d036d6d-86d6-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 21.366912ms
Jun  4 14:39:01.042: INFO: Pod "client-containers-7d036d6d-86d6-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026868785s
STEP: Saw pod success
Jun  4 14:39:01.043: INFO: Pod "client-containers-7d036d6d-86d6-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:39:01.047: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod client-containers-7d036d6d-86d6-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 14:39:01.237: INFO: Waiting for pod client-containers-7d036d6d-86d6-11e9-8620-ba945f56578b to disappear
Jun  4 14:39:01.241: INFO: Pod client-containers-7d036d6d-86d6-11e9-8620-ba945f56578b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:39:01.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4stv2" for this suite.
Jun  4 14:39:07.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:39:07.777: INFO: namespace: e2e-tests-containers-4stv2, resource: bindings, ignored listing per whitelist
Jun  4 14:39:07.781: INFO: namespace e2e-tests-containers-4stv2 deletion completed in 6.322966229s

• [SLOW TEST:9.132 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:39:07.787: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jun  4 14:39:08.177: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wqh9s,SelfLink:/api/v1/namespaces/e2e-tests-watch-wqh9s/configmaps/e2e-watch-test-label-changed,UID:82778c79-86d6-11e9-9957-a6a8fec88741,ResourceVersion:32915,Generation:0,CreationTimestamp:2019-06-04 14:39:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun  4 14:39:08.178: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wqh9s,SelfLink:/api/v1/namespaces/e2e-tests-watch-wqh9s/configmaps/e2e-watch-test-label-changed,UID:82778c79-86d6-11e9-9957-a6a8fec88741,ResourceVersion:32916,Generation:0,CreationTimestamp:2019-06-04 14:39:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun  4 14:39:08.178: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wqh9s,SelfLink:/api/v1/namespaces/e2e-tests-watch-wqh9s/configmaps/e2e-watch-test-label-changed,UID:82778c79-86d6-11e9-9957-a6a8fec88741,ResourceVersion:32917,Generation:0,CreationTimestamp:2019-06-04 14:39:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jun  4 14:39:18.463: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wqh9s,SelfLink:/api/v1/namespaces/e2e-tests-watch-wqh9s/configmaps/e2e-watch-test-label-changed,UID:82778c79-86d6-11e9-9957-a6a8fec88741,ResourceVersion:32943,Generation:0,CreationTimestamp:2019-06-04 14:39:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun  4 14:39:18.463: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wqh9s,SelfLink:/api/v1/namespaces/e2e-tests-watch-wqh9s/configmaps/e2e-watch-test-label-changed,UID:82778c79-86d6-11e9-9957-a6a8fec88741,ResourceVersion:32945,Generation:0,CreationTimestamp:2019-06-04 14:39:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jun  4 14:39:18.463: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-wqh9s,SelfLink:/api/v1/namespaces/e2e-tests-watch-wqh9s/configmaps/e2e-watch-test-label-changed,UID:82778c79-86d6-11e9-9957-a6a8fec88741,ResourceVersion:32946,Generation:0,CreationTimestamp:2019-06-04 14:39:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:39:18.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wqh9s" for this suite.
Jun  4 14:39:24.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:39:25.169: INFO: namespace: e2e-tests-watch-wqh9s, resource: bindings, ignored listing per whitelist
Jun  4 14:39:25.377: INFO: namespace e2e-tests-watch-wqh9s deletion completed in 6.90713162s

• [SLOW TEST:17.591 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:39:25.378: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-8d031a80-86d6-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume secrets
Jun  4 14:39:25.858: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8d04190c-86d6-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-dxcv5" to be "success or failure"
Jun  4 14:39:25.870: INFO: Pod "pod-projected-secrets-8d04190c-86d6-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.201182ms
Jun  4 14:39:27.876: INFO: Pod "pod-projected-secrets-8d04190c-86d6-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016560286s
STEP: Saw pod success
Jun  4 14:39:27.876: INFO: Pod "pod-projected-secrets-8d04190c-86d6-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:39:27.881: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-projected-secrets-8d04190c-86d6-11e9-8620-ba945f56578b container secret-volume-test: <nil>
STEP: delete the pod
Jun  4 14:39:28.037: INFO: Waiting for pod pod-projected-secrets-8d04190c-86d6-11e9-8620-ba945f56578b to disappear
Jun  4 14:39:28.047: INFO: Pod pod-projected-secrets-8d04190c-86d6-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:39:28.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dxcv5" for this suite.
Jun  4 14:39:34.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:39:34.636: INFO: namespace: e2e-tests-projected-dxcv5, resource: bindings, ignored listing per whitelist
Jun  4 14:39:34.948: INFO: namespace e2e-tests-projected-dxcv5 deletion completed in 6.88989675s

• [SLOW TEST:9.582 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:39:34.965: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-92b3d202-86d6-11e9-8620-ba945f56578b
STEP: Creating configMap with name cm-test-opt-upd-92b3d24d-86d6-11e9-8620-ba945f56578b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-92b3d202-86d6-11e9-8620-ba945f56578b
STEP: Updating configmap cm-test-opt-upd-92b3d24d-86d6-11e9-8620-ba945f56578b
STEP: Creating configMap with name cm-test-opt-create-92b3d269-86d6-11e9-8620-ba945f56578b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:39:42.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-shstx" for this suite.
Jun  4 14:40:04.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:40:04.580: INFO: namespace: e2e-tests-configmap-shstx, resource: bindings, ignored listing per whitelist
Jun  4 14:40:04.883: INFO: namespace e2e-tests-configmap-shstx deletion completed in 22.61703688s

• [SLOW TEST:29.919 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:40:04.886: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:40:05.454: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4937ce7-86d6-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-9cszz" to be "success or failure"
Jun  4 14:40:05.463: INFO: Pod "downwardapi-volume-a4937ce7-86d6-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.392294ms
Jun  4 14:40:07.541: INFO: Pod "downwardapi-volume-a4937ce7-86d6-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.086951941s
STEP: Saw pod success
Jun  4 14:40:07.542: INFO: Pod "downwardapi-volume-a4937ce7-86d6-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:40:07.547: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-a4937ce7-86d6-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:40:07.613: INFO: Waiting for pod downwardapi-volume-a4937ce7-86d6-11e9-8620-ba945f56578b to disappear
Jun  4 14:40:07.618: INFO: Pod downwardapi-volume-a4937ce7-86d6-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:40:07.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9cszz" for this suite.
Jun  4 14:40:13.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:40:13.877: INFO: namespace: e2e-tests-downward-api-9cszz, resource: bindings, ignored listing per whitelist
Jun  4 14:40:14.000: INFO: namespace e2e-tests-downward-api-9cszz deletion completed in 6.37585748s

• [SLOW TEST:9.114 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:40:14.006: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jun  4 14:40:14.389: INFO: Waiting up to 5m0s for pod "var-expansion-a9f105eb-86d6-11e9-8620-ba945f56578b" in namespace "e2e-tests-var-expansion-gkthc" to be "success or failure"
Jun  4 14:40:14.400: INFO: Pod "var-expansion-a9f105eb-86d6-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.869701ms
Jun  4 14:40:16.406: INFO: Pod "var-expansion-a9f105eb-86d6-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016821155s
Jun  4 14:40:18.444: INFO: Pod "var-expansion-a9f105eb-86d6-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054349098s
STEP: Saw pod success
Jun  4 14:40:18.444: INFO: Pod "var-expansion-a9f105eb-86d6-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:40:18.539: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod var-expansion-a9f105eb-86d6-11e9-8620-ba945f56578b container dapi-container: <nil>
STEP: delete the pod
Jun  4 14:40:18.657: INFO: Waiting for pod var-expansion-a9f105eb-86d6-11e9-8620-ba945f56578b to disappear
Jun  4 14:40:18.737: INFO: Pod var-expansion-a9f105eb-86d6-11e9-8620-ba945f56578b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:40:18.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-gkthc" for this suite.
Jun  4 14:40:24.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:40:25.149: INFO: namespace: e2e-tests-var-expansion-gkthc, resource: bindings, ignored listing per whitelist
Jun  4 14:40:25.691: INFO: namespace e2e-tests-var-expansion-gkthc deletion completed in 6.946217128s

• [SLOW TEST:11.687 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:40:25.698: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b113d817-86d6-11e9-8620-ba945f56578b
STEP: Creating secret with name s-test-opt-upd-b113d86a-86d6-11e9-8620-ba945f56578b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b113d817-86d6-11e9-8620-ba945f56578b
STEP: Updating secret s-test-opt-upd-b113d86a-86d6-11e9-8620-ba945f56578b
STEP: Creating secret with name s-test-opt-create-b113d888-86d6-11e9-8620-ba945f56578b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:41:40.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z99mt" for this suite.
Jun  4 14:42:02.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:42:02.356: INFO: namespace: e2e-tests-projected-z99mt, resource: bindings, ignored listing per whitelist
Jun  4 14:42:02.513: INFO: namespace e2e-tests-projected-z99mt deletion completed in 22.272947656s

• [SLOW TEST:96.815 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:42:02.513: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qbjrq/configmap-test-ea8780eb-86d6-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 14:42:02.758: INFO: Waiting up to 5m0s for pod "pod-configmaps-ea88cfad-86d6-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-qbjrq" to be "success or failure"
Jun  4 14:42:02.766: INFO: Pod "pod-configmaps-ea88cfad-86d6-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.404397ms
Jun  4 14:42:04.777: INFO: Pod "pod-configmaps-ea88cfad-86d6-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017825065s
STEP: Saw pod success
Jun  4 14:42:04.777: INFO: Pod "pod-configmaps-ea88cfad-86d6-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:42:04.781: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-ea88cfad-86d6-11e9-8620-ba945f56578b container env-test: <nil>
STEP: delete the pod
Jun  4 14:42:04.956: INFO: Waiting for pod pod-configmaps-ea88cfad-86d6-11e9-8620-ba945f56578b to disappear
Jun  4 14:42:04.961: INFO: Pod pod-configmaps-ea88cfad-86d6-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:42:04.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qbjrq" for this suite.
Jun  4 14:42:10.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:42:11.305: INFO: namespace: e2e-tests-configmap-qbjrq, resource: bindings, ignored listing per whitelist
Jun  4 14:42:11.565: INFO: namespace e2e-tests-configmap-qbjrq deletion completed in 6.596003758s

• [SLOW TEST:9.052 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:42:11.568: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-efe0f2fd-86d6-11e9-8620-ba945f56578b
Jun  4 14:42:11.747: INFO: Pod name my-hostname-basic-efe0f2fd-86d6-11e9-8620-ba945f56578b: Found 0 pods out of 1
Jun  4 14:42:16.754: INFO: Pod name my-hostname-basic-efe0f2fd-86d6-11e9-8620-ba945f56578b: Found 1 pods out of 1
Jun  4 14:42:16.754: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-efe0f2fd-86d6-11e9-8620-ba945f56578b" are running
Jun  4 14:42:16.759: INFO: Pod "my-hostname-basic-efe0f2fd-86d6-11e9-8620-ba945f56578b-mrgst" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-04 14:42:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-04 14:42:13 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-04 14:42:13 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-06-04 14:42:11 +0000 UTC Reason: Message:}])
Jun  4 14:42:16.759: INFO: Trying to dial the pod
Jun  4 14:42:21.887: INFO: Controller my-hostname-basic-efe0f2fd-86d6-11e9-8620-ba945f56578b: Got expected result from replica 1 [my-hostname-basic-efe0f2fd-86d6-11e9-8620-ba945f56578b-mrgst]: "my-hostname-basic-efe0f2fd-86d6-11e9-8620-ba945f56578b-mrgst", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:42:21.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-qwkrh" for this suite.
Jun  4 14:42:27.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:42:28.579: INFO: namespace: e2e-tests-replication-controller-qwkrh, resource: bindings, ignored listing per whitelist
Jun  4 14:42:28.585: INFO: namespace e2e-tests-replication-controller-qwkrh deletion completed in 6.685491744s

• [SLOW TEST:17.018 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:42:28.590: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:42:29.132: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jun  4 14:42:34.148: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun  4 14:42:34.148: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jun  4 14:42:36.237: INFO: Creating deployment "test-rollover-deployment"
Jun  4 14:42:36.253: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jun  4 14:42:38.340: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jun  4 14:42:38.366: INFO: Ensure that both replica sets have 1 created replica
Jun  4 14:42:38.384: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jun  4 14:42:38.404: INFO: Updating deployment test-rollover-deployment
Jun  4 14:42:38.405: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jun  4 14:42:40.448: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jun  4 14:42:40.549: INFO: Make sure deployment "test-rollover-deployment" is complete
Jun  4 14:42:40.650: INFO: all replica sets need to contain the pod-template-hash label
Jun  4 14:42:40.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256160, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 14:42:42.845: INFO: all replica sets need to contain the pod-template-hash label
Jun  4 14:42:42.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256160, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 14:42:44.748: INFO: all replica sets need to contain the pod-template-hash label
Jun  4 14:42:44.748: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256160, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 14:42:46.723: INFO: all replica sets need to contain the pod-template-hash label
Jun  4 14:42:46.724: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256160, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 14:42:48.662: INFO: all replica sets need to contain the pod-template-hash label
Jun  4 14:42:48.662: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256160, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 14:42:50.838: INFO: 
Jun  4 14:42:50.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256170, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63695256156, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun  4 14:42:52.664: INFO: 
Jun  4 14:42:52.664: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jun  4 14:42:52.679: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-j792c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j792c/deployments/test-rollover-deployment,UID:fe7fc98c-86d6-11e9-9957-a6a8fec88741,ResourceVersion:33761,Generation:2,CreationTimestamp:2019-06-04 14:42:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-06-04 14:42:36 +0000 UTC 2019-06-04 14:42:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-06-04 14:42:50 +0000 UTC 2019-06-04 14:42:36 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jun  4 14:42:52.686: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-j792c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j792c/replicasets/test-rollover-deployment-6b7f9d6597,UID:ffca21ce-86d6-11e9-9957-a6a8fec88741,ResourceVersion:33752,Generation:2,CreationTimestamp:2019-06-04 14:42:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fe7fc98c-86d6-11e9-9957-a6a8fec88741 0xc00141d947 0xc00141d948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jun  4 14:42:52.686: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jun  4 14:42:52.686: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-j792c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j792c/replicasets/test-rollover-controller,UID:fa3e04ae-86d6-11e9-9957-a6a8fec88741,ResourceVersion:33760,Generation:2,CreationTimestamp:2019-06-04 14:42:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fe7fc98c-86d6-11e9-9957-a6a8fec88741 0xc00141d7b7 0xc00141d7b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun  4 14:42:52.687: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-j792c,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j792c/replicasets/test-rollover-deployment-6586df867b,UID:fe836806-86d6-11e9-9957-a6a8fec88741,ResourceVersion:33712,Generation:2,CreationTimestamp:2019-06-04 14:42:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment fe7fc98c-86d6-11e9-9957-a6a8fec88741 0xc00141d877 0xc00141d878}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jun  4 14:42:52.692: INFO: Pod "test-rollover-deployment-6b7f9d6597-tvg9c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-tvg9c,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-j792c,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j792c/pods/test-rollover-deployment-6b7f9d6597-tvg9c,UID:ffd8d1d2-86d6-11e9-9957-a6a8fec88741,ResourceVersion:33725,Generation:0,CreationTimestamp:2019-06-04 14:42:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 ffca21ce-86d6-11e9-9957-a6a8fec88741 0xc000a92497 0xc000a92498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-449rg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-449rg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-449rg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-gv9cg,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000a92500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000a92520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:42:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:42:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:42:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:42:38 +0000 UTC  }],Message:,Reason:,HostIP:165.227.152.6,PodIP:172.25.2.56,StartTime:2019-06-04 14:42:38 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-06-04 14:42:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://fade084b3f4843ab90713c64d1b4fc5cb251a9629c338f9dcf5d1bee11ecff1a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:42:52.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-j792c" for this suite.
Jun  4 14:42:58.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:42:59.099: INFO: namespace: e2e-tests-deployment-j792c, resource: bindings, ignored listing per whitelist
Jun  4 14:42:59.186: INFO: namespace e2e-tests-deployment-j792c deletion completed in 6.487935815s

• [SLOW TEST:30.597 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:42:59.190: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:42:59.462: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c5336d7-86d7-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-464lh" to be "success or failure"
Jun  4 14:42:59.474: INFO: Pod "downwardapi-volume-0c5336d7-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.196431ms
Jun  4 14:43:01.479: INFO: Pod "downwardapi-volume-0c5336d7-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017141234s
Jun  4 14:43:03.484: INFO: Pod "downwardapi-volume-0c5336d7-86d7-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02147285s
STEP: Saw pod success
Jun  4 14:43:03.484: INFO: Pod "downwardapi-volume-0c5336d7-86d7-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:43:03.538: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-0c5336d7-86d7-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:43:03.622: INFO: Waiting for pod downwardapi-volume-0c5336d7-86d7-11e9-8620-ba945f56578b to disappear
Jun  4 14:43:03.627: INFO: Pod downwardapi-volume-0c5336d7-86d7-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:43:03.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-464lh" for this suite.
Jun  4 14:43:09.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:43:09.811: INFO: namespace: e2e-tests-projected-464lh, resource: bindings, ignored listing per whitelist
Jun  4 14:43:09.907: INFO: namespace e2e-tests-projected-464lh deletion completed in 6.274207416s

• [SLOW TEST:10.718 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:43:09.911: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun  4 14:43:14.496: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun  4 14:43:14.503: INFO: Pod pod-with-prestop-http-hook still exists
Jun  4 14:43:16.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun  4 14:43:16.539: INFO: Pod pod-with-prestop-http-hook still exists
Jun  4 14:43:18.504: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun  4 14:43:18.646: INFO: Pod pod-with-prestop-http-hook still exists
Jun  4 14:43:20.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun  4 14:43:20.509: INFO: Pod pod-with-prestop-http-hook still exists
Jun  4 14:43:22.504: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun  4 14:43:22.542: INFO: Pod pod-with-prestop-http-hook still exists
Jun  4 14:43:24.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun  4 14:43:24.544: INFO: Pod pod-with-prestop-http-hook still exists
Jun  4 14:43:26.504: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun  4 14:43:26.539: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:43:26.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-94mqs" for this suite.
Jun  4 14:43:49.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:43:49.274: INFO: namespace: e2e-tests-container-lifecycle-hook-94mqs, resource: bindings, ignored listing per whitelist
Jun  4 14:43:49.572: INFO: namespace e2e-tests-container-lifecycle-hook-94mqs deletion completed in 22.834650703s

• [SLOW TEST:39.662 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:43:49.576: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-9m4t
STEP: Creating a pod to test atomic-volume-subpath
Jun  4 14:43:50.106: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9m4t" in namespace "e2e-tests-subpath-dbfcz" to be "success or failure"
Jun  4 14:43:50.110: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Pending", Reason="", readiness=false. Elapsed: 4.155552ms
Jun  4 14:43:52.142: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036011129s
Jun  4 14:43:54.148: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 4.04167042s
Jun  4 14:43:56.153: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 6.047225901s
Jun  4 14:43:58.159: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 8.053279888s
Jun  4 14:44:00.243: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 10.13651871s
Jun  4 14:44:02.251: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 12.145362113s
Jun  4 14:44:04.257: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 14.151367303s
Jun  4 14:44:06.263: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 16.15697408s
Jun  4 14:44:08.269: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 18.162621494s
Jun  4 14:44:10.278: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 20.17196895s
Jun  4 14:44:12.338: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Running", Reason="", readiness=false. Elapsed: 22.231788271s
Jun  4 14:44:14.344: INFO: Pod "pod-subpath-test-configmap-9m4t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.237894507s
STEP: Saw pod success
Jun  4 14:44:14.348: INFO: Pod "pod-subpath-test-configmap-9m4t" satisfied condition "success or failure"
Jun  4 14:44:14.355: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-4wzp4 pod pod-subpath-test-configmap-9m4t container test-container-subpath-configmap-9m4t: <nil>
STEP: delete the pod
Jun  4 14:44:14.440: INFO: Waiting for pod pod-subpath-test-configmap-9m4t to disappear
Jun  4 14:44:14.538: INFO: Pod pod-subpath-test-configmap-9m4t no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9m4t
Jun  4 14:44:14.538: INFO: Deleting pod "pod-subpath-test-configmap-9m4t" in namespace "e2e-tests-subpath-dbfcz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:44:14.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dbfcz" for this suite.
Jun  4 14:44:20.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:44:20.730: INFO: namespace: e2e-tests-subpath-dbfcz, resource: bindings, ignored listing per whitelist
Jun  4 14:44:20.952: INFO: namespace e2e-tests-subpath-dbfcz deletion completed in 6.403414861s

• [SLOW TEST:31.377 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:44:20.957: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-3d3391c4-86d7-11e9-8620-ba945f56578b
STEP: Creating configMap with name cm-test-opt-upd-3d339211-86d7-11e9-8620-ba945f56578b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3d3391c4-86d7-11e9-8620-ba945f56578b
STEP: Updating configmap cm-test-opt-upd-3d339211-86d7-11e9-8620-ba945f56578b
STEP: Creating configMap with name cm-test-opt-create-3d339229-86d7-11e9-8620-ba945f56578b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:44:28.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cjxgv" for this suite.
Jun  4 14:44:50.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:44:50.593: INFO: namespace: e2e-tests-projected-cjxgv, resource: bindings, ignored listing per whitelist
Jun  4 14:44:50.704: INFO: namespace e2e-tests-projected-cjxgv deletion completed in 22.405002972s

• [SLOW TEST:29.747 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:44:50.712: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jun  4 14:44:51.055: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zchxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zchxt/configmaps/e2e-watch-test-watch-closed,UID:4ed814fc-86d7-11e9-9957-a6a8fec88741,ResourceVersion:34252,Generation:0,CreationTimestamp:2019-06-04 14:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun  4 14:44:51.056: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zchxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zchxt/configmaps/e2e-watch-test-watch-closed,UID:4ed814fc-86d7-11e9-9957-a6a8fec88741,ResourceVersion:34253,Generation:0,CreationTimestamp:2019-06-04 14:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jun  4 14:44:51.158: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zchxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zchxt/configmaps/e2e-watch-test-watch-closed,UID:4ed814fc-86d7-11e9-9957-a6a8fec88741,ResourceVersion:34254,Generation:0,CreationTimestamp:2019-06-04 14:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun  4 14:44:51.158: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-zchxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zchxt/configmaps/e2e-watch-test-watch-closed,UID:4ed814fc-86d7-11e9-9957-a6a8fec88741,ResourceVersion:34255,Generation:0,CreationTimestamp:2019-06-04 14:44:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:44:51.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zchxt" for this suite.
Jun  4 14:44:57.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:44:57.571: INFO: namespace: e2e-tests-watch-zchxt, resource: bindings, ignored listing per whitelist
Jun  4 14:44:57.681: INFO: namespace e2e-tests-watch-zchxt deletion completed in 6.514132136s

• [SLOW TEST:6.969 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:44:57.687: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jun  4 14:44:58.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7kw9h'
Jun  4 14:44:58.675: INFO: stderr: ""
Jun  4 14:44:58.675: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jun  4 14:45:03.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7kw9h -o json'
Jun  4 14:45:03.870: INFO: stderr: ""
Jun  4 14:45:03.870: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-06-04T14:44:58Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-7kw9h\",\n        \"resourceVersion\": \"34297\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-7kw9h/pods/e2e-test-nginx-pod\",\n        \"uid\": \"536199ae-86d7-11e9-9957-a6a8fec88741\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-q79s4\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker-4jvsx-65d7bd6f69-45s5z\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-q79s4\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-q79s4\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-04T14:44:58Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-04T14:45:00Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-04T14:45:00Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-06-04T14:44:58Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://aacec14291f5b5ba568d7ff47fb5d8db03c244c0c0dcc59007c3cff924f3693c\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-06-04T14:45:00Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"138.68.109.151\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.25.1.208\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-06-04T14:44:58Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jun  4 14:45:03.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 replace -f - --namespace=e2e-tests-kubectl-7kw9h'
Jun  4 14:45:04.644: INFO: stderr: ""
Jun  4 14:45:04.644: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Jun  4 14:45:04.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7kw9h'
Jun  4 14:45:12.094: INFO: stderr: ""
Jun  4 14:45:12.094: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:45:12.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7kw9h" for this suite.
Jun  4 14:45:18.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:45:18.389: INFO: namespace: e2e-tests-kubectl-7kw9h, resource: bindings, ignored listing per whitelist
Jun  4 14:45:18.668: INFO: namespace e2e-tests-kubectl-7kw9h deletion completed in 6.5227409s

• [SLOW TEST:20.981 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:45:18.673: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun  4 14:45:19.220: INFO: Waiting up to 5m0s for pod "pod-5fa1557d-86d7-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-bzql4" to be "success or failure"
Jun  4 14:45:19.227: INFO: Pod "pod-5fa1557d-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.091302ms
Jun  4 14:45:21.233: INFO: Pod "pod-5fa1557d-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012932966s
Jun  4 14:45:23.240: INFO: Pod "pod-5fa1557d-86d7-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019946085s
STEP: Saw pod success
Jun  4 14:45:23.240: INFO: Pod "pod-5fa1557d-86d7-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:45:23.244: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-5fa1557d-86d7-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 14:45:23.350: INFO: Waiting for pod pod-5fa1557d-86d7-11e9-8620-ba945f56578b to disappear
Jun  4 14:45:23.354: INFO: Pod pod-5fa1557d-86d7-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:45:23.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bzql4" for this suite.
Jun  4 14:45:29.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:45:29.708: INFO: namespace: e2e-tests-emptydir-bzql4, resource: bindings, ignored listing per whitelist
Jun  4 14:45:29.913: INFO: namespace e2e-tests-emptydir-bzql4 deletion completed in 6.552433679s

• [SLOW TEST:11.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:45:29.919: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:45:30.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-663daeeb-86d7-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-w249r" to be "success or failure"
Jun  4 14:45:30.346: INFO: Pod "downwardapi-volume-663daeeb-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.82563ms
Jun  4 14:45:32.351: INFO: Pod "downwardapi-volume-663daeeb-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012775387s
Jun  4 14:45:34.442: INFO: Pod "downwardapi-volume-663daeeb-86d7-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.103661888s
STEP: Saw pod success
Jun  4 14:45:34.442: INFO: Pod "downwardapi-volume-663daeeb-86d7-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:45:34.450: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-663daeeb-86d7-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:45:34.581: INFO: Waiting for pod downwardapi-volume-663daeeb-86d7-11e9-8620-ba945f56578b to disappear
Jun  4 14:45:34.587: INFO: Pod downwardapi-volume-663daeeb-86d7-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:45:34.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w249r" for this suite.
Jun  4 14:45:40.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:45:40.766: INFO: namespace: e2e-tests-projected-w249r, resource: bindings, ignored listing per whitelist
Jun  4 14:45:40.805: INFO: namespace e2e-tests-projected-w249r deletion completed in 6.213505461s

• [SLOW TEST:10.887 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:45:40.807: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-fvwf
STEP: Creating a pod to test atomic-volume-subpath
Jun  4 14:45:41.337: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-fvwf" in namespace "e2e-tests-subpath-67sc9" to be "success or failure"
Jun  4 14:45:41.344: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.948787ms
Jun  4 14:45:43.349: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012006267s
Jun  4 14:45:45.355: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017153966s
Jun  4 14:45:47.360: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 6.022872955s
Jun  4 14:45:49.366: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 8.028884561s
Jun  4 14:45:51.437: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 10.099426297s
Jun  4 14:45:53.543: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 12.206030369s
Jun  4 14:45:55.549: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 14.212038878s
Jun  4 14:45:57.739: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 16.401141785s
Jun  4 14:45:59.933: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 18.595758025s
Jun  4 14:46:02.042: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 20.704418893s
Jun  4 14:46:04.142: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 22.80457865s
Jun  4 14:46:06.147: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Running", Reason="", readiness=false. Elapsed: 24.809912507s
Jun  4 14:46:08.238: INFO: Pod "pod-subpath-test-projected-fvwf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.900192234s
STEP: Saw pod success
Jun  4 14:46:08.238: INFO: Pod "pod-subpath-test-projected-fvwf" satisfied condition "success or failure"
Jun  4 14:46:08.341: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-gv9cg pod pod-subpath-test-projected-fvwf container test-container-subpath-projected-fvwf: <nil>
STEP: delete the pod
Jun  4 14:46:08.449: INFO: Waiting for pod pod-subpath-test-projected-fvwf to disappear
Jun  4 14:46:08.454: INFO: Pod pod-subpath-test-projected-fvwf no longer exists
STEP: Deleting pod pod-subpath-test-projected-fvwf
Jun  4 14:46:08.454: INFO: Deleting pod "pod-subpath-test-projected-fvwf" in namespace "e2e-tests-subpath-67sc9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:46:08.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-67sc9" for this suite.
Jun  4 14:46:14.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:46:14.545: INFO: namespace: e2e-tests-subpath-67sc9, resource: bindings, ignored listing per whitelist
Jun  4 14:46:15.165: INFO: namespace e2e-tests-subpath-67sc9 deletion completed in 6.700588352s

• [SLOW TEST:34.358 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:46:15.170: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jun  4 14:46:15.592: INFO: Waiting up to 5m0s for pod "var-expansion-813c5370-86d7-11e9-8620-ba945f56578b" in namespace "e2e-tests-var-expansion-nwxk2" to be "success or failure"
Jun  4 14:46:15.597: INFO: Pod "var-expansion-813c5370-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.45841ms
Jun  4 14:46:17.602: INFO: Pod "var-expansion-813c5370-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009724099s
Jun  4 14:46:19.641: INFO: Pod "var-expansion-813c5370-86d7-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048451046s
STEP: Saw pod success
Jun  4 14:46:19.641: INFO: Pod "var-expansion-813c5370-86d7-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:46:19.738: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod var-expansion-813c5370-86d7-11e9-8620-ba945f56578b container dapi-container: <nil>
STEP: delete the pod
Jun  4 14:46:19.864: INFO: Waiting for pod var-expansion-813c5370-86d7-11e9-8620-ba945f56578b to disappear
Jun  4 14:46:19.872: INFO: Pod var-expansion-813c5370-86d7-11e9-8620-ba945f56578b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:46:19.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-nwxk2" for this suite.
Jun  4 14:46:26.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:46:26.398: INFO: namespace: e2e-tests-var-expansion-nwxk2, resource: bindings, ignored listing per whitelist
Jun  4 14:46:26.461: INFO: namespace e2e-tests-var-expansion-nwxk2 deletion completed in 6.581368183s

• [SLOW TEST:11.291 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:46:26.465: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:46:31.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-lkgn5" for this suite.
Jun  4 14:47:13.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:47:13.459: INFO: namespace: e2e-tests-kubelet-test-lkgn5, resource: bindings, ignored listing per whitelist
Jun  4 14:47:13.665: INFO: namespace e2e-tests-kubelet-test-lkgn5 deletion completed in 42.65527409s

• [SLOW TEST:47.201 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:47:13.675: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:47:14.073: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jun  4 14:47:14.088: INFO: Number of nodes with available pods: 0
Jun  4 14:47:14.089: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jun  4 14:47:14.155: INFO: Number of nodes with available pods: 0
Jun  4 14:47:14.156: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:15.163: INFO: Number of nodes with available pods: 0
Jun  4 14:47:15.164: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:16.162: INFO: Number of nodes with available pods: 0
Jun  4 14:47:16.162: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:17.163: INFO: Number of nodes with available pods: 1
Jun  4 14:47:17.163: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jun  4 14:47:17.541: INFO: Number of nodes with available pods: 1
Jun  4 14:47:17.541: INFO: Number of running nodes: 0, number of available pods: 1
Jun  4 14:47:18.641: INFO: Number of nodes with available pods: 0
Jun  4 14:47:18.642: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jun  4 14:47:18.655: INFO: Number of nodes with available pods: 0
Jun  4 14:47:18.655: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:19.761: INFO: Number of nodes with available pods: 0
Jun  4 14:47:19.762: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:20.662: INFO: Number of nodes with available pods: 0
Jun  4 14:47:20.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:21.664: INFO: Number of nodes with available pods: 0
Jun  4 14:47:21.664: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:22.662: INFO: Number of nodes with available pods: 0
Jun  4 14:47:22.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:23.662: INFO: Number of nodes with available pods: 0
Jun  4 14:47:23.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:24.666: INFO: Number of nodes with available pods: 0
Jun  4 14:47:24.667: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:25.741: INFO: Number of nodes with available pods: 0
Jun  4 14:47:25.741: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:26.744: INFO: Number of nodes with available pods: 0
Jun  4 14:47:26.744: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:27.665: INFO: Number of nodes with available pods: 0
Jun  4 14:47:27.665: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:28.662: INFO: Number of nodes with available pods: 0
Jun  4 14:47:28.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:29.663: INFO: Number of nodes with available pods: 0
Jun  4 14:47:29.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:30.661: INFO: Number of nodes with available pods: 0
Jun  4 14:47:30.661: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:31.663: INFO: Number of nodes with available pods: 0
Jun  4 14:47:31.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:32.838: INFO: Number of nodes with available pods: 0
Jun  4 14:47:32.838: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:33.663: INFO: Number of nodes with available pods: 0
Jun  4 14:47:33.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:34.661: INFO: Number of nodes with available pods: 0
Jun  4 14:47:34.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:35.662: INFO: Number of nodes with available pods: 0
Jun  4 14:47:35.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:36.664: INFO: Number of nodes with available pods: 0
Jun  4 14:47:36.664: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:37.743: INFO: Number of nodes with available pods: 0
Jun  4 14:47:37.744: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:38.664: INFO: Number of nodes with available pods: 0
Jun  4 14:47:38.665: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:39.661: INFO: Number of nodes with available pods: 0
Jun  4 14:47:39.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:40.742: INFO: Number of nodes with available pods: 0
Jun  4 14:47:40.743: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:41.680: INFO: Number of nodes with available pods: 0
Jun  4 14:47:41.680: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:42.743: INFO: Number of nodes with available pods: 0
Jun  4 14:47:42.743: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:43.664: INFO: Number of nodes with available pods: 0
Jun  4 14:47:43.664: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:44.739: INFO: Number of nodes with available pods: 0
Jun  4 14:47:44.739: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:45.661: INFO: Number of nodes with available pods: 0
Jun  4 14:47:45.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:46.663: INFO: Number of nodes with available pods: 0
Jun  4 14:47:46.664: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:47.663: INFO: Number of nodes with available pods: 0
Jun  4 14:47:47.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:48.663: INFO: Number of nodes with available pods: 0
Jun  4 14:47:48.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:49.666: INFO: Number of nodes with available pods: 0
Jun  4 14:47:49.667: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:50.661: INFO: Number of nodes with available pods: 0
Jun  4 14:47:50.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:51.664: INFO: Number of nodes with available pods: 0
Jun  4 14:47:51.664: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:52.663: INFO: Number of nodes with available pods: 0
Jun  4 14:47:52.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:53.748: INFO: Number of nodes with available pods: 0
Jun  4 14:47:53.749: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:54.662: INFO: Number of nodes with available pods: 0
Jun  4 14:47:54.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:55.662: INFO: Number of nodes with available pods: 0
Jun  4 14:47:55.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:56.661: INFO: Number of nodes with available pods: 0
Jun  4 14:47:56.661: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:57.662: INFO: Number of nodes with available pods: 0
Jun  4 14:47:57.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:58.742: INFO: Number of nodes with available pods: 0
Jun  4 14:47:58.742: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:47:59.745: INFO: Number of nodes with available pods: 0
Jun  4 14:47:59.745: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:48:00.662: INFO: Number of nodes with available pods: 0
Jun  4 14:48:00.662: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:48:01.740: INFO: Number of nodes with available pods: 0
Jun  4 14:48:01.741: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:48:02.662: INFO: Number of nodes with available pods: 0
Jun  4 14:48:02.663: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:48:03.838: INFO: Number of nodes with available pods: 0
Jun  4 14:48:03.838: INFO: Node worker-4jvsx-65d7bd6f69-45s5z is running more than one daemon pod
Jun  4 14:48:04.662: INFO: Number of nodes with available pods: 1
Jun  4 14:48:04.663: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-8p7h2, will wait for the garbage collector to delete the pods
Jun  4 14:48:05.000: INFO: Deleting DaemonSet.extensions daemon-set took: 11.514978ms
Jun  4 14:48:05.100: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.688411ms
Jun  4 14:48:41.742: INFO: Number of nodes with available pods: 0
Jun  4 14:48:41.742: INFO: Number of running nodes: 0, number of available pods: 0
Jun  4 14:48:41.750: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8p7h2/daemonsets","resourceVersion":"35040"},"items":null}

Jun  4 14:48:41.758: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8p7h2/pods","resourceVersion":"35041"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:48:41.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8p7h2" for this suite.
Jun  4 14:48:47.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:48:48.079: INFO: namespace: e2e-tests-daemonsets-8p7h2, resource: bindings, ignored listing per whitelist
Jun  4 14:48:48.480: INFO: namespace e2e-tests-daemonsets-8p7h2 deletion completed in 6.60879596s

• [SLOW TEST:94.805 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:48:48.484: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jun  4 14:48:49.052: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"dca9d186-86d7-11e9-9957-a6a8fec88741", Controller:(*bool)(0xc001237dde), BlockOwnerDeletion:(*bool)(0xc001237ddf)}}
Jun  4 14:48:49.160: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"dca67f3e-86d7-11e9-9957-a6a8fec88741", Controller:(*bool)(0xc0014e40c2), BlockOwnerDeletion:(*bool)(0xc0014e40c3)}}
Jun  4 14:48:49.248: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"dca80043-86d7-11e9-9957-a6a8fec88741", Controller:(*bool)(0xc0014e44ce), BlockOwnerDeletion:(*bool)(0xc0014e44cf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:48:54.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-psx9t" for this suite.
Jun  4 14:49:00.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:49:00.692: INFO: namespace: e2e-tests-gc-psx9t, resource: bindings, ignored listing per whitelist
Jun  4 14:49:00.981: INFO: namespace e2e-tests-gc-psx9t deletion completed in 6.709308409s

• [SLOW TEST:12.498 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:49:00.982: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:49:01.388: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e40edd8c-86d7-11e9-8620-ba945f56578b" in namespace "e2e-tests-projected-mht4x" to be "success or failure"
Jun  4 14:49:01.392: INFO: Pod "downwardapi-volume-e40edd8c-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.965062ms
Jun  4 14:49:03.442: INFO: Pod "downwardapi-volume-e40edd8c-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054054167s
Jun  4 14:49:05.449: INFO: Pod "downwardapi-volume-e40edd8c-86d7-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06050829s
STEP: Saw pod success
Jun  4 14:49:05.449: INFO: Pod "downwardapi-volume-e40edd8c-86d7-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:49:05.454: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-e40edd8c-86d7-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:49:05.524: INFO: Waiting for pod downwardapi-volume-e40edd8c-86d7-11e9-8620-ba945f56578b to disappear
Jun  4 14:49:05.530: INFO: Pod downwardapi-volume-e40edd8c-86d7-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:49:05.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mht4x" for this suite.
Jun  4 14:49:11.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:49:11.722: INFO: namespace: e2e-tests-projected-mht4x, resource: bindings, ignored listing per whitelist
Jun  4 14:49:11.869: INFO: namespace e2e-tests-projected-mht4x deletion completed in 6.331656109s

• [SLOW TEST:10.888 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:49:11.873: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ea9506ad-86d7-11e9-8620-ba945f56578b
STEP: Creating a pod to test consume configMaps
Jun  4 14:49:12.344: INFO: Waiting up to 5m0s for pod "pod-configmaps-ea95fae2-86d7-11e9-8620-ba945f56578b" in namespace "e2e-tests-configmap-d4tj8" to be "success or failure"
Jun  4 14:49:12.350: INFO: Pod "pod-configmaps-ea95fae2-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.402466ms
Jun  4 14:49:14.359: INFO: Pod "pod-configmaps-ea95fae2-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014792512s
Jun  4 14:49:16.372: INFO: Pod "pod-configmaps-ea95fae2-86d7-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027907842s
STEP: Saw pod success
Jun  4 14:49:16.372: INFO: Pod "pod-configmaps-ea95fae2-86d7-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:49:16.438: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-configmaps-ea95fae2-86d7-11e9-8620-ba945f56578b container configmap-volume-test: <nil>
STEP: delete the pod
Jun  4 14:49:16.557: INFO: Waiting for pod pod-configmaps-ea95fae2-86d7-11e9-8620-ba945f56578b to disappear
Jun  4 14:49:16.562: INFO: Pod pod-configmaps-ea95fae2-86d7-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:49:16.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-d4tj8" for this suite.
Jun  4 14:49:22.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:49:23.237: INFO: namespace: e2e-tests-configmap-d4tj8, resource: bindings, ignored listing per whitelist
Jun  4 14:49:23.562: INFO: namespace e2e-tests-configmap-d4tj8 deletion completed in 6.992535564s

• [SLOW TEST:11.690 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:49:23.570: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun  4 14:49:24.154: INFO: Waiting up to 5m0s for pod "pod-f1a06de9-86d7-11e9-8620-ba945f56578b" in namespace "e2e-tests-emptydir-kl5zk" to be "success or failure"
Jun  4 14:49:24.162: INFO: Pod "pod-f1a06de9-86d7-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.357127ms
Jun  4 14:49:26.245: INFO: Pod "pod-f1a06de9-86d7-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.090736636s
STEP: Saw pod success
Jun  4 14:49:26.245: INFO: Pod "pod-f1a06de9-86d7-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:49:26.342: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod pod-f1a06de9-86d7-11e9-8620-ba945f56578b container test-container: <nil>
STEP: delete the pod
Jun  4 14:49:26.408: INFO: Waiting for pod pod-f1a06de9-86d7-11e9-8620-ba945f56578b to disappear
Jun  4 14:49:26.414: INFO: Pod pod-f1a06de9-86d7-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:49:26.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kl5zk" for this suite.
Jun  4 14:49:32.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:49:33.071: INFO: namespace: e2e-tests-emptydir-kl5zk, resource: bindings, ignored listing per whitelist
Jun  4 14:49:33.164: INFO: namespace e2e-tests-emptydir-kl5zk deletion completed in 6.744064931s

• [SLOW TEST:9.594 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:49:33.171: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jun  4 14:49:33.642: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:49:39.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-fzvdg" for this suite.
Jun  4 14:50:03.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:50:04.047: INFO: namespace: e2e-tests-init-container-fzvdg, resource: bindings, ignored listing per whitelist
Jun  4 14:50:04.338: INFO: namespace e2e-tests-init-container-fzvdg deletion completed in 24.591893041s

• [SLOW TEST:31.168 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:50:04.344: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jun  4 14:50:04.540: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09b1e19f-86d8-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-lqrqm" to be "success or failure"
Jun  4 14:50:04.562: INFO: Pod "downwardapi-volume-09b1e19f-86d8-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 21.293215ms
Jun  4 14:50:06.569: INFO: Pod "downwardapi-volume-09b1e19f-86d8-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028389105s
Jun  4 14:50:08.575: INFO: Pod "downwardapi-volume-09b1e19f-86d8-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035132043s
STEP: Saw pod success
Jun  4 14:50:08.575: INFO: Pod "downwardapi-volume-09b1e19f-86d8-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:50:08.582: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downwardapi-volume-09b1e19f-86d8-11e9-8620-ba945f56578b container client-container: <nil>
STEP: delete the pod
Jun  4 14:50:08.657: INFO: Waiting for pod downwardapi-volume-09b1e19f-86d8-11e9-8620-ba945f56578b to disappear
Jun  4 14:50:08.665: INFO: Pod downwardapi-volume-09b1e19f-86d8-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:50:08.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lqrqm" for this suite.
Jun  4 14:50:14.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:50:14.984: INFO: namespace: e2e-tests-downward-api-lqrqm, resource: bindings, ignored listing per whitelist
Jun  4 14:50:15.188: INFO: namespace e2e-tests-downward-api-lqrqm deletion completed in 6.516010395s

• [SLOW TEST:10.844 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:50:15.194: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jun  4 14:50:18.114: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-10969581-86d8-11e9-8620-ba945f56578b,GenerateName:,Namespace:e2e-tests-events-xklbq,SelfLink:/api/v1/namespaces/e2e-tests-events-xklbq/pods/send-events-10969581-86d8-11e9-8620-ba945f56578b,UID:1097aad4-86d8-11e9-9957-a6a8fec88741,ResourceVersion:35481,Generation:0,CreationTimestamp:2019-06-04 14:50:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 87323867,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-c6wmc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-c6wmc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-c6wmc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-4jvsx-65d7bd6f69-45s5z,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003daf650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003daf670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:50:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:50:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:50:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-06-04 14:50:16 +0000 UTC  }],Message:,Reason:,HostIP:138.68.109.151,PodIP:172.25.1.220,StartTime:2019-06-04 14:50:16 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-06-04 14:50:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://330c779a6ec14b04834c54f86915615adc0e45d7282cd60af2710283ca6c7dfe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jun  4 14:50:20.120: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jun  4 14:50:22.128: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:50:22.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-xklbq" for this suite.
Jun  4 14:51:02.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:51:02.491: INFO: namespace: e2e-tests-events-xklbq, resource: bindings, ignored listing per whitelist
Jun  4 14:51:02.587: INFO: namespace e2e-tests-events-xklbq deletion completed in 40.434937773s

• [SLOW TEST:47.394 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:51:02.592: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jun  4 14:51:02.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 create -f - --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:03.247: INFO: stderr: ""
Jun  4 14:51:03.247: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun  4 14:51:03.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:03.397: INFO: stderr: ""
Jun  4 14:51:03.397: INFO: stdout: "update-demo-nautilus-86mhz update-demo-nautilus-klflb "
Jun  4 14:51:03.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-86mhz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:03.845: INFO: stderr: ""
Jun  4 14:51:03.845: INFO: stdout: ""
Jun  4 14:51:03.845: INFO: update-demo-nautilus-86mhz is created but not running
Jun  4 14:51:08.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:09.228: INFO: stderr: ""
Jun  4 14:51:09.228: INFO: stdout: "update-demo-nautilus-86mhz update-demo-nautilus-klflb "
Jun  4 14:51:09.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-86mhz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:09.441: INFO: stderr: ""
Jun  4 14:51:09.441: INFO: stdout: "true"
Jun  4 14:51:09.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-86mhz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:09.626: INFO: stderr: ""
Jun  4 14:51:09.626: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 14:51:09.626: INFO: validating pod update-demo-nautilus-86mhz
Jun  4 14:51:09.739: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 14:51:09.739: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 14:51:09.739: INFO: update-demo-nautilus-86mhz is verified up and running
Jun  4 14:51:09.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-klflb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:09.871: INFO: stderr: ""
Jun  4 14:51:09.871: INFO: stdout: "true"
Jun  4 14:51:09.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-klflb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:10.007: INFO: stderr: ""
Jun  4 14:51:10.007: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 14:51:10.007: INFO: validating pod update-demo-nautilus-klflb
Jun  4 14:51:10.099: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 14:51:10.099: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 14:51:10.099: INFO: update-demo-nautilus-klflb is verified up and running
STEP: scaling down the replication controller
Jun  4 14:51:10.111: INFO: scanned /root for discovery docs: <nil>
Jun  4 14:51:10.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:11.540: INFO: stderr: ""
Jun  4 14:51:11.540: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun  4 14:51:11.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:11.677: INFO: stderr: ""
Jun  4 14:51:11.677: INFO: stdout: "update-demo-nautilus-86mhz update-demo-nautilus-klflb "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun  4 14:51:16.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:16.950: INFO: stderr: ""
Jun  4 14:51:16.950: INFO: stdout: "update-demo-nautilus-klflb "
Jun  4 14:51:16.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-klflb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:17.090: INFO: stderr: ""
Jun  4 14:51:17.090: INFO: stdout: "true"
Jun  4 14:51:17.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-klflb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:17.233: INFO: stderr: ""
Jun  4 14:51:17.233: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 14:51:17.233: INFO: validating pod update-demo-nautilus-klflb
Jun  4 14:51:17.243: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 14:51:17.243: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 14:51:17.243: INFO: update-demo-nautilus-klflb is verified up and running
STEP: scaling up the replication controller
Jun  4 14:51:17.246: INFO: scanned /root for discovery docs: <nil>
Jun  4 14:51:17.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:18.479: INFO: stderr: ""
Jun  4 14:51:18.479: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun  4 14:51:18.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:18.753: INFO: stderr: ""
Jun  4 14:51:18.753: INFO: stdout: "update-demo-nautilus-6gjrl update-demo-nautilus-klflb "
Jun  4 14:51:18.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-6gjrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:19.006: INFO: stderr: ""
Jun  4 14:51:19.006: INFO: stdout: ""
Jun  4 14:51:19.006: INFO: update-demo-nautilus-6gjrl is created but not running
Jun  4 14:51:24.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:24.166: INFO: stderr: ""
Jun  4 14:51:24.166: INFO: stdout: "update-demo-nautilus-6gjrl update-demo-nautilus-klflb "
Jun  4 14:51:24.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-6gjrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:24.436: INFO: stderr: ""
Jun  4 14:51:24.436: INFO: stdout: "true"
Jun  4 14:51:24.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-6gjrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:24.631: INFO: stderr: ""
Jun  4 14:51:24.631: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 14:51:24.631: INFO: validating pod update-demo-nautilus-6gjrl
Jun  4 14:51:24.729: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 14:51:24.729: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 14:51:24.730: INFO: update-demo-nautilus-6gjrl is verified up and running
Jun  4 14:51:24.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-klflb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:24.894: INFO: stderr: ""
Jun  4 14:51:24.894: INFO: stdout: "true"
Jun  4 14:51:24.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods update-demo-nautilus-klflb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:25.115: INFO: stderr: ""
Jun  4 14:51:25.115: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun  4 14:51:25.115: INFO: validating pod update-demo-nautilus-klflb
Jun  4 14:51:25.125: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun  4 14:51:25.125: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun  4 14:51:25.125: INFO: update-demo-nautilus-klflb is verified up and running
STEP: using delete to clean up resources
Jun  4 14:51:25.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:25.279: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun  4 14:51:25.279: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun  4 14:51:25.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-vx9kt'
Jun  4 14:51:25.526: INFO: stderr: "No resources found.\n"
Jun  4 14:51:25.526: INFO: stdout: ""
Jun  4 14:51:25.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-063591806 get pods -l name=update-demo --namespace=e2e-tests-kubectl-vx9kt -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun  4 14:51:25.749: INFO: stderr: ""
Jun  4 14:51:25.749: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:51:25.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vx9kt" for this suite.
Jun  4 14:51:49.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:51:50.194: INFO: namespace: e2e-tests-kubectl-vx9kt, resource: bindings, ignored listing per whitelist
Jun  4 14:51:50.453: INFO: namespace e2e-tests-kubectl-vx9kt deletion completed in 24.695315647s

• [SLOW TEST:47.862 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:51:50.461: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jun  4 14:51:50.980: INFO: Waiting up to 5m0s for pod "downward-api-4923a3b9-86d8-11e9-8620-ba945f56578b" in namespace "e2e-tests-downward-api-pmtkh" to be "success or failure"
Jun  4 14:51:50.992: INFO: Pod "downward-api-4923a3b9-86d8-11e9-8620-ba945f56578b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.095154ms
Jun  4 14:51:53.047: INFO: Pod "downward-api-4923a3b9-86d8-11e9-8620-ba945f56578b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.066497383s
STEP: Saw pod success
Jun  4 14:51:53.047: INFO: Pod "downward-api-4923a3b9-86d8-11e9-8620-ba945f56578b" satisfied condition "success or failure"
Jun  4 14:51:53.061: INFO: Trying to get logs from node worker-4jvsx-65d7bd6f69-45s5z pod downward-api-4923a3b9-86d8-11e9-8620-ba945f56578b container dapi-container: <nil>
STEP: delete the pod
Jun  4 14:51:53.097: INFO: Waiting for pod downward-api-4923a3b9-86d8-11e9-8620-ba945f56578b to disappear
Jun  4 14:51:53.101: INFO: Pod downward-api-4923a3b9-86d8-11e9-8620-ba945f56578b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:51:53.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pmtkh" for this suite.
Jun  4 14:51:59.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:51:59.762: INFO: namespace: e2e-tests-downward-api-pmtkh, resource: bindings, ignored listing per whitelist
Jun  4 14:51:59.946: INFO: namespace e2e-tests-downward-api-pmtkh deletion completed in 6.839257894s

• [SLOW TEST:9.485 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Jun  4 14:51:59.951: INFO: >>> kubeConfig: /tmp/kubeconfig-063591806
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jun  4 14:52:03.151: INFO: Successfully updated pod "annotationupdate4ecd2fbf-86d8-11e9-8620-ba945f56578b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Jun  4 14:52:05.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rr5sk" for this suite.
Jun  4 14:52:27.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun  4 14:52:27.968: INFO: namespace: e2e-tests-projected-rr5sk, resource: bindings, ignored listing per whitelist
Jun  4 14:52:28.082: INFO: namespace e2e-tests-projected-rr5sk deletion completed in 22.535927377s

• [SLOW TEST:28.132 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSJun  4 14:52:28.086: INFO: Running AfterSuite actions on all nodes
Jun  4 14:52:28.086: INFO: Running AfterSuite actions on node 1
Jun  4 14:52:28.086: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6919.088 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h55m22.133253257s
Test Suite Passed
